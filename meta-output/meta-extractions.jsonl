{"id":"8879_label_robust_and_differentiall","title":"Label Robust and Differentially Private Linear Regression: Computational and Statistical Efficiency","authors":[{"first_name":"Xiyang","last_name":"Liu","affiliations":["Paul Allen School of Computer Science & Engineering, University of Washington","xiyangl@cs.washington.edu"]},{"first_name":"Prateek","last_name":"Jain","affiliations":["Google Research","prajain@google.com"]},{"first_name":"Weihao","last_name":"Kong","affiliations":["Google Research","weihaokong@google.com"]},{"first_name":"Sewoong","last_name":"Oh","affiliations":["Paul Allen School of Computer Science & Engineering, University of Washington","Google Research","sewoong@cs.washington.edu"]},{"first_name":"Arun Sai","last_name":"Suggala","affiliations":["Google Research","arunss@google.com"]}],"categories":["Differential Privacy","Linear Regression","Computational Efficiency","Statistical Efficiency","Privacy-Preserving Algorithms","Machine Learning"],"publication_date":null,"abstract":null}
{"id":"505_gslb_the_graph_structure_learn","title":"GSLB: The Graph Structure Learning Benchmark","authors":[{"first_name":"Zhixun","last_name":"Li","affiliations":["Department of Systems Engineering and Engineering Management"]},{"first_name":"Liang","last_name":"Wang","affiliations":["The Chinese University of Hong Kong","Center for Research on Intelligent Perception and Computing","State Key Laboratory of Multimodal Artificial Intelligence Systems","Institute of Automation","Chinese Academy of Sciences","School of Artificial Intelligence","University of Chinese Academy of Sciences"]},{"first_name":"Xin","last_name":"Sun","affiliations":["Department of Automation","University of Science and Technology of China"]},{"first_name":"Yifan","last_name":"Luo","affiliations":["School of Cyberspace Security","Beijing University of Posts and Telecommunications"]},{"first_name":"Yanqiao","last_name":"Zhu","affiliations":["Department of Computer Science","University of California","Los Angeles"]},{"first_name":"Dingshuo","last_name":"Chen","affiliations":["The Chinese University of Hong Kong","Center for Research on Intelligent Perception and Computing","State Key Laboratory of Multimodal Artificial Intelligence Systems","Institute of Automation","Chinese Academy of Sciences"]},{"first_name":"Yingtao","last_name":"Luo","affiliations":["Department of Computer Science","University of California","Los Angeles"]},{"first_name":"Xiangxin","last_name":"Zhou","affiliations":["The Chinese University of Hong Kong","Center for Research on Intelligent Perception and Computing","State Key Laboratory of Multimodal Artificial Intelligence Systems","Institute of Automation","Chinese Academy of Sciences"]},{"first_name":"Qiang","last_name":"Liu","affiliations":["The Chinese University of Hong Kong","Center for Research on Intelligent Perception and Computing","State Key Laboratory of Multimodal Artificial Intelligence Systems","Institute of Automation","Chinese Academy of Sciences"]},{"first_name":"Shu","last_name":"Wu","affiliations":["The Chinese University of Hong Kong","Center for Research on Intelligent Perception and Computing","State Key Laboratory of Multimodal Artificial Intelligence Systems","Institute of Automation","Chinese Academy of Sciences"]},{"first_name":"Jeffrey Xu","last_name":"Yu","affiliations":["The Chinese University of Hong Kong","Center for Research on Intelligent Perception and Computing","State Key Laboratory of Multimodal Artificial Intelligence Systems","Institute of Automation","Chinese Academy of Sciences","Heinz College of Information Systems and Public Policy","Machine Learning Department","School of Computer Science","Carnegie Mellon University"]}],"categories":["Graph Structure Learning","Graph Neural Networks","Benchmarking","Machine Learning","Artificial Intelligence","Graph Datasets"],"publication_date":null,"abstract":null}
{"id":"2307.00619","title":"Solving Linear Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models","authors":[{"first_name":"Litu","last_name":"Rout","affiliations":["The University of Texas at Austin"]},{"first_name":"Negin","last_name":"Raoof","affiliations":["The University of Texas at Austin"]},{"first_name":"Giannis","last_name":"Daras","affiliations":["The University of Texas at Austin"]},{"first_name":"Constantine","last_name":"Caramanis","affiliations":["The University of Texas at Austin"]},{"first_name":"Alexandros G.","last_name":"Dimakis","affiliations":["The University of Texas at Austin"]},{"first_name":"Sanjay","last_name":"Shakkottai","affiliations":["The University of Texas at Austin"]}],"categories":["Linear Inverse Problems","Posterior Sampling","Latent Diffusion Models","Generative Modeling","Denoising","Super-resolution"],"publication_date":"2023-07-02","abstract":"We present the first framework to solve linear inverse problems leveraging\npre-trained latent diffusion models. Previously proposed algorithms (such as\nDPS and DDRM) only apply to pixel-space diffusion models. We theoretically\nanalyze our algorithm showing provable sample recovery in a linear model\nsetting. The algorithmic insight obtained from our analysis extends to more\ngeneral settings often considered in practice. Experimentally, we outperform\npreviously proposed posterior sampling algorithms in a wide variety of problems\nincluding random inpainting, block inpainting, denoising, deblurring,\ndestriping, and super-resolution."}
{"id":"14483_label_poisoning_is_all_you_nee","title":"Label Poisoning is All You Need","authors":[{"first_name":"Rishi D.","last_name":"Jha","affiliations":["Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle"]},{"first_name":"Jonathan","last_name":"Hayase","affiliations":["Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle"]},{"first_name":"Sewoong","last_name":"Oh","affiliations":["Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle"]}],"categories":["Backdoor Attacks","Machine Learning Security","Label Poisoning","Model Poisoning","Adversarial Attacks","Neural Networks"],"publication_date":null,"abstract":"In a backdoor attack, an adversary injects corrupted data into a model’s training dataset in order to gain control over its predictions on images with a specific attacker-defined trigger. A typical corrupted training example requires altering both the image, by applying the trigger, and the label. Models trained on clean images, therefore, were considered safe from backdoor attacks. However, in some common machine learning scenarios, the training labels are provided by potentially malicious third-parties. This includes crowd-sourced annotation and knowledge distillation. We, hence, investigate a fundamental question: can we launch a successful backdoor attack by only corrupting labels? We introduce a novel approach to design label-only backdoor attacks, which we call FLIP, and demonstrate its strengths on three datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet) and four architectures (ResNet-32, ResNet-18, VGG-19, and Vision Transformer). With only 2% of CIFAR-10 labels corrupted, FLIP achieves a near-perfect attack success rate of 99.4% while suffering only a 1.8% drop in the clean test accuracy. Our approach builds upon the recent advances in trajectory matching, originally introduced for dataset distillation."}
{"id":"2310.03758","title":"A Unified Framework for Uniform Signal Recovery in Nonlinear Generative Compressed Sensing","authors":[{"first_name":"Junren","last_name":"Chen","affiliations":["University of Hong Kong"]},{"first_name":"Jonathan","last_name":"Scarlett","affiliations":["National University of Singapore"]},{"first_name":"Michael K.","last_name":"Ng","affiliations":["Hong Kong Baptist University"]},{"first_name":"Zhaoqiang","last_name":"Liu","affiliations":["UESTC"]}],"categories":["Generative Compressed Sensing","Nonlinear Signal Recovery","Uniform Recovery Guarantees","Lipschitz Approximation","Concentration Inequality","Experimental Results"],"publication_date":"2023-09-25","abstract":"In generative compressed sensing (GCS), we want to recover a signal\n$\\mathbf{x}^* \\in \\mathbb{R}^n$ from $m$ measurements ($m\\ll n$) using a\ngenerative prior $\\mathbf{x}^*\\in G(\\mathbb{B}_2^k(r))$, where $G$ is typically\nan $L$-Lipschitz continuous generative model and $\\mathbb{B}_2^k(r)$ represents\nthe radius-$r$ $\\ell_2$-ball in $\\mathbb{R}^k$. Under nonlinear measurements,\nmost prior results are non-uniform, i.e., they hold with high probability for a\nfixed $\\mathbf{x}^*$ rather than for all $\\mathbf{x}^*$ simultaneously. In this\npaper, we build a unified framework to derive uniform recovery guarantees for\nnonlinear GCS where the observation model is nonlinear and possibly\ndiscontinuous or unknown. Our framework accommodates GCS with 1-bit/uniformly\nquantized observations and single index models as canonical examples.\nSpecifically, using a single realization of the sensing ensemble and\ngeneralized Lasso, {\\em all} $\\mathbf{x}^*\\in G(\\mathbb{B}_2^k(r))$ can be\nrecovered up to an $\\ell_2$-error at most $\\epsilon$ using roughly\n$\\tilde{O}({k}/{\\epsilon^2})$ samples, with omitted logarithmic factors\ntypically being dominated by $\\log L$. Notably, this almost coincides with\nexisting non-uniform guarantees up to logarithmic factors, hence the uniformity\ncosts very little. As part of our technical contributions, we introduce the\nLipschitz approximation to handle discontinuous observation models. We also\ndevelop a concentration inequality that produces tighter bounds for product\nprocesses whose index sets have low metric entropy. Experimental results are\npresented to corroborate our theory."}
{"id":"2310.18786","title":"A Competitive Algorithm for Agnostic Active Learning","authors":[{"first_name":"Eric","last_name":"Price","affiliations":["Department of Computer Science, University of Texas at Austin"]},{"first_name":"Yihan","last_name":"Zhou","affiliations":["Department of Computer Science, University of Texas at Austin"]}],"categories":["Active Learning","Agnostic Learning","Algorithm","Binary Classification","Machine Learning","Optimization"],"publication_date":"2023-10-28","abstract":"For some hypothesis classes and input distributions, active agnostic learning\nneeds exponentially fewer samples than passive learning; for other classes and\ndistributions, it offers little to no improvement. The most popular algorithms\nfor agnostic active learning express their performance in terms of a parameter\ncalled the disagreement coefficient, but it is known that these algorithms are\ninefficient on some inputs.\n  We take a different approach to agnostic active learning, getting an\nalgorithm that is competitive with the optimal algorithm for any binary\nhypothesis class $H$ and distribution $D_X$ over $X$. In particular, if any\nalgorithm can use $m^*$ queries to get $O(\\eta)$ error, then our algorithm uses\n$O(m^* \\log |H|)$ queries to get $O(\\eta)$ error. Our algorithm lies in the\nvein of the splitting-based approach of Dasgupta [2004], which gets a similar\nresult for the realizable ($\\eta = 0$) setting.\n  We also show that it is NP-hard to do better than our algorithm's $O(\\log\n|H|)$ overhead in general."}
{"id":"35_discs_a_benchmark_for_discrete","title":"DISCS: A Benchmark for Discrete Sampling","authors":[{"first_name":"Anonymous","last_name":"Author(s)","affiliations":["Affiliation"]}],"categories":["Discrete Sampling","Benchmarking","Simulation","Optimization","Graphical Models","Generative Models"],"publication_date":null,"abstract":"Sampling in discrete spaces, with critical applications in simulation and optimization, has recently been boosted by significant advances in gradient-based approaches that exploit modern accelerators like GPUs. However, two key challenges hinder the further research progress in discrete sampling. First, since there is no consensus on experimental settings, the empirical results in different research papers are often not comparable. Secondly, implementing samplers and target distributions often requires a nontrivial amount of effort in terms of calibration, parallelism, and evaluation. To tackle these challenges, we propose DISCS (DIScrete Sampling), a tailored package and benchmark that supports unified and efficient implementation and evaluations for discrete sampling in three types of tasks: sampling for classical graphical models, combinatorial optimization, and energy-based generative models. Throughout the comprehensive evaluations in DISCS, we acquired new insights into scalability, design principles for proposal distributions, and lessons for adaptive sampling design. DISCS implements representative discrete samplers in existing research works as baselines, and offers a simple interface that researchers can conveniently design new discrete samplers and compare with baselines in a calibrated setup directly."}
{"id":"2310.12979","title":"Predicting a Protein's Stability under a Million Mutations","authors":[{"first_name":"Jeffrey","last_name":"Ouyang-Zhang","affiliations":["UT Austin","jozhang@utexas.edu"]},{"first_name":"Daniel J.","last_name":"Diaz","affiliations":["UT Austin","danny.diaz@utexas.edu"]},{"first_name":"Adam R.","last_name":"Klivans","affiliations":["UT Austin","klivans@cs.utexas.edu"]},{"first_name":"Philipp","last_name":"Krähenbühl","affiliations":["UT Austin","philkr@cs.utexas.edu"]}],"categories":["Protein Stability","Protein Engineering","Deep Learning","Thermodynamic Stability","Mutations","Epistatic Interactions"],"publication_date":"2023-10-19","abstract":"Stabilizing proteins is a foundational step in protein engineering. However,\nthe evolutionary pressure of all extant proteins makes identifying the scarce\nnumber of mutations that will improve thermodynamic stability challenging. Deep\nlearning has recently emerged as a powerful tool for identifying promising\nmutations. Existing approaches, however, are computationally expensive, as the\nnumber of model inferences scales with the number of mutations queried. Our\nmain contribution is a simple, parallel decoding algorithm. Our Mutate\nEverything is capable of predicting the effect of all single and double\nmutations in one forward pass. It is even versatile enough to predict\nhigher-order mutations with minimal computational overhead. We build Mutate\nEverything on top of ESM2 and AlphaFold, neither of which were trained to\npredict thermodynamic stability. We trained on the Mega-Scale cDNA proteolysis\ndataset and achieved state-of-the-art performance on single and higher-order\nmutations on S669, ProTherm, and ProteinGym datasets. Code is available at\nhttps://github.com/jozhang97/MutateEverything"}
{"id":"2306.10191","title":"Neural Priming for Sample-Efficient Adaptation","authors":[{"first_name":"Matthew","last_name":"Wallingford","affiliations":["University of Washington"]},{"first_name":"Vivek","last_name":"Ramanujan","affiliations":["University of Washington"]},{"first_name":"Alex","last_name":"Fang","affiliations":["University of Washington"]},{"first_name":"Aditya","last_name":"Kusupati","affiliations":["University of Washington"]},{"first_name":"Roozbeh","last_name":"Mottaghi","affiliations":["University of Washington"]},{"first_name":"Aniruddha","last_name":"Kembhavi","affiliations":["PRIOR, Allen Institute for AI"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington"]},{"first_name":"Ali","last_name":"Farhadi","affiliations":["University of Washington"]}],"categories":["Neural Priming","Sample-Efficient Adaptation","Distribution Shift","Transfer Learning","Pretrained Models","Deep Learning"],"publication_date":"2023-06-16","abstract":"We propose Neural Priming, a technique for adapting large pretrained models\nto distribution shifts and downstream tasks given few or no labeled examples.\nPresented with class names or unlabeled test samples, Neural Priming enables\nthe model to recall and conditions its parameters on relevant data seen\nthroughout pretraining, thereby priming it for the test distribution. Neural\nPriming can be performed at test time, even for pretraining datasets as large\nas LAION-2B. Performing lightweight updates on the recalled data significantly\nimproves accuracy across a variety of distribution shift and transfer learning\nbenchmarks. Concretely, in the zero-shot setting, we see a 2.45% improvement in\naccuracy on ImageNet and 3.81% accuracy improvement on average across standard\ntransfer learning benchmarks. Further, using Neural Priming at inference to\nadapt to distribution shift, we see a 1.41% accuracy improvement on ImageNetV2.\nThese results demonstrate the effectiveness of Neural Priming in addressing the\nchallenge of limited labeled data and changing distributions. Code is available\nat github.com/RAIVNLab/neural-priming."}
{"id":"2310.08702","title":"ELDEN: Exploration via Local Dependencies","authors":[{"first_name":"Jiaheng","last_name":"Hu","affiliations":["University of Texas at Austin"]},{"first_name":"Zizhao","last_name":"Wang","affiliations":["University of Texas at Austin"]},{"first_name":"Peter","last_name":"Stone","affiliations":["University of Texas at Austin","Sony AI"]},{"first_name":"Roberto","last_name":"Martín-Martín","affiliations":["University of Texas at Austin"]}],"categories":["Reinforcement Learning","Exploration","Intrinsic Reward","State Space","Dependencies","Curiosity"],"publication_date":"2023-10-12","abstract":"Tasks with large state space and sparse rewards present a longstanding\nchallenge to reinforcement learning. In these tasks, an agent needs to explore\nthe state space efficiently until it finds a reward. To deal with this problem,\nthe community has proposed to augment the reward function with intrinsic\nreward, a bonus signal that encourages the agent to visit interesting states.\nIn this work, we propose a new way of defining interesting states for\nenvironments with factored state spaces and complex chained dependencies, where\nan agent's actions may change the value of one entity that, in order, may\naffect the value of another entity. Our insight is that, in these environments,\ninteresting states for exploration are states where the agent is uncertain\nwhether (as opposed to how) entities such as the agent or objects have some\ninfluence on each other. We present ELDEN, Exploration via Local DepENdencies,\na novel intrinsic reward that encourages the discovery of new interactions\nbetween entities. ELDEN utilizes a novel scheme -- the partial derivative of\nthe learned dynamics to model the local dependencies between entities\naccurately and computationally efficiently. The uncertainty of the predicted\ndependencies is then used as an intrinsic reward to encourage exploration\ntoward new interactions. We evaluate the performance of ELDEN on four different\ndomains with complex dependencies, ranging from 2D grid worlds to 3D robotic\ntasks. In all domains, ELDEN correctly identifies local dependencies and learns\nsuccessful policies, significantly outperforming previous state-of-the-art\nexploration methods."}
{"id":"2301.04644","title":"Does progress on ImageNet transfer to real-world datasets?","authors":[{"first_name":"Alex","last_name":"Fang","affiliations":["University of Washington","apf1@cs.washington.edu"]},{"first_name":"Simon","last_name":"Kornblith","affiliations":["Google Research, Brain Team","skornblith@google.com"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington","Allen Institute for AI","schmidt@cs.washington.edu"]}],"categories":["Image Classification","Transfer Learning","Real-World Datasets","Neural Network Architecture","Model Transferability","Data Augmentation"],"publication_date":"2023-01-11","abstract":"Does progress on ImageNet transfer to real-world datasets? We investigate\nthis question by evaluating ImageNet pre-trained models with varying accuracy\n(57% - 83%) on six practical image classification datasets. In particular, we\nstudy datasets collected with the goal of solving real-world tasks (e.g.,\nclassifying images from camera traps or satellites), as opposed to web-scraped\nbenchmarks collected for comparing models. On multiple datasets, models with\nhigher ImageNet accuracy do not consistently yield performance improvements.\nFor certain tasks, interventions such as data augmentation improve performance\neven when architectures do not. We hope that future benchmarks will include\nmore diverse datasets to encourage a more comprehensive approach to improving\nlearning algorithms."}
{"id":"2312.07577","title":"Benchmarking Distribution Shift in Tabular Data with TableShift","authors":[{"first_name":"Josh","last_name":"Gardner","affiliations":["University of Washington"]},{"first_name":"Zoran","last_name":"Popovi´ c","affiliations":["Allen Institute for AI"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington","Allen Institute for AI"]}],"categories":["Machine Learning","Tabular Data","Distribution Shift","Benchmarking","Robustness","Domain Generalization"],"publication_date":"2023-12-10","abstract":"Robustness to distribution shift has become a growing concern for text and\nimage models as they transition from research subjects to deployment in the\nreal world. However, high-quality benchmarks for distribution shift in tabular\nmachine learning tasks are still lacking despite the widespread real-world use\nof tabular data and differences in the models used for tabular data in\ncomparison to text and images. As a consequence, the robustness of tabular\nmodels to distribution shift is poorly understood. To address this issue, we\nintroduce TableShift, a distribution shift benchmark for tabular data.\nTableShift contains 15 binary classification tasks in total, each with an\nassociated shift, and includes a diverse set of data sources, prediction\ntargets, and distribution shifts. The benchmark covers domains including\nfinance, education, public policy, healthcare, and civic participation, and is\naccessible using only a few lines of Python code via the TableShift API. We\nconduct a large-scale study comparing several state-of-the-art tabular data\nmodels alongside robust learning and domain generalization methods on the\nbenchmark tasks. Our study demonstrates (1) a linear trend between\nin-distribution (ID) and out-of-distribution (OOD) accuracy; (2) domain\nrobustness methods can reduce shift gaps but at the cost of reduced ID\naccuracy; (3) a strong relationship between shift gap (difference between ID\nand OOD performance) and shifts in the label distribution.\n  The benchmark data, Python package, model implementations, and more\ninformation about TableShift are available at\nhttps://github.com/mlfoundations/tableshift and https://tableshift.org ."}
{"id":"2307.07050","title":"Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the Quantum Many-Body Schrödinger Equation","authors":[{"first_name":"Kirill","last_name":"Neklyudov","affiliations":["Vector Institute"]},{"first_name":"Jannes","last_name":"Nys","affiliations":["Institute of Physics & Center for Quantum Science and Engineering"]},{"first_name":"Luca","last_name":"Thiede","affiliations":["École Polytechnique Fédérale de Lausanne (EPFL)"]},{"first_name":"Juan Felipe","last_name":"Carrasquilla","affiliations":["University of Toronto"]},{"first_name":"Qiang","last_name":"Liu","affiliations":["UT Austin"]},{"first_name":"Max","last_name":"Welling","affiliations":["Microsoft Research"]},{"first_name":"Alireza","last_name":"Makhzani","affiliations":["University of Waterloo","AI4Science"]}],"categories":["Quantum Physics","Quantum Chemistry","Computational Physics","Quantum Computing","Machine Learning","Optimization"],"publication_date":"2023-07-06","abstract":"Solving the quantum many-body Schr\\\"odinger equation is a fundamental and\nchallenging problem in the fields of quantum physics, quantum chemistry, and\nmaterial sciences. One of the common computational approaches to this problem\nis Quantum Variational Monte Carlo (QVMC), in which ground-state solutions are\nobtained by minimizing the energy of the system within a restricted family of\nparameterized wave functions. Deep learning methods partially address the\nlimitations of traditional QVMC by representing a rich family of wave functions\nin terms of neural networks. However, the optimization objective in QVMC\nremains notoriously hard to minimize and requires second-order optimization\nmethods such as natural gradient. In this paper, we first reformulate energy\nfunctional minimization in the space of Born distributions corresponding to\nparticle-permutation (anti-)symmetric wave functions, rather than the space of\nwave functions. We then interpret QVMC as the Fisher-Rao gradient flow in this\ndistributional space, followed by a projection step onto the variational\nmanifold. This perspective provides us with a principled framework to derive\nnew QMC algorithms, by endowing the distributional space with better metrics,\nand following the projected gradient flow induced by those metrics. More\nspecifically, we propose \"Wasserstein Quantum Monte Carlo\" (WQMC), which uses\nthe gradient flow induced by the Wasserstein metric, rather than Fisher-Rao\nmetric, and corresponds to transporting the probability mass, rather than\nteleporting it. We demonstrate empirically that the dynamics of WQMC results in\nfaster convergence to the ground state of molecular systems."}
{"id":"2310.06794v1","title":"$f$-Policy Gradients: A General Framework for Goal Conditioned RL using $f$-Divergences","authors":[{"first_name":"Siddhant","last_name":"Agarwal","affiliations":["The University of Texas at Austin"]},{"first_name":"Ishan","last_name":"Durugkar","affiliations":["Sony AI"]},{"first_name":"Peter","last_name":"Stone","affiliations":["The University of Texas at Austin"]},{"first_name":"Amy","last_name":"Zhang","affiliations":["The University of Texas at Austin","Sony AI"]}],"categories":["Reinforcement Learning","Policy Gradients","Goal-Conditioned RL","f-Divergences","Exploration","State-MaxEnt RL"],"publication_date":"2023-10-10","abstract":"Goal-Conditioned Reinforcement Learning (RL) problems often have access to\nsparse rewards where the agent receives a reward signal only when it has\nachieved the goal, making policy optimization a difficult problem. Several\nworks augment this sparse reward with a learned dense reward function, but this\ncan lead to sub-optimal policies if the reward is misaligned. Moreover, recent\nworks have demonstrated that effective shaping rewards for a particular problem\ncan depend on the underlying learning algorithm. This paper introduces a novel\nway to encourage exploration called $f$-Policy Gradients, or $f$-PG. $f$-PG\nminimizes the f-divergence between the agent's state visitation distribution\nand the goal, which we show can lead to an optimal policy. We derive gradients\nfor various f-divergences to optimize this objective. Our learning paradigm\nprovides dense learning signals for exploration in sparse reward settings. We\nfurther introduce an entropy-regularized policy optimization objective, that we\ncall $state$-MaxEnt RL (or $s$-MaxEnt RL) as a special case of our objective.\nWe show that several metric-based shaping rewards like L2 can be used with\n$s$-MaxEnt RL, providing a common ground to study such metric-based shaping\nrewards with efficient exploration. We find that $f$-PG has better performance\ncompared to standard policy gradient methods on a challenging gridworld as well\nas the Point Maze and FetchReach environments. More information on our website\nhttps://agarwalsiddhant10.github.io/projects/fpg.html."}
{"id":"2307.10350","title":"Improving Multimodal Datasets with Image Captioning","authors":[{"first_name":"Thao","last_name":"Nguyen","affiliations":["University of Washington"]},{"first_name":"Samir Yitzhak","last_name":"Gadre","affiliations":["Columbia University"]},{"first_name":"Gabriel","last_name":"Ilharco","affiliations":["University of Washington"]},{"first_name":"Sewoong","last_name":"Oh","affiliations":["University of Washington","Google Research"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington","Allen Institute for Artificial Intelligence","LAION"]}],"categories":["Multimodal Datasets","Image Captioning","Data Filtering","Synthetic Captions","Vision-Language Models","Web Datasets"],"publication_date":"2023-07-19","abstract":"Massive web datasets play a key role in the success of large vision-language\nmodels like CLIP and Flamingo. However, the raw web data is noisy, and existing\nfiltering methods to reduce noise often come at the expense of data diversity.\nOur work focuses on caption quality as one major source of noise, and studies\nhow generated captions can increase the utility of web-scraped datapoints with\nnondescript text. Through exploring different mixing strategies for raw and\ngenerated captions, we outperform the best filtering method proposed by the\nDataComp benchmark by 2% on ImageNet and 4% on average across 38 tasks, given a\ncandidate pool of 128M image-text pairs. Our best approach is also 2x better at\nFlickr and MS-COCO retrieval. We then analyze what makes synthetic captions an\neffective source of text supervision. In experimenting with different image\ncaptioning models, we also demonstrate that the performance of a model on\nstandard image captioning benchmarks (e.g., NoCaps CIDEr) is not a reliable\nindicator of the utility of the captions it generates for multimodal training.\nFinally, our experiments with using generated captions at DataComp's large\nscale (1.28B image-text pairs) offer insights into the limitations of synthetic\ntext, as well as the importance of image curation with increasing training data\nquantity. The synthetic captions used in our experiments are now available on\nHuggingFace."}
{"id":"solving-linear-inverse-probs","title":"Solving Linear Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models","authors":[{"first_name":"Litu","last_name":"Rout","affiliations":["The University of Texas at Austin"]},{"first_name":"Negin","last_name":"Raoof","affiliations":["The University of Texas at Austin"]},{"first_name":"Giannis","last_name":"Daras","affiliations":["The University of Texas at Austin"]},{"first_name":"Constantine","last_name":"Caramanis","affiliations":["The University of Texas at Austin"]},{"first_name":"Alexandros G.","last_name":"Dimakis","affiliations":["The University of Texas at Austin"]},{"first_name":"Sanjay","last_name":"Shakkottai","affiliations":["The University of Texas at Austin"]}],"categories":["Linear Inverse Problems","Posterior Sampling","Latent Diffusion Models","Denoising","Inpainting","Super-resolution"],"publication_date":null,"abstract":"We present the first framework to solve linear inverse problems leveraging pre-trained latent diffusion models. Previously proposed algorithms (such as DPS and DDRM) only apply to pixel-space diffusion models. We theoretically analyze our algorithm showing provable sample recovery in a linear model setting. The algorithmic insight obtained from our analysis extends to more general settings often considered in practice. Experimentally, we outperform previously proposed posterior sampling algorithms in a wide variety of problems including random inpainting, block inpainting, denoising, deblurring, destriping, and super-resolution."}
{"id":"2305.19435","title":"AdANNS: A Framework for Adaptive Semantic Search","authors":[{"first_name":"Aniket","last_name":"Rege","affiliations":["University of Washington"]},{"first_name":"Aditya","last_name":"Kusupati","affiliations":["University of Washington","Google Research"]},{"first_name":"Sharan Ranjit","last_name":"S","affiliations":["University of Washington"]},{"first_name":"Alan","last_name":"Fan","affiliations":["University of Washington"]},{"first_name":"Qingqing","last_name":"Cao","affiliations":["University of Washington"]},{"first_name":"Sham","last_name":"Kakade","affiliations":["Harvard University"]},{"first_name":"Prateek","last_name":"Jain","affiliations":["Google Research"]},{"first_name":"Ali","last_name":"Farhadi","affiliations":["University of Washington"]}],"categories":["Semantic Search","Adaptive Representations","Approximate Nearest Neighbor Search","ANNS","Matryoshka Representations","Quantization"],"publication_date":"2023-05-30","abstract":"Web-scale search systems learn an encoder to embed a given query which is\nthen hooked into an approximate nearest neighbor search (ANNS) pipeline to\nretrieve similar data points. To accurately capture tail queries and data\npoints, learned representations typically are rigid, high-dimensional vectors\nthat are generally used as-is in the entire ANNS pipeline and can lead to\ncomputationally expensive retrieval. In this paper, we argue that instead of\nrigid representations, different stages of ANNS can leverage adaptive\nrepresentations of varying capacities to achieve significantly better\naccuracy-compute trade-offs, i.e., stages of ANNS that can get away with more\napproximate computation should use a lower-capacity representation of the same\ndata point. To this end, we introduce AdANNS, a novel ANNS design framework\nthat explicitly leverages the flexibility of Matryoshka Representations. We\ndemonstrate state-of-the-art accuracy-compute trade-offs using novel\nAdANNS-based key ANNS building blocks like search data structures (AdANNS-IVF)\nand quantization (AdANNS-OPQ). For example on ImageNet retrieval, AdANNS-IVF is\nup to 1.5% more accurate than the rigid representations-based IVF at the same\ncompute budget; and matches accuracy while being up to 90x faster in wall-clock\ntime. For Natural Questions, 32-byte AdANNS-OPQ matches the accuracy of the\n64-byte OPQ baseline constructed using rigid representations -- same accuracy\nat half the cost! We further show that the gains from AdANNS translate to\nmodern-day composite ANNS indices that combine search structures and\nquantization. Finally, we demonstrate that AdANNS can enable inference-time\nadaptivity for compute-aware search on ANNS indices built non-adaptively on\nmatryoshka representations. Code is open-sourced at\nhttps://github.com/RAIVNLab/AdANNS."}
{"id":"2311.05067","title":"Accelerating Exploration with Unlabeled Prior Data","authors":[{"first_name":"Qiyang","last_name":"Li","affiliations":["UC Berkeley"]},{"first_name":"Jason","last_name":"Zhang","affiliations":["UC Berkeley"]},{"first_name":"Dibya","last_name":"Ghosh","affiliations":["UC Berkeley"]},{"first_name":"Amy","last_name":"Zhang","affiliations":["UT Austin"]},{"first_name":"Sergey","last_name":"Levine","affiliations":["UC Berkeley"]}],"categories":["Reinforcement Learning","Exploration","Prior Data","Sparse Reward Tasks","Deep RL","Neural Information Processing Systems"],"publication_date":"2023-11-09","abstract":"Learning to solve tasks from a sparse reward signal is a major challenge for\nstandard reinforcement learning (RL) algorithms. However, in the real world,\nagents rarely need to solve sparse reward tasks entirely from scratch. More\noften, we might possess prior experience to draw on that provides considerable\nguidance about which actions and outcomes are possible in the world, which we\ncan use to explore more effectively for new tasks. In this work, we study how\nprior data without reward labels may be used to guide and accelerate\nexploration for an agent solving a new sparse reward task. We propose a simple\napproach that learns a reward model from online experience, labels the\nunlabeled prior data with optimistic rewards, and then uses it concurrently\nalongside the online data for downstream policy and critic optimization. This\ngeneral formula leads to rapid exploration in several challenging sparse-reward\ndomains where tabula rasa exploration is insufficient, including the AntMaze\ndomain, Adroit hand manipulation domain, and a visual simulated robotic\nmanipulation domain. Our results highlight the ease of incorporating unlabeled\nprior data into existing online RL algorithms, and the (perhaps surprising)\neffectiveness of doing so."}
{"id":"2302.03770","title":"Provably Efficient Offline Goal-Conditioned Reinforcement Learning with General Function Approximation and Single-Policy Concentrability","authors":[{"first_name":"Hanlin","last_name":"Zhu","affiliations":["EECS, UC Berkeley","Meta AI"]},{"first_name":"Amy","last_name":"Zhang","affiliations":["ECE, UT Austin","Meta AI"]}],"categories":["Reinforcement Learning","Goal-Conditioned Learning","Offline Learning","Theoretical Analysis","Function Approximation","Sample Complexity"],"publication_date":"2023-02-07","abstract":"Goal-conditioned reinforcement learning (GCRL) refers to learning\ngeneral-purpose skills that aim to reach diverse goals. In particular, offline\nGCRL only requires purely pre-collected datasets to perform training tasks\nwithout additional interactions with the environment. Although offline GCRL has\nbecome increasingly prevalent and many previous works have demonstrated its\nempirical success, the theoretical understanding of efficient offline GCRL\nalgorithms is not well established, especially when the state space is huge and\nthe offline dataset only covers the policy we aim to learn. In this paper, we\nprovide a rigorous theoretical analysis of an existing empirically successful\noffline GCRL algorithm. We prove that under slight modification, this algorithm\nenjoys an $\\widetilde{O}(\\text{poly}(1/\\epsilon))$ sample complexity (where\n$\\epsilon$ is the desired suboptimality of the learned policy) with general\nfunction approximation thanks to the property of (semi-)strong convexity of the\nobjective functions. We only require nearly minimal assumptions on the dataset\n(single-policy concentrability) and the function class (realizability).\nMoreover, this algorithm consists of two uninterleaved optimization steps,\nwhich we refer to as $V$-learning and policy learning, and is computationally\nstable since it does not involve minimax optimization. We also empirically\nvalidate our theory by showing that the modified algorithm outperforms the\nprevious algorithm in various real-world environments. To the best of our\nknowledge, this is the first algorithm that is both provably efficient with\ngeneral function approximation and single-policy concentrability, and\nempirically successful without requiring solving minimax optimization problems."}
{"id":"2308.07536","title":"Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem","authors":[{"first_name":"Jincheng","last_name":"Cao","affiliations":["Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA"]},{"first_name":"Ruichen","last_name":"Jiang","affiliations":["Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA"]},{"first_name":"Nazanin","last_name":"Abolfazli","affiliations":["Department of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ, USA"]},{"first_name":"Erfan","last_name":"Yazdandoost Hamedani","affiliations":["Department of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ, USA"]},{"first_name":"Aryan","last_name":"Mokhtari","affiliations":["Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA"]}],"categories":["Stochastic Bilevel Optimization","Convex Optimization","Projection-Free Methods","Stochastic Gradients","Variance Reduction","Optimization Algorithms"],"publication_date":"2023-08-15","abstract":"In this paper, we study a class of stochastic bilevel optimization problems,\nalso known as stochastic simple bilevel optimization, where we minimize a\nsmooth stochastic objective function over the optimal solution set of another\nstochastic convex optimization problem. We introduce novel stochastic bilevel\noptimization methods that locally approximate the solution set of the\nlower-level problem via a stochastic cutting plane, and then run a conditional\ngradient update with variance reduction techniques to control the error induced\nby using stochastic gradients. For the case that the upper-level function is\nconvex, our method requires\n$\\tilde{\\mathcal{O}}(\\max\\{1/\\epsilon_f^{2},1/\\epsilon_g^{2}\\}) $ stochastic\noracle queries to obtain a solution that is $\\epsilon_f$-optimal for the\nupper-level and $\\epsilon_g$-optimal for the lower-level. This guarantee\nimproves the previous best-known complexity of\n$\\mathcal{O}(\\max\\{1/\\epsilon_f^{4},1/\\epsilon_g^{4}\\})$. Moreover, for the\ncase that the upper-level function is non-convex, our method requires at most\n$\\tilde{\\mathcal{O}}(\\max\\{1/\\epsilon_f^{3},1/\\epsilon_g^{3}\\}) $ stochastic\noracle queries to find an $(\\epsilon_f, \\epsilon_g)$-stationary point. In the\nfinite-sum setting, we show that the number of stochastic oracle calls required\nby our method are $\\tilde{\\mathcal{O}}(\\sqrt{n}/\\epsilon)$ and\n$\\tilde{\\mathcal{O}}(\\sqrt{n}/\\epsilon^{2})$ for the convex and non-convex\nsettings, respectively, where $\\epsilon=\\min \\{\\epsilon_f,\\epsilon_g\\}$."}
{"id":"2310.05309","title":"Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Methods","authors":[{"first_name":"Constantine","last_name":"Caramanis","affiliations":["University of Texas at Austin"]},{"first_name":"Dimitris","last_name":"Fotakis","affiliations":["NTUA"]},{"first_name":"Alkis","last_name":"Kalavasis","affiliations":["Yale University"]},{"first_name":"Vasilis","last_name":"Kontonis","affiliations":["University of Texas at Austin"]},{"first_name":"Christos","last_name":"Tzamos","affiliations":["UOA","University of Wisconsin-Madison"]}],"categories":["Deep Neural Networks","Reinforcement Learning","Combinatorial Optimization","Policy Gradient Methods","Generative Models","Regularization"],"publication_date":"2023-10-08","abstract":"Deep Neural Networks and Reinforcement Learning methods have empirically\nshown great promise in tackling challenging combinatorial problems. In those\nmethods a deep neural network is used as a solution generator which is then\ntrained by gradient-based methods (e.g., policy gradient) to successively\nobtain better solution distributions. In this work we introduce a novel\ntheoretical framework for analyzing the effectiveness of such methods. We ask\nwhether there exist generative models that (i) are expressive enough to\ngenerate approximately optimal solutions; (ii) have a tractable, i.e,\npolynomial in the size of the input, number of parameters; (iii) their\noptimization landscape is benign in the sense that it does not contain\nsub-optimal stationary points. Our main contribution is a positive answer to\nthis question. Our result holds for a broad class of combinatorial problems\nincluding Max- and Min-Cut, Max-$k$-CSP, Maximum-Weight-Bipartite-Matching, and\nthe Traveling Salesman Problem. As a byproduct of our analysis we introduce a\nnovel regularization process over vanilla gradient descent and provide\ntheoretical and experimental evidence that it helps address vanishing-gradient\nissues and escape bad stationary points."}
{"id":"2302.09057","title":"Consistent Diffusion Models: Mitigating Sampling Drift by Learning to be Consistent","authors":[{"first_name":"Giannis","last_name":"Daras","affiliations":["Department of Computer Science, University of Texas at Austin"]},{"first_name":"Yuval","last_name":"Dagan","affiliations":["Electrical Engineering and Computer Science, University of California, Berkeley"]},{"first_name":"Alexandros G.","last_name":"Dimakis","affiliations":["Department of ECE, University of Texas at Austin"]},{"first_name":"Constantinos","last_name":"Daskalakis","affiliations":["Electrical Engineering and Computer Science, Massachusetts Institute of Technology"]}],"categories":["Diffusion Models","Generative Models","Machine Learning","Computer Science","Artificial Intelligence","Deep Learning"],"publication_date":"2023-02-17","abstract":"Imperfect score-matching leads to a shift between the training and the\nsampling distribution of diffusion models. Due to the recursive nature of the\ngeneration process, errors in previous steps yield sampling iterates that drift\naway from the training distribution. Yet, the standard training objective via\nDenoising Score Matching (DSM) is only designed to optimize over non-drifted\ndata. To train on drifted data, we propose to enforce a \\emph{consistency}\nproperty which states that predictions of the model on its own generated data\nare consistent across time. Theoretically, we show that if the score is learned\nperfectly on some non-drifted points (via DSM) and if the consistency property\nis enforced everywhere, then the score is learned accurately everywhere.\nEmpirically we show that our novel training objective yields state-of-the-art\nresults for conditional and unconditional generation in CIFAR-10 and baseline\nimprovements in AFHQ and FFHQ. We open-source our code and models:\nhttps://github.com/giannisdaras/cdm"}
{"id":"2305.11765","title":"Tester-Learners for Halfspaces: Universal Algorithms","authors":[{"first_name":"Aravind","last_name":"Gollakota","affiliations":["UT Austin"]},{"first_name":"Adam R.","last_name":"Klivans","affiliations":["UT Austin"]},{"first_name":"Konstantinos","last_name":"Stavropoulos","affiliations":["UT Austin"]},{"first_name":"Arsen","last_name":"Vasilyan","affiliations":["MIT"]}],"categories":["Machine Learning","Testable Learning","Halfspaces","Poincaré Distributions","Log-Concave Distributions","Sum-of-Squares Program"],"publication_date":"2023-05-19","abstract":"We give the first tester-learner for halfspaces that succeeds universally\nover a wide class of structured distributions. Our universal tester-learner\nruns in fully polynomial time and has the following guarantee: the learner\nachieves error $O(\\mathrm{opt}) + \\epsilon$ on any labeled distribution that\nthe tester accepts, and moreover, the tester accepts whenever the marginal is\nany distribution that satisfies a Poincar\\'e inequality. In contrast to prior\nwork on testable learning, our tester is not tailored to any single target\ndistribution but rather succeeds for an entire target class of distributions.\nThe class of Poincar\\'e distributions includes all strongly log-concave\ndistributions, and, assuming the Kannan--L\\'{o}vasz--Simonovits (KLS)\nconjecture, includes all log-concave distributions. In the special case where\nthe label noise is known to be Massart, our tester-learner achieves error\n$\\mathrm{opt} + \\epsilon$ while accepting all log-concave distributions\nunconditionally (without assuming KLS). Our tests rely on checking\nhypercontractivity of the unknown distribution using a sum-of-squares (SOS)\nprogram, and crucially make use of the fact that Poincar\\'e distributions are\ncertifiably hypercontractive in the SOS framework."}
{"id":"2304.14108","title":"DataComp: In search of the next generation of multimodal datasets","authors":[{"first_name":"Samir Yitzhak","last_name":"Gadre","affiliations":["University of Washington"]},{"first_name":"Gabriel","last_name":"Ilharco","affiliations":["Columbia University"]},{"first_name":"Alex","last_name":"Fang","affiliations":["Tel Aviv University"]},{"first_name":"Jonathan","last_name":"Hayase","affiliations":["Apple"]},{"first_name":"Georgios","last_name":"Smyrnis","affiliations":["UT Austin"]},{"first_name":"Thao","last_name":"Nguyen","affiliations":["LAION"]},{"first_name":"Ryan","last_name":"Marten","affiliations":["AI2"]},{"first_name":"Mitchell","last_name":"Wortsman","affiliations":["Juelich Supercomputing Center, Research Center Juelich"]},{"first_name":"Dhruba","last_name":"Ghosh","affiliations":["University of Illinois Urbana-Champaign"]},{"first_name":"Jieyu","last_name":"Zhang","affiliations":["Graz University of Technology"]},{"first_name":"Eyal","last_name":"Orgad","affiliations":["Hebrew University"]},{"first_name":"Rahim","last_name":"Entezari","affiliations":["Google Research"]},{"first_name":"Giannis","last_name":"Daras","affiliations":["Snorkel AI"]},{"first_name":"Sarah","last_name":"Pratt","affiliations":["University of Washington"]},{"first_name":"Vivek","last_name":"Ramanujan","affiliations":["Columbia University"]},{"first_name":"Yonatan","last_name":"Bitton","affiliations":["Tel Aviv University"]},{"first_name":"Kalyani","last_name":"Marathe","affiliations":["Tel Aviv University"]},{"first_name":"Stephen","last_name":"Mussmann","affiliations":["University of Washington"]},{"first_name":"Richard","last_name":"Vencu","affiliations":["Columbia University"]},{"first_name":"Mehdi","last_name":"Cherti","affiliations":["Tel Aviv University"]},{"first_name":"Ranjay","last_name":"Krishna","affiliations":["University of Washington"]},{"first_name":"Pang Wei","last_name":"Koh","affiliations":["Columbia University"]},{"first_name":"Olga","last_name":"Saukh","affiliations":["Tel Aviv University"]},{"first_name":"Alexander","last_name":"Ratner","affiliations":["University of Washington"]},{"first_name":"Shuran","last_name":"Song","affiliations":["Columbia University"]},{"first_name":"Hannaneh","last_name":"Hajishirzi","affiliations":["Tel Aviv University"]},{"first_name":"Ali","last_name":"Farhadi","affiliations":["University of Washington"]},{"first_name":"Romain","last_name":"Beaumont","affiliations":["Columbia University"]},{"first_name":"Sewoong","last_name":"Oh","affiliations":["Tel Aviv University"]},{"first_name":"Alex","last_name":"Dimakis","affiliations":["University of Washington"]},{"first_name":"Jenia","last_name":"Jitsev","affiliations":["Columbia University"]},{"first_name":"Yair","last_name":"Carmon","affiliations":["Tel Aviv University"]},{"first_name":"Vaishaal","last_name":"Shankar","affiliations":["University of Washington"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["Columbia University"]}],"categories":["Multimodal Learning","Dataset Design","Machine Learning","CLIP","Image-Text Datasets","Benchmarking"],"publication_date":"2023-04-27","abstract":"Multimodal datasets are a critical component in recent breakthroughs such as\nStable Diffusion and GPT-4, yet their design does not receive the same research\nattention as model architectures or training algorithms. To address this\nshortcoming in the ML ecosystem, we introduce DataComp, a testbed for dataset\nexperiments centered around a new candidate pool of 12.8 billion image-text\npairs from Common Crawl. Participants in our benchmark design new filtering\ntechniques or curate new data sources and then evaluate their new dataset by\nrunning our standardized CLIP training code and testing the resulting model on\n38 downstream test sets. Our benchmark consists of multiple compute scales\nspanning four orders of magnitude, which enables the study of scaling trends\nand makes the benchmark accessible to researchers with varying resources. Our\nbaseline experiments show that the DataComp workflow leads to better training\nsets. In particular, our best baseline, DataComp-1B, enables training a CLIP\nViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperforming\nOpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training\nprocedure and compute. We release DataComp and all accompanying code at\nwww.datacomp.ai."}
{"id":"2306.09136","title":"Finite-Time Logarithmic Bayes Regret Upper Bounds","authors":[{"first_name":"Alexia","last_name":"Atsidakou","affiliations":["University of Texas, Austin"]},{"first_name":"Branislav","last_name":"Kveton","affiliations":["AWS AI Labs*"]},{"first_name":"Sumeet","last_name":"Katariya","affiliations":["Amazon"]},{"first_name":"Constantine","last_name":"Caramanis","affiliations":["University of Texas, Austin"]},{"first_name":"Sujay","last_name":"Sanghavi","affiliations":["University of Texas, Austin","Amazon"]}],"categories":["Bayesian bandits","Multi-armed bandit","Upper confidence bound algorithm","Linear bandits","Thompson sampling","Regret minimization"],"publication_date":"2023-06-15","abstract":"We derive the first finite-time logarithmic Bayes regret upper bounds for\nBayesian bandits. In a multi-armed bandit, we obtain $O(c_\\Delta \\log n)$ and\n$O(c_h \\log^2 n)$ upper bounds for an upper confidence bound algorithm, where\n$c_h$ and $c_\\Delta$ are constants depending on the prior distribution and the\ngaps of bandit instances sampled from it, respectively. The latter bound\nasymptotically matches the lower bound of Lai (1987). Our proofs are a major\ntechnical departure from prior works, while being simple and general. To show\nthe generality of our techniques, we apply them to linear bandits. Our results\nprovide insights on the value of prior in the Bayesian setting, both in the\nobjective and as a side information given to the learner. They significantly\nimprove upon existing $\\tilde{O}(\\sqrt{n})$ bounds, which have become standard\nin the literature despite the logarithmic lower bound of Lai (1987)."}
{"id":"2308.06595","title":"VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use","authors":[{"first_name":"Yonatan","last_name":"Bitton","affiliations":["Hebrew University","Google Research"]},{"first_name":"Hritik","last_name":"Bansal","affiliations":["UCLA"]},{"first_name":"Jack","last_name":"Hessel","affiliations":["Allen Institute for AI"]},{"first_name":"Rulin","last_name":"Shao","affiliations":["University of Washington"]},{"first_name":"Wanrong","last_name":"Zhu","affiliations":["UCSB"]},{"first_name":"Anas","last_name":"Awadalla","affiliations":["University of Washington"]},{"first_name":"Josh","last_name":"Gardner","affiliations":["University of Washington"]},{"first_name":"Rohan","last_name":"Taori","affiliations":["Stanford"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington","LAION"]}],"categories":["Vision-Language Models","Instruction Following","Benchmarking","Multimodal Generation","Evaluation","Real-World Applications"],"publication_date":"2023-08-12","abstract":"We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for\nevaluation of instruction-following vision-language models for real-world use.\nOur starting point is curating 70 'instruction families' that we envision\ninstruction tuned vision-language models should be able to address. Extending\nbeyond evaluations like VQAv2 and COCO, tasks range from basic recognition to\ngame playing and creative generation. Following curation, our dataset comprises\n592 test queries, each with a human-authored instruction-conditioned caption.\nThese descriptions surface instruction-specific factors, e.g., for an\ninstruction asking about the accessibility of a storefront for wheelchair\nusers, the instruction-conditioned caption describes ramps/potential obstacles.\nThese descriptions enable 1) collecting human-verified reference outputs for\neach instance; and 2) automatic evaluation of candidate multimodal generations\nusing a text-only LLM, aligning with human judgment. We quantify quality gaps\nbetween models and references using both human and automatic evaluations; e.g.,\nthe top-performing instruction-following model wins against the GPT-4 reference\nin just 27% of the comparison. VisIT-Bench is dynamic to participate,\npractitioners simply submit their model's response on the project website;\nData, code and leaderboard is available at visit-bench.github.io."}
{"id":"2306.10615","title":"Agnostically Learning Single-Index Models using Omnipredictors","authors":[{"first_name":"Aravind","last_name":"Gollakota","affiliations":["UT Austin"]},{"first_name":"Parikshit","last_name":"Gopalan","affiliations":["Apple"]},{"first_name":"Adam R.","last_name":"Klivans","affiliations":["UT Austin"]},{"first_name":"Konstantinos","last_name":"Stavropoulos","affiliations":["UT Austin"]}],"categories":["Single-Index Models","Agnostic Learning","Monotone Activations","Lipschitz Activations","Bregman Divergences","Calibrated Multiaccuracy"],"publication_date":"2023-06-18","abstract":"We give the first result for agnostically learning Single-Index Models (SIMs)\nwith arbitrary monotone and Lipschitz activations. All prior work either held\nonly in the realizable setting or required the activation to be known.\nMoreover, we only require the marginal to have bounded second moments, whereas\nall prior work required stronger distributional assumptions (such as\nanticoncentration or boundedness). Our algorithm is based on recent work by\n[GHK$^+$23] on omniprediction using predictors satisfying calibrated\nmultiaccuracy. Our analysis is simple and relies on the relationship between\nBregman divergences (or matching losses) and $\\ell_p$ distances. We also\nprovide new guarantees for standard algorithms like GLMtron and logistic\nregression in the agnostic setting."}
{"id":"2306.03310","title":"LIBERO: Benchmarking Knowledge Transfer for Lifelong Robot Learning","authors":[{"first_name":"Bo","last_name":"Liu","affiliations":["The University of Texas at Austin"]},{"first_name":"Yifeng","last_name":"Zhu","affiliations":["Sony AI"]},{"first_name":"Chongkai","last_name":"Gao","affiliations":["Tsinghua University"]},{"first_name":"Yihao","last_name":"Feng","affiliations":["Tsinghua University"]},{"first_name":"Qiang","last_name":"Liu","affiliations":["The University of Texas at Austin"]},{"first_name":"Yuke","last_name":"Zhu","affiliations":["The University of Texas at Austin"]},{"first_name":"Peter","last_name":"Stone","affiliations":["The University of Texas at Austin"]}],"categories":["Lifelong Learning","Robot Manipulation","Knowledge Transfer","Procedural Knowledge","Policy Architectures","Algorithms"],"publication_date":"2023-06-05","abstract":"Lifelong learning offers a promising paradigm of building a generalist agent\nthat learns and adapts over its lifespan. Unlike traditional lifelong learning\nproblems in image and text domains, which primarily involve the transfer of\ndeclarative knowledge of entities and concepts, lifelong learning in\ndecision-making (LLDM) also necessitates the transfer of procedural knowledge,\nsuch as actions and behaviors. To advance research in LLDM, we introduce\nLIBERO, a novel benchmark of lifelong learning for robot manipulation.\nSpecifically, LIBERO highlights five key research topics in LLDM: 1) how to\nefficiently transfer declarative knowledge, procedural knowledge, or the\nmixture of both; 2) how to design effective policy architectures and 3)\neffective algorithms for LLDM; 4) the robustness of a lifelong learner with\nrespect to task ordering; and 5) the effect of model pretraining for LLDM. We\ndevelop an extendible procedural generation pipeline that can in principle\ngenerate infinitely many tasks. For benchmarking purpose, we create four task\nsuites (130 tasks in total) that we use to investigate the above-mentioned\nresearch topics. To support sample-efficient learning, we provide high-quality\nhuman-teleoperated demonstration data for all tasks. Our extensive experiments\npresent several insightful or even unexpected discoveries: sequential\nfinetuning outperforms existing lifelong learning methods in forward transfer,\nno single visual encoder architecture excels at all types of knowledge\ntransfer, and naive supervised pretraining can hinder agents' performance in\nthe subsequent LLDM. Check the website at https://libero-project.github.io for\nthe code and the datasets."}
{"id":"2304.13013","title":"Stable and low-precision training for large-scale vision-language models","authors":[{"first_name":"Mitchell","last_name":"Wortsman","affiliations":["University of Washington"]},{"first_name":"Tim","last_name":"Dettmers","affiliations":["University of Washington"]},{"first_name":"Luke","last_name":"Zettlemoyer","affiliations":["University of Washington","Meta AI Research","FAIR Team","Allen Institute for AI","LAION"]},{"first_name":"Ari","last_name":"Morcos","affiliations":["Meta AI Research","FAIR Team"]},{"first_name":"Ali","last_name":"Farhadi","affiliations":["FAIR Team"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["FAIR Team","Allen Institute for AI","LAION"]}],"categories":["Vision-Language Models","Training Methods","Quantized Training","Stabilization Techniques","Large-scale Models","Machine Learning Breakthroughs"],"publication_date":"2023-04-25","abstract":"We introduce new methods for 1) accelerating and 2) stabilizing training for\nlarge language-vision models. 1) For acceleration, we introduce SwitchBack, a\nlinear layer for int8 quantized training which provides a speed-up of 13-25%\nwhile matching the performance of bfloat16 training within 0.1 percentage\npoints for the 1B parameter CLIP ViT-Huge -- the largest int8 training to date.\nOur main focus is int8 as GPU support for float8 is rare, though we also\nanalyze float8 training through simulation. While SwitchBack proves effective\nfor float8, we show that standard techniques are also successful if the network\nis trained and initialized so that large feature magnitudes are discouraged,\nwhich we accomplish via layer-scale initialized with zeros. 2) For stability,\nwe analyze loss spikes and find they consistently occur 1-8 iterations after\nthe squared gradients become under-estimated by their AdamW second moment\nestimator. As a result, we recommend an AdamW-Adafactor hybrid which avoids\nloss spikes when training a CLIP ViT-Huge model and outperforms gradient\nclipping at the scales we test."}
{"id":"11338_nearly_optimal_bounds_for_cycl","title":"Nearly Optimal Bounds for Cyclic Forgetting","authors":[{"first_name":"Halyun","last_name":"Jeong","affiliations":["University of California Los Angeles"]},{"first_name":"Mark","last_name":"Kong","affiliations":["University of California Los Angeles"]},{"first_name":"Deanna","last_name":"Needell","affiliations":["University of California Los Angeles"]},{"first_name":"William","last_name":"Swartworth","affiliations":["Carnegie Mellon University"]},{"first_name":"Rachel","last_name":"Ward","affiliations":["University of Texas at Austin"]}],"categories":["Continual Learning","Linear Tasks","Cyclic Task Ordering","Numerical Ranges","Sinusoidal Spiral","Machine Learning"],"publication_date":null,"abstract":null}
{"id":"2307.12532","title":"On the Connection between Pre-training Data Diversity and Fine-tuning Robustness","authors":[{"first_name":"Vivek","last_name":"Ramanujan","affiliations":["University of Washington"]},{"first_name":"Thao","last_name":"Nguyen","affiliations":["University of Washington"]},{"first_name":"Sewoong","last_name":"Oh","affiliations":["Google Research"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["Allen Institute for Artificial Intelligence"]},{"first_name":"Ali","last_name":"Farhadi","affiliations":["LAION"]}],"categories":["Pre-training","Data Diversity","Fine-tuning","Robustness","Deep Learning","Transfer Learning"],"publication_date":"2023-07-24","abstract":"Pre-training has been widely adopted in deep learning to improve model\nperformance, especially when the training data for a target task is limited. In\nour work, we seek to understand the implications of this training strategy on\nthe generalization properties of downstream models. More specifically, we ask\nthe following question: how do properties of the pre-training distribution\naffect the robustness of a fine-tuned model? The properties we explore include\nthe label space, label semantics, image diversity, data domains, and data\nquantity of the pre-training distribution. We find that the primary factor\ninfluencing downstream effective robustness (Taori et al., 2020) is data\nquantity, while other factors have limited significance. For example, reducing\nthe number of ImageNet pre-training classes by 4x while increasing the number\nof images per class by 4x (that is, keeping total data quantity fixed) does not\nimpact the robustness of fine-tuned models. We demonstrate our findings on\npre-training distributions drawn from various natural and synthetic data\nsources, primarily using the iWildCam-WILDS distribution shift as a test for\ndownstream robustness."}
{"id":"2306.02212","title":"Accelerated Quasi-Newton Proximal Extragradient: Faster Rate for Smooth Convex Optimization","authors":[{"first_name":"Ruichen","last_name":"Jiang","affiliations":["Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA"]},{"first_name":"Aryan","last_name":"Mokhtari","affiliations":["Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA"]}],"categories":["Smooth Convex Optimization","Quasi-Newton Method","Extragradient Method","Accelerated Optimization","Online Learning","Convex Optimization"],"publication_date":"2023-06-03","abstract":"In this paper, we propose an accelerated quasi-Newton proximal extragradient\n(A-QPNE) method for solving unconstrained smooth convex optimization problems.\nWith access only to the gradients of the objective, we prove that our method\ncan achieve a convergence rate of ${O}\\bigl(\\min\\{\\frac{1}{k^2},\n\\frac{\\sqrt{d\\log k}}{k^{2.5}}\\}\\bigr)$, where $d$ is the problem dimension and\n$k$ is the number of iterations. In particular, in the regime where $k =\n{O}(d)$, our method matches the optimal rate of ${O}(\\frac{1}{k^2})$ by\nNesterov's accelerated gradient (NAG). Moreover, in the the regime where $k =\n\\Omega(d \\log d)$, it outperforms NAG and converges at a faster rate of\n${O}\\bigl(\\frac{\\sqrt{d\\log k}}{k^{2.5}}\\bigr)$. To the best of our knowledge,\nthis result is the first to demonstrate a provable gain of a quasi-Newton-type\nmethod over NAG in the convex setting. To achieve such results, we build our\nmethod on a recent variant of the Monteiro-Svaiter acceleration framework and\nadopt an online learning perspective to update the Hessian approximation\nmatrices, in which we relate the convergence rate of our method to the dynamic\nregret of a specific online convex optimization problem in the space of\nmatrices."}
{"id":"2306.03792","title":"FAMO: Fast Adaptive Multitask Optimization","authors":[{"first_name":"Bo","last_name":"Liu","affiliations":["The University of Texas at Austin"]},{"first_name":"Yihao","last_name":"Feng","affiliations":["Salesforce AI Research"]},{"first_name":"Peter","last_name":"Stone","affiliations":["The University of Texas at Austin"]},{"first_name":"Qiang","last_name":"Liu","affiliations":["The University of Texas at Austin"]}],"categories":["Multitask Learning","Gradient Manipulation","Efficient Optimization","Machine Learning","Reinforcement Learning","Space and Time Complexity"],"publication_date":"2023-06-06","abstract":"One of the grand enduring goals of AI is to create generalist agents that can\nlearn multiple different tasks from diverse data via multitask learning (MTL).\nHowever, in practice, applying gradient descent (GD) on the average loss across\nall tasks may yield poor multitask performance due to severe under-optimization\nof certain tasks. Previous approaches that manipulate task gradients for a more\nbalanced loss decrease require storing and computing all task gradients\n($\\mathcal{O}(k)$ space and time where $k$ is the number of tasks), limiting\ntheir use in large-scale scenarios. In this work, we introduce Fast Adaptive\nMultitask Optimization FAMO, a dynamic weighting method that decreases task\nlosses in a balanced way using $\\mathcal{O}(1)$ space and time. We conduct an\nextensive set of experiments covering multi-task supervised and reinforcement\nlearning problems. Our results indicate that FAMO achieves comparable or\nsuperior performance to state-of-the-art gradient manipulation techniques while\noffering significant improvements in space and computational efficiency. Code\nis available at \\url{https://github.com/Cranial-XIX/FAMO}."}
{"id":"2302.14045","title":"Language Is Not All You Need: Aligning Perception with Language Models","authors":[{"first_name":"Shaohan","last_name":"Huang","affiliations":["Microsoft"]},{"first_name":"Li","last_name":"Dong","affiliations":["Microsoft"]},{"first_name":"Wenhui","last_name":"Wang","affiliations":["Microsoft"]},{"first_name":"Yaru","last_name":"Hao","affiliations":["Microsoft"]},{"first_name":"Saksham","last_name":"Singhal","affiliations":["Microsoft"]},{"first_name":"Shuming","last_name":"Ma","affiliations":["Microsoft"]},{"first_name":"Tengchao","last_name":"Lv","affiliations":["Microsoft"]},{"first_name":"Lei","last_name":"Cui","affiliations":["Microsoft"]},{"first_name":"Owais Khan","last_name":"Mohammed","affiliations":["Microsoft"]},{"first_name":"Barun","last_name":"Patra","affiliations":["Microsoft"]},{"first_name":"Qiang","last_name":"Liu","affiliations":["Microsoft"]},{"first_name":"Kriti","last_name":"Aggarwal","affiliations":["Microsoft"]},{"first_name":"Zewen","last_name":"Chi","affiliations":["Microsoft"]},{"first_name":"Johan","last_name":"Bjorck","affiliations":["Microsoft"]},{"first_name":"Vishrav","last_name":"Chaudhary","affiliations":["Microsoft"]},{"first_name":"Subhojit","last_name":"Som","affiliations":["Microsoft"]},{"first_name":"Xia","last_name":"Song","affiliations":["Microsoft"]},{"first_name":"Furu","last_name":"Wei","affiliations":["Microsoft"]}],"categories":["Language Models","Perception","Multimodal Learning","Vision","Multimodal Tasks","Large Language Models"],"publication_date":"2023-02-27","abstract":"A big convergence of language, multimodal perception, action, and world\nmodeling is a key step toward artificial general intelligence. In this work, we\nintroduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive\ngeneral modalities, learn in context (i.e., few-shot), and follow instructions\n(i.e., zero-shot). Specifically, we train Kosmos-1 from scratch on web-scale\nmultimodal corpora, including arbitrarily interleaved text and images,\nimage-caption pairs, and text data. We evaluate various settings, including\nzero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range\nof tasks without any gradient updates or finetuning. Experimental results show\nthat Kosmos-1 achieves impressive performance on (i) language understanding,\ngeneration, and even OCR-free NLP (directly fed with document images), (ii)\nperception-language tasks, including multimodal dialogue, image captioning,\nvisual question answering, and (iii) vision tasks, such as image recognition\nwith descriptions (specifying classification via text instructions). We also\nshow that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge\nfrom language to multimodal, and from multimodal to language. In addition, we\nintroduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning\ncapability of MLLMs."}
{"id":"2306.15447","title":"Are aligned neural networks adversarially aligned?","authors":[{"first_name":"Nicholas","last_name":"Carlini","affiliations":["Google DeepMind"]},{"first_name":"Milad","last_name":"Nasr","affiliations":["Google DeepMind"]},{"first_name":"Christopher A.","last_name":"Choquette-Choo","affiliations":["Google DeepMind"]},{"first_name":"Matthew","last_name":"Jagielski","affiliations":["Google DeepMind"]},{"first_name":"Irena","last_name":"Gao","affiliations":["Stanford"]},{"first_name":"Anas","last_name":"Awadalla","affiliations":["University of Washington"]},{"first_name":"Pang Wei","last_name":"Koh","affiliations":["Google DeepMind","University of Washington"]},{"first_name":"Daphne","last_name":"Ippolito","affiliations":["Google DeepMind"]},{"first_name":"Katherine","last_name":"Lee","affiliations":["Google DeepMind"]},{"first_name":"Florian","last_name":"Tramèr","affiliations":["ETH Zurich"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington"]}],"categories":["Neural Networks","Adversarial Attacks","NLP","Multimodal Models","Alignment Techniques","Ethical AI"],"publication_date":"2023-06-26","abstract":"Large language models are now tuned to align with the goals of their\ncreators, namely to be \"helpful and harmless.\" These models should respond\nhelpfully to user questions, but refuse to answer requests that could cause\nharm. However, adversarial users can construct inputs which circumvent attempts\nat alignment. In this work, we study to what extent these models remain\naligned, even when interacting with an adversarial user who constructs\nworst-case inputs (adversarial examples). These inputs are designed to cause\nthe model to emit harmful content that would otherwise be prohibited. We show\nthat existing NLP-based optimization attacks are insufficiently powerful to\nreliably attack aligned text models: even when current NLP-based attacks fail,\nwe can find adversarial inputs with brute force. As a result, the failure of\ncurrent attacks should not be seen as proof that aligned text models remain\naligned under adversarial inputs.\n  However the recent trend in large-scale ML models is multimodal models that\nallow users to provide images that influence the text that is generated. We\nshow these models can be easily attacked, i.e., induced to perform arbitrary\nun-aligned behavior through adversarial perturbation of the input image. We\nconjecture that improved NLP attacks may demonstrate this same level of\nadversarial control over text-only models."}
{"id":"2305.06927","title":"Convergence of Alternating Gradient Descent for Matrix Factorization","authors":[{"first_name":"Rachel","last_name":"Ward","affiliations":["University of Texas, Austin, TX"]},{"first_name":"Tamara G.","last_name":"Kolda","affiliations":["MathSci.ai, Dublin, CA"]}],"categories":["Matrix Factorization","Gradient Descent","Low-rank Factorization","Optimization","Convergence Analysis","Nonconvex Optimization"],"publication_date":"2023-05-11","abstract":"We consider alternating gradient descent (AGD) with fixed step size applied\nto the asymmetric matrix factorization objective. We show that, for a rank-$r$\nmatrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $T = C\n(\\frac{\\sigma_1(\\mathbf{A})}{\\sigma_r(\\mathbf{A})})^2 \\log(1/\\epsilon)$\niterations of alternating gradient descent suffice to reach an\n$\\epsilon$-optimal factorization $\\| \\mathbf{A} - \\mathbf{X} \\mathbf{Y}^{T}\n\\|^2 \\leq \\epsilon \\| \\mathbf{A}\\|^2$ with high probability starting from an\natypical random initialization. The factors have rank $d \\geq r$ so that\n$\\mathbf{X}_{T}\\in\\mathbb{R}^{m \\times d}$ and $\\mathbf{Y}_{T} \\in\\mathbb{R}^{n\n\\times d}$, and mild overparameterization suffices for the constant $C$ in the\niteration complexity $T$ to be an absolute constant. Experiments suggest that\nour proposed initialization is not merely of theoretical benefit, but rather\nsignificantly improves the convergence rate of gradient descent in practice.\nOur proof is conceptually simple: a uniform Polyak-\\L{}ojasiewicz (PL)\ninequality and uniform Lipschitz smoothness constant are guaranteed for a\nsufficient number of iterations, starting from our random initialization. Our\nproof method should be useful for extending and simplifying convergence\nanalyses for a broader class of nonconvex low-rank factorization problems."}
{"id":"2307.11030","title":"Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering","authors":[{"first_name":"Yijun","last_name":"Dong","affiliations":["Courant Institute of Mathematical Sciences, New York University"]},{"first_name":"Kevin","last_name":"Miller","affiliations":["Oden Institute for Computational Engineering & Science, University of Texas at Austin"]},{"first_name":"Qi","last_name":"Lei","affiliations":["Courant Institute of Mathematical Sciences & Center of Data Science, New York University"]},{"first_name":"Rachel","last_name":"Ward","affiliations":["Oden Institute for Computational Engineering & Science, University of Texas at Austin"]}],"categories":["Semi-supervised Learning","Relational Knowledge Distillation","Cluster-aware","Spectral Clustering","Label Efficiency","Data Augmentation Consistency Regularization"],"publication_date":"2023-07-20","abstract":"Despite the empirical success and practical significance of (relational)\nknowledge distillation that matches (the relations of) features between teacher\nand student models, the corresponding theoretical interpretations remain\nlimited for various knowledge distillation paradigms. In this work, we take an\ninitial step toward a theoretical understanding of relational knowledge\ndistillation (RKD), with a focus on semi-supervised classification problems. We\nstart by casting RKD as spectral clustering on a population-induced graph\nunveiled by a teacher model. Via a notion of clustering error that quantifies\nthe discrepancy between the predicted and ground truth clusterings, we\nillustrate that RKD over the population provably leads to low clustering error.\nMoreover, we provide a sample complexity bound for RKD with limited unlabeled\nsamples. For semi-supervised learning, we further demonstrate the label\nefficiency of RKD through a general framework of cluster-aware semi-supervised\nlearning that assumes low clustering errors. Finally, by unifying data\naugmentation consistency regularization into this cluster-aware framework, we\nshow that despite the common effect of learning accurate clusterings, RKD\nfacilitates a \"global\" perspective through spectral clustering, whereas\nconsistency regularization focuses on a \"local\" perspective via expansion."}
{"id":"2305.02456","title":"Streaming PCA for Markovian Data","authors":[{"first_name":"Syamantak","last_name":"Kumar","affiliations":["Department of Computer Science, University of Texas at Austin"]},{"first_name":"Purnamrita","last_name":"Sarkar","affiliations":["Department of Statistics and Data Sciences, University of Texas at Austin"]}],"categories":["Streaming PCA","Markovian Data","Principal Component Analysis","MCMC","Oja's Algorithm","Data Streams"],"publication_date":"2023-05-03","abstract":"Since its inception in 1982, Oja's algorithm has become an established method\nfor streaming principle component analysis (PCA). We study the problem of\nstreaming PCA, where the data-points are sampled from an irreducible,\naperiodic, and reversible Markov chain. Our goal is to estimate the top\neigenvector of the unknown covariance matrix of the stationary distribution.\nThis setting has implications in scenarios where data can solely be sampled\nfrom a Markov Chain Monte Carlo (MCMC) type algorithm, and the objective is to\nperform inference on parameters of the stationary distribution. Most\nconvergence guarantees for Oja's algorithm in the literature assume that the\ndata-points are sampled IID. For data streams with Markovian dependence, one\ntypically downsamples the data to get a \"nearly\" independent data stream. In\nthis paper, we obtain the first sharp rate for Oja's algorithm on the entire\ndata, where we remove the logarithmic dependence on the sample size, $n$,\nresulting from throwing data away in downsampling strategies."}
{"id":"NeurIPS-pggan","title":"Conditional Generative Model in Total Variation","authors":[{"first_name":"Ajil","last_name":"Jalal","affiliations":["UC Berkeley"]},{"first_name":"Justin","last_name":"Kang","affiliations":["UC Berkeley"]},{"first_name":"Ananya","last_name":"Uppal","affiliations":["UT Austin"]},{"first_name":"Kannan","last_name":"Ramchandran","affiliations":["UC Berkeley"]},{"first_name":"Eric","last_name":"Price","affiliations":["UT Austin"]}],"categories":["Conditional Generative Model","Total Variation","Generative Models","Linear Regression","Feed-forward Generative Models","Maximum Likelihood Estimator"],"publication_date":null,"abstract":"A conditional generative model is a method for sampling from a conditional distribution p(y | x). For example, one may want to sample an image of a cat given the label “cat”. A feed-forward conditional generative model is a function g(x, z) that takes the input x and a random seed z, and outputs a sample y from p(y | x). Ideally, the distribution of outputs (x, g(x, z)) would be close in total variation to the ideal distribution (x, y). Generalization bounds for other learning models require assumptions on the distribution of x, even in simple settings like linear regression with Gaussian noise. We show these assumptions are unnecessary in our model, for both linear regression and single-layer ReLU networks. Given samples (x, y), we show how to learn a 1-layer ReLU conditional generative model in total variation. As our result has no assumption on the distribution of inputs x, if we are given access to the internal activations of a deep generative model, we can compose our 1-layer guarantee to progressively learn the deep model using a near-linear number of samples."}
{"id":"2307.05663","title":"Objaverse-XL: A Universe of 10M+ 3D Objects","authors":[{"first_name":"Matt","last_name":"Deitke","affiliations":["Allen Institute for AI"]},{"first_name":"Ruoshi","last_name":"Liu","affiliations":["Columbia University"]},{"first_name":"Matthew","last_name":"Wallingford","affiliations":["University of Washington, Seattle"]},{"first_name":"Huong","last_name":"Ngo","affiliations":["University of Washington, Seattle"]},{"first_name":"Oscar","last_name":"Michel","affiliations":["Allen Institute for AI"]},{"first_name":"Aditya","last_name":"Kusupati","affiliations":["University of Washington, Seattle"]},{"first_name":"Alan","last_name":"Fan","affiliations":["University of Washington, Seattle"]},{"first_name":"Christian","last_name":"Laforte","affiliations":["Stability AI"]},{"first_name":"Vikram","last_name":"Voleti","affiliations":["Stability AI"]},{"first_name":"Samir Yitzhak","last_name":"Gadre","affiliations":["Columbia University"]},{"first_name":"Eli","last_name":"VanderBilt","affiliations":["Allen Institute for AI"]},{"first_name":"Aniruddha","last_name":"Kembhavi","affiliations":["Allen Institute for AI","University of Washington, Seattle"]},{"first_name":"Carl","last_name":"Vondrick","affiliations":["Columbia University"]},{"first_name":"Georgia","last_name":"Gkioxari","affiliations":["California Institute of Technology"]},{"first_name":"Kiana","last_name":"Ehsani","affiliations":["Allen Institute for AI"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["Allen Institute for AI","University of Washington, Seattle","LAION"]},{"first_name":"Ali","last_name":"Farhadi","affiliations":["University of Washington, Seattle"]}],"categories":["3D Objects","Dataset","3D Vision","Object Recognition","Machine Learning","Computer Vision"],"publication_date":"2023-07-11","abstract":"Natural language processing and 2D vision models have attained remarkable\nproficiency on many tasks primarily by escalating the scale of training data.\nHowever, 3D vision tasks have not seen the same progress, in part due to the\nchallenges of acquiring high-quality 3D data. In this work, we present\nObjaverse-XL, a dataset of over 10 million 3D objects. Our dataset comprises\ndeduplicated 3D objects from a diverse set of sources, including manually\ndesigned objects, photogrammetry scans of landmarks and everyday items, and\nprofessional scans of historic and antique artifacts. Representing the largest\nscale and diversity in the realm of 3D datasets, Objaverse-XL enables\nsignificant new possibilities for 3D vision. Our experiments demonstrate the\nimprovements enabled with the scale provided by Objaverse-XL. We show that by\ntraining Zero123 on novel view synthesis, utilizing over 100 million multi-view\nrendered images, we achieve strong zero-shot generalization abilities. We hope\nthat releasing Objaverse-XL will enable further innovations in the field of 3D\nvision at scale."}
{"id":"2304.06939","title":"Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with Text","authors":[{"first_name":"Wanrong","last_name":"Zhu","affiliations":["University of California, Santa Barbara"]},{"first_name":"Jack","last_name":"Hessel","affiliations":["Allen Institute for Artificial Intelligence"]},{"first_name":"Anas","last_name":"Awadalla","affiliations":["Paul G. Allen School of Computer Science, University of Washington"]},{"first_name":"Samir Yitzhak","last_name":"Gadre","affiliations":["Columbia University","Yonsei University","LAION"]},{"first_name":"Jesse","last_name":"Dodge","affiliations":["Allen Institute for Artificial Intelligence"]},{"first_name":"Alex","last_name":"Fang","affiliations":["Paul G. Allen School of Computer Science, University of Washington"]},{"first_name":"Youngjae","last_name":"Yu","affiliations":["University of California, Santa Barbara"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["Allen Institute for Artificial Intelligence"]},{"first_name":"William Yang","last_name":"Wang","affiliations":["University of California, Santa Barbara"]},{"first_name":"Yejin","last_name":"Choi","affiliations":["Paul G. Allen School of Computer Science, University of Washington"]}],"categories":["Multimodal Learning","Image-Text Interleaving","Large-scale Dataset","Few-shot Learning","Pretraining","CLIP Features"],"publication_date":"2023-04-14","abstract":"In-context vision and language models like Flamingo support arbitrarily\ninterleaved sequences of images and text as input. This format not only enables\nfew-shot learning via interleaving independent supervised (image, text)\nexamples, but also, more complex prompts involving interaction between images,\ne.g., \"What do image A and image B have in common?\" To support this interface,\npretraining occurs over web corpora that similarly contain interleaved\nimages+text. To date, however, large-scale data of this form have not been\npublicly available.\n  We release Multimodal C4, an augmentation of the popular text-only C4 corpus\nwith images interleaved. We use a linear assignment algorithm to place images\ninto longer bodies of text using CLIP features, a process that we show\noutperforms alternatives. Multimodal C4 spans everyday topics like cooking,\ntravel, technology, etc. A manual inspection of a random sample of documents\nshows that a vast majority (88%) of images are topically relevant, and that\nlinear assignment frequently selects individual sentences specifically\nwell-aligned with each image (80%). After filtering NSFW images, ads, etc., the\nresulting corpus consists of 101.2M documents with 571M images interleaved in\n43B English tokens."}
{"id":"2302.09699","title":"Private (Stochastic) Non-Convex Optimization Revisited: Second-Order Stationary Points and Excess Risks","authors":[{"first_name":"Arun","last_name":"Ganesh","affiliations":["Google Research","arunganesh@google.com"]},{"first_name":"Daogao","last_name":"Liu","affiliations":["University of Washington","most of this work was done while interning at Google","dgliu@uw.edu"]},{"first_name":"Sewoong","last_name":"Oh","affiliations":["University of Washington and Google Research","sewoong@cs.washington.edu"]},{"first_name":"Abhradeep","last_name":"Thakurta","affiliations":["Google Research","athakurta@google.com"]}],"categories":["Non-Convex Optimization","Privacy Preservation","Gradient Oracles","Differential Privacy","Exponential Mechanism","Second-Order Stationary Points"],"publication_date":"2023-02-20","abstract":"We consider the problem of minimizing a non-convex objective while preserving\nthe privacy of the examples in the training data. Building upon the previous\nvariance-reduced algorithm SpiderBoost, we introduce a new framework that\nutilizes two different kinds of gradient oracles. The first kind of oracles can\nestimate the gradient of one point, and the second kind of oracles, less\nprecise and more cost-effective, can estimate the gradient difference between\ntwo points. SpiderBoost uses the first kind periodically, once every few steps,\nwhile our framework proposes using the first oracle whenever the total drift\nhas become large and relies on the second oracle otherwise. This new framework\nensures the gradient estimations remain accurate all the time, resulting in\nimproved rates for finding second-order stationary points.\n  Moreover, we address a more challenging task of finding the global minima of\na non-convex objective using the exponential mechanism. Our findings indicate\nthat the regularized exponential mechanism can closely match previous empirical\nand population risk bounds, without requiring smoothness assumptions for\nalgorithms with polynomial running time. Furthermore, by disregarding running\ntime considerations, we show that the exponential mechanism can achieve a good\npopulation risk bound and provide a nearly matching lower bound."}
{"id":"2310.11513v1","title":"GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment","authors":[{"first_name":"Dhruba","last_name":"Ghosh","affiliations":["University of Washington"]},{"first_name":"Hannaneh","last_name":"Hajishirzi","affiliations":["University of Washington","Allen Institute for AI"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington","Allen Institute for AI","LAION"]}],"categories":["Text-to-Image Alignment","Automated Evaluation Methods","Object Detection","Text-to-Image Models","Image Generation","Evaluation Framework"],"publication_date":"2023-10-17","abstract":"Recent breakthroughs in diffusion models, multimodal pretraining, and\nefficient finetuning have led to an explosion of text-to-image generative\nmodels. Given human evaluation is expensive and difficult to scale, automated\nmethods are critical for evaluating the increasingly large number of new\nmodels. However, most current automated evaluation metrics like FID or\nCLIPScore only offer a holistic measure of image quality or image-text\nalignment, and are unsuited for fine-grained or instance-level analysis. In\nthis paper, we introduce GenEval, an object-focused framework to evaluate\ncompositional image properties such as object co-occurrence, position, count,\nand color. We show that current object detection models can be leveraged to\nevaluate text-to-image models on a variety of generation tasks with strong\nhuman agreement, and that other discriminative vision models can be linked to\nthis pipeline to further verify properties like object color. We then evaluate\nseveral open-source text-to-image models and analyze their relative generative\ncapabilities on our benchmark. We find that recent models demonstrate\nsignificant improvement on these tasks, though they are still lacking in\ncomplex capabilities such as spatial relations and attribute binding. Finally,\nwe demonstrate how GenEval might be used to help discover existing failure\nmodes, in order to inform development of the next generation of text-to-image\nmodels. Our code to run the GenEval framework is publicly available at\nhttps://github.com/djghosh13/geneval."}
{"id":"2303.11453","title":"Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing","authors":[{"first_name":"Nived","last_name":"Rajaraman","affiliations":["University of California, Berkeley"]},{"first_name":"Devvrit","last_name":"-","affiliations":["UT Austin"]},{"first_name":"Aryan","last_name":"Mokhtari","affiliations":["UT Austin"]},{"first_name":"Kannan","last_name":"Ramchandran","affiliations":["University of California, Berkeley"]}],"categories":["Pruning","Fine-tuning","Matrix Sensing","Group Lasso","Regularization","Gradient Descent"],"publication_date":"2023-03-20","abstract":"Pruning schemes have been widely used in practice to reduce the complexity of\ntrained models with a massive number of parameters. In fact, several practical\nstudies have shown that if a pruned model is fine-tuned with some\ngradient-based updates it generalizes well to new samples. Although the above\npipeline, which we refer to as pruning + fine-tuning, has been extremely\nsuccessful in lowering the complexity of trained models, there is very little\nknown about the theory behind this success. In this paper, we address this\nissue by investigating the pruning + fine-tuning framework on the\noverparameterized matrix sensing problem with the ground truth $U_\\star \\in\n\\mathbb{R}^{d \\times r}$ and the overparameterized model $U \\in \\mathbb{R}^{d\n\\times k}$ with $k \\gg r$. We study the approximate local minima of the mean\nsquare error, augmented with a smooth version of a group Lasso regularizer,\n$\\sum_{i=1}^k \\| U e_i \\|_2$. In particular, we provably show that pruning all\nthe columns below a certain explicit $\\ell_2$-norm threshold results in a\nsolution $U_{\\text{prune}}$ which has the minimum number of columns $r$, yet\nclose to the ground truth in training loss. Moreover, in the subsequent\nfine-tuning phase, gradient descent initialized at $U_{\\text{prune}}$ converges\nat a linear rate to its limit. While our analysis provides insights into the\nrole of regularization in pruning, we also show that running gradient descent\nin the absence of regularization results in models which {are not suitable for\ngreedy pruning}, i.e., many columns could have their $\\ell_2$ norm comparable\nto that of the maximum. To the best of our knowledge, our results provide the\nfirst rigorous insights on why greedy pruning + fine-tuning leads to smaller\nmodels which also generalize well."}
{"id":"2302.01381","title":"Effective Robustness against Natural Distribution Shifts for Models with Different Training Data","authors":[{"first_name":"Zhouxing","last_name":"Shi","affiliations":["UCLA"]},{"first_name":"Nicholas","last_name":"Carlini","affiliations":["Google Research"]},{"first_name":"Ananth","last_name":"Balashankar","affiliations":["Google Research"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington"]},{"first_name":"Cho-Jui","last_name":"Hsieh","affiliations":["Google","UCLA"]},{"first_name":"Alex","last_name":"Beutel","affiliations":["OpenAI"]},{"first_name":"Yao","last_name":"Qin","affiliations":["UCSB","Google Research"]}],"categories":["Robustness","Distribution Shifts","Machine Learning","Evaluation Metric","Training Data","Image Classification"],"publication_date":"2023-02-02","abstract":"\"Effective robustness\" measures the extra out-of-distribution (OOD)\nrobustness beyond what can be predicted from the in-distribution (ID)\nperformance. Existing effective robustness evaluations typically use a single\ntest set such as ImageNet to evaluate the ID accuracy. This becomes problematic\nwhen evaluating models trained on different data distributions, e.g., comparing\nmodels trained on ImageNet vs. zero-shot language-image pre-trained models\ntrained on LAION. In this paper, we propose a new evaluation metric to evaluate\nand compare the effective robustness of models trained on different data. To do\nthis, we control for the accuracy on multiple ID test sets that cover the\ntraining distributions for all the evaluated models. Our new evaluation metric\nprovides a better estimate of effective robustness when there are models with\ndifferent training data. It may also explain the surprising effective\nrobustness gains of zero-shot CLIP-like models exhibited in prior works that\nused ImageNet as the only ID test set, while the gains diminish under our new\nevaluation. Additional artifacts including interactive visualizations are\nprovided at https://shizhouxing.github.io/effective-robustness."}
{"id":"SSL4WS_ICML_Workshop_DMLR","title":"Characterizing the Impacts of Semi-supervised Learning for Weak Supervision","authors":[{"first_name":"Jeffrey","last_name":"Li","affiliations":["University of Washington"]},{"first_name":"Jieyu","last_name":"Zhang","affiliations":["University of Washington"]},{"first_name":"Ludwig","last_name":"Schmidt","affiliations":["University of Washington"]},{"first_name":"Alexander","last_name":"Ratner","affiliations":["University of Washington"]}],"categories":["Semi-supervised Learning","Weak Supervision","Machine Learning","Labeling Efficiency","SSL Techniques","WS Benchmarks"],"publication_date":null,"abstract":"Labeling training data is a critical and expensive step in producing high accuracy ML models, whether training from scratch or fine-tuning. To make labeling more efficient, two major approaches are programmatic weak supervision (WS) and semi-supervised learning (SSL). More recent works have either explicitly or implicitly used techniques at their intersection, but in various complex and ad hoc ways. In this work, we define a simple, modular design space to study the use of SSL techniques for WS more systematically. Surprisingly, we find that fairly simple methods from our design space match the performance of more complex state-of-the-art methods, averaging a 3 p.p. increase in accuracy/F1-score across 8 standard WS benchmarks. Further, we provide practical guidance on when different components are worth their added complexity and training costs. Contrary to current understanding, we find using SSL is not necessary to obtain the best performance on most WS benchmarks but is more effective when: (1) end models are smaller, and (2) WS provides labels for only a small portion of training examples."}
{"id":"2305.18447","title":"Unleashing the Power of Randomization in Auditing Differentially Private ML","authors":[{"first_name":"Krishna","last_name":"Pillutla","affiliations":["Google Research"]},{"first_name":"Galen","last_name":"Andrew","affiliations":["Google Research"]},{"first_name":"Peter","last_name":"Kairouz","affiliations":["Google Research"]},{"first_name":"H. Brendan","last_name":"McMahan","affiliations":["Google Research"]},{"first_name":"Alina","last_name":"Oprea","affiliations":["Google Research","Northeastern University"]},{"first_name":"Sewoong","last_name":"Oh","affiliations":["Google Research","University of Washington"]}],"categories":["Differential Privacy","Machine Learning","Randomization","Auditing","Privacy","Statistical Testing"],"publication_date":"2023-05-29","abstract":"We present a rigorous methodology for auditing differentially private machine\nlearning algorithms by adding multiple carefully designed examples called\ncanaries. We take a first principles approach based on three key components.\nFirst, we introduce Lifted Differential Privacy (LiDP) that expands the\ndefinition of differential privacy to handle randomized datasets. This gives us\nthe freedom to design randomized canaries. Second, we audit LiDP by trying to\ndistinguish between the model trained with $K$ canaries versus $K - 1$ canaries\nin the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP\ncan leverage the symmetry in the design and reuse each privately trained model\nto run multiple statistical tests, one for each canary. Third, we introduce\nnovel confidence intervals that take advantage of the multiple test statistics\nby adapting to the empirical higher-order correlations. Together, this new\nrecipe demonstrates significant improvements in sample complexity, both\ntheoretically and empirically, using synthetic and real data. Further, recent\nadvances in designing stronger canaries can be readily incorporated into the\nnew framework."}
{"id":"2305.19256","title":"Ambient Diffusion: Learning Clean Distributions from Corrupted Data","authors":[{"first_name":"Giannis","last_name":"Daras","affiliations":["UT Austin"]},{"first_name":"Kulin","last_name":"Shah","affiliations":["UT Austin"]},{"first_name":"Yuval","last_name":"Dagan","affiliations":["UC Berkeley"]},{"first_name":"Aravind","last_name":"Gollakota","affiliations":["UT Austin"]},{"first_name":"Alexandros G.","last_name":"Dimakis","affiliations":["UT Austin"]},{"first_name":"Adam","last_name":"Klivans","affiliations":["UT Austin"]}],"categories":["Diffusion-based Framework","Generative Models","Corrupted Data","Conditional Expectation","Inpainting","Compressed Sensing"],"publication_date":"2023-05-30","abstract":"We present the first diffusion-based framework that can learn an unknown\ndistribution using only highly-corrupted samples. This problem arises in\nscientific applications where access to uncorrupted samples is impossible or\nexpensive to acquire. Another benefit of our approach is the ability to train\ngenerative models that are less likely to memorize individual training samples\nsince they never observe clean training data. Our main idea is to introduce\nadditional measurement distortion during the diffusion process and require the\nmodel to predict the original corrupted image from the further corrupted image.\nWe prove that our method leads to models that learn the conditional expectation\nof the full uncorrupted image given this additional measurement corruption.\nThis holds for any corruption process that satisfies some technical conditions\n(and in particular includes inpainting and compressed sensing). We train models\non standard benchmarks (CelebA, CIFAR-10 and AFHQ) and show that we can learn\nthe distribution even when all the training samples have $90\\%$ of their pixels\nmissing. We also show that we can finetune foundation models on small corrupted\ndatasets (e.g. MRI scans with block corruptions) and learn the clean\ndistribution without memorizing the training set."}
{"id":"2307.01178","title":"Learning Mixtures of Gaussians Using the DDPM Objective","authors":[{"first_name":"Kulin","last_name":"Shah","affiliations":["UT Austin"]},{"first_name":"Sitan","last_name":"Chen","affiliations":["UC Berkeley"]},{"first_name":"Adam","last_name":"Klivans","affiliations":["UT Austin"]}],"categories":["Diffusion Models","Gaussian Mixture Models","Score Estimation","Gradient Descent","EM Algorithm","Spectral Methods"],"publication_date":"2023-07-03","abstract":"Recent works have shown that diffusion models can learn essentially any\ndistribution provided one can perform score estimation. Yet it remains poorly\nunderstood under what settings score estimation is possible, let alone when\npractical gradient-based algorithms for this task can provably succeed.\n  In this work, we give the first provably efficient results along these lines\nfor one of the most fundamental distribution families, Gaussian mixture models.\nWe prove that gradient descent on the denoising diffusion probabilistic model\n(DDPM) objective can efficiently recover the ground truth parameters of the\nmixture model in the following two settings: 1) We show gradient descent with\nrandom initialization learns mixtures of two spherical Gaussians in $d$\ndimensions with $1/\\text{poly}(d)$-separated centers. 2) We show gradient\ndescent with a warm start learns mixtures of $K$ spherical Gaussians with\n$\\Omega(\\sqrt{\\log(\\min(K,d))})$-separated centers. A key ingredient in our\nproofs is a new connection between score-based methods and two other approaches\nto distribution learning, the EM algorithm and spectral methods."}
