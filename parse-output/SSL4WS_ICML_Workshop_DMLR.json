{"pages": [{"page": 1, "text": " Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n                           Jeffrey Li 1 Jieyu Zhang 1 Ludwig Schmidt 1 Alexander Ratner 1\n                          Abstract                                  fields could be applied productively with one another, yet\n      Labeling training data is a critical and expen-               their intersection has not been systematically studied.\n      sive step in producing high accuracy ML mod-                  In this work, we anchor on WS approaches and study\n      els, whether training from scratch or fine-tuning.            whether they can be enhanced using techniques from SSL.\n      To make labeling more effi    cient, two major ap-            At a high-level, most WS methods consist of two steps. First,\n      proaches are programmatic weak supervision                    a label model aggregates a set of weak label sources to nois-\n      (WS) and semi-supervised learning (SSL). More                 ily label a training set. Commonly, these sources take the\n      recent works have either explicitly or implicitly             form of user-written heuristics (e.g., for sentiment analysis,\n      used techniques at their intersection, but in vari-           a user may check for the keyword \u201cgreat\u201d to provide the\n      ous complex and ad hoc ways. In this work, we                 label \u201cpositive\u201d). Second, an end model is learned on this\n      define a simple, modular design space to study                training set. Crucially, weak sources can often abstain (e.g.,\n      the use of SSL techniques for WS more system-                 the absence of \u201cgreat\u201d may not imply \u201cnegative\u201d), leaving\n      atically. Surprisingly, we find that fairly simple            certain examples to remain unlabeled and thereby unused.\n      methods from our design space match the perfor-               This presents a natural opportunity to use SSL.\n      mance of more complex state-of-the-art methods,               Indeed, this approach of using SSL in WS settings has\n      averaging a 3 p.p. increase in accuracy/F1-score              motivated several recent methods (Yu et al., 2021; Ren et al.,\n      across 8 standard WS benchmarks. Further, we                  2020; Karamanolakis et al., 2021; Gao et al., 2022). Though\n      provide practical guidance on when different com-             these works often attribute their observed improvements\n      ponents are worth their added complexity and                  to their usage of unlabeled data (Zhang et al., 2021; Yu\n      training costs. Contrary to current understand-               et al., 2021; Ren et al., 2020), they also incorporate various\n      ing, we find using SSL is not necessary to obtain             algorithmic components in addition to SSL. Thus, we lack\n      the best performance on most WS benchmarks                    clarity about the precise contributions of SSL and whether\n      but is more effective when: (1) end models are                simpler methods might also suffice. Also, while varying the\n      smaller, and (2) WS provides labels for only a                amount of unlabeled data is crucial when evaluating SSL\n      small portion of training examples.                           methods (Oliver et al., 2018), previous WS benchmarks\n                                                                    contain little diversity along this key dimension: most leave\n                                                                    only a small minority of examples as unlabeled. Here, we\n1. Introduction                                                     conduct a more systematic study of how useful SSL is in\nLearning with limited labels is a fundamental challenge in          a variety of WS settings, as well as how and when to best\nmachine learning (ML) applications (Koco\u00b4       n et al., 2023;     employ it.\nZhu et al., 2023). To address the significant costs of hand-        Specifically, we first organize the intersection between SSL\nlabeling training sets, programmatic weak supervision (WS)          and WS by proposing an explicit design space, centered\nhas emerged as a high impact research area (Ratner et al.,          around disentangling the following key methodological con-\n2016; Zhang et al., 2022a), where the aim is to learn from          siderations:\nmultiple cheaper sources of noisy labels. Meanwhile, semi-\nsupervised learning (SSL) is a more classical direction with         (1) Thresholding: What to treat as (un)labeled? Because\nsimilar high-level motivations. Instead of generating larger             WS uses heuristics for labeling, it often can only pro-\nquantities of noisy labels, SSL aims to directly leverage                vide labels for a subset of examples, leaving the rest\nadditional unlabeled data. It seems natural that these two               as unlabeled. Further, it can be beneficial to addition-\n    1University of Washington. Correspondence to: Jeffrey Li             ally remove some (likely) incorrect labels provided by\n<jwl2162@cs.washington.edu>.                                             WS, as shown by Lang et al. (2022). Since unlabeled\n                                                                         data can result in multiple ways when using WS, we\nWorkshop on Data-centric Machine Learning (DMLR) at the 40 th            view \u201cwhat to treat as unlabeled\u201d as a non-trivial and\nInternational Conference on Machine Learning, 2023.                      first-class axis in our design space.\n                                                                 1", "md": "# Document\n\n# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nJeffrey Li1, Jieyu Zhang1, Ludwig Schmidt1, Alexander Ratner1\n\n## Abstract\n\nLabeling training data is a critical and expensive step in producing high accuracy ML models, whether training from scratch or fine-tuning. To make labeling more efficient, two major approaches are programmatic weak supervision (WS) and semi-supervised learning (SSL). More recent works have either explicitly or implicitly used techniques at their intersection, but in various complex and ad hoc ways. In this work, we define a simple, modular design space to study the use of SSL techniques for WS more systematically. Surprisingly, we find that fairly simple methods from our design space match the performance of more complex state-of-the-art methods, averaging a 3 p.p. increase in accuracy/F1-score across 8 standard WS benchmarks. Further, we provide practical guidance on when different components are worth their added complexity and training costs. Contrary to current understanding, we find using SSL is not necessary to obtain the best performance on most WS benchmarks but is more effective when: (1) end models are smaller, and (2) WS provides labels for only a small portion of training examples.\n\n### 1. Introduction\n\nLearning with limited labels is a fundamental challenge in machine learning (ML) applications. To address the significant costs of hand-labeling training sets, programmatic weak supervision (WS) has emerged as a high impact research area, where the aim is to learn from multiple cheaper sources of noisy labels. Meanwhile, semi-supervised learning (SSL) is a more classical direction with similar high-level motivations. Instead of generating larger quantities of noisy labels, SSL aims to directly leverage additional unlabeled data. It seems natural that these two\n\nUniversity of Washington. Correspondence to: Jeffrey Li &lt;jwl2162@cs.washington.edu&gt;.\n\nWorkshop on Data-centric Machine Learning (DMLR) at the 40th International Conference on Machine Learning, 2023.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "text", "value": "Jeffrey Li1, Jieyu Zhang1, Ludwig Schmidt1, Alexander Ratner1", "md": "Jeffrey Li1, Jieyu Zhang1, Ludwig Schmidt1, Alexander Ratner1"}, {"type": "heading", "lvl": 2, "value": "Abstract", "md": "## Abstract"}, {"type": "text", "value": "Labeling training data is a critical and expensive step in producing high accuracy ML models, whether training from scratch or fine-tuning. To make labeling more efficient, two major approaches are programmatic weak supervision (WS) and semi-supervised learning (SSL). More recent works have either explicitly or implicitly used techniques at their intersection, but in various complex and ad hoc ways. In this work, we define a simple, modular design space to study the use of SSL techniques for WS more systematically. Surprisingly, we find that fairly simple methods from our design space match the performance of more complex state-of-the-art methods, averaging a 3 p.p. increase in accuracy/F1-score across 8 standard WS benchmarks. Further, we provide practical guidance on when different components are worth their added complexity and training costs. Contrary to current understanding, we find using SSL is not necessary to obtain the best performance on most WS benchmarks but is more effective when: (1) end models are smaller, and (2) WS provides labels for only a small portion of training examples.", "md": "Labeling training data is a critical and expensive step in producing high accuracy ML models, whether training from scratch or fine-tuning. To make labeling more efficient, two major approaches are programmatic weak supervision (WS) and semi-supervised learning (SSL). More recent works have either explicitly or implicitly used techniques at their intersection, but in various complex and ad hoc ways. In this work, we define a simple, modular design space to study the use of SSL techniques for WS more systematically. Surprisingly, we find that fairly simple methods from our design space match the performance of more complex state-of-the-art methods, averaging a 3 p.p. increase in accuracy/F1-score across 8 standard WS benchmarks. Further, we provide practical guidance on when different components are worth their added complexity and training costs. Contrary to current understanding, we find using SSL is not necessary to obtain the best performance on most WS benchmarks but is more effective when: (1) end models are smaller, and (2) WS provides labels for only a small portion of training examples."}, {"type": "heading", "lvl": 3, "value": "1. Introduction", "md": "### 1. Introduction"}, {"type": "text", "value": "Learning with limited labels is a fundamental challenge in machine learning (ML) applications. To address the significant costs of hand-labeling training sets, programmatic weak supervision (WS) has emerged as a high impact research area, where the aim is to learn from multiple cheaper sources of noisy labels. Meanwhile, semi-supervised learning (SSL) is a more classical direction with similar high-level motivations. Instead of generating larger quantities of noisy labels, SSL aims to directly leverage additional unlabeled data. It seems natural that these two\n\nUniversity of Washington. Correspondence to: Jeffrey Li &lt;jwl2162@cs.washington.edu&gt;.\n\nWorkshop on Data-centric Machine Learning (DMLR) at the 40th International Conference on Machine Learning, 2023.", "md": "Learning with limited labels is a fundamental challenge in machine learning (ML) applications. To address the significant costs of hand-labeling training sets, programmatic weak supervision (WS) has emerged as a high impact research area, where the aim is to learn from multiple cheaper sources of noisy labels. Meanwhile, semi-supervised learning (SSL) is a more classical direction with similar high-level motivations. Instead of generating larger quantities of noisy labels, SSL aims to directly leverage additional unlabeled data. It seems natural that these two\n\nUniversity of Washington. Correspondence to: Jeffrey Li &lt;jwl2162@cs.washington.edu&gt;.\n\nWorkshop on Data-centric Machine Learning (DMLR) at the 40th International Conference on Machine Learning, 2023."}]}, {"page": 2, "text": "                        Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n (2) SSL Technique: How to use unlabeled examples? After          as COSINE (Yu et al., 2021) and KeyClass (Gao et al.,\n     deciding what data should be treated as unlabeled, one       2022), which both use self-training (Lee, 2013). Other\n     can leverage these examples by simply using any ex-          works (Karamanolakis et al., 2021; Maheshwari et al., 2020;\n     isting SSL technique. Most recent proposals do so via        Chen et al., 2021; Mazzetto et al., 2021b;a; Pukdee et al.,\n     self-training, which uses the end model to periodically      2023; Awasthi et al., 2020) apply SSL when learning from\n     provide labels for unlabeled examples; in addition, we       weak labels plus a small set of clean labels. However, these\n     also try other out-of-the-box SSL methods.                   methods fundamentally differ in their use of SSL, i.e., they\n                                                                  define a labeled-unlabeled split based on whether an exam-\n (3) Re-labeling: Whether to update weak labels during            ple has been cleanly or weakly labeled. Further, integrating\n     end model training? Because some labels from WS              clean labels into WS enables a greater variety of special-\n     are incorrect, it can be helpful to re-label a training      ized strategies, so we do not consider this setting in our\n     set with the end model during training. This approach,       study. Likewise, Boecking & Dubrawski (2019) assume ad-\n     increasingly used by WS methods (Yu et al., 2021;            ditional supervision via heuristics for which examples share\n     Karamanolakis et al., 2021; Cachay et al., 2021), is of-     the same labels, similar in spirit to consistency-based SSL\n     ten packaged as part of self-training-based SSL. Here,       methods. Finally, we defer a more thorough background on\n     we identify that re-labeling and SSL can be indepen-         SSL in its own right to Section 3.\n     dently employed, and aim to disentangle their impacts.\n                                                                  SSL for learning with noisy labels. SSL techniques have\nWith our design space, we can organize previous works and         been regularly applied in the literature concerning learning\nmodularly generate a variety of methods. We test these            from noisy labels (Li et al., 2020; Ding et al., 2018; Kong\nmethods on several standard WS benchmarks, finding that           et al., 2019). Though this setting is similar to WS, its main\nour design space is sufficient for matching the performance       difference is that label noise comes from a single \u201cblack-\nof more complex state-of-the-art methods. We then compare         box\u201d noising process instead of from multiple explicit WS\nmethods within our design space to ablate the importance          sources. Thus, the resulting label noise patterns, often also\nof each axis and so provide guidance on when each is worth        artificially injected in input-independent ways (Wei et al.,\nusing. We summarize our key findings as follows:                  2022), may differ significantly from those in WS. Further-\n                                                                  more, the WS setting can contain some examples with no\n   \u2022 By searching over our design space, we identify two          labels since WS sources may abstain.\n     methods that at least match all previous baselines           Subset selection in WS. Lang et al. (2022) showcases the\n     across 6 of 8 WS benchmarks, averaging a 3 p.p. in-          broad utility of more carefully selecting subsets of weak\n     crease in accuracy/F1-score.                                 labels before end model training. In our work, we consider\n                                                                  subset selection in the greater context of two other trends\n   \u2022 While previous works emphasize utilizing data left           in the WS literature, applying SSL and re-labeling. Com-\n     unlabeled by WS sources, we find that on 6 of 8 bench-       pared to the core method of Lang et al. (2022), we also try\n     marks tasks, SSL is actually not necessary for achiev-       a simpler baseline, similar to Gao et al. (2022), based on\n     ing high performance: thresholding and re-labeling can       thresholding the existing confidences produced for weak\n     recover 89.1% of the gains enjoyed by also using SSL.        labels. We find that this method offers a competitive alter-\n   \u2022 To explain SSL\u2019s lack of impact, we find that the small      native on most datasets.\n     amounts of unlabeled data in these benchmarks (i.e.,\n     <31%) are mostly unnecessary; when using clean in-           3. Design Space\n     stead of weak labels, ignoring unlabeled examples            In this section, we first formalize WS and SSL. Then, we\n     drops test accuracy by <2.5 p.p.                             describe how our design space overlays on WS, detailing its\n   \u2022 In contrast, when WS sources leave more data as un-          three key axes along with the specific instantiations of each\n     labeled (i.e., >65%), SSL is generally worth priori-         that we use in our experiments. Finally, we contextualize\n     tizing; using SSL can improve upon thresholding and          which parts of existing work fit within our framework.\n     re-labeling by up to 16 p.p in such cases.\n                                                                  3.1. Problem Formalization\n2. Related Work                                                   Weak supervision. In WS, we start with an unlabeled\nSSL for WS tasks. Methods in WS have increasingly turned          training set D = {xi}n i=1 \u2208 X n drawn from an underlying\n                                                                  distribution (x, y) \u223c  P. Labels are provided by a set of\nto SSL to improve end model training. This includes DE-           labeling functions (LFs) {\u03bbj}m j=1, where each \u03bbj : X \u2192\nNOISE (Ren et al., 2020), which incorporates the temporal         Y \u222a  {\u2205} either labels or abstains (denoted as \u03bbj(xi) = \u2205)\nensembling SSL algorithm (Laine & Aila, 2017), as well\n                                                               2", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n(2) SSL Technique: How to use unlabeled examples? After deciding what data should be treated as unlabeled, one can leverage these examples by simply using any existing SSL technique. Most recent proposals do so via self-training, which uses the end model to periodically provide labels for unlabeled examples; in addition, we also try other out-of-the-box SSL methods.\n\n(3) Re-labeling: Whether to update weak labels during end model training? Because some labels from WS are incorrect, it can be helpful to re-label a training set with the end model during training. This approach, increasingly used by WS methods, is often packaged as part of self-training-based SSL. Here, we identify that re-labeling and SSL can be independently employed, and aim to disentangle their impacts.\n\nWith our design space, we can organize previous works and modularly generate a variety of methods. We test these methods on several standard WS benchmarks, finding that our design space is sufficient for matching the performance of more complex state-of-the-art methods. We then compare methods within our design space to ablate the importance of each axis and provide guidance on when each is worth using. We summarize our key findings as follows:\n\n- By searching over our design space, we identify two methods that at least match all previous baselines across 6 of 8 WS benchmarks, averaging a 3 p.p. increase in accuracy/F1-score.\n- While previous works emphasize utilizing data left unlabeled by WS sources, we find that on 6 of 8 benchmarks tasks, SSL is actually not necessary for achieving high performance: thresholding and re-labeling can recover 89.1% of the gains enjoyed by also using SSL.\n- To explain SSL\u2019s lack of impact, we find that the small amounts of unlabeled data in these benchmarks (i.e., &lt;31%) are mostly unnecessary; when using clean instead of weak labels, ignoring unlabeled examples drops test accuracy by &lt;2.5 p.p.\n- In contrast, when WS sources leave more data as unlabeled (i.e., &gt;65%), SSL is generally worth prioritizing; using SSL can improve upon thresholding and re-labeling by up to 16 p.p in such cases.\n\n### Related Work\n\nSSL for WS tasks. Methods in WS have increasingly turned to SSL to improve end model training. This includes DE-NOISE, which incorporates the temporal ensembling SSL algorithm, as well as COSINE and KeyClass, which both use self-training. Other works apply SSL when learning from weak labels plus a small set of clean labels. However, these methods fundamentally differ in their use of SSL, i.e., they define a labeled-unlabeled split based on whether an example has been cleanly or weakly labeled.\n\nSSL for learning with noisy labels. SSL techniques have been regularly applied in the literature concerning learning from noisy labels. Though this setting is similar to WS, its main difference is that label noise comes from a single \u201cblack-box\u201d noising process instead of from multiple explicit WS sources.\n\nSubset selection in WS. Lang et al. showcases the broad utility of more carefully selecting subsets of weak labels before end model training. In our work, we consider subset selection in the greater context of two other trends in the WS literature, applying SSL and re-labeling.\n\n### Design Space\n\nIn this section, we first formalize WS and SSL. Then, we describe how our design space overlays on WS, detailing its three key axes along with the specific instantiations of each that we use in our experiments. Finally, we contextualize which parts of existing work fit within our framework.\n\n#### Problem Formalization\n\nWeak supervision. In WS, we start with an unlabeled training set D = {xi}n i=1 \u2208 X n drawn from an underlying distribution (x, y) \u223c P. Labels are provided by a set of labeling functions (LFs) {\u03bbj}m j=1, where each \u03bbj : X \u2192 Y \u222a {\u2205} either labels or abstains (denoted as \u03bbj(xi) = \u2205).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "text", "value": "(2) SSL Technique: How to use unlabeled examples? After deciding what data should be treated as unlabeled, one can leverage these examples by simply using any existing SSL technique. Most recent proposals do so via self-training, which uses the end model to periodically provide labels for unlabeled examples; in addition, we also try other out-of-the-box SSL methods.\n\n(3) Re-labeling: Whether to update weak labels during end model training? Because some labels from WS are incorrect, it can be helpful to re-label a training set with the end model during training. This approach, increasingly used by WS methods, is often packaged as part of self-training-based SSL. Here, we identify that re-labeling and SSL can be independently employed, and aim to disentangle their impacts.\n\nWith our design space, we can organize previous works and modularly generate a variety of methods. We test these methods on several standard WS benchmarks, finding that our design space is sufficient for matching the performance of more complex state-of-the-art methods. We then compare methods within our design space to ablate the importance of each axis and provide guidance on when each is worth using. We summarize our key findings as follows:\n\n- By searching over our design space, we identify two methods that at least match all previous baselines across 6 of 8 WS benchmarks, averaging a 3 p.p. increase in accuracy/F1-score.\n- While previous works emphasize utilizing data left unlabeled by WS sources, we find that on 6 of 8 benchmarks tasks, SSL is actually not necessary for achieving high performance: thresholding and re-labeling can recover 89.1% of the gains enjoyed by also using SSL.\n- To explain SSL\u2019s lack of impact, we find that the small amounts of unlabeled data in these benchmarks (i.e., &lt;31%) are mostly unnecessary; when using clean instead of weak labels, ignoring unlabeled examples drops test accuracy by &lt;2.5 p.p.\n- In contrast, when WS sources leave more data as unlabeled (i.e., &gt;65%), SSL is generally worth prioritizing; using SSL can improve upon thresholding and re-labeling by up to 16 p.p in such cases.", "md": "(2) SSL Technique: How to use unlabeled examples? After deciding what data should be treated as unlabeled, one can leverage these examples by simply using any existing SSL technique. Most recent proposals do so via self-training, which uses the end model to periodically provide labels for unlabeled examples; in addition, we also try other out-of-the-box SSL methods.\n\n(3) Re-labeling: Whether to update weak labels during end model training? Because some labels from WS are incorrect, it can be helpful to re-label a training set with the end model during training. This approach, increasingly used by WS methods, is often packaged as part of self-training-based SSL. Here, we identify that re-labeling and SSL can be independently employed, and aim to disentangle their impacts.\n\nWith our design space, we can organize previous works and modularly generate a variety of methods. We test these methods on several standard WS benchmarks, finding that our design space is sufficient for matching the performance of more complex state-of-the-art methods. We then compare methods within our design space to ablate the importance of each axis and provide guidance on when each is worth using. We summarize our key findings as follows:\n\n- By searching over our design space, we identify two methods that at least match all previous baselines across 6 of 8 WS benchmarks, averaging a 3 p.p. increase in accuracy/F1-score.\n- While previous works emphasize utilizing data left unlabeled by WS sources, we find that on 6 of 8 benchmarks tasks, SSL is actually not necessary for achieving high performance: thresholding and re-labeling can recover 89.1% of the gains enjoyed by also using SSL.\n- To explain SSL\u2019s lack of impact, we find that the small amounts of unlabeled data in these benchmarks (i.e., &lt;31%) are mostly unnecessary; when using clean instead of weak labels, ignoring unlabeled examples drops test accuracy by &lt;2.5 p.p.\n- In contrast, when WS sources leave more data as unlabeled (i.e., &gt;65%), SSL is generally worth prioritizing; using SSL can improve upon thresholding and re-labeling by up to 16 p.p in such cases."}, {"type": "heading", "lvl": 3, "value": "Related Work", "md": "### Related Work"}, {"type": "text", "value": "SSL for WS tasks. Methods in WS have increasingly turned to SSL to improve end model training. This includes DE-NOISE, which incorporates the temporal ensembling SSL algorithm, as well as COSINE and KeyClass, which both use self-training. Other works apply SSL when learning from weak labels plus a small set of clean labels. However, these methods fundamentally differ in their use of SSL, i.e., they define a labeled-unlabeled split based on whether an example has been cleanly or weakly labeled.\n\nSSL for learning with noisy labels. SSL techniques have been regularly applied in the literature concerning learning from noisy labels. Though this setting is similar to WS, its main difference is that label noise comes from a single \u201cblack-box\u201d noising process instead of from multiple explicit WS sources.\n\nSubset selection in WS. Lang et al. showcases the broad utility of more carefully selecting subsets of weak labels before end model training. In our work, we consider subset selection in the greater context of two other trends in the WS literature, applying SSL and re-labeling.", "md": "SSL for WS tasks. Methods in WS have increasingly turned to SSL to improve end model training. This includes DE-NOISE, which incorporates the temporal ensembling SSL algorithm, as well as COSINE and KeyClass, which both use self-training. Other works apply SSL when learning from weak labels plus a small set of clean labels. However, these methods fundamentally differ in their use of SSL, i.e., they define a labeled-unlabeled split based on whether an example has been cleanly or weakly labeled.\n\nSSL for learning with noisy labels. SSL techniques have been regularly applied in the literature concerning learning from noisy labels. Though this setting is similar to WS, its main difference is that label noise comes from a single \u201cblack-box\u201d noising process instead of from multiple explicit WS sources.\n\nSubset selection in WS. Lang et al. showcases the broad utility of more carefully selecting subsets of weak labels before end model training. In our work, we consider subset selection in the greater context of two other trends in the WS literature, applying SSL and re-labeling."}, {"type": "heading", "lvl": 3, "value": "Design Space", "md": "### Design Space"}, {"type": "text", "value": "In this section, we first formalize WS and SSL. Then, we describe how our design space overlays on WS, detailing its three key axes along with the specific instantiations of each that we use in our experiments. Finally, we contextualize which parts of existing work fit within our framework.", "md": "In this section, we first formalize WS and SSL. Then, we describe how our design space overlays on WS, detailing its three key axes along with the specific instantiations of each that we use in our experiments. Finally, we contextualize which parts of existing work fit within our framework."}, {"type": "heading", "lvl": 4, "value": "Problem Formalization", "md": "#### Problem Formalization"}, {"type": "text", "value": "Weak supervision. In WS, we start with an unlabeled training set D = {xi}n i=1 \u2208 X n drawn from an underlying distribution (x, y) \u223c P. Labels are provided by a set of labeling functions (LFs) {\u03bbj}m j=1, where each \u03bbj : X \u2192 Y \u222a {\u2205} either labels or abstains (denoted as \u03bbj(xi) = \u2205).", "md": "Weak supervision. In WS, we start with an unlabeled training set D = {xi}n i=1 \u2208 X n drawn from an underlying distribution (x, y) \u223c P. Labels are provided by a set of labeling functions (LFs) {\u03bbj}m j=1, where each \u03bbj : X \u2192 Y \u222a {\u2205} either labels or abstains (denoted as \u03bbj(xi) = \u2205)."}]}, {"page": 3, "text": "                          Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n                                                                                    Labaaj Set [{5 ,MI          Erd Model\n             Label Mndel        Weakty Laboled Sut D        Throsholding                                           (DM\n                 IM                                                                                                SSL\n                                                                                  Unlabeled8ot                  Technique\n                                                                                       (551\n                                                                             Ro-labcllng\n                                   nreshcldino                    Ccverage  Conjicance; Cut-based}\n                                  SSL Technique         {Ncne; FM, VAT, Self-Trairing; Self-Training (DM asLA}\n                                   Re-laboling                     { Nan3, DM drecly DMas LF )\nFigure 1. Overview of our design space. In WS, a label model (LM) produces a weakly labeled training set \u02dc    D which is used to train the\ndiscriminative end model (DM). Our design space overlays three decision points on this pipeline: (1) thresholding, which filters out some\nweak labels in \u02dc\n               D to return labeled and unlabeled sets L and U; (2) SSL technique, which defines how the end model can still use U during\ntraining; (3) re-labeling, which uses the DM to update previously used weak labels.\non each xi. The goal is to train a discriminative end model             3.2. A Simple Design Space\n(DM) f : X \u2192       Y that performs well on P. Canonically,              By considering the standard WS pipeline, we anchor our\nWS methods contain two components. First, a label model\n(LM) observes      D, {\u03bbj}m j=1   and outputs a weakly labeled          design space on three natural decision points as shown in\n                                                                        Figure 1: (1) thresholding strategy, (2) SSL technique, and\ntraining set \u02dcD = {(xi, \u02dc yi)}ni=1. Second, f is trained using          (3) whether to re-label. Importantly, our design space is ag-\n \u02dc\nD. Often, the LM models \u02dc      yi probabilistically, allowing \u02dc yi      nostic to the specification of LM and DM, though particular\nto be a soft-label, a vector of probabilities over Y.                   LMs and DMs could affect which methods work best.\nProblematically, \u02dc  D may contain several uncovered exam-               Thresholding. To apply SSL, we must first define which\nples, where \u03bbj(xi) = \u2205     for all \u03bbj. Thus, the default practice       examples in \u02dc  D should be considered as part of L and U,\nis to train f only on covered examples that received at least           respectively. Though this is part of the problem definition\none non-abstaining LF vote. Concurrently, \u02dc          D may also         in traditional SSL settings, it is a non-trivial choice in WS.\ncontain several incorrect labels, where \u02dc     yi \u0338= yi (or in the       As a default, standard WS pipelines select L based on LF\nsoft-label case, arg max     c\u2208Y \u02dc\n                                 yi[c] \u0338= yi where \u02dc  yi[c] is the      coverage, ignoring uncovered examples on which all LFs\nprobability assigned to class c). Both issues may lead to               abstain. However, as shown by Lang et al. (2022), removing\nsub-optimal performance compared to standard supervised                 additional examples from \u02dc   D can help if they are more likely\nlearning. Here, we focus on whether SSL lets us more                    to be incorrectly labeled. In our work, we consider the\neffectively learn from \u02dc D in light of these challenges.                following strategies for partitioning \u02dc  D into L and U:\nSemi-supervised learning. SSL assumes access to a la-\nbeled dataset L = {(x\u2113     i, yi)}|L|                                      \u2022 Coverage-based (default): This removes uncovered\ndataset U = {xu    i }|U|         i=1 as well as an unlabeled                 points {(xi, \u02dcyi) : \u03bbj(xi) = \u2205, \u2200j}.\n                      i=1. The goal is to obtain a model that\nperforms well on L\u2019s underlying distribution despite the                   \u2022 Confidence-based: Since most LMs can output prob-\nlimited size of L. Though not strictly required, it is often                  abilistic labels, a basic yet under-explored approach\nassumed that |L| << |U| and both are drawn from the same                      tried by Gao et al. (2022) is to remove examples that\ntest distribution. Generally, each SSL method makes a core                    have low estimated confidence, here defined as the\nassumption about how P(x) relates to P(y|x). Popular                          highest probability assigned to a class. Formally, this\ncategories of methods include entropy-minimization (Grand-\nvalet & Bengio, 2004; Lee, 2013), which assumes P(y|x)                        removes the examples {(xi, \u02dc    yi) : maxc\u2208Y \u02dc   yi[c] < \u03be}\nis uncertain only when P(x) is small, and consistency regu-                   for some threshold |Y|\u22121 < \u03be < 1.\nlarization (Miyato et al., 2017; Tarvainen & Valpola, 2017;                \u2022 Cut-based: This is the method of Lang et al. (2022),\nLaine & Aila, 2017), which assumes local smoothness of                        which at a high-level removes examples whose labels\nP(y|x) when x \u223c       P(x), encouraging the model to make                     differ most from those of their nearest neighbors in\nsimilar predictions at similar inputs.                                        some pre-trained embedding space.\n                                                                     3", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nFigure 1. Overview of our design space. In WS, a label model (LM) produces a weakly labeled training set \u02dc D which is used to train the discriminative end model (DM). Our design space overlays three decision points on this pipeline: (1) thresholding, which filters out some weak labels in \u02dc D to return labeled and unlabeled sets L and U; (2) SSL technique, which defines how the end model can still use U during training; (3) re-labeling, which uses the DM to update previously used weak labels.\n\nOn each x_i. The goal is to train a discriminative end model (DM) f : X \u2192 Y that performs well on P. Canonically, WS methods contain two components. First, a label model (LM) observes D, {\u03bb_j}_j=1^m and outputs a weakly labeled training set \u02dcD = {(x_i, \u02dcy_i)}_i=1^n. Second, f is trained using \u02dcD. Often, the LM models \u02dcy_i probabilistically, allowing \u02dcy_i to be a soft-label, a vector of probabilities over Y.\n\nProblematically, \u02dcD may contain several uncovered examples, where \u03bb_j(x_i) = \u2205 for all \u03bb_j. Thus, the default practice is to train f only on covered examples that received at least one non-abstaining LF vote. Concurrently, \u02dcD may also contain several incorrect labels, where \u02dcy_i \u2260 y_i (or in the soft-label case, argmax_c\u2208Y \u02dcy_i[c] \u2260 y_i where \u02dcy_i[c] is the probability assigned to class c). Both issues may lead to sub-optimal performance compared to standard supervised learning. Here, we focus on whether SSL lets us more effectively learn from \u02dcD in light of these challenges.\n\nSemi-supervised learning. SSL assumes access to a labeled dataset L = {(x\u2113_i, y_i)}|L| dataset U = {xu_i}_i=1^|U|. The goal is to obtain a model that performs well on L\u2019s underlying distribution despite the limited size of L. Though not strictly required, it is often assumed that |L| << |U| and both are drawn from the same test distribution. Generally, each SSL method makes a core assumption about how P(x) relates to P(y|x). Popular categories of methods include entropy-minimization (Grandvalet & Bengio, 2004; Lee, 2013), which assumes P(y|x) is uncertain only when P(x) is small, and consistency regularization (Miyato et al., 2017; Tarvainen & Valpola, 2017; Laine & Aila, 2017), which assumes local smoothness of P(y|x) when x \u223c P(x), encouraging the model to make similar predictions at similar inputs.\n\n### 3.2. A Simple Design Space\n\nBy considering the standard WS pipeline, we anchor our design space on three natural decision points as shown in Figure 1: (1) thresholding strategy, (2) SSL technique, and (3) whether to re-label. Importantly, our design space is agnostic to the specification of LM and DM, though particular LMs and DMs could affect which methods work best.\n\nThresholding. To apply SSL, we must first define which examples in \u02dcD should be considered as part of L and U, respectively. Though this is part of the problem definition in traditional SSL settings, it is a non-trivial choice in WS. As a default, standard WS pipelines select L based on LF coverage, ignoring uncovered examples on which all LFs abstain. However, as shown by Lang et al. (2022), removing additional examples from \u02dcD can help if they are more likely to be incorrectly labeled. In our work, we consider the following strategies for partitioning \u02dcD into L and U:\n\n- Coverage-based (default): This removes uncovered points {(x_i, \u02dcy_i) : \u03bb_j(x_i) = \u2205, \u2200j}.\n- Confidence-based: This removes examples that have low estimated confidence, here defined as the highest probability assigned to a class. Formally, this removes the examples {(x_i, \u02dcy_i) : max_c\u2208Y \u02dcy_i[c] &lt; \u03be} for some threshold |Y|-1 &lt; \u03be &lt; 1.\n- Cut-based: This is the method of Lang et al. (2022), which at a high-level removes examples whose labels differ most from those of their nearest neighbors in some pre-trained embedding space.", "images": [{"name": "page-3-0.jpg", "height": 170, "width": 411, "x": 92, "y": 67}], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "text", "value": "Figure 1. Overview of our design space. In WS, a label model (LM) produces a weakly labeled training set \u02dc D which is used to train the discriminative end model (DM). Our design space overlays three decision points on this pipeline: (1) thresholding, which filters out some weak labels in \u02dc D to return labeled and unlabeled sets L and U; (2) SSL technique, which defines how the end model can still use U during training; (3) re-labeling, which uses the DM to update previously used weak labels.\n\nOn each x_i. The goal is to train a discriminative end model (DM) f : X \u2192 Y that performs well on P. Canonically, WS methods contain two components. First, a label model (LM) observes D, {\u03bb_j}_j=1^m and outputs a weakly labeled training set \u02dcD = {(x_i, \u02dcy_i)}_i=1^n. Second, f is trained using \u02dcD. Often, the LM models \u02dcy_i probabilistically, allowing \u02dcy_i to be a soft-label, a vector of probabilities over Y.\n\nProblematically, \u02dcD may contain several uncovered examples, where \u03bb_j(x_i) = \u2205 for all \u03bb_j. Thus, the default practice is to train f only on covered examples that received at least one non-abstaining LF vote. Concurrently, \u02dcD may also contain several incorrect labels, where \u02dcy_i \u2260 y_i (or in the soft-label case, argmax_c\u2208Y \u02dcy_i[c] \u2260 y_i where \u02dcy_i[c] is the probability assigned to class c). Both issues may lead to sub-optimal performance compared to standard supervised learning. Here, we focus on whether SSL lets us more effectively learn from \u02dcD in light of these challenges.\n\nSemi-supervised learning. SSL assumes access to a labeled dataset L = {(x\u2113_i, y_i)}|L| dataset U = {xu_i}_i=1^|U|. The goal is to obtain a model that performs well on L\u2019s underlying distribution despite the limited size of L. Though not strictly required, it is often assumed that |L| << |U| and both are drawn from the same test distribution. Generally, each SSL method makes a core assumption about how P(x) relates to P(y|x). Popular categories of methods include entropy-minimization (Grandvalet & Bengio, 2004; Lee, 2013), which assumes P(y|x) is uncertain only when P(x) is small, and consistency regularization (Miyato et al., 2017; Tarvainen & Valpola, 2017; Laine & Aila, 2017), which assumes local smoothness of P(y|x) when x \u223c P(x), encouraging the model to make similar predictions at similar inputs.", "md": "Figure 1. Overview of our design space. In WS, a label model (LM) produces a weakly labeled training set \u02dc D which is used to train the discriminative end model (DM). Our design space overlays three decision points on this pipeline: (1) thresholding, which filters out some weak labels in \u02dc D to return labeled and unlabeled sets L and U; (2) SSL technique, which defines how the end model can still use U during training; (3) re-labeling, which uses the DM to update previously used weak labels.\n\nOn each x_i. The goal is to train a discriminative end model (DM) f : X \u2192 Y that performs well on P. Canonically, WS methods contain two components. First, a label model (LM) observes D, {\u03bb_j}_j=1^m and outputs a weakly labeled training set \u02dcD = {(x_i, \u02dcy_i)}_i=1^n. Second, f is trained using \u02dcD. Often, the LM models \u02dcy_i probabilistically, allowing \u02dcy_i to be a soft-label, a vector of probabilities over Y.\n\nProblematically, \u02dcD may contain several uncovered examples, where \u03bb_j(x_i) = \u2205 for all \u03bb_j. Thus, the default practice is to train f only on covered examples that received at least one non-abstaining LF vote. Concurrently, \u02dcD may also contain several incorrect labels, where \u02dcy_i \u2260 y_i (or in the soft-label case, argmax_c\u2208Y \u02dcy_i[c] \u2260 y_i where \u02dcy_i[c] is the probability assigned to class c). Both issues may lead to sub-optimal performance compared to standard supervised learning. Here, we focus on whether SSL lets us more effectively learn from \u02dcD in light of these challenges.\n\nSemi-supervised learning. SSL assumes access to a labeled dataset L = {(x\u2113_i, y_i)}|L| dataset U = {xu_i}_i=1^|U|. The goal is to obtain a model that performs well on L\u2019s underlying distribution despite the limited size of L. Though not strictly required, it is often assumed that |L| << |U| and both are drawn from the same test distribution. Generally, each SSL method makes a core assumption about how P(x) relates to P(y|x). Popular categories of methods include entropy-minimization (Grandvalet & Bengio, 2004; Lee, 2013), which assumes P(y|x) is uncertain only when P(x) is small, and consistency regularization (Miyato et al., 2017; Tarvainen & Valpola, 2017; Laine & Aila, 2017), which assumes local smoothness of P(y|x) when x \u223c P(x), encouraging the model to make similar predictions at similar inputs."}, {"type": "heading", "lvl": 3, "value": "3.2. A Simple Design Space", "md": "### 3.2. A Simple Design Space"}, {"type": "text", "value": "By considering the standard WS pipeline, we anchor our design space on three natural decision points as shown in Figure 1: (1) thresholding strategy, (2) SSL technique, and (3) whether to re-label. Importantly, our design space is agnostic to the specification of LM and DM, though particular LMs and DMs could affect which methods work best.\n\nThresholding. To apply SSL, we must first define which examples in \u02dcD should be considered as part of L and U, respectively. Though this is part of the problem definition in traditional SSL settings, it is a non-trivial choice in WS. As a default, standard WS pipelines select L based on LF coverage, ignoring uncovered examples on which all LFs abstain. However, as shown by Lang et al. (2022), removing additional examples from \u02dcD can help if they are more likely to be incorrectly labeled. In our work, we consider the following strategies for partitioning \u02dcD into L and U:\n\n- Coverage-based (default): This removes uncovered points {(x_i, \u02dcy_i) : \u03bb_j(x_i) = \u2205, \u2200j}.\n- Confidence-based: This removes examples that have low estimated confidence, here defined as the highest probability assigned to a class. Formally, this removes the examples {(x_i, \u02dcy_i) : max_c\u2208Y \u02dcy_i[c] &lt; \u03be} for some threshold |Y|-1 &lt; \u03be &lt; 1.\n- Cut-based: This is the method of Lang et al. (2022), which at a high-level removes examples whose labels differ most from those of their nearest neighbors in some pre-trained embedding space.", "md": "By considering the standard WS pipeline, we anchor our design space on three natural decision points as shown in Figure 1: (1) thresholding strategy, (2) SSL technique, and (3) whether to re-label. Importantly, our design space is agnostic to the specification of LM and DM, though particular LMs and DMs could affect which methods work best.\n\nThresholding. To apply SSL, we must first define which examples in \u02dcD should be considered as part of L and U, respectively. Though this is part of the problem definition in traditional SSL settings, it is a non-trivial choice in WS. As a default, standard WS pipelines select L based on LF coverage, ignoring uncovered examples on which all LFs abstain. However, as shown by Lang et al. (2022), removing additional examples from \u02dcD can help if they are more likely to be incorrectly labeled. In our work, we consider the following strategies for partitioning \u02dcD into L and U:\n\n- Coverage-based (default): This removes uncovered points {(x_i, \u02dcy_i) : \u03bb_j(x_i) = \u2205, \u2200j}.\n- Confidence-based: This removes examples that have low estimated confidence, here defined as the highest probability assigned to a class. Formally, this removes the examples {(x_i, \u02dcy_i) : max_c\u2208Y \u02dcy_i[c] &lt; \u03be} for some threshold |Y|-1 &lt; \u03be &lt; 1.\n- Cut-based: This is the method of Lang et al. (2022), which at a high-level removes examples whose labels differ most from those of their nearest neighbors in some pre-trained embedding space."}]}, {"page": 4, "text": "                                  Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n                      Method                          Thresholding              SSL Technique             Re-labeling L        Novel LM       Add. Reg.       Add. Labels\n                     Vanilla WS                         Coverage                        \u2013                        \u2013                  \u2013              \u2013                \u2013\n             Cutstat (Lang et al., 2022)          Cut-based (one-time)                  \u2013                        \u2013                  \u2013              \u2013                \u2013\n             Denoise (Ren et al., 2020)                 Coverage              Temp. Ensembling            Self-Train LM            \u2713               \u2013                \u2013\n            Weasel (Cachay et al., 2021)                    \u2013                           \u2013               Agreement-based            \u2713               \u2013                \u2013\n              Cosine (Yu et al., 2021)              Confidence (dyn.)              Self-Train              DM directly              \u2013              \u2713                \u2013\n            KeyClass (Gao et al., 2022)             Confidence (dyn.)              Self-Train              DM directly              \u2013              \u2713                \u2013\n       ASTRA (Karamanolakis et al., 2021)               Coverage            Self-Train (DM as LF)           DM as LF               \u2713               \u2013               \u2713\n          LPA+WL (Pukdee et al., 2023)                      \u2013                  Label Propagation                 \u2013                  \u2013              \u2013               \u2713\n         SPEAR (Maheshwari et al., 2020)                    \u2013                     Entropy Min           Agreement-based            \u2713               \u2713               \u2713\nTable 1. Contextualizing methods within (middle columns) and outside (rightmost) our design space. \u201cNovel LM\u201d refers to a method\nintroducing its own label model. \u201cAdd. Reg.\u201d refers to using additional regularizations, such as contrastive losses and soft-label\nre-normalization. \u201cAdd. Labels\u201d refers to assuming an additional set of clean labels. For methods using clean labels, we do not compare\nto their results directly, but we can still place elements of their approaches in our design space.\nSSL Techniques.                 After partitioning \u02dc        D into L and U,                  U, these methods also do so for L. However, this makes it\nwe next consider how the end model can still make use                                        difficult to discern whether these methods improve perfor-\nof the examples in U. By default, WS methods ignore U                                        mance because they leverage U (i.e., apply SSL) or simply\naltogether, but we may instead apply a variety of strategies,                                because they clean up labels in L. Therefore, in our study,\nsuch as plugging in any existing SSL technique. Like Oliver                                  we explicitly decouple the use of SSL and re-labeling L as\net al. (2018), we limit ourselves to SSL techniques that add                                 two independent decisions; i.e., we can re-label L regardless\nunsupervised loss terms during training since these methods                                  of whether we use any specific SSL technique.\ntend to achieve the best performance on traditional SSL                                      Specifically, we consider two types of re-labeling: (1) using\nbenchmarks. We also pick representative methods from                                         the end model\u2019s predictions directly as in ST, and (2) re-\ntheir taxonomy of approaches:                                                                fitting the LM as in ST (DM as LF). For tractability, we treat\n                                                                                             re-labeling as a binary decision when accompanied by an\n    \u2022 Entropy minimization (EM): A classical SSL approach,                                   SSL technique; we re-label L with the end model directly in\n       EM (Grandvalet & Bengio, 2004) penalizes less confi-                                  except when the SSL technique is ST (DM as LF). Also, we\n       dent predictions on unlabeled examples, aiming for a                                  formalize re-labeling as looping the two-stage WS pipeline\n       decision boundary in low-density regions of P                        (x).             back onto itself. In principle, N rounds of re-labeling can be\n    \u2022 Self-training (ST): Self-training, along with the closely                              paired with N +1 separate choices for thresholding and SSL.\n       related pseudo-labeling (Lee, 2013; C. Rosenberg &                                    However, to reduce this search space, we consider either\n       Schneiderman, 2005), are traditional SSL methods that                                 using the same thresholding and SSL techniques across all\n       iteratively use current predictions on unlabeled exam-                                rounds or fixing the L/U split after thresholding the initial\n       ples as true labels. Uniquely in the WS setting, we also                              LM outputs; in the context of thresholding, we refer to\n       consider self-training the LM and DM together. In-                                    these two schedules as dynamic and one-time, respectively.\n       spired by Karamanolakis et al. (2021), we specifically                                Finally, some recent methods re-label by using a specialized\n       try feeding the end model as an additional LF \u03bbm+1                                    LM that can be jointly learned with the end model (Cachay\n       used to re-fit the LM. We call this ST (DM as LF).                                    et al., 2021; Maheshwari et al., 2020). We do not include this\n                                                                                             type of agreement-based re-labeling in our study, instead\n    \u2022 Consistency regularization: These methods encourage                                    focusing on methods agnostic to the form of LM.\n       models to make similar predictions on (realistic) pertur-\n       bations of unlabeled examples. Of these methods, we                                   3.3. Contextualizing previous works\n       use VAT (Miyato et al., 2017) as it does not rely on data\n       augmentations, unlike most others. Augmentations are                                  With our design space, we can contextualize several recent\n       less straightforward to define for text datasets, which                               WS methods, as shown in Table 1. Overall, this table demon-\n       comprise the majority of WS benchmarks.                                               strates the lack of systematic exploration. For instance, few\n                                                                                             works perform any thresholding beyond coverage-based,\nRe-labeling L. Traditional SSL assumes that all labels in L                                  and only Lang et al. (2022) and Gao et al. (2022) thresh-\nare correct. However, in WS, we may also consider using                                      old LM outputs. Furthermore, assessing the impact of SSL\nthe end model to correct labels in L as it trains. This increas-                             in WS settings is muddled because methods often incorpo-\ningly popular technique in WS methods (Cachay et al., 2021;                                  rate several different techniques. A salient example is that\nYu et al., 2021; Karamanolakis et al., 2021; Maheshwari                                      COSINE (Yu et al., 2021) was found by WRENCH (Zhang\net al., 2020) is often packaged with traditional self-training                               et al., 2021) to obtain state-of-the-art performance, with both\nas an overall \u201cSSL method\u201d (Yu et al., 2021; Karamanolakis                                   works championing the usage of unlabeled data as a key\net al., 2021): instead of using the current model to label just                              driver of improvements; however, what COSINE refers to\n                                                                                         4", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n## Table 1: Contextualizing methods within and outside the design space\n\n| Method          | Thresholding     | SSL Technique       | Re-labeling L       | Novel LM | Add. Reg. | Add. Labels |\n|-----------------|------------------|---------------------|---------------------|----------|-----------|-------------|\n| Vanilla WS      | Coverage         | -                   | -                   | -        | -         | -           |\n| Cutstat         | Cut-based        | -                   | -                   | -        | -         | -           |\n| Denoise         | Coverage         | Temp. Ensembling    | Self-Train LM       | \u2713        | -         | -           |\n| Weasel          | -                | -                   | Agreement-based     | \u2713        | -         | -           |\n| Cosine          | Confidence       | Self-Train          | DM directly         | -        | \u2713         | -           |\n| KeyClass        | Confidence       | Self-Train          | DM directly         | -        | \u2713         | -           |\n| ASTRA           | Coverage         | Self-Train (DM as LF)| DM as LF           | \u2713        | -         | \u2713           |\n| LPA+WL          | -                | Label Propagation   | -                   | -        | -         | \u2713           |\n| SPEAR           | -                | Entropy Min         | Agreement-based     | \u2713        | \u2713         | \u2713           |\n\n\"Novel LM\" refers to a method introducing its own label model. \"Add. Reg.\" refers to using additional regularizations, such as contrastive losses and soft-label re-normalization. \"Add. Labels\" refers to assuming an additional set of clean labels. For methods using clean labels, we do not compare to their results directly, but we can still place elements of their approaches in our design space.\n\n## SSL Techniques\n\nAfter partitioning D into L and U, these methods also do so for L. However, this makes it difficult to discern whether these methods improve performance because they leverage U (i.e., apply SSL) or simply because they clean up labels in L. Therefore, in our study, we explicitly decouple the use of SSL and re-labeling L as two independent decisions; i.e., we can re-label L regardless of whether we use any specific SSL technique.\n\nSpecifically, we consider two types of re-labeling: (1) using the end model's predictions directly as in ST, and (2) refitting the LM as in ST (DM as LF). For tractability, we treat re-labeling as a binary decision when accompanied by an SSL technique; we re-label L with the end model directly in except when the SSL technique is ST (DM as LF). Also, we formalize re-labeling as looping the two-stage WS pipeline back onto itself. In principle, N rounds of re-labeling can be paired with N +1 separate choices for thresholding and SSL. However, to reduce this search space, we consider either using the same thresholding and SSL techniques across all rounds or fixing the L/U split after thresholding the initial LM outputs; in the context of thresholding, we refer to these two schedules as dynamic and one-time, respectively.\n\nFinally, some recent methods re-label by using a specialized LM that can be jointly learned with the end model. We do not include this type of agreement-based re-labeling in our study, instead focusing on methods agnostic to the form of LM.\n\n## Re-labeling L\n\nTraditional SSL assumes that all labels in L are correct. However, in WS, we may also consider using the end model to correct labels in L as it trains. This increasingly popular technique in WS methods is often packaged with traditional self-training as an overall \"SSL method\": instead of using the current model to label just.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "Table 1: Contextualizing methods within and outside the design space", "md": "## Table 1: Contextualizing methods within and outside the design space"}, {"type": "table", "rows": [["Method", "Thresholding", "SSL Technique", "Re-labeling L", "Novel LM", "Add. Reg.", "Add. Labels"], ["Vanilla WS", "Coverage", "-", "-", "-", "-", "-"], ["Cutstat", "Cut-based", "-", "-", "-", "-", "-"], ["Denoise", "Coverage", "Temp. Ensembling", "Self-Train LM", "\u2713", "-", "-"], ["Weasel", "-", "-", "Agreement-based", "\u2713", "-", "-"], ["Cosine", "Confidence", "Self-Train", "DM directly", "-", "\u2713", "-"], ["KeyClass", "Confidence", "Self-Train", "DM directly", "-", "\u2713", "-"], ["ASTRA", "Coverage", "Self-Train (DM as LF)", "DM as LF", "\u2713", "-", "\u2713"], ["LPA+WL", "-", "Label Propagation", "-", "-", "-", "\u2713"], ["SPEAR", "-", "Entropy Min", "Agreement-based", "\u2713", "\u2713", "\u2713"]], "md": "| Method          | Thresholding     | SSL Technique       | Re-labeling L       | Novel LM | Add. Reg. | Add. Labels |\n|-----------------|------------------|---------------------|---------------------|----------|-----------|-------------|\n| Vanilla WS      | Coverage         | -                   | -                   | -        | -         | -           |\n| Cutstat         | Cut-based        | -                   | -                   | -        | -         | -           |\n| Denoise         | Coverage         | Temp. Ensembling    | Self-Train LM       | \u2713        | -         | -           |\n| Weasel          | -                | -                   | Agreement-based     | \u2713        | -         | -           |\n| Cosine          | Confidence       | Self-Train          | DM directly         | -        | \u2713         | -           |\n| KeyClass        | Confidence       | Self-Train          | DM directly         | -        | \u2713         | -           |\n| ASTRA           | Coverage         | Self-Train (DM as LF)| DM as LF           | \u2713        | -         | \u2713           |\n| LPA+WL          | -                | Label Propagation   | -                   | -        | -         | \u2713           |\n| SPEAR           | -                | Entropy Min         | Agreement-based     | \u2713        | \u2713         | \u2713           |", "isPerfectTable": true, "csv": "\"Method\",\"Thresholding\",\"SSL Technique\",\"Re-labeling L\",\"Novel LM\",\"Add. Reg.\",\"Add. Labels\"\n\"Vanilla WS\",\"Coverage\",\"-\",\"-\",\"-\",\"-\",\"-\"\n\"Cutstat\",\"Cut-based\",\"-\",\"-\",\"-\",\"-\",\"-\"\n\"Denoise\",\"Coverage\",\"Temp. Ensembling\",\"Self-Train LM\",\"\u2713\",\"-\",\"-\"\n\"Weasel\",\"-\",\"-\",\"Agreement-based\",\"\u2713\",\"-\",\"-\"\n\"Cosine\",\"Confidence\",\"Self-Train\",\"DM directly\",\"-\",\"\u2713\",\"-\"\n\"KeyClass\",\"Confidence\",\"Self-Train\",\"DM directly\",\"-\",\"\u2713\",\"-\"\n\"ASTRA\",\"Coverage\",\"Self-Train (DM as LF)\",\"DM as LF\",\"\u2713\",\"-\",\"\u2713\"\n\"LPA+WL\",\"-\",\"Label Propagation\",\"-\",\"-\",\"-\",\"\u2713\"\n\"SPEAR\",\"-\",\"Entropy Min\",\"Agreement-based\",\"\u2713\",\"\u2713\",\"\u2713\""}, {"type": "text", "value": "\"Novel LM\" refers to a method introducing its own label model. \"Add. Reg.\" refers to using additional regularizations, such as contrastive losses and soft-label re-normalization. \"Add. Labels\" refers to assuming an additional set of clean labels. For methods using clean labels, we do not compare to their results directly, but we can still place elements of their approaches in our design space.", "md": "\"Novel LM\" refers to a method introducing its own label model. \"Add. Reg.\" refers to using additional regularizations, such as contrastive losses and soft-label re-normalization. \"Add. Labels\" refers to assuming an additional set of clean labels. For methods using clean labels, we do not compare to their results directly, but we can still place elements of their approaches in our design space."}, {"type": "heading", "lvl": 2, "value": "SSL Techniques", "md": "## SSL Techniques"}, {"type": "text", "value": "After partitioning D into L and U, these methods also do so for L. However, this makes it difficult to discern whether these methods improve performance because they leverage U (i.e., apply SSL) or simply because they clean up labels in L. Therefore, in our study, we explicitly decouple the use of SSL and re-labeling L as two independent decisions; i.e., we can re-label L regardless of whether we use any specific SSL technique.\n\nSpecifically, we consider two types of re-labeling: (1) using the end model's predictions directly as in ST, and (2) refitting the LM as in ST (DM as LF). For tractability, we treat re-labeling as a binary decision when accompanied by an SSL technique; we re-label L with the end model directly in except when the SSL technique is ST (DM as LF). Also, we formalize re-labeling as looping the two-stage WS pipeline back onto itself. In principle, N rounds of re-labeling can be paired with N +1 separate choices for thresholding and SSL. However, to reduce this search space, we consider either using the same thresholding and SSL techniques across all rounds or fixing the L/U split after thresholding the initial LM outputs; in the context of thresholding, we refer to these two schedules as dynamic and one-time, respectively.\n\nFinally, some recent methods re-label by using a specialized LM that can be jointly learned with the end model. We do not include this type of agreement-based re-labeling in our study, instead focusing on methods agnostic to the form of LM.", "md": "After partitioning D into L and U, these methods also do so for L. However, this makes it difficult to discern whether these methods improve performance because they leverage U (i.e., apply SSL) or simply because they clean up labels in L. Therefore, in our study, we explicitly decouple the use of SSL and re-labeling L as two independent decisions; i.e., we can re-label L regardless of whether we use any specific SSL technique.\n\nSpecifically, we consider two types of re-labeling: (1) using the end model's predictions directly as in ST, and (2) refitting the LM as in ST (DM as LF). For tractability, we treat re-labeling as a binary decision when accompanied by an SSL technique; we re-label L with the end model directly in except when the SSL technique is ST (DM as LF). Also, we formalize re-labeling as looping the two-stage WS pipeline back onto itself. In principle, N rounds of re-labeling can be paired with N +1 separate choices for thresholding and SSL. However, to reduce this search space, we consider either using the same thresholding and SSL techniques across all rounds or fixing the L/U split after thresholding the initial LM outputs; in the context of thresholding, we refer to these two schedules as dynamic and one-time, respectively.\n\nFinally, some recent methods re-label by using a specialized LM that can be jointly learned with the end model. We do not include this type of agreement-based re-labeling in our study, instead focusing on methods agnostic to the form of LM."}, {"type": "heading", "lvl": 2, "value": "Re-labeling L", "md": "## Re-labeling L"}, {"type": "text", "value": "Traditional SSL assumes that all labels in L are correct. However, in WS, we may also consider using the end model to correct labels in L as it trains. This increasingly popular technique in WS methods is often packaged with traditional self-training as an overall \"SSL method\": instead of using the current model to label just.", "md": "Traditional SSL assumes that all labels in L are correct. However, in WS, we may also consider using the end model to correct labels in L as it trains. This increasingly popular technique in WS methods is often packaged with traditional self-training as an overall \"SSL method\": instead of using the current model to label just."}]}, {"page": 5, "text": "                                 Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n    Datasets     |Y|     |Train|      |Test|    Coverage      Snork. Precision            Baselines. We consider fi             ve baselines, corresponding to\n     IMDb          2      20000       2500        87.6%             74.4%\n      Yelp         2      30400       3800        82.8%             75.4%                 the WRENCH implementations of existing state-of-the-art\n    Youtube        2       1586        250        87.7%             87.0%\n    AgNews         4      96000      12000        69.1%             82.5%                 methods. As Table 1 shows, each incorporates some aspects\n      Trec         6       4965        500        95.1%             60.0%                 of our design space, while not necessarily being contained\n     Spouse        2      22254       2701        25.8%         65.6% (on Val)            completely within it. We list these methods as follows:\n   Chemprot       10      12861       1607        85.6%             58.0%\n     Census        2      10083      16281        99.1%             58.0%                 Vanilla: applies the default WS pipeline, using coverage\nTable 2. Statistics for the data/LF sets that we use, groupings are                       thresholding and no SSL or re-labeling.\nby task type: text, text relation, and tabular classification. Note\nthat Spouse does not come with ground-truth training labels.                              Cutstat + {Snorkel, MV}: uses the thresholding method\n                                                                                          from Lang et al. (2022), with no alterations.\n                                                                                          COSINE + {Snorkel, MV}: modifies the method from Yu\nas self-training actually involves pseudo-labeling the whole                              et al. (2021) in two ways when appropriate for fair compari-\ndataset, thereby performing both SSL and re-labeling. Fur-                                son; the LM used is Snorkel instead of MV except as shown\nther, many methods use techniques outside of our design                                   in Table 8, and the DM is an MLP in Table 6.\nspace entirely, such as novel LMs (Ren et al., 2020; Cachay                               Denoise + {Snorkel, MV}: applies the method from Ren\net al., 2021; Karamanolakis et al., 2021; Maheshwari et al.,                              et al. (2020) except using Snorkel instead of MV to initialize\n2020), contrastive learning (Yu et al., 2021), and soft-label                             their label aggregator as shown in Table 8. Also, we use\nre-normalization (Yu et al., 2021; Gao et al., 2022). As a re-                            RoBERTa-based end models instead of BERT.\nsult, it remains unclear whether our three axes are necessary\nor even sufficient to achieve optimal performance. Though                                 Weasel: applies the method from Cachay et al. (2021) except\nour design space is by no means exhaustive, we believe it                                 to train RoBERTa-based end models on the text datasets.\noffers a useful starting point to answer such questions.\n                                                                                          4.2. Does our design space yield competitive methods?\n4. Results                                                                                We first demonstrate that simple methods from our design\nWe begin by describing our experiment setup and various                                   space can at least match the performance of all previous\nbaselines in Section 4.1. Then, Section 4.2 explores how our                              methods. When the end model is RoBERTa, our best single\ndesign space yields methods that perform at least as well as                              method (shown in Figure 2) is the combination of (dynamic)\nthe aforementioned baselines. In Sections 4.3 and 4.4, we                                 confidence thresholding, ST (DM as LF), and re-labeling.\nconduct extensive ablations on our three axes, finding that                               This method at least matches the performance of other base-\nSSL is surprisingly unnecessary on most WS benchmarks.                                    lines on 5 of the 7 text-based datasets, on average closing\nFinally, Section 4.5 explains this phenomenon and explores                                11.5% of the remaining gap between previous WS methods\nsettings in which SSL is more helpful.                                                    and fully supervised learning. On AGNews and Chemprot,\n                                                                                          only Cutstat results in a better point estimate. However,\n                                                                                          for both tasks, swapping cut-based thresholding into our\n4.1. Experimental Setup                                                                   method produces state-of-the-art accuracies of 0.885 (0.002)\nDatasets and models. We use 8 classification datasets (see                                and 0.601 (0.008), respectively (as shown in Appendix B,\nTable 2) and largely follow the end model configurations                                  this method is similarly strong when the LM is instead Ma-\nfrom WRENCH (Zhang et al., 2021) with a few changes to                                    jority Voting). Finally, Figure 2 shows that searching our\nthe hyperparameter grid (Appendix A). For NLP tasks, we                                   design space exhaustively per dataset\u2013while not necessarily\nboth fine-tune RoBERTa pre-trained models and train MLP                                   practical\u2013can be even more effective, closing an additional\nclassification heads on (frozen) RoBERTa embeddings, de-                                  15% of the gap to fully supervised learning. Significantly,\nferring results for the latter to the appendix. For tabular                               our methods are strong despite not using some additional\ntasks, we just train MLPs. We tune all methods on a shared                                techniques employed by recent works (i.e., see Table 1).\nhyperparameter budget of 300 trials for MLPs and 50 tri-                                  This provides empirical justification for focusing only on\nals for full RoBERTa fine-tuning. All reported test perfor-                               methods from within our design space in later analyses.\nmances are then averages over over three additional runs,\nwhile all error bars are the standard deviations over these                               4.3. Which axes are most important?\nruns. Finally, though our design space is compatible with                                 Though our design space is sufficient for strong performance,\nany LM, we use the soft-labels produced by the Snorkel LM                                 we now show that SSL is, by and large, not necessary on\nfrom Ratner et al. (2019). However, we test robustness to                                 current benchmarks. Specifically, we conduct an extensive\nthis choice by also trying Majority Voting when comparing                                 ablation comparing all eight possible subsets of including\nwith existing methods. Zhang et al. (2021) found these two                                (or ignoring) each axis, presenting the results in Tables 3\nLMs to be the most consistent across many WS tasks.\n                                                                                      5", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n## Table 2. Statistics for the data/LF sets that we use, groupings are by task type: text, text relation, and tabular classification.\n\n|Datasets||Y|||Train|||Test||Coverage|Snork. Precision|\n|---|---|---|---|---|---|\n|IMDb|2|20000|2500|87.6%|74.4%|\n|Yelp|2|30400|3800|82.8%|75.4%|\n|Youtube|2|1586|250|87.7%|87.0%|\n|AgNews|4|96000|12000|69.1%|82.5%|\n|Trec|6|4965|500|95.1%|60.0%|\n|Spouse|2|22254|2701|25.8%|65.6% (on Val)|\n|Chemprot|10|12861|1607|85.6%|58.0%|\n|Census|2|10083|16281|99.1%|58.0%|\n\nNote that Spouse does not come with ground-truth training labels.\n\n...\n\n## 4.1. Experimental Setup\n\nDatasets and models. We use 8 classification datasets (see Table 2) and largely follow the end model configurations from WRENCH (Zhang et al., 2021) with a few changes to the hyperparameter grid (Appendix A). For NLP tasks, we both fine-tune RoBERTa pre-trained models and train MLP classification heads on (frozen) RoBERTa embeddings, deferring results for the latter to the appendix. For tabular tasks, we just train MLPs. We tune all methods on a shared hyperparameter budget of 300 trials for MLPs and 50 trials for full RoBERTa fine-tuning. All reported test performances are then averages over three additional runs, while all error bars are the standard deviations over these runs. Finally, though our design space is compatible with any LM, we use the soft-labels produced by the Snorkel LM from Ratner et al. (2019). However, we test robustness to this choice by also trying Majority Voting when comparing with existing methods. Zhang et al. (2021) found these two LMs to be the most consistent across many WS tasks.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "Table 2. Statistics for the data/LF sets that we use, groupings are by task type: text, text relation, and tabular classification.", "md": "## Table 2. Statistics for the data/LF sets that we use, groupings are by task type: text, text relation, and tabular classification."}, {"type": "table", "rows": [["Datasets", "", "Y", "", "", "Train", "", "", "Test", "", "Coverage", "Snork. Precision"], ["IMDb", "2", "20000", "2500", "87.6%", "74.4%"], ["Yelp", "2", "30400", "3800", "82.8%", "75.4%"], ["Youtube", "2", "1586", "250", "87.7%", "87.0%"], ["AgNews", "4", "96000", "12000", "69.1%", "82.5%"], ["Trec", "6", "4965", "500", "95.1%", "60.0%"], ["Spouse", "2", "22254", "2701", "25.8%", "65.6% (on Val)"], ["Chemprot", "10", "12861", "1607", "85.6%", "58.0%"], ["Census", "2", "10083", "16281", "99.1%", "58.0%"]], "md": "|Datasets||Y|||Train|||Test||Coverage|Snork. Precision|\n|---|---|---|---|---|---|\n|IMDb|2|20000|2500|87.6%|74.4%|\n|Yelp|2|30400|3800|82.8%|75.4%|\n|Youtube|2|1586|250|87.7%|87.0%|\n|AgNews|4|96000|12000|69.1%|82.5%|\n|Trec|6|4965|500|95.1%|60.0%|\n|Spouse|2|22254|2701|25.8%|65.6% (on Val)|\n|Chemprot|10|12861|1607|85.6%|58.0%|\n|Census|2|10083|16281|99.1%|58.0%|", "isPerfectTable": false, "csv": "\"Datasets\",\"\",\"Y\",\"\",\"\",\"Train\",\"\",\"\",\"Test\",\"\",\"Coverage\",\"Snork. Precision\"\n\"IMDb\",\"2\",\"20000\",\"2500\",\"87.6%\",\"74.4%\"\n\"Yelp\",\"2\",\"30400\",\"3800\",\"82.8%\",\"75.4%\"\n\"Youtube\",\"2\",\"1586\",\"250\",\"87.7%\",\"87.0%\"\n\"AgNews\",\"4\",\"96000\",\"12000\",\"69.1%\",\"82.5%\"\n\"Trec\",\"6\",\"4965\",\"500\",\"95.1%\",\"60.0%\"\n\"Spouse\",\"2\",\"22254\",\"2701\",\"25.8%\",\"65.6% (on Val)\"\n\"Chemprot\",\"10\",\"12861\",\"1607\",\"85.6%\",\"58.0%\"\n\"Census\",\"2\",\"10083\",\"16281\",\"99.1%\",\"58.0%\""}, {"type": "text", "value": "Note that Spouse does not come with ground-truth training labels.\n\n...", "md": "Note that Spouse does not come with ground-truth training labels.\n\n..."}, {"type": "heading", "lvl": 2, "value": "4.1. Experimental Setup", "md": "## 4.1. Experimental Setup"}, {"type": "text", "value": "Datasets and models. We use 8 classification datasets (see Table 2) and largely follow the end model configurations from WRENCH (Zhang et al., 2021) with a few changes to the hyperparameter grid (Appendix A). For NLP tasks, we both fine-tune RoBERTa pre-trained models and train MLP classification heads on (frozen) RoBERTa embeddings, deferring results for the latter to the appendix. For tabular tasks, we just train MLPs. We tune all methods on a shared hyperparameter budget of 300 trials for MLPs and 50 trials for full RoBERTa fine-tuning. All reported test performances are then averages over three additional runs, while all error bars are the standard deviations over these runs. Finally, though our design space is compatible with any LM, we use the soft-labels produced by the Snorkel LM from Ratner et al. (2019). However, we test robustness to this choice by also trying Majority Voting when comparing with existing methods. Zhang et al. (2021) found these two LMs to be the most consistent across many WS tasks.", "md": "Datasets and models. We use 8 classification datasets (see Table 2) and largely follow the end model configurations from WRENCH (Zhang et al., 2021) with a few changes to the hyperparameter grid (Appendix A). For NLP tasks, we both fine-tune RoBERTa pre-trained models and train MLP classification heads on (frozen) RoBERTa embeddings, deferring results for the latter to the appendix. For tabular tasks, we just train MLPs. We tune all methods on a shared hyperparameter budget of 300 trials for MLPs and 50 trials for full RoBERTa fine-tuning. All reported test performances are then averages over three additional runs, while all error bars are the standard deviations over these runs. Finally, though our design space is compatible with any LM, we use the soft-labels produced by the Snorkel LM from Ratner et al. (2019). However, we test robustness to this choice by also trying Majority Voting when comparing with existing methods. Zhang et al. (2021) found these two LMs to be the most consistent across many WS tasks."}]}, {"page": 6, "text": "                                         Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n                        0.06      IMDb-RoBERTa (Acc)               0.06      Yelp-RoBERTa (Acc)               0.03    Youtube-RoBERTa (Acc)              0.03    AGNews-RoBERTa (Acc)\n                      in Test Perf.\n                        0.04                                       0.04                                       0.02                                       0.02\n                        0.02                                       0.02                                       0.01                                       0.01\n                        0.00                                       0.00                                       0.00                                       0.00\n                        0.02                                       0.02                                       0.01                                       0.01\n                        0.15      TREC-RoBERTa (Acc)                0.3 Spouse-RoBERTa (F1_binary)            0.06   Chemprot-RoBERTa (Acc)              0.15    Census-MLP (F1_binary)\n                      in Test Perf.                                                                                                                                    Conf + VAT + Re-label\n                        0.10                                        0.2                                       0.04                                       0.10\n                        0.05                                        0.1                                       0.02                                       0.05\n                        0.00                                        0.0                                       0.00                                       0.00\n                        0.05                                        0.1                                       0.02                                       0.05\n                                                           Best of Design Space                               Cutstat + Snorkel                 Denoise + Snorkel\n                                                           Conf + ST (DM as LF) + Re-label                    COSINE + Snorkel                  Weasel\n Figure 2. Test performance for LM = Snorkel. We compare the best single method found for each DM from our design space (green) with\n the best methods per-dataset (turquoise, narrower error caps) as well as four recent proposals from the literature. We plot all performances\n relative to that of vanilla training (deferring absolute metrics to Table 7 in Appendix B). Note that for Census, a tabular dataset, the best\n single method is different since we report the one we found for MLPs (see Appendix B).\n and 9. As an example, for the row \u201cThresh + SSL,\u201d we                                                          labels is still adds unique value even when also allowing for\n run every combination within the cross-product of all non-                                                    SSL and re-labeling. Interestingly, the simpler confidence-\n default thresholding and SSL techniques (i.e., {Conf-based,                                                   based threshold matches the cut-based method (within error\n Cut-based} \u00d7 {EM, VAT, ST, ST w/ DM}) and then select                                                         bars) on all datasets except Chemprot.\n the best of these combinations using the validation set. For                                                  SSL and Re-labeling. For these two axes, we observe\n\u201cEntire Design Space,\u201d we perform this method selection\n procedure over all methods from the design space.1                                                            largely similar trends in Tables 10 and 11 in Appendix C.2.\n                                                                                                               SSL and re-labeling are each only strictly necessary for a\n From this analysis, we observe that SSL helps only in lim-                                                    minority of datasets, significantly outperforming \u201cno SSL\u201d\n ited scenarios. Including SSL on Spouse yields a 0.2 in-                                                      and \u201cno re-labeling\u201d on just one and two datasets, respec-\n crease in F1-score compared to not using any form of SSL.                                                     tively. As such, all SSL methods tend to perform similarly.\n However, on all the other six tasks, \u201cThresh + Re-label\u201d                                                      But for MLPs in Table 13, SSL is more useful and we see\n performs at least within a standard deviation of the best                                                     that VAT and ST (DM as LF) are the most consistent. No\n method, making up 89.1% of the gap between \u201cVanilla\u201d and                                                      other method comes within error bars on four tasks.\n\u201cThresh + SSL + Re-label.\u201d One explanation for this result\n is the distinctly lower coverage LF set for Spouse, a factor                                                  4.5. When is SSL more useful?\n we explore in depth in Sec 4.5. Further, model size may\n also play a role. In the corresponding Table 9 (Appendix B)                                                   To explain why SSL is largely redundant on most existing\n for MLPs, \u201cThresh + Re-label\u201d can make up only 68.2% of                                                       WS benchmarks, we show that the unlabeled data in each\n the gap between \u201cVanilla\u201d and \u201cThresh + SSL + Re-label.\u201d                                                      task is generally unnecessary for learning strong models.\n                                                                                                               However, when using lower coverage LF sets (a setting not\n 4.4. What are the best instantiations of each axis?                                                           captured by these benchmarks), ignoring unlabeled data can\n                                                                                                               significantly compromise performance. In these settings,\n Having compared the three axes at a macro-level, we now                                                       SSL has more room to be impactful.\n zoom in on each. Specifically, we compare all implemen-                                                       Data gaps in WS. We can think of any WS training set L =\n tations of a given axis when paired with the best possible                                                    {(X\u2113       yi)}|L|             D as suffering from three deficiencies:\n setting of the other two. For thresholding and SSL, we find                                                           i , \u02dc      i=1 \u2286        \u02dc\n that previously underexplored approaches are worth using.                                                        1. Limited size: Since not all examples are labeled, the\n Thresholding. Examining Table 4, we observe that thresh-                                                               quantity of labels may be insufficient.\n olding is significantly helpful in most cases. This extends                                                      2. Coverage bias: Since LFs abstain based on feature-\n the conclusions of Lang et al. (2022), showing that removing                                                           dependent rules, the inputs in L are a biased subpopu-\n      1 This differs from \u201cThresh + SSL + Re-label\u201d because methods                                                     lation of the full test distribution.\n for that row must employ non-default choices for each axis.                                                      3. Label noise: Since LFs are just heuristics, labels \u02dc                     yi can\n                                                                                                                        be biased towards incorrect classes.\n                                                                                                          6", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n| |IMDb-RoBERTa (Acc)|Yelp-RoBERTa (Acc)|Youtube-RoBERTa (Acc)|AGNews-RoBERTa (Acc)|\n|---|---|---|---|---|\n|in Test Perf.|0.06|0.06|0.03|0.03|\n| |0.04|0.04|0.02|0.02|\n| |0.02|0.02|0.01|0.01|\n| |0.00|0.00|0.00|0.00|\n| |0.02|0.02|0.01|0.01|\n| |0.15|TREC-RoBERTa (Acc)|0.3 Spouse-RoBERTa (F1_binary)|0.06 Chemprot-RoBERTa (Acc)|0.15 Census-MLP (F1_binary)|\n|in Test Perf.|0.10|0.2|0.04|0.10|\n| |0.05|0.1|0.02|0.05|\n| |0.00|0.0|0.00|0.00|\n| |0.05|0.1|0.02|0.05|\n\nBest of Design Space: Cutstat + Snorkel, Denoise + Snorkel\n\nConf + ST (DM as LF) + Re-label, COSINE + Snorkel, Weasel\n\nFigure 2. Test performance for LM = Snorkel. We compare the best single method found for each DM from our design space (green) with the best methods per-dataset (turquoise, narrower error caps) as well as four recent proposals from the literature. We plot all performances relative to that of vanilla training (deferring absolute metrics to Table 7 in Appendix B). Note that for Census, a tabular dataset, the best single method is different since we report the one we found for MLPs (see Appendix B).\n\nand 9. As an example, for the row \u201cThresh + SSL,\u201d we run every combination within the cross-product of all non-default thresholding and SSL techniques (i.e., {Conf-based, Cut-based} \u00d7 {EM, VAT, ST, ST w/ DM}) and then select the best of these combinations using the validation set. For \u201cEntire Design Space,\u201d we perform this method selection procedure over all methods from the design space.\n\nFrom this analysis, we observe that SSL helps only in limited scenarios. Including SSL on Spouse yields a 0.2 increase in F1-score compared to not using any form of SSL. However, on all the other six tasks, \u201cThresh + Re-label\u201d performs at least within a standard deviation of the best method, making up 89.1% of the gap between \u201cVanilla\u201d and \u201cThresh + SSL + Re-label.\u201d One explanation for this result is the distinctly lower coverage LF set for Spouse, a factor we explore in depth in Sec 4.5. Further, model size may also play a role. In the corresponding Table 9 (Appendix B) for MLPs, \u201cThresh + Re-label\u201d can make up only 68.2% of the gap between \u201cVanilla\u201d and \u201cThresh + SSL + Re-label.\u201d\n\n### 4.4. What are the best instantiations of each axis?\n\nHaving compared the three axes at a macro-level, we now zoom in on each. Specifically, we compare all implementations of a given axis when paired with the best possible setting of the other two. For thresholding and SSL, we find that previously underexplored approaches are worth using.\n\nThresholding. Examining Table 4, we observe that thresholding is significantly helpful in most cases. This extends the conclusions of Lang et al. (2022), showing that removing\n\n$$1$$ This differs from \u201cThresh + SSL + Re-label\u201d because methods for that row must employ non-default choices for each axis.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "table", "rows": [["", "IMDb-RoBERTa (Acc)", "Yelp-RoBERTa (Acc)", "Youtube-RoBERTa (Acc)", "AGNews-RoBERTa (Acc)"], ["in Test Perf.", "0.06", "0.06", "0.03", "0.03"], ["", "0.04", "0.04", "0.02", "0.02"], ["", "0.02", "0.02", "0.01", "0.01"], ["", "0.00", "0.00", "0.00", "0.00"], ["", "0.02", "0.02", "0.01", "0.01"], ["", "0.15", "TREC-RoBERTa (Acc)", "0.3 Spouse-RoBERTa (F1_binary)", "0.06 Chemprot-RoBERTa (Acc)", "0.15 Census-MLP (F1_binary)"], ["in Test Perf.", "0.10", "0.2", "0.04", "0.10"], ["", "0.05", "0.1", "0.02", "0.05"], ["", "0.00", "0.0", "0.00", "0.00"], ["", "0.05", "0.1", "0.02", "0.05"]], "md": "| |IMDb-RoBERTa (Acc)|Yelp-RoBERTa (Acc)|Youtube-RoBERTa (Acc)|AGNews-RoBERTa (Acc)|\n|---|---|---|---|---|\n|in Test Perf.|0.06|0.06|0.03|0.03|\n| |0.04|0.04|0.02|0.02|\n| |0.02|0.02|0.01|0.01|\n| |0.00|0.00|0.00|0.00|\n| |0.02|0.02|0.01|0.01|\n| |0.15|TREC-RoBERTa (Acc)|0.3 Spouse-RoBERTa (F1_binary)|0.06 Chemprot-RoBERTa (Acc)|0.15 Census-MLP (F1_binary)|\n|in Test Perf.|0.10|0.2|0.04|0.10|\n| |0.05|0.1|0.02|0.05|\n| |0.00|0.0|0.00|0.00|\n| |0.05|0.1|0.02|0.05|", "isPerfectTable": false, "csv": "\"\",\"IMDb-RoBERTa (Acc)\",\"Yelp-RoBERTa (Acc)\",\"Youtube-RoBERTa (Acc)\",\"AGNews-RoBERTa (Acc)\"\n\"in Test Perf.\",\"0.06\",\"0.06\",\"0.03\",\"0.03\"\n\"\",\"0.04\",\"0.04\",\"0.02\",\"0.02\"\n\"\",\"0.02\",\"0.02\",\"0.01\",\"0.01\"\n\"\",\"0.00\",\"0.00\",\"0.00\",\"0.00\"\n\"\",\"0.02\",\"0.02\",\"0.01\",\"0.01\"\n\"\",\"0.15\",\"TREC-RoBERTa (Acc)\",\"0.3 Spouse-RoBERTa (F1_binary)\",\"0.06 Chemprot-RoBERTa (Acc)\",\"0.15 Census-MLP (F1_binary)\"\n\"in Test Perf.\",\"0.10\",\"0.2\",\"0.04\",\"0.10\"\n\"\",\"0.05\",\"0.1\",\"0.02\",\"0.05\"\n\"\",\"0.00\",\"0.0\",\"0.00\",\"0.00\"\n\"\",\"0.05\",\"0.1\",\"0.02\",\"0.05\""}, {"type": "text", "value": "Best of Design Space: Cutstat + Snorkel, Denoise + Snorkel\n\nConf + ST (DM as LF) + Re-label, COSINE + Snorkel, Weasel\n\nFigure 2. Test performance for LM = Snorkel. We compare the best single method found for each DM from our design space (green) with the best methods per-dataset (turquoise, narrower error caps) as well as four recent proposals from the literature. We plot all performances relative to that of vanilla training (deferring absolute metrics to Table 7 in Appendix B). Note that for Census, a tabular dataset, the best single method is different since we report the one we found for MLPs (see Appendix B).\n\nand 9. As an example, for the row \u201cThresh + SSL,\u201d we run every combination within the cross-product of all non-default thresholding and SSL techniques (i.e., {Conf-based, Cut-based} \u00d7 {EM, VAT, ST, ST w/ DM}) and then select the best of these combinations using the validation set. For \u201cEntire Design Space,\u201d we perform this method selection procedure over all methods from the design space.\n\nFrom this analysis, we observe that SSL helps only in limited scenarios. Including SSL on Spouse yields a 0.2 increase in F1-score compared to not using any form of SSL. However, on all the other six tasks, \u201cThresh + Re-label\u201d performs at least within a standard deviation of the best method, making up 89.1% of the gap between \u201cVanilla\u201d and \u201cThresh + SSL + Re-label.\u201d One explanation for this result is the distinctly lower coverage LF set for Spouse, a factor we explore in depth in Sec 4.5. Further, model size may also play a role. In the corresponding Table 9 (Appendix B) for MLPs, \u201cThresh + Re-label\u201d can make up only 68.2% of the gap between \u201cVanilla\u201d and \u201cThresh + SSL + Re-label.\u201d", "md": "Best of Design Space: Cutstat + Snorkel, Denoise + Snorkel\n\nConf + ST (DM as LF) + Re-label, COSINE + Snorkel, Weasel\n\nFigure 2. Test performance for LM = Snorkel. We compare the best single method found for each DM from our design space (green) with the best methods per-dataset (turquoise, narrower error caps) as well as four recent proposals from the literature. We plot all performances relative to that of vanilla training (deferring absolute metrics to Table 7 in Appendix B). Note that for Census, a tabular dataset, the best single method is different since we report the one we found for MLPs (see Appendix B).\n\nand 9. As an example, for the row \u201cThresh + SSL,\u201d we run every combination within the cross-product of all non-default thresholding and SSL techniques (i.e., {Conf-based, Cut-based} \u00d7 {EM, VAT, ST, ST w/ DM}) and then select the best of these combinations using the validation set. For \u201cEntire Design Space,\u201d we perform this method selection procedure over all methods from the design space.\n\nFrom this analysis, we observe that SSL helps only in limited scenarios. Including SSL on Spouse yields a 0.2 increase in F1-score compared to not using any form of SSL. However, on all the other six tasks, \u201cThresh + Re-label\u201d performs at least within a standard deviation of the best method, making up 89.1% of the gap between \u201cVanilla\u201d and \u201cThresh + SSL + Re-label.\u201d One explanation for this result is the distinctly lower coverage LF set for Spouse, a factor we explore in depth in Sec 4.5. Further, model size may also play a role. In the corresponding Table 9 (Appendix B) for MLPs, \u201cThresh + Re-label\u201d can make up only 68.2% of the gap between \u201cVanilla\u201d and \u201cThresh + SSL + Re-label.\u201d"}, {"type": "heading", "lvl": 3, "value": "4.4. What are the best instantiations of each axis?", "md": "### 4.4. What are the best instantiations of each axis?"}, {"type": "text", "value": "Having compared the three axes at a macro-level, we now zoom in on each. Specifically, we compare all implementations of a given axis when paired with the best possible setting of the other two. For thresholding and SSL, we find that previously underexplored approaches are worth using.\n\nThresholding. Examining Table 4, we observe that thresholding is significantly helpful in most cases. This extends the conclusions of Lang et al. (2022), showing that removing\n\n$$1$$ This differs from \u201cThresh + SSL + Re-label\u201d because methods for that row must employ non-default choices for each axis.", "md": "Having compared the three axes at a macro-level, we now zoom in on each. Specifically, we compare all implementations of a given axis when paired with the best possible setting of the other two. For thresholding and SSL, we find that previously underexplored approaches are worth using.\n\nThresholding. Examining Table 4, we observe that thresholding is significantly helpful in most cases. This extends the conclusions of Lang et al. (2022), showing that removing\n\n$$1$$ This differs from \u201cThresh + SSL + Re-label\u201d because methods for that row must employ non-default choices for each axis."}]}, {"page": 7, "text": "                                     Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n                           Method                  IMDb          Yelp        Youtube        AGNews         TREC         Spouse       Chemprot          Mean         w/o Spouse\n                            Vanilla                 0.873        0.919         0.944          0.870         0.637        0.273          0.569           0.726          0.802\n                                                   (0.001)      (0.009)       (0.007)        (0.003)       (0.010)      (0.074)         (0.001)        (0.011)        (0.003)\n                        Thresh Alone                0.887        0.948         0.953          0.882         0.703        0.267          0.584           0.746          0.826\n                                                   (0.008)      (0.006)       (0.002)        (0.001)       (0.017)      (0.060)         (0.004)        (0.009)        (0.003)\n                          SSL Alone                 0.885        0.939         0.955          0.881         0.640        0.343          0.593           0.748          0.816\n                                                   (0.002)      (0.008)       (0.005)        (0.003)       (0.013)      (0.075)         (0.010)        (0.011)        (0.003)\n                        Re-label Alone              0.901        0.944         0.952          0.877         0.700        0.332          0.577           0.755          0.825\n                                                   (0.013)      (0.004)       (0.006)        (0.002)       (0.014)      (0.105)         (0.010)        (0.015)        (0.004)\n                        Thresh + SSL                0.885        0.959         0.943          0.887         0.732        0.529          0.592           0.790          0.833\n                                                   (0.018)      (0.002)       (0.008)        (0.005)       (0.014)      (0.057)         (0.005)        (0.009)        (0.004)\n                      Thresh + Re-label             0.905        0.961         0.952          0.883         0.748        0.236          0.600           0.755          0.841\n                                                   (0.011)      (0.002)       (0.006)        (0.005)       (0.023)      (0.085)         (0.006)        (0.013)        (0.005)\n                       SSL + Re-label               0.894        0.949         0.951          0.879         0.702        0.365          0.583           0.760          0.826\n                                                   (0.008)      (0.002)       (0.002)        (0.002)       (0.035)      (0.073)         (0.003)        (0.012)        (0.006)\n                  Thresh + SSL + Re-label           0.907        0.961         0.949          0.885         0.765        0.531          0.601           0.800          0.845\n                                                   (0.004)      (0.003)       (0.010)        (0.003)       (0.012)      (0.039)         (0.008)        (0.006)        (0.003)\n                     Entire Design Space            0.907        0.961         0.952          0.887         0.765        0.531          0.601           0.801          0.845\n                                                   (0.004)      (0.002)       (0.006)        (0.005)       (0.012)      (0.039)         (0.008)        (0.006)        (0.003)\n                       Fully supervised             0.932        0.976         0.967          0.918         0.966           \u2013           0.894             \u2013            0.943\n                                                   (0.005)      (0.001)       (0.013)        (0.006)       (0.004)          \u2013           (0.012)           \u2013           (0.003)\nTable 3. Axis ablation for LM = Snorkel, DM = RoBERTa. Each row corresponds to picking a specific method within our design space\nusing validation tuning. Blue numbers are the highest for a given dataset, while bold numbers are those within error bars of the best result.\n  Thresh        IMDb          Yelp        AGNews         TREC         Spouse        Chem.                                  Impacts of |L| and Coverage Bias\n    Cov          0.901        0.949         0.881         0.702        0.365        0.593                        1.00\n                (0.013)      (0.002)       (0.003)       (0.035)      (0.073)      (0.010)\n     Cut         0.907        0.958         0.887         0.765        0.531        0.608\n                (0.004)      (0.003)       (0.005)       (0.012)      (0.007)      (0.003)                      GT (Full) Test Acc\n                 0.906        0.961         0.884         0.753        0.531        0.593                        0.95                                                           imdb\n    Conf        (0.005)      (0.003)       (0.002)       (0.021)      (0.039)      (0.010)                                                                                      yelp\n                                                                                                                                                                                youtube\n                                                                                                                                                                                agnews\n                                                                                                                                                                                trec\nTable 4. Deeper dive into the thresholding axis for DM = RoBERTa.                                                0.90                                                           chemprot\nWe report the highest performance of a method that incorporates a\ngiven type of thresholding, selected by validation performance.\n                                                                                                                 0.85\n                                                                                                                    0.85            0.90            0.95            1.00\n                                                                                                                                    GT (Cov) Test Acc\nWe hypothesize that SSL adds more unique value within our\ndesign space when gaps (1) and (2) are more significant.                                             Figure 3. Measuring the impact of smaller |L| and coverage bias\nWhen gap (3) is the only dominating factor, there is less                                            on WS benchmarks. As seen, when label noise is removed from\nreason to expect SSL to outperform thresholding and re-                                              the covered set of examples for GT (Cov), the performance drops\nlabeling since the latter two more directly address label                                            <2% compared to having all the clean labels for GT (Full). Note\nnoise. However, these two axes still do not use the unlabeled                                        we cannot plot Spouse as it does not have clean training labels.\nexamples, which cause gaps (1) and (2).\nLabel noise is the main gap on WS benchmarks. To\nmeasure the relative importance of the three data gaps, we                                           show that SSL is more useful when the other two gaps are\ncompare the following models:                                                                        significant, i.e., when GT (Cov) performs markedly worse\nGT (Cov): the model trained on the clean labels for only                                             than GT (Full). One natural way to explore this would be to\ncovered inputs, removing gap (3) but retaining (1) and (2).                                          test on lower coverage LF sets, which result in more unla-\n                                                                                                     beled data. However, most existing benchmarks have cover-\nGT (Full): the model trained with a clean and fully labeled                                          ages above 80% (see Table 2). To overcome this limitation,\nversion of D, removing all gaps.                                                                     we first explore a wider range of coverages by subsampling\nGiven our hypothesis, we would expect these models to                                                or generating LFs on existing datasets. We also create two\nperform similarly on WRENCH benchmarks. Indeed, as                                                   new WS text classification tasks based on publicly available\nshown in Figure 3, the largest gap between them is <2 p.p.                                           datasets, Massive18 (FitzGerald et al., 2022) and Banking77\n                                                                                                     (Casanueva et al., 2020); these tasks have larger label spaces\nSSL helps more when coverage is lower. While SSL\u2019s                                                   than all WRENCH datasets and thus require more effort (i.e.,\nineffectiveness on existing benchmarks corresponds to label                                          LFs) to obtain high coverage. Finally, we explore the less-\nnoise being the predominant data gap, we would ideally also                                          studied tabular setting, using Mushroom, Spambase, and\n                                                                                                 7", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n## Table 1. Performance Comparison\n\n|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Mean|w/o Spouse|\n|---|---|---|---|---|---|---|---|---|---|\n|Vanilla|0.873|0.919|0.944|0.870|0.637|0.273|0.569|0.726|0.802|\n|Thresh Alone|0.887|0.948|0.953|0.882|0.703|0.267|0.584|0.746|0.826|\n|$<br/>\\begin{array}{|c|c|c|c|c|c|c|c|c|c|}<br/>\\hline<br/>\\text{Method} & \\text{IMDb} & \\text{Yelp} & \\text{Youtube} & \\text{AGNews} & \\text{TREC} & \\text{Spouse} & \\text{Chemprot} & \\text{Mean} & \\text{w/o Spouse} \\\\<br/>\\hline<br/>\\text{Vanilla} & 0.873 & 0.919 & 0.944 & 0.870 & 0.637 & 0.273 & 0.569 & 0.726 & 0.802 \\\\<br/>& (0.001) & (0.009) & (0.007) & (0.003) & (0.010) & (0.074) & (0.001) & (0.011) & (0.003) \\\\<br/>\\text{Thresh Alone} & 0.887 & 0.948 & 0.953 & 0.882 & 0.703 & 0.267 & 0.584 & 0.746 & 0.826 \\\\<br/>& (0.008) & (0.006) & (0.002) & (0.001) & (0.017) & (0.060) & (0.004) & (0.009) & (0.003) \\\\<br/>\\text{SSL Alone} & 0.885 & 0.939 & 0.955 & 0.881 & 0.640 & 0.343 & 0.593 & 0.748 & 0.816 \\\\<br/>& (0.002) & (0.008) & (0.005) & (0.003) & (0.013) & (0.075) & (0.010) & (0.011) & (0.003) \\\\<br/>\\text{Re-label Alone} & 0.901 & 0.944 & 0.952 & 0.877 & 0.700 & 0.332 & 0.577 & 0.755 & 0.825 \\\\<br/>& (0.013) & (0.004) & (0.006) & (0.002) & (0.014) & (0.105) & (0.010) & (0.015) & (0.004) \\\\<br/>\\text{Thresh + SSL} & 0.885 & 0.959 & 0.943 & 0.887 & 0.732 & 0.529 & 0.592 & 0.790 & 0.833 \\\\<br/>& (0.018) & (0.002) & (0.008) & (0.005) & (0.014) & (0.057) & (0.005) & (0.009) & (0.004) \\\\<br/>\\text{Thresh + Re-label} & 0.905 & 0.961 & 0.952 & 0.883 & 0.748 & 0.236 & 0.600 & 0.755 & 0.841 \\\\<br/>& (0.011) & (0.002) & (0.006) & (0.005) & (0.023) & (0.085) & (0.006) & (0.013) & (0.005) \\\\<br/>\\text{SSL + Re-label} & 0.894 & 0.949 & 0.951 & 0.879 & 0.702 & 0.365 & 0.583 & 0.760 & 0.826 \\\\<br/>& (0.008) & (0.002) & (0.002) & (0.002) & (0.035) & (0.073) & (0.003) & (0.012) & (0.006) \\\\<br/>\\text{Thresh + SSL + Re-label} & 0.907 & 0.961 & 0.949 & 0.885 & 0.765 & 0.531 & 0.601 & 0.800 & 0.845 \\\\<br/>& (0.004) & (0.003) & (0.010) & (0.003) & (0.012) & (0.039) & (0.008) & (0.006) & (0.003) \\\\<br/>\\text{Entire Design Space} & 0.907 & 0.961 & 0.952 & 0.887 & 0.765 & 0.531 & 0.601 & 0.801 & 0.845 \\\\<br/>& (0.004) & (0.002) & (0.006) & (0.005) & (0.012) & (0.039) & (0.008) & (0.006) & (0.003) \\\\<br/>\\text{Fully supervised} & 0.932 & 0.976 & 0.967 & 0.918 & 0.966 & - & 0.894 & - & 0.943 \\\\<br/>& (0.005) & (0.001) & (0.013) & (0.006) & (0.004) & - & (0.012) & - & (0.003) \\\\<br/>\\hline<br/>\\end{array}<br/>$<br/>\t## Table 2. Axis Ablation for LM = Snorkel, DM = RoBERTa<br/>\t|IMDb|Yelp|AGNews|TREC|Spouse|Chem.|\n|Thresh Cov|0.901|0.949|0.881|0.702|0.365|0.593|\n|Thresh Cut|0.907|0.958|0.887|0.765|0.531|0.608|\n|GT (Cov)|0.906|0.961|0.884|0.753|0.531|0.593|\n\n## Table 3. Deeper Dive into the Thresholding Axis for DM = RoBERTa\n\nWe report the highest performance of a method that incorporates a given type of thresholding, selected by validation performance.\n\n## Figure 1. Measuring the Impact of Smaller |L| and Coverage Bias\n\nAs seen, when label noise is removed from the covered set of examples for GT (Cov), the performance drops &lt;2% compared to having all the clean labels for GT (Full). Note we cannot plot Spouse as it does not have clean training labels.\n\nLabel noise is the main gap on WS benchmarks. To measure the relative importance of the three data gaps, we compare the following models:\n\n- GT (Cov): the model trained on the clean labels for only covered inputs, removing gap (3) but retaining (1) and (2).\n- GT (Full): the model trained with a clean and fully labeled version of D, removing all gaps.\n\nGiven our hypothesis, we would expect these models to perform similarly on WRENCH benchmarks. Indeed, as shown in Figure 3, the largest gap between them is &lt;2 p.p.\n\nSSL helps more when coverage is lower. While SSL\u2019s ineffectiveness on existing benchmarks corresponds to label noise being the predominant data gap, we would ideally also show that SSL is more useful when the other two gaps are significant, i.e., when GT (Cov) performs markedly worse than GT (Full).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "Table 1. Performance Comparison", "md": "## Table 1. Performance Comparison"}, {"type": "table", "rows": [["Method", "IMDb", "Yelp", "Youtube", "AGNews", "TREC", "Spouse", "Chemprot", "Mean", "w/o Spouse"], ["Vanilla", "0.873", "0.919", "0.944", "0.870", "0.637", "0.273", "0.569", "0.726", "0.802"], ["Thresh Alone", "0.887", "0.948", "0.953", "0.882", "0.703", "0.267", "0.584", "0.746", "0.826"], ["$<br/>\\begin{array}{", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "}<br/>\\hline<br/>\\text{Method} & \\text{IMDb} & \\text{Yelp} & \\text{Youtube} & \\text{AGNews} & \\text{TREC} & \\text{Spouse} & \\text{Chemprot} & \\text{Mean} & \\text{w/o Spouse} \\\\<br/>\\hline<br/>\\text{Vanilla} & 0.873 & 0.919 & 0.944 & 0.870 & 0.637 & 0.273 & 0.569 & 0.726 & 0.802 \\\\<br/>& (0.001) & (0.009) & (0.007) & (0.003) & (0.010) & (0.074) & (0.001) & (0.011) & (0.003) \\\\<br/>\\text{Thresh Alone} & 0.887 & 0.948 & 0.953 & 0.882 & 0.703 & 0.267 & 0.584 & 0.746 & 0.826 \\\\<br/>& (0.008) & (0.006) & (0.002) & (0.001) & (0.017) & (0.060) & (0.004) & (0.009) & (0.003) \\\\<br/>\\text{SSL Alone} & 0.885 & 0.939 & 0.955 & 0.881 & 0.640 & 0.343 & 0.593 & 0.748 & 0.816 \\\\<br/>& (0.002) & (0.008) & (0.005) & (0.003) & (0.013) & (0.075) & (0.010) & (0.011) & (0.003) \\\\<br/>\\text{Re-label Alone} & 0.901 & 0.944 & 0.952 & 0.877 & 0.700 & 0.332 & 0.577 & 0.755 & 0.825 \\\\<br/>& (0.013) & (0.004) & (0.006) & (0.002) & (0.014) & (0.105) & (0.010) & (0.015) & (0.004) \\\\<br/>\\text{Thresh + SSL} & 0.885 & 0.959 & 0.943 & 0.887 & 0.732 & 0.529 & 0.592 & 0.790 & 0.833 \\\\<br/>& (0.018) & (0.002) & (0.008) & (0.005) & (0.014) & (0.057) & (0.005) & (0.009) & (0.004) \\\\<br/>\\text{Thresh + Re-label} & 0.905 & 0.961 & 0.952 & 0.883 & 0.748 & 0.236 & 0.600 & 0.755 & 0.841 \\\\<br/>& (0.011) & (0.002) & (0.006) & (0.005) & (0.023) & (0.085) & (0.006) & (0.013) & (0.005) \\\\<br/>\\text{SSL + Re-label} & 0.894 & 0.949 & 0.951 & 0.879 & 0.702 & 0.365 & 0.583 & 0.760 & 0.826 \\\\<br/>& (0.008) & (0.002) & (0.002) & (0.002) & (0.035) & (0.073) & (0.003) & (0.012) & (0.006) \\\\<br/>\\text{Thresh + SSL + Re-label} & 0.907 & 0.961 & 0.949 & 0.885 & 0.765 & 0.531 & 0.601 & 0.800 & 0.845 \\\\<br/>& (0.004) & (0.003) & (0.010) & (0.003) & (0.012) & (0.039) & (0.008) & (0.006) & (0.003) \\\\<br/>\\text{Entire Design Space} & 0.907 & 0.961 & 0.952 & 0.887 & 0.765 & 0.531 & 0.601 & 0.801 & 0.845 \\\\<br/>& (0.004) & (0.002) & (0.006) & (0.005) & (0.012) & (0.039) & (0.008) & (0.006) & (0.003) \\\\<br/>\\text{Fully supervised} & 0.932 & 0.976 & 0.967 & 0.918 & 0.966 & - & 0.894 & - & 0.943 \\\\<br/>& (0.005) & (0.001) & (0.013) & (0.006) & (0.004) & - & (0.012) & - & (0.003) \\\\<br/>\\hline<br/>\\end{array}<br/>$<br/>\t## Table 2. Axis Ablation for LM = Snorkel, DM = RoBERTa<br/>", "IMDb", "Yelp", "AGNews", "TREC", "Spouse", "Chem."], ["Thresh Cov", "0.901", "0.949", "0.881", "0.702", "0.365", "0.593"], ["Thresh Cut", "0.907", "0.958", "0.887", "0.765", "0.531", "0.608"], ["GT (Cov)", "0.906", "0.961", "0.884", "0.753", "0.531", "0.593"]], "md": "|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Mean|w/o Spouse|\n|---|---|---|---|---|---|---|---|---|---|\n|Vanilla|0.873|0.919|0.944|0.870|0.637|0.273|0.569|0.726|0.802|\n|Thresh Alone|0.887|0.948|0.953|0.882|0.703|0.267|0.584|0.746|0.826|\n|$<br/>\\begin{array}{|c|c|c|c|c|c|c|c|c|c|}<br/>\\hline<br/>\\text{Method} & \\text{IMDb} & \\text{Yelp} & \\text{Youtube} & \\text{AGNews} & \\text{TREC} & \\text{Spouse} & \\text{Chemprot} & \\text{Mean} & \\text{w/o Spouse} \\\\<br/>\\hline<br/>\\text{Vanilla} & 0.873 & 0.919 & 0.944 & 0.870 & 0.637 & 0.273 & 0.569 & 0.726 & 0.802 \\\\<br/>& (0.001) & (0.009) & (0.007) & (0.003) & (0.010) & (0.074) & (0.001) & (0.011) & (0.003) \\\\<br/>\\text{Thresh Alone} & 0.887 & 0.948 & 0.953 & 0.882 & 0.703 & 0.267 & 0.584 & 0.746 & 0.826 \\\\<br/>& (0.008) & (0.006) & (0.002) & (0.001) & (0.017) & (0.060) & (0.004) & (0.009) & (0.003) \\\\<br/>\\text{SSL Alone} & 0.885 & 0.939 & 0.955 & 0.881 & 0.640 & 0.343 & 0.593 & 0.748 & 0.816 \\\\<br/>& (0.002) & (0.008) & (0.005) & (0.003) & (0.013) & (0.075) & (0.010) & (0.011) & (0.003) \\\\<br/>\\text{Re-label Alone} & 0.901 & 0.944 & 0.952 & 0.877 & 0.700 & 0.332 & 0.577 & 0.755 & 0.825 \\\\<br/>& (0.013) & (0.004) & (0.006) & (0.002) & (0.014) & (0.105) & (0.010) & (0.015) & (0.004) \\\\<br/>\\text{Thresh + SSL} & 0.885 & 0.959 & 0.943 & 0.887 & 0.732 & 0.529 & 0.592 & 0.790 & 0.833 \\\\<br/>& (0.018) & (0.002) & (0.008) & (0.005) & (0.014) & (0.057) & (0.005) & (0.009) & (0.004) \\\\<br/>\\text{Thresh + Re-label} & 0.905 & 0.961 & 0.952 & 0.883 & 0.748 & 0.236 & 0.600 & 0.755 & 0.841 \\\\<br/>& (0.011) & (0.002) & (0.006) & (0.005) & (0.023) & (0.085) & (0.006) & (0.013) & (0.005) \\\\<br/>\\text{SSL + Re-label} & 0.894 & 0.949 & 0.951 & 0.879 & 0.702 & 0.365 & 0.583 & 0.760 & 0.826 \\\\<br/>& (0.008) & (0.002) & (0.002) & (0.002) & (0.035) & (0.073) & (0.003) & (0.012) & (0.006) \\\\<br/>\\text{Thresh + SSL + Re-label} & 0.907 & 0.961 & 0.949 & 0.885 & 0.765 & 0.531 & 0.601 & 0.800 & 0.845 \\\\<br/>& (0.004) & (0.003) & (0.010) & (0.003) & (0.012) & (0.039) & (0.008) & (0.006) & (0.003) \\\\<br/>\\text{Entire Design Space} & 0.907 & 0.961 & 0.952 & 0.887 & 0.765 & 0.531 & 0.601 & 0.801 & 0.845 \\\\<br/>& (0.004) & (0.002) & (0.006) & (0.005) & (0.012) & (0.039) & (0.008) & (0.006) & (0.003) \\\\<br/>\\text{Fully supervised} & 0.932 & 0.976 & 0.967 & 0.918 & 0.966 & - & 0.894 & - & 0.943 \\\\<br/>& (0.005) & (0.001) & (0.013) & (0.006) & (0.004) & - & (0.012) & - & (0.003) \\\\<br/>\\hline<br/>\\end{array}<br/>$<br/>\t## Table 2. Axis Ablation for LM = Snorkel, DM = RoBERTa<br/>\t|IMDb|Yelp|AGNews|TREC|Spouse|Chem.|\n|Thresh Cov|0.901|0.949|0.881|0.702|0.365|0.593|\n|Thresh Cut|0.907|0.958|0.887|0.765|0.531|0.608|\n|GT (Cov)|0.906|0.961|0.884|0.753|0.531|0.593|", "isPerfectTable": false, "csv": "\"Method\",\"IMDb\",\"Yelp\",\"Youtube\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\",\"Mean\",\"w/o Spouse\"\n\"Vanilla\",\"0.873\",\"0.919\",\"0.944\",\"0.870\",\"0.637\",\"0.273\",\"0.569\",\"0.726\",\"0.802\"\n\"Thresh Alone\",\"0.887\",\"0.948\",\"0.953\",\"0.882\",\"0.703\",\"0.267\",\"0.584\",\"0.746\",\"0.826\"\n\"$<br/>\\begin{array}{\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"}<br/>\\hline<br/>\\text{Method} & \\text{IMDb} & \\text{Yelp} & \\text{Youtube} & \\text{AGNews} & \\text{TREC} & \\text{Spouse} & \\text{Chemprot} & \\text{Mean} & \\text{w/o Spouse} \\\\<br/>\\hline<br/>\\text{Vanilla} & 0.873 & 0.919 & 0.944 & 0.870 & 0.637 & 0.273 & 0.569 & 0.726 & 0.802 \\\\<br/>& (0.001) & (0.009) & (0.007) & (0.003) & (0.010) & (0.074) & (0.001) & (0.011) & (0.003) \\\\<br/>\\text{Thresh Alone} & 0.887 & 0.948 & 0.953 & 0.882 & 0.703 & 0.267 & 0.584 & 0.746 & 0.826 \\\\<br/>& (0.008) & (0.006) & (0.002) & (0.001) & (0.017) & (0.060) & (0.004) & (0.009) & (0.003) \\\\<br/>\\text{SSL Alone} & 0.885 & 0.939 & 0.955 & 0.881 & 0.640 & 0.343 & 0.593 & 0.748 & 0.816 \\\\<br/>& (0.002) & (0.008) & (0.005) & (0.003) & (0.013) & (0.075) & (0.010) & (0.011) & (0.003) \\\\<br/>\\text{Re-label Alone} & 0.901 & 0.944 & 0.952 & 0.877 & 0.700 & 0.332 & 0.577 & 0.755 & 0.825 \\\\<br/>& (0.013) & (0.004) & (0.006) & (0.002) & (0.014) & (0.105) & (0.010) & (0.015) & (0.004) \\\\<br/>\\text{Thresh + SSL} & 0.885 & 0.959 & 0.943 & 0.887 & 0.732 & 0.529 & 0.592 & 0.790 & 0.833 \\\\<br/>& (0.018) & (0.002) & (0.008) & (0.005) & (0.014) & (0.057) & (0.005) & (0.009) & (0.004) \\\\<br/>\\text{Thresh + Re-label} & 0.905 & 0.961 & 0.952 & 0.883 & 0.748 & 0.236 & 0.600 & 0.755 & 0.841 \\\\<br/>& (0.011) & (0.002) & (0.006) & (0.005) & (0.023) & (0.085) & (0.006) & (0.013) & (0.005) \\\\<br/>\\text{SSL + Re-label} & 0.894 & 0.949 & 0.951 & 0.879 & 0.702 & 0.365 & 0.583 & 0.760 & 0.826 \\\\<br/>& (0.008) & (0.002) & (0.002) & (0.002) & (0.035) & (0.073) & (0.003) & (0.012) & (0.006) \\\\<br/>\\text{Thresh + SSL + Re-label} & 0.907 & 0.961 & 0.949 & 0.885 & 0.765 & 0.531 & 0.601 & 0.800 & 0.845 \\\\<br/>& (0.004) & (0.003) & (0.010) & (0.003) & (0.012) & (0.039) & (0.008) & (0.006) & (0.003) \\\\<br/>\\text{Entire Design Space} & 0.907 & 0.961 & 0.952 & 0.887 & 0.765 & 0.531 & 0.601 & 0.801 & 0.845 \\\\<br/>& (0.004) & (0.002) & (0.006) & (0.005) & (0.012) & (0.039) & (0.008) & (0.006) & (0.003) \\\\<br/>\\text{Fully supervised} & 0.932 & 0.976 & 0.967 & 0.918 & 0.966 & - & 0.894 & - & 0.943 \\\\<br/>& (0.005) & (0.001) & (0.013) & (0.006) & (0.004) & - & (0.012) & - & (0.003) \\\\<br/>\\hline<br/>\\end{array}<br/>$<br/>\t## Table 2. Axis Ablation for LM = Snorkel, DM = RoBERTa<br/>\",\"IMDb\",\"Yelp\",\"AGNews\",\"TREC\",\"Spouse\",\"Chem.\"\n\"Thresh Cov\",\"0.901\",\"0.949\",\"0.881\",\"0.702\",\"0.365\",\"0.593\"\n\"Thresh Cut\",\"0.907\",\"0.958\",\"0.887\",\"0.765\",\"0.531\",\"0.608\"\n\"GT (Cov)\",\"0.906\",\"0.961\",\"0.884\",\"0.753\",\"0.531\",\"0.593\""}, {"type": "heading", "lvl": 2, "value": "Table 3. Deeper Dive into the Thresholding Axis for DM = RoBERTa", "md": "## Table 3. Deeper Dive into the Thresholding Axis for DM = RoBERTa"}, {"type": "text", "value": "We report the highest performance of a method that incorporates a given type of thresholding, selected by validation performance.", "md": "We report the highest performance of a method that incorporates a given type of thresholding, selected by validation performance."}, {"type": "heading", "lvl": 2, "value": "Figure 1. Measuring the Impact of Smaller |L| and Coverage Bias", "md": "## Figure 1. Measuring the Impact of Smaller |L| and Coverage Bias"}, {"type": "text", "value": "As seen, when label noise is removed from the covered set of examples for GT (Cov), the performance drops &lt;2% compared to having all the clean labels for GT (Full). Note we cannot plot Spouse as it does not have clean training labels.\n\nLabel noise is the main gap on WS benchmarks. To measure the relative importance of the three data gaps, we compare the following models:\n\n- GT (Cov): the model trained on the clean labels for only covered inputs, removing gap (3) but retaining (1) and (2).\n- GT (Full): the model trained with a clean and fully labeled version of D, removing all gaps.\n\nGiven our hypothesis, we would expect these models to perform similarly on WRENCH benchmarks. Indeed, as shown in Figure 3, the largest gap between them is &lt;2 p.p.\n\nSSL helps more when coverage is lower. While SSL\u2019s ineffectiveness on existing benchmarks corresponds to label noise being the predominant data gap, we would ideally also show that SSL is more useful when the other two gaps are significant, i.e., when GT (Cov) performs markedly worse than GT (Full).", "md": "As seen, when label noise is removed from the covered set of examples for GT (Cov), the performance drops &lt;2% compared to having all the clean labels for GT (Full). Note we cannot plot Spouse as it does not have clean training labels.\n\nLabel noise is the main gap on WS benchmarks. To measure the relative importance of the three data gaps, we compare the following models:\n\n- GT (Cov): the model trained on the clean labels for only covered inputs, removing gap (3) but retaining (1) and (2).\n- GT (Full): the model trained with a clean and fully labeled version of D, removing all gaps.\n\nGiven our hypothesis, we would expect these models to perform similarly on WRENCH benchmarks. Indeed, as shown in Figure 3, the largest gap between them is &lt;2 p.p.\n\nSSL helps more when coverage is lower. While SSL\u2019s ineffectiveness on existing benchmarks corresponds to label noise being the predominant data gap, we would ideally also show that SSL is more useful when the other two gaps are significant, i.e., when GT (Cov) performs markedly worse than GT (Full)."}]}, {"page": 8, "text": "                                    Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n                     0.95           Semeval                0.9          Chemprot                0.90     Massive18 (Ours)            0.90      Banking77 (Ours)\n                     0.90                                                                       0.85                                 0.85\n                    Test Acc                               0.8                                                                       0.80\n                     0.85                                                                       0.80\n                     0.80                                                                       0.75                                 0.75\n                     0.75                                  0.7                                                                       0.70\n                     0.70                                  0.6                                  0.70                                 0.65\n                     0.65                                                                       0.65                                 0.60\n                     0.60                                  0.5                                  0.60                                 0.55\n                     0.55                                                                                                            0.50\n                        0.0   0.2   0.4    0.6   0.8   1.0    0.0   0.2   0.4   0.6    0.8   1.0   0.0   0.2    0.4   0.6   0.8   1.0    0.0   0.2   0.4    0.6   0.8  1.0\n                                   Coverage                              Coverage                             Coverage                              Coverage\n                                       1.0      Mushroom (Tab.)              1.0      Spambase (Tab.)             1.00 Phishingwebsites (Tab.)\n                                       0.9\n                                      Test Acc                               0.9                                  0.95\n                                       0.8\n                                       0.7                                   0.8                                  0.90\n                                       0.6\n                                       0.5                                   0.7                                  0.85\n                                         0.0    0.2   0.4   0.6    0.8   1.0   0.0    0.2   0.4    0.6   0.8   1.0    0.0   0.2   0.4    0.6   0.8    1.0\n                                                     Coverage                              Coverage                              Coverage\n                                      0.94             Imdb                 0.98              Yelp                0.92            Agnews\n                                      0.92                                  0.96                                  0.90\n                                     Test Acc                               0.94                                  0.88\n                                      0.90                                                                        0.86\n                                      0.88                                  0.92                                  0.84\n                                      0.86                                  0.90                                  0.82\n                                      0.84                                  0.88                                  0.80\n                                         0.0   0.2    0.4   0.6    0.8   1.0   0.0    0.2   0.4   0.6    0.8   1.0   0.0    0.2   0.4    0.6   0.8   1.0\n                                                    Coverage                               Coverage                              Coverage\n                                      Thresh+SSL                 Thresh+Re-label                  GT (Full)              GT (Cov)               Vanilla WS\nFigure 4. Impacts of coverage level on data gaps and the effectiveness of SSL. Plotting GT (Full) (gray-dashed) and GT (Cov) (blue), we\nmeasure the impacts of removing label noise across nested LF subsets. We also compare the effectiveness of Thresh + SSL (green) to\nThresh + Re-label (red). For datasets more impacted by coverage bias and limited size (larger gaps between dashed and blue lines), SSL\nadds more unique value. \u201c(Ours)\u201d refers to datsets we introduce. \u201c(Tab.)\u201d refers to tabular tasks.\nPhishingWebsites in a setup similar to that of Zhang et al.                                       is enough to consistently outperform \u201cThresh + Re-label\u201d at\n(2022b) (see Appendix D for details on all these datasets).                                       lower coverage levels. In contrast, in the bottom row, where\nFrom this analysis, we first see that smaller coverage levels                                     GT (Cov) drops in performance by <2 p.p., \u201cThresh + SSL\u201d\n(within the ranges we test) do not always cause GT (Cov)                                          continues to perform within errors of \u201cThresh + Re-label.\u201d\nto perform poorly. On some tasks (top two rows of Figure                                          Overall, this suggests that SSL can indeed be useful in WS\n4), including the three tabular datasets and our two new                                          settings that differ from those captured by standard bench-\nones, GT (Cov) performs significantly worse as coverage de-                                       marks. At lower coverages (i.e., <35%), SSL is consistently\ncreases.2 In contrast, on IMDb, Yelp, and AGNews (bottom                                          worth trying; potentially allowing users to reduce the num-\nrow of Figure 4), GT (Cov) surprisingly comes within 2%                                           ber of LFs they need to write in order to achieve a particular\nof GT (Full) even when coverage drops to 10-20%.                                                  target performance. On our tabular tasks, SSL even allows\nImportantly, the partitioning of datasets based on the perfor-                                    one to match having 40 LFs (highest coverage plotted) with\nmance of GT (Cov) also corresponds to the effectiveness of                                        at most 20 LFs (second lowest).\nusing SSL over not using it. For each LF set used, we run\nthe methods within a reduced version of our design space:                                         5. Conclusions\nwe allow for confidence thresholding and try both versions                                        We proposed a design space for combining SSL and WS,\nof self-training to perform SSL (i.e., by labeling points in U)                                   using it to contextualize and match the performance of state-\nor to re-label (i.e., by labeling points in L). For the tabular                                   of-the-art WS methods. We show that on existing WS bench-\ntasks, we also try VAT for the SSL technique because of its                                       marks, using the unlabeled data is surprisingly not essential.\neffectiveness for MLPs. We plot the best performing meth-                                         However, it can be more useful when training MLPs instead\nods for both \u201cThresh + SSL\u201d and \u201cThresh + Re-label\u201d in                                            of RoBERTa and when the LFs cover fewer examples. Some\nFigure 4. As shown in the top two rows, just \u201cThresh + SSL\u201d                                       future directions include developing: (1) heuristics for more\n     2In Appendix E, we show that coverage bias (and not limited                                  efficiently navigating our design space given a new task; (2)\nsize) is primarily responsible for these performance drops.                                       ways to compare data gaps without using clean labels.\n                                                                                             8", "md": "# Document\n\n## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n| |0.95|Semeval|0.9|Chemprot|0.90|Massive18 (Ours)|0.90|Banking77 (Ours)|\n|---|---|---|---|---|---|---|---|---|\n| |0.90| |0.85| |0.85| |0.85| |\n|Test Acc|0.8| |0.80| |0.80| |0.80| |\n|0.75|0.7| |0.70| |0.70| |0.70| |\n|0.65| |0.65| |0.65| |0.60| | |\n|0.60|0.5| |0.60| |0.55| |0.50| |\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|\n| |Coverage| |Coverage| |Coverage| |Coverage| |\n|1.0|Mushroom (Tab.)|1.0|Spambase (Tab.)|1.00|Phishingwebsites (Tab.)| | | |\n|0.9| | | | | | | | |\n|Test Acc|0.9| |0.95| | | | | |\n|0.8| |0.8| |0.90| | | | |\n|0.7| |0.7| |0.85| | | | |\n|0.6| |0.6| | | | | | |\n|0.5| |0.5| | | | | | |\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|\n| |Coverage| |Coverage| |Coverage| |Coverage| |\n|0.94|Imdb|0.98|Yelp|0.92|Agnews| | | |\n|0.92| |0.96| |0.90| | | | |\n|Test Acc|0.94| |0.88| | | | | |\n|0.90| |0.86| | | | | | |\n|0.88| |0.92| | | | | | |\n|0.86| |0.90| | | | | | |\n|0.84| |0.88| | | | | | |\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|\n| |Coverage| |Coverage| |Coverage| |Coverage| |\n\nFigure 4. Impacts of coverage level on data gaps and the effectiveness of SSL. Plotting GT (Full) (gray-dashed) and GT (Cov) (blue), we measure the impacts of removing label noise across nested LF subsets. We also compare the effectiveness of Thresh + SSL (green) to Thresh + Re-label (red). For datasets more impacted by coverage bias and limited size (larger gaps between dashed and blue lines), SSL adds more unique value. \"(Ours)\" refers to datasets we introduce. \"(Tab.)\" refers to tabular tasks.\n\nPhishingWebsites in a setup similar to that of Zhang et al. (2022b) (see Appendix D for details on all these datasets).\n\nFrom this analysis, we first see that smaller coverage levels (within the ranges we test) do not always cause GT (Cov) to perform poorly. On some tasks (top two rows of Figure 4), including the three tabular datasets and our two new ones, GT (Cov) performs significantly worse as coverage decreases.2 In contrast, on IMDb, Yelp, and AGNews (bottom row of Figure 4), GT (Cov) surprisingly comes within 2% of GT (Full) even when coverage drops to 10-20%.\n\nImportantly, the partitioning of datasets based on the performance of GT (Cov) also corresponds to the effectiveness of using SSL over not using it. For each LF set used, we run the methods within a reduced version of our design space: we allow for confidence thresholding and try both versions of self-training to perform SSL (i.e., by labeling points in U) or to re-label (i.e., by labeling points in L). For the tabular tasks, we also try VAT for the SSL technique because of its effectiveness for MLPs. We plot the best performing methods for both \"Thresh + SSL\" and \"Thresh + Re-label\" in Figure 4. As shown in the top two rows, just \"Thresh + SSL\".\n\n2In Appendix E, we show that coverage bias (and not limited size) is primarily responsible for these performance drops.\n\n### 5. Conclusions\n\nWe proposed a design space for combining SSL and WS, using it to contextualize and match the performance of state-of-the-art WS methods. We show that on existing WS benchmarks, using the unlabeled data is surprisingly not essential. However, it can be more useful when training MLPs instead of RoBERTa and when the LFs cover fewer examples. Some future directions include developing: (1) heuristics for more efficiently navigating our design space given a new task; (2) ways to compare data gaps without using clean labels.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 2, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "table", "rows": [["", "0.95", "Semeval", "0.9", "Chemprot", "0.90", "Massive18 (Ours)", "0.90", "Banking77 (Ours)"], ["", "0.90", "", "0.85", "", "0.85", "", "0.85", ""], ["Test Acc", "0.8", "", "0.80", "", "0.80", "", "0.80", ""], ["0.75", "0.7", "", "0.70", "", "0.70", "", "0.70", ""], ["0.65", "", "0.65", "", "0.65", "", "0.60", "", ""], ["0.60", "0.5", "", "0.60", "", "0.55", "", "0.50", ""], ["", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0"], ["", "Coverage", "", "Coverage", "", "Coverage", "", "Coverage", ""], ["1.0", "Mushroom (Tab.)", "1.0", "Spambase (Tab.)", "1.00", "Phishingwebsites (Tab.)", "", "", ""], ["0.9", "", "", "", "", "", "", "", ""], ["Test Acc", "0.9", "", "0.95", "", "", "", "", ""], ["0.8", "", "0.8", "", "0.90", "", "", "", ""], ["0.7", "", "0.7", "", "0.85", "", "", "", ""], ["0.6", "", "0.6", "", "", "", "", "", ""], ["0.5", "", "0.5", "", "", "", "", "", ""], ["", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0"], ["", "Coverage", "", "Coverage", "", "Coverage", "", "Coverage", ""], ["0.94", "Imdb", "0.98", "Yelp", "0.92", "Agnews", "", "", ""], ["0.92", "", "0.96", "", "0.90", "", "", "", ""], ["Test Acc", "0.94", "", "0.88", "", "", "", "", ""], ["0.90", "", "0.86", "", "", "", "", "", ""], ["0.88", "", "0.92", "", "", "", "", "", ""], ["0.86", "", "0.90", "", "", "", "", "", ""], ["0.84", "", "0.88", "", "", "", "", "", ""], ["", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0"], ["", "Coverage", "", "Coverage", "", "Coverage", "", "Coverage", ""]], "md": "| |0.95|Semeval|0.9|Chemprot|0.90|Massive18 (Ours)|0.90|Banking77 (Ours)|\n|---|---|---|---|---|---|---|---|---|\n| |0.90| |0.85| |0.85| |0.85| |\n|Test Acc|0.8| |0.80| |0.80| |0.80| |\n|0.75|0.7| |0.70| |0.70| |0.70| |\n|0.65| |0.65| |0.65| |0.60| | |\n|0.60|0.5| |0.60| |0.55| |0.50| |\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|\n| |Coverage| |Coverage| |Coverage| |Coverage| |\n|1.0|Mushroom (Tab.)|1.0|Spambase (Tab.)|1.00|Phishingwebsites (Tab.)| | | |\n|0.9| | | | | | | | |\n|Test Acc|0.9| |0.95| | | | | |\n|0.8| |0.8| |0.90| | | | |\n|0.7| |0.7| |0.85| | | | |\n|0.6| |0.6| | | | | | |\n|0.5| |0.5| | | | | | |\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|\n| |Coverage| |Coverage| |Coverage| |Coverage| |\n|0.94|Imdb|0.98|Yelp|0.92|Agnews| | | |\n|0.92| |0.96| |0.90| | | | |\n|Test Acc|0.94| |0.88| | | | | |\n|0.90| |0.86| | | | | | |\n|0.88| |0.92| | | | | | |\n|0.86| |0.90| | | | | | |\n|0.84| |0.88| | | | | | |\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|\n| |Coverage| |Coverage| |Coverage| |Coverage| |", "isPerfectTable": false, "csv": "\"\",\"0.95\",\"Semeval\",\"0.9\",\"Chemprot\",\"0.90\",\"Massive18 (Ours)\",\"0.90\",\"Banking77 (Ours)\"\n\"\",\"0.90\",\"\",\"0.85\",\"\",\"0.85\",\"\",\"0.85\",\"\"\n\"Test Acc\",\"0.8\",\"\",\"0.80\",\"\",\"0.80\",\"\",\"0.80\",\"\"\n\"0.75\",\"0.7\",\"\",\"0.70\",\"\",\"0.70\",\"\",\"0.70\",\"\"\n\"0.65\",\"\",\"0.65\",\"\",\"0.65\",\"\",\"0.60\",\"\",\"\"\n\"0.60\",\"0.5\",\"\",\"0.60\",\"\",\"0.55\",\"\",\"0.50\",\"\"\n\"\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\"\n\"\",\"Coverage\",\"\",\"Coverage\",\"\",\"Coverage\",\"\",\"Coverage\",\"\"\n\"1.0\",\"Mushroom (Tab.)\",\"1.0\",\"Spambase (Tab.)\",\"1.00\",\"Phishingwebsites (Tab.)\",\"\",\"\",\"\"\n\"0.9\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"\n\"Test Acc\",\"0.9\",\"\",\"0.95\",\"\",\"\",\"\",\"\",\"\"\n\"0.8\",\"\",\"0.8\",\"\",\"0.90\",\"\",\"\",\"\",\"\"\n\"0.7\",\"\",\"0.7\",\"\",\"0.85\",\"\",\"\",\"\",\"\"\n\"0.6\",\"\",\"0.6\",\"\",\"\",\"\",\"\",\"\",\"\"\n\"0.5\",\"\",\"0.5\",\"\",\"\",\"\",\"\",\"\",\"\"\n\"\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\"\n\"\",\"Coverage\",\"\",\"Coverage\",\"\",\"Coverage\",\"\",\"Coverage\",\"\"\n\"0.94\",\"Imdb\",\"0.98\",\"Yelp\",\"0.92\",\"Agnews\",\"\",\"\",\"\"\n\"0.92\",\"\",\"0.96\",\"\",\"0.90\",\"\",\"\",\"\",\"\"\n\"Test Acc\",\"0.94\",\"\",\"0.88\",\"\",\"\",\"\",\"\",\"\"\n\"0.90\",\"\",\"0.86\",\"\",\"\",\"\",\"\",\"\",\"\"\n\"0.88\",\"\",\"0.92\",\"\",\"\",\"\",\"\",\"\",\"\"\n\"0.86\",\"\",\"0.90\",\"\",\"\",\"\",\"\",\"\",\"\"\n\"0.84\",\"\",\"0.88\",\"\",\"\",\"\",\"\",\"\",\"\"\n\"\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\"\n\"\",\"Coverage\",\"\",\"Coverage\",\"\",\"Coverage\",\"\",\"Coverage\",\"\""}, {"type": "text", "value": "Figure 4. Impacts of coverage level on data gaps and the effectiveness of SSL. Plotting GT (Full) (gray-dashed) and GT (Cov) (blue), we measure the impacts of removing label noise across nested LF subsets. We also compare the effectiveness of Thresh + SSL (green) to Thresh + Re-label (red). For datasets more impacted by coverage bias and limited size (larger gaps between dashed and blue lines), SSL adds more unique value. \"(Ours)\" refers to datasets we introduce. \"(Tab.)\" refers to tabular tasks.\n\nPhishingWebsites in a setup similar to that of Zhang et al. (2022b) (see Appendix D for details on all these datasets).\n\nFrom this analysis, we first see that smaller coverage levels (within the ranges we test) do not always cause GT (Cov) to perform poorly. On some tasks (top two rows of Figure 4), including the three tabular datasets and our two new ones, GT (Cov) performs significantly worse as coverage decreases.2 In contrast, on IMDb, Yelp, and AGNews (bottom row of Figure 4), GT (Cov) surprisingly comes within 2% of GT (Full) even when coverage drops to 10-20%.\n\nImportantly, the partitioning of datasets based on the performance of GT (Cov) also corresponds to the effectiveness of using SSL over not using it. For each LF set used, we run the methods within a reduced version of our design space: we allow for confidence thresholding and try both versions of self-training to perform SSL (i.e., by labeling points in U) or to re-label (i.e., by labeling points in L). For the tabular tasks, we also try VAT for the SSL technique because of its effectiveness for MLPs. We plot the best performing methods for both \"Thresh + SSL\" and \"Thresh + Re-label\" in Figure 4. As shown in the top two rows, just \"Thresh + SSL\".\n\n2In Appendix E, we show that coverage bias (and not limited size) is primarily responsible for these performance drops.", "md": "Figure 4. Impacts of coverage level on data gaps and the effectiveness of SSL. Plotting GT (Full) (gray-dashed) and GT (Cov) (blue), we measure the impacts of removing label noise across nested LF subsets. We also compare the effectiveness of Thresh + SSL (green) to Thresh + Re-label (red). For datasets more impacted by coverage bias and limited size (larger gaps between dashed and blue lines), SSL adds more unique value. \"(Ours)\" refers to datasets we introduce. \"(Tab.)\" refers to tabular tasks.\n\nPhishingWebsites in a setup similar to that of Zhang et al. (2022b) (see Appendix D for details on all these datasets).\n\nFrom this analysis, we first see that smaller coverage levels (within the ranges we test) do not always cause GT (Cov) to perform poorly. On some tasks (top two rows of Figure 4), including the three tabular datasets and our two new ones, GT (Cov) performs significantly worse as coverage decreases.2 In contrast, on IMDb, Yelp, and AGNews (bottom row of Figure 4), GT (Cov) surprisingly comes within 2% of GT (Full) even when coverage drops to 10-20%.\n\nImportantly, the partitioning of datasets based on the performance of GT (Cov) also corresponds to the effectiveness of using SSL over not using it. For each LF set used, we run the methods within a reduced version of our design space: we allow for confidence thresholding and try both versions of self-training to perform SSL (i.e., by labeling points in U) or to re-label (i.e., by labeling points in L). For the tabular tasks, we also try VAT for the SSL technique because of its effectiveness for MLPs. We plot the best performing methods for both \"Thresh + SSL\" and \"Thresh + Re-label\" in Figure 4. As shown in the top two rows, just \"Thresh + SSL\".\n\n2In Appendix E, we show that coverage bias (and not limited size) is primarily responsible for these performance drops."}, {"type": "heading", "lvl": 3, "value": "5. Conclusions", "md": "### 5. Conclusions"}, {"type": "text", "value": "We proposed a design space for combining SSL and WS, using it to contextualize and match the performance of state-of-the-art WS methods. We show that on existing WS benchmarks, using the unlabeled data is surprisingly not essential. However, it can be more useful when training MLPs instead of RoBERTa and when the LFs cover fewer examples. Some future directions include developing: (1) heuristics for more efficiently navigating our design space given a new task; (2) ways to compare data gaps without using clean labels.", "md": "We proposed a design space for combining SSL and WS, using it to contextualize and match the performance of state-of-the-art WS methods. We show that on existing WS benchmarks, using the unlabeled data is surprisingly not essential. However, it can be more useful when training MLPs instead of RoBERTa and when the LFs cover fewer examples. Some future directions include developing: (1) heuristics for more efficiently navigating our design space given a new task; (2) ways to compare data gaps without using clean labels."}]}, {"page": 9, "text": "                         Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nReferences                                                             W., Tur, G., and Natarajan, P. Massive: A 1m-example\nAwasthi, A., Ghosh, S., Goyal, R., and Sarawagi, S. Learn-             multilingual natural language understanding dataset with\n   ing from rules generalizing labeled exemplars. In In-               51 typologically-diverse languages, 2022. URL https:\n   ternational Conference on Learning Representations,                 //doi.org/10.48550/arXiv.2204.08582.\n   2020. URL https://openreview.net/forum?                          Gao, C., Goswami, M., Chen, J., and Dubrawski, A. Clas-\n   id=SkeuexBtDr.                                                      sifying unstructured clinical notes via automatic weak\nBoecking, B. and Dubrawski, A. Pairwise feedback for data              supervision. In Proceedings of the 7th Machine Learning\n   programming. In Proceedings of NeurIPS \u201919 Workshop                 for Healthcare Conference, volume 182 of Proceedings\n   on Learning with Rich Experience (LIRE \u201919), December               of Machine Learning Research, pp. 673\u2013690. PMLR, 05\u2013\n   2019.                                                               06 Aug 2022. URL https://proceedings.mlr.\n                                                                       press/v182/gao22a.html.\nC. Rosenberg, M. H. and Schneiderman, H.                 Semi-      Grandvalet, Y. and Bengio, Y. Semi-supervised learning\n   supervised learning by entropy minimization. In Semi-               by entropy minimization.         In Advances in Neural\n   Supervised Self-Training of Object Detection Models,                Information Processing Systems, volume 17. MIT\n   2005.                                                               Press,   2004.       URL     https://proceedings.\nCachay, S., Boecking, B., and Dubrawski, A.               End-         neurips.cc/paper/2004/file/\n   to-end weak supervision.           In Advances in Neu-              96f2b50b5d3613adf9c27049b2a888c7-Paper.\n   ral  Information     Processing    Systems,    volume    34,        pdf.\n   2021.     URL https://proceedings.neurips.                       Karamanolakis, G., Mukherjee, S., Zheng, G., and Awadal-\n   cc/paper_files/paper/2021/file/                                     lah, A. H. Self-training with weak supervision. In Pro-\n   0e674a918ebca3f78bfe02e2f387689d-Paper.                             ceedings of the 2021 Conference of the North American\n   pdf.                                                                Chapter of the Association for Computational Linguistics:\nCasanueva, I., Tem\u02c7   cinas, T., Gerz, D., Henderson, M.,              Human Language Technologies, pp. 845\u2013863, Online,\n   and Vuli\u00b4 c, I. Efficient intent detection with dual sen-           June 2021. Association for Computational Linguistics.\n   tence encoders.      In Proceedings of the 2nd Work-                doi: 10.18653/v1/2021.naacl-main.66. URL https:\n   shop on Natural Language Processing for Conversa-                   //aclanthology.org/2021.naacl-main.66.\n   tional AI, pp. 38\u201345, Online, July 2020. Association             Koco\u00b4 n, J., Cichecki, I., Kaszyca, O., Kochanek, M.,\n   for Computational Linguistics. doi: 10.18653/v1/2020.               Szyd\u0142o, D., Baran, J., Bielaniewicz, J., Gruza, M.,\n   nlp4convai-1.5.      URL https://aclanthology.                      Janz, A., Kanclerz, K., Koco\u00b4       n, A., Koptyra, B.,\n   org/2020.nlp4convai-1.5.                                            Mieleszczenko-Kowszewicz, W., Mi\u0142kowski, P., Oleksy,\nChen, M., Cohen-Wang, B., Mussmann, S., Sala, F.,                      M., Piasecki, M., Radli\u00b4 nski, , Wojtasik, K., Wo\u00b4zniak, S.,\n   and Re, C.       Comparing the value of labeled and                 and Kazienko, P. ChatGPT: Jack of all trades, master of\n   unlabeled data in method-of-moments latent variable                 none. Information Fusion, 99:101861, 2023. ISSN 1566-\n   estimation.     In Proceedings of The 24th Interna-                 2535. doi: https://doi.org/10.1016/j.inffus.2023.101861.\n   tional Conference on Artificial Intelligence and Statis-            URL         https://www.sciencedirect.com/\n   tics, volume 130 of Proceedings of Machine Learn-                   science/article/pii/S156625352300177X.\n   ing Research, pp. 3286\u20133294. PMLR, 13\u201315 Apr                     Kong, K., Lee, J., Kwak, Y., Kang, M., Kim, S. G.,\n   2021. URL https://proceedings.mlr.press/                            and Song, W.-J. Recycling: Semi-supervised learning\n   v130/chen21g.html.                                                  with noisy labels in deep neural networks. IEEE Ac-\nDing, Y., Wang, L., Fan, D., and Gong, B.             A semi-          cess, 7:66998\u201367005, 2019.        doi: 10.1109/ACCESS.\n   supervised two-stage approach to learning from noisy                2019.2918794. URL https://ieeexplore.ieee.\n   labels.   In 2018 IEEE Winter Conference on Appli-                  org/document/8721656.\n   cations of Computer Vision (WACV), pp. 1215\u20131224,                Laine, S. and Aila, T.      Temporal ensembling for semi-\n   Los Alamitos, CA, USA, mar 2018. IEEE Computer                      supervised learning.     In International Conference on\n   Society.     doi:   10.1109/WACV.2018.00138.           URL          Learning Representations, 2017.          URL https://\n   https://doi.ieeecomputersociety.org/                                openreview.net/forum?id=BJ6oOfqge.\n   10.1109/WACV.2018.00138.                                         Lang, H., Vijayaraghavan, A., and Sontag, D. Training\nFitzGerald, J., Hench, C., Peris, C., Mackie, S., Rottmann,            subset selection for weak supervision.        In Advances\n   K., Sanchez, A., Nash, A., Urbach, L., Kakarala, V.,                in  Neural    Information     Processing    Systems,    vol-\n   Singh, R., Ranganath, S., Crist, L., Britan, M., Leeuwis,           ume 35, pp. 16023\u201316036. Curran Associates, Inc.,\n                                                                 9", "md": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nReferences\n\n- Awasthi, A., Ghosh, S., Goyal, R., and Sarawagi, S. Learning from rules generalizing labeled exemplars. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=SkeuexBtDr.\n- Boecking, B. and Dubrawski, A. Pairwise feedback for data programming. In Proceedings of NeurIPS \u201919 Workshop on Learning with Rich Experience (LIRE \u201919), December 2019.\n- C. Rosenberg, M. H. and Schneiderman, H. Semi-supervised learning by entropy minimization. In Semi-Supervised Self-Training of Object Detection Models, 2005.\n- Cachay, S., Boecking, B., and Dubrawski, A. End-to-end weak supervision. In Advances in Neural Information Processing Systems, volume 34, 2021. URL https://proceedings.neurips.cc/paper_files/paper/2021/file/0e674a918ebca3f78bfe02e2f387689d-Paper.pdf.\n- Casanueva, I., Tem\u02c7cinas, T., Gerz, D., Henderson, M., and Vuli\u00b4c, I. Efficient intent detection with dual sentence encoders. In Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, July 2020. URL https://aclanthology.org/2020.nlp4convai-1.5.\n- Chen, M., Cohen-Wang, B., Mussmann, S., Sala, F., and Re, C. Comparing the value of labeled and unlabeled data in method-of-moments latent variable estimation. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, 2021. URL https://proceedings.mlr.press/v130/chen21g.html.\n- Ding, Y., Wang, L., Fan, D., and Gong, B. A semi-supervised two-stage approach to learning from noisy labels. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), March 2018. URL https://doi.ieeecomputersociety.org/10.1109/WACV.2018.00138.\n- FitzGerald, J., Hench, C., Peris, C., Mackie, S., Rottmann, K., Sanchez, A., Nash, A., Urbach, L., Kakarala, V., Singh, R., Ranganath, S., Crist, L., Britan, M., Leeuwis, A. ChatGPT: Jack of all trades, master of none. Information Fusion, 2023. ISSN 1566-2535. doi: https://doi.org/10.1016/j.inffus.2023.101861.\n- Kong, K., Lee, J., Kwak, Y., Kang, M., Kim, S. G., and Song, W.-J. Recycling: Semi-supervised learning with noisy labels in deep neural networks. IEEE Access, 2019. doi: 10.1109/ACCESS.2019.2918794. URL https://ieeexplore.ieee.org/document/8721656.\n- Laine, S. and Aila, T. Temporal ensembling for semi-supervised learning. In International Conference on Learning Representations, 2017. URL https://openreview.net/forum?id=BJ6oOfqge.\n- Lang, H., Vijayaraghavan, A., and Sontag, D. Training subset selection for weak supervision. In Advances in Neural Information Processing Systems, volume 35, 2021.", "images": [], "items": [{"type": "text", "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nReferences\n\n- Awasthi, A., Ghosh, S., Goyal, R., and Sarawagi, S. Learning from rules generalizing labeled exemplars. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=SkeuexBtDr.\n- Boecking, B. and Dubrawski, A. Pairwise feedback for data programming. In Proceedings of NeurIPS \u201919 Workshop on Learning with Rich Experience (LIRE \u201919), December 2019.\n- C. Rosenberg, M. H. and Schneiderman, H. Semi-supervised learning by entropy minimization. In Semi-Supervised Self-Training of Object Detection Models, 2005.\n- Cachay, S., Boecking, B., and Dubrawski, A. End-to-end weak supervision. In Advances in Neural Information Processing Systems, volume 34, 2021. URL https://proceedings.neurips.cc/paper_files/paper/2021/file/0e674a918ebca3f78bfe02e2f387689d-Paper.pdf.\n- Casanueva, I., Tem\u02c7cinas, T., Gerz, D., Henderson, M., and Vuli\u00b4c, I. Efficient intent detection with dual sentence encoders. In Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, July 2020. URL https://aclanthology.org/2020.nlp4convai-1.5.\n- Chen, M., Cohen-Wang, B., Mussmann, S., Sala, F., and Re, C. Comparing the value of labeled and unlabeled data in method-of-moments latent variable estimation. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, 2021. URL https://proceedings.mlr.press/v130/chen21g.html.\n- Ding, Y., Wang, L., Fan, D., and Gong, B. A semi-supervised two-stage approach to learning from noisy labels. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), March 2018. URL https://doi.ieeecomputersociety.org/10.1109/WACV.2018.00138.\n- FitzGerald, J., Hench, C., Peris, C., Mackie, S., Rottmann, K., Sanchez, A., Nash, A., Urbach, L., Kakarala, V., Singh, R., Ranganath, S., Crist, L., Britan, M., Leeuwis, A. ChatGPT: Jack of all trades, master of none. Information Fusion, 2023. ISSN 1566-2535. doi: https://doi.org/10.1016/j.inffus.2023.101861.\n- Kong, K., Lee, J., Kwak, Y., Kang, M., Kim, S. G., and Song, W.-J. Recycling: Semi-supervised learning with noisy labels in deep neural networks. IEEE Access, 2019. doi: 10.1109/ACCESS.2019.2918794. URL https://ieeexplore.ieee.org/document/8721656.\n- Laine, S. and Aila, T. Temporal ensembling for semi-supervised learning. In International Conference on Learning Representations, 2017. URL https://openreview.net/forum?id=BJ6oOfqge.\n- Lang, H., Vijayaraghavan, A., and Sontag, D. Training subset selection for weak supervision. In Advances in Neural Information Processing Systems, volume 35, 2021.", "md": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nReferences\n\n- Awasthi, A., Ghosh, S., Goyal, R., and Sarawagi, S. Learning from rules generalizing labeled exemplars. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=SkeuexBtDr.\n- Boecking, B. and Dubrawski, A. Pairwise feedback for data programming. In Proceedings of NeurIPS \u201919 Workshop on Learning with Rich Experience (LIRE \u201919), December 2019.\n- C. Rosenberg, M. H. and Schneiderman, H. Semi-supervised learning by entropy minimization. In Semi-Supervised Self-Training of Object Detection Models, 2005.\n- Cachay, S., Boecking, B., and Dubrawski, A. End-to-end weak supervision. In Advances in Neural Information Processing Systems, volume 34, 2021. URL https://proceedings.neurips.cc/paper_files/paper/2021/file/0e674a918ebca3f78bfe02e2f387689d-Paper.pdf.\n- Casanueva, I., Tem\u02c7cinas, T., Gerz, D., Henderson, M., and Vuli\u00b4c, I. Efficient intent detection with dual sentence encoders. In Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, July 2020. URL https://aclanthology.org/2020.nlp4convai-1.5.\n- Chen, M., Cohen-Wang, B., Mussmann, S., Sala, F., and Re, C. Comparing the value of labeled and unlabeled data in method-of-moments latent variable estimation. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, 2021. URL https://proceedings.mlr.press/v130/chen21g.html.\n- Ding, Y., Wang, L., Fan, D., and Gong, B. A semi-supervised two-stage approach to learning from noisy labels. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), March 2018. URL https://doi.ieeecomputersociety.org/10.1109/WACV.2018.00138.\n- FitzGerald, J., Hench, C., Peris, C., Mackie, S., Rottmann, K., Sanchez, A., Nash, A., Urbach, L., Kakarala, V., Singh, R., Ranganath, S., Crist, L., Britan, M., Leeuwis, A. ChatGPT: Jack of all trades, master of none. Information Fusion, 2023. ISSN 1566-2535. doi: https://doi.org/10.1016/j.inffus.2023.101861.\n- Kong, K., Lee, J., Kwak, Y., Kang, M., Kim, S. G., and Song, W.-J. Recycling: Semi-supervised learning with noisy labels in deep neural networks. IEEE Access, 2019. doi: 10.1109/ACCESS.2019.2918794. URL https://ieeexplore.ieee.org/document/8721656.\n- Laine, S. and Aila, T. Temporal ensembling for semi-supervised learning. In International Conference on Learning Representations, 2017. URL https://openreview.net/forum?id=BJ6oOfqge.\n- Lang, H., Vijayaraghavan, A., and Sontag, D. Training subset selection for weak supervision. In Advances in Neural Information Processing Systems, volume 35, 2021."}]}, {"page": 10, "text": "                         Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n   2022.    URL https://proceedings.neurips.                          Ratner, A., Hancock, B., Dunnmon, J., Sala, F., Pandey,\n   cc/paper_files/paper/2022/file/                                      S., and R\u00b4   e, C.       Training complex models with\n   66720ca4e5a09ff83b55a117a6b2a86c-Paper-Conference.                   multi-task weak supervision.           Proceedings of the\n   pdf.                                                                 AAAI Conference on Artificial Intelligence, 33(01):\nLee, D. The simple and efficient semi-supervised learning               4763\u20134771, Jul. 2019.           doi:   10.1609/aaai.v33i01.\n   method for deep neural networks. In ICML Workshop on                 33014763. URL https://ojs.aaai.org/index.\n   Challenges in Representation Learning, 2013.                         php/AAAI/article/view/4403.\nLi, J., Socher, R., and Hoi, S. C.         Dividemix: Learn-          Ratner, A. J., De Sa, C. M., Wu, S., Selsam, D., and\n   ing with noisy labels as semi-supervised learning. In                R\u00b4e, C.    Data programming: Creating large training\n   International Conference on Learning Representations,                sets, quickly. In Advances in Neural Information Pro-\n   2020. URL https://openreview.net/forum?                              cessing    Systems,    volume     29.   Curran    Associates,\n   id=HJgExaVtwr.                                                       Inc.,    2016.        URL     https://proceedings.\n                                                                        neurips.cc/paper/2016/file/\nMaheshwari, A., Chatterjee, O., Killamsetty, K., Iyer,                  6709e8d64a5f47269ed5cea9f625f7ab-Paper.\n   R. K., and Ramakrishnan, G.            Data programming              pdf.\n   using semi-supervision and subset selection.           CoRR,\n   abs/2008.09887, 2020. URL https://arxiv.org/                       Ren, W., Li, Y., Su, H., Kartchner, D., Mitchell, C.,\n   abs/2008.09887.                                                      and Zhang, C.          Denoising multi-source weak su-\n                                                                        pervision for neural text classification.            In Find-\nMazzetto, A., Cousins, C., Sam, D., Bach, S. H., and Up-                ings   of   the   Association    for   Computational      Lin-\n   fal, E.   Adversarial multi class learning under weak                guistics:    EMNLP 2020,         pp. 3739\u20133754,       Online,\n   supervision with performance guarantees.             In Pro-         November 2020. Association for Computational Lin-\n   ceedings of the 38th International Conference on Ma-                 guistics.       doi:    10.18653/v1/2020.findings-emnlp.\n   chine Learning, volume 139 of Proceedings of Ma-                     334. URL https://aclanthology.org/2020.\n   chine Learning Research, pp. 7534\u20137543. PMLR, 18\u2013                    findings-emnlp.334.\n   24 Jul 2021a. URL https://proceedings.mlr.\n   press/v139/mazzetto21a.html.                                       Tarvainen, A. and Valpola, H.             Mean teachers are\nMazzetto, A., Sam, D., Park, A., Upfal, E., and Bach, S.                better role models:         Weight-averaged consistency\n   Semi-supervised aggregation of dependent weak supervi-               targets    improve     semi-supervised       deep    learning\n   sion sources with performance guarantees. In Proceed-                results.     In Advances in Neural Information Pro-\n   ings of The 24th International Conference on Artificial              cessing    Systems,    volume     30.   Curran    Associates,\n   Intelligence and Statistics, volume 130 of Proceedings of            Inc.,    2017.        URL     https://proceedings.\n  Machine Learning Research, pp. 3196\u20133204. PMLR, 13\u2013                   neurips.cc/paper/2017/file/\n  15 Apr 2021b. URL https://proceedings.mlr.                            68053af2923e00204c3ca7c6a3150cf7-Paper.\n   press/v130/mazzetto21a.html.                                         pdf.\nMiyato, T., Maeda, S.-i., Koyama, M., and Ishii, S. Vir-              Wei, J., Zhu, Z., Cheng, H., Liu, T., Niu, G., and Liu, Y.\n   tual adversarial training: A regularization method for               Learning with noisy labels revisited: A study using real-\n   supervised and semi-supervised learning, 2017. URL                   world human annotations. In International Conference\n   https://arxiv.org/abs/1704.03976.                                    on Learning Representations, 2022. URL https://\n                                                                        openreview.net/forum?id=TBWA6PLJZQm.\nOliver, A., Odena, A., Raffel, C. A., Cubuk, E. D.,\n   and Goodfellow, I.         Realistic evaluation of deep            Yu, Y., Zuo, S., Jiang, H., Ren, W., Zhao, T., and Zhang,\n   semi-supervised learning algorithms.           In Advances           C. Fine-tuning pre-trained language model with weak\n   in  Neural    Information     Processing     Systems,     vol-       supervision: A contrastive-regularized self-training ap-\n   ume 31, 2018.         URL https://proceedings.                       proach. In Proceedings of the 2021 Conference of the\n   neurips.cc/paper/2018/file/                                          North American Chapter of the Association for Compu-\n   c1fea270c48e8079d8ddf7d06d26ab52-Paper.                              tational Linguistics: Human Language Technologies, pp.\n   pdf.                                                                 1063\u20131077, 2021. URL https://aclanthology.\n                                                                        org/2021.naacl-main.84.pdf.\nPukdee, R., Sam, D., Ravikumar, P. K., and Balcan, N. Label\n   propagation with weak supervision.         In The Eleventh         Zhang, J., Yu, Y., Li, Y., Wang, Y., Yang, Y., Yang, M.,\n   International Conference on Learning Representations,                and Ratner, A. WRENCH: A comprehensive benchmark\n   2023. URL https://openreview.net/forum?                              for weak supervision. In Thirty-fifth Conference on Neu-\n   id=aCuFa-RRqtI.                                                      ral Information Processing Systems Datasets and Bench-\n                                                                  10", "md": "## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nLee, D. The simple and efficient semi-supervised learning method for deep neural networks. In ICML Workshop on Challenges in Representation Learning, 2013.\n\nLi, J., Socher, R., and Hoi, S. C. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HJgExaVtwr.\n\nMaheshwari, A., Chatterjee, O., Killamsetty, K., Iyer, R. K., and Ramakrishnan, G. Data programming using semi-supervision and subset selection. CoRR, abs/2008.09887, 2020. URL https://arxiv.org/abs/2008.09887.\n\nMazzetto, A., Cousins, C., Sam, D., Bach, S. H., and Upfal, E. Adversarial multi class learning under weak supervision with performance guarantees. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 7534\u20137543. PMLR, 18\u201324 Jul 2021a. URL https://proceedings.mlr.press/v139/mazzetto21a.html.\n\nMazzetto, A., Sam, D., Park, A., Upfal, E., and Bach, S. Semi-supervised aggregation of dependent weak supervision sources with performance guarantees. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pp. 3196\u20133204. PMLR, 13\u201315 Apr 2021b. URL https://proceedings.mlr.press/v130/mazzetto21a.html.\n\nMiyato, T., Maeda, S.-i., Koyama, M., and Ishii, S. Virtual adversarial training: A regularization method for supervised and semi-supervised learning, 2017. URL https://arxiv.org/abs/1704.03976.\n\nOliver, A., Odena, A., Raffel, C. A., Cubuk, E. D., and Goodfellow, I. Realistic evaluation of deep semi-supervised learning algorithms. In Advances in Neural Information Processing Systems, volume 31, 2018. URL https://proceedings.neurips.cc/paper/2018/file/c1fea270c48e8079d8ddf7d06d26ab52-Paper.pdf.\n\nPukdee, R., Sam, D., Ravikumar, P. K., and Balcan, N. Label propagation with weak supervision. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=aCuFa-RRqtI.\n\nRatner, A., Hancock, B., Dunnmon, J., Sala, F., Pandey, S., and R\u00e9, C. Training complex models with multi-task weak supervision. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01): 4763\u20134771, Jul. 2019. doi: 10.1609/aaai.v33i01.33014763. URL https://ojs.aaai.org/index.php/AAAI/article/view/4403.\n\nRatner, A. J., De Sa, C. M., Wu, S., Selsam, D., and R\u00e9, C. Data programming: Creating large training sets, quickly. In Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc., 2016. URL https://proceedings.neurips.cc/paper/2016/file/6709e8d64a5f47269ed5cea9f625f7ab-Paper.pdf.\n\nRen, W., Li, Y., Su, H., Kartchner, D., Mitchell, C., and Zhang, C. Denoising multi-source weak supervision for neural text classification. In Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 3739\u20133754, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.334. URL https://aclanthology.org/2020.findings-emnlp.334.\n\nTarvainen, A. and Valpola, H. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/68053af2923e00204c3ca7c6a3150cf7-Paper.pdf.\n\nWei, J., Zhu, Z., Cheng, H., Liu, T., Niu, G., and Liu, Y. Learning with noisy labels revisited: A study using real-world human annotations. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=TBWA6PLJZQm.\n\nYu, Y., Zuo, S., Jiang, H., Ren, W., Zhao, T., and Zhang, C. Fine-tuning pre-trained language model with weak supervision: A contrastive-regularized self-training approach. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1063\u20131077, 2021. URL https://aclanthology.org/2021.naacl-main.84.pdf.\n\nZhang, J., Yu, Y., Li, Y., Wang, Y., Yang, Y., Yang, M., and Ratner, A. WRENCH: A comprehensive benchmark for weak supervision. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks.", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "text", "value": "Lee, D. The simple and efficient semi-supervised learning method for deep neural networks. In ICML Workshop on Challenges in Representation Learning, 2013.\n\nLi, J., Socher, R., and Hoi, S. C. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HJgExaVtwr.\n\nMaheshwari, A., Chatterjee, O., Killamsetty, K., Iyer, R. K., and Ramakrishnan, G. Data programming using semi-supervision and subset selection. CoRR, abs/2008.09887, 2020. URL https://arxiv.org/abs/2008.09887.\n\nMazzetto, A., Cousins, C., Sam, D., Bach, S. H., and Upfal, E. Adversarial multi class learning under weak supervision with performance guarantees. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 7534\u20137543. PMLR, 18\u201324 Jul 2021a. URL https://proceedings.mlr.press/v139/mazzetto21a.html.\n\nMazzetto, A., Sam, D., Park, A., Upfal, E., and Bach, S. Semi-supervised aggregation of dependent weak supervision sources with performance guarantees. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pp. 3196\u20133204. PMLR, 13\u201315 Apr 2021b. URL https://proceedings.mlr.press/v130/mazzetto21a.html.\n\nMiyato, T., Maeda, S.-i., Koyama, M., and Ishii, S. Virtual adversarial training: A regularization method for supervised and semi-supervised learning, 2017. URL https://arxiv.org/abs/1704.03976.\n\nOliver, A., Odena, A., Raffel, C. A., Cubuk, E. D., and Goodfellow, I. Realistic evaluation of deep semi-supervised learning algorithms. In Advances in Neural Information Processing Systems, volume 31, 2018. URL https://proceedings.neurips.cc/paper/2018/file/c1fea270c48e8079d8ddf7d06d26ab52-Paper.pdf.\n\nPukdee, R., Sam, D., Ravikumar, P. K., and Balcan, N. Label propagation with weak supervision. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=aCuFa-RRqtI.\n\nRatner, A., Hancock, B., Dunnmon, J., Sala, F., Pandey, S., and R\u00e9, C. Training complex models with multi-task weak supervision. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01): 4763\u20134771, Jul. 2019. doi: 10.1609/aaai.v33i01.33014763. URL https://ojs.aaai.org/index.php/AAAI/article/view/4403.\n\nRatner, A. J., De Sa, C. M., Wu, S., Selsam, D., and R\u00e9, C. Data programming: Creating large training sets, quickly. In Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc., 2016. URL https://proceedings.neurips.cc/paper/2016/file/6709e8d64a5f47269ed5cea9f625f7ab-Paper.pdf.\n\nRen, W., Li, Y., Su, H., Kartchner, D., Mitchell, C., and Zhang, C. Denoising multi-source weak supervision for neural text classification. In Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 3739\u20133754, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.334. URL https://aclanthology.org/2020.findings-emnlp.334.\n\nTarvainen, A. and Valpola, H. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/68053af2923e00204c3ca7c6a3150cf7-Paper.pdf.\n\nWei, J., Zhu, Z., Cheng, H., Liu, T., Niu, G., and Liu, Y. Learning with noisy labels revisited: A study using real-world human annotations. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=TBWA6PLJZQm.\n\nYu, Y., Zuo, S., Jiang, H., Ren, W., Zhao, T., and Zhang, C. Fine-tuning pre-trained language model with weak supervision: A contrastive-regularized self-training approach. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1063\u20131077, 2021. URL https://aclanthology.org/2021.naacl-main.84.pdf.\n\nZhang, J., Yu, Y., Li, Y., Wang, Y., Yang, Y., Yang, M., and Ratner, A. WRENCH: A comprehensive benchmark for weak supervision. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks.", "md": "Lee, D. The simple and efficient semi-supervised learning method for deep neural networks. In ICML Workshop on Challenges in Representation Learning, 2013.\n\nLi, J., Socher, R., and Hoi, S. C. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HJgExaVtwr.\n\nMaheshwari, A., Chatterjee, O., Killamsetty, K., Iyer, R. K., and Ramakrishnan, G. Data programming using semi-supervision and subset selection. CoRR, abs/2008.09887, 2020. URL https://arxiv.org/abs/2008.09887.\n\nMazzetto, A., Cousins, C., Sam, D., Bach, S. H., and Upfal, E. Adversarial multi class learning under weak supervision with performance guarantees. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 7534\u20137543. PMLR, 18\u201324 Jul 2021a. URL https://proceedings.mlr.press/v139/mazzetto21a.html.\n\nMazzetto, A., Sam, D., Park, A., Upfal, E., and Bach, S. Semi-supervised aggregation of dependent weak supervision sources with performance guarantees. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pp. 3196\u20133204. PMLR, 13\u201315 Apr 2021b. URL https://proceedings.mlr.press/v130/mazzetto21a.html.\n\nMiyato, T., Maeda, S.-i., Koyama, M., and Ishii, S. Virtual adversarial training: A regularization method for supervised and semi-supervised learning, 2017. URL https://arxiv.org/abs/1704.03976.\n\nOliver, A., Odena, A., Raffel, C. A., Cubuk, E. D., and Goodfellow, I. Realistic evaluation of deep semi-supervised learning algorithms. In Advances in Neural Information Processing Systems, volume 31, 2018. URL https://proceedings.neurips.cc/paper/2018/file/c1fea270c48e8079d8ddf7d06d26ab52-Paper.pdf.\n\nPukdee, R., Sam, D., Ravikumar, P. K., and Balcan, N. Label propagation with weak supervision. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=aCuFa-RRqtI.\n\nRatner, A., Hancock, B., Dunnmon, J., Sala, F., Pandey, S., and R\u00e9, C. Training complex models with multi-task weak supervision. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01): 4763\u20134771, Jul. 2019. doi: 10.1609/aaai.v33i01.33014763. URL https://ojs.aaai.org/index.php/AAAI/article/view/4403.\n\nRatner, A. J., De Sa, C. M., Wu, S., Selsam, D., and R\u00e9, C. Data programming: Creating large training sets, quickly. In Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc., 2016. URL https://proceedings.neurips.cc/paper/2016/file/6709e8d64a5f47269ed5cea9f625f7ab-Paper.pdf.\n\nRen, W., Li, Y., Su, H., Kartchner, D., Mitchell, C., and Zhang, C. Denoising multi-source weak supervision for neural text classification. In Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 3739\u20133754, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.334. URL https://aclanthology.org/2020.findings-emnlp.334.\n\nTarvainen, A. and Valpola, H. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/68053af2923e00204c3ca7c6a3150cf7-Paper.pdf.\n\nWei, J., Zhu, Z., Cheng, H., Liu, T., Niu, G., and Liu, Y. Learning with noisy labels revisited: A study using real-world human annotations. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=TBWA6PLJZQm.\n\nYu, Y., Zuo, S., Jiang, H., Ren, W., Zhao, T., and Zhang, C. Fine-tuning pre-trained language model with weak supervision: A contrastive-regularized self-training approach. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1063\u20131077, 2021. URL https://aclanthology.org/2021.naacl-main.84.pdf.\n\nZhang, J., Yu, Y., Li, Y., Wang, Y., Yang, Y., Yang, M., and Ratner, A. WRENCH: A comprehensive benchmark for weak supervision. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks."}]}, {"page": 11, "text": "                       Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n  marks Track, 2021.     URL https://openreview.\n  net/forum?id=Q9SKS5k8io.\nZhang, J., Hsieh, C.-Y., Yu, Y., Zhang, C., and Ratner, A. A\n  survey on programmatic weak supervision. arXiv preprint\n  arXiv:2202.05433, 2022a. URL https://doi.org/\n  10.48550/arXiv.2202.05433.\nZhang, J., Wang, H., Hsieh, C.-Y., and Ratner, A. J.\n  Understanding programmatic weak supervision via\n  source-aware influence function.     In Koyejo, S., Mo-\n  hamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A.\n  (eds.), Advances in Neural Information Processing Sys-\n  tems, volume 35, pp. 2862\u20132875. Curran Associates, Inc.,\n  2022b.    URL https://proceedings.neurips.\n  cc/paper_files/paper/2022/file/\n  1343edb2739a61a6e20bd8764e814b50-Paper-Conference.\n  pdf.\nZhou, W., Lin, H., Lin, B. Y., Wang, Z., Du, J., Neves,\n  L., and Ren, X. Nero: A neural rule grounding frame-\n  work for label-efficient relation extraction.     In Pro-\n  ceedings of The Web Conference 2020, WWW \u201920,\n  pp. 2166\u20132176. Association for Computing Machin-\n  ery, 2020.    ISBN 9781450370233.         doi:   10.1145/\n  3366423.3380282.       URL https://doi.org/10.\n  1145/3366423.3380282.\nZhu, Y., Zhang, P., Haq, E.-U., Hui, P., and Tyson, G. Can\n  chatgpt reproduce human-generated labels? a study of\n  social computing tasks, 2023. URL https://doi.\n  org/10.48550/arXiv.2304.10145.\n                                                             11", "md": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nZhang, J., Hsieh, C.-Y., Yu, Y., Zhang, C., and Ratner, A. A survey on programmatic weak supervision. arXiv preprint arXiv:2202.05433, 2022a. URL https://doi.org/10.48550/arXiv.2202.05433.\n\nZhang, J., Wang, H., Hsieh, C.-Y., and Ratner, A. J. Understanding programmatic weak supervision via source-aware influence function. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems, volume 35, pp. 2862\u20132875. Curran Associates, Inc., 2022b. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/1343edb2739a61a6e20bd8764e814b50-Paper-Conference.pdf.\n\nZhou, W., Lin, H., Lin, B. Y., Wang, Z., Du, J., Neves, L., and Ren, X. Nero: A neural rule grounding framework for label-efficient relation extraction. In Proceedings of The Web Conference 2020, WWW \u201920, pp. 2166\u20132176. Association for Computing Machinery, 2020. ISBN 9781450370233. doi: 10.1145/3366423.3380282. URL https://doi.org/10.1145/3366423.3380282.\n\nZhu, Y., Zhang, P., Haq, E.-U., Hui, P., and Tyson, G. Can chatgpt reproduce human-generated labels? a study of social computing tasks, 2023. URL https://doi.org/10.48550/arXiv.2304.10145.\n\n11", "images": [], "items": [{"type": "text", "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nZhang, J., Hsieh, C.-Y., Yu, Y., Zhang, C., and Ratner, A. A survey on programmatic weak supervision. arXiv preprint arXiv:2202.05433, 2022a. URL https://doi.org/10.48550/arXiv.2202.05433.\n\nZhang, J., Wang, H., Hsieh, C.-Y., and Ratner, A. J. Understanding programmatic weak supervision via source-aware influence function. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems, volume 35, pp. 2862\u20132875. Curran Associates, Inc., 2022b. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/1343edb2739a61a6e20bd8764e814b50-Paper-Conference.pdf.\n\nZhou, W., Lin, H., Lin, B. Y., Wang, Z., Du, J., Neves, L., and Ren, X. Nero: A neural rule grounding framework for label-efficient relation extraction. In Proceedings of The Web Conference 2020, WWW \u201920, pp. 2166\u20132176. Association for Computing Machinery, 2020. ISBN 9781450370233. doi: 10.1145/3366423.3380282. URL https://doi.org/10.1145/3366423.3380282.\n\nZhu, Y., Zhang, P., Haq, E.-U., Hui, P., and Tyson, G. Can chatgpt reproduce human-generated labels? a study of social computing tasks, 2023. URL https://doi.org/10.48550/arXiv.2304.10145.\n\n11", "md": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nZhang, J., Hsieh, C.-Y., Yu, Y., Zhang, C., and Ratner, A. A survey on programmatic weak supervision. arXiv preprint arXiv:2202.05433, 2022a. URL https://doi.org/10.48550/arXiv.2202.05433.\n\nZhang, J., Wang, H., Hsieh, C.-Y., and Ratner, A. J. Understanding programmatic weak supervision via source-aware influence function. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems, volume 35, pp. 2862\u20132875. Curran Associates, Inc., 2022b. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/1343edb2739a61a6e20bd8764e814b50-Paper-Conference.pdf.\n\nZhou, W., Lin, H., Lin, B. Y., Wang, Z., Du, J., Neves, L., and Ren, X. Nero: A neural rule grounding framework for label-efficient relation extraction. In Proceedings of The Web Conference 2020, WWW \u201920, pp. 2166\u20132176. Association for Computing Machinery, 2020. ISBN 9781450370233. doi: 10.1145/3366423.3380282. URL https://doi.org/10.1145/3366423.3380282.\n\nZhu, Y., Zhang, P., Haq, E.-U., Hui, P., and Tyson, G. Can chatgpt reproduce human-generated labels? a study of social computing tasks, 2023. URL https://doi.org/10.48550/arXiv.2304.10145.\n\n11"}]}, {"page": 12, "text": "                                Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nA. Experiment Details\nA.1. Search Spaces\n            Method                       Hyperparameters          Description                                         Range\n                                         lr                       learning rate                                       1e-5,1e-4,1e-3,1e-2,1e-1\n            Snorkel LM                   weight decay             weight decay                                        1e-5,1e-4,1e-3,1e-2,1e-1\n                                         num epoch                the number of training epochs                       5,10,50,100,200\n                                         batch size               batch size                                          32,128,512\n                                         lr                       learning rate                                       1e-4,1e-3,1e-2\n            MLP                          dropout                  dropout probability                                 0.2, 0.0\n                                         weight decay             weight decay                                        0.0\n                                         num layer                the number of hidden layers                         2\n                                         hidden size              the hidden size of MLP layers                       128, 256, 512\n                                         batch size               batch size                                          32\n            BERT                         lr                       learning rate                                       1e-5,3e-5,5e-5\n                                         weight decay             weight decay                                        1e-4\n                                         T                        period for updating pseudo-labels                   50,100,200\n                                         \u03be                        confidence threshold                                0.1, 0.3, 0.5, 0.7, 0.9\n            COSINE                       \u03bb                        weight for confidence regularization                0.01,0.05,0.1\n                                         \u00b5                        weight for contrastive regularization               1\n                                         \u03b3                        margin for contrastive regularization               1\n                                         \u03b1                        momentum term for temporal ensembling               0.6\n                                         d                        size of hidden layer                                26 \u2212   29\n            Denoise                      c1                       coefficient of denoiser loss                        0.1,0.3,0.5,0.7,0.9\n                                         c2                       coefficient of classifier loss                      0.1,0.3,0.5,0.7,0.9\n                                         c3                       coefficient of unsupervised self-training loss      1-c2-c1\n                                         \u03b3                        temperature                                         1.0, 0.33\n            WeaSEL                       d                        size of hidden layer                                26 \u2212   29\n                                         dropout                  dropout prob                                        0.3\n            Confidence Thresh            threshold                minimum confidence to keep                          np.linspace( 1      |Y| + 0.1, 0.9, 9)\n            Cutstat Thresh               percentile               what percentile as cut-off                          np.linspace(0.1, 0.9, 9)\n            Self-Training                T                        period for updating pseudo-labels                   50, 100\n            Self-Train (DM as LF)        T                        period for updating pseudo-labels                   50, 100\n            EM                           \u03bb                        the coefficient for EM loss                         1, 0.5, 1e-1, 1e-2, 1e-3\n                                         \u03bb                        the coefficient for VAT unsupervised loss           1, 0.5, 1e-1, 1e-2, 1e-3\n            VAT                          VAT ip                   Iterations of the power method for VAT              1\n                                         \u03be                        Finite difference for approximation in VAT          0.05, 0.1, 0.5, 1, 5\n                                         \u03f5                        VAT Perturbation distance                           1e-6, 1e-3, 1, 2.5, 5\nTable 5. Search spaces organized by type of method: label models, end models, baselines, thresholding, and SSL techniques.\nA.2. Implementation Details\nLabel Models. Of the two label models that we use, we must tune parameters only for Snorkel. We tune over the search\nspace in Table 5 once per dataset; we then fix the hyperparameters and seed for fitting Snorkel to ensure the same exact\nweak labels are given to all methods. This seed is chosen from a pool of three, also based on the validation set.\nEnd Models. For MLPs, we increase the range of hidden sizes compared to WRENCH and tune for dropout instead\nof weight decay. For RoBERTa, we do not tune the batch size in order to reduce the search space, observing minimal\ndifferences compared to using an alternative batch size of 16. Following WRENCH, we perform early stopping based on\nvalidation performance for all methods. Specifically, we use a patience of 1000 steps for MLPs and 100 steps for RoBERTa.\nThresholding. Whenever applying dynamic versions of thresholding, we use the same threshold value across different\nrounds for simplicity. Setting separate thresholds for different stages of learning (or adaptively) could be an interesting\ndirection for future work.\n                                                                                   12", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n## Experiment Details\n\n### Search Spaces\n\n|Method|Hyperparameters|Description|Range|\n|---|---|---|---|\n|Snorkel LM|lr|learning rate|$1e-5,1e-4,1e-3,1e-2,1e-1$|\n|Snorkel LM|weight decay|weight decay|$1e-5,1e-4,1e-3,1e-2,1e-1$|\n|Snorkel LM|num epoch|the number of training epochs|$5,10,50,100,200$|\n|Snorkel LM|batch size|batch size|$32,128,512$|\n|MLP|dropout|dropout probability|$0.2, 0.0$|\n|MLP|weight decay|weight decay|$0.0$|\n|MLP|num layer|the number of hidden layers|$2$|\n|MLP|hidden size|the hidden size of MLP layers|$128, 256, 512$|\n|MLP|batch size|batch size|$32$|\n|BERT|lr|learning rate|$1e-5,3e-5,5e-5$|\n|BERT|weight decay|weight decay|$1e-4$|\n|BERT|T|period for updating pseudo-labels|$50,100,200$|\n|BERT|\u03be|confidence threshold|$0.1, 0.3, 0.5, 0.7, 0.9$|\n|COSINE|\u03bb|weight for confidence regularization|$0.01,0.05,0.1$|\n|COSINE|\u00b5|weight for contrastive regularization|$1$|\n|COSINE|\u03b3|margin for contrastive regularization|$1$|\n|COSINE|\u03b1|momentum term for temporal ensembling|$0.6$|\n|COSINE|d|size of hidden layer|$26 - 29$|\n|Denoise|c1|coefficient of denoiser loss|$0.1,0.3,0.5,0.7,0.9$|\n|Denoise|c2|coefficient of classifier loss|$0.1,0.3,0.5,0.7,0.9$|\n|Denoise|c3|coefficient of unsupervised self-training loss|$1-c2-c1$|\n|Denoise|\u03b3|temperature|$1.0, 0.33$|\n|WeaSEL|d|size of hidden layer|$26 - 29$|\n|WeaSEL|dropout|dropout prob|$0.3$|\n|Confidence Thresh|threshold|minimum confidence to keep|$np.linspace(1 |Y| + 0.1, 0.9, 9)$|\n|Cutstat Thresh|percentile|what percentile as cut-off|$np.linspace(0.1, 0.9, 9)$|\n|Self-Training|T|period for updating pseudo-labels|$50, 100$|\n|Self-Train (DM as LF)|T|period for updating pseudo-labels|$50, 100$|\n|EM|\u03bb|the coefficient for EM loss|$1, 0.5, 1e-1, 1e-2, 1e-3$|\n|EM|\u03bb|the coefficient for VAT unsupervised loss|$1, 0.5, 1e-1, 1e-2, 1e-3$|\n|VAT|VAT ip|Iterations of the power method for VAT|$1$|\n|VAT|\u03be|Finite difference for approximation in VAT|$0.05, 0.1, 0.5, 1, 5$|\n|VAT|\u03f5|VAT Perturbation distance|$1e-6, 1e-3, 1, 2.5, 5$|\n\nTable 5. Search spaces organized by type of method: label models, end models, baselines, thresholding, and SSL techniques.\n\n### Implementation Details\n\nLabel Models. Of the two label models that we use, we must tune parameters only for Snorkel. We tune over the search space in Table 5 once per dataset; we then fix the hyperparameters and seed for fitting Snorkel to ensure the same exact weak labels are given to all methods. This seed is chosen from a pool of three, also based on the validation set.\n\nEnd Models. For MLPs, we increase the range of hidden sizes compared to WRENCH and tune for dropout instead of weight decay. For RoBERTa, we do not tune the batch size in order to reduce the search space, observing minimal differences compared to using an alternative batch size of 16. Following WRENCH, we perform early stopping based on validation performance for all methods. Specifically, we use a patience of 1000 steps for MLPs and 100 steps for RoBERTa.\n\nThresholding. Whenever applying dynamic versions of thresholding, we use the same threshold value across different rounds for simplicity. Setting separate thresholds for different stages of learning (or adaptively) could be an interesting direction for future work.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "Experiment Details", "md": "## Experiment Details"}, {"type": "heading", "lvl": 3, "value": "Search Spaces", "md": "### Search Spaces"}, {"type": "table", "rows": [["Method", "Hyperparameters", "Description", "Range"], ["Snorkel LM", "lr", "learning rate", "$1e-5,1e-4,1e-3,1e-2,1e-1$"], ["Snorkel LM", "weight decay", "weight decay", "$1e-5,1e-4,1e-3,1e-2,1e-1$"], ["Snorkel LM", "num epoch", "the number of training epochs", "$5,10,50,100,200$"], ["Snorkel LM", "batch size", "batch size", "$32,128,512$"], ["MLP", "dropout", "dropout probability", "$0.2, 0.0$"], ["MLP", "weight decay", "weight decay", "$0.0$"], ["MLP", "num layer", "the number of hidden layers", "$2$"], ["MLP", "hidden size", "the hidden size of MLP layers", "$128, 256, 512$"], ["MLP", "batch size", "batch size", "$32$"], ["BERT", "lr", "learning rate", "$1e-5,3e-5,5e-5$"], ["BERT", "weight decay", "weight decay", "$1e-4$"], ["BERT", "T", "period for updating pseudo-labels", "$50,100,200$"], ["BERT", "\u03be", "confidence threshold", "$0.1, 0.3, 0.5, 0.7, 0.9$"], ["COSINE", "\u03bb", "weight for confidence regularization", "$0.01,0.05,0.1$"], ["COSINE", "\u00b5", "weight for contrastive regularization", "$1$"], ["COSINE", "\u03b3", "margin for contrastive regularization", "$1$"], ["COSINE", "\u03b1", "momentum term for temporal ensembling", "$0.6$"], ["COSINE", "d", "size of hidden layer", "$26 - 29$"], ["Denoise", "c1", "coefficient of denoiser loss", "$0.1,0.3,0.5,0.7,0.9$"], ["Denoise", "c2", "coefficient of classifier loss", "$0.1,0.3,0.5,0.7,0.9$"], ["Denoise", "c3", "coefficient of unsupervised self-training loss", "$1-c2-c1$"], ["Denoise", "\u03b3", "temperature", "$1.0, 0.33$"], ["WeaSEL", "d", "size of hidden layer", "$26 - 29$"], ["WeaSEL", "dropout", "dropout prob", "$0.3$"], ["Confidence Thresh", "threshold", "minimum confidence to keep", "$np.linspace(1", "Y", "+ 0.1, 0.9, 9)$"], ["Cutstat Thresh", "percentile", "what percentile as cut-off", "$np.linspace(0.1, 0.9, 9)$"], ["Self-Training", "T", "period for updating pseudo-labels", "$50, 100$"], ["Self-Train (DM as LF)", "T", "period for updating pseudo-labels", "$50, 100$"], ["EM", "\u03bb", "the coefficient for EM loss", "$1, 0.5, 1e-1, 1e-2, 1e-3$"], ["EM", "\u03bb", "the coefficient for VAT unsupervised loss", "$1, 0.5, 1e-1, 1e-2, 1e-3$"], ["VAT", "VAT ip", "Iterations of the power method for VAT", "$1$"], ["VAT", "\u03be", "Finite difference for approximation in VAT", "$0.05, 0.1, 0.5, 1, 5$"], ["VAT", "\u03f5", "VAT Perturbation distance", "$1e-6, 1e-3, 1, 2.5, 5$"]], "md": "|Method|Hyperparameters|Description|Range|\n|---|---|---|---|\n|Snorkel LM|lr|learning rate|$1e-5,1e-4,1e-3,1e-2,1e-1$|\n|Snorkel LM|weight decay|weight decay|$1e-5,1e-4,1e-3,1e-2,1e-1$|\n|Snorkel LM|num epoch|the number of training epochs|$5,10,50,100,200$|\n|Snorkel LM|batch size|batch size|$32,128,512$|\n|MLP|dropout|dropout probability|$0.2, 0.0$|\n|MLP|weight decay|weight decay|$0.0$|\n|MLP|num layer|the number of hidden layers|$2$|\n|MLP|hidden size|the hidden size of MLP layers|$128, 256, 512$|\n|MLP|batch size|batch size|$32$|\n|BERT|lr|learning rate|$1e-5,3e-5,5e-5$|\n|BERT|weight decay|weight decay|$1e-4$|\n|BERT|T|period for updating pseudo-labels|$50,100,200$|\n|BERT|\u03be|confidence threshold|$0.1, 0.3, 0.5, 0.7, 0.9$|\n|COSINE|\u03bb|weight for confidence regularization|$0.01,0.05,0.1$|\n|COSINE|\u00b5|weight for contrastive regularization|$1$|\n|COSINE|\u03b3|margin for contrastive regularization|$1$|\n|COSINE|\u03b1|momentum term for temporal ensembling|$0.6$|\n|COSINE|d|size of hidden layer|$26 - 29$|\n|Denoise|c1|coefficient of denoiser loss|$0.1,0.3,0.5,0.7,0.9$|\n|Denoise|c2|coefficient of classifier loss|$0.1,0.3,0.5,0.7,0.9$|\n|Denoise|c3|coefficient of unsupervised self-training loss|$1-c2-c1$|\n|Denoise|\u03b3|temperature|$1.0, 0.33$|\n|WeaSEL|d|size of hidden layer|$26 - 29$|\n|WeaSEL|dropout|dropout prob|$0.3$|\n|Confidence Thresh|threshold|minimum confidence to keep|$np.linspace(1 |Y| + 0.1, 0.9, 9)$|\n|Cutstat Thresh|percentile|what percentile as cut-off|$np.linspace(0.1, 0.9, 9)$|\n|Self-Training|T|period for updating pseudo-labels|$50, 100$|\n|Self-Train (DM as LF)|T|period for updating pseudo-labels|$50, 100$|\n|EM|\u03bb|the coefficient for EM loss|$1, 0.5, 1e-1, 1e-2, 1e-3$|\n|EM|\u03bb|the coefficient for VAT unsupervised loss|$1, 0.5, 1e-1, 1e-2, 1e-3$|\n|VAT|VAT ip|Iterations of the power method for VAT|$1$|\n|VAT|\u03be|Finite difference for approximation in VAT|$0.05, 0.1, 0.5, 1, 5$|\n|VAT|\u03f5|VAT Perturbation distance|$1e-6, 1e-3, 1, 2.5, 5$|", "isPerfectTable": false, "csv": "\"Method\",\"Hyperparameters\",\"Description\",\"Range\"\n\"Snorkel LM\",\"lr\",\"learning rate\",\"$1e-5,1e-4,1e-3,1e-2,1e-1$\"\n\"Snorkel LM\",\"weight decay\",\"weight decay\",\"$1e-5,1e-4,1e-3,1e-2,1e-1$\"\n\"Snorkel LM\",\"num epoch\",\"the number of training epochs\",\"$5,10,50,100,200$\"\n\"Snorkel LM\",\"batch size\",\"batch size\",\"$32,128,512$\"\n\"MLP\",\"dropout\",\"dropout probability\",\"$0.2, 0.0$\"\n\"MLP\",\"weight decay\",\"weight decay\",\"$0.0$\"\n\"MLP\",\"num layer\",\"the number of hidden layers\",\"$2$\"\n\"MLP\",\"hidden size\",\"the hidden size of MLP layers\",\"$128, 256, 512$\"\n\"MLP\",\"batch size\",\"batch size\",\"$32$\"\n\"BERT\",\"lr\",\"learning rate\",\"$1e-5,3e-5,5e-5$\"\n\"BERT\",\"weight decay\",\"weight decay\",\"$1e-4$\"\n\"BERT\",\"T\",\"period for updating pseudo-labels\",\"$50,100,200$\"\n\"BERT\",\"\u03be\",\"confidence threshold\",\"$0.1, 0.3, 0.5, 0.7, 0.9$\"\n\"COSINE\",\"\u03bb\",\"weight for confidence regularization\",\"$0.01,0.05,0.1$\"\n\"COSINE\",\"\u00b5\",\"weight for contrastive regularization\",\"$1$\"\n\"COSINE\",\"\u03b3\",\"margin for contrastive regularization\",\"$1$\"\n\"COSINE\",\"\u03b1\",\"momentum term for temporal ensembling\",\"$0.6$\"\n\"COSINE\",\"d\",\"size of hidden layer\",\"$26 - 29$\"\n\"Denoise\",\"c1\",\"coefficient of denoiser loss\",\"$0.1,0.3,0.5,0.7,0.9$\"\n\"Denoise\",\"c2\",\"coefficient of classifier loss\",\"$0.1,0.3,0.5,0.7,0.9$\"\n\"Denoise\",\"c3\",\"coefficient of unsupervised self-training loss\",\"$1-c2-c1$\"\n\"Denoise\",\"\u03b3\",\"temperature\",\"$1.0, 0.33$\"\n\"WeaSEL\",\"d\",\"size of hidden layer\",\"$26 - 29$\"\n\"WeaSEL\",\"dropout\",\"dropout prob\",\"$0.3$\"\n\"Confidence Thresh\",\"threshold\",\"minimum confidence to keep\",\"$np.linspace(1\",\"Y\",\"+ 0.1, 0.9, 9)$\"\n\"Cutstat Thresh\",\"percentile\",\"what percentile as cut-off\",\"$np.linspace(0.1, 0.9, 9)$\"\n\"Self-Training\",\"T\",\"period for updating pseudo-labels\",\"$50, 100$\"\n\"Self-Train (DM as LF)\",\"T\",\"period for updating pseudo-labels\",\"$50, 100$\"\n\"EM\",\"\u03bb\",\"the coefficient for EM loss\",\"$1, 0.5, 1e-1, 1e-2, 1e-3$\"\n\"EM\",\"\u03bb\",\"the coefficient for VAT unsupervised loss\",\"$1, 0.5, 1e-1, 1e-2, 1e-3$\"\n\"VAT\",\"VAT ip\",\"Iterations of the power method for VAT\",\"$1$\"\n\"VAT\",\"\u03be\",\"Finite difference for approximation in VAT\",\"$0.05, 0.1, 0.5, 1, 5$\"\n\"VAT\",\"\u03f5\",\"VAT Perturbation distance\",\"$1e-6, 1e-3, 1, 2.5, 5$\""}, {"type": "text", "value": "Table 5. Search spaces organized by type of method: label models, end models, baselines, thresholding, and SSL techniques.", "md": "Table 5. Search spaces organized by type of method: label models, end models, baselines, thresholding, and SSL techniques."}, {"type": "heading", "lvl": 3, "value": "Implementation Details", "md": "### Implementation Details"}, {"type": "text", "value": "Label Models. Of the two label models that we use, we must tune parameters only for Snorkel. We tune over the search space in Table 5 once per dataset; we then fix the hyperparameters and seed for fitting Snorkel to ensure the same exact weak labels are given to all methods. This seed is chosen from a pool of three, also based on the validation set.\n\nEnd Models. For MLPs, we increase the range of hidden sizes compared to WRENCH and tune for dropout instead of weight decay. For RoBERTa, we do not tune the batch size in order to reduce the search space, observing minimal differences compared to using an alternative batch size of 16. Following WRENCH, we perform early stopping based on validation performance for all methods. Specifically, we use a patience of 1000 steps for MLPs and 100 steps for RoBERTa.\n\nThresholding. Whenever applying dynamic versions of thresholding, we use the same threshold value across different rounds for simplicity. Setting separate thresholds for different stages of learning (or adaptively) could be an interesting direction for future work.", "md": "Label Models. Of the two label models that we use, we must tune parameters only for Snorkel. We tune over the search space in Table 5 once per dataset; we then fix the hyperparameters and seed for fitting Snorkel to ensure the same exact weak labels are given to all methods. This seed is chosen from a pool of three, also based on the validation set.\n\nEnd Models. For MLPs, we increase the range of hidden sizes compared to WRENCH and tune for dropout instead of weight decay. For RoBERTa, we do not tune the batch size in order to reduce the search space, observing minimal differences compared to using an alternative batch size of 16. Following WRENCH, we perform early stopping based on validation performance for all methods. Specifically, we use a patience of 1000 steps for MLPs and 100 steps for RoBERTa.\n\nThresholding. Whenever applying dynamic versions of thresholding, we use the same threshold value across different rounds for simplicity. Setting separate thresholds for different stages of learning (or adaptively) could be an interesting direction for future work."}]}, {"page": 13, "text": "                        Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nSSL Techniques. We make note of some important details relevant to specific SSL techniques:\n   \u2022 For the two self-training methods, we use a training schedule similar to that of COSINE, whereby we divide training\n     into two stages: In the first stage, the end model is trained on weak labels as is done in standard WS end model training.\n     In the second stage, new pseudo-labels are generated upon reaching a pre-specified update period of {50,100} steps.\n   \u2022 For self-training, we also allow for applying thresholds to the pseudo-labels given to unlabeled data. When combining\n     this approach with thresholding the initial weak labels, we again use the same threshold value.\n   \u2022 When using ST (DM as LF), we do not re-tune the label model-specific hyperparameters for Snorkel in subsequent\n     self-training rounds. We default to instead using the same hyperparameters found from the initial search.\n   \u2022 For EM and VAT, we sample batches with equal numbers of labeled and unlabeled examples when taking each step but\n     tune a weighting parameter to balance their losses.\n   \u2022 When applying VAT to RoBERTa models, we calculate perturbations with respect to the RoBERTa-based features\n     (which are continuous) instead of the raw text inputs.\nRe-labeling. For re-labeling, we again use a two-stage training schedule where the second stage contains a label update\nperiod (as explained when discussing self-training). When combining re-labeling with thresholding, we consider the set\nof examples with candidate labels (i.e., which are possibly removed when performing dynamic thresholding) to be fixed\nafter the initial round of thresholding (of LM outputs). Thus, re-labeling provides new pseudo-labels only for examples that\nsurvived the initial thresholding.\nCompute. We ran all MLP experiments on AWS, using up to four g4dn.4xlarge EC2 instances at one time. Each\ninstance allowed for running up to 10 different experiments (i.e., here considered as a hyperparameter sweep for any specific\nmethod from our design space) in parallel. For all RoBERTa training runs, we ran our experiments on a fleet of up to 15\nNVIDIA-A40 GPUs hosted on a cluster shared by our research lab. Each experiment fits on a single A-40 GPU, which is\nlarge enough to use our batch sizes without needing gradient accumulation.\n                                                               13", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nSSL Techniques. We make note of some important details relevant to specific SSL techniques:\n\n- For the two self-training methods, we use a training schedule similar to that of COSINE, whereby we divide training\ninto two stages: In the first stage, the end model is trained on weak labels as is done in standard WS end model training.\nIn the second stage, new pseudo-labels are generated upon reaching a pre-specified update period of {50,100} steps.\n- For self-training, we also allow for applying thresholds to the pseudo-labels given to unlabeled data. When combining\nthis approach with thresholding the initial weak labels, we again use the same threshold value.\n- When using ST (DM as LF), we do not re-tune the label model-specific hyperparameters for Snorkel in subsequent\nself-training rounds. We default to instead using the same hyperparameters found from the initial search.\n- For EM and VAT, we sample batches with equal numbers of labeled and unlabeled examples when taking each step but\ntune a weighting parameter to balance their losses.\n- When applying VAT to RoBERTa models, we calculate perturbations with respect to the RoBERTa-based features\n(which are continuous) instead of the raw text inputs.\n\nRe-labeling. For re-labeling, we again use a two-stage training schedule where the second stage contains a label update\nperiod (as explained when discussing self-training). When combining re-labeling with thresholding, we consider the set\nof examples with candidate labels (i.e., which are possibly removed when performing dynamic thresholding) to be fixed\nafter the initial round of thresholding (of LM outputs). Thus, re-labeling provides new pseudo-labels only for examples that\nsurvived the initial thresholding.\n\nCompute. We ran all MLP experiments on AWS, using up to four g4dn.4xlarge EC2 instances at one time. Each\ninstance allowed for running up to 10 different experiments (i.e., here considered as a hyperparameter sweep for any specific\nmethod from our design space) in parallel. For all RoBERTa training runs, we ran our experiments on a fleet of up to 15\nNVIDIA-A40 GPUs hosted on a cluster shared by our research lab. Each experiment fits on a single A-40 GPU, which is\nlarge enough to use our batch sizes without needing gradient accumulation.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "text", "value": "SSL Techniques. We make note of some important details relevant to specific SSL techniques:\n\n- For the two self-training methods, we use a training schedule similar to that of COSINE, whereby we divide training\ninto two stages: In the first stage, the end model is trained on weak labels as is done in standard WS end model training.\nIn the second stage, new pseudo-labels are generated upon reaching a pre-specified update period of {50,100} steps.\n- For self-training, we also allow for applying thresholds to the pseudo-labels given to unlabeled data. When combining\nthis approach with thresholding the initial weak labels, we again use the same threshold value.\n- When using ST (DM as LF), we do not re-tune the label model-specific hyperparameters for Snorkel in subsequent\nself-training rounds. We default to instead using the same hyperparameters found from the initial search.\n- For EM and VAT, we sample batches with equal numbers of labeled and unlabeled examples when taking each step but\ntune a weighting parameter to balance their losses.\n- When applying VAT to RoBERTa models, we calculate perturbations with respect to the RoBERTa-based features\n(which are continuous) instead of the raw text inputs.\n\nRe-labeling. For re-labeling, we again use a two-stage training schedule where the second stage contains a label update\nperiod (as explained when discussing self-training). When combining re-labeling with thresholding, we consider the set\nof examples with candidate labels (i.e., which are possibly removed when performing dynamic thresholding) to be fixed\nafter the initial round of thresholding (of LM outputs). Thus, re-labeling provides new pseudo-labels only for examples that\nsurvived the initial thresholding.\n\nCompute. We ran all MLP experiments on AWS, using up to four g4dn.4xlarge EC2 instances at one time. Each\ninstance allowed for running up to 10 different experiments (i.e., here considered as a hyperparameter sweep for any specific\nmethod from our design space) in parallel. For all RoBERTa training runs, we ran our experiments on a fleet of up to 15\nNVIDIA-A40 GPUs hosted on a cluster shared by our research lab. Each experiment fits on a single A-40 GPU, which is\nlarge enough to use our batch sizes without needing gradient accumulation.", "md": "SSL Techniques. We make note of some important details relevant to specific SSL techniques:\n\n- For the two self-training methods, we use a training schedule similar to that of COSINE, whereby we divide training\ninto two stages: In the first stage, the end model is trained on weak labels as is done in standard WS end model training.\nIn the second stage, new pseudo-labels are generated upon reaching a pre-specified update period of {50,100} steps.\n- For self-training, we also allow for applying thresholds to the pseudo-labels given to unlabeled data. When combining\nthis approach with thresholding the initial weak labels, we again use the same threshold value.\n- When using ST (DM as LF), we do not re-tune the label model-specific hyperparameters for Snorkel in subsequent\nself-training rounds. We default to instead using the same hyperparameters found from the initial search.\n- For EM and VAT, we sample batches with equal numbers of labeled and unlabeled examples when taking each step but\ntune a weighting parameter to balance their losses.\n- When applying VAT to RoBERTa models, we calculate perturbations with respect to the RoBERTa-based features\n(which are continuous) instead of the raw text inputs.\n\nRe-labeling. For re-labeling, we again use a two-stage training schedule where the second stage contains a label update\nperiod (as explained when discussing self-training). When combining re-labeling with thresholding, we consider the set\nof examples with candidate labels (i.e., which are possibly removed when performing dynamic thresholding) to be fixed\nafter the initial round of thresholding (of LM outputs). Thus, re-labeling provides new pseudo-labels only for examples that\nsurvived the initial thresholding.\n\nCompute. We ran all MLP experiments on AWS, using up to four g4dn.4xlarge EC2 instances at one time. Each\ninstance allowed for running up to 10 different experiments (i.e., here considered as a hyperparameter sweep for any specific\nmethod from our design space) in parallel. For all RoBERTa training runs, we ran our experiments on a fleet of up to 15\nNVIDIA-A40 GPUs hosted on a cluster shared by our research lab. Each experiment fits on a single A-40 GPU, which is\nlarge enough to use our batch sizes without needing gradient accumulation."}]}, {"page": 14, "text": "                                        Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nB. Additional Results for Baseline Comparisons\nB.1. Additional Plots\n                         0.03        IMDb-MLP (Acc)               0.03         Yelp-MLP (Acc)              0.03       Youtube-MLP (Acc)             0.03       AGNews-MLP (Acc)\n                       in Test Perf.\n                         0.02                                     0.02                                     0.02                                     0.02\n                         0.01                                     0.01                                     0.01                                     0.01\n                         0.00                                     0.00                                     0.00                                     0.00\n                         0.01                                     0.01                                     0.01                                     0.01\n                         0.12        TREC-MLP (Acc)               0.18   Spouse-MLP (F1_binary)            0.03      Chemprot-MLP (Acc)             0.12    Census-MLP (F1_binary)\n                       in Test Perf.\n                         0.08                                     0.12                                     0.02                                     0.08\n                         0.04                                     0.06                                     0.01                                     0.04\n                         0.00                                     0.00                                     0.00                                     0.00\n                         0.04                                     0.06                                     0.01                                     0.04\n                                                           Best of Design Space                           Cutstat + Snorkel               Denoise + Snorkel\n                                                           Conf + VAT + Re-label (w/ DM)                  COSINE + Snorkel                Weasel\nFigure 5. Test performance for LM = Snorkel, DM = MLP. We compare a selected method from our design space (green) with four recent\nproposals from the literature. We plot all performances relative to that of vanilla training (see Table 6 for the absolute metrics)\n                        0.03      IMDb-BERT-MV (Acc)             0.06       Yelp-BERT-MV (Acc)             0.03   Youtube-BERT-MV (Acc)             0.03   AGNews-BERT-MV (Acc)\n                       in Test Perf.\n                        0.02                                     0.04                                      0.02                                     0.02\n                        0.01                                     0.02                                      0.01                                     0.01\n                        0.00                                     0.00                                      0.00                                     0.00\n                        0.01                                     0.02                                      0.01                                     0.01\n                        0.15      TREC-BERT-MV (Acc)             0.24 Spouse-BERT-MV (F1_binary)           0.06  Chemprot-BERT-MV (Acc)\n                       in Test Perf.\n                        0.10                                     0.16                                      0.04                                           Cut + ST (DM as LF) + Re-label\n                                                                                                                                                          Cutstat + MV\n                        0.05                                     0.08                                      0.02                                           COSINE + MV\n                                                                                                                                                          Denoise + MV\n                        0.00                                     0.00                                      0.00                                           Weasel\n                        0.05                                     0.08                                      0.02\nFigure 6. Test performance for LM = MV, DM = RoBERTa. We compare a selected method from our design space (green) with four recent\nproposals from the literature. We plot all performances relative to that of vanilla training (see Table 8 for the absolute metrics). For this\nsetting, we did not run an exhaustive search over the whole design space so we do not report \u201cBest of Design Space.\u201d\nMLP Results. While fully fine-tuning RoBERTa end models provides better overall performance across text-based tasks,\nwe also provide results for MLP end models for completeness. Here, the best single-method across datasets was (one-time)\nconfidence thresholding + VAT + re-labeling. This method achieves the best point estimate on all 8 datasets compared to\nprevious baselines.\nMajority Voting Results. We also ablate the specific choice of label model to be Majority Voting for the RoBERTa\nexperiments. Here, we mostly use the same method as for when the label model is Snorkel. However, we found that\nswapping in cut-based thresholding tended to perform better than sticking with confidence-based. This behavior can perhaps\nbe explained by the relatively cruder confidence estimates for Majority Voting soft-labels; instead of learning a probabilistic\nmodel, the soft-labels for Majority Voting simply use the ratios of LF votes (e.g. for a binary task, if an example received 2\nnegative and 3 positive votes, the soft-label would be [0.4, 0.6]). Overall, we find that this method can least match previous\nbaselines on all datasets except Spouse. Notably though, the best overall performance on Spouse is still obtained by applying\nour design space on top of the Snorkel label model (see Tables 7 and 8).\n                                                                                                      14", "md": "# Additional Results for Baseline Comparisons\n\n## Additional Plots\n\n| |IMDb-MLP (Acc)|Yelp-MLP (Acc)|Youtube-MLP (Acc)|AGNews-MLP (Acc)|\n|---|---|---|---|---|\n|0.03| | | | |\n|0.02| | | | |\n|0.01| | | | |\n|0.00| | | | |\n|0.12| | | | |\n\nBest of Design Space: Cutstat + Snorkel, Denoise + Snorkel, Conf + VAT + Re-label (w/ DM), COSINE + Snorkel, Weasel\n\nFigure 5. Test performance for LM = Snorkel, DM = MLP. We compare a selected method from our design space (green) with four recent proposals from the literature. We plot all performances relative to that of vanilla training (see Table 6 for the absolute metrics)\n\n| |IMDb-BERT-MV (Acc)|Yelp-BERT-MV (Acc)|Youtube-BERT-MV (Acc)|AGNews-BERT-MV (Acc)|\n|---|---|---|---|---|\n|0.03| | | | |\n|0.02| | | | |\n|0.01| | | | |\n|0.00| | | | |\n|0.15| | | | |\n\nFigure 6. Test performance for LM = MV, DM = RoBERTa. We compare a selected method from our design space (green) with four recent proposals from the literature. We plot all performances relative to that of vanilla training (see Table 8 for the absolute metrics). For this setting, we did not run an exhaustive search over the whole design space so we do not report \u201cBest of Design Space.\u201d\n\nMLP Results. While fully fine-tuning RoBERTa end models provides better overall performance across text-based tasks, we also provide results for MLP end models for completeness. Here, the best single-method across datasets was (one-time) confidence thresholding + VAT + re-labeling. This method achieves the best point estimate on all 8 datasets compared to previous baselines.\n\nMajority Voting Results. We also ablate the specific choice of label model to be Majority Voting for the RoBERTa experiments. Here, we mostly use the same method as for when the label model is Snorkel. However, we found that swapping in cut-based thresholding tended to perform better than sticking with confidence-based. This behavior can perhaps be explained by the relatively cruder confidence estimates for Majority Voting soft-labels; instead of learning a probabilistic model, the soft-labels for Majority Voting simply use the ratios of LF votes (e.g. for a binary task, if an example received 2 negative and 3 positive votes, the soft-label would be [0.4, 0.6]). Overall, we find that this method can least match previous baselines on all datasets except Spouse. Notably though, the best overall performance on Spouse is still obtained by applying our design space on top of the Snorkel label model (see Tables 7 and 8).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Additional Results for Baseline Comparisons", "md": "# Additional Results for Baseline Comparisons"}, {"type": "heading", "lvl": 2, "value": "Additional Plots", "md": "## Additional Plots"}, {"type": "table", "rows": [["", "IMDb-MLP (Acc)", "Yelp-MLP (Acc)", "Youtube-MLP (Acc)", "AGNews-MLP (Acc)"], ["0.03", "", "", "", ""], ["0.02", "", "", "", ""], ["0.01", "", "", "", ""], ["0.00", "", "", "", ""], ["0.12", "", "", "", ""]], "md": "| |IMDb-MLP (Acc)|Yelp-MLP (Acc)|Youtube-MLP (Acc)|AGNews-MLP (Acc)|\n|---|---|---|---|---|\n|0.03| | | | |\n|0.02| | | | |\n|0.01| | | | |\n|0.00| | | | |\n|0.12| | | | |", "isPerfectTable": true, "csv": "\"\",\"IMDb-MLP (Acc)\",\"Yelp-MLP (Acc)\",\"Youtube-MLP (Acc)\",\"AGNews-MLP (Acc)\"\n\"0.03\",\"\",\"\",\"\",\"\"\n\"0.02\",\"\",\"\",\"\",\"\"\n\"0.01\",\"\",\"\",\"\",\"\"\n\"0.00\",\"\",\"\",\"\",\"\"\n\"0.12\",\"\",\"\",\"\",\"\""}, {"type": "text", "value": "Best of Design Space: Cutstat + Snorkel, Denoise + Snorkel, Conf + VAT + Re-label (w/ DM), COSINE + Snorkel, Weasel\n\nFigure 5. Test performance for LM = Snorkel, DM = MLP. We compare a selected method from our design space (green) with four recent proposals from the literature. We plot all performances relative to that of vanilla training (see Table 6 for the absolute metrics)", "md": "Best of Design Space: Cutstat + Snorkel, Denoise + Snorkel, Conf + VAT + Re-label (w/ DM), COSINE + Snorkel, Weasel\n\nFigure 5. Test performance for LM = Snorkel, DM = MLP. We compare a selected method from our design space (green) with four recent proposals from the literature. We plot all performances relative to that of vanilla training (see Table 6 for the absolute metrics)"}, {"type": "table", "rows": [["", "IMDb-BERT-MV (Acc)", "Yelp-BERT-MV (Acc)", "Youtube-BERT-MV (Acc)", "AGNews-BERT-MV (Acc)"], ["0.03", "", "", "", ""], ["0.02", "", "", "", ""], ["0.01", "", "", "", ""], ["0.00", "", "", "", ""], ["0.15", "", "", "", ""]], "md": "| |IMDb-BERT-MV (Acc)|Yelp-BERT-MV (Acc)|Youtube-BERT-MV (Acc)|AGNews-BERT-MV (Acc)|\n|---|---|---|---|---|\n|0.03| | | | |\n|0.02| | | | |\n|0.01| | | | |\n|0.00| | | | |\n|0.15| | | | |", "isPerfectTable": true, "csv": "\"\",\"IMDb-BERT-MV (Acc)\",\"Yelp-BERT-MV (Acc)\",\"Youtube-BERT-MV (Acc)\",\"AGNews-BERT-MV (Acc)\"\n\"0.03\",\"\",\"\",\"\",\"\"\n\"0.02\",\"\",\"\",\"\",\"\"\n\"0.01\",\"\",\"\",\"\",\"\"\n\"0.00\",\"\",\"\",\"\",\"\"\n\"0.15\",\"\",\"\",\"\",\"\""}, {"type": "text", "value": "Figure 6. Test performance for LM = MV, DM = RoBERTa. We compare a selected method from our design space (green) with four recent proposals from the literature. We plot all performances relative to that of vanilla training (see Table 8 for the absolute metrics). For this setting, we did not run an exhaustive search over the whole design space so we do not report \u201cBest of Design Space.\u201d\n\nMLP Results. While fully fine-tuning RoBERTa end models provides better overall performance across text-based tasks, we also provide results for MLP end models for completeness. Here, the best single-method across datasets was (one-time) confidence thresholding + VAT + re-labeling. This method achieves the best point estimate on all 8 datasets compared to previous baselines.\n\nMajority Voting Results. We also ablate the specific choice of label model to be Majority Voting for the RoBERTa experiments. Here, we mostly use the same method as for when the label model is Snorkel. However, we found that swapping in cut-based thresholding tended to perform better than sticking with confidence-based. This behavior can perhaps be explained by the relatively cruder confidence estimates for Majority Voting soft-labels; instead of learning a probabilistic model, the soft-labels for Majority Voting simply use the ratios of LF votes (e.g. for a binary task, if an example received 2 negative and 3 positive votes, the soft-label would be [0.4, 0.6]). Overall, we find that this method can least match previous baselines on all datasets except Spouse. Notably though, the best overall performance on Spouse is still obtained by applying our design space on top of the Snorkel label model (see Tables 7 and 8).", "md": "Figure 6. Test performance for LM = MV, DM = RoBERTa. We compare a selected method from our design space (green) with four recent proposals from the literature. We plot all performances relative to that of vanilla training (see Table 8 for the absolute metrics). For this setting, we did not run an exhaustive search over the whole design space so we do not report \u201cBest of Design Space.\u201d\n\nMLP Results. While fully fine-tuning RoBERTa end models provides better overall performance across text-based tasks, we also provide results for MLP end models for completeness. Here, the best single-method across datasets was (one-time) confidence thresholding + VAT + re-labeling. This method achieves the best point estimate on all 8 datasets compared to previous baselines.\n\nMajority Voting Results. We also ablate the specific choice of label model to be Majority Voting for the RoBERTa experiments. Here, we mostly use the same method as for when the label model is Snorkel. However, we found that swapping in cut-based thresholding tended to perform better than sticking with confidence-based. This behavior can perhaps be explained by the relatively cruder confidence estimates for Majority Voting soft-labels; instead of learning a probabilistic model, the soft-labels for Majority Voting simply use the ratios of LF votes (e.g. for a binary task, if an example received 2 negative and 3 positive votes, the soft-label would be [0.4, 0.6]). Overall, we find that this method can least match previous baselines on all datasets except Spouse. Notably though, the best overall performance on Spouse is still obtained by applying our design space on top of the Snorkel label model (see Tables 7 and 8)."}]}, {"page": 15, "text": "                                 Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nB.2. Tables with Absolute Performance\n                                Method                IMDb        Yelp      Youtube       AGNews       TREC        Spouse     Chemprot       Census\n                                 Vanilla              0.828       0.917       0.925        0.854        0.623       0.228        0.544        0.511\n                                                      (0.001)    (0.001)     (0.004)       (0.002)     (0.004)     (0.013)      (0.002)       (0.012)\n                           Cutstat + Snorkel          0.827       0.913       0.919        0.865        0.662       0.228        0.553        0.587\n                                                      (0.002)    (0.001)     (0.005)       (0.001)     (0.017)     (0.003)      (0.004)       (0.001)\n                         Conf + VAT + Re-label        0.850       0.924       0.929        0.870        0.678       0.330        0.558        0.593\n                                                      (0.002)    (0.004)     (0.005)       (0.000)     (0.023)     (0.005)      (0.005)       (0.005)\n                          Best of Design Space        0.850       0.926       0.929        0.880        0.677       0.394        0.561        0.605\n                                                      (0.002)    (0.004)     (0.005)       (0.000)     (0.016)     (0.006)      (0.005)       (0.006)\n                       COSINE (MLP) + Snorkel         0.833       0.915       0.921        0.853        0.641       0.248        0.536        0.520\n                                                      (0.001)    (0.002)     (0.002)       (0.002)     (0.012)     (0.028)      (0.004)       (0.027)\n                       Denoise (MLP) + Snorkel        0.806       0.895       0.528        0.856        0.568       0.169        0.535        0.569\n                                                      (0.011)    (0.006)     (0.000)       (0.001)     (0.003)     (0.207)      (0.004)       (0.007)\n                             Weasel (MLP)             0.826       0.905       0.921        0.856        0.446       0.261        0.551        0.552\n                                                      (0.003)    (0.005)     (0.016)       (0.005)     (0.117)     (0.017)      (0.007)       (0.051)\nTable 6. Test performance for LM = Snorkel, DM = MLP. Blue referes to the best performance of a single method (i.e., excluding \u201cBest of\nDesign Space\u201d, which reports the best method per dataset) while bold refers to being within standard deviation error bars of the best\nmethod. Red indicates where \u201cBest of Design Space\u201d outperforms the best single method outside of error bars.\n                                      Method                    IMDb        Yelp      Youtube      AGNews        TREC       Spouse      Chemprot\n                                       Vanilla                  0.873       0.919       0.944        0.870        0.656      0.273        0.569\n                                                               (0.001)     (0.009)     (0.007)      (0.003)      (0.017)    (0.074)       (0.001)\n                                  Cutstat + Snorkel             0.869       0.943       0.953        0.882        0.703      0.242        0.584\n                                                               (0.015)     (0.006)     (0.002)      (0.001)      (0.017)    (0.016)       (0.004)\n                         Conf + ST (DM as LF) + Re-label        0.888       0.954       0.947        0.882        0.711      0.531        0.581\n                                                               (0.013)     (0.006)     (0.012)      (0.002)      (0.030)    (0.039)       (0.012)\n                                Best of Design Space            0.907       0.961       0.952        0.885        0.765      0.531        0.601\n                                                               (0.004)     (0.002)     (0.006)      (0.002)      (0.012)    (0.039)       (0.008)\n                          COSINE (RoBERTa) + Snorkel            0.875       0.942       0.944        0.875        0.675      0.311        0.580\n                                                               (0.008)     (0.001)     (0.010)      (0.002)      (0.002)    (0.048)      (0.005)\n                           Denoise (RoBERTa) + Snorkel          0.867       0.922       0.949        0.867        0.633      0.287        0.544\n                                                               (0.007)     (0.018)     (0.006)      (0.008)      (0.014)    (0.202)       (0.005)\n                                 Weasel (RoBERTa)               0.866       0.926       0.960        0.873        0.647      0.231        0.584\n                                                               (0.006)     (0.028)     (0.008)      (0.005)      (0.021)    (0.028)       (0.014)\nTable 7. Test performance for LM = Snorkel, DM = RoBERTa. Blue referes to the best performance of a single method (i.e., excluding\n\u201cBest of Design Space\u201d, which reports the best method per dataset) while bold refers to being within standard deviation error bars of the\nbest method. Red indicates where \u201cBest of Design Space\u201d outperforms the best single method outside of error bars.\n                                      Method                    IMDb         Yelp       Youtube      AGNews       TREC       Spouse      Chemprot\n                                      Vanilla                    0.862       0.906       0.959        0.870        0.667      0.247         0.572\n                                                                (0.010)     (0.020)     (0.010)       (0.004)     (0.013)     (0.049)      (0.010)\n                                   Cutstat + MV                  0.859       0.954       0.957        0.871        0.721      0.244         0.589\n                                                                (0.006)     (0.000)     (0.007)       (0.008)     (0.023)     (0.018)      (0.002)\n                        Cutstat + ST (DM as LF) + Re-label       0.882       0.954       0.969        0.882        0.743      0.347         0.606\n                                                                (0.007)     (0.004)     (0.004)       (0.004)     (0.049)     (0.052)      (0.004)\n                            COSINE (RoBERTa) + MV                0.882       0.945       0.956        0.876        0.702      0.431         0.589\n                                                                (0.007)     (0.004)     (0.009)       (0.002)     (0.018)     (0.034)      (0.011)\n                                   Denoise + MV                  0.866       0.905       0.956        0.873        0.678      0.172         0.576\n                                                                (0.013)     (0.029)     (0.010)       (0.006)     (0.025)     (0.205)      (0.010)\n                                Weasel (RoBERTa)                 0.866       0.926       0.960        0.873        0.647      0.231         0.584\n                                                                (0.006)     (0.028)     (0.008)       (0.005)     (0.021)     (0.028)      (0.014)\n                                        Table 8. Test performance for LM = Majority Voting, DM = RoBERTa.\n                                                                                    15", "md": "# Table Performance\n\n## Tables with Absolute Performance\n\n|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Census|\n|---|---|---|---|---|---|---|---|---|\n|Vanilla|0.828|0.917|0.925|0.854|0.623|0.228|0.544|0.511|\n|Cutstat + Snorkel|0.827|0.913|0.919|0.865|0.662|0.228|0.553|0.587|\n|Conf + VAT + Re-label|0.850|0.924|0.929|0.870|0.678|0.330|0.558|0.593|\n|Best of Design Space|0.850|0.926|0.929|0.880|0.677|0.394|0.561|0.605|\n|COSINE (MLP) + Snorkel|0.833|0.915|0.921|0.853|0.641|0.248|0.536|0.520|\n|Denoise (MLP) + Snorkel|0.806|0.895|0.528|0.856|0.568|0.169|0.535|0.569|\n|Weasel (MLP)|0.826|0.905|0.921|0.856|0.446|0.261|0.551|0.552|\n\nTable 6. Test performance for LM = Snorkel, DM = MLP. Blue refers to the best performance of a single method (i.e., excluding \"Best of Design Space\", which reports the best method per dataset) while bold refers to being within standard deviation error bars of the best method. Red indicates where \"Best of Design Space\" outperforms the best single method outside of error bars.\n\n|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|\n|---|---|---|---|---|---|---|---|\n|Vanilla|0.873|0.919|0.944|0.870|0.656|0.273|0.569|\n|Cutstat + Snorkel|0.869|0.943|0.953|0.882|0.703|0.242|0.584|\n|Conf + ST (DM as LF) + Re-label|0.888|0.954|0.947|0.882|0.711|0.531|0.581|\n|Best of Design Space|0.907|0.961|0.952|0.885|0.765|0.531|0.601|\n|COSINE (RoBERTa) + Snorkel|0.875|0.942|0.944|0.875|0.675|0.311|0.580|\n|Denoise (RoBERTa) + Snorkel|0.867|0.922|0.949|0.867|0.633|0.287|0.544|\n|Weasel (RoBERTa)|0.866|0.926|0.960|0.873|0.647|0.231|0.584|\n\nTable 7. Test performance for LM = Snorkel, DM = RoBERTa. Blue refers to the best performance of a single method (i.e., excluding \"Best of Design Space\", which reports the best method per dataset) while bold refers to being within standard deviation error bars of the best method. Red indicates where \"Best of Design Space\" outperforms the best single method outside of error bars.\n\n|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|\n|---|---|---|---|---|---|---|---|\n|Vanilla|0.862|0.906|0.959|0.870|0.667|0.247|0.572|\n|Cutstat + MV|0.859|0.954|0.957|0.871|0.721|0.244|0.589|\n|Cutstat + ST (DM as LF) + Re-label|0.882|0.954|0.969|0.882|0.743|0.347|0.606|\n|COSINE (RoBERTa) + MV|0.882|0.945|0.956|0.876|0.702|0.431|0.589|\n|Denoise + MV|0.866|0.905|0.956|0.873|0.678|0.172|0.576|\n|Weasel (RoBERTa)|0.866|0.926|0.960|0.873|0.647|0.231|0.584|\n\nTable 8. Test performance for LM = Majority Voting, DM = RoBERTa.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Table Performance", "md": "# Table Performance"}, {"type": "heading", "lvl": 2, "value": "Tables with Absolute Performance", "md": "## Tables with Absolute Performance"}, {"type": "table", "rows": [["Method", "IMDb", "Yelp", "Youtube", "AGNews", "TREC", "Spouse", "Chemprot", "Census"], ["Vanilla", "0.828", "0.917", "0.925", "0.854", "0.623", "0.228", "0.544", "0.511"], ["Cutstat + Snorkel", "0.827", "0.913", "0.919", "0.865", "0.662", "0.228", "0.553", "0.587"], ["Conf + VAT + Re-label", "0.850", "0.924", "0.929", "0.870", "0.678", "0.330", "0.558", "0.593"], ["Best of Design Space", "0.850", "0.926", "0.929", "0.880", "0.677", "0.394", "0.561", "0.605"], ["COSINE (MLP) + Snorkel", "0.833", "0.915", "0.921", "0.853", "0.641", "0.248", "0.536", "0.520"], ["Denoise (MLP) + Snorkel", "0.806", "0.895", "0.528", "0.856", "0.568", "0.169", "0.535", "0.569"], ["Weasel (MLP)", "0.826", "0.905", "0.921", "0.856", "0.446", "0.261", "0.551", "0.552"]], "md": "|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Census|\n|---|---|---|---|---|---|---|---|---|\n|Vanilla|0.828|0.917|0.925|0.854|0.623|0.228|0.544|0.511|\n|Cutstat + Snorkel|0.827|0.913|0.919|0.865|0.662|0.228|0.553|0.587|\n|Conf + VAT + Re-label|0.850|0.924|0.929|0.870|0.678|0.330|0.558|0.593|\n|Best of Design Space|0.850|0.926|0.929|0.880|0.677|0.394|0.561|0.605|\n|COSINE (MLP) + Snorkel|0.833|0.915|0.921|0.853|0.641|0.248|0.536|0.520|\n|Denoise (MLP) + Snorkel|0.806|0.895|0.528|0.856|0.568|0.169|0.535|0.569|\n|Weasel (MLP)|0.826|0.905|0.921|0.856|0.446|0.261|0.551|0.552|", "isPerfectTable": true, "csv": "\"Method\",\"IMDb\",\"Yelp\",\"Youtube\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\",\"Census\"\n\"Vanilla\",\"0.828\",\"0.917\",\"0.925\",\"0.854\",\"0.623\",\"0.228\",\"0.544\",\"0.511\"\n\"Cutstat + Snorkel\",\"0.827\",\"0.913\",\"0.919\",\"0.865\",\"0.662\",\"0.228\",\"0.553\",\"0.587\"\n\"Conf + VAT + Re-label\",\"0.850\",\"0.924\",\"0.929\",\"0.870\",\"0.678\",\"0.330\",\"0.558\",\"0.593\"\n\"Best of Design Space\",\"0.850\",\"0.926\",\"0.929\",\"0.880\",\"0.677\",\"0.394\",\"0.561\",\"0.605\"\n\"COSINE (MLP) + Snorkel\",\"0.833\",\"0.915\",\"0.921\",\"0.853\",\"0.641\",\"0.248\",\"0.536\",\"0.520\"\n\"Denoise (MLP) + Snorkel\",\"0.806\",\"0.895\",\"0.528\",\"0.856\",\"0.568\",\"0.169\",\"0.535\",\"0.569\"\n\"Weasel (MLP)\",\"0.826\",\"0.905\",\"0.921\",\"0.856\",\"0.446\",\"0.261\",\"0.551\",\"0.552\""}, {"type": "text", "value": "Table 6. Test performance for LM = Snorkel, DM = MLP. Blue refers to the best performance of a single method (i.e., excluding \"Best of Design Space\", which reports the best method per dataset) while bold refers to being within standard deviation error bars of the best method. Red indicates where \"Best of Design Space\" outperforms the best single method outside of error bars.", "md": "Table 6. Test performance for LM = Snorkel, DM = MLP. Blue refers to the best performance of a single method (i.e., excluding \"Best of Design Space\", which reports the best method per dataset) while bold refers to being within standard deviation error bars of the best method. Red indicates where \"Best of Design Space\" outperforms the best single method outside of error bars."}, {"type": "table", "rows": [["Method", "IMDb", "Yelp", "Youtube", "AGNews", "TREC", "Spouse", "Chemprot"], ["Vanilla", "0.873", "0.919", "0.944", "0.870", "0.656", "0.273", "0.569"], ["Cutstat + Snorkel", "0.869", "0.943", "0.953", "0.882", "0.703", "0.242", "0.584"], ["Conf + ST (DM as LF) + Re-label", "0.888", "0.954", "0.947", "0.882", "0.711", "0.531", "0.581"], ["Best of Design Space", "0.907", "0.961", "0.952", "0.885", "0.765", "0.531", "0.601"], ["COSINE (RoBERTa) + Snorkel", "0.875", "0.942", "0.944", "0.875", "0.675", "0.311", "0.580"], ["Denoise (RoBERTa) + Snorkel", "0.867", "0.922", "0.949", "0.867", "0.633", "0.287", "0.544"], ["Weasel (RoBERTa)", "0.866", "0.926", "0.960", "0.873", "0.647", "0.231", "0.584"]], "md": "|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|\n|---|---|---|---|---|---|---|---|\n|Vanilla|0.873|0.919|0.944|0.870|0.656|0.273|0.569|\n|Cutstat + Snorkel|0.869|0.943|0.953|0.882|0.703|0.242|0.584|\n|Conf + ST (DM as LF) + Re-label|0.888|0.954|0.947|0.882|0.711|0.531|0.581|\n|Best of Design Space|0.907|0.961|0.952|0.885|0.765|0.531|0.601|\n|COSINE (RoBERTa) + Snorkel|0.875|0.942|0.944|0.875|0.675|0.311|0.580|\n|Denoise (RoBERTa) + Snorkel|0.867|0.922|0.949|0.867|0.633|0.287|0.544|\n|Weasel (RoBERTa)|0.866|0.926|0.960|0.873|0.647|0.231|0.584|", "isPerfectTable": true, "csv": "\"Method\",\"IMDb\",\"Yelp\",\"Youtube\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\"\n\"Vanilla\",\"0.873\",\"0.919\",\"0.944\",\"0.870\",\"0.656\",\"0.273\",\"0.569\"\n\"Cutstat + Snorkel\",\"0.869\",\"0.943\",\"0.953\",\"0.882\",\"0.703\",\"0.242\",\"0.584\"\n\"Conf + ST (DM as LF) + Re-label\",\"0.888\",\"0.954\",\"0.947\",\"0.882\",\"0.711\",\"0.531\",\"0.581\"\n\"Best of Design Space\",\"0.907\",\"0.961\",\"0.952\",\"0.885\",\"0.765\",\"0.531\",\"0.601\"\n\"COSINE (RoBERTa) + Snorkel\",\"0.875\",\"0.942\",\"0.944\",\"0.875\",\"0.675\",\"0.311\",\"0.580\"\n\"Denoise (RoBERTa) + Snorkel\",\"0.867\",\"0.922\",\"0.949\",\"0.867\",\"0.633\",\"0.287\",\"0.544\"\n\"Weasel (RoBERTa)\",\"0.866\",\"0.926\",\"0.960\",\"0.873\",\"0.647\",\"0.231\",\"0.584\""}, {"type": "text", "value": "Table 7. Test performance for LM = Snorkel, DM = RoBERTa. Blue refers to the best performance of a single method (i.e., excluding \"Best of Design Space\", which reports the best method per dataset) while bold refers to being within standard deviation error bars of the best method. Red indicates where \"Best of Design Space\" outperforms the best single method outside of error bars.", "md": "Table 7. Test performance for LM = Snorkel, DM = RoBERTa. Blue refers to the best performance of a single method (i.e., excluding \"Best of Design Space\", which reports the best method per dataset) while bold refers to being within standard deviation error bars of the best method. Red indicates where \"Best of Design Space\" outperforms the best single method outside of error bars."}, {"type": "table", "rows": [["Method", "IMDb", "Yelp", "Youtube", "AGNews", "TREC", "Spouse", "Chemprot"], ["Vanilla", "0.862", "0.906", "0.959", "0.870", "0.667", "0.247", "0.572"], ["Cutstat + MV", "0.859", "0.954", "0.957", "0.871", "0.721", "0.244", "0.589"], ["Cutstat + ST (DM as LF) + Re-label", "0.882", "0.954", "0.969", "0.882", "0.743", "0.347", "0.606"], ["COSINE (RoBERTa) + MV", "0.882", "0.945", "0.956", "0.876", "0.702", "0.431", "0.589"], ["Denoise + MV", "0.866", "0.905", "0.956", "0.873", "0.678", "0.172", "0.576"], ["Weasel (RoBERTa)", "0.866", "0.926", "0.960", "0.873", "0.647", "0.231", "0.584"]], "md": "|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|\n|---|---|---|---|---|---|---|---|\n|Vanilla|0.862|0.906|0.959|0.870|0.667|0.247|0.572|\n|Cutstat + MV|0.859|0.954|0.957|0.871|0.721|0.244|0.589|\n|Cutstat + ST (DM as LF) + Re-label|0.882|0.954|0.969|0.882|0.743|0.347|0.606|\n|COSINE (RoBERTa) + MV|0.882|0.945|0.956|0.876|0.702|0.431|0.589|\n|Denoise + MV|0.866|0.905|0.956|0.873|0.678|0.172|0.576|\n|Weasel (RoBERTa)|0.866|0.926|0.960|0.873|0.647|0.231|0.584|", "isPerfectTable": true, "csv": "\"Method\",\"IMDb\",\"Yelp\",\"Youtube\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\"\n\"Vanilla\",\"0.862\",\"0.906\",\"0.959\",\"0.870\",\"0.667\",\"0.247\",\"0.572\"\n\"Cutstat + MV\",\"0.859\",\"0.954\",\"0.957\",\"0.871\",\"0.721\",\"0.244\",\"0.589\"\n\"Cutstat + ST (DM as LF) + Re-label\",\"0.882\",\"0.954\",\"0.969\",\"0.882\",\"0.743\",\"0.347\",\"0.606\"\n\"COSINE (RoBERTa) + MV\",\"0.882\",\"0.945\",\"0.956\",\"0.876\",\"0.702\",\"0.431\",\"0.589\"\n\"Denoise + MV\",\"0.866\",\"0.905\",\"0.956\",\"0.873\",\"0.678\",\"0.172\",\"0.576\"\n\"Weasel (RoBERTa)\",\"0.866\",\"0.926\",\"0.960\",\"0.873\",\"0.647\",\"0.231\",\"0.584\""}, {"type": "text", "value": "Table 8. Test performance for LM = Majority Voting, DM = RoBERTa.", "md": "Table 8. Test performance for LM = Majority Voting, DM = RoBERTa."}]}, {"page": 16, "text": "                                 Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nC. Additional Ablation Results\nC.1. Axis Ablation for MLP\n                          Method                IMDb        Yelp      Youtube      AGNews        TREC       Spouse      Chemprot       Census    Mean\n                           Vanilla              0.828      0.917        0.925        0.854       0.623       0.228        0.544         0.511    0.679\n                                               (0.001)     (0.001)     (0.004)      (0.002)      (0.004)    (0.013)      (0.002)       (0.012)  (0.002)\n                        Thresh Alone            0.833      0.924        0.915        0.865       0.678       0.228        0.547         0.587    0.697\n                                               (0.002)     (0.002)     (0.002)      (0.001)      (0.027)    (0.003)      (0.004)       (0.001)  (0.003)\n                         SSL Alone              0.841      0.918        0.932        0.877       0.605       0.375        0.533         0.518    0.700\n                                               (0.004)     (0.002)     (0.000)      (0.001)      (0.008)    (0.029)      (0.003)       (0.015)  (0.004)\n                       Re-label Alone           0.833      0.924        0.917        0.862       0.631       0.243        0.549         0.526    0.686\n                                               (0.001)     (0.002)     (0.014)      (0.001)      (0.024)    (0.003)      (0.007)       (0.027)  (0.005)\n                        Thresh + SSL            0.838      0.926        0.929        0.878       0.691       0.394        0.560         0.605    0.728\n                                               (0.004)     (0.004)     (0.002)      (0.001)      (0.012)    (0.006)      (0.001)       (0.006)  (0.002)\n                      Thresh + Re-label         0.837      0.925        0.917        0.870       0.677       0.270        0.558         0.602    0.707\n                                               (0.002)     (0.003)     (0.007)      (0.001)      (0.016)    (0.007)      (0.002)       (0.002)  (0.002)\n                       SSL + Re-label           0.835      0.925        0.935        0.875       0.662       0.347        0.557         0.542    0.710\n                                               (0.001)     (0.006)     (0.005)      (0.002)      (0.011)    (0.043)      (0.004)       (0.025)  (0.006)\n                  Thresh + SSL + Re-label       0.850      0.930        0.929        0.880       0.671       0.347        0.561         0.606    0.722\n                                               (0.002)     (0.001)     (0.005)      (0.000)      (0.034)    (0.043)      (0.005)       (0.001)  (0.007)\n                    Entire Design Space         0.850      0.926        0.929        0.880       0.677       0.394        0.561         0.605    0.728\n                                               (0.002)     (0.004)     (0.005)      (0.000)      (0.016)    (0.006)      (0.005)       (0.006)  (0.002)\nTable 9. Test performance for LM = Snorkel, DM = MLP. Each row corresponds to picking a specific method within our design space\nusing validation tuning. Numbers in blue are the highest for any given dataset, while numbers in bold are those within error bars of the\nbest result.\nC.2. Axis Instantiations for RoBERTa\n                                                                 IMDb        Yelp       AGNews       TREC       Spouse      Chemprot\n                                          Best w/o SSL           0.906       0.961       0.884        0.748      0.336         0.600\n                                                                 (0.005)    (0.002)      (0.003)     (0.023)     (0.095)      (0.006)\n                                           Best w/ EM            0.893       0.956       0.885        0.746      0.283         0.601\n                                                                 (0.011)    (0.001)      (0.001)     (0.043)     (0.083)      (0.009)\n                                          Best w/ VAT            0.900       0.952       0.885        0.753      0.244         0.608\n                                                                 (0.005)    (0.005)      (0.003)     (0.021)     (0.040)      (0.003)\n                                           Best w/ ST            0.907       0.961       0.887        0.765      0.392         0.601\n                                                                 (0.004)    (0.003)      (0.005)     (0.012)     (0.098)      (0.005)\n                                     Best w/ ST (DM as LF)       0.889       0.958       0.885        0.725      0.531         0.601\n                                                                 (0.004)    (0.003)      (0.003)     (0.018)     (0.039)      (0.008)\nTable 10. Details of the SSL axis for DM = RoBERTa. We report the highest performing method that incorporates a given SSL technique,\nselected by validation performance.\n                                                             IMDb        Yelp      AGNews        TREC       Spouse      Chemprot\n                                         No Re-labeling      0.885       0.959       0.887        0.732      0.529         0.592\n                                                             (0.018)    (0.002)     (0.005)      (0.014)    (0.057)       (0.005)\n                                           Re-labeling       0.907       0.961       0.885        0.765      0.532         0.601\n                                                             (0.004)    (0.002)     (0.003)      (0.012)    (0.039)       (0.005)\nTable 11. Details on whether re-labeling is useful for DM = RoBERTa. We report the highest performing method that either incorporates\nor does not incorporate re-labeling, selected by validation performance.\n                                                                                    16", "md": "# OCR Text\n\n## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n### C. Additional Ablation Results\n\n#### C.1. Axis Ablation for MLP\n\n|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Census|Mean|\n|---|---|---|---|---|---|---|---|---|---|\n|Vanilla|0.828|0.917|0.925|0.854|0.623|0.228|0.544|0.511|0.679|\n|Thresh Alone|0.833|0.924|0.915|0.865|0.678|0.228|0.547|0.587|0.697|\n|SSL Alone|0.841|0.918|0.932|0.877|0.605|0.375|0.533|0.518|0.700|\n|Re-label Alone|0.833|0.924|0.917|0.862|0.631|0.243|0.549|0.526|0.686|\n|Thresh + SSL|0.838|0.926|0.929|0.878|0.691|0.394|0.560|0.605|0.728|\n|Thresh + Re-label|0.837|0.925|0.917|0.870|0.677|0.270|0.558|0.602|0.707|\n|SSL + Re-label|0.835|0.925|0.935|0.875|0.662|0.347|0.557|0.542|0.710|\n|Thresh + SSL + Re-label|0.850|0.930|0.929|0.880|0.671|0.347|0.561|0.606|0.722|\n|Entire Design Space|0.850|0.926|0.929|0.880|0.677|0.394|0.561|0.605|0.728|\n\nTable 9. Test performance for LM = Snorkel, DM = MLP. Each row corresponds to picking a specific method within our design space using validation tuning. Numbers in blue are the highest for any given dataset, while numbers in bold are those within error bars of the best result.\n\n#### C.2. Axis Instantiations for RoBERTa\n\n| |IMDb|Yelp|AGNews|TREC|Spouse|Chemprot|\n|---|---|---|---|---|---|---|\n|Best w/o SSL|0.906|0.961|0.884|0.748|0.336|0.600|\n|Best w/ EM|0.893|0.956|0.885|0.746|0.283|0.601|\n|Best w/ VAT|0.900|0.952|0.885|0.753|0.244|0.608|\n|Best w/ ST|0.907|0.961|0.887|0.765|0.392|0.601|\n|Best w/ ST (DM as LF)|0.889|0.958|0.885|0.725|0.531|0.601|\n\nTable 10. Details of the SSL axis for DM = RoBERTa. We report the highest performing method that incorporates a given SSL technique, selected by validation performance.\n\n| |IMDb|Yelp|AGNews|TREC|Spouse|Chemprot|\n|---|---|---|---|---|---|---|\n|No Re-labeling|0.885|0.959|0.887|0.732|0.529|0.592|\n|Re-labeling|0.907|0.961|0.885|0.765|0.532|0.601|\n\nTable 11. Details on whether re-labeling is useful for DM = RoBERTa. We report the highest performing method that either incorporates or does not incorporate re-labeling, selected by validation performance.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "OCR Text", "md": "# OCR Text"}, {"type": "heading", "lvl": 2, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 3, "value": "C. Additional Ablation Results", "md": "### C. Additional Ablation Results"}, {"type": "heading", "lvl": 4, "value": "C.1. Axis Ablation for MLP", "md": "#### C.1. Axis Ablation for MLP"}, {"type": "table", "rows": [["Method", "IMDb", "Yelp", "Youtube", "AGNews", "TREC", "Spouse", "Chemprot", "Census", "Mean"], ["Vanilla", "0.828", "0.917", "0.925", "0.854", "0.623", "0.228", "0.544", "0.511", "0.679"], ["Thresh Alone", "0.833", "0.924", "0.915", "0.865", "0.678", "0.228", "0.547", "0.587", "0.697"], ["SSL Alone", "0.841", "0.918", "0.932", "0.877", "0.605", "0.375", "0.533", "0.518", "0.700"], ["Re-label Alone", "0.833", "0.924", "0.917", "0.862", "0.631", "0.243", "0.549", "0.526", "0.686"], ["Thresh + SSL", "0.838", "0.926", "0.929", "0.878", "0.691", "0.394", "0.560", "0.605", "0.728"], ["Thresh + Re-label", "0.837", "0.925", "0.917", "0.870", "0.677", "0.270", "0.558", "0.602", "0.707"], ["SSL + Re-label", "0.835", "0.925", "0.935", "0.875", "0.662", "0.347", "0.557", "0.542", "0.710"], ["Thresh + SSL + Re-label", "0.850", "0.930", "0.929", "0.880", "0.671", "0.347", "0.561", "0.606", "0.722"], ["Entire Design Space", "0.850", "0.926", "0.929", "0.880", "0.677", "0.394", "0.561", "0.605", "0.728"]], "md": "|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Census|Mean|\n|---|---|---|---|---|---|---|---|---|---|\n|Vanilla|0.828|0.917|0.925|0.854|0.623|0.228|0.544|0.511|0.679|\n|Thresh Alone|0.833|0.924|0.915|0.865|0.678|0.228|0.547|0.587|0.697|\n|SSL Alone|0.841|0.918|0.932|0.877|0.605|0.375|0.533|0.518|0.700|\n|Re-label Alone|0.833|0.924|0.917|0.862|0.631|0.243|0.549|0.526|0.686|\n|Thresh + SSL|0.838|0.926|0.929|0.878|0.691|0.394|0.560|0.605|0.728|\n|Thresh + Re-label|0.837|0.925|0.917|0.870|0.677|0.270|0.558|0.602|0.707|\n|SSL + Re-label|0.835|0.925|0.935|0.875|0.662|0.347|0.557|0.542|0.710|\n|Thresh + SSL + Re-label|0.850|0.930|0.929|0.880|0.671|0.347|0.561|0.606|0.722|\n|Entire Design Space|0.850|0.926|0.929|0.880|0.677|0.394|0.561|0.605|0.728|", "isPerfectTable": true, "csv": "\"Method\",\"IMDb\",\"Yelp\",\"Youtube\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\",\"Census\",\"Mean\"\n\"Vanilla\",\"0.828\",\"0.917\",\"0.925\",\"0.854\",\"0.623\",\"0.228\",\"0.544\",\"0.511\",\"0.679\"\n\"Thresh Alone\",\"0.833\",\"0.924\",\"0.915\",\"0.865\",\"0.678\",\"0.228\",\"0.547\",\"0.587\",\"0.697\"\n\"SSL Alone\",\"0.841\",\"0.918\",\"0.932\",\"0.877\",\"0.605\",\"0.375\",\"0.533\",\"0.518\",\"0.700\"\n\"Re-label Alone\",\"0.833\",\"0.924\",\"0.917\",\"0.862\",\"0.631\",\"0.243\",\"0.549\",\"0.526\",\"0.686\"\n\"Thresh + SSL\",\"0.838\",\"0.926\",\"0.929\",\"0.878\",\"0.691\",\"0.394\",\"0.560\",\"0.605\",\"0.728\"\n\"Thresh + Re-label\",\"0.837\",\"0.925\",\"0.917\",\"0.870\",\"0.677\",\"0.270\",\"0.558\",\"0.602\",\"0.707\"\n\"SSL + Re-label\",\"0.835\",\"0.925\",\"0.935\",\"0.875\",\"0.662\",\"0.347\",\"0.557\",\"0.542\",\"0.710\"\n\"Thresh + SSL + Re-label\",\"0.850\",\"0.930\",\"0.929\",\"0.880\",\"0.671\",\"0.347\",\"0.561\",\"0.606\",\"0.722\"\n\"Entire Design Space\",\"0.850\",\"0.926\",\"0.929\",\"0.880\",\"0.677\",\"0.394\",\"0.561\",\"0.605\",\"0.728\""}, {"type": "text", "value": "Table 9. Test performance for LM = Snorkel, DM = MLP. Each row corresponds to picking a specific method within our design space using validation tuning. Numbers in blue are the highest for any given dataset, while numbers in bold are those within error bars of the best result.", "md": "Table 9. Test performance for LM = Snorkel, DM = MLP. Each row corresponds to picking a specific method within our design space using validation tuning. Numbers in blue are the highest for any given dataset, while numbers in bold are those within error bars of the best result."}, {"type": "heading", "lvl": 4, "value": "C.2. Axis Instantiations for RoBERTa", "md": "#### C.2. Axis Instantiations for RoBERTa"}, {"type": "table", "rows": [["", "IMDb", "Yelp", "AGNews", "TREC", "Spouse", "Chemprot"], ["Best w/o SSL", "0.906", "0.961", "0.884", "0.748", "0.336", "0.600"], ["Best w/ EM", "0.893", "0.956", "0.885", "0.746", "0.283", "0.601"], ["Best w/ VAT", "0.900", "0.952", "0.885", "0.753", "0.244", "0.608"], ["Best w/ ST", "0.907", "0.961", "0.887", "0.765", "0.392", "0.601"], ["Best w/ ST (DM as LF)", "0.889", "0.958", "0.885", "0.725", "0.531", "0.601"]], "md": "| |IMDb|Yelp|AGNews|TREC|Spouse|Chemprot|\n|---|---|---|---|---|---|---|\n|Best w/o SSL|0.906|0.961|0.884|0.748|0.336|0.600|\n|Best w/ EM|0.893|0.956|0.885|0.746|0.283|0.601|\n|Best w/ VAT|0.900|0.952|0.885|0.753|0.244|0.608|\n|Best w/ ST|0.907|0.961|0.887|0.765|0.392|0.601|\n|Best w/ ST (DM as LF)|0.889|0.958|0.885|0.725|0.531|0.601|", "isPerfectTable": true, "csv": "\"\",\"IMDb\",\"Yelp\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\"\n\"Best w/o SSL\",\"0.906\",\"0.961\",\"0.884\",\"0.748\",\"0.336\",\"0.600\"\n\"Best w/ EM\",\"0.893\",\"0.956\",\"0.885\",\"0.746\",\"0.283\",\"0.601\"\n\"Best w/ VAT\",\"0.900\",\"0.952\",\"0.885\",\"0.753\",\"0.244\",\"0.608\"\n\"Best w/ ST\",\"0.907\",\"0.961\",\"0.887\",\"0.765\",\"0.392\",\"0.601\"\n\"Best w/ ST (DM as LF)\",\"0.889\",\"0.958\",\"0.885\",\"0.725\",\"0.531\",\"0.601\""}, {"type": "text", "value": "Table 10. Details of the SSL axis for DM = RoBERTa. We report the highest performing method that incorporates a given SSL technique, selected by validation performance.", "md": "Table 10. Details of the SSL axis for DM = RoBERTa. We report the highest performing method that incorporates a given SSL technique, selected by validation performance."}, {"type": "table", "rows": [["", "IMDb", "Yelp", "AGNews", "TREC", "Spouse", "Chemprot"], ["No Re-labeling", "0.885", "0.959", "0.887", "0.732", "0.529", "0.592"], ["Re-labeling", "0.907", "0.961", "0.885", "0.765", "0.532", "0.601"]], "md": "| |IMDb|Yelp|AGNews|TREC|Spouse|Chemprot|\n|---|---|---|---|---|---|---|\n|No Re-labeling|0.885|0.959|0.887|0.732|0.529|0.592|\n|Re-labeling|0.907|0.961|0.885|0.765|0.532|0.601|", "isPerfectTable": true, "csv": "\"\",\"IMDb\",\"Yelp\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\"\n\"No Re-labeling\",\"0.885\",\"0.959\",\"0.887\",\"0.732\",\"0.529\",\"0.592\"\n\"Re-labeling\",\"0.907\",\"0.961\",\"0.885\",\"0.765\",\"0.532\",\"0.601\""}, {"type": "text", "value": "Table 11. Details on whether re-labeling is useful for DM = RoBERTa. We report the highest performing method that either incorporates or does not incorporate re-labeling, selected by validation performance.", "md": "Table 11. Details on whether re-labeling is useful for DM = RoBERTa. We report the highest performing method that either incorporates or does not incorporate re-labeling, selected by validation performance."}]}, {"page": 17, "text": "                                Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n C.2.1. AXIS INSTANTIATIONS FOR MLPS\n                                Method      IMDb        Yelp      Youtube      AGNews       TREC       Spouse     Chemprot       Census\n                                  Cov        0.841      0.925       0.935       0.877        0.662      0.375        0.557        0.542\n                                            (0.004)    (0.006)     (0.005)      (0.001)     (0.011)    (0.029)      (0.004)      (0.025)\n                                  Cut        0.832      0.930       0.935       0.880        0.684      0.394        0.566        0.606\n                                            (0.002)    (0.001)     (0.002)      (0.000)     (0.016)    (0.015)      (0.003)      (0.001)\n                                 Conf        0.850      0.928       0.929       0.878        0.691      0.417        0.560        0.592\n                                            (0.002)    (0.002)     (0.005)      (0.002)     (0.012)    (0.009)      (0.011)      (0.008)\nTable 12. Details of the thresholding axis for DM = MLP. \u201cBest with\u201d represents the highest performing method that incorporates a given\n thresholding method, selected by validation tuning.\n                                Method              IMDb        Yelp     Youtube      AGNews       TREC       Spouse      Chemprot      Census\n                             Best w/o SSL           0.837      0.927       0.935        0.870       0.684      0.270        0.560        0.602\n                                                   (0.002)    (0.001)     (0.002)      (0.001)     (0.016)    (0.007)      (0.011)      (0.002)\n                              Best w/ VAT           0.850      0.926       0.935        0.880       0.691      0.355        0.563        0.605\n                                                   (0.002)    (0.002)     (0.005)      (0.000)     (0.012)    (0.015)      (0.007)      (0.006)\n                              Best w/ EM            0.835      0.922       0.925        0.869       0.664      0.268        0.560        0.595\n                                                   (0.001)    (0.001)     (0.002)      (0.002)     (0.007)    (0.032)      (0.009)      (0.004)\n                              Best w/ ST            0.838      0.928       0.929        0.866       0.674      0.379        0.566        0.592\n                                                   (0.001)    (0.002)     (0.005)      (0.001)     (0.018)    (0.008)      (0.003)      (0.002)\n                        Best w/ ST (DM as LF)       0.834      0.930       0.935        0.869       0.668      0.417        0.561        0.606\n                                                   (0.001)    (0.001)     (0.002)      (0.000)     (0.038)    (0.009)      (0.005)      (0.001)\nTable 13. Details of the SSL axis for DM = MLP. We report the highest performing method that incorporates a given SSL method, selected\n by validation tuning.\n                                                                                  17", "md": "# Impacts of Semi-supervised Learning for Weak Supervision\n\n## AXIS INSTANTIATIONS FOR MLPS\n\n|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Census|\n|---|---|---|---|---|---|---|---|---|\n|Cov|0.841|0.925|0.935|0.877|0.662|0.375|0.557|0.542|\n| |(0.004)|(0.006)|(0.005)|(0.001)|(0.011)|(0.029)|(0.004)|(0.025)|\n|Cut|0.832|0.930|0.935|0.880|0.684|0.394|0.566|0.606|\n| |(0.002)|(0.001)|(0.002)|(0.000)|(0.016)|(0.015)|(0.003)|(0.001)|\n|Conf|0.850|0.928|0.929|0.878|0.691|0.417|0.560|0.592|\n| |(0.002)|(0.002)|(0.005)|(0.002)|(0.012)|(0.009)|(0.011)|(0.008)|\n\nTable 12. Details of the thresholding axis for DM = MLP. \"Best with\" represents the highest performing method that incorporates a given thresholding method, selected by validation tuning.\n\n|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Census|\n|---|---|---|---|---|---|---|---|---|\n|Best w/o SSL|0.837|0.927|0.935|0.870|0.684|0.270|0.560|0.602|\n| |(0.002)|(0.001)|(0.002)|(0.001)|(0.016)|(0.007)|(0.011)|(0.002)|\n|Best w/ VAT|0.850|0.926|0.935|0.880|0.691|0.355|0.563|0.605|\n| |(0.002)|(0.002)|(0.005)|(0.000)|(0.012)|(0.015)|(0.007)|(0.006)|\n|Best w/ EM|0.835|0.922|0.925|0.869|0.664|0.268|0.560|0.595|\n| |(0.001)|(0.001)|(0.002)|(0.002)|(0.007)|(0.032)|(0.009)|(0.004)|\n|Best w/ ST|0.838|0.928|0.929|0.866|0.674|0.379|0.566|0.592|\n| |(0.001)|(0.002)|(0.005)|(0.001)|(0.018)|(0.008)|(0.003)|(0.002)|\n|Best w/ ST (DM as LF)|0.834|0.930|0.935|0.869|0.668|0.417|0.561|0.606|\n| |(0.001)|(0.001)|(0.002)|(0.000)|(0.038)|(0.009)|(0.005)|(0.001)|\n\nTable 13. Details of the SSL axis for DM = MLP. We report the highest performing method that incorporates a given SSL method, selected by validation tuning.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "AXIS INSTANTIATIONS FOR MLPS", "md": "## AXIS INSTANTIATIONS FOR MLPS"}, {"type": "table", "rows": [["Method", "IMDb", "Yelp", "Youtube", "AGNews", "TREC", "Spouse", "Chemprot", "Census"], ["Cov", "0.841", "0.925", "0.935", "0.877", "0.662", "0.375", "0.557", "0.542"], ["", "(0.004)", "(0.006)", "(0.005)", "(0.001)", "(0.011)", "(0.029)", "(0.004)", "(0.025)"], ["Cut", "0.832", "0.930", "0.935", "0.880", "0.684", "0.394", "0.566", "0.606"], ["", "(0.002)", "(0.001)", "(0.002)", "(0.000)", "(0.016)", "(0.015)", "(0.003)", "(0.001)"], ["Conf", "0.850", "0.928", "0.929", "0.878", "0.691", "0.417", "0.560", "0.592"], ["", "(0.002)", "(0.002)", "(0.005)", "(0.002)", "(0.012)", "(0.009)", "(0.011)", "(0.008)"]], "md": "|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Census|\n|---|---|---|---|---|---|---|---|---|\n|Cov|0.841|0.925|0.935|0.877|0.662|0.375|0.557|0.542|\n| |(0.004)|(0.006)|(0.005)|(0.001)|(0.011)|(0.029)|(0.004)|(0.025)|\n|Cut|0.832|0.930|0.935|0.880|0.684|0.394|0.566|0.606|\n| |(0.002)|(0.001)|(0.002)|(0.000)|(0.016)|(0.015)|(0.003)|(0.001)|\n|Conf|0.850|0.928|0.929|0.878|0.691|0.417|0.560|0.592|\n| |(0.002)|(0.002)|(0.005)|(0.002)|(0.012)|(0.009)|(0.011)|(0.008)|", "isPerfectTable": true, "csv": "\"Method\",\"IMDb\",\"Yelp\",\"Youtube\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\",\"Census\"\n\"Cov\",\"0.841\",\"0.925\",\"0.935\",\"0.877\",\"0.662\",\"0.375\",\"0.557\",\"0.542\"\n\"\",\"(0.004)\",\"(0.006)\",\"(0.005)\",\"(0.001)\",\"(0.011)\",\"(0.029)\",\"(0.004)\",\"(0.025)\"\n\"Cut\",\"0.832\",\"0.930\",\"0.935\",\"0.880\",\"0.684\",\"0.394\",\"0.566\",\"0.606\"\n\"\",\"(0.002)\",\"(0.001)\",\"(0.002)\",\"(0.000)\",\"(0.016)\",\"(0.015)\",\"(0.003)\",\"(0.001)\"\n\"Conf\",\"0.850\",\"0.928\",\"0.929\",\"0.878\",\"0.691\",\"0.417\",\"0.560\",\"0.592\"\n\"\",\"(0.002)\",\"(0.002)\",\"(0.005)\",\"(0.002)\",\"(0.012)\",\"(0.009)\",\"(0.011)\",\"(0.008)\""}, {"type": "text", "value": "Table 12. Details of the thresholding axis for DM = MLP. \"Best with\" represents the highest performing method that incorporates a given thresholding method, selected by validation tuning.", "md": "Table 12. Details of the thresholding axis for DM = MLP. \"Best with\" represents the highest performing method that incorporates a given thresholding method, selected by validation tuning."}, {"type": "table", "rows": [["Method", "IMDb", "Yelp", "Youtube", "AGNews", "TREC", "Spouse", "Chemprot", "Census"], ["Best w/o SSL", "0.837", "0.927", "0.935", "0.870", "0.684", "0.270", "0.560", "0.602"], ["", "(0.002)", "(0.001)", "(0.002)", "(0.001)", "(0.016)", "(0.007)", "(0.011)", "(0.002)"], ["Best w/ VAT", "0.850", "0.926", "0.935", "0.880", "0.691", "0.355", "0.563", "0.605"], ["", "(0.002)", "(0.002)", "(0.005)", "(0.000)", "(0.012)", "(0.015)", "(0.007)", "(0.006)"], ["Best w/ EM", "0.835", "0.922", "0.925", "0.869", "0.664", "0.268", "0.560", "0.595"], ["", "(0.001)", "(0.001)", "(0.002)", "(0.002)", "(0.007)", "(0.032)", "(0.009)", "(0.004)"], ["Best w/ ST", "0.838", "0.928", "0.929", "0.866", "0.674", "0.379", "0.566", "0.592"], ["", "(0.001)", "(0.002)", "(0.005)", "(0.001)", "(0.018)", "(0.008)", "(0.003)", "(0.002)"], ["Best w/ ST (DM as LF)", "0.834", "0.930", "0.935", "0.869", "0.668", "0.417", "0.561", "0.606"], ["", "(0.001)", "(0.001)", "(0.002)", "(0.000)", "(0.038)", "(0.009)", "(0.005)", "(0.001)"]], "md": "|Method|IMDb|Yelp|Youtube|AGNews|TREC|Spouse|Chemprot|Census|\n|---|---|---|---|---|---|---|---|---|\n|Best w/o SSL|0.837|0.927|0.935|0.870|0.684|0.270|0.560|0.602|\n| |(0.002)|(0.001)|(0.002)|(0.001)|(0.016)|(0.007)|(0.011)|(0.002)|\n|Best w/ VAT|0.850|0.926|0.935|0.880|0.691|0.355|0.563|0.605|\n| |(0.002)|(0.002)|(0.005)|(0.000)|(0.012)|(0.015)|(0.007)|(0.006)|\n|Best w/ EM|0.835|0.922|0.925|0.869|0.664|0.268|0.560|0.595|\n| |(0.001)|(0.001)|(0.002)|(0.002)|(0.007)|(0.032)|(0.009)|(0.004)|\n|Best w/ ST|0.838|0.928|0.929|0.866|0.674|0.379|0.566|0.592|\n| |(0.001)|(0.002)|(0.005)|(0.001)|(0.018)|(0.008)|(0.003)|(0.002)|\n|Best w/ ST (DM as LF)|0.834|0.930|0.935|0.869|0.668|0.417|0.561|0.606|\n| |(0.001)|(0.001)|(0.002)|(0.000)|(0.038)|(0.009)|(0.005)|(0.001)|", "isPerfectTable": true, "csv": "\"Method\",\"IMDb\",\"Yelp\",\"Youtube\",\"AGNews\",\"TREC\",\"Spouse\",\"Chemprot\",\"Census\"\n\"Best w/o SSL\",\"0.837\",\"0.927\",\"0.935\",\"0.870\",\"0.684\",\"0.270\",\"0.560\",\"0.602\"\n\"\",\"(0.002)\",\"(0.001)\",\"(0.002)\",\"(0.001)\",\"(0.016)\",\"(0.007)\",\"(0.011)\",\"(0.002)\"\n\"Best w/ VAT\",\"0.850\",\"0.926\",\"0.935\",\"0.880\",\"0.691\",\"0.355\",\"0.563\",\"0.605\"\n\"\",\"(0.002)\",\"(0.002)\",\"(0.005)\",\"(0.000)\",\"(0.012)\",\"(0.015)\",\"(0.007)\",\"(0.006)\"\n\"Best w/ EM\",\"0.835\",\"0.922\",\"0.925\",\"0.869\",\"0.664\",\"0.268\",\"0.560\",\"0.595\"\n\"\",\"(0.001)\",\"(0.001)\",\"(0.002)\",\"(0.002)\",\"(0.007)\",\"(0.032)\",\"(0.009)\",\"(0.004)\"\n\"Best w/ ST\",\"0.838\",\"0.928\",\"0.929\",\"0.866\",\"0.674\",\"0.379\",\"0.566\",\"0.592\"\n\"\",\"(0.001)\",\"(0.002)\",\"(0.005)\",\"(0.001)\",\"(0.018)\",\"(0.008)\",\"(0.003)\",\"(0.002)\"\n\"Best w/ ST (DM as LF)\",\"0.834\",\"0.930\",\"0.935\",\"0.869\",\"0.668\",\"0.417\",\"0.561\",\"0.606\"\n\"\",\"(0.001)\",\"(0.001)\",\"(0.002)\",\"(0.000)\",\"(0.038)\",\"(0.009)\",\"(0.005)\",\"(0.001)\""}, {"type": "text", "value": "Table 13. Details of the SSL axis for DM = MLP. We report the highest performing method that incorporates a given SSL method, selected by validation tuning.", "md": "Table 13. Details of the SSL axis for DM = MLP. We report the highest performing method that incorporates a given SSL method, selected by validation tuning."}]}, {"page": 18, "text": "                         Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nD. Beyond standard WS benchmarks: datasets for coverage ablations\nD.1. LF subsampling and procedural generation on existing WRENCH datasets\nOverall, WS benchmarks lack agreed-upon ways to explore different LF coverage/precision trade-offs. In this work, we\nchoose to do so by sub-sampling LFs from an overall base set. However, the default LF sets associated with WS benchmarks\nare not equally as suitable to subsample from. In particular, we are wary about subsampling default LF sets when they:\n (1) Contain very few LFs, which reduces the possible granularities of subsampling\n (2) Contain LFs which are heterogeneous or have untracked lineages (e.g., \u03bb1 closely relates to or was only provided in\n     response to another LF \u03bb2).\nFor datsets where we subsample directly, we choose ones with both larger LF counts and where all LFs are of the same form.\nThis includes:\n   \u2022 Semeval: 164 string-matching rules selected by humans from an automated candidate generation procedure (Zhou\n     et al., 2020)\n   \u2022 Chemprot: 26 individual keyword-based rules (Yu et al., 2021)\nThese contrast with LF sets that are far smaller, more heterogeneous, or have unclear dependencies. For these datasets, we\ninstead procedurally generate LFs using the tools from WRENCH (Zhang et al., 2021)\n   \u2022 IMDb:      4 aggregate keyword based rules (i.e., each LF checks for the presence of any of multiple keywords), 1\n     expression-based rule (Ren et al., 2020)\n   \u2022 Yelp: 7 heuristic rules on keywords, 1 third-party model on polarity of sentiment (Ren et al., 2020)\n   \u2022 Agnews: 9 aggregate keyword based rules split amongst four respective classes (Ren et al., 2020)\nSubsampling. On some datasets, we directly subsample the LFs coming from WRENCH, selecting the most accurate\nLFs in a class-stratified fashion in order to roughly preserve similar ratios of LFs between classes. We also take care not\nto completely remove all the LFs for a given class, setting the minimum count to 1 per class. We explore subsampling\nper-class ratios within [0.1, 0.9], avoiding LF sets that are near-duplicates of each other (i.e., having coverage levels within\n1% of each other). We subsample based on accuracy to (optimistically) simulate an LF writer who is both careful and has\nconsiderable domain expertise; we assume that if they were to end up at a lower coverage LF set (either by writing fewer\nLFs or by pruning LFs written during a \u201cbrainstorming\u201d phase), they would prioritize rules that they are most confident\nabout. Assuming the LF writer has sufficient domain knowledge, these LFs are also the ones more likely to be accurate on\nthe examples they fire on.\nProcedural Generation. For the datasets where subsampling is less appropriate, we use WRENCH\u2019s LF generator to\nconstruct LF sets with {2, 5, 10, 15, 20} n-gram based LFs per class, choosing the most accurate LFs from the candidate\npool that have at least 2% coverage over the training set.\nD.2. New WS benchmarks: Massive18 and Banking77\nWe also create two new WS benchmarks by writing LFs for the publicly available intent classification datasets MASSIVE\n(FitzGerald et al., 2022) and Banking77 (Casanueva et al., 2020). These tasks were chosen a high-level to capture some\npractical challenges that are not as well-represented by current WRENCH tasks; most notably, they contain significantly\nhigher class counts, which makes them more challenging to write LFs for. Roughly speaking, assuming one writes uni-polar\nLFs (i.e., each LF either votes for a single class or abstains), the form of the vast majority of LFs in WRENCH, the number\nof LFs needed to reach a certain coverage level will likely need to scale with the number of classes.3. Further, because tasks\nwith larger label spaces require writing more LFs, we also view these tasks as being especially relevant for studying lower\ncoverage LF sets. We provide more details about the new tasks as follows:\n   3This, of course, also assumes that the coverage of LFs within each class does not change dramatically\n                                                                  18", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n### D. Beyond standard WS benchmarks: datasets for coverage ablations\n\n#### D.1. LF subsampling and procedural generation on existing WRENCH datasets\n\nOverall, WS benchmarks lack agreed-upon ways to explore different LF coverage/precision trade-offs. In this work, we choose to do so by sub-sampling LFs from an overall base set. However, the default LF sets associated with WS benchmarks are not equally as suitable to subsample from. In particular, we are wary about subsampling default LF sets when they:\n\n1. Contain very few LFs, which reduces the possible granularities of subsampling\n2. Contain LFs which are heterogeneous or have untracked lineages (e.g., $\\lambda_1$ closely relates to or was only provided in response to another LF $\\lambda_2$).\n\nFor datasets where we subsample directly, we choose ones with both larger LF counts and where all LFs are of the same form. This includes:\n\n- Semeval: 164 string-matching rules selected by humans from an automated candidate generation procedure (Zhou et al., 2020)\n- Chemprot: 26 individual keyword-based rules (Yu et al., 2021)\n\nThese contrast with LF sets that are far smaller, more heterogeneous, or have unclear dependencies. For these datasets, we instead procedurally generate LFs using the tools from WRENCH (Zhang et al., 2021)\n\n- IMDb: 4 aggregate keyword-based rules (i.e., each LF checks for the presence of any of multiple keywords), 1 expression-based rule (Ren et al., 2020)\n- Yelp: 7 heuristic rules on keywords, 1 third-party model on polarity of sentiment (Ren et al., 2020)\n- Agnews: 9 aggregate keyword-based rules split amongst four respective classes (Ren et al., 2020)\n\nSubsampling. On some datasets, we directly subsample the LFs coming from WRENCH, selecting the most accurate LFs in a class-stratified fashion in order to roughly preserve similar ratios of LFs between classes. We also take care not to completely remove all the LFs for a given class, setting the minimum count to 1 per class. We explore subsampling per-class ratios within [0.1, 0.9], avoiding LF sets that are near-duplicates of each other (i.e., having coverage levels within 1% of each other). We subsample based on accuracy to (optimistically) simulate an LF writer who is both careful and has considerable domain expertise; we assume that if they were to end up at a lower coverage LF set (either by writing fewer LFs or by pruning LFs written during a \u201cbrainstorming\u201d phase), they would prioritize rules that they are most confident about. Assuming the LF writer has sufficient domain knowledge, these LFs are also the ones more likely to be accurate on the examples they fire on.\n\nProcedural Generation. For the datasets where subsampling is less appropriate, we use WRENCH\u2019s LF generator to construct LF sets with {2, 5, 10, 15, 20} n-gram based LFs per class, choosing the most accurate LFs from the candidate pool that have at least 2% coverage over the training set.\n\n#### D.2. New WS benchmarks: Massive18 and Banking77\n\nWe also create two new WS benchmarks by writing LFs for the publicly available intent classification datasets MASSIVE (FitzGerald et al., 2022) and Banking77 (Casanueva et al., 2020). These tasks were chosen a high-level to capture some practical challenges that are not as well-represented by current WRENCH tasks; most notably, they contain significantly higher class counts, which makes them more challenging to write LFs for. Roughly speaking, assuming one writes uni-polar LFs (i.e., each LF either votes for a single class or abstains), the form of the vast majority of LFs in WRENCH, the number of LFs needed to reach a certain coverage level will likely need to scale with the number of classes.3 Further, because tasks with larger label spaces require writing more LFs, we also view these tasks as being especially relevant for studying lower coverage LF sets. We provide more details about the new tasks as follows:\n\n3This, of course, also assumes that the coverage of LFs within each class does not change dramatically", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 3, "value": "D. Beyond standard WS benchmarks: datasets for coverage ablations", "md": "### D. Beyond standard WS benchmarks: datasets for coverage ablations"}, {"type": "heading", "lvl": 4, "value": "D.1. LF subsampling and procedural generation on existing WRENCH datasets", "md": "#### D.1. LF subsampling and procedural generation on existing WRENCH datasets"}, {"type": "text", "value": "Overall, WS benchmarks lack agreed-upon ways to explore different LF coverage/precision trade-offs. In this work, we choose to do so by sub-sampling LFs from an overall base set. However, the default LF sets associated with WS benchmarks are not equally as suitable to subsample from. In particular, we are wary about subsampling default LF sets when they:\n\n1. Contain very few LFs, which reduces the possible granularities of subsampling\n2. Contain LFs which are heterogeneous or have untracked lineages (e.g., $\\lambda_1$ closely relates to or was only provided in response to another LF $\\lambda_2$).\n\nFor datasets where we subsample directly, we choose ones with both larger LF counts and where all LFs are of the same form. This includes:\n\n- Semeval: 164 string-matching rules selected by humans from an automated candidate generation procedure (Zhou et al., 2020)\n- Chemprot: 26 individual keyword-based rules (Yu et al., 2021)\n\nThese contrast with LF sets that are far smaller, more heterogeneous, or have unclear dependencies. For these datasets, we instead procedurally generate LFs using the tools from WRENCH (Zhang et al., 2021)\n\n- IMDb: 4 aggregate keyword-based rules (i.e., each LF checks for the presence of any of multiple keywords), 1 expression-based rule (Ren et al., 2020)\n- Yelp: 7 heuristic rules on keywords, 1 third-party model on polarity of sentiment (Ren et al., 2020)\n- Agnews: 9 aggregate keyword-based rules split amongst four respective classes (Ren et al., 2020)\n\nSubsampling. On some datasets, we directly subsample the LFs coming from WRENCH, selecting the most accurate LFs in a class-stratified fashion in order to roughly preserve similar ratios of LFs between classes. We also take care not to completely remove all the LFs for a given class, setting the minimum count to 1 per class. We explore subsampling per-class ratios within [0.1, 0.9], avoiding LF sets that are near-duplicates of each other (i.e., having coverage levels within 1% of each other). We subsample based on accuracy to (optimistically) simulate an LF writer who is both careful and has considerable domain expertise; we assume that if they were to end up at a lower coverage LF set (either by writing fewer LFs or by pruning LFs written during a \u201cbrainstorming\u201d phase), they would prioritize rules that they are most confident about. Assuming the LF writer has sufficient domain knowledge, these LFs are also the ones more likely to be accurate on the examples they fire on.\n\nProcedural Generation. For the datasets where subsampling is less appropriate, we use WRENCH\u2019s LF generator to construct LF sets with {2, 5, 10, 15, 20} n-gram based LFs per class, choosing the most accurate LFs from the candidate pool that have at least 2% coverage over the training set.", "md": "Overall, WS benchmarks lack agreed-upon ways to explore different LF coverage/precision trade-offs. In this work, we choose to do so by sub-sampling LFs from an overall base set. However, the default LF sets associated with WS benchmarks are not equally as suitable to subsample from. In particular, we are wary about subsampling default LF sets when they:\n\n1. Contain very few LFs, which reduces the possible granularities of subsampling\n2. Contain LFs which are heterogeneous or have untracked lineages (e.g., $\\lambda_1$ closely relates to or was only provided in response to another LF $\\lambda_2$).\n\nFor datasets where we subsample directly, we choose ones with both larger LF counts and where all LFs are of the same form. This includes:\n\n- Semeval: 164 string-matching rules selected by humans from an automated candidate generation procedure (Zhou et al., 2020)\n- Chemprot: 26 individual keyword-based rules (Yu et al., 2021)\n\nThese contrast with LF sets that are far smaller, more heterogeneous, or have unclear dependencies. For these datasets, we instead procedurally generate LFs using the tools from WRENCH (Zhang et al., 2021)\n\n- IMDb: 4 aggregate keyword-based rules (i.e., each LF checks for the presence of any of multiple keywords), 1 expression-based rule (Ren et al., 2020)\n- Yelp: 7 heuristic rules on keywords, 1 third-party model on polarity of sentiment (Ren et al., 2020)\n- Agnews: 9 aggregate keyword-based rules split amongst four respective classes (Ren et al., 2020)\n\nSubsampling. On some datasets, we directly subsample the LFs coming from WRENCH, selecting the most accurate LFs in a class-stratified fashion in order to roughly preserve similar ratios of LFs between classes. We also take care not to completely remove all the LFs for a given class, setting the minimum count to 1 per class. We explore subsampling per-class ratios within [0.1, 0.9], avoiding LF sets that are near-duplicates of each other (i.e., having coverage levels within 1% of each other). We subsample based on accuracy to (optimistically) simulate an LF writer who is both careful and has considerable domain expertise; we assume that if they were to end up at a lower coverage LF set (either by writing fewer LFs or by pruning LFs written during a \u201cbrainstorming\u201d phase), they would prioritize rules that they are most confident about. Assuming the LF writer has sufficient domain knowledge, these LFs are also the ones more likely to be accurate on the examples they fire on.\n\nProcedural Generation. For the datasets where subsampling is less appropriate, we use WRENCH\u2019s LF generator to construct LF sets with {2, 5, 10, 15, 20} n-gram based LFs per class, choosing the most accurate LFs from the candidate pool that have at least 2% coverage over the training set."}, {"type": "heading", "lvl": 4, "value": "D.2. New WS benchmarks: Massive18 and Banking77", "md": "#### D.2. New WS benchmarks: Massive18 and Banking77"}, {"type": "text", "value": "We also create two new WS benchmarks by writing LFs for the publicly available intent classification datasets MASSIVE (FitzGerald et al., 2022) and Banking77 (Casanueva et al., 2020). These tasks were chosen a high-level to capture some practical challenges that are not as well-represented by current WRENCH tasks; most notably, they contain significantly higher class counts, which makes them more challenging to write LFs for. Roughly speaking, assuming one writes uni-polar LFs (i.e., each LF either votes for a single class or abstains), the form of the vast majority of LFs in WRENCH, the number of LFs needed to reach a certain coverage level will likely need to scale with the number of classes.3 Further, because tasks with larger label spaces require writing more LFs, we also view these tasks as being especially relevant for studying lower coverage LF sets. We provide more details about the new tasks as follows:\n\n3This, of course, also assumes that the coverage of LFs within each class does not change dramatically", "md": "We also create two new WS benchmarks by writing LFs for the publicly available intent classification datasets MASSIVE (FitzGerald et al., 2022) and Banking77 (Casanueva et al., 2020). These tasks were chosen a high-level to capture some practical challenges that are not as well-represented by current WRENCH tasks; most notably, they contain significantly higher class counts, which makes them more challenging to write LFs for. Roughly speaking, assuming one writes uni-polar LFs (i.e., each LF either votes for a single class or abstains), the form of the vast majority of LFs in WRENCH, the number of LFs needed to reach a certain coverage level will likely need to scale with the number of classes.3 Further, because tasks with larger label spaces require writing more LFs, we also view these tasks as being especially relevant for studying lower coverage LF sets. We provide more details about the new tasks as follows:\n\n3This, of course, also assumes that the coverage of LFs within each class does not change dramatically"}]}, {"page": 19, "text": "                                 Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nMassive18 is derived from the MASSIVE dataset, a collection of single-shot interactions between human users and general\nintelligent voice assistants across 52 languages. We exclusively use the English-US portion of this dataset and treat the broad\nscenarios (i.e., general domains) as labels instead of the finer-grained intents. For instance, \u201calarm\u201d is a scenario whereas\n\u201calarm set\u201d and \u201calarm remove\u201d are two intents within that scenario. We call the resulting task Massive18 since there\nare 18 different scenario classes. Notably, even with this simplification, Massive18 contains at least nearly double the class\ncount of all previous WRENCH classification tasks (see Table 14 below).\nBanking77 is a collection of online banking queries along with the corresponding user intents. We use this task as defined\nwith the full set of 77 intents, which can be both quite domain specific and especially fine-grained. If we were to write the\nminimum number of LFs for Banking77, i.e. one for each class, this would already require 77 LFs, more than the number of\nLFs for most previous WRENCH datasets.\n                                    Datasets         |Y|     |Train|     |Test|     # LFs     Coverage      Snork. Precision        Metric\n                                     IMDb             2       20000       2500        5         87.6%             74.4%              Acc.\n                                      Yelp            2       30400       3800        8         82.8%             75.4%              Acc.\n                                    Youtube           2       1586        250        10         87.7%             87.0%              Acc.\n                                    AgNews            4       96000      12000        9         69.1%             82.5%              Acc.\n                                      Trec            6       4965        500        68         95.1%             60.0%              Acc.\n                               Massive18 (ours)       18      11514       2974       59        61.3%              83.8%              Acc.\n                               Banking77 (ours)       77      9003        3080       218        54.5%             76.5%              Acc.\n                                    Spouse            2       22254       2701        9         25.8%        65.6% (on Val)       F1 (binary)\n                                   Chemprot           10      12861       1607       26         85.6%             58.0%              Acc.\n                                    Census            2       10083      16281       83         99.1%             58.0%           F1 (binary)\nTable 14. Comparing our two new datasets (blue) to previous benchmarks. Coverage is the percentage of training examples on which at\nleast one LF does not abstain. \u201cSnork. precision\u201d refers to the accuracy of the Snorkel LM on the covered set of inputs.\nLabeling Functions. For both datasets, we manually write the LFs ourselves based upon a randomly sampled development\nset of 250 cleanly-labeled examples. Each LF checks whether a specific keyword (or set of multiple keywords) is a substring\nof the given example and then votes for a specific class if the substring(s) are present (and otherwise abstaining). We provide\nsome examples of the LFs we wrote in Tables 15 and 16. We share the full LF sets in our supplied codebase 4.\nFinally, in our experiments, we also try the same subsampling procedure from Appendix D.1 to further explore different\ncoverage levels. For Massive18 we use the ratios {0.1, 0.5, 0.7, 0.8, 1} and for Banking77 we use the ratios {0.1, 0.5, 0.7,\n1.0}.                         Label                   Keyword LFs\n                              \u2018\u2018alarm\u2019\u2019               [\u2018\u2018alarm\u2019\u2019, \u2018\u2018wake+up\u2019\u2019]\n                              \u2018\u2018takeaway\u2019\u2019            [\u2018\u2018takeaway\u2019\u2019, \u2018\u2018delivery\u2019\u2019, \u2018\u2018order\u2019\u2019]\n                              \u2018\u2018social\u2019\u2019              [\u2018\u2018tweet\u2019\u2019, \u2018\u2018twitter\u2019\u2019, \u2018\u2018facebook\u2019\u2019, \u2018\u2018complain\u2019\u2019]\n                              \u2018\u2018music\u2019\u2019               [\u2018\u2018what+song\u2019\u2019, \u2018\u2018save+song\u2019\u2019, \u2018\u2018shuffle\u2019\u2019]\n                              \u2018\u2018calendar\u2019\u2019            [\u2018\u2018calendar\u2019\u2019, \u2018\u2018schedule\u2019\u2019, \u2018\u2018remind\u2019\u2019]\nTable 15. Example LFs for Massive18. Each row shows one of the possible labels and the associated keyword-based LFs. Note that some\nLFs contain multiple keywords/substrings that are joined by the \u201c+\u201d character. This signifies that the LF checks whether all the keywords\nsupplied are in a given example (though they do not necessarily have to appear in the provided order).\n                Label                                          Keyword LFs\n                \u2018\u2018age limit\u2019\u2019                                  [\u2018\u2018age limit\u2019\u2019, \u2018\u2018child\u2019\u2019, \u2018\u2018my son\u2019\u2019, \u2018\u2018my daughter\u2019\u2019]\n                \u2018\u2018pin blocked\u2019\u2019                                [\u2018\u2018takeaway\u2019\u2019, \u2018\u2018delivery\u2019\u2019, \u2018\u2018order\u2019\u2019]\n                \u2018\u2018lost or stolen card\u2019\u2019                        [\u2018\u2018tweet\u2019\u2019, \u2018\u2018twitter\u2019\u2019, \u2018\u2018facebook\u2019\u2019, \u2018\u2018complain\u2019\u2019]\n                \u2018\u2018verify my identity\u2019\u2019                         [\u2018\u2018id+check\u2019\u2019, \u2018\u2018what+ id\u2019\u2019]\n                \u2018\u2018disposable card limits\u2019\u2019                     [\u2018\u2018disposable+limit\u2019\u2019, \u2018\u2018disposable+max\u2019\u2019]\n                     Table 16. Example LFs for Banking77. Note the usage of \u201c+\u201d, as explained in the caption of Table 15.\n     4https://github.com/jeffreywpli/SSL4WS\n                                                                                     19", "md": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nMassive18 is derived from the MASSIVE dataset, a collection of single-shot interactions between human users and general intelligent voice assistants across 52 languages. We exclusively use the English-US portion of this dataset and treat the broad scenarios (i.e., general domains) as labels instead of the finer-grained intents. For instance, \"alarm\" is a scenario whereas \"alarm set\" and \"alarm remove\" are two intents within that scenario. We call the resulting task Massive18 since there are 18 different scenario classes. Notably, even with this simplification, Massive18 contains at least nearly double the class count of all previous WRENCH classification tasks (see Table 14 below).\n\nBanking77 is a collection of online banking queries along with the corresponding user intents. We use this task as defined with the full set of 77 intents, which can be both quite domain specific and especially fine-grained. If we were to write the minimum number of LFs for Banking77, i.e. one for each class, this would already require 77 LFs, more than the number of LFs for most previous WRENCH datasets.\n\n| Datasets       | Y | Train | Test | # LFs | Coverage | Snork. Precision | Metric |\n|----------------|---|-------|------|-------|----------|------------------|--------|\n| IMDb           | 2 | 20000 | 2500 | 5     | 87.6%    | 74.4%            | Acc.   |\n| Yelp           | 2 | 30400 | 3800 | 8     | 82.8%    | 75.4%            | Acc.   |\n| Youtube        | 2 | 1586  | 250  | 10    | 87.7%    | 87.0%            | Acc.   |\n| AgNews         | 4 | 96000 | 12000| 9     | 69.1%    | 82.5%            | Acc.   |\n| Trec           | 6 | 4965  | 500  | 68    | 95.1%    | 60.0%            | Acc.   |\n| Massive18 (ours) | 18 | 11514 | 2974 | 59  | 61.3%    | 83.8%            | Acc.   |\n| Banking77 (ours) | 77 | 9003 | 3080 | 218 | 54.5%    | 76.5%            | Acc.   |\n| Spouse         | 2 | 22254 | 2701 | 9     | 25.8%    | 65.6% (on Val)   | F1 (binary) |\n| Chemprot       | 10| 12861 | 1607 | 26    | 85.6%    | 58.0%            | Acc.   |\n| Census         | 2 | 10083 | 16281| 83    | 99.1%    | 58.0%            | F1 (binary) |\n\nTable 14. Comparing our two new datasets (blue) to previous benchmarks. Coverage is the percentage of training examples on which at least one LF does not abstain. \"Snork. precision\" refers to the accuracy of the Snorkel LM on the covered set of inputs.\n\nLabeling Functions. For both datasets, we manually write the LFs ourselves based upon a randomly sampled development set of 250 cleanly-labeled examples. Each LF checks whether a specific keyword (or set of multiple keywords) is a substring of the given example and then votes for a specific class if the substring(s) are present (and otherwise abstaining). We provide some examples of the LFs we wrote in Tables 15 and 16. We share the full LF sets in our supplied codebase 4.\n\nFinally, in our experiments, we also try the same subsampling procedure from Appendix D.1 to further explore different coverage levels. For Massive18 we use the ratios {0.1, 0.5, 0.7, 0.8, 1} and for Banking77 we use the ratios {0.1, 0.5, 0.7, 1.0}.\n\n| Label            | Keyword LFs                    |\n|------------------|--------------------------------|\n| 'alarm'          | ['alarm', 'wake+up']           |\n| 'takeaway'       | ['takeaway', 'delivery', 'order'] |\n| 'social'         | ['tweet', 'twitter', 'facebook', 'complain'] |\n| 'music'          | ['what+song', 'save+song', 'shuffle'] |\n| 'calendar'       | ['calendar', 'schedule', 'remind'] |\n\nTable 15. Example LFs for Massive18. Each row shows one of the possible labels and the associated keyword-based LFs. Note that some LFs contain multiple keywords/substrings that are joined by the \"+\" character. This signifies that the LF checks whether all the keywords supplied are in a given example (though they do not necessarily have to appear in the provided order).\n\n| Label                 | Keyword LFs                                |\n|-----------------------|--------------------------------------------|\n| 'age limit'           | ['age limit', 'child', 'my son', 'my daughter'] |\n| 'pin blocked'         | ['takeaway', 'delivery', 'order']          |\n| 'lost or stolen card' | ['tweet', 'twitter', 'facebook', 'complain'] |\n| 'verify my identity'  | ['id+check', 'what+ id']                    |\n| 'disposable card limits' | ['disposable+limit', 'disposable+max']    |\n\nTable 16. Example LFs for Banking77. Note the usage of \"+\" as explained in the caption of Table 15.", "images": [], "items": [{"type": "text", "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nMassive18 is derived from the MASSIVE dataset, a collection of single-shot interactions between human users and general intelligent voice assistants across 52 languages. We exclusively use the English-US portion of this dataset and treat the broad scenarios (i.e., general domains) as labels instead of the finer-grained intents. For instance, \"alarm\" is a scenario whereas \"alarm set\" and \"alarm remove\" are two intents within that scenario. We call the resulting task Massive18 since there are 18 different scenario classes. Notably, even with this simplification, Massive18 contains at least nearly double the class count of all previous WRENCH classification tasks (see Table 14 below).\n\nBanking77 is a collection of online banking queries along with the corresponding user intents. We use this task as defined with the full set of 77 intents, which can be both quite domain specific and especially fine-grained. If we were to write the minimum number of LFs for Banking77, i.e. one for each class, this would already require 77 LFs, more than the number of LFs for most previous WRENCH datasets.", "md": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nMassive18 is derived from the MASSIVE dataset, a collection of single-shot interactions between human users and general intelligent voice assistants across 52 languages. We exclusively use the English-US portion of this dataset and treat the broad scenarios (i.e., general domains) as labels instead of the finer-grained intents. For instance, \"alarm\" is a scenario whereas \"alarm set\" and \"alarm remove\" are two intents within that scenario. We call the resulting task Massive18 since there are 18 different scenario classes. Notably, even with this simplification, Massive18 contains at least nearly double the class count of all previous WRENCH classification tasks (see Table 14 below).\n\nBanking77 is a collection of online banking queries along with the corresponding user intents. We use this task as defined with the full set of 77 intents, which can be both quite domain specific and especially fine-grained. If we were to write the minimum number of LFs for Banking77, i.e. one for each class, this would already require 77 LFs, more than the number of LFs for most previous WRENCH datasets."}, {"type": "table", "rows": [["Datasets", "Y", "Train", "Test", "# LFs", "Coverage", "Snork. Precision", "Metric"], ["IMDb", "2", "20000", "2500", "5", "87.6%", "74.4%", "Acc."], ["Yelp", "2", "30400", "3800", "8", "82.8%", "75.4%", "Acc."], ["Youtube", "2", "1586", "250", "10", "87.7%", "87.0%", "Acc."], ["AgNews", "4", "96000", "12000", "9", "69.1%", "82.5%", "Acc."], ["Trec", "6", "4965", "500", "68", "95.1%", "60.0%", "Acc."], ["Massive18 (ours)", "18", "11514", "2974", "59", "61.3%", "83.8%", "Acc."], ["Banking77 (ours)", "77", "9003", "3080", "218", "54.5%", "76.5%", "Acc."], ["Spouse", "2", "22254", "2701", "9", "25.8%", "65.6% (on Val)", "F1 (binary)"], ["Chemprot", "10", "12861", "1607", "26", "85.6%", "58.0%", "Acc."], ["Census", "2", "10083", "16281", "83", "99.1%", "58.0%", "F1 (binary)"]], "md": "| Datasets       | Y | Train | Test | # LFs | Coverage | Snork. Precision | Metric |\n|----------------|---|-------|------|-------|----------|------------------|--------|\n| IMDb           | 2 | 20000 | 2500 | 5     | 87.6%    | 74.4%            | Acc.   |\n| Yelp           | 2 | 30400 | 3800 | 8     | 82.8%    | 75.4%            | Acc.   |\n| Youtube        | 2 | 1586  | 250  | 10    | 87.7%    | 87.0%            | Acc.   |\n| AgNews         | 4 | 96000 | 12000| 9     | 69.1%    | 82.5%            | Acc.   |\n| Trec           | 6 | 4965  | 500  | 68    | 95.1%    | 60.0%            | Acc.   |\n| Massive18 (ours) | 18 | 11514 | 2974 | 59  | 61.3%    | 83.8%            | Acc.   |\n| Banking77 (ours) | 77 | 9003 | 3080 | 218 | 54.5%    | 76.5%            | Acc.   |\n| Spouse         | 2 | 22254 | 2701 | 9     | 25.8%    | 65.6% (on Val)   | F1 (binary) |\n| Chemprot       | 10| 12861 | 1607 | 26    | 85.6%    | 58.0%            | Acc.   |\n| Census         | 2 | 10083 | 16281| 83    | 99.1%    | 58.0%            | F1 (binary) |", "isPerfectTable": true, "csv": "\"Datasets\",\"Y\",\"Train\",\"Test\",\"# LFs\",\"Coverage\",\"Snork. Precision\",\"Metric\"\n\"IMDb\",\"2\",\"20000\",\"2500\",\"5\",\"87.6%\",\"74.4%\",\"Acc.\"\n\"Yelp\",\"2\",\"30400\",\"3800\",\"8\",\"82.8%\",\"75.4%\",\"Acc.\"\n\"Youtube\",\"2\",\"1586\",\"250\",\"10\",\"87.7%\",\"87.0%\",\"Acc.\"\n\"AgNews\",\"4\",\"96000\",\"12000\",\"9\",\"69.1%\",\"82.5%\",\"Acc.\"\n\"Trec\",\"6\",\"4965\",\"500\",\"68\",\"95.1%\",\"60.0%\",\"Acc.\"\n\"Massive18 (ours)\",\"18\",\"11514\",\"2974\",\"59\",\"61.3%\",\"83.8%\",\"Acc.\"\n\"Banking77 (ours)\",\"77\",\"9003\",\"3080\",\"218\",\"54.5%\",\"76.5%\",\"Acc.\"\n\"Spouse\",\"2\",\"22254\",\"2701\",\"9\",\"25.8%\",\"65.6% (on Val)\",\"F1 (binary)\"\n\"Chemprot\",\"10\",\"12861\",\"1607\",\"26\",\"85.6%\",\"58.0%\",\"Acc.\"\n\"Census\",\"2\",\"10083\",\"16281\",\"83\",\"99.1%\",\"58.0%\",\"F1 (binary)\""}, {"type": "text", "value": "Table 14. Comparing our two new datasets (blue) to previous benchmarks. Coverage is the percentage of training examples on which at least one LF does not abstain. \"Snork. precision\" refers to the accuracy of the Snorkel LM on the covered set of inputs.\n\nLabeling Functions. For both datasets, we manually write the LFs ourselves based upon a randomly sampled development set of 250 cleanly-labeled examples. Each LF checks whether a specific keyword (or set of multiple keywords) is a substring of the given example and then votes for a specific class if the substring(s) are present (and otherwise abstaining). We provide some examples of the LFs we wrote in Tables 15 and 16. We share the full LF sets in our supplied codebase 4.\n\nFinally, in our experiments, we also try the same subsampling procedure from Appendix D.1 to further explore different coverage levels. For Massive18 we use the ratios {0.1, 0.5, 0.7, 0.8, 1} and for Banking77 we use the ratios {0.1, 0.5, 0.7, 1.0}.", "md": "Table 14. Comparing our two new datasets (blue) to previous benchmarks. Coverage is the percentage of training examples on which at least one LF does not abstain. \"Snork. precision\" refers to the accuracy of the Snorkel LM on the covered set of inputs.\n\nLabeling Functions. For both datasets, we manually write the LFs ourselves based upon a randomly sampled development set of 250 cleanly-labeled examples. Each LF checks whether a specific keyword (or set of multiple keywords) is a substring of the given example and then votes for a specific class if the substring(s) are present (and otherwise abstaining). We provide some examples of the LFs we wrote in Tables 15 and 16. We share the full LF sets in our supplied codebase 4.\n\nFinally, in our experiments, we also try the same subsampling procedure from Appendix D.1 to further explore different coverage levels. For Massive18 we use the ratios {0.1, 0.5, 0.7, 0.8, 1} and for Banking77 we use the ratios {0.1, 0.5, 0.7, 1.0}."}, {"type": "table", "rows": [["Label", "Keyword LFs"], ["'alarm'", "['alarm', 'wake+up']"], ["'takeaway'", "['takeaway', 'delivery', 'order']"], ["'social'", "['tweet', 'twitter', 'facebook', 'complain']"], ["'music'", "['what+song', 'save+song', 'shuffle']"], ["'calendar'", "['calendar', 'schedule', 'remind']"]], "md": "| Label            | Keyword LFs                    |\n|------------------|--------------------------------|\n| 'alarm'          | ['alarm', 'wake+up']           |\n| 'takeaway'       | ['takeaway', 'delivery', 'order'] |\n| 'social'         | ['tweet', 'twitter', 'facebook', 'complain'] |\n| 'music'          | ['what+song', 'save+song', 'shuffle'] |\n| 'calendar'       | ['calendar', 'schedule', 'remind'] |", "isPerfectTable": true, "csv": "\"Label\",\"Keyword LFs\"\n\"'alarm'\",\"['alarm', 'wake+up']\"\n\"'takeaway'\",\"['takeaway', 'delivery', 'order']\"\n\"'social'\",\"['tweet', 'twitter', 'facebook', 'complain']\"\n\"'music'\",\"['what+song', 'save+song', 'shuffle']\"\n\"'calendar'\",\"['calendar', 'schedule', 'remind']\""}, {"type": "text", "value": "Table 15. Example LFs for Massive18. Each row shows one of the possible labels and the associated keyword-based LFs. Note that some LFs contain multiple keywords/substrings that are joined by the \"+\" character. This signifies that the LF checks whether all the keywords supplied are in a given example (though they do not necessarily have to appear in the provided order).", "md": "Table 15. Example LFs for Massive18. Each row shows one of the possible labels and the associated keyword-based LFs. Note that some LFs contain multiple keywords/substrings that are joined by the \"+\" character. This signifies that the LF checks whether all the keywords supplied are in a given example (though they do not necessarily have to appear in the provided order)."}, {"type": "table", "rows": [["Label", "Keyword LFs"], ["'age limit'", "['age limit', 'child', 'my son', 'my daughter']"], ["'pin blocked'", "['takeaway', 'delivery', 'order']"], ["'lost or stolen card'", "['tweet', 'twitter', 'facebook', 'complain']"], ["'verify my identity'", "['id+check', 'what+ id']"], ["'disposable card limits'", "['disposable+limit', 'disposable+max']"]], "md": "| Label                 | Keyword LFs                                |\n|-----------------------|--------------------------------------------|\n| 'age limit'           | ['age limit', 'child', 'my son', 'my daughter'] |\n| 'pin blocked'         | ['takeaway', 'delivery', 'order']          |\n| 'lost or stolen card' | ['tweet', 'twitter', 'facebook', 'complain'] |\n| 'verify my identity'  | ['id+check', 'what+ id']                    |\n| 'disposable card limits' | ['disposable+limit', 'disposable+max']    |", "isPerfectTable": true, "csv": "\"Label\",\"Keyword LFs\"\n\"'age limit'\",\"['age limit', 'child', 'my son', 'my daughter']\"\n\"'pin blocked'\",\"['takeaway', 'delivery', 'order']\"\n\"'lost or stolen card'\",\"['tweet', 'twitter', 'facebook', 'complain']\"\n\"'verify my identity'\",\"['id+check', 'what+ id']\"\n\"'disposable card limits'\",\"['disposable+limit', 'disposable+max']\""}, {"type": "text", "value": "Table 16. Example LFs for Banking77. Note the usage of \"+\" as explained in the caption of Table 15.", "md": "Table 16. Example LFs for Banking77. Note the usage of \"+\" as explained in the caption of Table 15."}]}, {"page": 20, "text": "                                      Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nD.3. Tabular Datasets\nLabeling Functions. We use three tabular tasks and the LF generation procedure from Zhang et al. (2022b). At a high-\nlevel, this procedure uses the sklearn implementation of random forests (i.e., RandomForestClassifier) to train\nmultiple decision trees on a small cleanly-labeled development set (i.e., formed by uniformly sampling 5% of the training\nset in our experiments). Uni-polar LFs are then derived from individual trees. In our experiments, we generate a set of 100\ncandidate LFs for each task and then select the top-{5%, 10%, 15%, 20%} most accurate LFs (per-class) based upon the\nfull training set (i.e., similar in spirit to WRENCH\u2019s procedural LF generator). Again, while this selection step isn\u2019t possible\nwithout access to all the labels, we consider it as a loose (optimistic) approximation of integrating of a domain expert\u2019s\nknowledge and judgment.\nRobustness to seeding. One caveat of this approach for genearting LFs is that the behavior may vary depending on the\ninitial random seed given to RandomForestClassifier. To try to account for this, we try multiple seeds and find that\nthe overall conclusions do not change across different runs of the LF generator. As seen in Figure 7, while the absolute\nperformance levels may vary across seeds, SSL is consistently more useful at lower coverage levels.\n                                              1.0      Mushroom (Seed 1)             1.0     Mushroom (Seed 2)             1.0     Mushroom (Seed 3)\n                                              0.9                                    0.9                                   0.9\n                                             Test Acc\n                                              0.8                                    0.8                                   0.8\n                                              0.7                                    0.7                                   0.7\n                                              0.6                                    0.6                                   0.6\n                                              0.5                                    0.5                                   0.5\n                                                 0.0   0.2   0.4    0.6   0.8   1.0    0.0   0.2   0.4    0.6   0.8    1.0   0.0   0.2    0.4   0.6   0.8    1.0\n                                             0.95      Spambase (Seed 1)           0.95      Spambase (Seed 2)           0.95      Spambase (Seed 3)\n                                             0.90                                  0.90                                  0.90\n                                            Test Acc\n                                             0.85                                  0.85                                  0.85\n                                             0.80                                  0.80                                  0.80\n                                             0.75                                  0.75                                  0.75\n                                             0.70                                  0.70                                  0.70\n                                                 0.0   0.2   0.4    0.6   0.8   1.0    0.0   0.2   0.4    0.6   0.8    1.0   0.0   0.2    0.4   0.6   0.8    1.0\n                                             1.00  Phishingwebsites (Seed 1)         1.0 Phishingwebsites (Seed 2)       1.00 Phishingwebsites (Seed 3)\n                                                                                     0.9\n                                             0.95                                                                        0.95\n                                            Test Acc                                 0.8\n                                             0.90                                    0.7                                 0.90\n                                                                                     0.6\n                                             0.85                                    0.5                                 0.85\n                                                 0.0   0.2   0.4    0.6   0.8   1.0    0.0   0.2   0.4    0.6   0.8    1.0   0.0   0.2    0.4   0.6   0.8    1.0\n                                                            Coverage                               Coverage                              Coverage\n                                                    GT (Cov)              Vanilla            Thresh+SSL               Thresh+Re-label               GT (Full)\n                                                 Figure 7. Replication of our tabular experiments across different seeds\n                                                                                                    20", "md": "# Tabular Datasets\n\n## Labeling Functions\n\nWe use three tabular tasks and the LF generation procedure from Zhang et al. (2022b). At a high-level, this procedure uses the sklearn implementation of random forests (i.e., RandomForestClassifier) to train multiple decision trees on a small cleanly-labeled development set (i.e., formed by uniformly sampling 5% of the training set in our experiments). Uni-polar LFs are then derived from individual trees. In our experiments, we generate a set of 100 candidate LFs for each task and then select the top-{5%, 10%, 15%, 20%} most accurate LFs (per-class) based upon the full training set (i.e., similar in spirit to WRENCH\u2019s procedural LF generator). Again, while this selection step isn\u2019t possible without access to all the labels, we consider it as a loose (optimistic) approximation of integrating of a domain expert\u2019s knowledge and judgment.\n\nRobustness to seeding. One caveat of this approach for generating LFs is that the behavior may vary depending on the initial random seed given to RandomForestClassifier. To try to account for this, we try multiple seeds and find that the overall conclusions do not change across different runs of the LF generator. As seen in Figure 7, while the absolute performance levels may vary across seeds, SSL is consistently more useful at lower coverage levels.\n\n### Table: Replication of our tabular experiments across different seeds\n\n| |Mushroom (Seed 1)|Mushroom (Seed 2)|Mushroom (Seed 3)|\n|---|---|---|---|\n|Test Acc|1.0|1.0|1.0|\n| |0.9|0.9|0.9|\n| |0.8|0.8|0.8|\n| |0.7|0.7|0.7|\n| |0.6|0.6|0.6|\n\n| |Spambase (Seed 1)|Spambase (Seed 2)|Spambase (Seed 3)|\n|---|---|---|---|\n|Test Acc|0.95|0.95|0.95|\n| |0.90|0.90|0.90|\n| |0.85|0.85|0.85|\n| |0.80|0.80|0.80|\n| |0.75|0.75|0.75|\n\n| |Phishingwebsites (Seed 1)|Phishingwebsites (Seed 2)|Phishingwebsites (Seed 3)|\n|---|---|---|---|\n|Test Acc|1.00|1.0|1.00|\n| |0.95| |0.95|\n| |0.90| |0.90|\n| |0.85| |0.85|\n| |0.80| |0.80|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Tabular Datasets", "md": "# Tabular Datasets"}, {"type": "heading", "lvl": 2, "value": "Labeling Functions", "md": "## Labeling Functions"}, {"type": "text", "value": "We use three tabular tasks and the LF generation procedure from Zhang et al. (2022b). At a high-level, this procedure uses the sklearn implementation of random forests (i.e., RandomForestClassifier) to train multiple decision trees on a small cleanly-labeled development set (i.e., formed by uniformly sampling 5% of the training set in our experiments). Uni-polar LFs are then derived from individual trees. In our experiments, we generate a set of 100 candidate LFs for each task and then select the top-{5%, 10%, 15%, 20%} most accurate LFs (per-class) based upon the full training set (i.e., similar in spirit to WRENCH\u2019s procedural LF generator). Again, while this selection step isn\u2019t possible without access to all the labels, we consider it as a loose (optimistic) approximation of integrating of a domain expert\u2019s knowledge and judgment.\n\nRobustness to seeding. One caveat of this approach for generating LFs is that the behavior may vary depending on the initial random seed given to RandomForestClassifier. To try to account for this, we try multiple seeds and find that the overall conclusions do not change across different runs of the LF generator. As seen in Figure 7, while the absolute performance levels may vary across seeds, SSL is consistently more useful at lower coverage levels.", "md": "We use three tabular tasks and the LF generation procedure from Zhang et al. (2022b). At a high-level, this procedure uses the sklearn implementation of random forests (i.e., RandomForestClassifier) to train multiple decision trees on a small cleanly-labeled development set (i.e., formed by uniformly sampling 5% of the training set in our experiments). Uni-polar LFs are then derived from individual trees. In our experiments, we generate a set of 100 candidate LFs for each task and then select the top-{5%, 10%, 15%, 20%} most accurate LFs (per-class) based upon the full training set (i.e., similar in spirit to WRENCH\u2019s procedural LF generator). Again, while this selection step isn\u2019t possible without access to all the labels, we consider it as a loose (optimistic) approximation of integrating of a domain expert\u2019s knowledge and judgment.\n\nRobustness to seeding. One caveat of this approach for generating LFs is that the behavior may vary depending on the initial random seed given to RandomForestClassifier. To try to account for this, we try multiple seeds and find that the overall conclusions do not change across different runs of the LF generator. As seen in Figure 7, while the absolute performance levels may vary across seeds, SSL is consistently more useful at lower coverage levels."}, {"type": "heading", "lvl": 3, "value": "Table: Replication of our tabular experiments across different seeds", "md": "### Table: Replication of our tabular experiments across different seeds"}, {"type": "table", "rows": [["", "Mushroom (Seed 1)", "Mushroom (Seed 2)", "Mushroom (Seed 3)"], ["Test Acc", "1.0", "1.0", "1.0"], ["", "0.9", "0.9", "0.9"], ["", "0.8", "0.8", "0.8"], ["", "0.7", "0.7", "0.7"], ["", "0.6", "0.6", "0.6"]], "md": "| |Mushroom (Seed 1)|Mushroom (Seed 2)|Mushroom (Seed 3)|\n|---|---|---|---|\n|Test Acc|1.0|1.0|1.0|\n| |0.9|0.9|0.9|\n| |0.8|0.8|0.8|\n| |0.7|0.7|0.7|\n| |0.6|0.6|0.6|", "isPerfectTable": true, "csv": "\"\",\"Mushroom (Seed 1)\",\"Mushroom (Seed 2)\",\"Mushroom (Seed 3)\"\n\"Test Acc\",\"1.0\",\"1.0\",\"1.0\"\n\"\",\"0.9\",\"0.9\",\"0.9\"\n\"\",\"0.8\",\"0.8\",\"0.8\"\n\"\",\"0.7\",\"0.7\",\"0.7\"\n\"\",\"0.6\",\"0.6\",\"0.6\""}, {"type": "table", "rows": [["", "Spambase (Seed 1)", "Spambase (Seed 2)", "Spambase (Seed 3)"], ["Test Acc", "0.95", "0.95", "0.95"], ["", "0.90", "0.90", "0.90"], ["", "0.85", "0.85", "0.85"], ["", "0.80", "0.80", "0.80"], ["", "0.75", "0.75", "0.75"]], "md": "| |Spambase (Seed 1)|Spambase (Seed 2)|Spambase (Seed 3)|\n|---|---|---|---|\n|Test Acc|0.95|0.95|0.95|\n| |0.90|0.90|0.90|\n| |0.85|0.85|0.85|\n| |0.80|0.80|0.80|\n| |0.75|0.75|0.75|", "isPerfectTable": true, "csv": "\"\",\"Spambase (Seed 1)\",\"Spambase (Seed 2)\",\"Spambase (Seed 3)\"\n\"Test Acc\",\"0.95\",\"0.95\",\"0.95\"\n\"\",\"0.90\",\"0.90\",\"0.90\"\n\"\",\"0.85\",\"0.85\",\"0.85\"\n\"\",\"0.80\",\"0.80\",\"0.80\"\n\"\",\"0.75\",\"0.75\",\"0.75\""}, {"type": "table", "rows": [["", "Phishingwebsites (Seed 1)", "Phishingwebsites (Seed 2)", "Phishingwebsites (Seed 3)"], ["Test Acc", "1.00", "1.0", "1.00"], ["", "0.95", "", "0.95"], ["", "0.90", "", "0.90"], ["", "0.85", "", "0.85"], ["", "0.80", "", "0.80"]], "md": "| |Phishingwebsites (Seed 1)|Phishingwebsites (Seed 2)|Phishingwebsites (Seed 3)|\n|---|---|---|---|\n|Test Acc|1.00|1.0|1.00|\n| |0.95| |0.95|\n| |0.90| |0.90|\n| |0.85| |0.85|\n| |0.80| |0.80|", "isPerfectTable": true, "csv": "\"\",\"Phishingwebsites (Seed 1)\",\"Phishingwebsites (Seed 2)\",\"Phishingwebsites (Seed 3)\"\n\"Test Acc\",\"1.00\",\"1.0\",\"1.00\"\n\"\",\"0.95\",\"\",\"0.95\"\n\"\",\"0.90\",\"\",\"0.90\"\n\"\",\"0.85\",\"\",\"0.85\"\n\"\",\"0.80\",\"\",\"0.80\""}]}, {"page": 21, "text": "                                     Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\nE. Coverage bias explains the value of unlabeled data\n                        0.95           Semeval                 0.9          Chemprot               0.90      Massive18 (Ours)            0.90    Banking77 (Ours)\n                        0.90                                                                       0.85                                  0.85\n                       Test Acc                                0.8                                                                       0.80\n                        0.85                                                                       0.80\n                        0.80                                                                                                             0.75\n                        0.75                                   0.7                                 0.75                                  0.70\n                        0.70                                   0.6                                 0.70                                  0.65\n                        0.65                                                                       0.65                                  0.60\n                        0.60                                   0.5                                 0.60                                  0.55\n                        0.55                                                                                                             0.50\n                           0.0    0.2   0.4   0.6   0.8    1.0   0.0   0.2    0.4   0.6   0.8   1.0    0.0   0.2   0.4   0.6    0.8   1.0   0.0  0.2    0.4   0.6  0.8  1.0\n                                       Coverage                             Coverage                              Coverage                            Coverage\n                                         0.94              Imdb                 0.98              Yelp                0.92            Agnews\n                                         0.92                                   0.96                                  0.90\n                                        Test Acc                                0.94                                  0.88\n                                         0.90                                                                         0.86\n                                         0.88                                   0.92                                  0.84\n                                         0.86                                   0.90                                  0.82\n                                         0.84                                   0.88                                  0.80\n                                             0.0   0.2    0.4   0.6   0.8    1.0   0.0   0.2    0.4   0.6    0.8   1.0   0.0    0.2   0.4   0.6   0.8   1.0\n                                                        Coverage                              Coverage                               Coverage\n                                                            GT (Full)              GT (Cov)               GT (Sub)               Vanilla WS\nFigure 8. Limited Size versus Coverage Bias. We may assess the relative impacts of the limited size of WS training sets (comparing GT\n(Full) and GT (Sub)) versus their coverage bias (comparing GT (Sub) and GT (Cov)).\nIn Section 4.5, we observed that on some datasets, as coverage decreases, so does the performance of GT (Cov). Indeed, for\nany LF set, we can view the gap in performance between GT (Cov) and GT (Full) as a reflection of the aggregate impact of\ntwo data gaps that WS datasets suffer from: (1) limited size (i.e., not all training examples are labeled) and (2) coverage bias\n(i.e., the examples covered by LFs come from a biased subpopulation of the test distribution). Because GT (Cov) simply\nignores all unlabeled examples, this gap also then reflects the value of said examples.\nA natural follow up question is whether limited size or coverage bias more greatly hinders learning under WS. Here, we\nfurther decompose the performance drops we observed between GT (Cov) and GT (Full) by considering a third model\nthat interpolates between the two. Specifically, we consider GT (Sub), a model that suffers only from limited size but not\ncoverage bias. This model is trained on a training set that shares the same size as the dataset for GT (Cov), but consists of\nexamples re-sampled uniformly from the full training set (i.e., eliminating coverage bias).\nOnce we have trained all three models, we may then simply compare the following performance gaps:\n    \u2022 TestPerf(GT (Full)) \u2212                  TestPerf(GT (Sub)): to ablate the impact limited size\n    \u2022 TestPerf(GT (Sub)) \u2212                  TestPerf(GT (Cov)): to ablate the impact of coverage bias\nAs we see in Figure 8, when large gaps exist between GT (Full) and GT (Cov), most of this gap is explained by the\nperformance drop between GT (Sub) and GT (Cov) instead of the drop between GT (Full) and GT (Sub) (e.g., especially on\nSemeval, Massive18, Banking77). This suggests that coverage bias is far more responsible than limited size, which perhaps\nmakes sense in the context of WS, as LFs can label an arbitrary amount of data but only from the covered set. Also, this\nmeans that SSL techniques, initially developed in settings where labeled and unlabeled sets are i.i.d. (i.e., where limited\nsize is the only relevant data gap), actually remain effective in low coverage WS settings despite the significant impacts of\ncoverage bias.\n                                                                                                21", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\n## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision\n\nE. Coverage bias explains the value of unlabeled data\n\n| |0.95|Semeval|0.9|Chemprot|0.90|Massive18 (Ours)|0.90|Banking77 (Ours)|\n|---|---|---|---|---|---|---|---|---|\n|Test Acc|0.85| |0.8| |0.85| |0.75| |\n| |0.75|0.7|0.75|0.70|0.70|0.6|0.65|0.65|\n| |0.60|0.5|0.60|0.55| |0.50| | |\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|\n\n| |0.94|Imdb|0.98|Yelp|0.92|Agnews|\n|---|---|---|---|---|---|---|\n|Test Acc|0.90| |0.94|0.88|0.86|0.92|\n| |0.84|0.88|0.86|0.90|0.82|0.88|\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|\n\nFigure 8. Limited Size versus Coverage Bias. We may assess the relative impacts of the limited size of WS training sets (comparing GT (Full) and GT (Sub)) versus their coverage bias (comparing GT (Sub) and GT (Cov)).\n\nIn Section 4.5, we observed that on some datasets, as coverage decreases, so does the performance of GT (Cov). Indeed, for any LF set, we can view the gap in performance between GT (Cov) and GT (Full) as a reflection of the aggregate impact of two data gaps that WS datasets suffer from: (1) limited size (i.e., not all training examples are labeled) and (2) coverage bias (i.e., the examples covered by LFs come from a biased subpopulation of the test distribution). Because GT (Cov) simply ignores all unlabeled examples, this gap also then reflects the value of said examples.\n\nA natural follow up question is whether limited size or coverage bias more greatly hinders learning under WS. Here, we further decompose the performance drops we observed between GT (Cov) and GT (Full) by considering a third model that interpolates between the two. Specifically, we consider GT (Sub), a model that suffers only from limited size but not coverage bias. This model is trained on a training set that shares the same size as the dataset for GT (Cov), but consists of examples re-sampled uniformly from the full training set (i.e., eliminating coverage bias).\n\nOnce we have trained all three models, we may then simply compare the following performance gaps:\n\n- $TestPerf(GT (Full)) - TestPerf(GT (Sub))$: to ablate the impact limited size\n- $TestPerf(GT (Sub)) - TestPerf(GT (Cov))$: to ablate the impact of coverage bias\n\nAs we see in Figure 8, when large gaps exist between GT (Full) and GT (Cov), most of this gap is explained by the performance drop between GT (Sub) and GT (Cov) instead of the drop between GT (Full) and GT (Sub) (e.g., especially on Semeval, Massive18, Banking77). This suggests that coverage bias is far more responsible than limited size, which perhaps makes sense in the context of WS, as LFs can label an arbitrary amount of data but only from the covered set. Also, this means that SSL techniques, initially developed in settings where labeled and unlabeled sets are i.i.d. (i.e., where limited size is the only relevant data gap), actually remain effective in low coverage WS settings despite the significant impacts of coverage bias.\n\n21", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "# Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "heading", "lvl": 2, "value": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision", "md": "## Characterizing the Impacts of Semi-supervised Learning for Weak Supervision"}, {"type": "text", "value": "E. Coverage bias explains the value of unlabeled data", "md": "E. Coverage bias explains the value of unlabeled data"}, {"type": "table", "rows": [["", "0.95", "Semeval", "0.9", "Chemprot", "0.90", "Massive18 (Ours)", "0.90", "Banking77 (Ours)"], ["Test Acc", "0.85", "", "0.8", "", "0.85", "", "0.75", ""], ["", "0.75", "0.7", "0.75", "0.70", "0.70", "0.6", "0.65", "0.65"], ["", "0.60", "0.5", "0.60", "0.55", "", "0.50", "", ""], ["", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0"]], "md": "| |0.95|Semeval|0.9|Chemprot|0.90|Massive18 (Ours)|0.90|Banking77 (Ours)|\n|---|---|---|---|---|---|---|---|---|\n|Test Acc|0.85| |0.8| |0.85| |0.75| |\n| |0.75|0.7|0.75|0.70|0.70|0.6|0.65|0.65|\n| |0.60|0.5|0.60|0.55| |0.50| | |\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|", "isPerfectTable": false, "csv": "\"\",\"0.95\",\"Semeval\",\"0.9\",\"Chemprot\",\"0.90\",\"Massive18 (Ours)\",\"0.90\",\"Banking77 (Ours)\"\n\"Test Acc\",\"0.85\",\"\",\"0.8\",\"\",\"0.85\",\"\",\"0.75\",\"\"\n\"\",\"0.75\",\"0.7\",\"0.75\",\"0.70\",\"0.70\",\"0.6\",\"0.65\",\"0.65\"\n\"\",\"0.60\",\"0.5\",\"0.60\",\"0.55\",\"\",\"0.50\",\"\",\"\"\n\"\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\""}, {"type": "table", "rows": [["", "0.94", "Imdb", "0.98", "Yelp", "0.92", "Agnews"], ["Test Acc", "0.90", "", "0.94", "0.88", "0.86", "0.92"], ["", "0.84", "0.88", "0.86", "0.90", "0.82", "0.88"], ["", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0"]], "md": "| |0.94|Imdb|0.98|Yelp|0.92|Agnews|\n|---|---|---|---|---|---|---|\n|Test Acc|0.90| |0.94|0.88|0.86|0.92|\n| |0.84|0.88|0.86|0.90|0.82|0.88|\n| |0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|0.0|0.2|0.4|0.6|0.8|1.0|", "isPerfectTable": false, "csv": "\"\",\"0.94\",\"Imdb\",\"0.98\",\"Yelp\",\"0.92\",\"Agnews\"\n\"Test Acc\",\"0.90\",\"\",\"0.94\",\"0.88\",\"0.86\",\"0.92\"\n\"\",\"0.84\",\"0.88\",\"0.86\",\"0.90\",\"0.82\",\"0.88\"\n\"\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\""}, {"type": "text", "value": "Figure 8. Limited Size versus Coverage Bias. We may assess the relative impacts of the limited size of WS training sets (comparing GT (Full) and GT (Sub)) versus their coverage bias (comparing GT (Sub) and GT (Cov)).\n\nIn Section 4.5, we observed that on some datasets, as coverage decreases, so does the performance of GT (Cov). Indeed, for any LF set, we can view the gap in performance between GT (Cov) and GT (Full) as a reflection of the aggregate impact of two data gaps that WS datasets suffer from: (1) limited size (i.e., not all training examples are labeled) and (2) coverage bias (i.e., the examples covered by LFs come from a biased subpopulation of the test distribution). Because GT (Cov) simply ignores all unlabeled examples, this gap also then reflects the value of said examples.\n\nA natural follow up question is whether limited size or coverage bias more greatly hinders learning under WS. Here, we further decompose the performance drops we observed between GT (Cov) and GT (Full) by considering a third model that interpolates between the two. Specifically, we consider GT (Sub), a model that suffers only from limited size but not coverage bias. This model is trained on a training set that shares the same size as the dataset for GT (Cov), but consists of examples re-sampled uniformly from the full training set (i.e., eliminating coverage bias).\n\nOnce we have trained all three models, we may then simply compare the following performance gaps:\n\n- $TestPerf(GT (Full)) - TestPerf(GT (Sub))$: to ablate the impact limited size\n- $TestPerf(GT (Sub)) - TestPerf(GT (Cov))$: to ablate the impact of coverage bias\n\nAs we see in Figure 8, when large gaps exist between GT (Full) and GT (Cov), most of this gap is explained by the performance drop between GT (Sub) and GT (Cov) instead of the drop between GT (Full) and GT (Sub) (e.g., especially on Semeval, Massive18, Banking77). This suggests that coverage bias is far more responsible than limited size, which perhaps makes sense in the context of WS, as LFs can label an arbitrary amount of data but only from the covered set. Also, this means that SSL techniques, initially developed in settings where labeled and unlabeled sets are i.i.d. (i.e., where limited size is the only relevant data gap), actually remain effective in low coverage WS settings despite the significant impacts of coverage bias.\n\n21", "md": "Figure 8. Limited Size versus Coverage Bias. We may assess the relative impacts of the limited size of WS training sets (comparing GT (Full) and GT (Sub)) versus their coverage bias (comparing GT (Sub) and GT (Cov)).\n\nIn Section 4.5, we observed that on some datasets, as coverage decreases, so does the performance of GT (Cov). Indeed, for any LF set, we can view the gap in performance between GT (Cov) and GT (Full) as a reflection of the aggregate impact of two data gaps that WS datasets suffer from: (1) limited size (i.e., not all training examples are labeled) and (2) coverage bias (i.e., the examples covered by LFs come from a biased subpopulation of the test distribution). Because GT (Cov) simply ignores all unlabeled examples, this gap also then reflects the value of said examples.\n\nA natural follow up question is whether limited size or coverage bias more greatly hinders learning under WS. Here, we further decompose the performance drops we observed between GT (Cov) and GT (Full) by considering a third model that interpolates between the two. Specifically, we consider GT (Sub), a model that suffers only from limited size but not coverage bias. This model is trained on a training set that shares the same size as the dataset for GT (Cov), but consists of examples re-sampled uniformly from the full training set (i.e., eliminating coverage bias).\n\nOnce we have trained all three models, we may then simply compare the following performance gaps:\n\n- $TestPerf(GT (Full)) - TestPerf(GT (Sub))$: to ablate the impact limited size\n- $TestPerf(GT (Sub)) - TestPerf(GT (Cov))$: to ablate the impact of coverage bias\n\nAs we see in Figure 8, when large gaps exist between GT (Full) and GT (Cov), most of this gap is explained by the performance drop between GT (Sub) and GT (Cov) instead of the drop between GT (Full) and GT (Sub) (e.g., especially on Semeval, Massive18, Banking77). This suggests that coverage bias is far more responsible than limited size, which perhaps makes sense in the context of WS, as LFs can label an arbitrary amount of data but only from the covered set. Also, this means that SSL techniques, initially developed in settings where labeled and unlabeled sets are i.i.d. (i.e., where limited size is the only relevant data gap), actually remain effective in low coverage WS settings despite the significant impacts of coverage bias.\n\n21"}]}], "job_id": "d7e6ede1-e870-42e3-9609-fd41cb4dcb39", "file_path": "./corpus/SSL4WS_ICML_Workshop_DMLR.pdf"}