{"pages": [{"page": 1, "text": "           Projection-Free Methods for Stochastic Simple Bilevel Optimization\n                                           with Convex Lower-level Problem\narXiv:2308.07536v1  [math.OC]  15 Aug 2023\n                                Jincheng Cao\u2217                Ruichen Jiang\u2217                 Nazanin Abolfazli\u2020\n                                    Erfan Yazdandoost Hamedani\u2020                          Aryan Mokhtari\u2217\n                                                                     Abstract\n                      In this paper, we study a class of stochastic bilevel optimization problems, also known as\n                  stochastic simple bilevel optimization, where we minimize a smooth stochastic objective function\n                  over the optimal solution set of another stochastic convex optimization problem. We introduce\n                  novel stochastic bilevel optimization methods that locally approximate the solution set of the\n                  lower-level problem via a stochastic cutting plane, and then run a conditional gradient update\n                  with variance reduction techniques to control the error induced by using stochastic gradients.\n                  For the case that the upper-level function is convex, our method requires \u02dc              O(max{1/\u01eb2          g})\n                                                                                                                         f, 1/\u01eb2\n                  stochastic oracle queries to obtain a solution that is \u01ebf-optimal for the upper-level and \u01ebg-\n                  optimal for the lower-level.         This guarantee improves the previous best-known complexity\n                  of O(max{1/\u01eb4    f, 1/\u01eb4g}).   Moreover, for the case that the upper-level function is non-convex,\n                  our method requires at most \u02dc       O(max{1/\u01eb3          g}) stochastic oracle queries to fi     nd an (\u01ebf, \u01ebg)-\n                                                                    f, 1/\u01eb3\n                  stationary point. In the fi    nite-sum setting, we show that the number of stochastic oracle calls\n                  required by our method are \u02dc       O(\u221an/\u01eb) and \u02dc    O(\u221an/\u01eb2) for the convex and non-convex settings,\n                  respectively, where \u01eb = min{\u01ebf, \u01ebg}.\n              \u2217 Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA\n           {jinchengcao@utexas.edu, rjiang@utexas.edu, mokhtari@austin.utexas.edu}\n               \u2020Department     of  Systems    and   Industrial   Engineering,    The   University   of  Arizona,    Tucson,    AZ,  USA\n           {nazaninabolfazli@email.arizona.edu, erfany@arizona.edu}\n                                                                          1", "md": "# Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem\n\n# Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem\n\narXiv:2308.07536v1 [math.OC] 15 Aug 2023\n\nJincheng Cao\u2217 Ruichen Jiang\u2217 Nazanin Abolfazli\u2020 Erfan Yazdandoost Hamedani\u2020 Aryan Mokhtari\u2217\n\n## Abstract\n\nIn this paper, we study a class of stochastic bilevel optimization problems, also known as stochastic simple bilevel optimization, where we minimize a smooth stochastic objective function over the optimal solution set of another stochastic convex optimization problem. We introduce novel stochastic bilevel optimization methods that locally approximate the solution set of the lower-level problem via a stochastic cutting plane, and then run a conditional gradient update with variance reduction techniques to control the error induced by using stochastic gradients. For the case that the upper-level function is convex, our method requires $$\\tilde{O}\\left(\\max\\left\\{\\frac{1}{\\epsilon^2_f}, \\frac{1}{\\epsilon^2_g}\\right\\}\\right)$$ stochastic oracle queries to obtain a solution that is $$\\epsilon_f$$-optimal for the upper-level and $$\\epsilon_g$$-optimal for the lower-level. This guarantee improves the previous best-known complexity of $$O\\left(\\max\\left\\{\\frac{1}{\\epsilon^4_f}, \\frac{1}{\\epsilon^4_g}\\right\\}\\right)$$. Moreover, for the case that the upper-level function is non-convex, our method requires at most $$\\tilde{O}\\left(\\max\\left\\{\\frac{1}{\\epsilon^3_g}\\right\\}\\right)$$ stochastic oracle queries to find an $$(\\epsilon_f, \\epsilon_g)$$-stationary point. In the finite-sum setting, we show that the number of stochastic oracle calls required by our method are $$\\tilde{O}\\left(\\frac{\\sqrt{n}}{\\epsilon}\\right)$$ and $$\\tilde{O}\\left(\\frac{\\sqrt{n}}{\\epsilon^2}\\right)$$ for the convex and non-convex settings, respectively, where $$\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}$$.\n\n\u2217 Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA\n\n{jinchengcao@utexas.edu, rjiang@utexas.edu, mokhtari@austin.utexas.edu}\n\n\u2020Department of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ, USA\n\n{nazaninabolfazli@email.arizona.edu, erfany@arizona.edu}", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem", "md": "# Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem"}, {"type": "heading", "lvl": 1, "value": "Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem", "md": "# Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem"}, {"type": "text", "value": "arXiv:2308.07536v1 [math.OC] 15 Aug 2023\n\nJincheng Cao\u2217 Ruichen Jiang\u2217 Nazanin Abolfazli\u2020 Erfan Yazdandoost Hamedani\u2020 Aryan Mokhtari\u2217", "md": "arXiv:2308.07536v1 [math.OC] 15 Aug 2023\n\nJincheng Cao\u2217 Ruichen Jiang\u2217 Nazanin Abolfazli\u2020 Erfan Yazdandoost Hamedani\u2020 Aryan Mokhtari\u2217"}, {"type": "heading", "lvl": 2, "value": "Abstract", "md": "## Abstract"}, {"type": "text", "value": "In this paper, we study a class of stochastic bilevel optimization problems, also known as stochastic simple bilevel optimization, where we minimize a smooth stochastic objective function over the optimal solution set of another stochastic convex optimization problem. We introduce novel stochastic bilevel optimization methods that locally approximate the solution set of the lower-level problem via a stochastic cutting plane, and then run a conditional gradient update with variance reduction techniques to control the error induced by using stochastic gradients. For the case that the upper-level function is convex, our method requires $$\\tilde{O}\\left(\\max\\left\\{\\frac{1}{\\epsilon^2_f}, \\frac{1}{\\epsilon^2_g}\\right\\}\\right)$$ stochastic oracle queries to obtain a solution that is $$\\epsilon_f$$-optimal for the upper-level and $$\\epsilon_g$$-optimal for the lower-level. This guarantee improves the previous best-known complexity of $$O\\left(\\max\\left\\{\\frac{1}{\\epsilon^4_f}, \\frac{1}{\\epsilon^4_g}\\right\\}\\right)$$. Moreover, for the case that the upper-level function is non-convex, our method requires at most $$\\tilde{O}\\left(\\max\\left\\{\\frac{1}{\\epsilon^3_g}\\right\\}\\right)$$ stochastic oracle queries to find an $$(\\epsilon_f, \\epsilon_g)$$-stationary point. In the finite-sum setting, we show that the number of stochastic oracle calls required by our method are $$\\tilde{O}\\left(\\frac{\\sqrt{n}}{\\epsilon}\\right)$$ and $$\\tilde{O}\\left(\\frac{\\sqrt{n}}{\\epsilon^2}\\right)$$ for the convex and non-convex settings, respectively, where $$\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}$$.\n\n\u2217 Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA\n\n{jinchengcao@utexas.edu, rjiang@utexas.edu, mokhtari@austin.utexas.edu}\n\n\u2020Department of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ, USA\n\n{nazaninabolfazli@email.arizona.edu, erfany@arizona.edu}", "md": "In this paper, we study a class of stochastic bilevel optimization problems, also known as stochastic simple bilevel optimization, where we minimize a smooth stochastic objective function over the optimal solution set of another stochastic convex optimization problem. We introduce novel stochastic bilevel optimization methods that locally approximate the solution set of the lower-level problem via a stochastic cutting plane, and then run a conditional gradient update with variance reduction techniques to control the error induced by using stochastic gradients. For the case that the upper-level function is convex, our method requires $$\\tilde{O}\\left(\\max\\left\\{\\frac{1}{\\epsilon^2_f}, \\frac{1}{\\epsilon^2_g}\\right\\}\\right)$$ stochastic oracle queries to obtain a solution that is $$\\epsilon_f$$-optimal for the upper-level and $$\\epsilon_g$$-optimal for the lower-level. This guarantee improves the previous best-known complexity of $$O\\left(\\max\\left\\{\\frac{1}{\\epsilon^4_f}, \\frac{1}{\\epsilon^4_g}\\right\\}\\right)$$. Moreover, for the case that the upper-level function is non-convex, our method requires at most $$\\tilde{O}\\left(\\max\\left\\{\\frac{1}{\\epsilon^3_g}\\right\\}\\right)$$ stochastic oracle queries to find an $$(\\epsilon_f, \\epsilon_g)$$-stationary point. In the finite-sum setting, we show that the number of stochastic oracle calls required by our method are $$\\tilde{O}\\left(\\frac{\\sqrt{n}}{\\epsilon}\\right)$$ and $$\\tilde{O}\\left(\\frac{\\sqrt{n}}{\\epsilon^2}\\right)$$ for the convex and non-convex settings, respectively, where $$\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}$$.\n\n\u2217 Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA\n\n{jinchengcao@utexas.edu, rjiang@utexas.edu, mokhtari@austin.utexas.edu}\n\n\u2020Department of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ, USA\n\n{nazaninabolfazli@email.arizona.edu, erfany@arizona.edu}"}]}, {"page": 2, "text": "1        Introduction\nAn important class of bilevel optimization problems is simple bilevel optimization in which we aim\nto minimize an upper-level objective function over the solution set of a lower-level problem [BM73;\nDDD10; DP20; SVZ21]. Recently this class of problems has attracted great attention in machine\nlearning society due to their applications in continual learning [BMK20], hyper-parameter opti-\nmization [FFSGP18; SCHB19], meta-learning [RFKL19; BHTV18], and reinforcement learning\n[HWWY20; Zha+20]. Motivated by large-scale learning problems, in this paper, we are particu-\nlarly interested in the stochastic variant of the simple bilevel optimization where the upper and\nlower-level objective functions are the expectations of some random functions with unknown dis-\ntributions and are accessible only through their samples. Hence, the computation of the objective\nfunction values or their gradients is not computationally tractable. Specifically, we focus on the\nstochastic simple bilevel problem defined as\n                              min        f(x) = E[ \u02dc      f(x, \u03b8)]            s.t.     x \u2208    arg min      g(z) = E[\u02dc      g(z, \u03be)],                         (1)\n                              x\u2208Rd                                                               z\u2208Z\nwhere Z is compact and convex and \u02dc                              f, \u02dcg : Rd \u2192          R are continuously differentiable functions on\nan open set containing Z, and \u03b8 and \u03be are some independent random variables drawn from some\npossibly unknown probability distributions.                                   As a result, the functions f, g : Rd \u2192                           R are also\ncontinuously differentiable functions on Z. We assume that g is convex but not necessarily strongly\nconvex, and hence the solution set of the lower-level problem in (1) is in general not a singleton. We\nalso study the finite sum version of the above problem where both functions can be written as the\naverage of n component functions, i.e., f(x) = (1/n)  n                                      i=1 \u02dc f(x, \u03b8i) and g(z) = (1/n)  n               i=1 \u02dc g(z, \u03bei).\nThe main challenge in solving problem (1), which is inherited from its deterministic variant, is the\nabsence of access to the feasible set, i.e., the lower-level solution set. This issue eliminates the\npossibility of using any projection-based or projection-free methods. There have been some efforts\nto overcome this issue in the deterministic setting (where access to f and g and their gradients is\npossible), including [JAMH23; GL21; SS17; KY21], however, there is little done on the stochastic\nsetting described above. In fact, the only work that addresses the stochastic problem in (1) is [JY22],\nwhere the authors present an iterative regularization-based stochastic extra gradient algorithm and\nshow that it requires O(1/\u01eb4                  f ) and O(1/\u01eb4        g) queries to the stochastic gradient of the upper-level and\nlower-level function, respectively, to obtain a solution that is \u01ebf-optimal for the upper-level and\n\u01ebg-optimal for the lower-level. We improve these bounds and also extend our results to nonconvex\nsettings.\nTable 1: Results on stochastic simple bilevel optimization. The abbreviations \u201cSC\u201d, \u201cC\u201d, and \u201cNC\u201d\nstand for \u201cstrongly convex\u201d, \u201cconvex\u201d, and \u201cnon-convex\u201d, respectively. Note that \u01eb = min{\u01ebf, \u01ebg}\n       References              Type           Upper level                  Lower level                          Convergence            Sample Complexity\n                                             Objective f        Objective g        Feasible set Z       Upper level       Lower level\n  aR-IP-SeG [JY22]          Stochastic       C, Lipschitz       C, Lipschitz           Closed              O(max{1/\u01eb4           g})            O(1/\u01eb4)\n                                                                                                                         f , 1/\u01eb4\n                                                                                                            \u02dc                                  \u02dc\n     Algorithm1             Stochastic        C, smooth          C, smooth            Compact              O(max{1/\u01eb2           g})            O(1/\u01eb2)\n                                                                                                                         f , 1/\u01eb2\n                                                                                                            \u02dc                                  \u02dc\n     Algorithm1             Stochastic       NC, smooth          C, smooth            Compact              O(max{1/\u01eb3           g})            O(1/\u01eb3)\n                                                                                                                         f , 1/\u01eb3\n                                                                                                            \u02dc                                  \u02dc\n     Algorithm2             Finite-sum        C, smooth          C, smooth            Compact              O(max{1/\u01ebf , 1/\u01ebg})                O(\u221an/\u01eb)\n                                                                                                            \u02dc                                 \u02dc\n     Algorithm2             Finite-sum       NC, smooth          C, smooth            Compact              O(max{1/\u01eb2           g})          O(\u221an/\u01eb2)\n                                                                                                                         f , 1/\u01eb2\nContributions.                 In this paper, we present novel projection-free stochastic bilevel optimization\nmethods with tight non-asymptotic guarantees for both upper and lower-level problems. At each\n                                                                                  2", "md": "# Document\n\n# Introduction\n\nAn important class of bilevel optimization problems is simple bilevel optimization in which we aim to minimize an upper-level objective function over the solution set of a lower-level problem [BM73; DDD10; DP20; SVZ21]. Recently this class of problems has attracted great attention in machine learning society due to their applications in continual learning [BMK20], hyper-parameter optimization [FFSGP18; SCHB19], meta-learning [RFKL19; BHTV18], and reinforcement learning [HWWY20; Zha+20]. Motivated by large-scale learning problems, in this paper, we are particularly interested in the stochastic variant of the simple bilevel optimization where the upper and lower-level objective functions are the expectations of some random functions with unknown distributions and are accessible only through their samples. Hence, the computation of the objective function values or their gradients is not computationally tractable. Specifically, we focus on the stochastic simple bilevel problem defined as\n\n$$\\min_{x\\in\\mathbb{R}^d} f(x) = E[\\tilde{f}(x, \\theta)] \\quad \\text{s.t.} \\quad x \\in \\arg\\min_{z\\in Z} g(z) = E[\\tilde{g}(z, \\xi)] \\quad (1)$$\nwhere Z is compact and convex and $\\tilde{f}, \\tilde{g} : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ are continuously differentiable functions on an open set containing Z, and $\\theta$ and $\\xi$ are some independent random variables drawn from some possibly unknown probability distributions. As a result, the functions $f, g : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ are also continuously differentiable functions on Z. We assume that g is convex but not necessarily strongly convex, and hence the solution set of the lower-level problem in (1) is in general not a singleton. We also study the finite sum version of the above problem where both functions can be written as the average of n component functions, i.e., $f(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{f}(x, \\theta_i)$ and $g(z) = \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{g}(z, \\xi_i)$.\n\nThe main challenge in solving problem (1), which is inherited from its deterministic variant, is the absence of access to the feasible set, i.e., the lower-level solution set. This issue eliminates the possibility of using any projection-based or projection-free methods. There have been some efforts to overcome this issue in the deterministic setting (where access to f and g and their gradients is possible), including [JAMH23; GL21; SS17; KY21], however, there is little done on the stochastic setting described above. In fact, the only work that addresses the stochastic problem in (1) is [JY22], where the authors present an iterative regularization-based stochastic extra gradient algorithm and show that it requires $O(\\frac{1}{\\epsilon^4_f})$ and $O(\\frac{1}{\\epsilon^4_g})$ queries to the stochastic gradient of the upper-level and lower-level function, respectively, to obtain a solution that is $\\epsilon_f$-optimal for the upper-level and $\\epsilon_g$-optimal for the lower-level. We improve these bounds and also extend our results to nonconvex settings.\n\n|References|Type|Upper level Objective f|Lower level Objective g|Feasible set Z|Upper level Convergence|Lower level Convergence|Sample Complexity|\n|---|---|---|---|---|---|---|---|\n|aR-IP-SeG [JY22]|Stochastic|C, Lipschitz|C, Lipschitz|Closed|$O(\\max\\{\\frac{1}{\\epsilon^4_g}\\})$|$O(\\frac{1}{\\epsilon^4_f}, \\frac{1}{\\epsilon^4_g})$|O(1/\\epsilon^4)|\n|Algorithm1|Stochastic|C, smooth|C, smooth|Compact|$O(\\max\\{\\frac{1}{\\epsilon^2_g}\\})$|$O(\\frac{1}{\\epsilon^2_f}, \\frac{1}{\\epsilon^2_g})$|O(1/\\epsilon^2)|\n|Algorithm1|Stochastic|NC, smooth|C, smooth|Compact|$O(\\max\\{\\frac{1}{\\epsilon^3_g}\\})$|$O(\\frac{1}{\\epsilon^3_f}, \\frac{1}{\\epsilon^3_g})$|O(1/\\epsilon^3)|\n|Algorithm2|Finite-sum|C, smooth|C, smooth|Compact|$O(\\max\\{\\frac{1}{\\epsilon_f}, \\frac{1}{\\epsilon_g}\\})$|O(\u221an/\\epsilon)| |\n|Algorithm2|Finite-sum|NC, smooth|C, smooth|Compact|$O(\\max\\{\\frac{1}{\\epsilon^2_g}\\})$|O(\u221an/\\epsilon^2)| |\n\nContributions: In this paper, we present novel projection-free stochastic bilevel optimization methods with tight non-asymptotic guarantees for both upper and lower-level problems. At each", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 1, "value": "Introduction", "md": "# Introduction"}, {"type": "text", "value": "An important class of bilevel optimization problems is simple bilevel optimization in which we aim to minimize an upper-level objective function over the solution set of a lower-level problem [BM73; DDD10; DP20; SVZ21]. Recently this class of problems has attracted great attention in machine learning society due to their applications in continual learning [BMK20], hyper-parameter optimization [FFSGP18; SCHB19], meta-learning [RFKL19; BHTV18], and reinforcement learning [HWWY20; Zha+20]. Motivated by large-scale learning problems, in this paper, we are particularly interested in the stochastic variant of the simple bilevel optimization where the upper and lower-level objective functions are the expectations of some random functions with unknown distributions and are accessible only through their samples. Hence, the computation of the objective function values or their gradients is not computationally tractable. Specifically, we focus on the stochastic simple bilevel problem defined as\n\n$$\\min_{x\\in\\mathbb{R}^d} f(x) = E[\\tilde{f}(x, \\theta)] \\quad \\text{s.t.} \\quad x \\in \\arg\\min_{z\\in Z} g(z) = E[\\tilde{g}(z, \\xi)] \\quad (1)$$\nwhere Z is compact and convex and $\\tilde{f}, \\tilde{g} : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ are continuously differentiable functions on an open set containing Z, and $\\theta$ and $\\xi$ are some independent random variables drawn from some possibly unknown probability distributions. As a result, the functions $f, g : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ are also continuously differentiable functions on Z. We assume that g is convex but not necessarily strongly convex, and hence the solution set of the lower-level problem in (1) is in general not a singleton. We also study the finite sum version of the above problem where both functions can be written as the average of n component functions, i.e., $f(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{f}(x, \\theta_i)$ and $g(z) = \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{g}(z, \\xi_i)$.\n\nThe main challenge in solving problem (1), which is inherited from its deterministic variant, is the absence of access to the feasible set, i.e., the lower-level solution set. This issue eliminates the possibility of using any projection-based or projection-free methods. There have been some efforts to overcome this issue in the deterministic setting (where access to f and g and their gradients is possible), including [JAMH23; GL21; SS17; KY21], however, there is little done on the stochastic setting described above. In fact, the only work that addresses the stochastic problem in (1) is [JY22], where the authors present an iterative regularization-based stochastic extra gradient algorithm and show that it requires $O(\\frac{1}{\\epsilon^4_f})$ and $O(\\frac{1}{\\epsilon^4_g})$ queries to the stochastic gradient of the upper-level and lower-level function, respectively, to obtain a solution that is $\\epsilon_f$-optimal for the upper-level and $\\epsilon_g$-optimal for the lower-level. We improve these bounds and also extend our results to nonconvex settings.", "md": "An important class of bilevel optimization problems is simple bilevel optimization in which we aim to minimize an upper-level objective function over the solution set of a lower-level problem [BM73; DDD10; DP20; SVZ21]. Recently this class of problems has attracted great attention in machine learning society due to their applications in continual learning [BMK20], hyper-parameter optimization [FFSGP18; SCHB19], meta-learning [RFKL19; BHTV18], and reinforcement learning [HWWY20; Zha+20]. Motivated by large-scale learning problems, in this paper, we are particularly interested in the stochastic variant of the simple bilevel optimization where the upper and lower-level objective functions are the expectations of some random functions with unknown distributions and are accessible only through their samples. Hence, the computation of the objective function values or their gradients is not computationally tractable. Specifically, we focus on the stochastic simple bilevel problem defined as\n\n$$\\min_{x\\in\\mathbb{R}^d} f(x) = E[\\tilde{f}(x, \\theta)] \\quad \\text{s.t.} \\quad x \\in \\arg\\min_{z\\in Z} g(z) = E[\\tilde{g}(z, \\xi)] \\quad (1)$$\nwhere Z is compact and convex and $\\tilde{f}, \\tilde{g} : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ are continuously differentiable functions on an open set containing Z, and $\\theta$ and $\\xi$ are some independent random variables drawn from some possibly unknown probability distributions. As a result, the functions $f, g : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ are also continuously differentiable functions on Z. We assume that g is convex but not necessarily strongly convex, and hence the solution set of the lower-level problem in (1) is in general not a singleton. We also study the finite sum version of the above problem where both functions can be written as the average of n component functions, i.e., $f(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{f}(x, \\theta_i)$ and $g(z) = \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{g}(z, \\xi_i)$.\n\nThe main challenge in solving problem (1), which is inherited from its deterministic variant, is the absence of access to the feasible set, i.e., the lower-level solution set. This issue eliminates the possibility of using any projection-based or projection-free methods. There have been some efforts to overcome this issue in the deterministic setting (where access to f and g and their gradients is possible), including [JAMH23; GL21; SS17; KY21], however, there is little done on the stochastic setting described above. In fact, the only work that addresses the stochastic problem in (1) is [JY22], where the authors present an iterative regularization-based stochastic extra gradient algorithm and show that it requires $O(\\frac{1}{\\epsilon^4_f})$ and $O(\\frac{1}{\\epsilon^4_g})$ queries to the stochastic gradient of the upper-level and lower-level function, respectively, to obtain a solution that is $\\epsilon_f$-optimal for the upper-level and $\\epsilon_g$-optimal for the lower-level. We improve these bounds and also extend our results to nonconvex settings."}, {"type": "table", "rows": [["References", "Type", "Upper level Objective f", "Lower level Objective g", "Feasible set Z", "Upper level Convergence", "Lower level Convergence", "Sample Complexity"], ["aR-IP-SeG [JY22]", "Stochastic", "C, Lipschitz", "C, Lipschitz", "Closed", "$O(\\max\\{\\frac{1}{\\epsilon^4_g}\\})$", "$O(\\frac{1}{\\epsilon^4_f}, \\frac{1}{\\epsilon^4_g})$", "O(1/\\epsilon^4)"], ["Algorithm1", "Stochastic", "C, smooth", "C, smooth", "Compact", "$O(\\max\\{\\frac{1}{\\epsilon^2_g}\\})$", "$O(\\frac{1}{\\epsilon^2_f}, \\frac{1}{\\epsilon^2_g})$", "O(1/\\epsilon^2)"], ["Algorithm1", "Stochastic", "NC, smooth", "C, smooth", "Compact", "$O(\\max\\{\\frac{1}{\\epsilon^3_g}\\})$", "$O(\\frac{1}{\\epsilon^3_f}, \\frac{1}{\\epsilon^3_g})$", "O(1/\\epsilon^3)"], ["Algorithm2", "Finite-sum", "C, smooth", "C, smooth", "Compact", "$O(\\max\\{\\frac{1}{\\epsilon_f}, \\frac{1}{\\epsilon_g}\\})$", "O(\u221an/\\epsilon)", ""], ["Algorithm2", "Finite-sum", "NC, smooth", "C, smooth", "Compact", "$O(\\max\\{\\frac{1}{\\epsilon^2_g}\\})$", "O(\u221an/\\epsilon^2)", ""]], "md": "|References|Type|Upper level Objective f|Lower level Objective g|Feasible set Z|Upper level Convergence|Lower level Convergence|Sample Complexity|\n|---|---|---|---|---|---|---|---|\n|aR-IP-SeG [JY22]|Stochastic|C, Lipschitz|C, Lipschitz|Closed|$O(\\max\\{\\frac{1}{\\epsilon^4_g}\\})$|$O(\\frac{1}{\\epsilon^4_f}, \\frac{1}{\\epsilon^4_g})$|O(1/\\epsilon^4)|\n|Algorithm1|Stochastic|C, smooth|C, smooth|Compact|$O(\\max\\{\\frac{1}{\\epsilon^2_g}\\})$|$O(\\frac{1}{\\epsilon^2_f}, \\frac{1}{\\epsilon^2_g})$|O(1/\\epsilon^2)|\n|Algorithm1|Stochastic|NC, smooth|C, smooth|Compact|$O(\\max\\{\\frac{1}{\\epsilon^3_g}\\})$|$O(\\frac{1}{\\epsilon^3_f}, \\frac{1}{\\epsilon^3_g})$|O(1/\\epsilon^3)|\n|Algorithm2|Finite-sum|C, smooth|C, smooth|Compact|$O(\\max\\{\\frac{1}{\\epsilon_f}, \\frac{1}{\\epsilon_g}\\})$|O(\u221an/\\epsilon)| |\n|Algorithm2|Finite-sum|NC, smooth|C, smooth|Compact|$O(\\max\\{\\frac{1}{\\epsilon^2_g}\\})$|O(\u221an/\\epsilon^2)| |", "isPerfectTable": true, "csv": "\"References\",\"Type\",\"Upper level Objective f\",\"Lower level Objective g\",\"Feasible set Z\",\"Upper level Convergence\",\"Lower level Convergence\",\"Sample Complexity\"\n\"aR-IP-SeG [JY22]\",\"Stochastic\",\"C, Lipschitz\",\"C, Lipschitz\",\"Closed\",\"$O(\\max\\{\\frac{1}{\\epsilon^4_g}\\})$\",\"$O(\\frac{1}{\\epsilon^4_f}, \\frac{1}{\\epsilon^4_g})$\",\"O(1/\\epsilon^4)\"\n\"Algorithm1\",\"Stochastic\",\"C, smooth\",\"C, smooth\",\"Compact\",\"$O(\\max\\{\\frac{1}{\\epsilon^2_g}\\})$\",\"$O(\\frac{1}{\\epsilon^2_f}, \\frac{1}{\\epsilon^2_g})$\",\"O(1/\\epsilon^2)\"\n\"Algorithm1\",\"Stochastic\",\"NC, smooth\",\"C, smooth\",\"Compact\",\"$O(\\max\\{\\frac{1}{\\epsilon^3_g}\\})$\",\"$O(\\frac{1}{\\epsilon^3_f}, \\frac{1}{\\epsilon^3_g})$\",\"O(1/\\epsilon^3)\"\n\"Algorithm2\",\"Finite-sum\",\"C, smooth\",\"C, smooth\",\"Compact\",\"$O(\\max\\{\\frac{1}{\\epsilon_f}, \\frac{1}{\\epsilon_g}\\})$\",\"O(\u221an/\\epsilon)\",\"\"\n\"Algorithm2\",\"Finite-sum\",\"NC, smooth\",\"C, smooth\",\"Compact\",\"$O(\\max\\{\\frac{1}{\\epsilon^2_g}\\})$\",\"O(\u221an/\\epsilon^2)\",\"\""}, {"type": "text", "value": "Contributions: In this paper, we present novel projection-free stochastic bilevel optimization methods with tight non-asymptotic guarantees for both upper and lower-level problems. At each", "md": "Contributions: In this paper, we present novel projection-free stochastic bilevel optimization methods with tight non-asymptotic guarantees for both upper and lower-level problems. At each"}]}, {"page": 3, "text": "iteration, the algorithms use a small number of samples to build unbiased and low variance estimates\nand construct a cutting plane to locally approximate the solution set of the lower-level problem and\nthen combine it with a Frank-Wolfe-type update on the upper-level objective. Our methods require\ncareful construction of the cutting plane so that with high probability it contains the solution set\nof the lower-level problem, which is obtained by selecting proper function and gradient estimators\nto achieve the obtained optimal convergence guarantees. Next, we summarize our main theoretical\nresults for the proposed Stochastic Bilevel Conditional Gradient methods for Infinite and Finite\nsample settings denoted by SBCGI and SBCGF, respectively.\n  \u2022 (Stochastic setting) We show that SBCGI (Algorithm 1), in the convex setting, finds a solution\n     \u02c6\n     x that satisfies f(\u02c6 x)\u2212f \u2217    \u2264  \u01ebf and g(\u02c6 x)\u2212g\u2217    \u2264  \u01ebg with probability 1\u2212\u03b4 within O(log(d/\u03b4\u01eb)/\u01eb2)\n     stochastic oracle queries, where \u01eb = min{\u01ebf, \u01ebg}, f \u2217          is the optimal value of problem (1) and g\u2217\n     is the optimal value of the lower-level problem. Moreover, in the non-convex setting, it finds\n     \u02c6\n     x satisfying G(\u02c6  x) \u2264   \u01ebf and g(\u02c6 x) \u2212   g\u2217 \u2264  \u01ebg with probability 1 \u2212       \u03b4 within O((log(d/\u03b4\u01eb))3/2/\u01eb3)\n     stochastic oracle queries, where G(\u02c6      x) is the Frank-Wolfe (FW) gap.\n  \u2022 (Finite-sum setting) We show that SBCGF (Algorithm 2), in the convex setting, finds \u02c6                      x that\n     satisfies f(\u02c6x)\u2212f \u2217   \u2264  \u01ebf and g(\u02c6 x)\u2212g\u2217    \u2264  \u01ebg with probability 1\u2212\u03b4 within O(\u221a           n(log(1/\u03b4\u01eb))3/2/\u01eb)\n     stochastic oracle queries, where n is the number of samples of finite-sum problem. Moreover,\n     in the nonconvex setting, it finds \u02c6    x that satisfies G(\u02c6  x) \u2264  \u01ebf and g(\u02c6 x) \u2212g\u2217    \u2264  \u01ebg with probability\n     1 \u2212  \u03b4 within O(\u221a    n log(1/\u03b4\u01eb)/\u01eb2) stochastic oracle queries.\n1.1     Related work\nGeneral stochastic bilevel. In a general format of stochastic bilevel problems, the upper-level\nfunction f also depends on an extra variable y \u2208            Rp which also affects the lower-level objective,\n                min                     f(x, y, \u03b8)]          s.t. x \u2208 arg ming(z, y) = E[\u02dc    g(z, y, \u03be)].          (2)\n             x\u2208Rd,y\u2208Rp f(x, y) = E[ \u02dc                                    z\u2208Z\nThere have been several works including [HWWY20; GW18; YJL21; Kha+21; CSY21; ABTR21]\non solving the general stochastic bilevel problem (2). However, they only focus on the setting where\nthe lower-level problem is strongly convex, i.e., g(z, y) is strongly convex with respect to z for any\nvalue of y. In fact, (2) with a convex lower-level problem is known to be NP-hard [CMS07]. Hence,\nthe results of these works are not directly comparable with our work as we focus on a simpler\nsetting, but our assumption on the lower-level objective function is weaker and it only requires the\nfunction to be convex.\nDeterministic simple bilevel. There have been some recent results on non-asymptotic guar-\nantees for the deterministic variant of problem (1).                 The BiG-SAM algorithm was presented\nin [SS17], and it was shown that its lower-level objective error converges to zero at a rate of O(1/t),\nwhile the upper-level error asymptotically converges to zero. In [KY21], the authors achieved the\nfirst non-asymptotic rate for both upper- and lower-level problems by introducing an iterative\nregularization-based method which achieves an (\u01ebf, \u01ebg)-optimal solution after O(max{1/\u01eb4                     f, 1/\u01eb4g})\niterations. In [JAMH23], the authors proposed a projection-free method for deterministic simple\nbilevel problems that has a complexity of O(max{1/\u01ebf, 1/\u01ebg}) for convex upper-level and complexity\nof O(max{1/\u01eb2    f, 1/(\u01ebf\u01ebg)}) for non-convex upper-level. Moreover, in [CXZ23] the authors presented\na switching gradient method to solve simple bilevel problems with convex smooth functions for\nboth upper- and lower-level problems with complexity O(1/\u01eb). However, all the above results are\nlimited to the deterministic setting.\n                                                           3", "md": "# Stochastic Bilevel Optimization\n\n## Stochastic Bilevel Optimization\n\nDuring each iteration, the algorithms use a small number of samples to build unbiased and low variance estimates and construct a cutting plane to locally approximate the solution set of the lower-level problem and then combine it with a Frank-Wolfe-type update on the upper-level objective. Our methods require careful construction of the cutting plane so that with high probability it contains the solution set of the lower-level problem, which is obtained by selecting proper function and gradient estimators to achieve the obtained optimal convergence guarantees. Next, we summarize our main theoretical results for the proposed Stochastic Bilevel Conditional Gradient methods for Infinite and Finite sample settings denoted by SBCGI and SBCGF, respectively.\n\n- (Stochastic setting) We show that SBCGI (Algorithm 1), in the convex setting, finds a solution \\( \\hat{x} \\) that satisfies \\( f(\\hat{x}) - f^* \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\frac{\\log(d/\\delta\\epsilon)}{\\epsilon^2}\\right) \\) stochastic oracle queries, where \\( \\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\} \\), \\( f^* \\) is the optimal value of problem (1) and \\( g^* \\) is the optimal value of the lower-level problem. Moreover, in the non-convex setting, it finds \\( \\hat{x} \\) satisfying \\( G(\\hat{x}) \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\frac{(\\log(d/\\delta\\epsilon))^{\\frac{3}{2}}}{\\epsilon^3}\\right) \\) stochastic oracle queries, where \\( G(\\hat{x}) \\) is the Frank-Wolfe (FW) gap.\n- (Finite-sum setting) We show that SBCGF (Algorithm 2), in the convex setting, finds \\( \\hat{x} \\) that satisfies \\( f(\\hat{x}) - f^* \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\sqrt{n}(\\log(1/\\delta\\epsilon))^{\\frac{3}{2}}/\\epsilon\\right) \\) stochastic oracle queries, where \\( n \\) is the number of samples of finite-sum problem. Moreover, in the nonconvex setting, it finds \\( \\hat{x} \\) that satisfies \\( G(\\hat{x}) \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\sqrt{n} \\log(1/\\delta\\epsilon)/\\epsilon^2\\right) \\) stochastic oracle queries.\n\n### Related work\n\nGeneral stochastic bilevel. In a general format of stochastic bilevel problems, the upper-level function \\( f \\) also depends on an extra variable \\( y \\in \\mathbb{R}^p \\) which also affects the lower-level objective,\n\n$$\n\\begin{aligned}\n\\min_{x\\in\\mathbb{R}^d,y\\in\\mathbb{R}^p} f(x, y) &= \\mathbb{E}\\left[\\min_{z\\in Z} g(z, y, \\xi)\\right]. \\quad (2)\n\\end{aligned}\n$$\nThere have been several works including [HWWY20; GW18; YJL21; Kha+21; CSY21; ABTR21] on solving the general stochastic bilevel problem (2). However, they only focus on the setting where the lower-level problem is strongly convex, i.e., \\( g(z, y) \\) is strongly convex with respect to \\( z \\) for any value of \\( y \\). In fact, (2) with a convex lower-level problem is known to be NP-hard [CMS07]. Hence, the results of these works are not directly comparable with our work as we focus on a simpler setting, but our assumption on the lower-level objective function is weaker and it only requires the function to be convex.\n\nDeterministic simple bilevel. There have been some recent results on non-asymptotic guarantees for the deterministic variant of problem (1). The BiG-SAM algorithm was presented in [SS17], and it was shown that its lower-level objective error converges to zero at a rate of \\( O(1/t) \\), while the upper-level error asymptotically converges to zero. In [KY21], the authors achieved the first non-asymptotic rate for both upper- and lower-level problems by introducing an iterative regularization-based method which achieves an \\( (\\epsilon_f, \\epsilon_g) \\)-optimal solution after \\( O(\\max\\{1/\\epsilon^4_f, 1/\\epsilon^4_g\\}) \\) iterations. In [JAMH23], the authors proposed a projection-free method for deterministic simple bilevel problems that has a complexity of \\( O(\\max\\{1/\\epsilon_f, 1/\\epsilon_g\\}) \\) for convex upper-level and complexity of \\( O(\\max\\{1/\\epsilon^2_f, 1/(\\epsilon_f\\epsilon_g)\\}) \\) for non-convex upper-level. Moreover, in [CXZ23] the authors presented a switching gradient method to solve simple bilevel problems with convex smooth functions for both upper- and lower-level problems with complexity \\( O(1/\\epsilon) \\). However, all the above results are limited to the deterministic setting.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Stochastic Bilevel Optimization", "md": "# Stochastic Bilevel Optimization"}, {"type": "heading", "lvl": 2, "value": "Stochastic Bilevel Optimization", "md": "## Stochastic Bilevel Optimization"}, {"type": "text", "value": "During each iteration, the algorithms use a small number of samples to build unbiased and low variance estimates and construct a cutting plane to locally approximate the solution set of the lower-level problem and then combine it with a Frank-Wolfe-type update on the upper-level objective. Our methods require careful construction of the cutting plane so that with high probability it contains the solution set of the lower-level problem, which is obtained by selecting proper function and gradient estimators to achieve the obtained optimal convergence guarantees. Next, we summarize our main theoretical results for the proposed Stochastic Bilevel Conditional Gradient methods for Infinite and Finite sample settings denoted by SBCGI and SBCGF, respectively.\n\n- (Stochastic setting) We show that SBCGI (Algorithm 1), in the convex setting, finds a solution \\( \\hat{x} \\) that satisfies \\( f(\\hat{x}) - f^* \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\frac{\\log(d/\\delta\\epsilon)}{\\epsilon^2}\\right) \\) stochastic oracle queries, where \\( \\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\} \\), \\( f^* \\) is the optimal value of problem (1) and \\( g^* \\) is the optimal value of the lower-level problem. Moreover, in the non-convex setting, it finds \\( \\hat{x} \\) satisfying \\( G(\\hat{x}) \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\frac{(\\log(d/\\delta\\epsilon))^{\\frac{3}{2}}}{\\epsilon^3}\\right) \\) stochastic oracle queries, where \\( G(\\hat{x}) \\) is the Frank-Wolfe (FW) gap.\n- (Finite-sum setting) We show that SBCGF (Algorithm 2), in the convex setting, finds \\( \\hat{x} \\) that satisfies \\( f(\\hat{x}) - f^* \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\sqrt{n}(\\log(1/\\delta\\epsilon))^{\\frac{3}{2}}/\\epsilon\\right) \\) stochastic oracle queries, where \\( n \\) is the number of samples of finite-sum problem. Moreover, in the nonconvex setting, it finds \\( \\hat{x} \\) that satisfies \\( G(\\hat{x}) \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\sqrt{n} \\log(1/\\delta\\epsilon)/\\epsilon^2\\right) \\) stochastic oracle queries.", "md": "During each iteration, the algorithms use a small number of samples to build unbiased and low variance estimates and construct a cutting plane to locally approximate the solution set of the lower-level problem and then combine it with a Frank-Wolfe-type update on the upper-level objective. Our methods require careful construction of the cutting plane so that with high probability it contains the solution set of the lower-level problem, which is obtained by selecting proper function and gradient estimators to achieve the obtained optimal convergence guarantees. Next, we summarize our main theoretical results for the proposed Stochastic Bilevel Conditional Gradient methods for Infinite and Finite sample settings denoted by SBCGI and SBCGF, respectively.\n\n- (Stochastic setting) We show that SBCGI (Algorithm 1), in the convex setting, finds a solution \\( \\hat{x} \\) that satisfies \\( f(\\hat{x}) - f^* \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\frac{\\log(d/\\delta\\epsilon)}{\\epsilon^2}\\right) \\) stochastic oracle queries, where \\( \\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\} \\), \\( f^* \\) is the optimal value of problem (1) and \\( g^* \\) is the optimal value of the lower-level problem. Moreover, in the non-convex setting, it finds \\( \\hat{x} \\) satisfying \\( G(\\hat{x}) \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\frac{(\\log(d/\\delta\\epsilon))^{\\frac{3}{2}}}{\\epsilon^3}\\right) \\) stochastic oracle queries, where \\( G(\\hat{x}) \\) is the Frank-Wolfe (FW) gap.\n- (Finite-sum setting) We show that SBCGF (Algorithm 2), in the convex setting, finds \\( \\hat{x} \\) that satisfies \\( f(\\hat{x}) - f^* \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\sqrt{n}(\\log(1/\\delta\\epsilon))^{\\frac{3}{2}}/\\epsilon\\right) \\) stochastic oracle queries, where \\( n \\) is the number of samples of finite-sum problem. Moreover, in the nonconvex setting, it finds \\( \\hat{x} \\) that satisfies \\( G(\\hat{x}) \\leq \\epsilon_f \\) and \\( g(\\hat{x}) - g^* \\leq \\epsilon_g \\) with probability \\( 1 - \\delta \\) within \\( O\\left(\\sqrt{n} \\log(1/\\delta\\epsilon)/\\epsilon^2\\right) \\) stochastic oracle queries."}, {"type": "heading", "lvl": 3, "value": "Related work", "md": "### Related work"}, {"type": "text", "value": "General stochastic bilevel. In a general format of stochastic bilevel problems, the upper-level function \\( f \\) also depends on an extra variable \\( y \\in \\mathbb{R}^p \\) which also affects the lower-level objective,\n\n$$\n\\begin{aligned}\n\\min_{x\\in\\mathbb{R}^d,y\\in\\mathbb{R}^p} f(x, y) &= \\mathbb{E}\\left[\\min_{z\\in Z} g(z, y, \\xi)\\right]. \\quad (2)\n\\end{aligned}\n$$\nThere have been several works including [HWWY20; GW18; YJL21; Kha+21; CSY21; ABTR21] on solving the general stochastic bilevel problem (2). However, they only focus on the setting where the lower-level problem is strongly convex, i.e., \\( g(z, y) \\) is strongly convex with respect to \\( z \\) for any value of \\( y \\). In fact, (2) with a convex lower-level problem is known to be NP-hard [CMS07]. Hence, the results of these works are not directly comparable with our work as we focus on a simpler setting, but our assumption on the lower-level objective function is weaker and it only requires the function to be convex.\n\nDeterministic simple bilevel. There have been some recent results on non-asymptotic guarantees for the deterministic variant of problem (1). The BiG-SAM algorithm was presented in [SS17], and it was shown that its lower-level objective error converges to zero at a rate of \\( O(1/t) \\), while the upper-level error asymptotically converges to zero. In [KY21], the authors achieved the first non-asymptotic rate for both upper- and lower-level problems by introducing an iterative regularization-based method which achieves an \\( (\\epsilon_f, \\epsilon_g) \\)-optimal solution after \\( O(\\max\\{1/\\epsilon^4_f, 1/\\epsilon^4_g\\}) \\) iterations. In [JAMH23], the authors proposed a projection-free method for deterministic simple bilevel problems that has a complexity of \\( O(\\max\\{1/\\epsilon_f, 1/\\epsilon_g\\}) \\) for convex upper-level and complexity of \\( O(\\max\\{1/\\epsilon^2_f, 1/(\\epsilon_f\\epsilon_g)\\}) \\) for non-convex upper-level. Moreover, in [CXZ23] the authors presented a switching gradient method to solve simple bilevel problems with convex smooth functions for both upper- and lower-level problems with complexity \\( O(1/\\epsilon) \\). However, all the above results are limited to the deterministic setting.", "md": "General stochastic bilevel. In a general format of stochastic bilevel problems, the upper-level function \\( f \\) also depends on an extra variable \\( y \\in \\mathbb{R}^p \\) which also affects the lower-level objective,\n\n$$\n\\begin{aligned}\n\\min_{x\\in\\mathbb{R}^d,y\\in\\mathbb{R}^p} f(x, y) &= \\mathbb{E}\\left[\\min_{z\\in Z} g(z, y, \\xi)\\right]. \\quad (2)\n\\end{aligned}\n$$\nThere have been several works including [HWWY20; GW18; YJL21; Kha+21; CSY21; ABTR21] on solving the general stochastic bilevel problem (2). However, they only focus on the setting where the lower-level problem is strongly convex, i.e., \\( g(z, y) \\) is strongly convex with respect to \\( z \\) for any value of \\( y \\). In fact, (2) with a convex lower-level problem is known to be NP-hard [CMS07]. Hence, the results of these works are not directly comparable with our work as we focus on a simpler setting, but our assumption on the lower-level objective function is weaker and it only requires the function to be convex.\n\nDeterministic simple bilevel. There have been some recent results on non-asymptotic guarantees for the deterministic variant of problem (1). The BiG-SAM algorithm was presented in [SS17], and it was shown that its lower-level objective error converges to zero at a rate of \\( O(1/t) \\), while the upper-level error asymptotically converges to zero. In [KY21], the authors achieved the first non-asymptotic rate for both upper- and lower-level problems by introducing an iterative regularization-based method which achieves an \\( (\\epsilon_f, \\epsilon_g) \\)-optimal solution after \\( O(\\max\\{1/\\epsilon^4_f, 1/\\epsilon^4_g\\}) \\) iterations. In [JAMH23], the authors proposed a projection-free method for deterministic simple bilevel problems that has a complexity of \\( O(\\max\\{1/\\epsilon_f, 1/\\epsilon_g\\}) \\) for convex upper-level and complexity of \\( O(\\max\\{1/\\epsilon^2_f, 1/(\\epsilon_f\\epsilon_g)\\}) \\) for non-convex upper-level. Moreover, in [CXZ23] the authors presented a switching gradient method to solve simple bilevel problems with convex smooth functions for both upper- and lower-level problems with complexity \\( O(1/\\epsilon) \\). However, all the above results are limited to the deterministic setting."}]}, {"page": 4, "text": " General bilevel without lower-level strong convexity.                                                     Recently, there are several recent\n works on general bilevel optimization problems without lower-level strong convexity including\n [LLZZ21; SJGL22; SC23; Hua23; CXZ23]. However, they either have a weaker theoretical results\n like asymptotic convergence rate in [LLZZ21] or have some additional assumptions. Specifically, in\n [SJGL22], the authors reformulated the problem as a constrained optimization problem and further\n assumes such problem to be a convex program. Moreover, in [SC23; Hua23], the authors in both\n papers assumed that the lower-level objective satisfies the PL inequality, while we assumed that\n the lower-level objective is convex. In [CXZ23], the authors used a looser convergence criterion that\n only guarantees convergence to a Goldstein stationary point. Since these works consider a more\n general class of problems, we argue that their theoretical results when applied to our setting are\n necessarily weaker.\n 2       Preliminaries\n 2.1       Motivating examples\nExample 1: Over-parameterized regression. A general form of problem (1) is when the lower-level\n problem represents training loss and the upper-level represents test loss. The goal is to minimize\n the test loss by selecting one of the optimal solutions for the training loss [GL21]. An instance of\n that is the constrained regression problem, where we intend to find an optimal parameter vector\n \u03b2 \u2208      Rd that minimizes the loss \u2113tr(\u03b2) over the training dataset Dtr.                                                 To represent some prior\n knowledge, we usually constrain \u03b2 to be in some subsets Z \u2286                                                Rd, e.g., Z = {\u03b2 | \u2225\u03b2\u22251 \u2264                     \u03bb} for\n some \u03bb > 0 to induce sparsity. To handle multiple global minima, we adopt the over-parameterized\n approach, where the number of samples is less than the parameters. Although achieving one of\n these global minima is possible, not all optimal solutions perform equally on other datasets. Hence,\n we introduce an upper-level objective: the loss on a validation set Dval . This helps select a training\n loss optimizer that performs well on both training and validation sets. It leads to the following\n bilevel problem:\n                                 min                                          s.t.      \u03b2 \u2208    argmin       g(z) \u225c      \u2113tr(z)                                  (3)\n                                \u03b2\u2208Rd f(\u03b2) \u225c            \u2113val(\u03b2)                                    z\u2208Z\n In this case, both the upper- and lower-level losses are smooth and convex if \u2113                                                 is smooth and convex.\nExample 2: Dictionary learning. Problem (1) also appears in lifelong learning, where the learner\n takes a series of tasks sequentially and tries to accumulate knowledge from past tasks to improve\n performance in new tasks. Here we focus on continual dictionary learning. The aim of dictionary\n learning is to obtain a compact representation of the input data. Let A = {a1, . . . , an} \u2208                                                             Rm\u00d7n\n denote a dataset of n points. We aim to get a dictionary D = [d1, . . . , dp] \u2208                                                    Rm\u00d7p such that all\n data point ai can be represented by a linear combination of basis vectors in D which can be cast\n as [Kre+03; YBD09; Roz+21; BJQS15]:\n               min         min        1          \u2225ai \u2212     Dxi\u22252    2          s.t. \u2225dj\u22252 \u2264          1, j = 1, . . . , p; \u2225xi\u22251 \u2264          \u03b4, i \u2208    N  .       (4)\n            D\u2208Rm\u00d7p       X\u2208Rp\u00d7n      2n    i\u2208N\n Moreover, we denote X = [x1, . . . , xn] \u2208                           Rp\u00d7n as the coefficient matrix. In practice, data points\n usually arrive sequentially and the representation evolves gradually. Hence, the dictionary must be\n updated sequentially as well. Assume that we already have learned a dictionary \u02c6                                                    D \u2208     Rm\u00d7p and the\n corresponding coefficient matrix \u02c6                    X \u2208     Rp\u00d7n for the dataset A. As a new dataset A\u2032 =                                     a\u20321, . . . , a\u2032\n                                                                                                                                                               n\u2032\n arrives, we intend to enrich our dictionary by learning \u02dc                       4         D \u2208     Rm\u00d7q(q > p) and the coefficient matrix", "md": "# Bilevel Optimization\n\n## General bilevel without lower-level strong convexity\n\nRecently, there are several recent works on general bilevel optimization problems without lower-level strong convexity including [LLZZ21; SJGL22; SC23; Hua23; CXZ23]. However, they either have weaker theoretical results like asymptotic convergence rate in [LLZZ21] or have some additional assumptions. Specifically, in [SJGL22], the authors reformulated the problem as a constrained optimization problem and further assume such problem to be a convex program. Moreover, in [SC23; Hua23], the authors in both papers assumed that the lower-level objective satisfies the PL inequality, while we assumed that the lower-level objective is convex. In [CXZ23], the authors used a looser convergence criterion that only guarantees convergence to a Goldstein stationary point. Since these works consider a more general class of problems, we argue that their theoretical results when applied to our setting are necessarily weaker.\n\n### Preliminaries\n\n#### Motivating examples\n\nExample 1: Over-parameterized regression\n\nA general form of problem (1) is when the lower-level problem represents training loss and the upper-level represents test loss. The goal is to minimize the test loss by selecting one of the optimal solutions for the training loss [GL21]. An instance of that is the constrained regression problem, where we intend to find an optimal parameter vector $$\\beta \\in \\mathbb{R}^d$$ that minimizes the loss $$\\ell_{tr}(\\beta)$$ over the training dataset $$D_{tr}$$. To represent some prior knowledge, we usually constrain $$\\beta$$ to be in some subsets $$Z \\subseteq \\mathbb{R}^d$$, e.g., $$Z = \\{\\beta | \\|\\beta\\|_1 \\leq \\lambda\\}$$ for some $$\\lambda > 0$$ to induce sparsity. To handle multiple global minima, we adopt the over-parameterized approach, where the number of samples is less than the parameters. Although achieving one of these global minima is possible, not all optimal solutions perform equally on other datasets. Hence, we introduce an upper-level objective: the loss on a validation set $$D_{val}$$. This helps select a training loss optimizer that performs well on both training and validation sets. It leads to the following bilevel problem:\n\n$$\n\\begin{aligned}\n&\\min_{\\beta \\in \\mathbb{R}^d} f(\\beta) \\equiv \\ell_{val}(\\beta) \\\\\n&\\text{s.t. } \\beta \\in \\text{argmin}_{z \\in Z} g(z) \\equiv \\ell_{tr}(z) \\quad (3)\n\\end{aligned}\n$$\nIn this case, both the upper- and lower-level losses are smooth and convex if $$\\ell$$ is smooth and convex.\n\nExample 2: Dictionary learning\n\nProblem (1) also appears in lifelong learning, where the learner takes a series of tasks sequentially and tries to accumulate knowledge from past tasks to improve performance in new tasks. Here we focus on continual dictionary learning. The aim of dictionary learning is to obtain a compact representation of the input data. Let $$A = \\{a_1, ..., a_n\\} \\in \\mathbb{R}^{m \\times n}$$ denote a dataset of $$n$$ points. We aim to get a dictionary $$D = [d_1, ..., d_p] \\in \\mathbb{R}^{m \\times p}$$ such that all data point $$a_i$$ can be represented by a linear combination of basis vectors in $$D$$ which can be cast as:\n\n$$\n\\begin{aligned}\n&\\min_{D \\in \\mathbb{R}^{m \\times p}, X \\in \\mathbb{R}^{p \\times n}} \\sum_{i \\in N} \\left\\|a_i - Dx_i\\right\\|_2^2 \\\\\n&\\text{s.t. } \\left\\|d_j\\right\\|_2 \\leq 1, j = 1, ..., p; \\left\\|x_i\\right\\|_1 \\leq \\delta, i \\in N \\quad (4)\n\\end{aligned}\n$$\nMoreover, we denote $$X = [x_1, ..., x_n] \\in \\mathbb{R}^{p \\times n}$$ as the coefficient matrix. In practice, data points usually arrive sequentially and the representation evolves gradually. Hence, the dictionary must be updated sequentially as well. Assume that we already have learned a dictionary $$\\hat{D} \\in \\mathbb{R}^{m \\times p}$$ and the corresponding coefficient matrix $$\\hat{X} \\in \\mathbb{R}^{p \\times n}$$ for the dataset $$A$$. As a new dataset $$A' = \\{a'_1, ..., a'_{n'}\\}$$ arrives, we intend to enrich our dictionary by learning $$\\tilde{D} \\in \\mathbb{R}^{m \\times q} (q > p)$$ and the coefficient matrix", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Bilevel Optimization", "md": "# Bilevel Optimization"}, {"type": "heading", "lvl": 2, "value": "General bilevel without lower-level strong convexity", "md": "## General bilevel without lower-level strong convexity"}, {"type": "text", "value": "Recently, there are several recent works on general bilevel optimization problems without lower-level strong convexity including [LLZZ21; SJGL22; SC23; Hua23; CXZ23]. However, they either have weaker theoretical results like asymptotic convergence rate in [LLZZ21] or have some additional assumptions. Specifically, in [SJGL22], the authors reformulated the problem as a constrained optimization problem and further assume such problem to be a convex program. Moreover, in [SC23; Hua23], the authors in both papers assumed that the lower-level objective satisfies the PL inequality, while we assumed that the lower-level objective is convex. In [CXZ23], the authors used a looser convergence criterion that only guarantees convergence to a Goldstein stationary point. Since these works consider a more general class of problems, we argue that their theoretical results when applied to our setting are necessarily weaker.", "md": "Recently, there are several recent works on general bilevel optimization problems without lower-level strong convexity including [LLZZ21; SJGL22; SC23; Hua23; CXZ23]. However, they either have weaker theoretical results like asymptotic convergence rate in [LLZZ21] or have some additional assumptions. Specifically, in [SJGL22], the authors reformulated the problem as a constrained optimization problem and further assume such problem to be a convex program. Moreover, in [SC23; Hua23], the authors in both papers assumed that the lower-level objective satisfies the PL inequality, while we assumed that the lower-level objective is convex. In [CXZ23], the authors used a looser convergence criterion that only guarantees convergence to a Goldstein stationary point. Since these works consider a more general class of problems, we argue that their theoretical results when applied to our setting are necessarily weaker."}, {"type": "heading", "lvl": 3, "value": "Preliminaries", "md": "### Preliminaries"}, {"type": "heading", "lvl": 4, "value": "Motivating examples", "md": "#### Motivating examples"}, {"type": "text", "value": "Example 1: Over-parameterized regression\n\nA general form of problem (1) is when the lower-level problem represents training loss and the upper-level represents test loss. The goal is to minimize the test loss by selecting one of the optimal solutions for the training loss [GL21]. An instance of that is the constrained regression problem, where we intend to find an optimal parameter vector $$\\beta \\in \\mathbb{R}^d$$ that minimizes the loss $$\\ell_{tr}(\\beta)$$ over the training dataset $$D_{tr}$$. To represent some prior knowledge, we usually constrain $$\\beta$$ to be in some subsets $$Z \\subseteq \\mathbb{R}^d$$, e.g., $$Z = \\{\\beta | \\|\\beta\\|_1 \\leq \\lambda\\}$$ for some $$\\lambda > 0$$ to induce sparsity. To handle multiple global minima, we adopt the over-parameterized approach, where the number of samples is less than the parameters. Although achieving one of these global minima is possible, not all optimal solutions perform equally on other datasets. Hence, we introduce an upper-level objective: the loss on a validation set $$D_{val}$$. This helps select a training loss optimizer that performs well on both training and validation sets. It leads to the following bilevel problem:\n\n$$\n\\begin{aligned}\n&\\min_{\\beta \\in \\mathbb{R}^d} f(\\beta) \\equiv \\ell_{val}(\\beta) \\\\\n&\\text{s.t. } \\beta \\in \\text{argmin}_{z \\in Z} g(z) \\equiv \\ell_{tr}(z) \\quad (3)\n\\end{aligned}\n$$\nIn this case, both the upper- and lower-level losses are smooth and convex if $$\\ell$$ is smooth and convex.\n\nExample 2: Dictionary learning\n\nProblem (1) also appears in lifelong learning, where the learner takes a series of tasks sequentially and tries to accumulate knowledge from past tasks to improve performance in new tasks. Here we focus on continual dictionary learning. The aim of dictionary learning is to obtain a compact representation of the input data. Let $$A = \\{a_1, ..., a_n\\} \\in \\mathbb{R}^{m \\times n}$$ denote a dataset of $$n$$ points. We aim to get a dictionary $$D = [d_1, ..., d_p] \\in \\mathbb{R}^{m \\times p}$$ such that all data point $$a_i$$ can be represented by a linear combination of basis vectors in $$D$$ which can be cast as:\n\n$$\n\\begin{aligned}\n&\\min_{D \\in \\mathbb{R}^{m \\times p}, X \\in \\mathbb{R}^{p \\times n}} \\sum_{i \\in N} \\left\\|a_i - Dx_i\\right\\|_2^2 \\\\\n&\\text{s.t. } \\left\\|d_j\\right\\|_2 \\leq 1, j = 1, ..., p; \\left\\|x_i\\right\\|_1 \\leq \\delta, i \\in N \\quad (4)\n\\end{aligned}\n$$\nMoreover, we denote $$X = [x_1, ..., x_n] \\in \\mathbb{R}^{p \\times n}$$ as the coefficient matrix. In practice, data points usually arrive sequentially and the representation evolves gradually. Hence, the dictionary must be updated sequentially as well. Assume that we already have learned a dictionary $$\\hat{D} \\in \\mathbb{R}^{m \\times p}$$ and the corresponding coefficient matrix $$\\hat{X} \\in \\mathbb{R}^{p \\times n}$$ for the dataset $$A$$. As a new dataset $$A' = \\{a'_1, ..., a'_{n'}\\}$$ arrives, we intend to enrich our dictionary by learning $$\\tilde{D} \\in \\mathbb{R}^{m \\times q} (q > p)$$ and the coefficient matrix", "md": "Example 1: Over-parameterized regression\n\nA general form of problem (1) is when the lower-level problem represents training loss and the upper-level represents test loss. The goal is to minimize the test loss by selecting one of the optimal solutions for the training loss [GL21]. An instance of that is the constrained regression problem, where we intend to find an optimal parameter vector $$\\beta \\in \\mathbb{R}^d$$ that minimizes the loss $$\\ell_{tr}(\\beta)$$ over the training dataset $$D_{tr}$$. To represent some prior knowledge, we usually constrain $$\\beta$$ to be in some subsets $$Z \\subseteq \\mathbb{R}^d$$, e.g., $$Z = \\{\\beta | \\|\\beta\\|_1 \\leq \\lambda\\}$$ for some $$\\lambda > 0$$ to induce sparsity. To handle multiple global minima, we adopt the over-parameterized approach, where the number of samples is less than the parameters. Although achieving one of these global minima is possible, not all optimal solutions perform equally on other datasets. Hence, we introduce an upper-level objective: the loss on a validation set $$D_{val}$$. This helps select a training loss optimizer that performs well on both training and validation sets. It leads to the following bilevel problem:\n\n$$\n\\begin{aligned}\n&\\min_{\\beta \\in \\mathbb{R}^d} f(\\beta) \\equiv \\ell_{val}(\\beta) \\\\\n&\\text{s.t. } \\beta \\in \\text{argmin}_{z \\in Z} g(z) \\equiv \\ell_{tr}(z) \\quad (3)\n\\end{aligned}\n$$\nIn this case, both the upper- and lower-level losses are smooth and convex if $$\\ell$$ is smooth and convex.\n\nExample 2: Dictionary learning\n\nProblem (1) also appears in lifelong learning, where the learner takes a series of tasks sequentially and tries to accumulate knowledge from past tasks to improve performance in new tasks. Here we focus on continual dictionary learning. The aim of dictionary learning is to obtain a compact representation of the input data. Let $$A = \\{a_1, ..., a_n\\} \\in \\mathbb{R}^{m \\times n}$$ denote a dataset of $$n$$ points. We aim to get a dictionary $$D = [d_1, ..., d_p] \\in \\mathbb{R}^{m \\times p}$$ such that all data point $$a_i$$ can be represented by a linear combination of basis vectors in $$D$$ which can be cast as:\n\n$$\n\\begin{aligned}\n&\\min_{D \\in \\mathbb{R}^{m \\times p}, X \\in \\mathbb{R}^{p \\times n}} \\sum_{i \\in N} \\left\\|a_i - Dx_i\\right\\|_2^2 \\\\\n&\\text{s.t. } \\left\\|d_j\\right\\|_2 \\leq 1, j = 1, ..., p; \\left\\|x_i\\right\\|_1 \\leq \\delta, i \\in N \\quad (4)\n\\end{aligned}\n$$\nMoreover, we denote $$X = [x_1, ..., x_n] \\in \\mathbb{R}^{p \\times n}$$ as the coefficient matrix. In practice, data points usually arrive sequentially and the representation evolves gradually. Hence, the dictionary must be updated sequentially as well. Assume that we already have learned a dictionary $$\\hat{D} \\in \\mathbb{R}^{m \\times p}$$ and the corresponding coefficient matrix $$\\hat{X} \\in \\mathbb{R}^{p \\times n}$$ for the dataset $$A$$. As a new dataset $$A' = \\{a'_1, ..., a'_{n'}\\}$$ arrives, we intend to enrich our dictionary by learning $$\\tilde{D} \\in \\mathbb{R}^{m \\times q} (q > p)$$ and the coefficient matrix"}]}, {"page": 5, "text": " X\u02dc\u2208    Rq\u00d7n\u2032 for the new dataset while maintaining good performance of \u02dc                      D on the old dataset A as\n well as the learned coefficient matrix \u02c6         X. This leads to the following stochastic bilevel problem:\n                min        min                                                                 \u02dc              g( \u02dc\n                                      D, \u02dc                                                                       D),           (5)\n              \u02dc          \u02dc               X)         s.t.    \u2225\u02dcxk\u22251 \u2264    \u03b4, k = 1, . . . , n\u2032; D \u2208    argmin\n              D\u2208Rm\u00d7q    X\u2208Rq\u00d7n\u2032 f( \u02dc                                                                \u2225\u02dcdj\u22252\u22641\n where f( \u02dc  D, \u02dcX) \u225c      1   n\u2032k=1 \u2225a\u2032       D\u02dcx k\u222522 represents the average reconstruction error on the new\n dataset A\u2032, and g( \u02dc     2n\u2032     1   n  k \u2212   \u02dc    D\u02c6 x i\u22252\n                         D) \u225c     2n    i=1 \u2225ai \u2212    \u02dc     2 represents the error on the old dataset A. Note that\n we denote \u02c6    x i as the prolonged vector in Rq by appending zeros at the end. In problem (5), the\n upper-level objective is non-convex, while the lower-level loss is convex with multiple minima.\n 2.2      Assumptions and defi               nitions\n Next, we formally state the assumptions required in this work.\n Assumption 2.1. Z is convex and compact with diameter D, i.e., \u2200x, y \u2208                           Z, we have \u2225x\u2212y\u2225         \u2264   D.\n Assumption 2.2. The upper-level stochastic function \u02dc                    f satisfi es the following conditions:\n  (i) \u2207  f\u02dcis Lipschitz with constant Lf, i.e., \u2200x, y \u2208              Z, \u2200\u03b8, \u2225\u2207    \u02dc\n                                                                                 f(x, \u03b8) \u2212    \u2207  \u02dc\n (ii) The stochastic gradients noise is sub-Gaussian, E[exp{\u2225\u2207                     \u02dc            f(y, \u03b8)\u2225    \u2264  Lf\u2225x \u2212    y\u2225.\n                                                                                  f(x, \u03b8) \u2212    \u2207f(x)\u22252/\u03c32    f}] \u2264   exp{1}.\n Assumption 2.3. The lower-level stochastic function \u02dc                   g satisfi  es the following conditions:\n  (i) g is convex and \u2207\u02dc       g is Lg-Lipschitz, i.e., \u2200x, y \u2208        Z, \u2200\u03be, \u2225\u2207\u02dc   g(x, \u03be) \u2212   \u2207\u02dcg(y, \u03be)\u2225   \u2264   Lg\u2225x \u2212    y\u2225.\n (ii) The stochastic gradients noise is sub-Gaussian, E[exp{\u2225\u2207\u02dc                   g(x, \u03be) \u2212   \u2207g(x)\u22252/\u03c32     g}] \u2264  exp{1}.\n(iii) The stochastic functions noise is sub-Gaussian, E[exp{|\u02dc                 g(x, \u03be) \u2212   g(x)|2/\u03c32  l }] \u2264  exp{1}.\n Remark 2.1. Assumptions 2.1 and 2.3(i) imply that \u02dc                       g is Lipschitz continuous on an open set\n containing Z with some constant Ll, i.e., for all x, y \u2208                 Z, we have |\u02dc    g(x) \u2212   \u02dc\n                                                                                                    g(y)| \u2264    Ll\u2225x \u2212   y\u2225.\n In the paper, we denote g\u2217          \u225c   minz\u2208Z g(z) and X \u2217     g \u225c   arg min   z\u2208Z g(z) as the optimal value and the\n optimal solution set of the lower-level problem, respectively. Note that by Assumption 2.3, the set\n X \u2217\n   g is nonempty, convex, and compact, but typically not a singleton as g potentially has multiple\n minima on Z. Furthermore, we denote f \u2217                 and x\u2217    as the optimal value and an optimal solution of\n problem (1), which are assured to exist since f is continuous and X \u2217                    g is compact.\n Definition 2.1. When f is convex, a point \u02c6                   x \u2208    Z is (\u01ebf, \u01ebg)-optimal if f(\u02c6       x) \u2212   f \u2217  \u2264   \u01ebf and\n g(\u02c6x) \u2212   g\u2217  \u2264  \u01ebg. When f is non-convex, \u02c6         x \u2208   Z is (\u01ebf, \u01ebg)-optimal if G(\u02c6      x) \u2264   \u01ebf and g(\u02c6  x) \u2212   g\u2217  \u2264  \u01ebg,\n where G(\u02c6   x) is the FW gap [Jag13; Lac16] defi            ned as G(\u02c6   x) \u225c   maxs\u2208X \u2217  g {\u27e8\u2207f(\u02c6 x), \u02c6x \u2212  s\u27e9}.\n 3      Algorithms\n Conditional gradient for simple bilevel optimization. A variant of the conditional gradient\n (CG) method for solving bilevel problems has been introduced in [JAMH23] which uses a cutting\n                                                                 5", "md": "$$\n\\tilde{X} \\in \\mathbb{R}^{q \\times n'} \\text{ for the new dataset while maintaining good performance of } \\tilde{D} \\text{ on the old dataset } A \\text{ as well as the learned coefficient matrix } \\hat{X}. \\text{ This leads to the following stochastic bilevel problem:}\n$$\n\n$$\n\\begin{aligned}\n&\\min_{D \\in \\mathbb{R}^{m \\times q}} \\min_{X \\in \\mathbb{R}^{q \\times n'}} \\tilde{g}(\\tilde{D}, \\tilde{X}) \\\\\n&\\text{s.t. } \\| \\tilde{x}_k \\|_1 \\leq \\delta, k = 1, ..., n'; D \\in \\arg\\min \\left\\{ f(\\tilde{D}, \\tilde{X}) \\mid \\| \\tilde{d}_j \\|_2 \\leq 1 \\right\\}\n\\end{aligned}\n$$\n\n$$\n\\text{where } f(\\tilde{D}, \\tilde{X}) \\triangleq \\frac{1}{n'} \\sum_{k=1}^{n'} \\| \\mathbf{a}'_k \\tilde{D} \\tilde{x}_k \\|_2^2 \\text{ represents the average reconstruction error on the new dataset } A', \\text{ and } g(\\tilde{D}) \\triangleq \\frac{1}{2n'} \\sum_{i=1}^{n} \\| \\mathbf{a}_i - \\tilde{D} \\hat{x}_i \\|_2^2 \\text{ represents the error on the old dataset } A. \\text{ Note that we denote } \\hat{x}_i \\text{ as the prolonged vector in } \\mathbb{R}^q \\text{ by appending zeros at the end. In problem (5), the upper-level objective is non-convex, while the lower-level loss is convex with multiple minima.}\n$$\n\n## Assumptions and definitions\n\nNext, we formally state the assumptions required in this work.\n\nAssumption 2.1. Z is convex and compact with diameter D, i.e., $\\forall x, y \\in Z$, we have $\\|x-y\\| \\leq D$.\n\nAssumption 2.2. The upper-level stochastic function $\\tilde{f}$ satisfies the following conditions:\n\n1. (i) $\\nabla \\tilde{f}$ is Lipschitz with constant $L_f$, i.e., $\\forall x, y \\in Z, \\forall \\theta, \\| \\nabla \\tilde{f}(x, \\theta) - \\nabla \\tilde{f}(y, \\theta) \\| \\leq L_f \\|x - y\\|$.\n2. (ii) The stochastic gradients noise is sub-Gaussian, $E[\\exp\\{\\| \\nabla \\tilde{f}(y, \\theta) \\| \\leq L_f \\|x - y\\| \\}] \\leq \\exp\\{1\\}$.\n\nAssumption 2.3. The lower-level stochastic function $\\tilde{g}$ satisfies the following conditions:\n\n1. (i) $g$ is convex and $\\nabla \\tilde{g}$ is $L_g$-Lipschitz, i.e., $\\forall x, y \\in Z, \\forall \\xi, \\| \\nabla \\tilde{g}(x, \\xi) - \\nabla \\tilde{g}(y, \\xi) \\| \\leq L_g \\|x - y\\|$.\n2. (ii) The stochastic gradients noise is sub-Gaussian, $E[\\exp\\{\\| \\nabla \\tilde{g}(x, \\xi) - \\nabla g(x) \\| \\leq \\sigma^2_g \\}] \\leq \\exp\\{1\\}$.\n3. (iii) The stochastic functions noise is sub-Gaussian, $E[\\exp\\{| \\tilde{g}(x, \\xi) - g(x) |^2 / \\sigma^2_l \\}] \\leq \\exp\\{1\\}$.\n\nRemark 2.1. Assumptions 2.1 and 2.3(i) imply that $\\tilde{g}$ is Lipschitz continuous on an open set containing $Z$ with some constant $L_l$, i.e., for all $x, y \\in Z$, we have $| \\tilde{g}(x) - \\tilde{g}(y) | \\leq L_l \\|x - y\\|$.\n\nIn the paper, we denote $g^* \\triangleq \\min_{z \\in Z} g(z)$ and $X^*_g \\triangleq \\arg \\min_{z \\in Z} g(z)$ as the optimal value and the optimal solution set of the lower-level problem, respectively. Note that by Assumption 2.3, the set $X^*_g$ is nonempty, convex, and compact, but typically not a singleton as $g$ potentially has multiple minima on $Z$. Furthermore, we denote $f^*$ and $x^*$ as the optimal value and an optimal solution of problem (1), which are assured to exist since $f$ is continuous and $X^*_g$ is compact.\n\nDefinition 2.1. When $f$ is convex, a point $\\hat{x} \\in Z$ is $(\\epsilon_f, \\epsilon_g)$-optimal if $f(\\hat{x}) - f^* \\leq \\epsilon_f$ and $g(\\hat{x}) - g^* \\leq \\epsilon_g$. When $f$ is non-convex, $\\hat{x} \\in Z$ is $(\\epsilon_f, \\epsilon_g)$-optimal if $G(\\hat{x}) \\leq \\epsilon_f$ and $g(\\hat{x}) - g^* \\leq \\epsilon_g$, where $G(\\hat{x})$ is the FW gap [Jag13; Lac16] defined as $G(\\hat{x}) \\triangleq \\max_{s \\in X^*_g} \\{ \\langle \\nabla f(\\hat{x}), \\hat{x} - s \\rangle \\}$.\n\n## Algorithms\n\nConditional gradient for simple bilevel optimization. A variant of the conditional gradient (CG) method for solving bilevel problems has been introduced in [JAMH23] which uses a cutting", "images": [], "items": [{"type": "text", "value": "$$\n\\tilde{X} \\in \\mathbb{R}^{q \\times n'} \\text{ for the new dataset while maintaining good performance of } \\tilde{D} \\text{ on the old dataset } A \\text{ as well as the learned coefficient matrix } \\hat{X}. \\text{ This leads to the following stochastic bilevel problem:}\n$$\n\n$$\n\\begin{aligned}\n&\\min_{D \\in \\mathbb{R}^{m \\times q}} \\min_{X \\in \\mathbb{R}^{q \\times n'}} \\tilde{g}(\\tilde{D}, \\tilde{X}) \\\\\n&\\text{s.t. } \\| \\tilde{x}_k \\|_1 \\leq \\delta, k = 1, ..., n'; D \\in \\arg\\min \\left\\{ f(\\tilde{D}, \\tilde{X}) \\mid \\| \\tilde{d}_j \\|_2 \\leq 1 \\right\\}\n\\end{aligned}\n$$\n\n$$\n\\text{where } f(\\tilde{D}, \\tilde{X}) \\triangleq \\frac{1}{n'} \\sum_{k=1}^{n'} \\| \\mathbf{a}'_k \\tilde{D} \\tilde{x}_k \\|_2^2 \\text{ represents the average reconstruction error on the new dataset } A', \\text{ and } g(\\tilde{D}) \\triangleq \\frac{1}{2n'} \\sum_{i=1}^{n} \\| \\mathbf{a}_i - \\tilde{D} \\hat{x}_i \\|_2^2 \\text{ represents the error on the old dataset } A. \\text{ Note that we denote } \\hat{x}_i \\text{ as the prolonged vector in } \\mathbb{R}^q \\text{ by appending zeros at the end. In problem (5), the upper-level objective is non-convex, while the lower-level loss is convex with multiple minima.}\n$$", "md": "$$\n\\tilde{X} \\in \\mathbb{R}^{q \\times n'} \\text{ for the new dataset while maintaining good performance of } \\tilde{D} \\text{ on the old dataset } A \\text{ as well as the learned coefficient matrix } \\hat{X}. \\text{ This leads to the following stochastic bilevel problem:}\n$$\n\n$$\n\\begin{aligned}\n&\\min_{D \\in \\mathbb{R}^{m \\times q}} \\min_{X \\in \\mathbb{R}^{q \\times n'}} \\tilde{g}(\\tilde{D}, \\tilde{X}) \\\\\n&\\text{s.t. } \\| \\tilde{x}_k \\|_1 \\leq \\delta, k = 1, ..., n'; D \\in \\arg\\min \\left\\{ f(\\tilde{D}, \\tilde{X}) \\mid \\| \\tilde{d}_j \\|_2 \\leq 1 \\right\\}\n\\end{aligned}\n$$\n\n$$\n\\text{where } f(\\tilde{D}, \\tilde{X}) \\triangleq \\frac{1}{n'} \\sum_{k=1}^{n'} \\| \\mathbf{a}'_k \\tilde{D} \\tilde{x}_k \\|_2^2 \\text{ represents the average reconstruction error on the new dataset } A', \\text{ and } g(\\tilde{D}) \\triangleq \\frac{1}{2n'} \\sum_{i=1}^{n} \\| \\mathbf{a}_i - \\tilde{D} \\hat{x}_i \\|_2^2 \\text{ represents the error on the old dataset } A. \\text{ Note that we denote } \\hat{x}_i \\text{ as the prolonged vector in } \\mathbb{R}^q \\text{ by appending zeros at the end. In problem (5), the upper-level objective is non-convex, while the lower-level loss is convex with multiple minima.}\n$$"}, {"type": "heading", "lvl": 2, "value": "Assumptions and definitions", "md": "## Assumptions and definitions"}, {"type": "text", "value": "Next, we formally state the assumptions required in this work.\n\nAssumption 2.1. Z is convex and compact with diameter D, i.e., $\\forall x, y \\in Z$, we have $\\|x-y\\| \\leq D$.\n\nAssumption 2.2. The upper-level stochastic function $\\tilde{f}$ satisfies the following conditions:\n\n1. (i) $\\nabla \\tilde{f}$ is Lipschitz with constant $L_f$, i.e., $\\forall x, y \\in Z, \\forall \\theta, \\| \\nabla \\tilde{f}(x, \\theta) - \\nabla \\tilde{f}(y, \\theta) \\| \\leq L_f \\|x - y\\|$.\n2. (ii) The stochastic gradients noise is sub-Gaussian, $E[\\exp\\{\\| \\nabla \\tilde{f}(y, \\theta) \\| \\leq L_f \\|x - y\\| \\}] \\leq \\exp\\{1\\}$.\n\nAssumption 2.3. The lower-level stochastic function $\\tilde{g}$ satisfies the following conditions:\n\n1. (i) $g$ is convex and $\\nabla \\tilde{g}$ is $L_g$-Lipschitz, i.e., $\\forall x, y \\in Z, \\forall \\xi, \\| \\nabla \\tilde{g}(x, \\xi) - \\nabla \\tilde{g}(y, \\xi) \\| \\leq L_g \\|x - y\\|$.\n2. (ii) The stochastic gradients noise is sub-Gaussian, $E[\\exp\\{\\| \\nabla \\tilde{g}(x, \\xi) - \\nabla g(x) \\| \\leq \\sigma^2_g \\}] \\leq \\exp\\{1\\}$.\n3. (iii) The stochastic functions noise is sub-Gaussian, $E[\\exp\\{| \\tilde{g}(x, \\xi) - g(x) |^2 / \\sigma^2_l \\}] \\leq \\exp\\{1\\}$.\n\nRemark 2.1. Assumptions 2.1 and 2.3(i) imply that $\\tilde{g}$ is Lipschitz continuous on an open set containing $Z$ with some constant $L_l$, i.e., for all $x, y \\in Z$, we have $| \\tilde{g}(x) - \\tilde{g}(y) | \\leq L_l \\|x - y\\|$.\n\nIn the paper, we denote $g^* \\triangleq \\min_{z \\in Z} g(z)$ and $X^*_g \\triangleq \\arg \\min_{z \\in Z} g(z)$ as the optimal value and the optimal solution set of the lower-level problem, respectively. Note that by Assumption 2.3, the set $X^*_g$ is nonempty, convex, and compact, but typically not a singleton as $g$ potentially has multiple minima on $Z$. Furthermore, we denote $f^*$ and $x^*$ as the optimal value and an optimal solution of problem (1), which are assured to exist since $f$ is continuous and $X^*_g$ is compact.\n\nDefinition 2.1. When $f$ is convex, a point $\\hat{x} \\in Z$ is $(\\epsilon_f, \\epsilon_g)$-optimal if $f(\\hat{x}) - f^* \\leq \\epsilon_f$ and $g(\\hat{x}) - g^* \\leq \\epsilon_g$. When $f$ is non-convex, $\\hat{x} \\in Z$ is $(\\epsilon_f, \\epsilon_g)$-optimal if $G(\\hat{x}) \\leq \\epsilon_f$ and $g(\\hat{x}) - g^* \\leq \\epsilon_g$, where $G(\\hat{x})$ is the FW gap [Jag13; Lac16] defined as $G(\\hat{x}) \\triangleq \\max_{s \\in X^*_g} \\{ \\langle \\nabla f(\\hat{x}), \\hat{x} - s \\rangle \\}$.", "md": "Next, we formally state the assumptions required in this work.\n\nAssumption 2.1. Z is convex and compact with diameter D, i.e., $\\forall x, y \\in Z$, we have $\\|x-y\\| \\leq D$.\n\nAssumption 2.2. The upper-level stochastic function $\\tilde{f}$ satisfies the following conditions:\n\n1. (i) $\\nabla \\tilde{f}$ is Lipschitz with constant $L_f$, i.e., $\\forall x, y \\in Z, \\forall \\theta, \\| \\nabla \\tilde{f}(x, \\theta) - \\nabla \\tilde{f}(y, \\theta) \\| \\leq L_f \\|x - y\\|$.\n2. (ii) The stochastic gradients noise is sub-Gaussian, $E[\\exp\\{\\| \\nabla \\tilde{f}(y, \\theta) \\| \\leq L_f \\|x - y\\| \\}] \\leq \\exp\\{1\\}$.\n\nAssumption 2.3. The lower-level stochastic function $\\tilde{g}$ satisfies the following conditions:\n\n1. (i) $g$ is convex and $\\nabla \\tilde{g}$ is $L_g$-Lipschitz, i.e., $\\forall x, y \\in Z, \\forall \\xi, \\| \\nabla \\tilde{g}(x, \\xi) - \\nabla \\tilde{g}(y, \\xi) \\| \\leq L_g \\|x - y\\|$.\n2. (ii) The stochastic gradients noise is sub-Gaussian, $E[\\exp\\{\\| \\nabla \\tilde{g}(x, \\xi) - \\nabla g(x) \\| \\leq \\sigma^2_g \\}] \\leq \\exp\\{1\\}$.\n3. (iii) The stochastic functions noise is sub-Gaussian, $E[\\exp\\{| \\tilde{g}(x, \\xi) - g(x) |^2 / \\sigma^2_l \\}] \\leq \\exp\\{1\\}$.\n\nRemark 2.1. Assumptions 2.1 and 2.3(i) imply that $\\tilde{g}$ is Lipschitz continuous on an open set containing $Z$ with some constant $L_l$, i.e., for all $x, y \\in Z$, we have $| \\tilde{g}(x) - \\tilde{g}(y) | \\leq L_l \\|x - y\\|$.\n\nIn the paper, we denote $g^* \\triangleq \\min_{z \\in Z} g(z)$ and $X^*_g \\triangleq \\arg \\min_{z \\in Z} g(z)$ as the optimal value and the optimal solution set of the lower-level problem, respectively. Note that by Assumption 2.3, the set $X^*_g$ is nonempty, convex, and compact, but typically not a singleton as $g$ potentially has multiple minima on $Z$. Furthermore, we denote $f^*$ and $x^*$ as the optimal value and an optimal solution of problem (1), which are assured to exist since $f$ is continuous and $X^*_g$ is compact.\n\nDefinition 2.1. When $f$ is convex, a point $\\hat{x} \\in Z$ is $(\\epsilon_f, \\epsilon_g)$-optimal if $f(\\hat{x}) - f^* \\leq \\epsilon_f$ and $g(\\hat{x}) - g^* \\leq \\epsilon_g$. When $f$ is non-convex, $\\hat{x} \\in Z$ is $(\\epsilon_f, \\epsilon_g)$-optimal if $G(\\hat{x}) \\leq \\epsilon_f$ and $g(\\hat{x}) - g^* \\leq \\epsilon_g$, where $G(\\hat{x})$ is the FW gap [Jag13; Lac16] defined as $G(\\hat{x}) \\triangleq \\max_{s \\in X^*_g} \\{ \\langle \\nabla f(\\hat{x}), \\hat{x} - s \\rangle \\}$."}, {"type": "heading", "lvl": 2, "value": "Algorithms", "md": "## Algorithms"}, {"type": "text", "value": "Conditional gradient for simple bilevel optimization. A variant of the conditional gradient (CG) method for solving bilevel problems has been introduced in [JAMH23] which uses a cutting", "md": "Conditional gradient for simple bilevel optimization. A variant of the conditional gradient (CG) method for solving bilevel problems has been introduced in [JAMH23] which uses a cutting"}]}, {"page": 6, "text": "plane idea [BV07] to approximate the solution set of the lower-level problem denoted by X \u2217                            g . More\nprecisely, if one has access to X \u2217       g , it is possible to run the FW update with stepsize \u03b3t as\n                         x t+1 = (1 \u2212    \u03b3t)xt + \u03b3tst,         where      st = arg min\u27e8\u2207f(xt), s\u27e9                             (6)\n                                                                                  s\u2208X \u2217g\nHowever, the set X \u2217       g is not explicitly given and the above method is not implementable.                                In\n[JAMH23], the authors suggested the use of the following set: Xt = {s \u2208                            Z : \u27e8\u2207g(xt), s \u2212       xt\u27e9  \u2264\ng(x0) \u2212    g(xt)} instead of the set X \u2217      g in the FW update given in (6). Note that x0 is selected in a\nway that g(x0) \u2212        g\u2217  is smaller than \u01ebg/2, and such a point can be efficiently computed. A crucial\nproperty of the above set is that it always contains the solution set of the lower-level problem\ndenoted by X \u2217    g . This can be easily verified by the fact that for any x\u2217              g in X \u2217g we have x\u2217    g \u2208  Z and\n                                \u27e8\u2207g(xt), x\u2217  g \u2212  xt\u27e9  \u2264  g(x\u2217 g) \u2212  g(xt) \u2264    g(x0) \u2212   g(xt),                              (7)\nwhere the second inequality holds as g(x0) \u2265                    g(x\u2217g). As shown in [JAMH23], this condition is\nsufficient to show that if one follows the update in (6) with Xt instead of X \u2217                         g , the iterates will\nconverge to the optimal solution.               However, this framework is not applicable to the stochastic\nsetting as we cannot access the functions or their gradients. Next, we present our main idea to\naddress this delicate issue.\nRandom set for the subproblem.                        A natural idea to address stochasticity is to replace all\ngradients and functions with their stochastic estimators for both the subproblem in (6), i.e., \u2207f(xt),\nas well as the construction of the cutting plane Xt, i.e., g(xt), and \u2207g(xt). However, this simple\nidea fails since the set Xt may no longer contain the solution set X \u2217                  g . More precisely, if \u02c6   gt and   \u2207gt\nare unbiased estimators of g(xt) and \u2207g(xt), respectively, for the following approximation set\n                                      X \u2032                 \u2207gt, s \u2212   xt\u27e9  \u2264  g(x0) \u2212    \u02c6\n                                        t = {s \u2208    Z : \u27e8                               gt}                                   (8)\nwe can not argue that it contains X \u2217        g , as the second inequality in (7) does not hold, i.e., \u27e8          \u2207g(xt), x\u2217   g\u2212\n                   g(xt) \u2270    g(x0) \u2212   \u02c6\nx t\u27e9 \u2264  \u02c6                               g(xt). In the appendix, we numerically illustrate this point.\n        g(x\u2217 g) \u2212  \u02c6\nTo address this issue, we tune the cutting plane by only moving it but not rotating it, i.e., adding\nanother term to tolerate the noise from stochastic estimates. We introduce the stochastic cutting\nplane\n                                   \u02c6\n                                  Xt = {s \u2208     Z : \u27e8 \u2207gt, s \u2212   xt\u27e9  \u2264  g(x0) \u2212    \u02c6\n                                                                                    gt + Kt},                                 (9)\nwhere    \u2207gt and \u02c6   gt are gradient and function value estimators, respectively, that we formally define\nlater.    In the above expression, the addition of the term Kt, which is a sequence of constants\nconverging to zero as t \u2192           \u221e, allows us to ensure that with high probability the random set \u02c6                        Xt\ncontains all optimal solutions of the lower-level problem. Choosing suitable values for the sequence\nKt is a crucial task. If we select a large value for Kt then the probability of \u02c6                         Xt containing X \u2217     g\ngoes up at the price allowing points with larger values g in the set. As a result, once we perform\nan update similar to the one in (6), the lower-level function value could increase significantly. On\nthe other hand, selecting small values for Kt would allow us to show that the lower level objective\nfunction is not growing, while the probability of \u02c6               Xt containing X \u2217     g becomes smaller which could\neven lead to a case that the set becomes empty and the bilevel problem becomes infeasible.\nRemark 3.1. How to compute g(x0)?                        In the fi  nite sum setting, we can accurately compute\ng(x0), and the additional cost of n function evaluations will be dominated by the overall com-\nplexity.    In the stochastic setting, we could use a large batch of samples to compute g(x0) with\n                                                                6", "md": "# Math Equations in HTML\n\nplane idea [BV07] to approximate the solution set of the lower-level problem denoted by X* g. More precisely, if one has access to X* g, it is possible to run the FW update with stepsize \u03b3t as\n\n$$\nx_{t+1} = (1 - \\gamma_t)x_t + \\gamma_t s_t, \\text{ where } s_t = \\arg \\min_{s \\in X* g} \\langle \\nabla f(x_t), s \\rangle \\quad (6)\n$$\nHowever, the set X* g is not explicitly given and the above method is not implementable. In [JAMH23], the authors suggested the use of the following set: Xt = {s \u2208 Z : \\langle \\nabla g(x_t), s - x_t \\rangle \\leq g(x_0) - g(x_t)} instead of the set X* g in the FW update given in (6). Note that x_0 is selected in a way that g(x_0) - g* is smaller than \u03b5g/2, and such a point can be efficiently computed. A crucial property of the above set is that it always contains the solution set of the lower-level problem denoted by X* g. This can be easily verified by the fact that for any x* g in X* g we have x* g \\in Z and\n\n$$\n\\langle \\nabla g(x_t), x* g - x_t \\rangle \\leq g(x* g) - g(x_t) \\leq g(x_0) - g(x_t) \\quad (7)\n$$\nwhere the second inequality holds as g(x_0) \\geq g(x* g). As shown in [JAMH23], this condition is sufficient to show that if one follows the update in (6) with Xt instead of X* g, the iterates will converge to the optimal solution. However, this framework is not applicable to the stochastic setting as we cannot access the functions or their gradients. Next, we present our main idea to address this delicate issue.\n\nRandom set for the subproblem. A natural idea to address stochasticity is to replace all gradients and functions with their stochastic estimators for both the subproblem in (6), i.e., \\nabla f(x_t), as well as the construction of the cutting plane Xt, i.e., g(x_t), and \\nabla g(x_t). However, this simple idea fails since the set Xt may no longer contain the solution set X* g. More precisely, if \\hat{g}_t and \\nabla \\hat{g}_t are unbiased estimators of g(x_t) and \\nabla g(x_t), respectively, for the following approximation set\n\n$$\nX'_{t} = \\{s \\in Z : \\langle \\nabla \\hat{g}_t, s - x_t \\rangle \\leq g(x_0) - \\hat{g}_t\\} \\quad (8)\n$$\nwe cannot argue that it contains X* g, as the second inequality in (7) does not hold, i.e., \\langle \\nabla g(x_t), x* g - x_t \\rangle \\nleq g(x_0) - \\hat{g}_t. In the appendix, we numerically illustrate this point.\n\nTo address this issue, we tune the cutting plane by only moving it but not rotating it, i.e., adding another term to tolerate the noise from stochastic estimates. We introduce the stochastic cutting plane\n\n$$\n\\hat{X}_t = \\{s \\in Z : \\langle \\nabla \\hat{g}_t, s - x_t \\rangle \\leq g(x_0) - \\hat{g}_t + K_t\\} \\quad (9)\n$$\nwhere \\nabla \\hat{g}_t and \\hat{g}_t are gradient and function value estimators, respectively, that we formally define later. In the above expression, the addition of the term K_t, which is a sequence of constants converging to zero as t \\rightarrow \\infty, allows us to ensure that with high probability the random set \\hat{X}_t contains all optimal solutions of the lower-level problem. Choosing suitable values for the sequence K_t is a crucial task. If we select a large value for K_t then the probability of \\hat{X}_t containing X* g goes up at the price allowing points with larger values g in the set. As a result, once we perform an update similar to the one in (6), the lower-level function value could increase significantly. On the other hand, selecting small values for K_t would allow us to show that the lower level objective function is not growing, while the probability of \\hat{X}_t containing X* g becomes smaller which could even lead to a case that the set becomes empty and the bilevel problem becomes infeasible.\n\nRemark 3.1. How to compute g(x_0)? In the finite sum setting, we can accurately compute g(x_0), and the additional cost of n function evaluations will be dominated by the overall complexity. In the stochastic setting, we could use a large batch of samples to compute g(x_0) with", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations in HTML", "md": "# Math Equations in HTML"}, {"type": "text", "value": "plane idea [BV07] to approximate the solution set of the lower-level problem denoted by X* g. More precisely, if one has access to X* g, it is possible to run the FW update with stepsize \u03b3t as\n\n$$\nx_{t+1} = (1 - \\gamma_t)x_t + \\gamma_t s_t, \\text{ where } s_t = \\arg \\min_{s \\in X* g} \\langle \\nabla f(x_t), s \\rangle \\quad (6)\n$$\nHowever, the set X* g is not explicitly given and the above method is not implementable. In [JAMH23], the authors suggested the use of the following set: Xt = {s \u2208 Z : \\langle \\nabla g(x_t), s - x_t \\rangle \\leq g(x_0) - g(x_t)} instead of the set X* g in the FW update given in (6). Note that x_0 is selected in a way that g(x_0) - g* is smaller than \u03b5g/2, and such a point can be efficiently computed. A crucial property of the above set is that it always contains the solution set of the lower-level problem denoted by X* g. This can be easily verified by the fact that for any x* g in X* g we have x* g \\in Z and\n\n$$\n\\langle \\nabla g(x_t), x* g - x_t \\rangle \\leq g(x* g) - g(x_t) \\leq g(x_0) - g(x_t) \\quad (7)\n$$\nwhere the second inequality holds as g(x_0) \\geq g(x* g). As shown in [JAMH23], this condition is sufficient to show that if one follows the update in (6) with Xt instead of X* g, the iterates will converge to the optimal solution. However, this framework is not applicable to the stochastic setting as we cannot access the functions or their gradients. Next, we present our main idea to address this delicate issue.\n\nRandom set for the subproblem. A natural idea to address stochasticity is to replace all gradients and functions with their stochastic estimators for both the subproblem in (6), i.e., \\nabla f(x_t), as well as the construction of the cutting plane Xt, i.e., g(x_t), and \\nabla g(x_t). However, this simple idea fails since the set Xt may no longer contain the solution set X* g. More precisely, if \\hat{g}_t and \\nabla \\hat{g}_t are unbiased estimators of g(x_t) and \\nabla g(x_t), respectively, for the following approximation set\n\n$$\nX'_{t} = \\{s \\in Z : \\langle \\nabla \\hat{g}_t, s - x_t \\rangle \\leq g(x_0) - \\hat{g}_t\\} \\quad (8)\n$$\nwe cannot argue that it contains X* g, as the second inequality in (7) does not hold, i.e., \\langle \\nabla g(x_t), x* g - x_t \\rangle \\nleq g(x_0) - \\hat{g}_t. In the appendix, we numerically illustrate this point.\n\nTo address this issue, we tune the cutting plane by only moving it but not rotating it, i.e., adding another term to tolerate the noise from stochastic estimates. We introduce the stochastic cutting plane\n\n$$\n\\hat{X}_t = \\{s \\in Z : \\langle \\nabla \\hat{g}_t, s - x_t \\rangle \\leq g(x_0) - \\hat{g}_t + K_t\\} \\quad (9)\n$$\nwhere \\nabla \\hat{g}_t and \\hat{g}_t are gradient and function value estimators, respectively, that we formally define later. In the above expression, the addition of the term K_t, which is a sequence of constants converging to zero as t \\rightarrow \\infty, allows us to ensure that with high probability the random set \\hat{X}_t contains all optimal solutions of the lower-level problem. Choosing suitable values for the sequence K_t is a crucial task. If we select a large value for K_t then the probability of \\hat{X}_t containing X* g goes up at the price allowing points with larger values g in the set. As a result, once we perform an update similar to the one in (6), the lower-level function value could increase significantly. On the other hand, selecting small values for K_t would allow us to show that the lower level objective function is not growing, while the probability of \\hat{X}_t containing X* g becomes smaller which could even lead to a case that the set becomes empty and the bilevel problem becomes infeasible.\n\nRemark 3.1. How to compute g(x_0)? In the finite sum setting, we can accurately compute g(x_0), and the additional cost of n function evaluations will be dominated by the overall complexity. In the stochastic setting, we could use a large batch of samples to compute g(x_0) with", "md": "plane idea [BV07] to approximate the solution set of the lower-level problem denoted by X* g. More precisely, if one has access to X* g, it is possible to run the FW update with stepsize \u03b3t as\n\n$$\nx_{t+1} = (1 - \\gamma_t)x_t + \\gamma_t s_t, \\text{ where } s_t = \\arg \\min_{s \\in X* g} \\langle \\nabla f(x_t), s \\rangle \\quad (6)\n$$\nHowever, the set X* g is not explicitly given and the above method is not implementable. In [JAMH23], the authors suggested the use of the following set: Xt = {s \u2208 Z : \\langle \\nabla g(x_t), s - x_t \\rangle \\leq g(x_0) - g(x_t)} instead of the set X* g in the FW update given in (6). Note that x_0 is selected in a way that g(x_0) - g* is smaller than \u03b5g/2, and such a point can be efficiently computed. A crucial property of the above set is that it always contains the solution set of the lower-level problem denoted by X* g. This can be easily verified by the fact that for any x* g in X* g we have x* g \\in Z and\n\n$$\n\\langle \\nabla g(x_t), x* g - x_t \\rangle \\leq g(x* g) - g(x_t) \\leq g(x_0) - g(x_t) \\quad (7)\n$$\nwhere the second inequality holds as g(x_0) \\geq g(x* g). As shown in [JAMH23], this condition is sufficient to show that if one follows the update in (6) with Xt instead of X* g, the iterates will converge to the optimal solution. However, this framework is not applicable to the stochastic setting as we cannot access the functions or their gradients. Next, we present our main idea to address this delicate issue.\n\nRandom set for the subproblem. A natural idea to address stochasticity is to replace all gradients and functions with their stochastic estimators for both the subproblem in (6), i.e., \\nabla f(x_t), as well as the construction of the cutting plane Xt, i.e., g(x_t), and \\nabla g(x_t). However, this simple idea fails since the set Xt may no longer contain the solution set X* g. More precisely, if \\hat{g}_t and \\nabla \\hat{g}_t are unbiased estimators of g(x_t) and \\nabla g(x_t), respectively, for the following approximation set\n\n$$\nX'_{t} = \\{s \\in Z : \\langle \\nabla \\hat{g}_t, s - x_t \\rangle \\leq g(x_0) - \\hat{g}_t\\} \\quad (8)\n$$\nwe cannot argue that it contains X* g, as the second inequality in (7) does not hold, i.e., \\langle \\nabla g(x_t), x* g - x_t \\rangle \\nleq g(x_0) - \\hat{g}_t. In the appendix, we numerically illustrate this point.\n\nTo address this issue, we tune the cutting plane by only moving it but not rotating it, i.e., adding another term to tolerate the noise from stochastic estimates. We introduce the stochastic cutting plane\n\n$$\n\\hat{X}_t = \\{s \\in Z : \\langle \\nabla \\hat{g}_t, s - x_t \\rangle \\leq g(x_0) - \\hat{g}_t + K_t\\} \\quad (9)\n$$\nwhere \\nabla \\hat{g}_t and \\hat{g}_t are gradient and function value estimators, respectively, that we formally define later. In the above expression, the addition of the term K_t, which is a sequence of constants converging to zero as t \\rightarrow \\infty, allows us to ensure that with high probability the random set \\hat{X}_t contains all optimal solutions of the lower-level problem. Choosing suitable values for the sequence K_t is a crucial task. If we select a large value for K_t then the probability of \\hat{X}_t containing X* g goes up at the price allowing points with larger values g in the set. As a result, once we perform an update similar to the one in (6), the lower-level function value could increase significantly. On the other hand, selecting small values for K_t would allow us to show that the lower level objective function is not growing, while the probability of \\hat{X}_t containing X* g becomes smaller which could even lead to a case that the set becomes empty and the bilevel problem becomes infeasible.\n\nRemark 3.1. How to compute g(x_0)? In the finite sum setting, we can accurately compute g(x_0), and the additional cost of n function evaluations will be dominated by the overall complexity. In the stochastic setting, we could use a large batch of samples to compute g(x_0) with"}]}, {"page": 7, "text": "high precision at the beginning of the process. This additional operation will not affect the over-\nall sample complexity of the proposed method, as the additional cost is negligible compared to the\noverall sample complexity. Specifi             cally, we need to take a batch size of b = \u02dc               O(\u01eb\u22122) to estimate\n\u02c6\ng(x0).     Using the Hoeffding inequality for subgaussian random variables, we have the following\nbound: |\u02c6  g(x0) \u2212    g(x0)| \u2264    \u221a  2\u03c3l(T + 1)\u2212\u03c9/2 log(2/\u03b4), with a probability of at least 1 \u2212                      \u03b4, where T\nis the maximum number of iterations. Comparing this with Lemma 4.1.3, we can further derive:\n|\u02c6                       \u221a                                        \u221a                 3\u03c9\n g(x0) \u2212    g(x0)| \u2264       2\u03c3l(T + 1)\u2212\u03c9/2 log(2/\u03b4) \u2264                 2(2LlD +      3\u03c9\u22121\u03c3l)(t + 1)\u2212\u03c9/2          log(6/\u03b4), with a\nprobability of at least 1 \u2212        \u03b4 for all 0 \u2264      t \u2264   T. Consequently, the introduced error term would be\nabsorbed in K0,t and will not affect any parts of the analysis.\nVariance reduced estimators. As mentioned above, a key point in the design of our stochastic\nbilevel algorithms is to select Kt properly such that \u02c6                 Xt contains X \u2217    g with high probability, for all\nt \u2265   0. To achieve such a guarantee, we first need to characterize the error of our gradient and\nfunction value estimators. More precisely, suppose that for our function estimator we have that\nP(|\u02c6gt \u2212g(xt)| \u2264      K0,t) \u2265    1\u2212\u03b4   \u2032 and for the gradient estimator we have P(\u2225                \u2207gt \u2212\u2207g(xt)\u2225        \u2264   K1,t) \u2265\n     \u2032, for some \u03b4\u2032 \u2208     (0, 1). Then, by setting Kt = K0,t+DK1,t, we can guarantee that the conditions\n1\u2212\u03b4                                                                                              \u2032\nrequired for the inequalities in (7) hold with probability at least (1 \u2212                      2\u03b4  ).\nUsing simple sample average estimators would not allow for the selection of a diminishing Kt, as\nthe variance is not vanishing, but by using proper variance-reduced estimators the variance of the\nestimators vanishes over time and eventually, we can send Kt to zero. In this section, we focus on\ntwo different variance reduction estimators. For the stochastic setting in (1) we use the STOchastic\nRecursive Momentum estimator (STORM), proposed in [CO19], and for the finite-sum setting, we\nutilize the Stochastic Path-Integrated Differential EstimatoR (SPIDER) proposed in [FLLZ18]. If\nv t\u22121 is the gradient estimator of STORM at time t \u2212                     1, the next estimator is computed as\n                              v t = (1 \u2212   \u03b1t)vt\u22121 + \u2207      \u02dc\n                                                            f(xt, \u03b8t) \u2212    (1 \u2212  \u03b1t)\u2207    \u02dc\nwhere \u2207     \u02dc                                                                           f(xt\u22121, \u03b8t),                           (10)\n           f(x, \u03b8) is the stochastic gradient evaluated at x with sample \u03b8. The main advantage of the\nabove estimator is that it can be implemented even with one sample per iteration. Unlike STORM,\nfor the SPIDER estimator, we need a larger batch of samples per update. More precisely, if we\nconsider vt\u22121 as the estimator of SPIDER for \u2207f(xt), it is updated according to\n                                           v t = \u2207fS(xt) \u2212       \u2207fS(xt\u22121) + vt\u22121,                                             (11)\nwhere \u2207fS(x) = (1/S)  i\u2208S \u2207f(x, \u03b8i) is the average sub-sampled stochastic gradient computed\nusing samples that are in the set S. As we will discuss later, in the finite sum case that we use\nSPIDER, the size of batch S depends on n which is the number of component functions. We delay\nestablishing a high probability error bound for these estimators to section 4.1.\n3.1      Conditional gradient algorithms with random sets: stochastic and fi                                                  nite-\n         sum\nNext, we present our Stochastic Bilevel Conditional Gradient method for Infinite sample case\nabbreviated by SBCGI for solving (1) and its finite sum variant denoted by SBCGF. In both cases,\nwe first find a point x0 that satisfies g(x0) \u2212              g\u2217  \u2264   \u01ebg/2, for some accuracy \u01ebg. The cost of finding\nsuch a point is negligible compared to the cost of the main algorithm as we discuss later. At each\niteration t, we first update the gradient estimator of the upper-level and the function and gradient\nestimators of the lower-level problem. In SBCGI, we follow the STORM idea as described in steps\n                                                                 7", "md": "high precision at the beginning of the process. This additional operation will not affect the overall sample complexity of the proposed method, as the additional cost is negligible compared to the overall sample complexity. Specifically, we need to take a batch size of \\( b = \\tilde{O}(\\epsilon^{-2}) \\) to estimate \\( \\hat{g}(x_0) \\). Using the Hoeffding inequality for subgaussian random variables, we have the following bound: \\( |\\hat{g}(x_0) - g(x_0)| \\leq \\sqrt{2\\sigma l(T + 1) - \\omega/2 \\log(2/\\delta)} \\), with a probability of at least \\( 1 - \\delta \\), where \\( T \\) is the maximum number of iterations. Comparing this with Lemma 4.1.3, we can further derive: \\( |\\hat{g}(x_0) - g(x_0)| \\leq \\sqrt{2\\sigma l(T + 1) - \\omega/2 \\log(2/\\delta)} \\leq 2(2LlD + 3\\omega^{-1}\\sigma l)(t + 1)^{-\\omega/2} \\log(6/\\delta) \\), with a probability of at least \\( 1 - \\delta \\) for all \\( 0 \\leq t \\leq T \\). Consequently, the introduced error term would be absorbed in \\( K_{0,t} \\) and will not affect any parts of the analysis.\n\nVariance reduced estimators. As mentioned above, a key point in the design of our stochastic bilevel algorithms is to select \\( K_t \\) properly such that \\( \\hat{X}_t \\) contains \\( X^* g \\) with high probability, for all \\( t \\geq 0 \\). To achieve such a guarantee, we first need to characterize the error of our gradient and function value estimators. More precisely, suppose that for our function estimator we have that \\( P(|\\hat{g}_t - g(x_t)| \\leq K_{0,t}) \\geq 1 - \\delta' \\) and for the gradient estimator we have \\( P(\\| \\nabla \\hat{g}_t - \\nabla g(x_t) \\| \\leq K_{1,t}) \\geq \\delta' \\), for some \\( \\delta' \\in (0, 1) \\). Then, by setting \\( K_t = K_{0,t} + DK_{1,t} \\), we can guarantee that the conditions required for the inequalities in (7) hold with probability at least \\( 1 - 2\\delta' \\).\n\nUsing simple sample average estimators would not allow for the selection of a diminishing \\( K_t \\), as the variance is not vanishing, but by using proper variance-reduced estimators the variance of the estimators vanishes over time and eventually, we can send \\( K_t \\) to zero. In this section, we focus on two different variance reduction estimators. For the stochastic setting in (1) we use the STOchastic Recursive Momentum estimator (STORM), proposed in [CO19], and for the finite-sum setting, we utilize the Stochastic Path-Integrated Differential EstimatoR (SPIDER) proposed in [FLLZ18]. If \\( v_{t-1} \\) is the gradient estimator of STORM at time \\( t - 1 \\), the next estimator is computed as\n\n$$ v_t = (1 - \\alpha_t)v_{t-1} + \\nabla \\tilde{f}(x_t, \\theta_t) - (1 - \\alpha_t)\\nabla \\tilde{f}(x_{t-1}, \\theta_t), \\quad (10) $$\n\nwhere \\( \\nabla \\tilde{f}(x, \\theta) \\) is the stochastic gradient evaluated at \\( x \\) with sample \\( \\theta \\). The main advantage of the above estimator is that it can be implemented even with one sample per iteration. Unlike STORM, for the SPIDER estimator, we need a larger batch of samples per update. More precisely, if we consider \\( v_{t-1} \\) as the estimator of SPIDER for \\( \\nabla f(x_t) \\), it is updated according to\n\n$$ v_t = \\nabla f_S(x_t) - \\nabla f_S(x_{t-1}) + v_{t-1}, \\quad (11) $$\n\nwhere \\( \\nabla f_S(x) = (1/S) \\sum_{i \\in S} \\nabla f(x, \\theta_i) \\) is the average sub-sampled stochastic gradient computed using samples that are in the set \\( S \\). As we will discuss later, in the finite sum case that we use SPIDER, the size of batch \\( S \\) depends on \\( n \\) which is the number of component functions. We delay establishing a high probability error bound for these estimators to section 4.1.\n\n### 3.1 Conditional gradient algorithms with random sets: stochastic and finite-sum\n\nNext, we present our Stochastic Bilevel Conditional Gradient method for Infinite sample case abbreviated by SBCGI for solving (1) and its finite sum variant denoted by SBCGF. In both cases, we first find a point \\( x_0 \\) that satisfies \\( g(x_0) - g^* \\leq \\epsilon_g/2 \\), for some accuracy \\( \\epsilon_g \\). The cost of finding such a point is negligible compared to the cost of the main algorithm as we discuss later. At each iteration \\( t \\), we first update the gradient estimator of the upper-level and the function and gradient estimators of the lower-level problem. In SBCGI, we follow the STORM idea as described in steps 7.", "images": [], "items": [{"type": "text", "value": "high precision at the beginning of the process. This additional operation will not affect the overall sample complexity of the proposed method, as the additional cost is negligible compared to the overall sample complexity. Specifically, we need to take a batch size of \\( b = \\tilde{O}(\\epsilon^{-2}) \\) to estimate \\( \\hat{g}(x_0) \\). Using the Hoeffding inequality for subgaussian random variables, we have the following bound: \\( |\\hat{g}(x_0) - g(x_0)| \\leq \\sqrt{2\\sigma l(T + 1) - \\omega/2 \\log(2/\\delta)} \\), with a probability of at least \\( 1 - \\delta \\), where \\( T \\) is the maximum number of iterations. Comparing this with Lemma 4.1.3, we can further derive: \\( |\\hat{g}(x_0) - g(x_0)| \\leq \\sqrt{2\\sigma l(T + 1) - \\omega/2 \\log(2/\\delta)} \\leq 2(2LlD + 3\\omega^{-1}\\sigma l)(t + 1)^{-\\omega/2} \\log(6/\\delta) \\), with a probability of at least \\( 1 - \\delta \\) for all \\( 0 \\leq t \\leq T \\). Consequently, the introduced error term would be absorbed in \\( K_{0,t} \\) and will not affect any parts of the analysis.\n\nVariance reduced estimators. As mentioned above, a key point in the design of our stochastic bilevel algorithms is to select \\( K_t \\) properly such that \\( \\hat{X}_t \\) contains \\( X^* g \\) with high probability, for all \\( t \\geq 0 \\). To achieve such a guarantee, we first need to characterize the error of our gradient and function value estimators. More precisely, suppose that for our function estimator we have that \\( P(|\\hat{g}_t - g(x_t)| \\leq K_{0,t}) \\geq 1 - \\delta' \\) and for the gradient estimator we have \\( P(\\| \\nabla \\hat{g}_t - \\nabla g(x_t) \\| \\leq K_{1,t}) \\geq \\delta' \\), for some \\( \\delta' \\in (0, 1) \\). Then, by setting \\( K_t = K_{0,t} + DK_{1,t} \\), we can guarantee that the conditions required for the inequalities in (7) hold with probability at least \\( 1 - 2\\delta' \\).\n\nUsing simple sample average estimators would not allow for the selection of a diminishing \\( K_t \\), as the variance is not vanishing, but by using proper variance-reduced estimators the variance of the estimators vanishes over time and eventually, we can send \\( K_t \\) to zero. In this section, we focus on two different variance reduction estimators. For the stochastic setting in (1) we use the STOchastic Recursive Momentum estimator (STORM), proposed in [CO19], and for the finite-sum setting, we utilize the Stochastic Path-Integrated Differential EstimatoR (SPIDER) proposed in [FLLZ18]. If \\( v_{t-1} \\) is the gradient estimator of STORM at time \\( t - 1 \\), the next estimator is computed as\n\n$$ v_t = (1 - \\alpha_t)v_{t-1} + \\nabla \\tilde{f}(x_t, \\theta_t) - (1 - \\alpha_t)\\nabla \\tilde{f}(x_{t-1}, \\theta_t), \\quad (10) $$\n\nwhere \\( \\nabla \\tilde{f}(x, \\theta) \\) is the stochastic gradient evaluated at \\( x \\) with sample \\( \\theta \\). The main advantage of the above estimator is that it can be implemented even with one sample per iteration. Unlike STORM, for the SPIDER estimator, we need a larger batch of samples per update. More precisely, if we consider \\( v_{t-1} \\) as the estimator of SPIDER for \\( \\nabla f(x_t) \\), it is updated according to\n\n$$ v_t = \\nabla f_S(x_t) - \\nabla f_S(x_{t-1}) + v_{t-1}, \\quad (11) $$\n\nwhere \\( \\nabla f_S(x) = (1/S) \\sum_{i \\in S} \\nabla f(x, \\theta_i) \\) is the average sub-sampled stochastic gradient computed using samples that are in the set \\( S \\). As we will discuss later, in the finite sum case that we use SPIDER, the size of batch \\( S \\) depends on \\( n \\) which is the number of component functions. We delay establishing a high probability error bound for these estimators to section 4.1.", "md": "high precision at the beginning of the process. This additional operation will not affect the overall sample complexity of the proposed method, as the additional cost is negligible compared to the overall sample complexity. Specifically, we need to take a batch size of \\( b = \\tilde{O}(\\epsilon^{-2}) \\) to estimate \\( \\hat{g}(x_0) \\). Using the Hoeffding inequality for subgaussian random variables, we have the following bound: \\( |\\hat{g}(x_0) - g(x_0)| \\leq \\sqrt{2\\sigma l(T + 1) - \\omega/2 \\log(2/\\delta)} \\), with a probability of at least \\( 1 - \\delta \\), where \\( T \\) is the maximum number of iterations. Comparing this with Lemma 4.1.3, we can further derive: \\( |\\hat{g}(x_0) - g(x_0)| \\leq \\sqrt{2\\sigma l(T + 1) - \\omega/2 \\log(2/\\delta)} \\leq 2(2LlD + 3\\omega^{-1}\\sigma l)(t + 1)^{-\\omega/2} \\log(6/\\delta) \\), with a probability of at least \\( 1 - \\delta \\) for all \\( 0 \\leq t \\leq T \\). Consequently, the introduced error term would be absorbed in \\( K_{0,t} \\) and will not affect any parts of the analysis.\n\nVariance reduced estimators. As mentioned above, a key point in the design of our stochastic bilevel algorithms is to select \\( K_t \\) properly such that \\( \\hat{X}_t \\) contains \\( X^* g \\) with high probability, for all \\( t \\geq 0 \\). To achieve such a guarantee, we first need to characterize the error of our gradient and function value estimators. More precisely, suppose that for our function estimator we have that \\( P(|\\hat{g}_t - g(x_t)| \\leq K_{0,t}) \\geq 1 - \\delta' \\) and for the gradient estimator we have \\( P(\\| \\nabla \\hat{g}_t - \\nabla g(x_t) \\| \\leq K_{1,t}) \\geq \\delta' \\), for some \\( \\delta' \\in (0, 1) \\). Then, by setting \\( K_t = K_{0,t} + DK_{1,t} \\), we can guarantee that the conditions required for the inequalities in (7) hold with probability at least \\( 1 - 2\\delta' \\).\n\nUsing simple sample average estimators would not allow for the selection of a diminishing \\( K_t \\), as the variance is not vanishing, but by using proper variance-reduced estimators the variance of the estimators vanishes over time and eventually, we can send \\( K_t \\) to zero. In this section, we focus on two different variance reduction estimators. For the stochastic setting in (1) we use the STOchastic Recursive Momentum estimator (STORM), proposed in [CO19], and for the finite-sum setting, we utilize the Stochastic Path-Integrated Differential EstimatoR (SPIDER) proposed in [FLLZ18]. If \\( v_{t-1} \\) is the gradient estimator of STORM at time \\( t - 1 \\), the next estimator is computed as\n\n$$ v_t = (1 - \\alpha_t)v_{t-1} + \\nabla \\tilde{f}(x_t, \\theta_t) - (1 - \\alpha_t)\\nabla \\tilde{f}(x_{t-1}, \\theta_t), \\quad (10) $$\n\nwhere \\( \\nabla \\tilde{f}(x, \\theta) \\) is the stochastic gradient evaluated at \\( x \\) with sample \\( \\theta \\). The main advantage of the above estimator is that it can be implemented even with one sample per iteration. Unlike STORM, for the SPIDER estimator, we need a larger batch of samples per update. More precisely, if we consider \\( v_{t-1} \\) as the estimator of SPIDER for \\( \\nabla f(x_t) \\), it is updated according to\n\n$$ v_t = \\nabla f_S(x_t) - \\nabla f_S(x_{t-1}) + v_{t-1}, \\quad (11) $$\n\nwhere \\( \\nabla f_S(x) = (1/S) \\sum_{i \\in S} \\nabla f(x, \\theta_i) \\) is the average sub-sampled stochastic gradient computed using samples that are in the set \\( S \\). As we will discuss later, in the finite sum case that we use SPIDER, the size of batch \\( S \\) depends on \\( n \\) which is the number of component functions. We delay establishing a high probability error bound for these estimators to section 4.1."}, {"type": "heading", "lvl": 3, "value": "3.1 Conditional gradient algorithms with random sets: stochastic and finite-sum", "md": "### 3.1 Conditional gradient algorithms with random sets: stochastic and finite-sum"}, {"type": "text", "value": "Next, we present our Stochastic Bilevel Conditional Gradient method for Infinite sample case abbreviated by SBCGI for solving (1) and its finite sum variant denoted by SBCGF. In both cases, we first find a point \\( x_0 \\) that satisfies \\( g(x_0) - g^* \\leq \\epsilon_g/2 \\), for some accuracy \\( \\epsilon_g \\). The cost of finding such a point is negligible compared to the cost of the main algorithm as we discuss later. At each iteration \\( t \\), we first update the gradient estimator of the upper-level and the function and gradient estimators of the lower-level problem. In SBCGI, we follow the STORM idea as described in steps 7.", "md": "Next, we present our Stochastic Bilevel Conditional Gradient method for Infinite sample case abbreviated by SBCGI for solving (1) and its finite sum variant denoted by SBCGF. In both cases, we first find a point \\( x_0 \\) that satisfies \\( g(x_0) - g^* \\leq \\epsilon_g/2 \\), for some accuracy \\( \\epsilon_g \\). The cost of finding such a point is negligible compared to the cost of the main algorithm as we discuss later. At each iteration \\( t \\), we first update the gradient estimator of the upper-level and the function and gradient estimators of the lower-level problem. In SBCGI, we follow the STORM idea as described in steps 7."}]}, {"page": 8, "text": "Algorithm 1 SBCGI\n 1: Input: Target accuracy: \u01ebf, \u01ebg > 0, probability \u03b4 > 0, step size: \u03b1t, \u03b2t, \u03c1t, \u03b3t > 0\n 2: Initialization: Initialize x0 \u2208           Z such that g(x0) \u2212         g\u2217  \u2264  \u01ebg/2\n 3: for t = 0, . . . , T do\n 4:       if t = 0 then\n 5:           \u2207ft = \u2207      \u02dc\n 6:       else            f(xt, \u03b8t),  \u2207gt = \u2207\u02dc    g(xt, \u03bet), \u02c6gt = \u02dc g(xt, \u03bet)\n 7:           Update the estimate of \u2207f,            \u2207ft = (1 \u2212      \u03b1t) \u2207ft\u22121 + \u2207       \u02dc\n                                                                                       f(xt, \u03b8t) \u2212    (1 \u2212  \u03b1t)\u2207    \u02dc\n                                                                                                                   f(xt\u22121, \u03b8t)\n 8:           Update the estimate of \u2207g,            \u2207gt = (1 \u2212      \u03b2t) \u2207gt\u22121 + \u2207\u02dc    g(xt, \u03bet) \u2212   (1 \u2212   \u03b2t)\u2207\u02dc g(xt\u22121, \u03bet)\n 9:           Update the estimate of g, \u02c6         gt = (1 \u2212    \u03c1t)\u02c6\n10:       end if                                                  gt\u22121 + \u02dc  g(xt, \u03bet) \u2212   (1 \u2212  \u03c1t)\u02dcg(xt\u22121, \u03bet)\n11:       Compute st \u2208       arg mins\u2208Xt{     \u2207f  \u22a4                                  \u2207gt, s \u2212   xt\u27e9  \u2264   g(x0) \u2212    \u02c6\n                                                  t s} where Xt = {s \u2208         Z : \u27e8                               gt + Kt}\n12:       Update the variable xt+1 = (1 \u2212             \u03b3t+1)xt + \u03b3t+1st\n13: end for\nAlgorithm 2 SBCGF\n 1: Input: Target accuracy: \u01ebf, \u01ebg > 0, probability accuracy: \u03b40, \u03b41 > 0, step size: \u03b3t > 0\n 2: Initialization: Initialize x0 \u2208           Z such that g(x0) \u2212         g\u2217  \u2264  \u01ebg/2\n 3: for t = 0, . . . , T do\n 4:       if mod(t, q) = 0 then\n 5:           Set  \u2207ft = \u2207f(xt),        \u2207gt = \u2207g(xt), \u02c6      gt = g(xt)\n 6:       else\n 7:           Draw S samples\n 8:           Update the estimate of \u2207f as             \u2207ft =     \u2207ft\u22121 + \u2207fS(xt) \u2212          \u2207fS(xt\u22121)\n 9:           Update the estimate of \u2207g as             \u2207gt =    \u2207gt\u22121 + \u2207gS(xt) \u2212          \u2207gS(xt\u22121)\n10:           Update the estimate of g as \u02c6         gt = \u02c6 gt\u22121 + gS(xt) \u2212      gS(xt\u22121)\n11:       end if\n12:       Compute st \u2208       arg mins\u2208Xt{     \u2207f  \u22a4                                  \u2207gt, s \u2212   xt\u27e9  \u2264   g(x0) \u2212    \u02c6\n                                                  t s} where Xt = {s \u2208         Z : \u27e8                               gt + Kt}\n13:       Update the variable xt+1 = (1 \u2212             \u03b3t+1)xt + \u03b3t+1st\n14: end for\n4-6 of Algorithm 1, while in SBCGF, we use the SPIDER technique as presented in steps 7-10 of\nAlgorithm 2. In the case of SBCGF, we need to compute the exact gradient and function values\nonce every q iteration as presented in steps 4-6 of Algorithm 2. Once the estimators are updated,\nwe can define the random set \u02c6          Xt as in (9) and solve the following subproblem over the set \u02c6                   Xt,\n                                                   st = arg min      \u27e8\u2207ft, s\u27e9,                                                (12)\n                                                            s\u2208 \u02c6\n                                                               Xt\nwhere   \u2207ft is the unbiased estimator of \u2207f(xt). Note that we implicitly assume that we have access\nto a linear optimization oracle that returns a solution of the subproblem in (12), which is standard\nfor projection-free methods [Jag13; Lac16]. In particular, if Z can be described by a system of\nlinear inequalities, then problem (12) corresponds to a linear program and can be solved efficiently\nby a standard solver as we show in our experiments. Once, st is calculated we simply update the\niterate\n                                               xt+1 = (1 \u2212     \u03b3t+1)xt + \u03b3t+1st                                               (13)\nwith stepsize \u03b3t+1 \u2208         [0, 1]. The only missing part for the implementation of our methods is the\nchoice of Kt in the random set and the stepsize parameters. We address these points in the next\n                                                                 8", "md": "# SBCGI and SBCGF Algorithms\n\n## Algorithm 1: SBCGI\n\nInput: Target accuracy: $$\\epsilon_f, \\epsilon_g > 0$$, probability $$\\delta > 0$$, step size: $$\\alpha_t, \\beta_t, \\rho_t, \\gamma_t > 0$$\n\nInitialization: Initialize $$x_0 \\in Z$$ such that $$g(x_0) - g^* \\leq \\frac{\\epsilon_g}{2}$$\n\nAlgorithm Steps:\n\n1. For $t = 0, ..., T$\n\n## Algorithm 2: SBCGF\n\nInput: Target accuracy: $$\\epsilon_f, \\epsilon_g > 0$$, probability accuracy: $$\\delta_0, \\delta_1 > 0$$, step size: $$\\gamma_t > 0$$\n\nInitialization: Initialize $$x_0 \\in Z$$ such that $$g(x_0) - g^* \\leq \\frac{\\epsilon_g}{2}$$\n\nAlgorithm Steps:\n\n1. For $t = 0, ..., T$\n\nIn the case of SBCGF, the SPIDER technique is used as presented in steps 7-10 of Algorithm 2. Once the estimators are updated, the random set $$\\hat{X}_t$$ is defined and the subproblem is solved over the set $$\\hat{X}_t$$ as shown in equation (12).\n\n$$s_t = \\text{arg min}_{s \\in \\hat{X}_t} \\langle \\nabla f_t, s \\rangle$$\n\nOnce $$s_t$$ is calculated, the iterate is updated as $$x_{t+1} = (1 - \\gamma_{t+1})x_t + \\gamma_{t+1}s_t$$ with step size $$\\gamma_{t+1} \\in [0, 1]$$. The choice of $$K_t$$ in the random set and the step size parameters are addressed in the implementation of the methods.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "SBCGI and SBCGF Algorithms", "md": "# SBCGI and SBCGF Algorithms"}, {"type": "heading", "lvl": 2, "value": "Algorithm 1: SBCGI", "md": "## Algorithm 1: SBCGI"}, {"type": "text", "value": "Input: Target accuracy: $$\\epsilon_f, \\epsilon_g > 0$$, probability $$\\delta > 0$$, step size: $$\\alpha_t, \\beta_t, \\rho_t, \\gamma_t > 0$$\n\nInitialization: Initialize $$x_0 \\in Z$$ such that $$g(x_0) - g^* \\leq \\frac{\\epsilon_g}{2}$$\n\nAlgorithm Steps:\n\n1. For $t = 0, ..., T$", "md": "Input: Target accuracy: $$\\epsilon_f, \\epsilon_g > 0$$, probability $$\\delta > 0$$, step size: $$\\alpha_t, \\beta_t, \\rho_t, \\gamma_t > 0$$\n\nInitialization: Initialize $$x_0 \\in Z$$ such that $$g(x_0) - g^* \\leq \\frac{\\epsilon_g}{2}$$\n\nAlgorithm Steps:\n\n1. For $t = 0, ..., T$"}, {"type": "heading", "lvl": 2, "value": "Algorithm 2: SBCGF", "md": "## Algorithm 2: SBCGF"}, {"type": "text", "value": "Input: Target accuracy: $$\\epsilon_f, \\epsilon_g > 0$$, probability accuracy: $$\\delta_0, \\delta_1 > 0$$, step size: $$\\gamma_t > 0$$\n\nInitialization: Initialize $$x_0 \\in Z$$ such that $$g(x_0) - g^* \\leq \\frac{\\epsilon_g}{2}$$\n\nAlgorithm Steps:\n\n1. For $t = 0, ..., T$\n\nIn the case of SBCGF, the SPIDER technique is used as presented in steps 7-10 of Algorithm 2. Once the estimators are updated, the random set $$\\hat{X}_t$$ is defined and the subproblem is solved over the set $$\\hat{X}_t$$ as shown in equation (12).\n\n$$s_t = \\text{arg min}_{s \\in \\hat{X}_t} \\langle \\nabla f_t, s \\rangle$$\n\nOnce $$s_t$$ is calculated, the iterate is updated as $$x_{t+1} = (1 - \\gamma_{t+1})x_t + \\gamma_{t+1}s_t$$ with step size $$\\gamma_{t+1} \\in [0, 1]$$. The choice of $$K_t$$ in the random set and the step size parameters are addressed in the implementation of the methods.", "md": "Input: Target accuracy: $$\\epsilon_f, \\epsilon_g > 0$$, probability accuracy: $$\\delta_0, \\delta_1 > 0$$, step size: $$\\gamma_t > 0$$\n\nInitialization: Initialize $$x_0 \\in Z$$ such that $$g(x_0) - g^* \\leq \\frac{\\epsilon_g}{2}$$\n\nAlgorithm Steps:\n\n1. For $t = 0, ..., T$\n\nIn the case of SBCGF, the SPIDER technique is used as presented in steps 7-10 of Algorithm 2. Once the estimators are updated, the random set $$\\hat{X}_t$$ is defined and the subproblem is solved over the set $$\\hat{X}_t$$ as shown in equation (12).\n\n$$s_t = \\text{arg min}_{s \\in \\hat{X}_t} \\langle \\nabla f_t, s \\rangle$$\n\nOnce $$s_t$$ is calculated, the iterate is updated as $$x_{t+1} = (1 - \\gamma_{t+1})x_t + \\gamma_{t+1}s_t$$ with step size $$\\gamma_{t+1} \\in [0, 1]$$. The choice of $$K_t$$ in the random set and the step size parameters are addressed in the implementation of the methods."}]}, {"page": 9, "text": "section.\nRemark 3.2. Note that SBCGI can be implemented with a batch size as small as S = 1. However,\nthis does not imply that the batch size \u201dhas to be\u201d S = 1. In other words, the main advantage of\nSBCGI, compared to SBCGF, is its capability to be implemented with any mini-batch size, even as\nsmall as S = 1. Therefore, for SBCGI, the batch size can be set arbitrarily, whereas for SBCGF, it\nmust be \u221a  n.\nRemark 3.3. In the fi    nite-sum setting, if the numbers of functions in the upper- and lower-level\nlosses are different, we could simply modify SBCGF 2 by choosing Su = qu = \u221anu and Sl = ql =\n\u221anl, where nu and nl are the number of functions in the upper- and lower-level, respectively.\n4    Convergence analysis\nIn this section, we characterize the sample complexity of our methods for stochastic and finite-\nsum settings. Before stating our results, we first characterize a high probability bound for the\nestimators of our algorithms, which are crucial in the selection of parameter Kt and the overall\nsample complexity.\n4.1    High probability bound for the error terms\nTo achieve a high probability bound, it is common to assume that the noise of gradient or function is\nuniformly bounded as in [FLLZ18; XSZWQ20], but such assumptions may not be realistic for most\nmachine learning applications. Hence, in our analysis, we consider a milder assumption and assume\nthe noise of function and gradient are sub-Gaussian as in Assumptions 2.2 and 2.3, respectively.\nGiven these assumptions, we next establish a high probability error bound for the estimators in\nSBCGI.\nLemma 4.1. Consider SBCGI in Algorithm 1 with parameters \u03b1t = \u03b2t = \u03c1t = \u03b3t = 1/(t + 1)\u03c9\nwhere \u03c9 \u2208   (0, 1]. If Assumptions 2.1, 2.2, and 2.3 are satisfi  ed, for any t \u2265  1 and \u03b4 \u2208  (0, 1), with\nprobability at least 1 \u2212 \u03b4, for some absolute constant c, (d is the number of dimension), we have\n                                       \u221a               3\u03c9\n                 \u2225\u2207f t \u2212  \u2207f(xt)\u2225  \u2264  c  2(2LfD +    3\u03c9 \u2212  1\u03c3f)(t + 1)\u2212\u03c9/2    log(6d/\u03b4),              (14)\n                  \u2225\u2207gt \u2212  \u2207g(xt)\u2225  \u2264  c\u221a 2(2LgD +      3\u03c9                     log(6d/\u03b4),              (15)\n                                                     3\u03c9 \u2212 1\u03c3g)(t + 1)\u2212\u03c9/2\n                       |\u02c6              \u221a               3\u03c9\n                       gt \u2212  g(xt)| \u2264 c  2(2LlD +   3\u03c9 \u2212  1\u03c3l)(t + 1)\u2212\u03c9/2    log(6/\u03b4).                (16)\nLemma 4.1 shows that for any \u03c9 \u2208       (0, 1], if we set \u03b1t = \u03b2t = \u03c1t = \u03b3t = 1/(t + 1)\u03c9, then with high\nprobability the gradient and function approximation errors converge to zero at a sublinear rate of\n \u02dc\nO(1/t\u03c9/2). Moreover, the above result characterizes the choice of Kt. More precisely, if we define\nK1,t as the upper bound in (15) and K0,t as the upper bound in (16), by setting Kt = K0,t +DK1,t,\nthen with probability (1 \u2212    \u03b4) the random set \u02c6  Xt contains X \u2217 g . Later, we will show that \u03c9 = 1\nleads to the best complexity bound for the convex setting and \u03c9 = 2/3 is the best choice for the\nnonconvex setting.\nNext, we establish a similar result for the estimators in SBCGF.\n                                                    9", "md": "## Remark 3.2\n\nNote that SBCGI can be implemented with a batch size as small as S = 1. However, this does not imply that the batch size \"has to be\" S = 1. In other words, the main advantage of SBCGI, compared to SBCGF, is its capability to be implemented with any mini-batch size, even as small as S = 1. Therefore, for SBCGI, the batch size can be set arbitrarily, whereas for SBCGF, it must be $$\\sqrt{n}$$.\n\n## Remark 3.3\n\nIn the finite-sum setting, if the numbers of functions in the upper- and lower-level losses are different, we could simply modify SBCGF 2 by choosing $$S_u = q_u = \\sqrt{n_u}$$ and $$S_l = q_l = \\sqrt{n_l}$$, where $$n_u$$ and $$n_l$$ are the number of functions in the upper- and lower-level, respectively.\n\n## Convergence analysis\n\nIn this section, we characterize the sample complexity of our methods for stochastic and finite-sum settings. Before stating our results, we first characterize a high probability bound for the estimators of our algorithms, which are crucial in the selection of parameter $$K_t$$ and the overall sample complexity.\n\n### 4.1 High probability bound for the error terms\n\nTo achieve a high probability bound, it is common to assume that the noise of gradient or function is uniformly bounded as in [FLLZ18; XSZWQ20], but such assumptions may not be realistic for most machine learning applications. Hence, in our analysis, we consider a milder assumption and assume the noise of function and gradient are sub-Gaussian as in Assumptions 2.2 and 2.3, respectively.\n\nGiven these assumptions, we next establish a high probability error bound for the estimators in SBCGI.\n\n|Lemma 4.1|Consider SBCGI in Algorithm 1 with parameters $\\alpha_t = \\beta_t = \\rho_t = \\gamma_t = \\frac{1}{(t + 1)^\\omega}$ where $\\omega \\in (0, 1]$. If Assumptions 2.1, 2.2, and 2.3 are satisfied, for any $t \\geq 1$ and $\\delta \\in (0, 1)$, with probability at least $1 - \\delta$, for some absolute constant c, (d is the number of dimension), we have|\n|---|---|\n| |$\\| \\nabla f_t - \\nabla f(x_t) \\| \\leq c \\sqrt{2(2LfD + 3\\omega - 1\\sigma_f)(t + 1)^{-\\omega/2} \\log(6d/\\delta)}$|\n| |$\\| \\nabla g_t - \\nabla g(x_t) \\| \\leq c \\sqrt{2(2LgD + 3\\omega - 1\\sigma_g)(t + 1)^{-\\omega/2} \\log(6d/\\delta)}$|\n| |$| \\hat{g}_t - g(x_t) | \\leq c \\sqrt{2(2LlD + 3\\omega - 1\\sigma_l)(t + 1)^{-\\omega/2} \\log(6/\\delta)}$|\n\nLemma 4.1 shows that for any $$\\omega \\in (0, 1]$$, if we set $$\\alpha_t = \\beta_t = \\rho_t = \\gamma_t = \\frac{1}{(t + 1)^\\omega}$$, then with high probability the gradient and function approximation errors converge to zero at a sublinear rate of $$\\tilde{O}(1/t^{\\omega/2})$$. Moreover, the above result characterizes the choice of $$K_t$$. More precisely, if we define $$K_{1,t}$$ as the upper bound in (15) and $$K_{0,t}$$ as the upper bound in (16), by setting $$K_t = K_{0,t} + DK_{1,t}$$, then with probability $$(1 - \\delta)$$ the random set $$\\hat{X}_t$$ contains $$X^* g$$. Later, we will show that $$\\omega = 1$$ leads to the best complexity bound for the convex setting and $$\\omega = 2/3$$ is the best choice for the nonconvex setting.\n\nNext, we establish a similar result for the estimators in SBCGF.", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "Remark 3.2", "md": "## Remark 3.2"}, {"type": "text", "value": "Note that SBCGI can be implemented with a batch size as small as S = 1. However, this does not imply that the batch size \"has to be\" S = 1. In other words, the main advantage of SBCGI, compared to SBCGF, is its capability to be implemented with any mini-batch size, even as small as S = 1. Therefore, for SBCGI, the batch size can be set arbitrarily, whereas for SBCGF, it must be $$\\sqrt{n}$$.", "md": "Note that SBCGI can be implemented with a batch size as small as S = 1. However, this does not imply that the batch size \"has to be\" S = 1. In other words, the main advantage of SBCGI, compared to SBCGF, is its capability to be implemented with any mini-batch size, even as small as S = 1. Therefore, for SBCGI, the batch size can be set arbitrarily, whereas for SBCGF, it must be $$\\sqrt{n}$$."}, {"type": "heading", "lvl": 2, "value": "Remark 3.3", "md": "## Remark 3.3"}, {"type": "text", "value": "In the finite-sum setting, if the numbers of functions in the upper- and lower-level losses are different, we could simply modify SBCGF 2 by choosing $$S_u = q_u = \\sqrt{n_u}$$ and $$S_l = q_l = \\sqrt{n_l}$$, where $$n_u$$ and $$n_l$$ are the number of functions in the upper- and lower-level, respectively.", "md": "In the finite-sum setting, if the numbers of functions in the upper- and lower-level losses are different, we could simply modify SBCGF 2 by choosing $$S_u = q_u = \\sqrt{n_u}$$ and $$S_l = q_l = \\sqrt{n_l}$$, where $$n_u$$ and $$n_l$$ are the number of functions in the upper- and lower-level, respectively."}, {"type": "heading", "lvl": 2, "value": "Convergence analysis", "md": "## Convergence analysis"}, {"type": "text", "value": "In this section, we characterize the sample complexity of our methods for stochastic and finite-sum settings. Before stating our results, we first characterize a high probability bound for the estimators of our algorithms, which are crucial in the selection of parameter $$K_t$$ and the overall sample complexity.", "md": "In this section, we characterize the sample complexity of our methods for stochastic and finite-sum settings. Before stating our results, we first characterize a high probability bound for the estimators of our algorithms, which are crucial in the selection of parameter $$K_t$$ and the overall sample complexity."}, {"type": "heading", "lvl": 3, "value": "4.1 High probability bound for the error terms", "md": "### 4.1 High probability bound for the error terms"}, {"type": "text", "value": "To achieve a high probability bound, it is common to assume that the noise of gradient or function is uniformly bounded as in [FLLZ18; XSZWQ20], but such assumptions may not be realistic for most machine learning applications. Hence, in our analysis, we consider a milder assumption and assume the noise of function and gradient are sub-Gaussian as in Assumptions 2.2 and 2.3, respectively.\n\nGiven these assumptions, we next establish a high probability error bound for the estimators in SBCGI.", "md": "To achieve a high probability bound, it is common to assume that the noise of gradient or function is uniformly bounded as in [FLLZ18; XSZWQ20], but such assumptions may not be realistic for most machine learning applications. Hence, in our analysis, we consider a milder assumption and assume the noise of function and gradient are sub-Gaussian as in Assumptions 2.2 and 2.3, respectively.\n\nGiven these assumptions, we next establish a high probability error bound for the estimators in SBCGI."}, {"type": "table", "rows": [["Lemma 4.1", "Consider SBCGI in Algorithm 1 with parameters $\\alpha_t = \\beta_t = \\rho_t = \\gamma_t = \\frac{1}{(t + 1)^\\omega}$ where $\\omega \\in (0, 1]$. If Assumptions 2.1, 2.2, and 2.3 are satisfied, for any $t \\geq 1$ and $\\delta \\in (0, 1)$, with probability at least $1 - \\delta$, for some absolute constant c, (d is the number of dimension), we have"], ["", "$\\", "\\nabla f_t - \\nabla f(x_t) \\", "\\leq c \\sqrt{2(2LfD + 3\\omega - 1\\sigma_f)(t + 1)^{-\\omega/2} \\log(6d/\\delta)}$"], ["", "$\\", "\\nabla g_t - \\nabla g(x_t) \\", "\\leq c \\sqrt{2(2LgD + 3\\omega - 1\\sigma_g)(t + 1)^{-\\omega/2} \\log(6d/\\delta)}$"], ["", "$", "\\hat{g}_t - g(x_t)", "\\leq c \\sqrt{2(2LlD + 3\\omega - 1\\sigma_l)(t + 1)^{-\\omega/2} \\log(6/\\delta)}$"]], "md": "|Lemma 4.1|Consider SBCGI in Algorithm 1 with parameters $\\alpha_t = \\beta_t = \\rho_t = \\gamma_t = \\frac{1}{(t + 1)^\\omega}$ where $\\omega \\in (0, 1]$. If Assumptions 2.1, 2.2, and 2.3 are satisfied, for any $t \\geq 1$ and $\\delta \\in (0, 1)$, with probability at least $1 - \\delta$, for some absolute constant c, (d is the number of dimension), we have|\n|---|---|\n| |$\\| \\nabla f_t - \\nabla f(x_t) \\| \\leq c \\sqrt{2(2LfD + 3\\omega - 1\\sigma_f)(t + 1)^{-\\omega/2} \\log(6d/\\delta)}$|\n| |$\\| \\nabla g_t - \\nabla g(x_t) \\| \\leq c \\sqrt{2(2LgD + 3\\omega - 1\\sigma_g)(t + 1)^{-\\omega/2} \\log(6d/\\delta)}$|\n| |$| \\hat{g}_t - g(x_t) | \\leq c \\sqrt{2(2LlD + 3\\omega - 1\\sigma_l)(t + 1)^{-\\omega/2} \\log(6/\\delta)}$|", "isPerfectTable": false, "csv": "\"Lemma 4.1\",\"Consider SBCGI in Algorithm 1 with parameters $\\alpha_t = \\beta_t = \\rho_t = \\gamma_t = \\frac{1}{(t + 1)^\\omega}$ where $\\omega \\in (0, 1]$. If Assumptions 2.1, 2.2, and 2.3 are satisfied, for any $t \\geq 1$ and $\\delta \\in (0, 1)$, with probability at least $1 - \\delta$, for some absolute constant c, (d is the number of dimension), we have\"\n\"\",\"$\\\",\"\\nabla f_t - \\nabla f(x_t) \\\",\"\\leq c \\sqrt{2(2LfD + 3\\omega - 1\\sigma_f)(t + 1)^{-\\omega/2} \\log(6d/\\delta)}$\"\n\"\",\"$\\\",\"\\nabla g_t - \\nabla g(x_t) \\\",\"\\leq c \\sqrt{2(2LgD + 3\\omega - 1\\sigma_g)(t + 1)^{-\\omega/2} \\log(6d/\\delta)}$\"\n\"\",\"$\",\"\\hat{g}_t - g(x_t)\",\"\\leq c \\sqrt{2(2LlD + 3\\omega - 1\\sigma_l)(t + 1)^{-\\omega/2} \\log(6/\\delta)}$\""}, {"type": "text", "value": "Lemma 4.1 shows that for any $$\\omega \\in (0, 1]$$, if we set $$\\alpha_t = \\beta_t = \\rho_t = \\gamma_t = \\frac{1}{(t + 1)^\\omega}$$, then with high probability the gradient and function approximation errors converge to zero at a sublinear rate of $$\\tilde{O}(1/t^{\\omega/2})$$. Moreover, the above result characterizes the choice of $$K_t$$. More precisely, if we define $$K_{1,t}$$ as the upper bound in (15) and $$K_{0,t}$$ as the upper bound in (16), by setting $$K_t = K_{0,t} + DK_{1,t}$$, then with probability $$(1 - \\delta)$$ the random set $$\\hat{X}_t$$ contains $$X^* g$$. Later, we will show that $$\\omega = 1$$ leads to the best complexity bound for the convex setting and $$\\omega = 2/3$$ is the best choice for the nonconvex setting.\n\nNext, we establish a similar result for the estimators in SBCGF.", "md": "Lemma 4.1 shows that for any $$\\omega \\in (0, 1]$$, if we set $$\\alpha_t = \\beta_t = \\rho_t = \\gamma_t = \\frac{1}{(t + 1)^\\omega}$$, then with high probability the gradient and function approximation errors converge to zero at a sublinear rate of $$\\tilde{O}(1/t^{\\omega/2})$$. Moreover, the above result characterizes the choice of $$K_t$$. More precisely, if we define $$K_{1,t}$$ as the upper bound in (15) and $$K_{0,t}$$ as the upper bound in (16), by setting $$K_t = K_{0,t} + DK_{1,t}$$, then with probability $$(1 - \\delta)$$ the random set $$\\hat{X}_t$$ contains $$X^* g$$. Later, we will show that $$\\omega = 1$$ leads to the best complexity bound for the convex setting and $$\\omega = 2/3$$ is the best choice for the nonconvex setting.\n\nNext, we establish a similar result for the estimators in SBCGF."}]}, {"page": 10, "text": "Lemma 4.2. Consider SBCGF with stepsize \u03b3 and S = q = \u221an. If Assumptions 2.1-2.3 hold,                                                   log(12/\u03b4),\nfor any t \u2265        1 and \u03b4 \u2208        (0, 1), with probability 1 \u2212              \u03b4 we have \u2225       \u2207f t \u2212     \u2207f(xt)\u2225       \u2264   4LgD\u03b3\n\u2225 \u2207gt \u2212      \u2207g(xt)\u2225      \u2264   4LgD\u03b3          log(12/\u03b4), and |\u02c6        gt \u2212   g(xt)| \u2264      4LlD\u03b3         log(12/\u03b4).\nSimilarly, for SBCGF, we set K1,t = 4LgD\u03b3                                 log(12/\u03b4) and K0,t = 4LlD\u03b3                      log(12/\u03b4) and choose\nKt = K0,t + DK1,t, then the random set \u02c6                         Xt contains X \u2217       g with probability 1 \u2212              \u03b4.\nNext, we formalize our claim about the random set with the above choice of Kt.\nLemma 4.3. If X \u2217           g is the solution set of the lower-level problem and \u02c6                        Xt is the feasible set constructed\nby cutting plane at iteration t, then for any t \u2265                           0 and \u03b4 \u2208       (0, 1), we have P(X \u2217                 Xt) \u2265     1 \u2212   \u03b4.\n                                                                                                                           g \u2286     \u02c6\nThis lemma shows all X \u2217               g is a subset of the constructed feasible set \u02c6                       Xt with a high probability of\n1 \u2212   \u03b4. Indeed, using a union bound one can show that the above statement holds for all iterations\nup to time t with probability 1 \u2212                     t\u03b4.\n4.2       Convergence and complexity results for the stochastic setting\nNext, we characterize the iteration and sample complexity of the proposed method in SBCGI for\nthe stochastic setting. First, we present the result for the case that f is convex.\nTheorem 4.4 (Stochastic setting with convex upper-level). Consider SBCGI in Algorithm 1 for\nsolving problem (1). Suppose Assumptions 2.1, 2.2, and 2.3 hold and f is convex. If the stepsizes\nof SBCGI are selected as \u03b1t = \u03b2t = \u03c1t = \u03b3t = (t + 1)\u22121, and the cutting plane parameter is\nKt = c((2LlD + 3           2\u03c3l)      2 log(6t/\u03b4) + D(2LgD + 3               2\u03c3g)      2 log(6td/\u03b4))(t + 1)\u22121/2, then\n      g(xt) \u2212      g\u2217  \u2264   \u221a  C1\u03b6              t + 1        + \u01ebg 2 ,     f(xt) \u2212      f \u2217 \u2264    \u221a C2\u03b6                         t + 1                  .\n                              t + 1 + LgD2 log t                                                  t + 1 + f(x0) \u2212           f \u2217 + LfD2 log t\nwith probability 1 \u2212            \u03b4 for some absolute constants C1 and C2 and \u03b6 :=                                 log (6td/\u03b4).\nTheorem 4.4 shows a convergence rate of O(                                     log(td/\u03b4)/      \u221a  t).    As a corollary, SBCGI returns\nan (\u01ebf, \u01ebg)-optimal solution with probability 1 \u2212                                \u03b4 after O(log(d/\u03b4\u01eb)/\u01eb2) iterations, where \u01eb =\nmin{\u01ebf, \u01ebg}. Since we use one sample per iteration, the overall sample complexity is also O(log(d/\u03b4\u01eb)/\u01eb2).\nNote that the iteration complexity and sample complexity of our method outperform the ones in\n[JY22], as they require O(1/\u01eb4) iterations and sample to achieve the same guarantee.\nRemark 4.1. The task of fi                    nding x0 which is equivalent to a single-level stochastic optimization\nproblem requires O(1/\u01eb2              g) iterations and samples. As a result, this additional cost does not affect\nthe overall complexity of our method. The same argument also holds in the non-convex case.\nTheorem 4.5 (Stochastic setting with non-convex upper level). Consider SBCGI for solving prob-\nlem (1). Suppose Assumptions 2.1-2.3 hold, f is nonconvex, and defi                                            ne f     = minx\u2208Z f(x). If the\nstepsizes of SBCGI are selected as \u03b1t = \u03b2t = \u03c1t = (t+1)\u22122/3, \u03b3t = (T +1)\u22122/3, and the cutting plane\nparameter is Kt = c((2LlD+                     32/3            2 log(6T/\u03b4)+D(2LgD+                    32/3            2 log(6T     d/\u03b4))(t+1)\u22121/3,\nthen after T iterations, there exists t\u2217      32/3 \u22121\u03c3l)     \u2208  {0, 1, . . . , T \u2212    1} such that  32/3\u22121\u03c3g)\n                        g(xt\u2217)\u2212g\u2217        \u2264   C3\u03b6 + LgD2          + \u01ebg 2 ,     G(xt\u2217) \u2264       f(x0)\u2212f        + C4\u03b6 + LfD2\n                                               (T + 1)1/3                                               (T + 1)1/3\n                                                                            10", "md": "## Lemma 4.2\n\nConsider SBCGF with stepsize \u03b3 and S = q = \u221an. If Assumptions 2.1-2.3 hold, log(12/\u03b4), for any t \u2265 1 and \u03b4 \u2208 (0, 1), with probability 1 \u2212 \u03b4 we have\n\n$$\n\\| \\nabla f_t - \\nabla f(x_t) \\| \\leq 4LgD\\gamma \\\\\n\\| \\nabla g_t - \\nabla g(x_t) \\| \\leq 4LgD\\gamma \\log(12/\u03b4) \\\\\n| \\hat{g}_t - g(x_t) | \\leq 4LlD\\gamma \\log(12/\u03b4).\n$$\nSimilarly, for SBCGF, we set K1,t = 4LgD\u03b3 log(12/\u03b4) and K0,t = 4LlD\u03b3 log(12/\u03b4) and choose Kt = K0,t + DK1,t, then the random set \u02c6X_t contains X^*g with probability 1 \u2212 \u03b4.\n\n## Lemma 4.3\n\nIf X^*g is the solution set of the lower-level problem and \u02c6X_t is the feasible set constructed by cutting plane at iteration t, then for any t \u2265 0 and \u03b4 \u2208 (0, 1), we have P(X^* \\subseteq X_t) \\geq 1 - \u03b4.\n\nThis lemma shows all X^*g is a subset of the constructed feasible set \u02c6X_t with a high probability of 1 \u2212 \u03b4. Indeed, using a union bound one can show that the above statement holds for all iterations up to time t with probability 1 \u2212 t\u03b4.\n\n## Convergence and complexity results for the stochastic setting\n\nNext, we characterize the iteration and sample complexity of the proposed method in SBCGI for the stochastic setting. First, we present the result for the case that f is convex.\n\n### Theorem 4.4 (Stochastic setting with convex upper-level)\n\nConsider SBCGI in Algorithm 1 for solving problem (1). Suppose Assumptions 2.1, 2.2, and 2.3 hold and f is convex. If the stepsizes of SBCGI are selected as \u03b1_t = \u03b2_t = \u03c1_t = \u03b3_t = (t + 1)^{-1}, and the cutting plane parameter is\n\n$$\nK_t = c\\left(\\left(2LlD + \\frac{3}{2}\\sigma_l\\right)^2 \\log\\left(\\frac{6t}{\u03b4}\\right) + D\\left(2LgD + \\frac{3}{2}\\sigma_g\\right)^2 \\log\\left(\\frac{6td}{\u03b4}\\right)\\right)(t + 1)^{-1/2},\n$$\nthen\n\n$$\ng(x_t) - g^* \\leq \\sqrt{C1\u03b6t + 1} + \u01ebg^2, \\\\\nf(x_t) - f^* \\leq \\sqrt{C2\u03b6t + 1},\n$$\nwith probability 1 \u2212 \u03b4 for some absolute constants C1 and C2 and \u03b6 := log(6td/\u03b4).\n\nTheorem 4.4 shows a convergence rate of O(log(td/\u03b4)/\u221at). As a corollary, SBCGI returns an (\u01ebf, \u01ebg)-optimal solution with probability 1 \u2212 \u03b4 after O(log(d/\u03b4\u01eb)/\u01eb^2) iterations, where \u01eb = min{\u01ebf, \u01ebg}. Since we use one sample per iteration, the overall sample complexity is also O(log(d/\u03b4\u01eb)/\u01eb^2.\n\nNote that the iteration complexity and sample complexity of our method outperform the ones in [JY22], as they require O(1/\u01eb^4) iterations and samples to achieve the same guarantee.\n\n### Remark 4.1\n\nThe task of finding x0 which is equivalent to a single-level stochastic optimization problem requires O(1/\u01eb^2g) iterations and samples. As a result, this additional cost does not affect the overall complexity of our method. The same argument also holds in the non-convex case.\n\n### Theorem 4.5 (Stochastic setting with non-convex upper level)\n\nConsider SBCGI for solving problem (1). Suppose Assumptions 2.1-2.3 hold, f is nonconvex, and define f* = minx\u2208Z f(x). If the stepsizes of SBCGI are selected as \u03b1_t = \u03b2_t = \u03c1_t = (t+1)^{-2/3}, \u03b3_t = (T +1)^{-2/3}, and the cutting plane parameter is\n\n$$\nK_t = c\\left(\\left(2LlD+ \\frac{3}{2}\\right)^{2/3} \\log\\left(\\frac{6T}{\u03b4}\\right)+D\\left(2LgD+ \\frac{3}{2}\\right)^{2/3} \\log\\left(\\frac{6Td}{\u03b4}\\right)\\right)(t+1)^{-1/3},\n$$\nthen after T iterations, there exists t* \u2208 {0, 1, . . . , T \u2212 1} such that\n\n$$\ng(x_{t^*}) - g^* \\leq C3\u03b6 + LgD^2 + \u01ebg^2, \\\\\nf(x_{t^*}) \\leq f(x_0) - f^* + C4\u03b6 + LfD^2,\n$$\nwith probability 1 \u2212 \u03b4.", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "Lemma 4.2", "md": "## Lemma 4.2"}, {"type": "text", "value": "Consider SBCGF with stepsize \u03b3 and S = q = \u221an. If Assumptions 2.1-2.3 hold, log(12/\u03b4), for any t \u2265 1 and \u03b4 \u2208 (0, 1), with probability 1 \u2212 \u03b4 we have\n\n$$\n\\| \\nabla f_t - \\nabla f(x_t) \\| \\leq 4LgD\\gamma \\\\\n\\| \\nabla g_t - \\nabla g(x_t) \\| \\leq 4LgD\\gamma \\log(12/\u03b4) \\\\", "md": "Consider SBCGF with stepsize \u03b3 and S = q = \u221an. If Assumptions 2.1-2.3 hold, log(12/\u03b4), for any t \u2265 1 and \u03b4 \u2208 (0, 1), with probability 1 \u2212 \u03b4 we have\n\n$$\n\\| \\nabla f_t - \\nabla f(x_t) \\| \\leq 4LgD\\gamma \\\\\n\\| \\nabla g_t - \\nabla g(x_t) \\| \\leq 4LgD\\gamma \\log(12/\u03b4) \\\\"}, {"type": "table", "rows": [["\\hat{g}_t - g(x_t)"]], "md": "| \\hat{g}_t - g(x_t) | \\leq 4LlD\\gamma \\log(12/\u03b4).", "isPerfectTable": true, "csv": "\"\\hat{g}_t - g(x_t)\""}, {"type": "text", "value": "$$\nSimilarly, for SBCGF, we set K1,t = 4LgD\u03b3 log(12/\u03b4) and K0,t = 4LlD\u03b3 log(12/\u03b4) and choose Kt = K0,t + DK1,t, then the random set \u02c6X_t contains X^*g with probability 1 \u2212 \u03b4.", "md": "$$\nSimilarly, for SBCGF, we set K1,t = 4LgD\u03b3 log(12/\u03b4) and K0,t = 4LlD\u03b3 log(12/\u03b4) and choose Kt = K0,t + DK1,t, then the random set \u02c6X_t contains X^*g with probability 1 \u2212 \u03b4."}, {"type": "heading", "lvl": 2, "value": "Lemma 4.3", "md": "## Lemma 4.3"}, {"type": "text", "value": "If X^*g is the solution set of the lower-level problem and \u02c6X_t is the feasible set constructed by cutting plane at iteration t, then for any t \u2265 0 and \u03b4 \u2208 (0, 1), we have P(X^* \\subseteq X_t) \\geq 1 - \u03b4.\n\nThis lemma shows all X^*g is a subset of the constructed feasible set \u02c6X_t with a high probability of 1 \u2212 \u03b4. Indeed, using a union bound one can show that the above statement holds for all iterations up to time t with probability 1 \u2212 t\u03b4.", "md": "If X^*g is the solution set of the lower-level problem and \u02c6X_t is the feasible set constructed by cutting plane at iteration t, then for any t \u2265 0 and \u03b4 \u2208 (0, 1), we have P(X^* \\subseteq X_t) \\geq 1 - \u03b4.\n\nThis lemma shows all X^*g is a subset of the constructed feasible set \u02c6X_t with a high probability of 1 \u2212 \u03b4. Indeed, using a union bound one can show that the above statement holds for all iterations up to time t with probability 1 \u2212 t\u03b4."}, {"type": "heading", "lvl": 2, "value": "Convergence and complexity results for the stochastic setting", "md": "## Convergence and complexity results for the stochastic setting"}, {"type": "text", "value": "Next, we characterize the iteration and sample complexity of the proposed method in SBCGI for the stochastic setting. First, we present the result for the case that f is convex.", "md": "Next, we characterize the iteration and sample complexity of the proposed method in SBCGI for the stochastic setting. First, we present the result for the case that f is convex."}, {"type": "heading", "lvl": 3, "value": "Theorem 4.4 (Stochastic setting with convex upper-level)", "md": "### Theorem 4.4 (Stochastic setting with convex upper-level)"}, {"type": "text", "value": "Consider SBCGI in Algorithm 1 for solving problem (1). Suppose Assumptions 2.1, 2.2, and 2.3 hold and f is convex. If the stepsizes of SBCGI are selected as \u03b1_t = \u03b2_t = \u03c1_t = \u03b3_t = (t + 1)^{-1}, and the cutting plane parameter is\n\n$$\nK_t = c\\left(\\left(2LlD + \\frac{3}{2}\\sigma_l\\right)^2 \\log\\left(\\frac{6t}{\u03b4}\\right) + D\\left(2LgD + \\frac{3}{2}\\sigma_g\\right)^2 \\log\\left(\\frac{6td}{\u03b4}\\right)\\right)(t + 1)^{-1/2},\n$$\nthen\n\n$$\ng(x_t) - g^* \\leq \\sqrt{C1\u03b6t + 1} + \u01ebg^2, \\\\\nf(x_t) - f^* \\leq \\sqrt{C2\u03b6t + 1},\n$$\nwith probability 1 \u2212 \u03b4 for some absolute constants C1 and C2 and \u03b6 := log(6td/\u03b4).\n\nTheorem 4.4 shows a convergence rate of O(log(td/\u03b4)/\u221at). As a corollary, SBCGI returns an (\u01ebf, \u01ebg)-optimal solution with probability 1 \u2212 \u03b4 after O(log(d/\u03b4\u01eb)/\u01eb^2) iterations, where \u01eb = min{\u01ebf, \u01ebg}. Since we use one sample per iteration, the overall sample complexity is also O(log(d/\u03b4\u01eb)/\u01eb^2.\n\nNote that the iteration complexity and sample complexity of our method outperform the ones in [JY22], as they require O(1/\u01eb^4) iterations and samples to achieve the same guarantee.", "md": "Consider SBCGI in Algorithm 1 for solving problem (1). Suppose Assumptions 2.1, 2.2, and 2.3 hold and f is convex. If the stepsizes of SBCGI are selected as \u03b1_t = \u03b2_t = \u03c1_t = \u03b3_t = (t + 1)^{-1}, and the cutting plane parameter is\n\n$$\nK_t = c\\left(\\left(2LlD + \\frac{3}{2}\\sigma_l\\right)^2 \\log\\left(\\frac{6t}{\u03b4}\\right) + D\\left(2LgD + \\frac{3}{2}\\sigma_g\\right)^2 \\log\\left(\\frac{6td}{\u03b4}\\right)\\right)(t + 1)^{-1/2},\n$$\nthen\n\n$$\ng(x_t) - g^* \\leq \\sqrt{C1\u03b6t + 1} + \u01ebg^2, \\\\\nf(x_t) - f^* \\leq \\sqrt{C2\u03b6t + 1},\n$$\nwith probability 1 \u2212 \u03b4 for some absolute constants C1 and C2 and \u03b6 := log(6td/\u03b4).\n\nTheorem 4.4 shows a convergence rate of O(log(td/\u03b4)/\u221at). As a corollary, SBCGI returns an (\u01ebf, \u01ebg)-optimal solution with probability 1 \u2212 \u03b4 after O(log(d/\u03b4\u01eb)/\u01eb^2) iterations, where \u01eb = min{\u01ebf, \u01ebg}. Since we use one sample per iteration, the overall sample complexity is also O(log(d/\u03b4\u01eb)/\u01eb^2.\n\nNote that the iteration complexity and sample complexity of our method outperform the ones in [JY22], as they require O(1/\u01eb^4) iterations and samples to achieve the same guarantee."}, {"type": "heading", "lvl": 3, "value": "Remark 4.1", "md": "### Remark 4.1"}, {"type": "text", "value": "The task of finding x0 which is equivalent to a single-level stochastic optimization problem requires O(1/\u01eb^2g) iterations and samples. As a result, this additional cost does not affect the overall complexity of our method. The same argument also holds in the non-convex case.", "md": "The task of finding x0 which is equivalent to a single-level stochastic optimization problem requires O(1/\u01eb^2g) iterations and samples. As a result, this additional cost does not affect the overall complexity of our method. The same argument also holds in the non-convex case."}, {"type": "heading", "lvl": 3, "value": "Theorem 4.5 (Stochastic setting with non-convex upper level)", "md": "### Theorem 4.5 (Stochastic setting with non-convex upper level)"}, {"type": "text", "value": "Consider SBCGI for solving problem (1). Suppose Assumptions 2.1-2.3 hold, f is nonconvex, and define f* = minx\u2208Z f(x). If the stepsizes of SBCGI are selected as \u03b1_t = \u03b2_t = \u03c1_t = (t+1)^{-2/3}, \u03b3_t = (T +1)^{-2/3}, and the cutting plane parameter is\n\n$$\nK_t = c\\left(\\left(2LlD+ \\frac{3}{2}\\right)^{2/3} \\log\\left(\\frac{6T}{\u03b4}\\right)+D\\left(2LgD+ \\frac{3}{2}\\right)^{2/3} \\log\\left(\\frac{6Td}{\u03b4}\\right)\\right)(t+1)^{-1/3},\n$$\nthen after T iterations, there exists t* \u2208 {0, 1, . . . , T \u2212 1} such that\n\n$$\ng(x_{t^*}) - g^* \\leq C3\u03b6 + LgD^2 + \u01ebg^2, \\\\\nf(x_{t^*}) \\leq f(x_0) - f^* + C4\u03b6 + LfD^2,\n$$\nwith probability 1 \u2212 \u03b4.", "md": "Consider SBCGI for solving problem (1). Suppose Assumptions 2.1-2.3 hold, f is nonconvex, and define f* = minx\u2208Z f(x). If the stepsizes of SBCGI are selected as \u03b1_t = \u03b2_t = \u03c1_t = (t+1)^{-2/3}, \u03b3_t = (T +1)^{-2/3}, and the cutting plane parameter is\n\n$$\nK_t = c\\left(\\left(2LlD+ \\frac{3}{2}\\right)^{2/3} \\log\\left(\\frac{6T}{\u03b4}\\right)+D\\left(2LgD+ \\frac{3}{2}\\right)^{2/3} \\log\\left(\\frac{6Td}{\u03b4}\\right)\\right)(t+1)^{-1/3},\n$$\nthen after T iterations, there exists t* \u2208 {0, 1, . . . , T \u2212 1} such that\n\n$$\ng(x_{t^*}) - g^* \\leq C3\u03b6 + LgD^2 + \u01ebg^2, \\\\\nf(x_{t^*}) \\leq f(x_0) - f^* + C4\u03b6 + LfD^2,\n$$\nwith probability 1 \u2212 \u03b4."}]}, {"page": 11, "text": "with probability 1 \u2212           \u03b4 for some absolute constants C3, C4 and \u03b6 :=                                log (6T     d/\u03b4). Note that G(\u00b7) is\nFrank-Wolfe gap defi             ned in Defi      nition 2.1.\nAs a corollary of Theorem 4.5, the number of iterations required to find an (\u01ebf, \u01ebg)-optimal solution\ncan be upper bounded by O(log(d/\u03b4\u01eb)3/2/\u01eb3), where \u01eb = min{\u01ebf, \u01ebg}. We note that the dependence\non the upper-level accuracy \u01ebf also matches that in the standard CG method for a single-level\nnon-convex problem [Lac16; MOJ18].                               Moreover, as we only need one stochastic oracle query\nper iteration, SBCGI only requires O(log (d/\u03b4\u01eb)3/2/\u01eb3) stochastic oracle queries to find an (\u01ebf, \u01ebg)-\noptimal.\n4.3       Convergence and complexity results for the fi                                            nite-sum setting\nSimilarly, we present iteration and sample complexity for algorithm 2 under the finite-sum setting.\nTheorem 4.6 (Finite-sum setting with convex upper-level). Consider SBCGF presented in Algo-\nrithm 2 for solving the fi             nite-sum version of (1). Suppose Assumptions 2.1, 2.2, and 2.3 hold and\nf is convex. If we set the stepsizes of SBCGF as \u03b3 = log T/T                                      , S = q = \u221an, and the cutting plane\nparameter as Kt = 4D(Ll                     log(12T/\u03b4) + LgD                 log(12T/\u03b4)) log T/T            , then we have\n              g(xT ) \u2212     g\u2217   \u2264   (C5\u03b6\u2032 + LgD2) log T             + \u01ebg         f(xT ) \u2212      f \u2217  \u2264   f(x0) \u2212      f \u2217 + C6\u03b6\u2032 log T        ,\n                                                  T                      2 ,                                             T\n  with probability at least 1 \u2212               \u03b4, for some absolute constant C5 and C6, and \u03b6\u2032 =                                 log(12T /\u03b4).\nTheorem 4.6 implies the number of stochastic oracle queries is O(log(1/\u03b4\u01eb)3/2\u221an/\u01eb), where \u01eb =\nmin{\u01ebf, \u01ebg}, which matches the optimal sample complexity of single-level problems [BDG23].\nTheorem 4.7 (Finite-sum setting with non-convex upper-level). Consider SBCGF presented in\nAlgorithm 2 for solving the fi                  nite-sum version of (1). Suppose Assumptions2.1-2.3 hold, and f                                      \u221a\nis non-convex. Defi            ne f     = minx\u2208Z f(x). If the parameters of SBCGF are selected as \u03b3 = 1/                                             \u221a  T  ,\nS = q = \u221an, and the cutting plane parameter is Kt = 4D(Ll                                         log(12T/\u03b4)+LgD                 log(12T/\u03b4))/           T  ,\nthen, after T iterations, there exists t\u2217                     \u2208  {0, 1, . . . , T \u2212    1} such that\n                             g(xt\u2217) \u2212      g\u2217  \u2264    C7\u03b6\u2032 + LgD2          + \u01ebg2 ,      G(xt\u2217) \u2264       f(x0)\u2212f        + C8\u03b6\u2032\n                                                          T 1/2                                               T 1/2\n  with probability at least 1 \u2212                 \u03b4, for some absolute constants C7 and C8, and \u03b6\u2032 =                                     log(12T /\u03b4).\nNote that G(\u00b7) is Frank-Wolfe gap defi                      ned in Defi       nition 2.1.\nAs a corollary of Theorem 4.7, the number of stochastic oracle queries is O(log(1/\u03b4\u01eb)\u221an/\u01eb2),\nwhere \u01eb = min{\u01ebf, \u01ebg}, which matches the state-of-the-art single-level result O(\u221a                                               n/\u01eb2) in [YSC19].\nSBCGF also improves the number of linear minimization oracle queries of SBCGI from O(1/\u01eb2) to\nO(1/\u01eb) for convex upper-level and from O(1/\u01eb3) to O(1/\u01eb2) for non-convex upper-level.\n5       Numerical experiments\nIn this section, we test our methods on two different stochastic bilevel optimization problems with\nreal and synthetic datasets and compare them with other existing stochastic methods in [JY22]\nand [GL21].\n                                                                            11", "md": "# Stochastic Bilevel Optimization\n\n## Convergence and Complexity Results\n\nWith probability \\(1 - \\delta\\) for some absolute constants \\(C3\\), \\(C4\\) and \\(\\zeta := \\log(6Td/\\delta)\\). Note that \\(G(\\cdot)\\) is Frank-Wolfe gap defined in Definition 2.1.\n\nAs a corollary of Theorem 4.5, the number of iterations required to find an \\((\\epsilon_f, \\epsilon_g)\\)-optimal solution can be upper bounded by \\(O(\\log(d/\\delta\\epsilon)^{3/2}/\\epsilon^3)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\). We note that the dependence on the upper-level accuracy \\(\\epsilon_f\\) also matches that in the standard CG method for a single-level non-convex problem [Lac16; MOJ18]. Moreover, as we only need one stochastic oracle query per iteration, SBCGI only requires \\(O(\\log(d/\\delta\\epsilon)^{3/2}/\\epsilon^3)\\) stochastic oracle queries to find an \\((\\epsilon_f, \\epsilon_g)\\)-optimal.\n\n### Convergence and Complexity Results for the Finite-Sum Setting\n\nSimilarly, we present iteration and sample complexity for algorithm 2 under the finite-sum setting.\n\nTheorem 4.6 (Finite-sum setting with convex upper-level). Consider SBCGF presented in Algorithm 2 for solving the finite-sum version of (1). Suppose Assumptions 2.1, 2.2, and 2.3 hold and \\(f\\) is convex. If we set the stepsizes of SBCGF as \\(\\gamma = \\log T/T\\), \\(S = q = \\sqrt{n}\\), and the cutting plane parameter as \\(Kt = 4D(Ll \\log(12T/\\delta) + LgD \\log(12T/\\delta)) \\log T/T\\), then we have\n\n$$\ng(x_T) - g^* \\leq (C5\\zeta' + LgD^2) \\log T + \\epsilon_g, \\quad f(x_T) - f^* \\leq f(x_0) - f^* + C6\\zeta' \\log T,\n$$\nwith probability at least \\(1 - \\delta\\), for some absolute constant \\(C5\\) and \\(C6\\), and \\(\\zeta' = \\log(12T/\\delta)\\).\n\nTheorem 4.6 implies the number of stochastic oracle queries is \\(O(\\log(1/\\delta\\epsilon)^{3/2}\\sqrt{n}/\\epsilon)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\), which matches the optimal sample complexity of single-level problems [BDG23].\n\nTheorem 4.7 (Finite-sum setting with non-convex upper-level). Consider SBCGF presented in Algorithm 2 for solving the finite-sum version of (1). Suppose Assumptions 2.1-2.3 hold, and \\(f\\) is non-convex. Define \\(f = \\min_{x \\in Z} f(x)\\). If the parameters of SBCGF are selected as \\(\\gamma = 1/\\sqrt{T}\\), \\(S = q = \\sqrt{n}\\), and the cutting plane parameter is \\(Kt = 4D(Ll \\log(12T/\\delta) + LgD \\log(12T/\\delta))/\\sqrt{T}\\), then, after \\(T\\) iterations, there exists \\(t^* \\in \\{0, 1, ..., T - 1\\}\\) such that\n\n$$\ng(x_{t^*}) - g^* \\leq C7\\zeta' + LgD^2 + \\epsilon_g^2, \\quad G(x_{t^*}) \\leq f(x_0) - f + C8\\zeta',\n$$\nwith probability at least \\(1 - \\delta\\), for some absolute constants \\(C7\\) and \\(C8\\), and \\(\\zeta' = \\log(12T/\\delta)\\).\n\nAs a corollary of Theorem 4.7, the number of stochastic oracle queries is \\(O(\\log(1/\\delta\\epsilon)\\sqrt{n}/\\epsilon^2)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\), which matches the state-of-the-art single-level result \\(O(\\sqrt{n}/\\epsilon^2)\\) in [YSC19].\n\nSBCGF also improves the number of linear minimization oracle queries of SBCGI from \\(O(1/\\epsilon^2)\\) to \\(O(1/\\epsilon)\\) for convex upper-level and from \\(O(1/\\epsilon^3)\\) to \\(O(1/\\epsilon^2)\\) for non-convex upper-level.\n\n## Numerical Experiments\n\nIn this section, we test our methods on two different stochastic bilevel optimization problems with real and synthetic datasets and compare them with other existing stochastic methods in [JY22] and [GL21].", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Stochastic Bilevel Optimization", "md": "# Stochastic Bilevel Optimization"}, {"type": "heading", "lvl": 2, "value": "Convergence and Complexity Results", "md": "## Convergence and Complexity Results"}, {"type": "text", "value": "With probability \\(1 - \\delta\\) for some absolute constants \\(C3\\), \\(C4\\) and \\(\\zeta := \\log(6Td/\\delta)\\). Note that \\(G(\\cdot)\\) is Frank-Wolfe gap defined in Definition 2.1.\n\nAs a corollary of Theorem 4.5, the number of iterations required to find an \\((\\epsilon_f, \\epsilon_g)\\)-optimal solution can be upper bounded by \\(O(\\log(d/\\delta\\epsilon)^{3/2}/\\epsilon^3)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\). We note that the dependence on the upper-level accuracy \\(\\epsilon_f\\) also matches that in the standard CG method for a single-level non-convex problem [Lac16; MOJ18]. Moreover, as we only need one stochastic oracle query per iteration, SBCGI only requires \\(O(\\log(d/\\delta\\epsilon)^{3/2}/\\epsilon^3)\\) stochastic oracle queries to find an \\((\\epsilon_f, \\epsilon_g)\\)-optimal.", "md": "With probability \\(1 - \\delta\\) for some absolute constants \\(C3\\), \\(C4\\) and \\(\\zeta := \\log(6Td/\\delta)\\). Note that \\(G(\\cdot)\\) is Frank-Wolfe gap defined in Definition 2.1.\n\nAs a corollary of Theorem 4.5, the number of iterations required to find an \\((\\epsilon_f, \\epsilon_g)\\)-optimal solution can be upper bounded by \\(O(\\log(d/\\delta\\epsilon)^{3/2}/\\epsilon^3)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\). We note that the dependence on the upper-level accuracy \\(\\epsilon_f\\) also matches that in the standard CG method for a single-level non-convex problem [Lac16; MOJ18]. Moreover, as we only need one stochastic oracle query per iteration, SBCGI only requires \\(O(\\log(d/\\delta\\epsilon)^{3/2}/\\epsilon^3)\\) stochastic oracle queries to find an \\((\\epsilon_f, \\epsilon_g)\\)-optimal."}, {"type": "heading", "lvl": 3, "value": "Convergence and Complexity Results for the Finite-Sum Setting", "md": "### Convergence and Complexity Results for the Finite-Sum Setting"}, {"type": "text", "value": "Similarly, we present iteration and sample complexity for algorithm 2 under the finite-sum setting.\n\nTheorem 4.6 (Finite-sum setting with convex upper-level). Consider SBCGF presented in Algorithm 2 for solving the finite-sum version of (1). Suppose Assumptions 2.1, 2.2, and 2.3 hold and \\(f\\) is convex. If we set the stepsizes of SBCGF as \\(\\gamma = \\log T/T\\), \\(S = q = \\sqrt{n}\\), and the cutting plane parameter as \\(Kt = 4D(Ll \\log(12T/\\delta) + LgD \\log(12T/\\delta)) \\log T/T\\), then we have\n\n$$\ng(x_T) - g^* \\leq (C5\\zeta' + LgD^2) \\log T + \\epsilon_g, \\quad f(x_T) - f^* \\leq f(x_0) - f^* + C6\\zeta' \\log T,\n$$\nwith probability at least \\(1 - \\delta\\), for some absolute constant \\(C5\\) and \\(C6\\), and \\(\\zeta' = \\log(12T/\\delta)\\).\n\nTheorem 4.6 implies the number of stochastic oracle queries is \\(O(\\log(1/\\delta\\epsilon)^{3/2}\\sqrt{n}/\\epsilon)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\), which matches the optimal sample complexity of single-level problems [BDG23].\n\nTheorem 4.7 (Finite-sum setting with non-convex upper-level). Consider SBCGF presented in Algorithm 2 for solving the finite-sum version of (1). Suppose Assumptions 2.1-2.3 hold, and \\(f\\) is non-convex. Define \\(f = \\min_{x \\in Z} f(x)\\). If the parameters of SBCGF are selected as \\(\\gamma = 1/\\sqrt{T}\\), \\(S = q = \\sqrt{n}\\), and the cutting plane parameter is \\(Kt = 4D(Ll \\log(12T/\\delta) + LgD \\log(12T/\\delta))/\\sqrt{T}\\), then, after \\(T\\) iterations, there exists \\(t^* \\in \\{0, 1, ..., T - 1\\}\\) such that\n\n$$\ng(x_{t^*}) - g^* \\leq C7\\zeta' + LgD^2 + \\epsilon_g^2, \\quad G(x_{t^*}) \\leq f(x_0) - f + C8\\zeta',\n$$\nwith probability at least \\(1 - \\delta\\), for some absolute constants \\(C7\\) and \\(C8\\), and \\(\\zeta' = \\log(12T/\\delta)\\).\n\nAs a corollary of Theorem 4.7, the number of stochastic oracle queries is \\(O(\\log(1/\\delta\\epsilon)\\sqrt{n}/\\epsilon^2)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\), which matches the state-of-the-art single-level result \\(O(\\sqrt{n}/\\epsilon^2)\\) in [YSC19].\n\nSBCGF also improves the number of linear minimization oracle queries of SBCGI from \\(O(1/\\epsilon^2)\\) to \\(O(1/\\epsilon)\\) for convex upper-level and from \\(O(1/\\epsilon^3)\\) to \\(O(1/\\epsilon^2)\\) for non-convex upper-level.", "md": "Similarly, we present iteration and sample complexity for algorithm 2 under the finite-sum setting.\n\nTheorem 4.6 (Finite-sum setting with convex upper-level). Consider SBCGF presented in Algorithm 2 for solving the finite-sum version of (1). Suppose Assumptions 2.1, 2.2, and 2.3 hold and \\(f\\) is convex. If we set the stepsizes of SBCGF as \\(\\gamma = \\log T/T\\), \\(S = q = \\sqrt{n}\\), and the cutting plane parameter as \\(Kt = 4D(Ll \\log(12T/\\delta) + LgD \\log(12T/\\delta)) \\log T/T\\), then we have\n\n$$\ng(x_T) - g^* \\leq (C5\\zeta' + LgD^2) \\log T + \\epsilon_g, \\quad f(x_T) - f^* \\leq f(x_0) - f^* + C6\\zeta' \\log T,\n$$\nwith probability at least \\(1 - \\delta\\), for some absolute constant \\(C5\\) and \\(C6\\), and \\(\\zeta' = \\log(12T/\\delta)\\).\n\nTheorem 4.6 implies the number of stochastic oracle queries is \\(O(\\log(1/\\delta\\epsilon)^{3/2}\\sqrt{n}/\\epsilon)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\), which matches the optimal sample complexity of single-level problems [BDG23].\n\nTheorem 4.7 (Finite-sum setting with non-convex upper-level). Consider SBCGF presented in Algorithm 2 for solving the finite-sum version of (1). Suppose Assumptions 2.1-2.3 hold, and \\(f\\) is non-convex. Define \\(f = \\min_{x \\in Z} f(x)\\). If the parameters of SBCGF are selected as \\(\\gamma = 1/\\sqrt{T}\\), \\(S = q = \\sqrt{n}\\), and the cutting plane parameter is \\(Kt = 4D(Ll \\log(12T/\\delta) + LgD \\log(12T/\\delta))/\\sqrt{T}\\), then, after \\(T\\) iterations, there exists \\(t^* \\in \\{0, 1, ..., T - 1\\}\\) such that\n\n$$\ng(x_{t^*}) - g^* \\leq C7\\zeta' + LgD^2 + \\epsilon_g^2, \\quad G(x_{t^*}) \\leq f(x_0) - f + C8\\zeta',\n$$\nwith probability at least \\(1 - \\delta\\), for some absolute constants \\(C7\\) and \\(C8\\), and \\(\\zeta' = \\log(12T/\\delta)\\).\n\nAs a corollary of Theorem 4.7, the number of stochastic oracle queries is \\(O(\\log(1/\\delta\\epsilon)\\sqrt{n}/\\epsilon^2)\\), where \\(\\epsilon = \\min\\{\\epsilon_f, \\epsilon_g\\}\\), which matches the state-of-the-art single-level result \\(O(\\sqrt{n}/\\epsilon^2)\\) in [YSC19].\n\nSBCGF also improves the number of linear minimization oracle queries of SBCGI from \\(O(1/\\epsilon^2)\\) to \\(O(1/\\epsilon)\\) for convex upper-level and from \\(O(1/\\epsilon^3)\\) to \\(O(1/\\epsilon^2)\\) for non-convex upper-level."}, {"type": "heading", "lvl": 2, "value": "Numerical Experiments", "md": "## Numerical Experiments"}, {"type": "text", "value": "In this section, we test our methods on two different stochastic bilevel optimization problems with real and synthetic datasets and compare them with other existing stochastic methods in [JY22] and [GL21].", "md": "In this section, we test our methods on two different stochastic bilevel optimization problems with real and synthetic datasets and compare them with other existing stochastic methods in [JY22] and [GL21]."}]}, {"page": 12, "text": "                                                                                 102                                                        101\n              100\n                                                                                 100\n             10-2                                                                                                                           100\n                                                                                10-2\n             10-4\n             10-6 0         2         4         6         8        10           10-4 0         2         4         6         8        10   10-1 0         2         4        6     8       10\n                                                                105                                                                105                                                  105\n                        (a) Lower-level gap                                               (b) Upper-level gap                                              (c) Test error\n    Figure 1: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (3)\n               100                                                               100                                                        1\n               10-2                                                                                                                       0.8\n                                                                                                                                          0.6\n               10-4                                                             10-1\n                                                                                                                                          0.4\n               10-6                                                                                                                       0.2\n               10-80      1      2       3      4      5      6      7          10-20      1       2      3      4      5       6      7    0 0      1      2      3      4     5   6     7\n                                                                   105                                                              105                                                105\n                         (a) Lower-level gap                                              (b) Upper-level gap                                         (c) Recovery rate\n   Figure 2: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (5).\nOver-parameterized regression. We consider the bilevel problem corresponding to sparse linear\nregression introduced in (3).                                        We apply the Wikipedia Math Essential dataset [Roz+21] which\ncomposes of a data matrix A \u2208                                           Rn\u00d7d with n = 1068 samples and d = 730 features and an output\nvector b \u2208               Rn. To ensure the problem is over-parameterized, we assign 1/3 of the dataset as the\ntraining set (Atr, btr), 1/3 as the validation set (Aval , bval ) and the remaining 1/3 as the test\nset (Atest , btest ). For both upper- and lower-level loss functions we use the least squared loss,\nand we set \u03bb = 10. We compare the performance of our methods with the aR-IP-SeG method\nby [JY22] and the stochastic version of DBGD introduced by [GL21]. We employ CVX [GB08;\nGB14] to solve the lower-level problem and the reformulation of the bilevel problem to obtain g\u2217\nand f \u2217, respectively. We also include the additional cost of finding x0 in SBCGI and SBCGF in\nour comparisons.\nIn Figure 1(a)(b), we observe that SBCGF maintains a smaller lower-level gap than other methods\nand converges faster than the rest in terms of upper-level error.                                                                                 SBCGI has the second-best\nperformance in terms of lower- and upper-level gaps, while aR-IP-SeG performs poorly in terms of\nboth lower- and upper-level objectives. The performance of DBGD-sto for the upper-level objective\nis well, however, it underperforms in terms of lower-level error. In Figure 1(c), SBCGF, SBCGI,\nand DBGD-sto achieve almost equally small test errors, while aR-IP-SeG fails to achieve a low test\nerror. Note that after the initial stage, SBCGI increases slightly in terms of all the performance\ncriteria, because SBCGI (1) only takes one sample per iteration and uses a decreasing step-size\nwhile SBCGF takes \u221an samples per iteration and uses a small constant stepsize, demonstrating a\nmore robust performance.\nDictionary learning. To test our methods on problems with non-convex upper-level we consider\n                                                                                                          12", "md": "# Document\n\n## Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (3)\n\n| |Lower-level gap|Upper-level gap|Test error|\n|---|---|---|---|\n|100|10^-2|100|10^-2|\n|10^-4|10^-6|0|2|\n|4|6|8|10|\n|10^-4|0|2|4|\n|6|8|10|10^-1|\n|0|2|4|6|\n|8|10|105|105|\n\n## Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (5)\n\n| |Lower-level gap|Upper-level gap|Recovery rate|\n|---|---|---|---|\n|100|10^-2|100|0.8|\n|10^-4|10^-1|0.6|0.4|\n|10^-6|10^-80|1|2|\n|3|4|5|6|\n|7|10^-20|1|2|\n|3|4|5|6|\n|7|0|1|2|\n|3|4|5|6|\n|7|105|105|105|\n\nOver-parameterized regression. We consider the bilevel problem corresponding to sparse linear regression introduced in (3). We apply the Wikipedia Math Essential dataset [Roz+21] which composes of a data matrix $$A \\in \\mathbb{R}^{n \\times d}$$ with $$n = 1068$$ samples and $$d = 730$$ features and an output vector $$b \\in \\mathbb{R}^n$$. To ensure the problem is over-parameterized, we assign 1/3 of the dataset as the training set $$(A_{tr}, b_{tr})$$, 1/3 as the validation set $$(A_{val}, b_{val})$$ and the remaining 1/3 as the test set $$(A_{test}, b_{test})$$. For both upper- and lower-level loss functions we use the least squared loss, and we set $$\\lambda = 10$$. We compare the performance of our methods with the aR-IP-SeG method by [JY22] and the stochastic version of DBGD introduced by [GL21]. We employ CVX [GB08; GB14] to solve the lower-level problem and the reformulation of the bilevel problem to obtain $$g^*$$ and $$f^*$$, respectively. We also include the additional cost of finding $$x_0$$ in SBCGI and SBCGF in our comparisons.\n\nIn Figure 1(a)(b), we observe that SBCGF maintains a smaller lower-level gap than other methods and converges faster than the rest in terms of upper-level error. SBCGI has the second-best performance in terms of lower- and upper-level gaps, while aR-IP-SeG performs poorly in terms of both lower- and upper-level objectives. The performance of DBGD-sto for the upper-level objective is well, however, it underperforms in terms of lower-level error. In Figure 1(c), SBCGF, SBCGI, and DBGD-sto achieve almost equally small test errors, while aR-IP-SeG fails to achieve a low test error. Note that after the initial stage, SBCGI increases slightly in terms of all the performance criteria, because SBCGI (1) only takes one sample per iteration and uses a decreasing step-size while SBCGF takes $$\\sqrt{n}$$ samples per iteration and uses a small constant stepsize, demonstrating a more robust performance.\n\nDictionary learning. To test our methods on problems with non-convex upper-level we consider", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 2, "value": "Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (3)", "md": "## Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (3)"}, {"type": "table", "rows": [["", "Lower-level gap", "Upper-level gap", "Test error"], ["100", "10^-2", "100", "10^-2"], ["10^-4", "10^-6", "0", "2"], ["4", "6", "8", "10"], ["10^-4", "0", "2", "4"], ["6", "8", "10", "10^-1"], ["0", "2", "4", "6"], ["8", "10", "105", "105"]], "md": "| |Lower-level gap|Upper-level gap|Test error|\n|---|---|---|---|\n|100|10^-2|100|10^-2|\n|10^-4|10^-6|0|2|\n|4|6|8|10|\n|10^-4|0|2|4|\n|6|8|10|10^-1|\n|0|2|4|6|\n|8|10|105|105|", "isPerfectTable": true, "csv": "\"\",\"Lower-level gap\",\"Upper-level gap\",\"Test error\"\n\"100\",\"10^-2\",\"100\",\"10^-2\"\n\"10^-4\",\"10^-6\",\"0\",\"2\"\n\"4\",\"6\",\"8\",\"10\"\n\"10^-4\",\"0\",\"2\",\"4\"\n\"6\",\"8\",\"10\",\"10^-1\"\n\"0\",\"2\",\"4\",\"6\"\n\"8\",\"10\",\"105\",\"105\""}, {"type": "heading", "lvl": 2, "value": "Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (5)", "md": "## Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (5)"}, {"type": "table", "rows": [["", "Lower-level gap", "Upper-level gap", "Recovery rate"], ["100", "10^-2", "100", "0.8"], ["10^-4", "10^-1", "0.6", "0.4"], ["10^-6", "10^-80", "1", "2"], ["3", "4", "5", "6"], ["7", "10^-20", "1", "2"], ["3", "4", "5", "6"], ["7", "0", "1", "2"], ["3", "4", "5", "6"], ["7", "105", "105", "105"]], "md": "| |Lower-level gap|Upper-level gap|Recovery rate|\n|---|---|---|---|\n|100|10^-2|100|0.8|\n|10^-4|10^-1|0.6|0.4|\n|10^-6|10^-80|1|2|\n|3|4|5|6|\n|7|10^-20|1|2|\n|3|4|5|6|\n|7|0|1|2|\n|3|4|5|6|\n|7|105|105|105|", "isPerfectTable": true, "csv": "\"\",\"Lower-level gap\",\"Upper-level gap\",\"Recovery rate\"\n\"100\",\"10^-2\",\"100\",\"0.8\"\n\"10^-4\",\"10^-1\",\"0.6\",\"0.4\"\n\"10^-6\",\"10^-80\",\"1\",\"2\"\n\"3\",\"4\",\"5\",\"6\"\n\"7\",\"10^-20\",\"1\",\"2\"\n\"3\",\"4\",\"5\",\"6\"\n\"7\",\"0\",\"1\",\"2\"\n\"3\",\"4\",\"5\",\"6\"\n\"7\",\"105\",\"105\",\"105\""}, {"type": "text", "value": "Over-parameterized regression. We consider the bilevel problem corresponding to sparse linear regression introduced in (3). We apply the Wikipedia Math Essential dataset [Roz+21] which composes of a data matrix $$A \\in \\mathbb{R}^{n \\times d}$$ with $$n = 1068$$ samples and $$d = 730$$ features and an output vector $$b \\in \\mathbb{R}^n$$. To ensure the problem is over-parameterized, we assign 1/3 of the dataset as the training set $$(A_{tr}, b_{tr})$$, 1/3 as the validation set $$(A_{val}, b_{val})$$ and the remaining 1/3 as the test set $$(A_{test}, b_{test})$$. For both upper- and lower-level loss functions we use the least squared loss, and we set $$\\lambda = 10$$. We compare the performance of our methods with the aR-IP-SeG method by [JY22] and the stochastic version of DBGD introduced by [GL21]. We employ CVX [GB08; GB14] to solve the lower-level problem and the reformulation of the bilevel problem to obtain $$g^*$$ and $$f^*$$, respectively. We also include the additional cost of finding $$x_0$$ in SBCGI and SBCGF in our comparisons.\n\nIn Figure 1(a)(b), we observe that SBCGF maintains a smaller lower-level gap than other methods and converges faster than the rest in terms of upper-level error. SBCGI has the second-best performance in terms of lower- and upper-level gaps, while aR-IP-SeG performs poorly in terms of both lower- and upper-level objectives. The performance of DBGD-sto for the upper-level objective is well, however, it underperforms in terms of lower-level error. In Figure 1(c), SBCGF, SBCGI, and DBGD-sto achieve almost equally small test errors, while aR-IP-SeG fails to achieve a low test error. Note that after the initial stage, SBCGI increases slightly in terms of all the performance criteria, because SBCGI (1) only takes one sample per iteration and uses a decreasing step-size while SBCGF takes $$\\sqrt{n}$$ samples per iteration and uses a small constant stepsize, demonstrating a more robust performance.\n\nDictionary learning. To test our methods on problems with non-convex upper-level we consider", "md": "Over-parameterized regression. We consider the bilevel problem corresponding to sparse linear regression introduced in (3). We apply the Wikipedia Math Essential dataset [Roz+21] which composes of a data matrix $$A \\in \\mathbb{R}^{n \\times d}$$ with $$n = 1068$$ samples and $$d = 730$$ features and an output vector $$b \\in \\mathbb{R}^n$$. To ensure the problem is over-parameterized, we assign 1/3 of the dataset as the training set $$(A_{tr}, b_{tr})$$, 1/3 as the validation set $$(A_{val}, b_{val})$$ and the remaining 1/3 as the test set $$(A_{test}, b_{test})$$. For both upper- and lower-level loss functions we use the least squared loss, and we set $$\\lambda = 10$$. We compare the performance of our methods with the aR-IP-SeG method by [JY22] and the stochastic version of DBGD introduced by [GL21]. We employ CVX [GB08; GB14] to solve the lower-level problem and the reformulation of the bilevel problem to obtain $$g^*$$ and $$f^*$$, respectively. We also include the additional cost of finding $$x_0$$ in SBCGI and SBCGF in our comparisons.\n\nIn Figure 1(a)(b), we observe that SBCGF maintains a smaller lower-level gap than other methods and converges faster than the rest in terms of upper-level error. SBCGI has the second-best performance in terms of lower- and upper-level gaps, while aR-IP-SeG performs poorly in terms of both lower- and upper-level objectives. The performance of DBGD-sto for the upper-level objective is well, however, it underperforms in terms of lower-level error. In Figure 1(c), SBCGF, SBCGI, and DBGD-sto achieve almost equally small test errors, while aR-IP-SeG fails to achieve a low test error. Note that after the initial stage, SBCGI increases slightly in terms of all the performance criteria, because SBCGI (1) only takes one sample per iteration and uses a decreasing step-size while SBCGF takes $$\\sqrt{n}$$ samples per iteration and uses a small constant stepsize, demonstrating a more robust performance.\n\nDictionary learning. To test our methods on problems with non-convex upper-level we consider"}]}, {"page": 13, "text": " problem (5) on a synthetic dataset with a similar setup to [JAMH23]. We first construct the true\n dictionary \u02dc      D\u2217    \u2208  R25\u00d750 comprising of 50 basis vectors in R25. All entries of these basis vectors are\n drawn from the standard Gaussian distribution and then normalized to have unit \u21132-norm. We also\n generate two more dictionaries D\u2217                        and D\u2032\u2217       consisting of 40 and 20 basis vectors in \u02dc                       D\u2217, respectively\n(thus they share at least 10 bases). These two datasets A = {a1, . . . , a250} and A\u2032 = {a\u2032                                                      1, . . . , a\u2032\n are constructed as ai = D\u2217xi + ni, for i = 1, . . . , 250, and a\u2032                                     k = D\u2032\u2217x\u2032       k + n\u2032    k, for k = 1, . . . , 250,  250}\nwhere {xi}250      i=1, {x\u2032   k}250                                                           i=1, {n\u2032\n                                  k=1 are coefficient vectors and {ni}250                                k}250\n                                                                                                             k=1 are random Gaussian noises.\nAs neither A nor A\u2032 includes all the elements of \u02dc                                  D\u2217, it is important to renew our dictionary by\n using the new dataset A\u2032 while maintaining the knowledge from the old dataset A.\n In our experiment, we initially solve the standard dictionary learning problem employing dataset\nA, achieving the initial dictionary \u02c6                        D and coefficient vectors {\u02c6                  x}250i=1.     We define the lower-level\n objective as the reconstruction error on A using {\u02c6                                x}250\n                                                                                        i=1, and the upper-level objective as the error\n on new dataset A\u2032. We compare our algorithms with aR-IP-SeG and DBGD (stochastic version),\n measuring performance with the recovery rate of true basis vectors. Note that a basis vector \u02dc                                                                d\u2217 i\n in \u02dcD\u2217    is considered as successfully recovered if there exists \u02dc                                d j in \u02dc  D such that |\u27e8\u02dc         d\u2217    dj\u27e9| > 0.9 (for\n                                                                                                                                        i , \u02dc\n more details of the experiment setup see Appendix F). In Figure 2(a), we observe SBCGF converges\n faster than any other method regarding the lower-level objective. While SBCGI has the second-best\n performance in terms of the lower-level gap, aR-IP-SeG and DBGD-sto perform poorly compared\nwith SBCGI and SBCGF. In Figures 2(b) and (c), we see that SBCGI, SBCGF, and DBGD-sto\n achieve good results in terms of the upper-level objective and the recovery rate. However, aR-IP-\n SeG still performs poorly in terms of both criteria, which matches the theoretical results in Table\n1.\n Acknowledgements\nThe research of J. Cao, R. Jiang and A. Mokhtari is supported in part by NSF Grants 2127697,\n2019844, and 2112471, ARO Grant W911NF2110226, the Machine Learning Lab (MLL) at UT\nAustin, and the Wireless Networking and Communications Group (WNCG) Industrial Affiliates\n Program. The research of N. Abolfazli and E. Yazdandoost Hamedani is supported by NSF Grant\n2127696.\n References\n [ABTR21]               Zeeshan Akhtar, Amrit Singh Bedi, Srujan Teja Thomdapu, and Ketan Rajawat.\n                       \u201cProjection-Free Stochastic Bi-level Optimization\u201d. In: arXiv preprint arXiv:2110.11721\n                        (2021) (page 3).\n [BJQS15]               Chenglong Bao, Hui Ji, Yuhui Quan, and Zuowei Shen. \u201cDictionary learning for\n                        sparse coding: Algorithms and convergence analysis\u201d. In: IEEE transactions on pat-\n                        tern analysis and machine intelligence 38.7 (2015), pp. 1356\u20131369 (page 4).\n [BHTV18]               Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi. \u201cMeta-\n                        learning with differentiable closed-form solvers\u201d. In: arXiv preprint arXiv:1805.08136\n                        (2018) (page 2).\n [BDG23]                Aleksandr Beznosikov, David Dobre, and Gauthier Gidel. \u201cSarah Frank-Wolfe: Meth-\n                        ods for Constrained Optimization with Best Rates and Practical Features\u201d. In: arXiv\n                        preprint arXiv:2304.11737 (2023) (page 11).\n                                                                                13", "md": "Problem (5) on a synthetic dataset with a similar setup to [JAMH23]. We first construct the true dictionary \\( \\tilde{D}^* \\in \\mathbb{R}^{25 \\times 50} \\) comprising of 50 basis vectors in \\( \\mathbb{R}^{25} \\). All entries of these basis vectors are drawn from the standard Gaussian distribution and then normalized to have unit \\( \\ell_2 \\)-norm. We also generate two more dictionaries \\( D^* \\) and \\( D'^* \\) consisting of 40 and 20 basis vectors in \\( \\tilde{D}^* \\), respectively (thus they share at least 10 bases). These two datasets \\( A = \\{a_1, ..., a_{250}\\} \\) and \\( A' = \\{a'_1, ..., a'_{250}\\} \\) are constructed as \\( a_i = D^*x_i + n_i \\), for \\( i = 1, ..., 250 \\), and \\( a'_k = D'^*x'_k + n'_k \\), for \\( k = 1, ..., 250 \\), where \\( \\{x_i\\}_{i=1}^{250} \\), \\( \\{x'_k\\}_{i=1}^{250} \\), \\( \\{n'_k\\}_{k=1}^{250} \\) are coefficient vectors and \\( \\{n_i\\}_{k=1}^{250} \\) are random Gaussian noises.\n\nAs neither \\( A \\) nor \\( A' \\) includes all the elements of \\( \\tilde{D}^* \\), it is important to renew our dictionary by using the new dataset \\( A' \\) while maintaining the knowledge from the old dataset \\( A \\).\n\nIn our experiment, we initially solve the standard dictionary learning problem employing dataset \\( A \\), achieving the initial dictionary \\( \\hat{D} \\) and coefficient vectors \\( \\{\\hat{x}_i\\}_{i=1}^{250} \\). We define the lower-level objective as the reconstruction error on \\( A \\) using \\( \\{\\hat{x}_i\\}_{i=1}^{250} \\), and the upper-level objective as the error on new dataset \\( A' \\). We compare our algorithms with aR-IP-SeG and DBGD (stochastic version), measuring performance with the recovery rate of true basis vectors. Note that a basis vector \\( \\tilde{d}^*_i \\) in \\( \\tilde{D}^* \\) is considered as successfully recovered if there exists \\( \\tilde{d}_j \\) in \\( \\tilde{D} \\) such that \\( |\\langle \\tilde{d}^*_i, \\tilde{d}_j \\rangle| > 0.9 \\) (for more details of the experiment setup see Appendix F). In Figure 2(a), we observe SBCGF converges faster than any other method regarding the lower-level objective. While SBCGI has the second-best performance in terms of the lower-level gap, aR-IP-SeG and DBGD-sto perform poorly compared with SBCGI and SBCGF. In Figures 2(b) and (c), we see that SBCGI, SBCGF, and DBGD-sto achieve good results in terms of the upper-level objective and the recovery rate. However, aR-IP-SeG still performs poorly in terms of both criteria, which matches the theoretical results in Table 1.\n\nAcknowledgements\n\nThe research of J. Cao, R. Jiang and A. Mokhtari is supported in part by NSF Grants 2127697, 2019844, and 2112471, ARO Grant W911NF2110226, the Machine Learning Lab (MLL) at UT Austin, and the Wireless Networking and Communications Group (WNCG) Industrial Affiliates Program. The research of N. Abolfazli and E. Yazdandoost Hamedani is supported by NSF Grant 2127696.\n\nReferences\n\n- [ABTR21] Zeeshan Akhtar, Amrit Singh Bedi, Srujan Teja Thomdapu, and Ketan Rajawat. \"Projection-Free Stochastic Bi-level Optimization\". In: arXiv preprint arXiv:2110.11721 (2021) (page 3).\n- [BJQS15] Chenglong Bao, Hui Ji, Yuhui Quan, and Zuowei Shen. \"Dictionary learning for sparse coding: Algorithms and convergence analysis\". In: IEEE transactions on pattern analysis and machine intelligence 38.7 (2015), pp. 1356-1369 (page 4).\n- [BHTV18] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi. \"Meta-learning with differentiable closed-form solvers\". In: arXiv preprint arXiv:1805.08136 (2018) (page 2).\n- [BDG23] Aleksandr Beznosikov, David Dobre, and Gauthier Gidel. \"Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features\". In: arXiv preprint arXiv:2304.11737 (2023) (page 11).", "images": [], "items": [{"type": "text", "value": "Problem (5) on a synthetic dataset with a similar setup to [JAMH23]. We first construct the true dictionary \\( \\tilde{D}^* \\in \\mathbb{R}^{25 \\times 50} \\) comprising of 50 basis vectors in \\( \\mathbb{R}^{25} \\). All entries of these basis vectors are drawn from the standard Gaussian distribution and then normalized to have unit \\( \\ell_2 \\)-norm. We also generate two more dictionaries \\( D^* \\) and \\( D'^* \\) consisting of 40 and 20 basis vectors in \\( \\tilde{D}^* \\), respectively (thus they share at least 10 bases). These two datasets \\( A = \\{a_1, ..., a_{250}\\} \\) and \\( A' = \\{a'_1, ..., a'_{250}\\} \\) are constructed as \\( a_i = D^*x_i + n_i \\), for \\( i = 1, ..., 250 \\), and \\( a'_k = D'^*x'_k + n'_k \\), for \\( k = 1, ..., 250 \\), where \\( \\{x_i\\}_{i=1}^{250} \\), \\( \\{x'_k\\}_{i=1}^{250} \\), \\( \\{n'_k\\}_{k=1}^{250} \\) are coefficient vectors and \\( \\{n_i\\}_{k=1}^{250} \\) are random Gaussian noises.\n\nAs neither \\( A \\) nor \\( A' \\) includes all the elements of \\( \\tilde{D}^* \\), it is important to renew our dictionary by using the new dataset \\( A' \\) while maintaining the knowledge from the old dataset \\( A \\).\n\nIn our experiment, we initially solve the standard dictionary learning problem employing dataset \\( A \\), achieving the initial dictionary \\( \\hat{D} \\) and coefficient vectors \\( \\{\\hat{x}_i\\}_{i=1}^{250} \\). We define the lower-level objective as the reconstruction error on \\( A \\) using \\( \\{\\hat{x}_i\\}_{i=1}^{250} \\), and the upper-level objective as the error on new dataset \\( A' \\). We compare our algorithms with aR-IP-SeG and DBGD (stochastic version), measuring performance with the recovery rate of true basis vectors. Note that a basis vector \\( \\tilde{d}^*_i \\) in \\( \\tilde{D}^* \\) is considered as successfully recovered if there exists \\( \\tilde{d}_j \\) in \\( \\tilde{D} \\) such that \\( |\\langle \\tilde{d}^*_i, \\tilde{d}_j \\rangle| > 0.9 \\) (for more details of the experiment setup see Appendix F). In Figure 2(a), we observe SBCGF converges faster than any other method regarding the lower-level objective. While SBCGI has the second-best performance in terms of the lower-level gap, aR-IP-SeG and DBGD-sto perform poorly compared with SBCGI and SBCGF. In Figures 2(b) and (c), we see that SBCGI, SBCGF, and DBGD-sto achieve good results in terms of the upper-level objective and the recovery rate. However, aR-IP-SeG still performs poorly in terms of both criteria, which matches the theoretical results in Table 1.\n\nAcknowledgements\n\nThe research of J. Cao, R. Jiang and A. Mokhtari is supported in part by NSF Grants 2127697, 2019844, and 2112471, ARO Grant W911NF2110226, the Machine Learning Lab (MLL) at UT Austin, and the Wireless Networking and Communications Group (WNCG) Industrial Affiliates Program. The research of N. Abolfazli and E. Yazdandoost Hamedani is supported by NSF Grant 2127696.\n\nReferences\n\n- [ABTR21] Zeeshan Akhtar, Amrit Singh Bedi, Srujan Teja Thomdapu, and Ketan Rajawat. \"Projection-Free Stochastic Bi-level Optimization\". In: arXiv preprint arXiv:2110.11721 (2021) (page 3).\n- [BJQS15] Chenglong Bao, Hui Ji, Yuhui Quan, and Zuowei Shen. \"Dictionary learning for sparse coding: Algorithms and convergence analysis\". In: IEEE transactions on pattern analysis and machine intelligence 38.7 (2015), pp. 1356-1369 (page 4).\n- [BHTV18] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi. \"Meta-learning with differentiable closed-form solvers\". In: arXiv preprint arXiv:1805.08136 (2018) (page 2).\n- [BDG23] Aleksandr Beznosikov, David Dobre, and Gauthier Gidel. \"Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features\". In: arXiv preprint arXiv:2304.11737 (2023) (page 11).", "md": "Problem (5) on a synthetic dataset with a similar setup to [JAMH23]. We first construct the true dictionary \\( \\tilde{D}^* \\in \\mathbb{R}^{25 \\times 50} \\) comprising of 50 basis vectors in \\( \\mathbb{R}^{25} \\). All entries of these basis vectors are drawn from the standard Gaussian distribution and then normalized to have unit \\( \\ell_2 \\)-norm. We also generate two more dictionaries \\( D^* \\) and \\( D'^* \\) consisting of 40 and 20 basis vectors in \\( \\tilde{D}^* \\), respectively (thus they share at least 10 bases). These two datasets \\( A = \\{a_1, ..., a_{250}\\} \\) and \\( A' = \\{a'_1, ..., a'_{250}\\} \\) are constructed as \\( a_i = D^*x_i + n_i \\), for \\( i = 1, ..., 250 \\), and \\( a'_k = D'^*x'_k + n'_k \\), for \\( k = 1, ..., 250 \\), where \\( \\{x_i\\}_{i=1}^{250} \\), \\( \\{x'_k\\}_{i=1}^{250} \\), \\( \\{n'_k\\}_{k=1}^{250} \\) are coefficient vectors and \\( \\{n_i\\}_{k=1}^{250} \\) are random Gaussian noises.\n\nAs neither \\( A \\) nor \\( A' \\) includes all the elements of \\( \\tilde{D}^* \\), it is important to renew our dictionary by using the new dataset \\( A' \\) while maintaining the knowledge from the old dataset \\( A \\).\n\nIn our experiment, we initially solve the standard dictionary learning problem employing dataset \\( A \\), achieving the initial dictionary \\( \\hat{D} \\) and coefficient vectors \\( \\{\\hat{x}_i\\}_{i=1}^{250} \\). We define the lower-level objective as the reconstruction error on \\( A \\) using \\( \\{\\hat{x}_i\\}_{i=1}^{250} \\), and the upper-level objective as the error on new dataset \\( A' \\). We compare our algorithms with aR-IP-SeG and DBGD (stochastic version), measuring performance with the recovery rate of true basis vectors. Note that a basis vector \\( \\tilde{d}^*_i \\) in \\( \\tilde{D}^* \\) is considered as successfully recovered if there exists \\( \\tilde{d}_j \\) in \\( \\tilde{D} \\) such that \\( |\\langle \\tilde{d}^*_i, \\tilde{d}_j \\rangle| > 0.9 \\) (for more details of the experiment setup see Appendix F). In Figure 2(a), we observe SBCGF converges faster than any other method regarding the lower-level objective. While SBCGI has the second-best performance in terms of the lower-level gap, aR-IP-SeG and DBGD-sto perform poorly compared with SBCGI and SBCGF. In Figures 2(b) and (c), we see that SBCGI, SBCGF, and DBGD-sto achieve good results in terms of the upper-level objective and the recovery rate. However, aR-IP-SeG still performs poorly in terms of both criteria, which matches the theoretical results in Table 1.\n\nAcknowledgements\n\nThe research of J. Cao, R. Jiang and A. Mokhtari is supported in part by NSF Grants 2127697, 2019844, and 2112471, ARO Grant W911NF2110226, the Machine Learning Lab (MLL) at UT Austin, and the Wireless Networking and Communications Group (WNCG) Industrial Affiliates Program. The research of N. Abolfazli and E. Yazdandoost Hamedani is supported by NSF Grant 2127696.\n\nReferences\n\n- [ABTR21] Zeeshan Akhtar, Amrit Singh Bedi, Srujan Teja Thomdapu, and Ketan Rajawat. \"Projection-Free Stochastic Bi-level Optimization\". In: arXiv preprint arXiv:2110.11721 (2021) (page 3).\n- [BJQS15] Chenglong Bao, Hui Ji, Yuhui Quan, and Zuowei Shen. \"Dictionary learning for sparse coding: Algorithms and convergence analysis\". In: IEEE transactions on pattern analysis and machine intelligence 38.7 (2015), pp. 1356-1369 (page 4).\n- [BHTV18] Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi. \"Meta-learning with differentiable closed-form solvers\". In: arXiv preprint arXiv:1805.08136 (2018) (page 2).\n- [BDG23] Aleksandr Beznosikov, David Dobre, and Gauthier Gidel. \"Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features\". In: arXiv preprint arXiv:2304.11737 (2023) (page 11)."}]}, {"page": 14, "text": "[BMK20]    Zal\u00b4an Borsos, Mojmir Mutny, and Andreas Krause. \u201cCoresets via bilevel optimization\n           for continual learning and streaming\u201d. In: Advances in Neural Information Processing\n           Systems 33 (2020), pp. 14879\u201314890 (page 2).\n[BV07]     Stephen Boyd and Lieven Vandenberghe. \u201cLocalization and cutting-plane methods\u201d.\n           In: From Stanford EE 364b lecture notes (2007) (page 6).\n[BM73]     Jerome Bracken and James T McGill. \u201cMathematical programs with optimization\n           problems in the constraints\u201d. In: Operations research 21.1 (1973), pp. 37\u201344 (page 2).\n[CXZ23]    Lesi Chen, Jing Xu, and Jingzhao Zhang. \u201cOn Bilevel Optimization without Lower-\n           level Strong Convexity\u201d. In: arXiv preprint arXiv:2301.00712 (2023) (pages 3, 4).\n[CSY21]    Tianyi Chen, Yuejiao Sun, and Wotao Yin. \u201cTighter analysis of alternating stochastic\n           gradient method for stochastic nested problems\u201d. In: arXiv preprint arXiv:2106.13781\n           (2021) (page 3).\n[CMS07]    Beno\u02c6\u0131t Colson, Patrice Marcotte, and Gilles Savard. \u201cAn overview of bilevel opti-\n           mization\u201d. In: Annals of operations research 153 (2007), pp. 235\u2013256 (page 3).\n[CO19]     Ashok Cutkosky and Francesco Orabona. \u201cMomentum-based variance reduction in\n           non-convex sgd\u201d. In: Advances in neural information processing systems 32 (2019)\n           (page 7).\n[DDD10]    Stephen Dempe, Nguyen Dinh, and Joydeep Dutta. \u201cOptimality conditions for a\n           simple convex bilevel programming problem\u201d. In: Variational Analysis and General-\n           ized Differentiation in Optimization and Control: In Honor of Boris S. Mordukhovich\n           (2010), pp. 149\u2013161 (page 2).\n[DP20]     Joydeep Dutta and Tanushree Pandit. \u201cAlgorithms for simple bilevel programming\u201d.\n           In: Bilevel Optimization: Advances and Next Challenges (2020), pp. 253\u2013291 (page 2).\n[FLLZ18]   Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. \u201cSpider: Near-optimal\n           non-convex optimization via stochastic path-integrated differential estimator\u201d. In:\n           Advances in Neural Information Processing Systems 31 (2018) (pages 7, 9).\n[FFSGP18]  Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano\n           Pontil. \u201cBilevel programming for hyperparameter optimization and meta-learning\u201d.\n           In: International Conference on Machine Learning. PMLR. 2018, pp. 1568\u20131577\n           (page 2).\n[GW18]     Saeed Ghadimi and Mengdi Wang. \u201cApproximation methods for bilevel program-\n           ming\u201d. In: arXiv preprint arXiv:1802.02246 (2018) (page 3).\n[GL21]     Chengyue Gong and Xingchao Liu. \u201cBi-objective trade-off with dynamic barrier gra-\n           dient descent\u201d. In: NeurIPS 2021 (2021) (pages 2, 4, 11, 12, 17, 29, 30).\n[GB14]     Michael Grant and Stephen Boyd. CVX: Matlab software for disciplined convex pro-\n           gramming, version 2.1. 2014 (page 12).\n[GB08]     Michael C Grant and Stephen P Boyd. \u201cGraph implementations for nonsmooth con-\n           vex programs\u201d. In: Recent advances in learning and control. Springer. 2008, pp. 95\u2013\n           110 (page 12).\n[HWWY20]   Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. \u201cA two-timescale\n           framework for bilevel optimization: Complexity analysis and application to actor-\n           critic\u201d. In: arXiv preprint arXiv:2007.05170 (2020) (pages 2, 3).\n                                              14", "md": "# References\n\n# References\n\n|[BMK20]|Zal'an Borsos, Mojmir Mutny, and Andreas Krause. \"Coresets via bilevel optimization for continual learning and streaming\". In: Advances in Neural Information Processing Systems 33 (2020), pp. 14879\u201314890 (page 2).|\n|---|---|\n|[BV07]|Stephen Boyd and Lieven Vandenberghe. \"Localization and cutting-plane methods\". In: From Stanford EE 364b lecture notes (2007) (page 6).|\n|[BM73]|Jerome Bracken and James T McGill. \"Mathematical programs with optimization problems in the constraints\". In: Operations research 21.1 (1973), pp. 37\u201344 (page 2).|\n|[CXZ23]|Lesi Chen, Jing Xu, and Jingzhao Zhang. \"On Bilevel Optimization without Lower-level Strong Convexity\". In: arXiv preprint arXiv:2301.00712 (2023) (pages 3, 4).|\n|[CSY21]|Tianyi Chen, Yuejiao Sun, and Wotao Yin. \"Tighter analysis of alternating stochastic gradient method for stochastic nested problems\". In: arXiv preprint arXiv:2106.13781 (2021) (page 3).|\n|[CMS07]|Beno\u02c6\u0131t Colson, Patrice Marcotte, and Gilles Savard. \"An overview of bilevel optimization\". In: Annals of operations research 153 (2007), pp. 235\u2013256 (page 3).|\n|[CO19]|Ashok Cutkosky and Francesco Orabona. \"Momentum-based variance reduction in non-convex sgd\". In: Advances in neural information processing systems 32 (2019) (page 7).|\n|[DDD10]|Stephen Dempe, Nguyen Dinh, and Joydeep Dutta. \"Optimality conditions for a simple convex bilevel programming problem\". In: Variational Analysis and Generalized Differentiation in Optimization and Control: In Honor of Boris S. Mordukhovich (2010), pp. 149\u2013161 (page 2).|\n|[DP20]|Joydeep Dutta and Tanushree Pandit. \"Algorithms for simple bilevel programming\". In: Bilevel Optimization: Advances and Next Challenges (2020), pp. 253\u2013291 (page 2).|\n|[FLLZ18]|Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. \"Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator\". In: Advances in Neural Information Processing Systems 31 (2018) (pages 7, 9).|\n|[FFSGP18]|Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil. \"Bilevel programming for hyperparameter optimization and meta-learning\". In: International Conference on Machine Learning. PMLR. 2018, pp. 1568\u20131577 (page 2).|\n|[GW18]|Saeed Ghadimi and Mengdi Wang. \"Approximation methods for bilevel programming\". In: arXiv preprint arXiv:1802.02246 (2018) (page 3).|\n|[GL21]|Chengyue Gong and Xingchao Liu. \"Bi-objective trade-off with dynamic barrier gradient descent\". In: NeurIPS 2021 (2021) (pages 2, 4, 11, 12, 17, 29, 30).|\n|[GB14]|Michael Grant and Stephen Boyd. CVX: Matlab software for disciplined convex programming, version 2.1. 2014 (page 12).|\n|[GB08]|Michael C Grant and Stephen P Boyd. \"Graph implementations for nonsmooth convex programs\". In: Recent advances in learning and control. Springer. 2008, pp. 95\u2013110 (page 12).|\n|[HWWY20]|Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. \"A two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic\". In: arXiv preprint arXiv:2007.05170 (2020) (pages 2, 3).|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "table", "rows": [["[BMK20]", "Zal'an Borsos, Mojmir Mutny, and Andreas Krause. \"Coresets via bilevel optimization for continual learning and streaming\". In: Advances in Neural Information Processing Systems 33 (2020), pp. 14879\u201314890 (page 2)."], ["[BV07]", "Stephen Boyd and Lieven Vandenberghe. \"Localization and cutting-plane methods\". In: From Stanford EE 364b lecture notes (2007) (page 6)."], ["[BM73]", "Jerome Bracken and James T McGill. \"Mathematical programs with optimization problems in the constraints\". In: Operations research 21.1 (1973), pp. 37\u201344 (page 2)."], ["[CXZ23]", "Lesi Chen, Jing Xu, and Jingzhao Zhang. \"On Bilevel Optimization without Lower-level Strong Convexity\". In: arXiv preprint arXiv:2301.00712 (2023) (pages 3, 4)."], ["[CSY21]", "Tianyi Chen, Yuejiao Sun, and Wotao Yin. \"Tighter analysis of alternating stochastic gradient method for stochastic nested problems\". In: arXiv preprint arXiv:2106.13781 (2021) (page 3)."], ["[CMS07]", "Beno\u02c6\u0131t Colson, Patrice Marcotte, and Gilles Savard. \"An overview of bilevel optimization\". In: Annals of operations research 153 (2007), pp. 235\u2013256 (page 3)."], ["[CO19]", "Ashok Cutkosky and Francesco Orabona. \"Momentum-based variance reduction in non-convex sgd\". In: Advances in neural information processing systems 32 (2019) (page 7)."], ["[DDD10]", "Stephen Dempe, Nguyen Dinh, and Joydeep Dutta. \"Optimality conditions for a simple convex bilevel programming problem\". In: Variational Analysis and Generalized Differentiation in Optimization and Control: In Honor of Boris S. Mordukhovich (2010), pp. 149\u2013161 (page 2)."], ["[DP20]", "Joydeep Dutta and Tanushree Pandit. \"Algorithms for simple bilevel programming\". In: Bilevel Optimization: Advances and Next Challenges (2020), pp. 253\u2013291 (page 2)."], ["[FLLZ18]", "Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. \"Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator\". In: Advances in Neural Information Processing Systems 31 (2018) (pages 7, 9)."], ["[FFSGP18]", "Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil. \"Bilevel programming for hyperparameter optimization and meta-learning\". In: International Conference on Machine Learning. PMLR. 2018, pp. 1568\u20131577 (page 2)."], ["[GW18]", "Saeed Ghadimi and Mengdi Wang. \"Approximation methods for bilevel programming\". In: arXiv preprint arXiv:1802.02246 (2018) (page 3)."], ["[GL21]", "Chengyue Gong and Xingchao Liu. \"Bi-objective trade-off with dynamic barrier gradient descent\". In: NeurIPS 2021 (2021) (pages 2, 4, 11, 12, 17, 29, 30)."], ["[GB14]", "Michael Grant and Stephen Boyd. CVX: Matlab software for disciplined convex programming, version 2.1. 2014 (page 12)."], ["[GB08]", "Michael C Grant and Stephen P Boyd. \"Graph implementations for nonsmooth convex programs\". In: Recent advances in learning and control. Springer. 2008, pp. 95\u2013110 (page 12)."], ["[HWWY20]", "Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. \"A two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic\". In: arXiv preprint arXiv:2007.05170 (2020) (pages 2, 3)."]], "md": "|[BMK20]|Zal'an Borsos, Mojmir Mutny, and Andreas Krause. \"Coresets via bilevel optimization for continual learning and streaming\". In: Advances in Neural Information Processing Systems 33 (2020), pp. 14879\u201314890 (page 2).|\n|---|---|\n|[BV07]|Stephen Boyd and Lieven Vandenberghe. \"Localization and cutting-plane methods\". In: From Stanford EE 364b lecture notes (2007) (page 6).|\n|[BM73]|Jerome Bracken and James T McGill. \"Mathematical programs with optimization problems in the constraints\". In: Operations research 21.1 (1973), pp. 37\u201344 (page 2).|\n|[CXZ23]|Lesi Chen, Jing Xu, and Jingzhao Zhang. \"On Bilevel Optimization without Lower-level Strong Convexity\". In: arXiv preprint arXiv:2301.00712 (2023) (pages 3, 4).|\n|[CSY21]|Tianyi Chen, Yuejiao Sun, and Wotao Yin. \"Tighter analysis of alternating stochastic gradient method for stochastic nested problems\". In: arXiv preprint arXiv:2106.13781 (2021) (page 3).|\n|[CMS07]|Beno\u02c6\u0131t Colson, Patrice Marcotte, and Gilles Savard. \"An overview of bilevel optimization\". In: Annals of operations research 153 (2007), pp. 235\u2013256 (page 3).|\n|[CO19]|Ashok Cutkosky and Francesco Orabona. \"Momentum-based variance reduction in non-convex sgd\". In: Advances in neural information processing systems 32 (2019) (page 7).|\n|[DDD10]|Stephen Dempe, Nguyen Dinh, and Joydeep Dutta. \"Optimality conditions for a simple convex bilevel programming problem\". In: Variational Analysis and Generalized Differentiation in Optimization and Control: In Honor of Boris S. Mordukhovich (2010), pp. 149\u2013161 (page 2).|\n|[DP20]|Joydeep Dutta and Tanushree Pandit. \"Algorithms for simple bilevel programming\". In: Bilevel Optimization: Advances and Next Challenges (2020), pp. 253\u2013291 (page 2).|\n|[FLLZ18]|Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. \"Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator\". In: Advances in Neural Information Processing Systems 31 (2018) (pages 7, 9).|\n|[FFSGP18]|Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil. \"Bilevel programming for hyperparameter optimization and meta-learning\". In: International Conference on Machine Learning. PMLR. 2018, pp. 1568\u20131577 (page 2).|\n|[GW18]|Saeed Ghadimi and Mengdi Wang. \"Approximation methods for bilevel programming\". In: arXiv preprint arXiv:1802.02246 (2018) (page 3).|\n|[GL21]|Chengyue Gong and Xingchao Liu. \"Bi-objective trade-off with dynamic barrier gradient descent\". In: NeurIPS 2021 (2021) (pages 2, 4, 11, 12, 17, 29, 30).|\n|[GB14]|Michael Grant and Stephen Boyd. CVX: Matlab software for disciplined convex programming, version 2.1. 2014 (page 12).|\n|[GB08]|Michael C Grant and Stephen P Boyd. \"Graph implementations for nonsmooth convex programs\". In: Recent advances in learning and control. Springer. 2008, pp. 95\u2013110 (page 12).|\n|[HWWY20]|Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. \"A two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic\". In: arXiv preprint arXiv:2007.05170 (2020) (pages 2, 3).|", "isPerfectTable": true, "csv": "\"[BMK20]\",\"Zal'an Borsos, Mojmir Mutny, and Andreas Krause. \"\"Coresets via bilevel optimization for continual learning and streaming\"\". In: Advances in Neural Information Processing Systems 33 (2020), pp. 14879\u201314890 (page 2).\"\n\"[BV07]\",\"Stephen Boyd and Lieven Vandenberghe. \"\"Localization and cutting-plane methods\"\". In: From Stanford EE 364b lecture notes (2007) (page 6).\"\n\"[BM73]\",\"Jerome Bracken and James T McGill. \"\"Mathematical programs with optimization problems in the constraints\"\". In: Operations research 21.1 (1973), pp. 37\u201344 (page 2).\"\n\"[CXZ23]\",\"Lesi Chen, Jing Xu, and Jingzhao Zhang. \"\"On Bilevel Optimization without Lower-level Strong Convexity\"\". In: arXiv preprint arXiv:2301.00712 (2023) (pages 3, 4).\"\n\"[CSY21]\",\"Tianyi Chen, Yuejiao Sun, and Wotao Yin. \"\"Tighter analysis of alternating stochastic gradient method for stochastic nested problems\"\". In: arXiv preprint arXiv:2106.13781 (2021) (page 3).\"\n\"[CMS07]\",\"Beno\u02c6\u0131t Colson, Patrice Marcotte, and Gilles Savard. \"\"An overview of bilevel optimization\"\". In: Annals of operations research 153 (2007), pp. 235\u2013256 (page 3).\"\n\"[CO19]\",\"Ashok Cutkosky and Francesco Orabona. \"\"Momentum-based variance reduction in non-convex sgd\"\". In: Advances in neural information processing systems 32 (2019) (page 7).\"\n\"[DDD10]\",\"Stephen Dempe, Nguyen Dinh, and Joydeep Dutta. \"\"Optimality conditions for a simple convex bilevel programming problem\"\". In: Variational Analysis and Generalized Differentiation in Optimization and Control: In Honor of Boris S. Mordukhovich (2010), pp. 149\u2013161 (page 2).\"\n\"[DP20]\",\"Joydeep Dutta and Tanushree Pandit. \"\"Algorithms for simple bilevel programming\"\". In: Bilevel Optimization: Advances and Next Challenges (2020), pp. 253\u2013291 (page 2).\"\n\"[FLLZ18]\",\"Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. \"\"Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator\"\". In: Advances in Neural Information Processing Systems 31 (2018) (pages 7, 9).\"\n\"[FFSGP18]\",\"Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil. \"\"Bilevel programming for hyperparameter optimization and meta-learning\"\". In: International Conference on Machine Learning. PMLR. 2018, pp. 1568\u20131577 (page 2).\"\n\"[GW18]\",\"Saeed Ghadimi and Mengdi Wang. \"\"Approximation methods for bilevel programming\"\". In: arXiv preprint arXiv:1802.02246 (2018) (page 3).\"\n\"[GL21]\",\"Chengyue Gong and Xingchao Liu. \"\"Bi-objective trade-off with dynamic barrier gradient descent\"\". In: NeurIPS 2021 (2021) (pages 2, 4, 11, 12, 17, 29, 30).\"\n\"[GB14]\",\"Michael Grant and Stephen Boyd. CVX: Matlab software for disciplined convex programming, version 2.1. 2014 (page 12).\"\n\"[GB08]\",\"Michael C Grant and Stephen P Boyd. \"\"Graph implementations for nonsmooth convex programs\"\". In: Recent advances in learning and control. Springer. 2008, pp. 95\u2013110 (page 12).\"\n\"[HWWY20]\",\"Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. \"\"A two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic\"\". In: arXiv preprint arXiv:2007.05170 (2020) (pages 2, 3).\""}]}, {"page": 15, "text": "[Hua23]     Feihu Huang. \u201cOn momentum-based gradient methods for bilevel optimization with\n            nonconvex lower-level\u201d. In: arXiv preprint arXiv:2303.03944 (2023) (page 4).\n[Jag13]     Martin Jaggi. \u201cRevisiting Frank-Wolfe: Projection-free sparse convex optimization\u201d.\n            In: International Conference on Machine Learning. PMLR. 2013, pp. 427\u2013435 (pages 5,\n            8).\n[JY22]      Afrooz Jalilzadeh and Farzad Yousefian. \u201cStochastic Approximation for Estimating\n            the Price of Stability in Stochastic Nash Games\u201d. In: arXiv preprint arXiv:2203.01271\n            (2022) (pages 2, 10\u201312, 29).\n[JAMH23]    Ruichen Jiang, Nazanin Abolfazli, Aryan Mokhtari, and Erfan Yazdandoost Hamedani.\n           \u201cA conditional gradient-based method for simple bilevel optimization with convex\n            lower-level problem\u201d. In: International Conference on Artifi      cial Intelligence and Statis-\n            tics. PMLR. 2023, pp. 10305\u201310323 (pages 2, 3, 5, 6, 13, 18, 31).\n[JNGKJ19]   Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. \u201cA\n            short note on concentration inequalities for random vectors with subgaussian norm\u201d.\n            In: arXiv preprint arXiv:1902.03736 (2019) (page 29).\n[KY21]      Harshal D Kaushik and Farzad Yousefian. \u201cA method with convergence rates for\n            optimization problems with variational inequality constraints\u201d. In: SIAM Journal on\n            Optimization 31.3 (2021), pp. 2171\u20132198 (pages 2, 3).\n[Kha+21]    Prashant Khanduri, Siliang Zeng, Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and\n            Zhuoran Yang. \u201cA near-optimal algorithm for stochastic bilevel optimization via\n            double-momentum\u201d. In: Advances in neural information processing systems 34 (2021),\n            pp. 30271\u201330283 (page 3).\n[Kre+03]    Kenneth Kreutz-Delgado, Joseph F Murray, Bhaskar D Rao, Kjersti Engan, Te-Won\n            Lee, and Terrence J Sejnowski. \u201cDictionary learning algorithms for sparse represen-\n            tation\u201d. In: Neural computation 15.2 (2003), pp. 349\u2013396 (page 4).\n[Lac16]     Simon Lacoste-Julien. \u201cConvergence rate of frank-wolfe for non-convex objectives\u201d.\n            In: arXiv preprint arXiv:1607.00345 (2016) (pages 5, 8, 11).\n[LLZZ21]    Risheng Liu, Yaohua Liu, Shangzhi Zeng, and Jin Zhang. \u201cTowards gradient-based\n            bilevel optimization with non-convex followers and beyond\u201d. In: Advances in Neural\n            Information Processing Systems 34 (2021), pp. 8662\u20138675 (page 4).\n[MOJ18]     Aryan Mokhtari, Asuman Ozdaglar, and Ali Jadbabaie. \u201cEscaping saddle points in\n            constrained optimization\u201d. In: Advances in Neural Information Processing Systems\n            31 (2018) (page 11).\n[Pin94]     Iosif Pinelis. \u201cOptimum bounds for the distributions of martingales in Banach spaces\u201d.\n            In: The Annals of Probability (1994), pp. 1679\u20131706 (page 29).\n[RFKL19]    Aravind Rajeswaran, Chelsea Finn, Sham M Kakade, and Sergey Levine. \u201cMeta-\n            learning with implicit gradients\u201d. In: Advances in neural information processing sys-\n            tems 32 (2019) (page 2).\n[Roz+21]    Benedek Rozemberczki, Paul Scherer, Yixuan He, George Panagopoulos, Alexander\n            Riedel, Maria Astefanoaei, Oliver Kiss, Ferenc Beres, Guzm\u00b4          an L\u00b4opez, Nicolas Col-\n            lignon, et al. \u201cPytorch geometric temporal: Spatiotemporal signal processing with\n            neural machine learning models\u201d. In: Proceedings of the 30th ACM International\n           Conference on Information & Knowledge Management. 2021, pp. 4564\u20134573 (pages 4,\n            12, 30).\n                                                  15", "md": "# References\n\n# List of References\n\n## [Hua23]\n\nFeihu Huang. \"On momentum-based gradient methods for bilevel optimization with nonconvex lower-level\". In: arXiv preprint arXiv:2303.03944 (2023) (page 4).\n\n## [Jag13]\n\nMartin Jaggi. \"Revisiting Frank-Wolfe: Projection-free sparse convex optimization\". In: International Conference on Machine Learning. PMLR. 2013, pp. 427\u2013435 (pages 5, 8).\n\n## [JY22]\n\nAfrooz Jalilzadeh and Farzad Yousefian. \"Stochastic Approximation for Estimating the Price of Stability in Stochastic Nash Games\". In: arXiv preprint arXiv:2203.01271 (2022) (pages 2, 10\u201312, 29).\n\n## [JAMH23]\n\nRuichen Jiang, Nazanin Abolfazli, Aryan Mokhtari, and Erfan Yazdandoost Hamedani. \"A conditional gradient-based method for simple bilevel optimization with convex lower-level problem\". In: International Conference on Artificial Intelligence and Statistics. PMLR. 2023, pp. 10305\u201310323 (pages 2, 3, 5, 6, 13, 18, 31).\n\n## [JNGKJ19]\n\nChi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. \"A short note on concentration inequalities for random vectors with subgaussian norm\". In: arXiv preprint arXiv:1902.03736 (2019) (page 29).\n\n## [KY21]\n\nHarshal D Kaushik and Farzad Yousefian. \"A method with convergence rates for optimization problems with variational inequality constraints\". In: SIAM Journal on Optimization 31.3 (2021), pp. 2171\u20132198 (pages 2, 3).\n\n## [Kha+21]\n\nPrashant Khanduri, Siliang Zeng, Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. \"A near-optimal algorithm for stochastic bilevel optimization via double-momentum\". In: Advances in neural information processing systems 34 (2021), pp. 30271\u201330283 (page 3).\n\n## [Kre+03]\n\nKenneth Kreutz-Delgado, Joseph F Murray, Bhaskar D Rao, Kjersti Engan, Te-Won Lee, and Terrence J Sejnowski. \"Dictionary learning algorithms for sparse representation\". In: Neural computation 15.2 (2003), pp. 349\u2013396 (page 4).\n\n## [Lac16]\n\nSimon Lacoste-Julien. \"Convergence rate of frank-wolfe for non-convex objectives\". In: arXiv preprint arXiv:1607.00345 (2016) (pages 5, 8, 11).\n\n## [LLZZ21]\n\nRisheng Liu, Yaohua Liu, Shangzhi Zeng, and Jin Zhang. \"Towards gradient-based bilevel optimization with non-convex followers and beyond\". In: Advances in Neural Information Processing Systems 34 (2021), pp. 8662\u20138675 (page 4).\n\n## [MOJ18]\n\nAryan Mokhtari, Asuman Ozdaglar, and Ali Jadbabaie. \"Escaping saddle points in constrained optimization\". In: Advances in Neural Information Processing Systems 31 (2018) (page 11).\n\n## [Pin94]\n\nIosif Pinelis. \"Optimum bounds for the distributions of martingales in Banach spaces\". In: The Annals of Probability (1994), pp. 1679\u20131706 (page 29).\n\n## [RFKL19]\n\nAravind Rajeswaran, Chelsea Finn, Sham M Kakade, and Sergey Levine. \"Meta-learning with implicit gradients\". In: Advances in neural information processing systems 32 (2019) (page 2).\n\n## [Roz+21]\n\nBenedek Rozemberczki, Paul Scherer, Yixuan He, George Panagopoulos, Alexander Riedel, Maria Astefanoaei, Oliver Kiss, Ferenc Beres, Guzm\u00e1n L\u00f3pez, Nicolas Collignon, et al. \"Pytorch geometric temporal: Spatiotemporal signal processing with neural machine learning models\". In: Proceedings of the 30th ACM International Conference on Information & Knowledge Management. 2021, pp. 4564\u20134573 (pages 4, 12, 30).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 1, "value": "List of References", "md": "# List of References"}, {"type": "heading", "lvl": 2, "value": "[Hua23]", "md": "## [Hua23]"}, {"type": "text", "value": "Feihu Huang. \"On momentum-based gradient methods for bilevel optimization with nonconvex lower-level\". In: arXiv preprint arXiv:2303.03944 (2023) (page 4).", "md": "Feihu Huang. \"On momentum-based gradient methods for bilevel optimization with nonconvex lower-level\". In: arXiv preprint arXiv:2303.03944 (2023) (page 4)."}, {"type": "heading", "lvl": 2, "value": "[Jag13]", "md": "## [Jag13]"}, {"type": "text", "value": "Martin Jaggi. \"Revisiting Frank-Wolfe: Projection-free sparse convex optimization\". In: International Conference on Machine Learning. PMLR. 2013, pp. 427\u2013435 (pages 5, 8).", "md": "Martin Jaggi. \"Revisiting Frank-Wolfe: Projection-free sparse convex optimization\". In: International Conference on Machine Learning. PMLR. 2013, pp. 427\u2013435 (pages 5, 8)."}, {"type": "heading", "lvl": 2, "value": "[JY22]", "md": "## [JY22]"}, {"type": "text", "value": "Afrooz Jalilzadeh and Farzad Yousefian. \"Stochastic Approximation for Estimating the Price of Stability in Stochastic Nash Games\". In: arXiv preprint arXiv:2203.01271 (2022) (pages 2, 10\u201312, 29).", "md": "Afrooz Jalilzadeh and Farzad Yousefian. \"Stochastic Approximation for Estimating the Price of Stability in Stochastic Nash Games\". In: arXiv preprint arXiv:2203.01271 (2022) (pages 2, 10\u201312, 29)."}, {"type": "heading", "lvl": 2, "value": "[JAMH23]", "md": "## [JAMH23]"}, {"type": "text", "value": "Ruichen Jiang, Nazanin Abolfazli, Aryan Mokhtari, and Erfan Yazdandoost Hamedani. \"A conditional gradient-based method for simple bilevel optimization with convex lower-level problem\". In: International Conference on Artificial Intelligence and Statistics. PMLR. 2023, pp. 10305\u201310323 (pages 2, 3, 5, 6, 13, 18, 31).", "md": "Ruichen Jiang, Nazanin Abolfazli, Aryan Mokhtari, and Erfan Yazdandoost Hamedani. \"A conditional gradient-based method for simple bilevel optimization with convex lower-level problem\". In: International Conference on Artificial Intelligence and Statistics. PMLR. 2023, pp. 10305\u201310323 (pages 2, 3, 5, 6, 13, 18, 31)."}, {"type": "heading", "lvl": 2, "value": "[JNGKJ19]", "md": "## [JNGKJ19]"}, {"type": "text", "value": "Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. \"A short note on concentration inequalities for random vectors with subgaussian norm\". In: arXiv preprint arXiv:1902.03736 (2019) (page 29).", "md": "Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. \"A short note on concentration inequalities for random vectors with subgaussian norm\". In: arXiv preprint arXiv:1902.03736 (2019) (page 29)."}, {"type": "heading", "lvl": 2, "value": "[KY21]", "md": "## [KY21]"}, {"type": "text", "value": "Harshal D Kaushik and Farzad Yousefian. \"A method with convergence rates for optimization problems with variational inequality constraints\". In: SIAM Journal on Optimization 31.3 (2021), pp. 2171\u20132198 (pages 2, 3).", "md": "Harshal D Kaushik and Farzad Yousefian. \"A method with convergence rates for optimization problems with variational inequality constraints\". In: SIAM Journal on Optimization 31.3 (2021), pp. 2171\u20132198 (pages 2, 3)."}, {"type": "heading", "lvl": 2, "value": "[Kha+21]", "md": "## [Kha+21]"}, {"type": "text", "value": "Prashant Khanduri, Siliang Zeng, Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. \"A near-optimal algorithm for stochastic bilevel optimization via double-momentum\". In: Advances in neural information processing systems 34 (2021), pp. 30271\u201330283 (page 3).", "md": "Prashant Khanduri, Siliang Zeng, Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. \"A near-optimal algorithm for stochastic bilevel optimization via double-momentum\". In: Advances in neural information processing systems 34 (2021), pp. 30271\u201330283 (page 3)."}, {"type": "heading", "lvl": 2, "value": "[Kre+03]", "md": "## [Kre+03]"}, {"type": "text", "value": "Kenneth Kreutz-Delgado, Joseph F Murray, Bhaskar D Rao, Kjersti Engan, Te-Won Lee, and Terrence J Sejnowski. \"Dictionary learning algorithms for sparse representation\". In: Neural computation 15.2 (2003), pp. 349\u2013396 (page 4).", "md": "Kenneth Kreutz-Delgado, Joseph F Murray, Bhaskar D Rao, Kjersti Engan, Te-Won Lee, and Terrence J Sejnowski. \"Dictionary learning algorithms for sparse representation\". In: Neural computation 15.2 (2003), pp. 349\u2013396 (page 4)."}, {"type": "heading", "lvl": 2, "value": "[Lac16]", "md": "## [Lac16]"}, {"type": "text", "value": "Simon Lacoste-Julien. \"Convergence rate of frank-wolfe for non-convex objectives\". In: arXiv preprint arXiv:1607.00345 (2016) (pages 5, 8, 11).", "md": "Simon Lacoste-Julien. \"Convergence rate of frank-wolfe for non-convex objectives\". In: arXiv preprint arXiv:1607.00345 (2016) (pages 5, 8, 11)."}, {"type": "heading", "lvl": 2, "value": "[LLZZ21]", "md": "## [LLZZ21]"}, {"type": "text", "value": "Risheng Liu, Yaohua Liu, Shangzhi Zeng, and Jin Zhang. \"Towards gradient-based bilevel optimization with non-convex followers and beyond\". In: Advances in Neural Information Processing Systems 34 (2021), pp. 8662\u20138675 (page 4).", "md": "Risheng Liu, Yaohua Liu, Shangzhi Zeng, and Jin Zhang. \"Towards gradient-based bilevel optimization with non-convex followers and beyond\". In: Advances in Neural Information Processing Systems 34 (2021), pp. 8662\u20138675 (page 4)."}, {"type": "heading", "lvl": 2, "value": "[MOJ18]", "md": "## [MOJ18]"}, {"type": "text", "value": "Aryan Mokhtari, Asuman Ozdaglar, and Ali Jadbabaie. \"Escaping saddle points in constrained optimization\". In: Advances in Neural Information Processing Systems 31 (2018) (page 11).", "md": "Aryan Mokhtari, Asuman Ozdaglar, and Ali Jadbabaie. \"Escaping saddle points in constrained optimization\". In: Advances in Neural Information Processing Systems 31 (2018) (page 11)."}, {"type": "heading", "lvl": 2, "value": "[Pin94]", "md": "## [Pin94]"}, {"type": "text", "value": "Iosif Pinelis. \"Optimum bounds for the distributions of martingales in Banach spaces\". In: The Annals of Probability (1994), pp. 1679\u20131706 (page 29).", "md": "Iosif Pinelis. \"Optimum bounds for the distributions of martingales in Banach spaces\". In: The Annals of Probability (1994), pp. 1679\u20131706 (page 29)."}, {"type": "heading", "lvl": 2, "value": "[RFKL19]", "md": "## [RFKL19]"}, {"type": "text", "value": "Aravind Rajeswaran, Chelsea Finn, Sham M Kakade, and Sergey Levine. \"Meta-learning with implicit gradients\". In: Advances in neural information processing systems 32 (2019) (page 2).", "md": "Aravind Rajeswaran, Chelsea Finn, Sham M Kakade, and Sergey Levine. \"Meta-learning with implicit gradients\". In: Advances in neural information processing systems 32 (2019) (page 2)."}, {"type": "heading", "lvl": 2, "value": "[Roz+21]", "md": "## [Roz+21]"}, {"type": "text", "value": "Benedek Rozemberczki, Paul Scherer, Yixuan He, George Panagopoulos, Alexander Riedel, Maria Astefanoaei, Oliver Kiss, Ferenc Beres, Guzm\u00e1n L\u00f3pez, Nicolas Collignon, et al. \"Pytorch geometric temporal: Spatiotemporal signal processing with neural machine learning models\". In: Proceedings of the 30th ACM International Conference on Information & Knowledge Management. 2021, pp. 4564\u20134573 (pages 4, 12, 30).", "md": "Benedek Rozemberczki, Paul Scherer, Yixuan He, George Panagopoulos, Alexander Riedel, Maria Astefanoaei, Oliver Kiss, Ferenc Beres, Guzm\u00e1n L\u00f3pez, Nicolas Collignon, et al. \"Pytorch geometric temporal: Spatiotemporal signal processing with neural machine learning models\". In: Proceedings of the 30th ACM International Conference on Information & Knowledge Management. 2021, pp. 4564\u20134573 (pages 4, 12, 30)."}]}, {"page": 16, "text": "[SS17]      Shoham Sabach and Shimrit Shtern. \u201cA first order method for solving convex bilevel\n            optimization problems\u201d. In: SIAM Journal on Optimization 27.2 (2017), pp. 640\u2013660\n           (pages 2, 3).\n[SCHB19]    Amirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron Boots. \u201cTruncated\n            back-propagation for bilevel optimization\u201d. In: The 22nd International Conference\n           on Artificial Intelligence and Statistics. PMLR. 2019, pp. 1723\u20131732 (page 2).\n[SVZ21]     Yekini Shehu, Phan Tu Vuong, and Alain Zemkoho. \u201cAn inertial extrapolation method\n            for convex simple bilevel optimization\u201d. In: Optimization Methods and Software 36.1\n           (2021), pp. 1\u201319 (page 2).\n[SC23]      Han Shen and Tianyi Chen. \u201cOn penalty-based bilevel gradient descent method\u201d. In:\n           arXiv preprint arXiv:2302.05185 (2023) (page 4).\n[SJGL22]    Daouda Sow, Kaiyi Ji, Ziwei Guan, and Yingbin Liang. \u201cA Primal-Dual Approach to\n            Bilevel Optimization with Multiple Inner Minima\u201d. In: arXiv preprint arXiv:2203.01123\n           (2022) (page 4).\n[Ver18]     Roman Vershynin. High-dimensional probability: An introduction with applications\n           in data science. Vol. 47. Cambridge university press, 2018 (page 20).\n[XSZWQ20]   Jiahao Xie, Zebang Shen, Chao Zhang, Boyu Wang, and Hui Qian. \u201cEfficient projection-\n            free online methods with stochastic recursive gradient\u201d. In: Proceedings of the AAAI\n           Conference on Artifi  cial Intelligence. Vol. 34. 2020, pp. 6446\u20136453 (pages 9, 29, 33).\n[YBD09]     Mehrdad Yaghoobi, Thomas Blumensath, and Mike E Davies. \u201cDictionary learning\n            for sparse approximations with the majorization method\u201d. In: IEEE Transactions on\n           Signal Processing 57.6 (2009), pp. 2178\u20132191 (page 4).\n[YJL21]     Junjie Yang, Kaiyi Ji, and Yingbin Liang. \u201cProvably faster algorithms for bilevel\n            optimization\u201d. In: Advances in Neural Information Processing Systems 34 (2021),\n            pp. 13670\u201313682 (page 3).\n[YSC19]     Alp Yurtsever, Suvrit Sra, and Volkan Cevher. \u201cConditional gradient methods via\n            stochastic path-integrated differential estimator\u201d. In: International Conference on\n           Machine Learning. PMLR. 2019, pp. 7282\u20137291 (pages 11, 30, 33).\n[Zha+20]    Haifeng Zhang, Weizhe Chen, Zeren Huang, Minne Li, Yaodong Yang, Weinan Zhang,\n            and Jun Wang. \u201cBi-level actor-critic for multi-agent coordination\u201d. In: Proceedings of\n           the AAAI Conference on Artifi    cial Intelligence. Vol. 34. 2020, pp. 7325\u20137332 (page 2).\n[Zha05]     Tong Zhang. \u201cLearning bounds for kernel regression using effective data dimension-\n            ality\u201d. In: Neural Computation 17.9 (2005), pp. 2077\u20132098 (page 29).\n                                               16", "md": "# Bilevel Optimization References\n\n# Bilevel Optimization References\n\n|Reference|Authors|Title|Journal/Conference|Year|Pages|\n|---|---|---|---|---|---|\n|SS17|Shoham Sabach and Shimrit Shtern|A first order method for solving convex bilevel optimization problems|SIAM Journal on Optimization|2017|640-660|\n|SCHB19|Amirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron Boots|Truncated back-propagation for bilevel optimization|The 22nd International Conference on Artificial Intelligence and Statistics|2019|1723-1732|\n|SVZ21|Yekini Shehu, Phan Tu Vuong, and Alain Zemkoho|An inertial extrapolation method for convex simple bilevel optimization|Optimization Methods and Software|2021|1-19|\n|SC23|Han Shen and Tianyi Chen|On penalty-based bilevel gradient descent method|arXiv preprint arXiv:2302.05185|2023|Page 4|\n|SJGL22|Daouda Sow, Kaiyi Ji, Ziwei Guan, and Yingbin Liang|A Primal-Dual Approach to Bilevel Optimization with Multiple Inner Minima|arXiv preprint arXiv:2203.01123|2022|Page 4|\n|Ver18|Roman Vershynin|High-dimensional probability: An introduction with applications in data science|Cambridge university press|2018|Page 20|\n|XSZWQ20|Jiahao Xie, Zebang Shen, Chao Zhang, Boyu Wang, and Hui Qian|Efficient projection-free online methods with stochastic recursive gradient|Proceedings of the AAAI Conference on Artificial Intelligence|2020|6446-6453|\n|YBD09|Mehrdad Yaghoobi, Thomas Blumensath, and Mike E Davies|Dictionary learning for sparse approximations with the majorization method|IEEE Transactions on Signal Processing|2009|2178-2191|\n|YJL21|Junjie Yang, Kaiyi Ji, and Yingbin Liang|Provably faster algorithms for bilevel optimization|Advances in Neural Information Processing Systems 34|2021|13670-13682|\n|YSC19|Alp Yurtsever, Suvrit Sra, and Volkan Cevher|Conditional gradient methods via stochastic path-integrated differential estimator|International Conference on Machine Learning|2019|7282-7291|\n|Zha+20|Haifeng Zhang, Weizhe Chen, Zeren Huang, Minne Li, Yaodong Yang, Weinan Zhang, and Jun Wang|Bi-level actor-critic for multi-agent coordination|Proceedings of the AAAI Conference on Artificial Intelligence|2020|7325-7332|\n|Zha05|Tong Zhang|Learning bounds for kernel regression using effective data dimensionality|Neural Computation|2005|2077-2098|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Bilevel Optimization References", "md": "# Bilevel Optimization References"}, {"type": "heading", "lvl": 1, "value": "Bilevel Optimization References", "md": "# Bilevel Optimization References"}, {"type": "table", "rows": [["Reference", "Authors", "Title", "Journal/Conference", "Year", "Pages"], ["SS17", "Shoham Sabach and Shimrit Shtern", "A first order method for solving convex bilevel optimization problems", "SIAM Journal on Optimization", "2017", "640-660"], ["SCHB19", "Amirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron Boots", "Truncated back-propagation for bilevel optimization", "The 22nd International Conference on Artificial Intelligence and Statistics", "2019", "1723-1732"], ["SVZ21", "Yekini Shehu, Phan Tu Vuong, and Alain Zemkoho", "An inertial extrapolation method for convex simple bilevel optimization", "Optimization Methods and Software", "2021", "1-19"], ["SC23", "Han Shen and Tianyi Chen", "On penalty-based bilevel gradient descent method", "arXiv preprint arXiv:2302.05185", "2023", "Page 4"], ["SJGL22", "Daouda Sow, Kaiyi Ji, Ziwei Guan, and Yingbin Liang", "A Primal-Dual Approach to Bilevel Optimization with Multiple Inner Minima", "arXiv preprint arXiv:2203.01123", "2022", "Page 4"], ["Ver18", "Roman Vershynin", "High-dimensional probability: An introduction with applications in data science", "Cambridge university press", "2018", "Page 20"], ["XSZWQ20", "Jiahao Xie, Zebang Shen, Chao Zhang, Boyu Wang, and Hui Qian", "Efficient projection-free online methods with stochastic recursive gradient", "Proceedings of the AAAI Conference on Artificial Intelligence", "2020", "6446-6453"], ["YBD09", "Mehrdad Yaghoobi, Thomas Blumensath, and Mike E Davies", "Dictionary learning for sparse approximations with the majorization method", "IEEE Transactions on Signal Processing", "2009", "2178-2191"], ["YJL21", "Junjie Yang, Kaiyi Ji, and Yingbin Liang", "Provably faster algorithms for bilevel optimization", "Advances in Neural Information Processing Systems 34", "2021", "13670-13682"], ["YSC19", "Alp Yurtsever, Suvrit Sra, and Volkan Cevher", "Conditional gradient methods via stochastic path-integrated differential estimator", "International Conference on Machine Learning", "2019", "7282-7291"], ["Zha+20", "Haifeng Zhang, Weizhe Chen, Zeren Huang, Minne Li, Yaodong Yang, Weinan Zhang, and Jun Wang", "Bi-level actor-critic for multi-agent coordination", "Proceedings of the AAAI Conference on Artificial Intelligence", "2020", "7325-7332"], ["Zha05", "Tong Zhang", "Learning bounds for kernel regression using effective data dimensionality", "Neural Computation", "2005", "2077-2098"]], "md": "|Reference|Authors|Title|Journal/Conference|Year|Pages|\n|---|---|---|---|---|---|\n|SS17|Shoham Sabach and Shimrit Shtern|A first order method for solving convex bilevel optimization problems|SIAM Journal on Optimization|2017|640-660|\n|SCHB19|Amirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron Boots|Truncated back-propagation for bilevel optimization|The 22nd International Conference on Artificial Intelligence and Statistics|2019|1723-1732|\n|SVZ21|Yekini Shehu, Phan Tu Vuong, and Alain Zemkoho|An inertial extrapolation method for convex simple bilevel optimization|Optimization Methods and Software|2021|1-19|\n|SC23|Han Shen and Tianyi Chen|On penalty-based bilevel gradient descent method|arXiv preprint arXiv:2302.05185|2023|Page 4|\n|SJGL22|Daouda Sow, Kaiyi Ji, Ziwei Guan, and Yingbin Liang|A Primal-Dual Approach to Bilevel Optimization with Multiple Inner Minima|arXiv preprint arXiv:2203.01123|2022|Page 4|\n|Ver18|Roman Vershynin|High-dimensional probability: An introduction with applications in data science|Cambridge university press|2018|Page 20|\n|XSZWQ20|Jiahao Xie, Zebang Shen, Chao Zhang, Boyu Wang, and Hui Qian|Efficient projection-free online methods with stochastic recursive gradient|Proceedings of the AAAI Conference on Artificial Intelligence|2020|6446-6453|\n|YBD09|Mehrdad Yaghoobi, Thomas Blumensath, and Mike E Davies|Dictionary learning for sparse approximations with the majorization method|IEEE Transactions on Signal Processing|2009|2178-2191|\n|YJL21|Junjie Yang, Kaiyi Ji, and Yingbin Liang|Provably faster algorithms for bilevel optimization|Advances in Neural Information Processing Systems 34|2021|13670-13682|\n|YSC19|Alp Yurtsever, Suvrit Sra, and Volkan Cevher|Conditional gradient methods via stochastic path-integrated differential estimator|International Conference on Machine Learning|2019|7282-7291|\n|Zha+20|Haifeng Zhang, Weizhe Chen, Zeren Huang, Minne Li, Yaodong Yang, Weinan Zhang, and Jun Wang|Bi-level actor-critic for multi-agent coordination|Proceedings of the AAAI Conference on Artificial Intelligence|2020|7325-7332|\n|Zha05|Tong Zhang|Learning bounds for kernel regression using effective data dimensionality|Neural Computation|2005|2077-2098|", "isPerfectTable": true, "csv": "\"Reference\",\"Authors\",\"Title\",\"Journal/Conference\",\"Year\",\"Pages\"\n\"SS17\",\"Shoham Sabach and Shimrit Shtern\",\"A first order method for solving convex bilevel optimization problems\",\"SIAM Journal on Optimization\",\"2017\",\"640-660\"\n\"SCHB19\",\"Amirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron Boots\",\"Truncated back-propagation for bilevel optimization\",\"The 22nd International Conference on Artificial Intelligence and Statistics\",\"2019\",\"1723-1732\"\n\"SVZ21\",\"Yekini Shehu, Phan Tu Vuong, and Alain Zemkoho\",\"An inertial extrapolation method for convex simple bilevel optimization\",\"Optimization Methods and Software\",\"2021\",\"1-19\"\n\"SC23\",\"Han Shen and Tianyi Chen\",\"On penalty-based bilevel gradient descent method\",\"arXiv preprint arXiv:2302.05185\",\"2023\",\"Page 4\"\n\"SJGL22\",\"Daouda Sow, Kaiyi Ji, Ziwei Guan, and Yingbin Liang\",\"A Primal-Dual Approach to Bilevel Optimization with Multiple Inner Minima\",\"arXiv preprint arXiv:2203.01123\",\"2022\",\"Page 4\"\n\"Ver18\",\"Roman Vershynin\",\"High-dimensional probability: An introduction with applications in data science\",\"Cambridge university press\",\"2018\",\"Page 20\"\n\"XSZWQ20\",\"Jiahao Xie, Zebang Shen, Chao Zhang, Boyu Wang, and Hui Qian\",\"Efficient projection-free online methods with stochastic recursive gradient\",\"Proceedings of the AAAI Conference on Artificial Intelligence\",\"2020\",\"6446-6453\"\n\"YBD09\",\"Mehrdad Yaghoobi, Thomas Blumensath, and Mike E Davies\",\"Dictionary learning for sparse approximations with the majorization method\",\"IEEE Transactions on Signal Processing\",\"2009\",\"2178-2191\"\n\"YJL21\",\"Junjie Yang, Kaiyi Ji, and Yingbin Liang\",\"Provably faster algorithms for bilevel optimization\",\"Advances in Neural Information Processing Systems 34\",\"2021\",\"13670-13682\"\n\"YSC19\",\"Alp Yurtsever, Suvrit Sra, and Volkan Cevher\",\"Conditional gradient methods via stochastic path-integrated differential estimator\",\"International Conference on Machine Learning\",\"2019\",\"7282-7291\"\n\"Zha+20\",\"Haifeng Zhang, Weizhe Chen, Zeren Huang, Minne Li, Yaodong Yang, Weinan Zhang, and Jun Wang\",\"Bi-level actor-critic for multi-agent coordination\",\"Proceedings of the AAAI Conference on Artificial Intelligence\",\"2020\",\"7325-7332\"\n\"Zha05\",\"Tong Zhang\",\"Learning bounds for kernel regression using effective data dimensionality\",\"Neural Computation\",\"2005\",\"2077-2098\""}]}, {"page": 17, "text": " Appendix\n A        Additional Motivating Examples\nThe bilevel optimization problem in (1) provides a versatile framework that covers a broad class of\n optimization problems. In addition to the motivating examples provided in the main body of the\n paper, here we also provide a generic example of stochastic convex constrained optimization that\n can be formulated as (1). We further present a more general form of the examples covered in the\n main body.\nGeneric Example: Stochastic convex optimization with many conic constraints. Consider the fol-\n lowing convex optimization problem\n                                            min        f(x, \u03b8)]            s.t.    h(x, \u03be) \u2208       \u2212K, \u2200\u03be \u2208         \u2126,\n                                           x\u2208Rd E[ \u02dc\nwhere K \u2286           Rd is a closed convex cone. This problem can be formulated as a special case of (1)\n by letting \u02dc     g(x, \u03be) = 1     2d2 \u2212K(h(x, \u03be)) where d\u2212K(\u00b7) \u225c                     \u2225  \u00b7 \u2212P\u2212K(\u00b7)\u2225         denotes the distance function and\n P\u2212K(\u00b7) denotes the projection map.                              Our proposed framework provides an efficient method for\n solving this class of problems when the projections onto K can be computed efficiently, while the\n projection onto the preimage h\u22121(\u2212K, \u03be) is not practical, e.g., when K is the positive semidefinite\n cone, computing a projection onto the preimage set requires solving a nonlinear SDP.\n A.1        Lexicographic optimization\nExample 1 (over-parameterized regression) can be generalized as a broader class of problem, which\n is known as lexicographic optimization [GL21] and uses the secondary loss to improve generalization.\nThe problem can be formulated as the following stochastic simple bilevel optimization problem,\n                                      min                s.t.     \u03b2 \u2208    arg min      \u2113tr(\u03b8) = EDtr[\u2113(y, \u02c6         y\u03b8(x))]                                   (17)\n                                     \u03b2\u2208Rd L(\u03b2)                               \u03b8\u2208Z\n In general, the lower-level problem could have multiple optimal solutions and be very sensitive to\n small perturbations. To tackle the issue, we use a secondary criterion L(\u00b7) to select some of the\n optimal solutions with our desired properties. For instance, we can find the optimal solutions with\n minimal \u21132-norm by letting L(\u03b2) = \u2225\u03b2\u22252, which is also known as Lexicographic \u21132 Regularization.\n A.2        Lifelong learning\nExample 2 (dictionary learning) is an instance of a popular framework known as lifelong learning,\nwhich can be formulated as follows,\n             min     1    n\u2032  \u2113     x\u2032i, \u03b2    , y\u2032i       s.t.                      \u2113(\u27e8xi, \u03b2\u27e9, yi) \u2264                        \u2113(\u27e8xi, \u03b2(t\u22121)\u27e9, yi)              (18)\n               \u03b2    n\u2032   i=1                                          (x i,yi)\u2208M                             (xi,yi)\u2208M\n In this problem, the objective is the training loss on the current tasks Dt = {(x\u2032                                                     i, y\u2032i)}n\u2032\n                                                                                                                                                 i=1. While\n the constraint enforces that the model parameterized by \u03b2 performs no worse than the previous\n one on the episodic memory M (i.e., data samples from all the past tasks).\n                                                                                17", "md": "# Appendix\n\n## Additional Motivating Examples\n\nThe bilevel optimization problem in (1) provides a versatile framework that covers a broad class of optimization problems. In addition to the motivating examples provided in the main body of the paper, here we also provide a generic example of stochastic convex constrained optimization that can be formulated as (1). We further present a more general form of the examples covered in the main body.\n\nGeneric Example: Stochastic convex optimization with many conic constraints. Consider the following convex optimization problem\n\n$$\n\\begin{aligned}\n&\\min f(x, \\theta) \\\\\n&s.t. \\quad h(x, \\xi) \\in -K, \\forall \\xi \\in \\Omega,\n\\end{aligned}\n$$\nwhere $K \\subseteq \\mathbb{R}^d$ is a closed convex cone. This problem can be formulated as a special case of (1) by letting $\\tilde{g}(x, \\xi) = \\frac{1}{2}d^2 - K(h(x, \\xi))$ where $d-K(\\cdot) \\triangleq \\|\\cdot - P-K(\\cdot)\\|$ denotes the distance function and $P-K(\\cdot)$ denotes the projection map. Our proposed framework provides an efficient method for solving this class of problems when the projections onto $K$ can be computed efficiently, while the projection onto the preimage $h^{-1}(-K, \\xi)$ is not practical, e.g., when $K$ is the positive semidefinite cone, computing a projection onto the preimage set requires solving a nonlinear SDP.\n\n### Lexicographic optimization\n\nExample 1 (over-parameterized regression) can be generalized as a broader class of problem, which is known as lexicographic optimization [GL21] and uses the secondary loss to improve generalization. The problem can be formulated as the following stochastic simple bilevel optimization problem,\n\n$$\n\\begin{aligned}\n&\\min_{\\beta \\in \\mathbb{R}^d} L(\\beta) \\\\\n&s.t. \\quad \\beta \\in \\arg\\min_{\\theta \\in Z} \\mathcal{L}_{tr}(\\theta) = E_{D_{tr}}[\\mathcal{L}(y, \\hat{y}_{\\theta}(x))] \\quad (17)\n\\end{aligned}\n$$\nIn general, the lower-level problem could have multiple optimal solutions and be very sensitive to small perturbations. To tackle the issue, we use a secondary criterion $L(\\cdot)$ to select some of the optimal solutions with our desired properties. For instance, we can find the optimal solutions with minimal $\\ell_2$-norm by letting $L(\\beta) = \\|\\beta\\|_2$, which is also known as Lexicographic $\\ell_2$ Regularization.\n\n### Lifelong learning\n\nExample 2 (dictionary learning) is an instance of a popular framework known as lifelong learning, which can be formulated as follows,\n\n$$\n\\begin{aligned}\n&\\min_{\\beta} \\frac{1}{n'} \\sum_{i=1}^{n'} \\ell(x'_i, \\beta, y'_i) \\\\\n&s.t. \\quad \\ell(\\langle x_i, \\beta \\rangle, y_i) \\leq \\ell(\\langle x_i, \\beta^{(t-1)} \\rangle, y_i) \\quad (18)\n\\end{aligned}\n$$\nIn this problem, the objective is the training loss on the current tasks $D_t = \\{(x'_i, y'_i)\\}_{i=1}^{n'}$. While the constraint enforces that the model parameterized by $\\beta$ performs no worse than the previous one on the episodic memory $M$ (i.e., data samples from all the past tasks).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Appendix", "md": "# Appendix"}, {"type": "heading", "lvl": 2, "value": "Additional Motivating Examples", "md": "## Additional Motivating Examples"}, {"type": "text", "value": "The bilevel optimization problem in (1) provides a versatile framework that covers a broad class of optimization problems. In addition to the motivating examples provided in the main body of the paper, here we also provide a generic example of stochastic convex constrained optimization that can be formulated as (1). We further present a more general form of the examples covered in the main body.\n\nGeneric Example: Stochastic convex optimization with many conic constraints. Consider the following convex optimization problem\n\n$$\n\\begin{aligned}\n&\\min f(x, \\theta) \\\\\n&s.t. \\quad h(x, \\xi) \\in -K, \\forall \\xi \\in \\Omega,\n\\end{aligned}\n$$\nwhere $K \\subseteq \\mathbb{R}^d$ is a closed convex cone. This problem can be formulated as a special case of (1) by letting $\\tilde{g}(x, \\xi) = \\frac{1}{2}d^2 - K(h(x, \\xi))$ where $d-K(\\cdot) \\triangleq \\|\\cdot - P-K(\\cdot)\\|$ denotes the distance function and $P-K(\\cdot)$ denotes the projection map. Our proposed framework provides an efficient method for solving this class of problems when the projections onto $K$ can be computed efficiently, while the projection onto the preimage $h^{-1}(-K, \\xi)$ is not practical, e.g., when $K$ is the positive semidefinite cone, computing a projection onto the preimage set requires solving a nonlinear SDP.", "md": "The bilevel optimization problem in (1) provides a versatile framework that covers a broad class of optimization problems. In addition to the motivating examples provided in the main body of the paper, here we also provide a generic example of stochastic convex constrained optimization that can be formulated as (1). We further present a more general form of the examples covered in the main body.\n\nGeneric Example: Stochastic convex optimization with many conic constraints. Consider the following convex optimization problem\n\n$$\n\\begin{aligned}\n&\\min f(x, \\theta) \\\\\n&s.t. \\quad h(x, \\xi) \\in -K, \\forall \\xi \\in \\Omega,\n\\end{aligned}\n$$\nwhere $K \\subseteq \\mathbb{R}^d$ is a closed convex cone. This problem can be formulated as a special case of (1) by letting $\\tilde{g}(x, \\xi) = \\frac{1}{2}d^2 - K(h(x, \\xi))$ where $d-K(\\cdot) \\triangleq \\|\\cdot - P-K(\\cdot)\\|$ denotes the distance function and $P-K(\\cdot)$ denotes the projection map. Our proposed framework provides an efficient method for solving this class of problems when the projections onto $K$ can be computed efficiently, while the projection onto the preimage $h^{-1}(-K, \\xi)$ is not practical, e.g., when $K$ is the positive semidefinite cone, computing a projection onto the preimage set requires solving a nonlinear SDP."}, {"type": "heading", "lvl": 3, "value": "Lexicographic optimization", "md": "### Lexicographic optimization"}, {"type": "text", "value": "Example 1 (over-parameterized regression) can be generalized as a broader class of problem, which is known as lexicographic optimization [GL21] and uses the secondary loss to improve generalization. The problem can be formulated as the following stochastic simple bilevel optimization problem,\n\n$$\n\\begin{aligned}\n&\\min_{\\beta \\in \\mathbb{R}^d} L(\\beta) \\\\\n&s.t. \\quad \\beta \\in \\arg\\min_{\\theta \\in Z} \\mathcal{L}_{tr}(\\theta) = E_{D_{tr}}[\\mathcal{L}(y, \\hat{y}_{\\theta}(x))] \\quad (17)\n\\end{aligned}\n$$\nIn general, the lower-level problem could have multiple optimal solutions and be very sensitive to small perturbations. To tackle the issue, we use a secondary criterion $L(\\cdot)$ to select some of the optimal solutions with our desired properties. For instance, we can find the optimal solutions with minimal $\\ell_2$-norm by letting $L(\\beta) = \\|\\beta\\|_2$, which is also known as Lexicographic $\\ell_2$ Regularization.", "md": "Example 1 (over-parameterized regression) can be generalized as a broader class of problem, which is known as lexicographic optimization [GL21] and uses the secondary loss to improve generalization. The problem can be formulated as the following stochastic simple bilevel optimization problem,\n\n$$\n\\begin{aligned}\n&\\min_{\\beta \\in \\mathbb{R}^d} L(\\beta) \\\\\n&s.t. \\quad \\beta \\in \\arg\\min_{\\theta \\in Z} \\mathcal{L}_{tr}(\\theta) = E_{D_{tr}}[\\mathcal{L}(y, \\hat{y}_{\\theta}(x))] \\quad (17)\n\\end{aligned}\n$$\nIn general, the lower-level problem could have multiple optimal solutions and be very sensitive to small perturbations. To tackle the issue, we use a secondary criterion $L(\\cdot)$ to select some of the optimal solutions with our desired properties. For instance, we can find the optimal solutions with minimal $\\ell_2$-norm by letting $L(\\beta) = \\|\\beta\\|_2$, which is also known as Lexicographic $\\ell_2$ Regularization."}, {"type": "heading", "lvl": 3, "value": "Lifelong learning", "md": "### Lifelong learning"}, {"type": "text", "value": "Example 2 (dictionary learning) is an instance of a popular framework known as lifelong learning, which can be formulated as follows,\n\n$$\n\\begin{aligned}\n&\\min_{\\beta} \\frac{1}{n'} \\sum_{i=1}^{n'} \\ell(x'_i, \\beta, y'_i) \\\\\n&s.t. \\quad \\ell(\\langle x_i, \\beta \\rangle, y_i) \\leq \\ell(\\langle x_i, \\beta^{(t-1)} \\rangle, y_i) \\quad (18)\n\\end{aligned}\n$$\nIn this problem, the objective is the training loss on the current tasks $D_t = \\{(x'_i, y'_i)\\}_{i=1}^{n'}$. While the constraint enforces that the model parameterized by $\\beta$ performs no worse than the previous one on the episodic memory $M$ (i.e., data samples from all the past tasks).", "md": "Example 2 (dictionary learning) is an instance of a popular framework known as lifelong learning, which can be formulated as follows,\n\n$$\n\\begin{aligned}\n&\\min_{\\beta} \\frac{1}{n'} \\sum_{i=1}^{n'} \\ell(x'_i, \\beta, y'_i) \\\\\n&s.t. \\quad \\ell(\\langle x_i, \\beta \\rangle, y_i) \\leq \\ell(\\langle x_i, \\beta^{(t-1)} \\rangle, y_i) \\quad (18)\n\\end{aligned}\n$$\nIn this problem, the objective is the training loss on the current tasks $D_t = \\{(x'_i, y'_i)\\}_{i=1}^{n'}$. While the constraint enforces that the model parameterized by $\\beta$ performs no worse than the previous one on the episodic memory $M$ (i.e., data samples from all the past tasks)."}]}, {"page": 18, "text": " In the paper, we discuss a variant of the problem above, where we slightly change the constraint\n and ensure that the current model also minimizes the error on the past tasks. It can be formulated\n as the following finite-sum/stochastic simple bilevel optimization problem [JAMH23],\n                         min     1    n\u2032   \u2113     x\u2032i, \u03b2    , y\u2032i       s.t.       \u03b2 \u2208    argmin                     \u2113 (\u27e8xi, z\u27e9    , yi) .                  (19)\n                            \u03b2    n\u2032  i=1                                                      z      (x i,yi)\u2208M\n B        Supporting lemmas\n B.1        Proof of Lemma 4.1\n Before we proceed to the proof for Lemma 4.1, we present the following technical lemma, which\n gives us an upper bound for a complex term appearing in the following analysis.\n Lemma B.1. Defi                 ne \u03c1t = 1/(t + 1)\u03c9 where \u03c9 \u2208                         (0, 1] and t \u2265           1. For all t \u2265            2, let {st} be a\nsequence of real numbers given by\n                                                           st =       t     \u03c1\u03c4    t   (1 \u2212    \u03c1k)   2  .\n                                                                    \u03c4=2         k=\u03c4\nThen it holds that                                                                  1\n                                                                      st \u2264     (t + 1)\u03c9 .                                                                  (20)\n Proof. We prove the result by induction. For t = 2, we can verify that\n                                                     s2 =         1                  2   \u2264     1\n                                                                 3\u03c9 \u00b7 3\u03c9 \u2212  3\u03c9   1           32\u03c9 \u2264        1\n                                                                                                         3\u03c9 .\n Now we suppose that the inequality in (20) holds when t = T for some T \u2265                                                      2, i.e.,\n                                                 sT =       T      \u03c1\u03c4    T                 2   \u2264         1\n                                                           \u03c4=2         k=\u03c4   (1 \u2212    \u03c1k)            (t + 1)\u03c9 .\n First note that the sequence {st} satisfies the following recurrence relation:\n                   sT+1 =      T+1      \u03c1\u03c4   T+1  (1 \u2212    \u03c1k)    2   = (1 \u2212      \u03c1T+1)2      T+1      \u03c1\u03c4    T  (1 \u2212    \u03c1k)    2\n                                \u03c4=2          k=\u03c4                                             \u03c4=2          k=\u03c4\n                                                                     = (1 \u2212      \u03c1T+1)2         T      \u03c1\u03c4    T   (1 \u2212    \u03c1k)   2   + \u03c12  T+1\n                                                                                              \u03c4=2          k=\u03c4\n                                                                     = (1 \u2212      \u03c1T+1)2(sT + \u03c12         T+1).\n                                                                                18", "md": "In the paper, we discuss a variant of the problem above, where we slightly change the constraint\nand ensure that the current model also minimizes the error on the past tasks. It can be formulated\nas the following finite-sum/stochastic simple bilevel optimization problem [JAMH23],\n\n$$\n\\begin{aligned}\n&\\min_{\\beta} \\frac{1}{n'} \\sum_{i=1}^{n'} \\mathcal{L}(x'_i, \\beta, y'_i) \\\\\n&s.t. \\quad \\beta \\in \\arg\\min_{\\beta} \\mathcal{L}(\\langle x_i, z \\rangle, y_i) \\quad \\forall (x_i, y_i) \\in M \\quad (19)\n\\end{aligned}\n$$\n\nB Supporting lemmas\n\nB.1 Proof of Lemma 4.1\n\nBefore we proceed to the proof for Lemma 4.1, we present the following technical lemma, which\ngives us an upper bound for a complex term appearing in the following analysis.\n\nLemma B.1. Define $\\rho_t = \\frac{1}{(t + 1)^\\omega}$ where $\\omega \\in (0, 1]$ and $t \\geq 1$. For all $t \\geq 2$, let $\\{s_t\\}$ be a\nsequence of real numbers given by\n\n$$\ns_t = \\sum_{\\tau=2}^{t} t \\rho_{\\tau} (1 - \\rho_k)^2.\n$$\n\nThen it holds that\n\n$$\ns_t \\leq (t + 1)^\\omega \\quad (20)\n$$\n\nProof. We prove the result by induction. For $t = 2$, we can verify that\n\n$$\n\\begin{aligned}\ns_2 &= 1 \\cdot \\frac{1}{3\\omega} \\cdot (3\\omega - 3\\omega \\cdot \\frac{1}{3})^2 \\\\\n&\\leq \\frac{1}{3\\omega}.\n\\end{aligned}\n$$\n\nNow we suppose that the inequality in (20) holds when $t = T$ for some $T \\geq 2$, i.e.,\n\n$$\ns_T = \\sum_{\\tau=2}^{T} T \\rho_{\\tau}^2 (1 - \\rho_k) \\leq (t + 1)^\\omega.\n$$\n\nFirst note that the sequence $\\{s_t\\}$ satisfies the following recurrence relation:\n\n$$\n\\begin{aligned}\ns_{T+1} &= \\sum_{\\tau=2}^{T+1} (1 - \\rho_{T+1})^2 T \\rho_{\\tau} (1 - \\rho_k)^2 \\\\\n&= (1 - \\rho_{T+1})^2 \\sum_{\\tau=2}^{T} T \\rho_{\\tau} (1 - \\rho_k)^2 + \\rho^2 T+1 \\\\\n&= (1 - \\rho_{T+1})^2(s_T + \\rho^2 T+1).\n\\end{aligned}\n$$", "images": [], "items": [{"type": "text", "value": "In the paper, we discuss a variant of the problem above, where we slightly change the constraint\nand ensure that the current model also minimizes the error on the past tasks. It can be formulated\nas the following finite-sum/stochastic simple bilevel optimization problem [JAMH23],\n\n$$\n\\begin{aligned}\n&\\min_{\\beta} \\frac{1}{n'} \\sum_{i=1}^{n'} \\mathcal{L}(x'_i, \\beta, y'_i) \\\\\n&s.t. \\quad \\beta \\in \\arg\\min_{\\beta} \\mathcal{L}(\\langle x_i, z \\rangle, y_i) \\quad \\forall (x_i, y_i) \\in M \\quad (19)\n\\end{aligned}\n$$\n\nB Supporting lemmas\n\nB.1 Proof of Lemma 4.1\n\nBefore we proceed to the proof for Lemma 4.1, we present the following technical lemma, which\ngives us an upper bound for a complex term appearing in the following analysis.\n\nLemma B.1. Define $\\rho_t = \\frac{1}{(t + 1)^\\omega}$ where $\\omega \\in (0, 1]$ and $t \\geq 1$. For all $t \\geq 2$, let $\\{s_t\\}$ be a\nsequence of real numbers given by\n\n$$\ns_t = \\sum_{\\tau=2}^{t} t \\rho_{\\tau} (1 - \\rho_k)^2.\n$$\n\nThen it holds that\n\n$$\ns_t \\leq (t + 1)^\\omega \\quad (20)\n$$\n\nProof. We prove the result by induction. For $t = 2$, we can verify that\n\n$$\n\\begin{aligned}\ns_2 &= 1 \\cdot \\frac{1}{3\\omega} \\cdot (3\\omega - 3\\omega \\cdot \\frac{1}{3})^2 \\\\\n&\\leq \\frac{1}{3\\omega}.\n\\end{aligned}\n$$\n\nNow we suppose that the inequality in (20) holds when $t = T$ for some $T \\geq 2$, i.e.,\n\n$$\ns_T = \\sum_{\\tau=2}^{T} T \\rho_{\\tau}^2 (1 - \\rho_k) \\leq (t + 1)^\\omega.\n$$\n\nFirst note that the sequence $\\{s_t\\}$ satisfies the following recurrence relation:\n\n$$\n\\begin{aligned}\ns_{T+1} &= \\sum_{\\tau=2}^{T+1} (1 - \\rho_{T+1})^2 T \\rho_{\\tau} (1 - \\rho_k)^2 \\\\\n&= (1 - \\rho_{T+1})^2 \\sum_{\\tau=2}^{T} T \\rho_{\\tau} (1 - \\rho_k)^2 + \\rho^2 T+1 \\\\\n&= (1 - \\rho_{T+1})^2(s_T + \\rho^2 T+1).\n\\end{aligned}\n$$", "md": "In the paper, we discuss a variant of the problem above, where we slightly change the constraint\nand ensure that the current model also minimizes the error on the past tasks. It can be formulated\nas the following finite-sum/stochastic simple bilevel optimization problem [JAMH23],\n\n$$\n\\begin{aligned}\n&\\min_{\\beta} \\frac{1}{n'} \\sum_{i=1}^{n'} \\mathcal{L}(x'_i, \\beta, y'_i) \\\\\n&s.t. \\quad \\beta \\in \\arg\\min_{\\beta} \\mathcal{L}(\\langle x_i, z \\rangle, y_i) \\quad \\forall (x_i, y_i) \\in M \\quad (19)\n\\end{aligned}\n$$\n\nB Supporting lemmas\n\nB.1 Proof of Lemma 4.1\n\nBefore we proceed to the proof for Lemma 4.1, we present the following technical lemma, which\ngives us an upper bound for a complex term appearing in the following analysis.\n\nLemma B.1. Define $\\rho_t = \\frac{1}{(t + 1)^\\omega}$ where $\\omega \\in (0, 1]$ and $t \\geq 1$. For all $t \\geq 2$, let $\\{s_t\\}$ be a\nsequence of real numbers given by\n\n$$\ns_t = \\sum_{\\tau=2}^{t} t \\rho_{\\tau} (1 - \\rho_k)^2.\n$$\n\nThen it holds that\n\n$$\ns_t \\leq (t + 1)^\\omega \\quad (20)\n$$\n\nProof. We prove the result by induction. For $t = 2$, we can verify that\n\n$$\n\\begin{aligned}\ns_2 &= 1 \\cdot \\frac{1}{3\\omega} \\cdot (3\\omega - 3\\omega \\cdot \\frac{1}{3})^2 \\\\\n&\\leq \\frac{1}{3\\omega}.\n\\end{aligned}\n$$\n\nNow we suppose that the inequality in (20) holds when $t = T$ for some $T \\geq 2$, i.e.,\n\n$$\ns_T = \\sum_{\\tau=2}^{T} T \\rho_{\\tau}^2 (1 - \\rho_k) \\leq (t + 1)^\\omega.\n$$\n\nFirst note that the sequence $\\{s_t\\}$ satisfies the following recurrence relation:\n\n$$\n\\begin{aligned}\ns_{T+1} &= \\sum_{\\tau=2}^{T+1} (1 - \\rho_{T+1})^2 T \\rho_{\\tau} (1 - \\rho_k)^2 \\\\\n&= (1 - \\rho_{T+1})^2 \\sum_{\\tau=2}^{T} T \\rho_{\\tau} (1 - \\rho_k)^2 + \\rho^2 T+1 \\\\\n&= (1 - \\rho_{T+1})^2(s_T + \\rho^2 T+1).\n\\end{aligned}\n$$"}]}, {"page": 19, "text": "Moreover, since \u03c9 \u2208             (0, 1], we have (T + 2)\u03c9 \u2212               1 \u2264    (t + 1)\u03c9. Therefore, we obtain\n                                               (T + 2)\u03c9 \u2212          1  2           1                 1\n                                  sT+1 \u2264            (T + 2)\u03c9                 (t + 1)\u03c9 +       (T + 2)2\u03c9\n                                          \u2264   ((T + 2)\u03c9 \u2212        1)(t + 1)\u03c9               1                  1\n                                                        (T + 2)2\u03c9                    (t + 1)\u03c9 +       (T + 1)2\u03c9\n                                          = (T + 2)\u03c9 \u2212          1 (T + 1)\u03c9 + 1\n                                                (T + 2)2\u03c9             (T + 1)\u03c9\n                                          = (T + 2)\u03c9(t + 1)\u03c9 + (T + 2)\u03c9 \u2212                     1 \u2212   (t + 1)\u03c9\n                                                                  (T + 2)2\u03c9(t + 1)\u03c9\n                                          \u2264    (T + 2)\u03c9(t + 1)\u03c9                      1\n                                              (T + 2)2\u03c9(t + 1)\u03c9 =              (T + 2)\u03c9 .\nBy induction, the inequality in (20) holds for all t \u2265                             2.\nNow we proceed to prove Lemma 4.1.\nProof of Lemma 4.1. We show the proof of part (i) here. The proof of part (ii) is very similar to\npart (i). The first step is to reformulate et =                         \u2207gt \u2212      \u2207g(xt) as the sum of a martingale difference\nsequence. For t \u2265            1, by unrolling the reucurrence we have\n      et = (1 \u2212      \u03b2t)et\u22121 + \u03b2t(\u2207\u02dc        g(xt, \u03bet) \u2212      \u2207g(xt))\n              + (1 \u2212     \u03b2t)(\u2207\u02dc   g(xt, \u03bet) \u2212      \u2207\u02dc g(xt\u22121, \u03bet) \u2212       (\u2207g(xt) \u2212        \u2207g(xt\u22121))\n               t                         t     t\n          =  k=2  (1 \u2212    \u03b2k)e1 +      \u03c4=2   k=\u03c4  (1 \u2212   \u03b2k)(\u2207\u02dc    g(x\u03c4, \u03be\u03c4) \u2212       \u2207\u02dc g(x\u03c4\u22121, \u03be\u03c4) \u2212        (\u2207g(x\u03c4) \u2212        \u2207g(x\u03c4\u22121))    (21)\n               t           t\n         +   \u03c4=2   \u03b2\u03c4  k=\u03c4+1    (1 \u2212   \u03b2k)(\u2207\u02dc    g(x\u03c4, \u03be\u03c4) \u2212       \u2207g(x\u03c4)).\nThus, we can write et as the sum et =  t                         \u03c4=1 \u03b6\u03c4, where we define \u03b61 =  t                 k=2(1 \u2212      \u03b2k)e1 and\n                                  t\n                        \u03b6\u03c4 =    k=\u03c4  (1 \u2212   t\u03b2k)(\u2207\u02dc   g(x\u03c4, \u03be\u03c4) \u2212       \u2207\u02dc g(x\u03c4\u22121, \u03be\u03c4) \u2212        (\u2207g(x\u03c4 ) \u2212       \u2207g(x\u03c4\u22121))                 (22)\n                                 + \u03b2\u03c4    k=\u03c4+1   (1 \u2212    \u03b2k)(\u2207\u02dc   g(x\u03c4, \u03be\u03c4) \u2212       \u2207g(x\u03c4))                                                (23)\nfor \u03c4 > 1. Recall that e1 = \u2207\u02dc                    g(xt, \u03b61) \u2212       \u2207g(x1). We observe that E[\u03b6\u03c4|F\u03c4\u22121] = 0 where F\u03c4\u22121\nis the \u03c3-field generated by {x1, \u03be1, . . . , x\u03c4\u22121, \u03be\u03c4\u22121}. Therefore, {\u03b6\u03c4}t                                 \u03c4=1 is a martingale difference\nsequence.\nNext, we derive upper bounds of \u2225\u03b6\u03c4\u2225. To begin with, we observe that for any \u03c4 = 1, 2, . . . , t,\n                t                     t                 1           =    t   (k + 1)\u03c9 \u2212        1  \u2264     t       k\u03b1                \u03c4 \u03c9      (24)\n              k=\u03c4  (1 \u2212   \u03b2k) =     k=\u03c4     1 \u2212    (k + 1)\u03c9            k=\u03c4       (k + 1)\u03c9             k=\u03c4   (k + 1)\u03c9 =        (t + 1)\u03c9 ,\n                                                                           19", "md": "Moreover, since $$\\omega \\in (0, 1]$$, we have $$(T + 2)\\omega - 1 \\leq (t + 1)\\omega$$. Therefore, we obtain\n\n$$\n\\begin{align*}\nsT+1 &\\leq \\frac{(T + 2)\\omega}{(t + 1)\\omega + (T + 2)^2\\omega} \\\\\n&\\leq \\frac{((T + 2)\\omega - 1)(t + 1)\\omega}{(T + 2)^2\\omega + (t + 1)\\omega + (T + 1)^2\\omega} \\\\\n&= \\frac{(T + 2)\\omega - 1}{(T + 1)\\omega + 1} \\\\\n&= \\frac{(T + 2)\\omega(t + 1)\\omega + (T + 2)\\omega - 1 - (t + 1)\\omega}{(T + 2)^2\\omega(t + 1)\\omega} \\\\\n&\\leq \\frac{(T + 2)\\omega(t + 1)\\omega}{(T + 2)^2\\omega(t + 1)\\omega} = \\frac{T + 2}{\\omega}.\n\\end{align*}\n$$\nBy induction, the inequality in (20) holds for all $$t \\geq 2$$.\n\nNow we proceed to prove Lemma 4.1.\n\nProof of Lemma 4.1. We show the proof of part (i) here. The proof of part (ii) is very similar to part (i). The first step is to reformulate $$e_t = \\nabla g_t - \\nabla g(x_t)$$ as the sum of a martingale difference sequence. For $$t \\geq 1$$, by unrolling the recurrence we have\n\n$$\n\\begin{align*}\ne_t &= (1 - \\beta_t)e_{t-1} + \\beta_t(\\nabla \\tilde{g}(x_t, \\xi_t) - \\nabla g(x_t)) \\\\\n&\\quad + (1 - \\beta_t)(\\nabla \\tilde{g}(x_t, \\xi_t) - \\nabla \\tilde{g}(x_{t-1}, \\xi_t) - (\\nabla g(x_t) - \\nabla g(x_{t-1})) \\\\\n&= \\sum_{k=2}^{t} (1 - \\beta_k)e_1 + \\sum_{\\tau=2}^{t} \\sum_{k=\\tau}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla \\tilde{g}(x_{\\tau-1}, \\xi_{\\tau}) - (\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})) \\quad (21) \\\\\n&\\quad + \\sum_{\\tau=2}^{t} \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})).\n\\end{align*}\n$$\nThus, we can write $$e_t$$ as the sum $$e_t = \\sum_{\\tau=1}^{t} \\zeta_{\\tau}$$, where we define $$\\zeta_1 = \\sum_{k=2}^{t}(1 - \\beta_k)e_1$$ and\n\n$$\n\\begin{align*}\n\\zeta_{\\tau} &= \\sum_{k=\\tau}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla \\tilde{g}(x_{\\tau-1}, \\xi_{\\tau}) - (\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})) \\quad (22) \\\\\n&\\quad + \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})) \\quad (23)\n\\end{align*}\n$$\nfor $$\\tau > 1$$. Recall that $$e_1 = \\nabla \\tilde{g}(x_t, \\zeta_1) - \\nabla g(x_1)$$. We observe that $$E[\\zeta_{\\tau}|F_{\\tau-1}] = 0$$ where $$F_{\\tau-1}$$ is the $$\\sigma$$-field generated by {$x_1, \\xi_1, ..., x_{\\tau-1}, \\xi_{\\tau-1}$}. Therefore, {$\\zeta_{\\tau}$} for $$t \\geq 1$$ is a martingale difference sequence.\n\nNext, we derive upper bounds of $$\\|\\zeta_{\\tau}\\|$$. To begin with, we observe that for any $$\\tau = 1, 2, ..., t$$,\n\n$$\n\\begin{align*}\n\\sum_{k=\\tau}^{t} (1 - \\beta_k) &= \\sum_{k=\\tau}^{t} 1 - (k + 1)\\omega \\leq \\sum_{k=\\tau}^{t} k\\alpha \\tau \\omega \\quad (24) \\\\\n&= (t + 1)\\omega.\n\\end{align*}\n$$", "images": [], "items": [{"type": "text", "value": "Moreover, since $$\\omega \\in (0, 1]$$, we have $$(T + 2)\\omega - 1 \\leq (t + 1)\\omega$$. Therefore, we obtain\n\n$$\n\\begin{align*}\nsT+1 &\\leq \\frac{(T + 2)\\omega}{(t + 1)\\omega + (T + 2)^2\\omega} \\\\\n&\\leq \\frac{((T + 2)\\omega - 1)(t + 1)\\omega}{(T + 2)^2\\omega + (t + 1)\\omega + (T + 1)^2\\omega} \\\\\n&= \\frac{(T + 2)\\omega - 1}{(T + 1)\\omega + 1} \\\\\n&= \\frac{(T + 2)\\omega(t + 1)\\omega + (T + 2)\\omega - 1 - (t + 1)\\omega}{(T + 2)^2\\omega(t + 1)\\omega} \\\\\n&\\leq \\frac{(T + 2)\\omega(t + 1)\\omega}{(T + 2)^2\\omega(t + 1)\\omega} = \\frac{T + 2}{\\omega}.\n\\end{align*}\n$$\nBy induction, the inequality in (20) holds for all $$t \\geq 2$$.\n\nNow we proceed to prove Lemma 4.1.\n\nProof of Lemma 4.1. We show the proof of part (i) here. The proof of part (ii) is very similar to part (i). The first step is to reformulate $$e_t = \\nabla g_t - \\nabla g(x_t)$$ as the sum of a martingale difference sequence. For $$t \\geq 1$$, by unrolling the recurrence we have\n\n$$\n\\begin{align*}\ne_t &= (1 - \\beta_t)e_{t-1} + \\beta_t(\\nabla \\tilde{g}(x_t, \\xi_t) - \\nabla g(x_t)) \\\\\n&\\quad + (1 - \\beta_t)(\\nabla \\tilde{g}(x_t, \\xi_t) - \\nabla \\tilde{g}(x_{t-1}, \\xi_t) - (\\nabla g(x_t) - \\nabla g(x_{t-1})) \\\\\n&= \\sum_{k=2}^{t} (1 - \\beta_k)e_1 + \\sum_{\\tau=2}^{t} \\sum_{k=\\tau}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla \\tilde{g}(x_{\\tau-1}, \\xi_{\\tau}) - (\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})) \\quad (21) \\\\\n&\\quad + \\sum_{\\tau=2}^{t} \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})).\n\\end{align*}\n$$\nThus, we can write $$e_t$$ as the sum $$e_t = \\sum_{\\tau=1}^{t} \\zeta_{\\tau}$$, where we define $$\\zeta_1 = \\sum_{k=2}^{t}(1 - \\beta_k)e_1$$ and\n\n$$\n\\begin{align*}\n\\zeta_{\\tau} &= \\sum_{k=\\tau}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla \\tilde{g}(x_{\\tau-1}, \\xi_{\\tau}) - (\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})) \\quad (22) \\\\\n&\\quad + \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})) \\quad (23)\n\\end{align*}\n$$\nfor $$\\tau > 1$$. Recall that $$e_1 = \\nabla \\tilde{g}(x_t, \\zeta_1) - \\nabla g(x_1)$$. We observe that $$E[\\zeta_{\\tau}|F_{\\tau-1}] = 0$$ where $$F_{\\tau-1}$$ is the $$\\sigma$$-field generated by {$x_1, \\xi_1, ..., x_{\\tau-1}, \\xi_{\\tau-1}$}. Therefore, {$\\zeta_{\\tau}$} for $$t \\geq 1$$ is a martingale difference sequence.\n\nNext, we derive upper bounds of $$\\|\\zeta_{\\tau}\\|$$. To begin with, we observe that for any $$\\tau = 1, 2, ..., t$$,\n\n$$\n\\begin{align*}\n\\sum_{k=\\tau}^{t} (1 - \\beta_k) &= \\sum_{k=\\tau}^{t} 1 - (k + 1)\\omega \\leq \\sum_{k=\\tau}^{t} k\\alpha \\tau \\omega \\quad (24) \\\\\n&= (t + 1)\\omega.\n\\end{align*}\n$$", "md": "Moreover, since $$\\omega \\in (0, 1]$$, we have $$(T + 2)\\omega - 1 \\leq (t + 1)\\omega$$. Therefore, we obtain\n\n$$\n\\begin{align*}\nsT+1 &\\leq \\frac{(T + 2)\\omega}{(t + 1)\\omega + (T + 2)^2\\omega} \\\\\n&\\leq \\frac{((T + 2)\\omega - 1)(t + 1)\\omega}{(T + 2)^2\\omega + (t + 1)\\omega + (T + 1)^2\\omega} \\\\\n&= \\frac{(T + 2)\\omega - 1}{(T + 1)\\omega + 1} \\\\\n&= \\frac{(T + 2)\\omega(t + 1)\\omega + (T + 2)\\omega - 1 - (t + 1)\\omega}{(T + 2)^2\\omega(t + 1)\\omega} \\\\\n&\\leq \\frac{(T + 2)\\omega(t + 1)\\omega}{(T + 2)^2\\omega(t + 1)\\omega} = \\frac{T + 2}{\\omega}.\n\\end{align*}\n$$\nBy induction, the inequality in (20) holds for all $$t \\geq 2$$.\n\nNow we proceed to prove Lemma 4.1.\n\nProof of Lemma 4.1. We show the proof of part (i) here. The proof of part (ii) is very similar to part (i). The first step is to reformulate $$e_t = \\nabla g_t - \\nabla g(x_t)$$ as the sum of a martingale difference sequence. For $$t \\geq 1$$, by unrolling the recurrence we have\n\n$$\n\\begin{align*}\ne_t &= (1 - \\beta_t)e_{t-1} + \\beta_t(\\nabla \\tilde{g}(x_t, \\xi_t) - \\nabla g(x_t)) \\\\\n&\\quad + (1 - \\beta_t)(\\nabla \\tilde{g}(x_t, \\xi_t) - \\nabla \\tilde{g}(x_{t-1}, \\xi_t) - (\\nabla g(x_t) - \\nabla g(x_{t-1})) \\\\\n&= \\sum_{k=2}^{t} (1 - \\beta_k)e_1 + \\sum_{\\tau=2}^{t} \\sum_{k=\\tau}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla \\tilde{g}(x_{\\tau-1}, \\xi_{\\tau}) - (\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})) \\quad (21) \\\\\n&\\quad + \\sum_{\\tau=2}^{t} \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})).\n\\end{align*}\n$$\nThus, we can write $$e_t$$ as the sum $$e_t = \\sum_{\\tau=1}^{t} \\zeta_{\\tau}$$, where we define $$\\zeta_1 = \\sum_{k=2}^{t}(1 - \\beta_k)e_1$$ and\n\n$$\n\\begin{align*}\n\\zeta_{\\tau} &= \\sum_{k=\\tau}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla \\tilde{g}(x_{\\tau-1}, \\xi_{\\tau}) - (\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})) \\quad (22) \\\\\n&\\quad + \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta_k)(\\nabla \\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})) \\quad (23)\n\\end{align*}\n$$\nfor $$\\tau > 1$$. Recall that $$e_1 = \\nabla \\tilde{g}(x_t, \\zeta_1) - \\nabla g(x_1)$$. We observe that $$E[\\zeta_{\\tau}|F_{\\tau-1}] = 0$$ where $$F_{\\tau-1}$$ is the $$\\sigma$$-field generated by {$x_1, \\xi_1, ..., x_{\\tau-1}, \\xi_{\\tau-1}$}. Therefore, {$\\zeta_{\\tau}$} for $$t \\geq 1$$ is a martingale difference sequence.\n\nNext, we derive upper bounds of $$\\|\\zeta_{\\tau}\\|$$. To begin with, we observe that for any $$\\tau = 1, 2, ..., t$$,\n\n$$\n\\begin{align*}\n\\sum_{k=\\tau}^{t} (1 - \\beta_k) &= \\sum_{k=\\tau}^{t} 1 - (k + 1)\\omega \\leq \\sum_{k=\\tau}^{t} k\\alpha \\tau \\omega \\quad (24) \\\\\n&= (t + 1)\\omega.\n\\end{align*}\n$$"}]}, {"page": 20, "text": "where we used the fact that (k + 1)\u03c9 \u2212                                               1 \u2264       k\u03c9 in the last inequality. By using the above inequality,\nwe can bound \u2225\u03b61\u2225                          as follows:\n       \u2225\u03b61\u2225       =       t   (1 \u2212       \u03b2k)\u2225e1\u2225           \u2264           2\u03c9                g(x1, \u03be1) \u2212             \u2207g(x1)\u2225             =        2\u03c9    \u03c31       \u2225\u2207\u02dc    g(x1, \u03be1) \u2212             \u2207g(x1)\u2225       .\n                       k=2    2\u03c9  \u03c3g                             (t + 1)\u03c9 \u2225\u2207\u02dc                                                              (t + 1)\u03c9                                \u03c31\nDefine c1 =                 (T  +1)\u03c9 , then by Assumption 2.3(ii) we have E[exp (\u2225\u03b61\u22252/c2                                                                  1)] \u2264       exp (1). Moreover, for\n\u03c4 > 1, by triangle inequality, \u2225\u03b6\u03c4        t                             \u2225   can be bounded by\n                       \u2225\u03b6\u03c4    \u2225   \u2264      (1 \u2212            \u03b2k)(\u2225\u2207\u02dc         g(x\u03c4      , \u03be\u03c4   ) \u2212     \u2207\u02dc  g(x\u03c4\u22121, \u03be\u03c4            )\u2225   + \u2225(\u2207g(x\u03c4 ) \u2212                   \u2207g(x\u03c4\u22121)\u2225)\n                                       k=\u03c4\n                                  + \u03b2\u03c4       k=\u03c4+1t      (1 \u2212       \u03b2k)\u2225\u2207\u02dc    t   g(x\u03c4     , \u03be\u03c4   ) \u2212     \u2207g(x\u03c4         )\u2225                                              t\n                                  \u2264    2Lg\u2225x\u03c4 \u2212              tx\u03c4\u22121\u2225        k=\u03c4     (1 \u2212      \u03b2k) + \u2225\u2207\u02dc           g(x\u03c4      , \u03be\u03c4   ) \u2212     \u2207g(x\u03c4       t )\u2225\u03b2\u03c4      k=\u03c4+1        (1 \u2212      \u03b2k)\n                                  = 2Lg\u03b3\u03c4            D    k=\u03c4t   (1 \u2212      \u03b2k) + \u2225\u2207\u02dc           g(x\u03c4      , \u03be\u03c4   ) \u2212     \u2207g(x\u03c4         )\u2225\u03b2\u03c4       k=\u03c4+1       (1 \u2212  t   \u03b2k)                                (25)\n                                  \u2264    2LgD\u03b2\u03c4             k=\u03c4    (1 \u2212       \u03b2k) +        3\u03c9 \u2212 3\u03c9     1  \u2225\u2207\u02dc    g(x\u03c4      , \u03be\u03c4  ) \u2212     \u2207g(x\u03c4         )\u2225\u03b2\u03c4       k=\u03c4    (1 \u2212       \u03b2k)\n                                  =        2LgD +             3\u03c9 \u22123\u03c9      1  \u2225\u2207\u02dc   g(x\u03c4      , \u03be\u03c4   ) \u2212     \u2207g(x\u03c4         )\u2225      \u03b2\u03c4    k=\u03c4t    (1 \u2212      \u03b2k)\n                                  =        2LgD + 3\u03c9\u03c3g                       \u2225\u2207\u02dc    g(x\u03c4      , \u03be\u03c4   ) \u2212     \u2207g(x\u03c4         )\u2225      \u03b2\u03c4       t    (1 \u2212      \u03b2k)\n                                                              3\u03c9 \u2212        1                         \u03c3g                                   k=\u03c4\nDefine c\u03c4 = (2LgD + 3\u03c9\u03c3g                              3\u03c9\u22121      )\u03b2\u03c4      t  k=\u03c4     (1 \u2212        \u03b2k).         Note that if we have E[exp(X2                                         1  /c2 1)] \u2264      1 and\nE[exp(X2           2  /c2 2)] \u2264          1, then we have E[exp((X1 + X2)2/(c1 + c2)2)] \u2264                                                                    1 [Ver18].                Thus, we have      \u2032\nE[exp (\u2225\u03b6\u03c4             \u22252/c2    \u03c4 )] \u2264      exp (1) for all 1 \u2264                      \u03c4 \u2264      t. Hence by proposition E.2, with probability 1 \u2212                                                        \u03b4\nwhere c is an absolute constant, d is the number of dimension, and  T            \u2225et\u2225      \u2264     c \u00b7        \u03c4=1t    c2\u03c4 log 2d    \u03b4 \u2032                         \u03c4=1 c2    \u03c4 can be bounded by               (26)\n Lemma B.1 as follows,\n                           t    c2 \u03c4 = c2     1 +        t    c2\u03c4 =           22\u03c9\u03c32     g                                      3\u03c9                    T    (\u03b2\u03c4       T    (1 \u2212       \u03b2k))2\n                        \u03c4=1                           \u03c4=2                 (T + 1)2\u03c9 + (2LgD +                             3\u03c9 \u2212        1  \u03c3g)2      \u03c4=2            k=\u03c4\n                                                                                                                             3\u03c9\n                                                                    \u2264         22\u03c9    \u03c32 g             (2LgD +              3\u03c9\u22121      \u03c3g)2\n                                                                          (T +\u221a1)2\u03c9 +                            (t + 1)\u03c9        3\u03c9                                                                       (27)\n                                                                    \u2264     ((      2)\u03c9\u03c3      g)2     +     (2LgD +              3\u03c9\u22121     \u03c3g)2\n                                                                              (t + 1)\u03c9                               (t + 1)\u03c9\n                                                                                                    3\u03c9\n                                                                    \u2264     2(2LgD +     (t + 1)\u03c9  3\u03c9\u22121      \u03c3g)2\n                                                                                                         20", "md": "# Math Equations\n\nwhere we used the fact that $$(k + 1)\\omega - 1 \\leq k\\omega$$ in the last inequality. By using the above inequality, we can bound $$\\|\\zeta_1\\|$$ as follows:\n\n$$\n\\begin{align*}\n\\|\\zeta_1\\| &= t(1 - \\beta k)\\|e_1\\| \\\\\n&\\leq 2\\omega [g(x_1, \\xi_1) - \\nabla g(x_1)\\| \\\\\n&= 2\\omega \\sigma_1 \\|\\nabla\\tilde{g}(x_1, \\xi_1) - \\nabla g(x_1)\\|\n\\end{align*}\n$$\n\nDefine $$c_1 = \\frac{(t+1)\\omega}{\\sigma_g}$$. Then by Assumption 2.3(ii) we have $$E[\\exp (\\|\\zeta_1\\|^2/c_1)] \\leq \\exp(1)$$. Moreover, for $$\\tau > 1$$, by triangle inequality, $$\\|\\zeta_{\\tau}\\|$$ can be bounded by\n\n$$\n\\begin{align*}\n\\|\\zeta_{\\tau}\\| &\\leq (1 - \\beta k)(\\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla\\tilde{g}(x_{\\tau-1}, \\xi_{\\tau})\\| + \\|\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})\\|) \\\\\n&+ \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k)\\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\| \\\\\n&\\leq 2L_g\\|x_{\\tau} - t x_{\\tau-1}\\| \\sum_{k=\\tau}^{t} (1 - \\beta k) + \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k) \\\\\n&= 2L_g\\gamma_{\\tau} D \\sum_{k=\\tau}^{t} (1 - \\beta k) + \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k) \\\\\n&\\leq 2L_gD\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) + 3\\omega - 3\\omega \\frac{1}{\\sigma_g} \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) \\\\\n&= 2L_gD + 3\\omega - 3\\omega \\frac{1}{\\sigma_g} \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) \\\\\n&= 2L_gD + 3\\omega\\sigma_g \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k)\n\\end{align*}\n$$\n\nDefine $$c_{\\tau} = \\left(2L_gD + 3\\omega\\sigma_g \\frac{3\\omega - 1}{\\sigma_g}\\right)\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k)$$. Note that if we have $$E[\\exp(X_1^2/c_1^2)] \\leq 1$$ and $$E[\\exp(X_2^2/c_2^2)] \\leq 1$$, then we have $$E[\\exp((X_1 + X_2)^2/(c_1 + c_2)^2)] \\leq 1$$ [Ver18]. Thus, we have $$E[\\exp (\\|\\zeta_{\\tau}\\|^2/c_{\\tau})] \\leq \\exp(1)$$ for all $$1 \\leq \\tau \\leq t$$. Hence by proposition E.2, with probability $$1 - \\delta$$ where $$c$$ is an absolute constant, $$d$$ is the number of dimensions, and $$T \\|\\mathbf{e}_t\\| \\leq c \\cdot \\sum_{\\tau=1}^{t} c_{2\\tau} \\log 2d \\delta' \\sum_{\\tau=1} c_{2\\tau}$$ can be bounded by\n\nLemma B.1 as follows,\n\n$$\n\\begin{align*}\n\\sum_{\\tau=1}^{t} c_{2\\tau} &= c_2^1 + \\sum_{\\tau=2} c_{2\\tau} \\\\\n&= 22\\omega\\sigma_g^2 + (T+1)^2\\omega + (2L_gD + 3\\omega - 1 \\sigma_g)^2 \\sum_{\\tau=2} \\sum_{k=\\tau} \\\\\n&\\leq 22\\omega\\sigma_g^2 (2L_gD + 3\\omega - 1 \\sigma_g)^2 \\\\\n&\\leq ((2\\omega\\sigma_g)^2 + (2L_gD + 3\\omega - 1 \\sigma_g)^2) (t + 1)\\omega \\\\\n&\\leq 2(2L_gD + (t + 1)\\omega \\frac{3\\omega - 1}{\\sigma_g})^2\n\\end{align*}\n$$", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations", "md": "# Math Equations"}, {"type": "text", "value": "where we used the fact that $$(k + 1)\\omega - 1 \\leq k\\omega$$ in the last inequality. By using the above inequality, we can bound $$\\|\\zeta_1\\|$$ as follows:\n\n$$\n\\begin{align*}\n\\|\\zeta_1\\| &= t(1 - \\beta k)\\|e_1\\| \\\\\n&\\leq 2\\omega [g(x_1, \\xi_1) - \\nabla g(x_1)\\| \\\\\n&= 2\\omega \\sigma_1 \\|\\nabla\\tilde{g}(x_1, \\xi_1) - \\nabla g(x_1)\\|\n\\end{align*}\n$$\n\nDefine $$c_1 = \\frac{(t+1)\\omega}{\\sigma_g}$$. Then by Assumption 2.3(ii) we have $$E[\\exp (\\|\\zeta_1\\|^2/c_1)] \\leq \\exp(1)$$. Moreover, for $$\\tau > 1$$, by triangle inequality, $$\\|\\zeta_{\\tau}\\|$$ can be bounded by\n\n$$\n\\begin{align*}\n\\|\\zeta_{\\tau}\\| &\\leq (1 - \\beta k)(\\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla\\tilde{g}(x_{\\tau-1}, \\xi_{\\tau})\\| + \\|\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})\\|) \\\\\n&+ \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k)\\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\| \\\\\n&\\leq 2L_g\\|x_{\\tau} - t x_{\\tau-1}\\| \\sum_{k=\\tau}^{t} (1 - \\beta k) + \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k) \\\\\n&= 2L_g\\gamma_{\\tau} D \\sum_{k=\\tau}^{t} (1 - \\beta k) + \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k) \\\\\n&\\leq 2L_gD\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) + 3\\omega - 3\\omega \\frac{1}{\\sigma_g} \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) \\\\\n&= 2L_gD + 3\\omega - 3\\omega \\frac{1}{\\sigma_g} \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) \\\\\n&= 2L_gD + 3\\omega\\sigma_g \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k)\n\\end{align*}\n$$\n\nDefine $$c_{\\tau} = \\left(2L_gD + 3\\omega\\sigma_g \\frac{3\\omega - 1}{\\sigma_g}\\right)\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k)$$. Note that if we have $$E[\\exp(X_1^2/c_1^2)] \\leq 1$$ and $$E[\\exp(X_2^2/c_2^2)] \\leq 1$$, then we have $$E[\\exp((X_1 + X_2)^2/(c_1 + c_2)^2)] \\leq 1$$ [Ver18]. Thus, we have $$E[\\exp (\\|\\zeta_{\\tau}\\|^2/c_{\\tau})] \\leq \\exp(1)$$ for all $$1 \\leq \\tau \\leq t$$. Hence by proposition E.2, with probability $$1 - \\delta$$ where $$c$$ is an absolute constant, $$d$$ is the number of dimensions, and $$T \\|\\mathbf{e}_t\\| \\leq c \\cdot \\sum_{\\tau=1}^{t} c_{2\\tau} \\log 2d \\delta' \\sum_{\\tau=1} c_{2\\tau}$$ can be bounded by\n\nLemma B.1 as follows,\n\n$$\n\\begin{align*}\n\\sum_{\\tau=1}^{t} c_{2\\tau} &= c_2^1 + \\sum_{\\tau=2} c_{2\\tau} \\\\\n&= 22\\omega\\sigma_g^2 + (T+1)^2\\omega + (2L_gD + 3\\omega - 1 \\sigma_g)^2 \\sum_{\\tau=2} \\sum_{k=\\tau} \\\\\n&\\leq 22\\omega\\sigma_g^2 (2L_gD + 3\\omega - 1 \\sigma_g)^2 \\\\\n&\\leq ((2\\omega\\sigma_g)^2 + (2L_gD + 3\\omega - 1 \\sigma_g)^2) (t + 1)\\omega \\\\\n&\\leq 2(2L_gD + (t + 1)\\omega \\frac{3\\omega - 1}{\\sigma_g})^2\n\\end{align*}\n$$", "md": "where we used the fact that $$(k + 1)\\omega - 1 \\leq k\\omega$$ in the last inequality. By using the above inequality, we can bound $$\\|\\zeta_1\\|$$ as follows:\n\n$$\n\\begin{align*}\n\\|\\zeta_1\\| &= t(1 - \\beta k)\\|e_1\\| \\\\\n&\\leq 2\\omega [g(x_1, \\xi_1) - \\nabla g(x_1)\\| \\\\\n&= 2\\omega \\sigma_1 \\|\\nabla\\tilde{g}(x_1, \\xi_1) - \\nabla g(x_1)\\|\n\\end{align*}\n$$\n\nDefine $$c_1 = \\frac{(t+1)\\omega}{\\sigma_g}$$. Then by Assumption 2.3(ii) we have $$E[\\exp (\\|\\zeta_1\\|^2/c_1)] \\leq \\exp(1)$$. Moreover, for $$\\tau > 1$$, by triangle inequality, $$\\|\\zeta_{\\tau}\\|$$ can be bounded by\n\n$$\n\\begin{align*}\n\\|\\zeta_{\\tau}\\| &\\leq (1 - \\beta k)(\\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla\\tilde{g}(x_{\\tau-1}, \\xi_{\\tau})\\| + \\|\\nabla g(x_{\\tau}) - \\nabla g(x_{\\tau-1})\\|) \\\\\n&+ \\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k)\\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\| \\\\\n&\\leq 2L_g\\|x_{\\tau} - t x_{\\tau-1}\\| \\sum_{k=\\tau}^{t} (1 - \\beta k) + \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k) \\\\\n&= 2L_g\\gamma_{\\tau} D \\sum_{k=\\tau}^{t} (1 - \\beta k) + \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau+1}^{t} (1 - \\beta k) \\\\\n&\\leq 2L_gD\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) + 3\\omega - 3\\omega \\frac{1}{\\sigma_g} \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) \\\\\n&= 2L_gD + 3\\omega - 3\\omega \\frac{1}{\\sigma_g} \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k) \\\\\n&= 2L_gD + 3\\omega\\sigma_g \\|\\nabla\\tilde{g}(x_{\\tau}, \\xi_{\\tau}) - \\nabla g(x_{\\tau})\\|\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k)\n\\end{align*}\n$$\n\nDefine $$c_{\\tau} = \\left(2L_gD + 3\\omega\\sigma_g \\frac{3\\omega - 1}{\\sigma_g}\\right)\\beta_{\\tau} \\sum_{k=\\tau}^{t} (1 - \\beta k)$$. Note that if we have $$E[\\exp(X_1^2/c_1^2)] \\leq 1$$ and $$E[\\exp(X_2^2/c_2^2)] \\leq 1$$, then we have $$E[\\exp((X_1 + X_2)^2/(c_1 + c_2)^2)] \\leq 1$$ [Ver18]. Thus, we have $$E[\\exp (\\|\\zeta_{\\tau}\\|^2/c_{\\tau})] \\leq \\exp(1)$$ for all $$1 \\leq \\tau \\leq t$$. Hence by proposition E.2, with probability $$1 - \\delta$$ where $$c$$ is an absolute constant, $$d$$ is the number of dimensions, and $$T \\|\\mathbf{e}_t\\| \\leq c \\cdot \\sum_{\\tau=1}^{t} c_{2\\tau} \\log 2d \\delta' \\sum_{\\tau=1} c_{2\\tau}$$ can be bounded by\n\nLemma B.1 as follows,\n\n$$\n\\begin{align*}\n\\sum_{\\tau=1}^{t} c_{2\\tau} &= c_2^1 + \\sum_{\\tau=2} c_{2\\tau} \\\\\n&= 22\\omega\\sigma_g^2 + (T+1)^2\\omega + (2L_gD + 3\\omega - 1 \\sigma_g)^2 \\sum_{\\tau=2} \\sum_{k=\\tau} \\\\\n&\\leq 22\\omega\\sigma_g^2 (2L_gD + 3\\omega - 1 \\sigma_g)^2 \\\\\n&\\leq ((2\\omega\\sigma_g)^2 + (2L_gD + 3\\omega - 1 \\sigma_g)^2) (t + 1)\\omega \\\\\n&\\leq 2(2L_gD + (t + 1)\\omega \\frac{3\\omega - 1}{\\sigma_g})^2\n\\end{align*}\n$$"}]}, {"page": 21, "text": "where the last inequality follows from the fact that (                                   \u221a  2)\u03c9 \u2264      \u20323\u03c9/(3\u03c9 \u2212        1) for any \u03c9 \u2208             (0, 1].\nCombining (26) and (27), we have with probability at least 1 \u2212                                       \u03b4  ,\n                    \u2225\u2207g(xt) \u2212                      \u221a                      3\u03c9                                             \u2032) def\n                                     \u2207gt\u2225     \u2264   c   2(2LgD + \u2032       3\u03c9 \u2212     1\u03c3g)(t + 1)\u2212\u03c9/2             log(2d/\u03b4         = K1,t                  (28)\nSimilarly with probability at least 1 \u2212                      \u03b4  ,\n                        |g(xt) \u2212      \u02c6         \u221a  2(2LlD +            3\u03c9                              log(2d/\u03b4      \u2032) def\n                                      gt| \u2264    c       \u2032           3\u03c9 \u2212     1\u03c3l)(t + 1)\u2212\u03c9/2                             = K0,t                       (29)\nand with probability at least 1 \u2212                  \u221a \u03b4  ,                  3\u03c9                                            \u2032 ) def\n                   \u2225\u2207f(xt) \u2212         \u2207ft\u2225     \u2264   c   2(2LfD +          3\u03c9 \u2212    1\u03c3f)(t + 1)\u2212\u03c9/2             log(2d/\u03b4         = K2,t                  (30)\nwhere c is an absolute constant and d is the dimension of vectors. We can use union bound to\nobtain that these three inequalities hold for at least probability 1 \u2212                                      3\u03b4 \u2032 = 1 \u2212     \u03b4. For simplicity, we\ndefine constant A\u03c9          1 and A\u03c9     0 such that,\n                    A\u03c91 (t + 1)\u2212\u03c9/2          log(6d/\u03b4) = K1,t              and      A\u03c9 0 (t + 1)\u2212\u03c9/2          log(6d/\u03b4) = K0,t                       (31)\nand similarly A\u03c9         2 (t + 1)\u2212\u03c9/2          log(6d/\u03b4) = K2,t.\nB.2        Proof of Lemma 4.2\nProof. Let us define t0 \u225c                  \u230at/q\u230b    for any t \u2208         {0, . . . , T \u2212    1}, then whenever t = t0q according to\nthe Algorithm 2 a full batch of sample gradients are selected, hence,                                        \u2207gt = \u2207g(xt); otherwise, the\nerror of computing a sample gradient can be expressed as follows\n                                \u01ebt,i = 1  S (\u2207gS(i)(xt) \u2212          \u2207gS(i)(xt\u22121) \u2212          \u2207g(xt) + \u2207g(xt\u22121)),                                       (32)\nwhere i is the index with S(i) denoting the i-th random component function selected at iteration\nt. Furthermore, from the update rule of xt we have \u2225xt \u2212                                      xt\u22121\u2225     = \u03b3t\u2225st\u22121 \u2212         xt\u22121\u2225     \u2264   D\u03b3 for any\nt \u2265   0, therefore,            \u2225\u01ebt,i\u2225   \u2264    1\n                                             S (\u2225\u2207gi(xt) \u2212         \u2207gi(xt\u22121)\u2225        + \u2225\u2207g(xt) \u2212          \u2207g(xt\u22121)\u2225)                                 (33)\n                                        \u2264    2Lg                                      ,\n                                              S \u2225xt \u2212        xt\u22121\u2225    \u2264   2LgD\u03b3S\nfor all t \u2208      {t0 + 1, . . . , t0 + q} and i \u2208            {1, . . . , S}. On the other hand, from the update of                            \u2207gt and\n(32) we have that for any t \u0338= t0q,                     \u2207gt \u2212      \u2207g(xt) =         \u2207gt\u22121 \u2212       \u2207g(xt\u22121) +  S          i=1 \u01ebt,i. Therefore, by\ncontinuing the recursive relation and taking the norm from both sides of the equality we obtain\n                                                                                                        t      S\n                                  \u2225 \u2207gt \u2212     \u2207g(xt)\u2225       = \u2225   \u2207g(xt0) \u2212        \u2207g(xt0) +       j=t0+1     i=1  \u01ebj,i\u2225                             (34)\n                                                                       t      S\n                                                            = \u2225   j=t0+1     i=1  \u01ebj,i\u2225,\n                                                                            21", "md": "where the last inequality follows from the fact that $$ (\\sqrt{2})^\\omega \\leq \\frac{3^\\omega}{3^\\omega - 1} $$ for any $$ \\omega \\in (0, 1] $$.\n\nCombining (26) and (27), we have with probability at least $$ 1 - \\delta $$,\n\n$$\n\\| \\nabla g(x_t) - \\sqrt{3\\omega} \\nabla g_t \\| \\leq c2(2LgD + \\sqrt{3\\omega} - 1\\sigma_g)(t + 1)^{-\\omega/2} \\log(2d/\\delta) = K_{1,t} \\tag{28}\n$$\n\nSimilarly with probability at least $$ 1 - \\delta $$,\n\n$$\n|g(x_t) - \\hat{\\sqrt{2}}(2LlD + \\sqrt{3\\omega} \\log(2d/\\delta) g_t| \\leq c\\sqrt{3\\omega} - 1\\sigma_l)(t + 1)^{-\\omega/2} = K_{0,t} \\tag{29}\n$$\n\nand with probability at least $$ 1 - \\sqrt{\\delta} $$,\n\n$$\n\\| \\nabla f(x_t) - \\nabla f_t \\| \\leq c2(2LfD + \\sqrt{3\\omega} - 1\\sigma_f)(t + 1)^{-\\omega/2} \\log(2d/\\delta) = K_{2,t} \\tag{30}\n$$\n\nwhere c is an absolute constant and d is the dimension of vectors. We can use union bound to obtain that these three inequalities hold for at least probability $$ 1 - 3\\delta' = 1 - \\delta $$. For simplicity, we define constant $$ A^\\omega_1 $$ and $$ A^\\omega_0 $$ such that,\n\n$$\nA^\\omega_1(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{1,t} \\text{ and } A^\\omega_0(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{0,t} \\tag{31}\n$$\n\nand similarly $$ A^\\omega_2(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{2,t} $$.\n\n## Proof of Lemma 4.2\n\nProof. Let us define $$ t_0 \\triangleq \\left\\lfloor \\frac{t}{q} \\right\\rfloor $$ for any $$ t \\in \\{0, ..., T - 1\\} $$, then whenever $$ t = t_0q $$ according to the Algorithm 2 a full batch of sample gradients are selected, hence, $$ \\nabla g_t = \\nabla g(x_t) $$; otherwise, the error of computing a sample gradient can be expressed as follows\n\n$$\n\\epsilon_{t,i} = \\frac{1}{S} (\\nabla g_{S(i)}(x_t) - \\nabla g_{S(i)}(x_{t-1}) - \\nabla g(x_t) + \\nabla g(x_{t-1})), \\tag{32}\n$$\n\nwhere i is the index with S(i) denoting the i-th random component function selected at iteration t. Furthermore, from the update rule of $$ x_t $$ we have $$ \\|x_t - x_{t-1}\\| = \\gamma_t \\|s_{t-1} - x_{t-1}\\| \\leq D\\gamma $$ for any $$ t \\geq 0 $$, therefore,\n\n$$\n\\| \\epsilon_{t,i} \\| \\leq \\frac{1}{S} (\\| \\nabla g_i(x_t) - \\nabla g_i(x_{t-1}) \\| + \\| \\nabla g(x_t) - \\nabla g(x_{t-1}) \\|) \\leq 2Lg \\leq 2LgD\\gamma S\n$$\n\nfor all $$ t \\in \\{t_0 + 1, ..., t_0 + q\\} $$ and $$ i \\in \\{1, ..., S\\} $$. On the other hand, from the update of $$ \\nabla g_t $$ and (32) we have that for any $$ t \\neq t_0q $$,\n\n$$\n\\nabla g_t - \\nabla g(x_t) = \\nabla g_{t-1} - \\nabla g(x_{t-1}) + \\sum_{i=1}^{S} \\epsilon_{t,i}.\n$$\n\nTherefore, by continuing the recursive relation and taking the norm from both sides of the equality we obtain\n\n$$\n\\| \\nabla g_t - \\nabla g(x_t) \\| = \\| \\sum_{j=t_0+1}^{t} \\sum_{i=1}^{S} \\epsilon_{j,i} \\| = \\| \\sum_{j=t_0+1}^{t} \\sum_{i=1}^{S} \\epsilon_{j,i} \\|. \\tag{34}\n$$", "images": [], "items": [{"type": "text", "value": "where the last inequality follows from the fact that $$ (\\sqrt{2})^\\omega \\leq \\frac{3^\\omega}{3^\\omega - 1} $$ for any $$ \\omega \\in (0, 1] $$.\n\nCombining (26) and (27), we have with probability at least $$ 1 - \\delta $$,\n\n$$\n\\| \\nabla g(x_t) - \\sqrt{3\\omega} \\nabla g_t \\| \\leq c2(2LgD + \\sqrt{3\\omega} - 1\\sigma_g)(t + 1)^{-\\omega/2} \\log(2d/\\delta) = K_{1,t} \\tag{28}\n$$\n\nSimilarly with probability at least $$ 1 - \\delta $$,\n\n$$", "md": "where the last inequality follows from the fact that $$ (\\sqrt{2})^\\omega \\leq \\frac{3^\\omega}{3^\\omega - 1} $$ for any $$ \\omega \\in (0, 1] $$.\n\nCombining (26) and (27), we have with probability at least $$ 1 - \\delta $$,\n\n$$\n\\| \\nabla g(x_t) - \\sqrt{3\\omega} \\nabla g_t \\| \\leq c2(2LgD + \\sqrt{3\\omega} - 1\\sigma_g)(t + 1)^{-\\omega/2} \\log(2d/\\delta) = K_{1,t} \\tag{28}\n$$\n\nSimilarly with probability at least $$ 1 - \\delta $$,\n\n$$"}, {"type": "table", "rows": [["g(x_t) - \\hat{\\sqrt{2}}(2LlD + \\sqrt{3\\omega} \\log(2d/\\delta) g_t"]], "md": "|g(x_t) - \\hat{\\sqrt{2}}(2LlD + \\sqrt{3\\omega} \\log(2d/\\delta) g_t| \\leq c\\sqrt{3\\omega} - 1\\sigma_l)(t + 1)^{-\\omega/2} = K_{0,t} \\tag{29}", "isPerfectTable": true, "csv": "\"g(x_t) - \\hat{\\sqrt{2}}(2LlD + \\sqrt{3\\omega} \\log(2d/\\delta) g_t\""}, {"type": "text", "value": "$$\n\nand with probability at least $$ 1 - \\sqrt{\\delta} $$,\n\n$$\n\\| \\nabla f(x_t) - \\nabla f_t \\| \\leq c2(2LfD + \\sqrt{3\\omega} - 1\\sigma_f)(t + 1)^{-\\omega/2} \\log(2d/\\delta) = K_{2,t} \\tag{30}\n$$\n\nwhere c is an absolute constant and d is the dimension of vectors. We can use union bound to obtain that these three inequalities hold for at least probability $$ 1 - 3\\delta' = 1 - \\delta $$. For simplicity, we define constant $$ A^\\omega_1 $$ and $$ A^\\omega_0 $$ such that,\n\n$$\nA^\\omega_1(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{1,t} \\text{ and } A^\\omega_0(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{0,t} \\tag{31}\n$$\n\nand similarly $$ A^\\omega_2(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{2,t} $$.", "md": "$$\n\nand with probability at least $$ 1 - \\sqrt{\\delta} $$,\n\n$$\n\\| \\nabla f(x_t) - \\nabla f_t \\| \\leq c2(2LfD + \\sqrt{3\\omega} - 1\\sigma_f)(t + 1)^{-\\omega/2} \\log(2d/\\delta) = K_{2,t} \\tag{30}\n$$\n\nwhere c is an absolute constant and d is the dimension of vectors. We can use union bound to obtain that these three inequalities hold for at least probability $$ 1 - 3\\delta' = 1 - \\delta $$. For simplicity, we define constant $$ A^\\omega_1 $$ and $$ A^\\omega_0 $$ such that,\n\n$$\nA^\\omega_1(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{1,t} \\text{ and } A^\\omega_0(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{0,t} \\tag{31}\n$$\n\nand similarly $$ A^\\omega_2(t + 1)^{-\\omega/2} \\log(6d/\\delta) = K_{2,t} $$."}, {"type": "heading", "lvl": 2, "value": "Proof of Lemma 4.2", "md": "## Proof of Lemma 4.2"}, {"type": "text", "value": "Proof. Let us define $$ t_0 \\triangleq \\left\\lfloor \\frac{t}{q} \\right\\rfloor $$ for any $$ t \\in \\{0, ..., T - 1\\} $$, then whenever $$ t = t_0q $$ according to the Algorithm 2 a full batch of sample gradients are selected, hence, $$ \\nabla g_t = \\nabla g(x_t) $$; otherwise, the error of computing a sample gradient can be expressed as follows\n\n$$\n\\epsilon_{t,i} = \\frac{1}{S} (\\nabla g_{S(i)}(x_t) - \\nabla g_{S(i)}(x_{t-1}) - \\nabla g(x_t) + \\nabla g(x_{t-1})), \\tag{32}\n$$\n\nwhere i is the index with S(i) denoting the i-th random component function selected at iteration t. Furthermore, from the update rule of $$ x_t $$ we have $$ \\|x_t - x_{t-1}\\| = \\gamma_t \\|s_{t-1} - x_{t-1}\\| \\leq D\\gamma $$ for any $$ t \\geq 0 $$, therefore,\n\n$$\n\\| \\epsilon_{t,i} \\| \\leq \\frac{1}{S} (\\| \\nabla g_i(x_t) - \\nabla g_i(x_{t-1}) \\| + \\| \\nabla g(x_t) - \\nabla g(x_{t-1}) \\|) \\leq 2Lg \\leq 2LgD\\gamma S\n$$\n\nfor all $$ t \\in \\{t_0 + 1, ..., t_0 + q\\} $$ and $$ i \\in \\{1, ..., S\\} $$. On the other hand, from the update of $$ \\nabla g_t $$ and (32) we have that for any $$ t \\neq t_0q $$,\n\n$$\n\\nabla g_t - \\nabla g(x_t) = \\nabla g_{t-1} - \\nabla g(x_{t-1}) + \\sum_{i=1}^{S} \\epsilon_{t,i}.\n$$\n\nTherefore, by continuing the recursive relation and taking the norm from both sides of the equality we obtain\n\n$$\n\\| \\nabla g_t - \\nabla g(x_t) \\| = \\| \\sum_{j=t_0+1}^{t} \\sum_{i=1}^{S} \\epsilon_{j,i} \\| = \\| \\sum_{j=t_0+1}^{t} \\sum_{i=1}^{S} \\epsilon_{j,i} \\|. \\tag{34}\n$$", "md": "Proof. Let us define $$ t_0 \\triangleq \\left\\lfloor \\frac{t}{q} \\right\\rfloor $$ for any $$ t \\in \\{0, ..., T - 1\\} $$, then whenever $$ t = t_0q $$ according to the Algorithm 2 a full batch of sample gradients are selected, hence, $$ \\nabla g_t = \\nabla g(x_t) $$; otherwise, the error of computing a sample gradient can be expressed as follows\n\n$$\n\\epsilon_{t,i} = \\frac{1}{S} (\\nabla g_{S(i)}(x_t) - \\nabla g_{S(i)}(x_{t-1}) - \\nabla g(x_t) + \\nabla g(x_{t-1})), \\tag{32}\n$$\n\nwhere i is the index with S(i) denoting the i-th random component function selected at iteration t. Furthermore, from the update rule of $$ x_t $$ we have $$ \\|x_t - x_{t-1}\\| = \\gamma_t \\|s_{t-1} - x_{t-1}\\| \\leq D\\gamma $$ for any $$ t \\geq 0 $$, therefore,\n\n$$\n\\| \\epsilon_{t,i} \\| \\leq \\frac{1}{S} (\\| \\nabla g_i(x_t) - \\nabla g_i(x_{t-1}) \\| + \\| \\nabla g(x_t) - \\nabla g(x_{t-1}) \\|) \\leq 2Lg \\leq 2LgD\\gamma S\n$$\n\nfor all $$ t \\in \\{t_0 + 1, ..., t_0 + q\\} $$ and $$ i \\in \\{1, ..., S\\} $$. On the other hand, from the update of $$ \\nabla g_t $$ and (32) we have that for any $$ t \\neq t_0q $$,\n\n$$\n\\nabla g_t - \\nabla g(x_t) = \\nabla g_{t-1} - \\nabla g(x_{t-1}) + \\sum_{i=1}^{S} \\epsilon_{t,i}.\n$$\n\nTherefore, by continuing the recursive relation and taking the norm from both sides of the equality we obtain\n\n$$\n\\| \\nabla g_t - \\nabla g(x_t) \\| = \\| \\sum_{j=t_0+1}^{t} \\sum_{i=1}^{S} \\epsilon_{j,i} \\| = \\| \\sum_{j=t_0+1}^{t} \\sum_{i=1}^{S} \\epsilon_{j,i} \\|. \\tag{34}\n$$"}]}, {"page": 22, "text": "where the last equality follows from                    \u2207g(xt0) = \u2207g(xt0). Then by Proposition E.1, we have\n                                                                                 \u03bb2                                      \u03bb2\n                 P(\u2225  \u2207gt \u2212      \u2207g(xt)\u2225      \u2265   \u03bb) \u2264    4 exp(\u2212                    4L2gD2\u03b32    ) \u2264   4 exp(\u2212     16L2  gD2\u03b32 ),               (35)\nwhere the last inequality follows from the fact S = \u221an and t \u2212        4S(t \u2212     t0)     S2           t0 \u2264    q = \u221an. By setting \u03bb =\n(4LgD\u03b3          log(4/\u03b4   \u2032 )) for some \u03b4      \u2032 \u2208  (0, 1), we have with probability at least 1 \u2212                       \u03b4\u2032,\n                                               \u2225\u2207gt \u2212     \u2207g(xt)\u2225       \u2264  4LgD\u03b3          log(4/\u03b4   \u2032).                                         (36)\n                                                              \u2032\nSimilarly, with probability at least 1 \u2212           |\u02c6       \u03b4  ,                      log(4/\u03b4   \u2032),\n                                         \u2032          gt \u2212   g(xt)| \u2264     4LlD\u03b3                                                                   (37)\nand with probability 1 \u2212               \u03b4  ,   \u2225 \u2207ft\u2032\u2212     \u2207f(xt)\u2225       \u2264   4LfD\u03b3         log(4/\u03b4    \u2032).                                        (38)\nThen by union bound and \u03b4 = 3\u03b4                      , we show these three equalities hold with probability 1 \u2212                               \u03b4.\nB.3        Proof of Lemma 4.3\nProof. Let x\u2217      g be any point in X \u2217       g , i.e., any optimal solution of the lower-level problem. By definition,\nwe have g         x\u2217g   = g\u2217. Since g is convex and g\u2217                 \u2264   g (x0), we have\n                         g (x0) \u2212     g (xt) \u2265     g\u2217  \u2212  g (xt) = g       x\u2217g   \u2212   g (xt) \u2265      \u2207g (xt) , x\u2217    g \u2212   xt                     (39)\nAdd and subtract terms in (47), we have,\n                       \u27e8\u2207gt, x\u2217   g \u2212   xt\u27e9  + \u02c6 gt \u2212   g(x0) \u2264     |\u27e8 \u2207gt \u2212     \u2207g(xt), x\u2217    g \u2212   xt\u27e9| + |\u02c6  gt \u2212   g(xt)|                   (40)\nConsidering the random hyperplane we used in (9), we want to prove the following inequality holds\nwith high probability,\n                                                   \u27e8\u2207gt, x\u2217  g \u2212   xt\u27e9   + \u02c6gt \u2212   g(x0) \u2264      Kt                                              (41)\nRecall Kt = K0,t + DK1,t. And K0,t and K1,t were set as the high probability bounds of \u2225                                                     \u2207gt \u2212\n\u2207g(xt)\u2225       and |\u02c6   gt \u2212   g(xt)| in Lemma 4.1 for Algorithm 1 or Lemma 4.2 for Algorithm 2.                                               Then\ncompare the two inequalities above and use Jensen\u2019s inequality, |\u27e8                                  \u2207gt, x\u2217   g \u2212  xt\u27e9| + |\u02c6 gt \u2212   g(x0)| \u2264      Kt\nholds with high probability 1 \u2212                  \u03b4 for all t \u2265      0. Hence, Lemma 4.3 holds with probability 1 \u2212                             \u03b4 for\nall t \u2265    0.\nB.4        Improvement in one step\nThe following lemma characterizes the improvement of both the upper-level and lower-level objec-\ntive values after one step of the algorithms.\nLemma B.2. If Assumptions 2.1, 2.2, 2.3 are satisfi                               ed,\n                                                                          22", "md": "# Math Equations\n\nwhere the last equality follows from $$\\nabla g(x_{t0}) = \\nabla g(x_{t0})$$. Then by Proposition E.1, we have\n\n$$P\\left(\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\| \\geq \\lambda\\right) \\leq 4 \\exp\\left(-\\frac{\\lambda^2}{4L^2gD^2\\gamma^2}\\right) \\leq 4 \\exp\\left(-\\frac{16L^2gD^2\\gamma^2}{\\lambda^2}\\right)$$, (35)\n\nwhere the last inequality follows from the fact S = \u221an and $$t - 4S(t - t_{0}) \\leq S^2 t_{0} \\leq q = \\sqrt{n}$$. By setting $$\\lambda = (4LgD\\gamma) \\log\\left(\\frac{4}{\\delta'}\\right)$$ for some $$\\delta' \\in (0, 1)$$, we have with probability at least $$1 - \\delta'$$,\n\n$$\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\| \\leq 4LgD\\gamma \\log\\left(\\frac{4}{\\delta'}\\right)$$. (36)\n\nSimilarly, with probability at least $$1 - \\delta'$$,\n\n$$\\left| \\hat{\\delta}, g_{t} - g(x_{t}) \\right| \\leq 4LlD\\gamma$$. (37)\n\nand with probability $$1 - \\delta$$,\n\n$$\\left\\| \\nabla f_{t'} - \\nabla f(x_{t}) \\right\\| \\leq 4LfD\\gamma \\log\\left(\\frac{4}{\\delta'}\\right)$$. (38)\n\nThen by union bound and $$\\delta = 3\\delta'$$, we show these three equalities hold with probability $$1 - \\delta$$.\n\nProof of Lemma 4.3\n\nProof. Let $$x^{*}_{g}$$ be any point in $$X^{*}_{g}$$, i.e., any optimal solution of the lower-level problem. By definition, we have $$g(x^{*}_{g}) = g^{*}$$. Since g is convex and $$g^{*} \\leq g(x_{0})$$, we have\n\n$$g(x_{0}) - g(x_{t}) \\geq g^{*} - g(x_{t}) = \\langle \\nabla g(x_{t}), x^{*}_{g} - x_{t} \\rangle$$. (39)\n\nAdd and subtract terms in (47), we have,\n\n$$\\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle + \\hat{g}_{t} - g(x_{0}) \\leq \\left| \\langle \\nabla g_{t} - \\nabla g(x_{t}), x^{*}_{g} - x_{t} \\rangle \\right| + \\left| \\hat{g}_{t} - g(x_{t}) \\right|$$. (40)\n\nConsidering the random hyperplane we used in (9), we want to prove the following inequality holds with high probability,\n\n$$\\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle + \\hat{g}_{t} - g(x_{0}) \\leq K_{t}$$. (41)\n\nRecall $$K_{t} = K_{0,t} + DK_{1,t}$$. And $$K_{0,t}$$ and $$K_{1,t}$$ were set as the high probability bounds of $$\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\|$$ and $$\\left| \\hat{g}_{t} - g(x_{t}) \\right|$$ in Lemma 4.1 for Algorithm 1 or Lemma 4.2 for Algorithm 2. Then compare the two inequalities above and use Jensen\u2019s inequality, $$\\left| \\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle \\right| + \\left| \\hat{g}_{t} - g(x_{0}) \\right| \\leq K_{t}$$ holds with high probability $$1 - \\delta$$ for all $$t \\geq 0$$. Hence, Lemma 4.3 holds with probability $$1 - \\delta$$ for all $$t \\geq 0$$.\n\nImprovement in one step\n\nThe following lemma characterizes the improvement of both the upper-level and lower-level objective values after one step of the algorithms.\n\nLemma B.2. If Assumptions 2.1, 2.2, 2.3 are satisfied,", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations", "md": "# Math Equations"}, {"type": "text", "value": "where the last equality follows from $$\\nabla g(x_{t0}) = \\nabla g(x_{t0})$$. Then by Proposition E.1, we have\n\n$$P\\left(\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\| \\geq \\lambda\\right) \\leq 4 \\exp\\left(-\\frac{\\lambda^2}{4L^2gD^2\\gamma^2}\\right) \\leq 4 \\exp\\left(-\\frac{16L^2gD^2\\gamma^2}{\\lambda^2}\\right)$$, (35)\n\nwhere the last inequality follows from the fact S = \u221an and $$t - 4S(t - t_{0}) \\leq S^2 t_{0} \\leq q = \\sqrt{n}$$. By setting $$\\lambda = (4LgD\\gamma) \\log\\left(\\frac{4}{\\delta'}\\right)$$ for some $$\\delta' \\in (0, 1)$$, we have with probability at least $$1 - \\delta'$$,\n\n$$\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\| \\leq 4LgD\\gamma \\log\\left(\\frac{4}{\\delta'}\\right)$$. (36)\n\nSimilarly, with probability at least $$1 - \\delta'$$,\n\n$$\\left| \\hat{\\delta}, g_{t} - g(x_{t}) \\right| \\leq 4LlD\\gamma$$. (37)\n\nand with probability $$1 - \\delta$$,\n\n$$\\left\\| \\nabla f_{t'} - \\nabla f(x_{t}) \\right\\| \\leq 4LfD\\gamma \\log\\left(\\frac{4}{\\delta'}\\right)$$. (38)\n\nThen by union bound and $$\\delta = 3\\delta'$$, we show these three equalities hold with probability $$1 - \\delta$$.\n\nProof of Lemma 4.3\n\nProof. Let $$x^{*}_{g}$$ be any point in $$X^{*}_{g}$$, i.e., any optimal solution of the lower-level problem. By definition, we have $$g(x^{*}_{g}) = g^{*}$$. Since g is convex and $$g^{*} \\leq g(x_{0})$$, we have\n\n$$g(x_{0}) - g(x_{t}) \\geq g^{*} - g(x_{t}) = \\langle \\nabla g(x_{t}), x^{*}_{g} - x_{t} \\rangle$$. (39)\n\nAdd and subtract terms in (47), we have,\n\n$$\\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle + \\hat{g}_{t} - g(x_{0}) \\leq \\left| \\langle \\nabla g_{t} - \\nabla g(x_{t}), x^{*}_{g} - x_{t} \\rangle \\right| + \\left| \\hat{g}_{t} - g(x_{t}) \\right|$$. (40)\n\nConsidering the random hyperplane we used in (9), we want to prove the following inequality holds with high probability,\n\n$$\\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle + \\hat{g}_{t} - g(x_{0}) \\leq K_{t}$$. (41)\n\nRecall $$K_{t} = K_{0,t} + DK_{1,t}$$. And $$K_{0,t}$$ and $$K_{1,t}$$ were set as the high probability bounds of $$\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\|$$ and $$\\left| \\hat{g}_{t} - g(x_{t}) \\right|$$ in Lemma 4.1 for Algorithm 1 or Lemma 4.2 for Algorithm 2. Then compare the two inequalities above and use Jensen\u2019s inequality, $$\\left| \\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle \\right| + \\left| \\hat{g}_{t} - g(x_{0}) \\right| \\leq K_{t}$$ holds with high probability $$1 - \\delta$$ for all $$t \\geq 0$$. Hence, Lemma 4.3 holds with probability $$1 - \\delta$$ for all $$t \\geq 0$$.\n\nImprovement in one step\n\nThe following lemma characterizes the improvement of both the upper-level and lower-level objective values after one step of the algorithms.\n\nLemma B.2. If Assumptions 2.1, 2.2, 2.3 are satisfied,", "md": "where the last equality follows from $$\\nabla g(x_{t0}) = \\nabla g(x_{t0})$$. Then by Proposition E.1, we have\n\n$$P\\left(\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\| \\geq \\lambda\\right) \\leq 4 \\exp\\left(-\\frac{\\lambda^2}{4L^2gD^2\\gamma^2}\\right) \\leq 4 \\exp\\left(-\\frac{16L^2gD^2\\gamma^2}{\\lambda^2}\\right)$$, (35)\n\nwhere the last inequality follows from the fact S = \u221an and $$t - 4S(t - t_{0}) \\leq S^2 t_{0} \\leq q = \\sqrt{n}$$. By setting $$\\lambda = (4LgD\\gamma) \\log\\left(\\frac{4}{\\delta'}\\right)$$ for some $$\\delta' \\in (0, 1)$$, we have with probability at least $$1 - \\delta'$$,\n\n$$\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\| \\leq 4LgD\\gamma \\log\\left(\\frac{4}{\\delta'}\\right)$$. (36)\n\nSimilarly, with probability at least $$1 - \\delta'$$,\n\n$$\\left| \\hat{\\delta}, g_{t} - g(x_{t}) \\right| \\leq 4LlD\\gamma$$. (37)\n\nand with probability $$1 - \\delta$$,\n\n$$\\left\\| \\nabla f_{t'} - \\nabla f(x_{t}) \\right\\| \\leq 4LfD\\gamma \\log\\left(\\frac{4}{\\delta'}\\right)$$. (38)\n\nThen by union bound and $$\\delta = 3\\delta'$$, we show these three equalities hold with probability $$1 - \\delta$$.\n\nProof of Lemma 4.3\n\nProof. Let $$x^{*}_{g}$$ be any point in $$X^{*}_{g}$$, i.e., any optimal solution of the lower-level problem. By definition, we have $$g(x^{*}_{g}) = g^{*}$$. Since g is convex and $$g^{*} \\leq g(x_{0})$$, we have\n\n$$g(x_{0}) - g(x_{t}) \\geq g^{*} - g(x_{t}) = \\langle \\nabla g(x_{t}), x^{*}_{g} - x_{t} \\rangle$$. (39)\n\nAdd and subtract terms in (47), we have,\n\n$$\\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle + \\hat{g}_{t} - g(x_{0}) \\leq \\left| \\langle \\nabla g_{t} - \\nabla g(x_{t}), x^{*}_{g} - x_{t} \\rangle \\right| + \\left| \\hat{g}_{t} - g(x_{t}) \\right|$$. (40)\n\nConsidering the random hyperplane we used in (9), we want to prove the following inequality holds with high probability,\n\n$$\\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle + \\hat{g}_{t} - g(x_{0}) \\leq K_{t}$$. (41)\n\nRecall $$K_{t} = K_{0,t} + DK_{1,t}$$. And $$K_{0,t}$$ and $$K_{1,t}$$ were set as the high probability bounds of $$\\left\\| \\nabla g_{t} - \\nabla g(x_{t}) \\right\\|$$ and $$\\left| \\hat{g}_{t} - g(x_{t}) \\right|$$ in Lemma 4.1 for Algorithm 1 or Lemma 4.2 for Algorithm 2. Then compare the two inequalities above and use Jensen\u2019s inequality, $$\\left| \\langle \\nabla g_{t}, x^{*}_{g} - x_{t} \\rangle \\right| + \\left| \\hat{g}_{t} - g(x_{0}) \\right| \\leq K_{t}$$ holds with high probability $$1 - \\delta$$ for all $$t \\geq 0$$. Hence, Lemma 4.3 holds with probability $$1 - \\delta$$ for all $$t \\geq 0$$.\n\nImprovement in one step\n\nThe following lemma characterizes the improvement of both the upper-level and lower-level objective values after one step of the algorithms.\n\nLemma B.2. If Assumptions 2.1, 2.2, 2.3 are satisfied,"}]}, {"page": 23, "text": " (i) For all t \u2265         0, assume that X \u2217         g \u2282   Xt. Then we have\n                            \u03b3t+1G(xt) \u2264         f(xt) \u2212      f(xt+1) + \u03b3t+1D\u2225\u2207f(xt) \u2212                    \u2207ft\u2225     + LfD2\u03b32   2   t+1                 (42)\n       As a corollary, if f is convex, we further have\n(ii) We have        f(xt+1) \u2212       f \u2217  \u2264   (1 \u2212   \u03b3t+1)(f(xt) \u2212         f \u2217)) + \u03b3t+1D\u2225\u2207f(xt) \u2212                 \u2207ft\u2225    + LfD2\u03b32   2   t+1  .       (43)\n          g(xt+1) \u2212       g(x0) \u2264      (1 \u2212    \u03b3t+1)(g(xt) \u2212         g(x0)) + D\u03b3t+1(\u2225\u2207g(xt) \u2212                   \u2207gt\u2225    + K1,t)             t+1\n                                                                                  + \u03b3t+1(\u2225g(xt) \u2212           \u02c6\nProof. (i) Based on the Lf-smoothness of the expected function f we show that f(xt+1) is bounded            gt\u2225  + K0,t) + LgD2\u03b32       2        .   (44)\nby\n                                 f(xt+1) \u2264       f(xt) + \u2207f(xt)\u22a4(xt+1 \u2212                  xt) + Lf  2 \u2225xt+1 \u2212        xt\u22252               T             (45)\nReplace the terms xt+1 \u2212                  xt by \u03b3t+1(st \u2212          xt) and add and subtract the term \u03b3t+1                         \u2207ft (st \u2212       xt) to\nthe right hand side to obtain,\n                                                                                                   \u22a4\n      f(xt+1) \u2264        f(xt) + \u03b3t+1(\u2207f(xt) \u2212               \u2207f t)\u22a4(st \u2212        xt) + \u03b3t+1      \u2207ft (st \u2212       xt) + Lf   2 \u2225xt+1 \u2212       xt\u22252        (46)\nBy Lemma 4.3, X \u2217            g \u2286    Xt with high probability 1 \u2212                   \u03b4, for all t = 1, . . . , T       . Note that if we define\ns\u2032t = arg max       s\u2208Xt{\u27e8\u2207f(xt), xt \u2212             s\u27e9}. Recall that FW gap is G(\u02c6                  x) = maxs\u2208X \u2217       g {\u27e8\u2207f(\u02c6    x), \u02c6x \u2212    s\u27e9}. We\ncan replace the inner product \u27e8                    \u2207f t, st\u27e9    by its upper bound \u27e8              \u2207ft, s\u2032  t\u27e9. Applying this substitution\nleads to\n      f(xt+1) \u2264        f(xt) + \u03b3t+1(\u2207f(xt) \u2212               \u2207f t)\u22a4(st \u2212        xt) + \u03b3t+1           \u22a4\n                                                                                              \u2207ft (s\u2032   t \u2212   xt) + Lf   2 \u2225xt+1 \u2212       xt\u22252\n                   = f(xt) + \u03b3t+1(\u2207f(xt) \u2212                 \u2207f t)\u22a4(st \u2212        xt) + \u03b3t+1(      \u2207ft \u2212      \u2207f(xt))\u22a4(s\u2032       t \u2212   xt)\n                   \u2212  \u03b3t+1\u2207f(xt)\u22a4(xt \u2212              s\u2032\n                                                     t) + Lf  2 \u2225xt+1 \u2212        xt\u22252                                                                  (47)\n                   \u2264   f(xt) + \u03b3t+1(\u2207f(xt) \u2212               \u2207f t)\u22a4(st \u2212        s\u2032t) \u2212   \u03b3t+1G(xt) + Lft+1D2  2 \u2225xt+1 \u2212       xt\u22252\n                   \u2264   f(xt) + \u03b3t+1D\u2225\u2207f(xt) \u2212                  \u2207ft\u2225     \u2212  \u03b3t+1G(xt) + Lf\u03b32           2\nRearrange the terms for the inequality above, we can obtain,\n                                                                                                                         t+1D2\n                        \u03b3t+1G(xt) \u2264         f(xt) \u2212      f(xt+1) + \u03b3t+1D\u2225\u2207f(xt) \u2212                    \u2207ft)\u2225     + Lf\u03b32     2                          (48)\nAs a simple corollary, since G(xt) \u2265                      f(xt) \u2212     f \u2217  when f is convex, we have,\n                 f(xt+1) \u2212       f \u2217  \u2264   (1 \u2212   \u03b3t+1)(f(xt) \u2212          f \u2217)) + \u03b3t+1D\u2225\u2207f(xt) \u2212                \u2207ft\u2225     + LfD2\u03b32   2  t+1             (49)\n                                                                            23", "md": "(i) For all \\( t \\geq 0 \\), assume that \\( X^* \\subseteq g \\subset X_t \\). Then we have\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\quad (42)\n$$\nAs a corollary, if \\( f \\) is convex, we further have\n\n(ii) We have \\( f(x_{t+1}) - f^* \\leq (1 - \\gamma_{t+1})(f(x_t) - f^*)) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\) . (43)\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\| \\nabla g(x_t) - \\nabla g_t \\| + K_{1,t}) \\frac{t+1}{t+1}\n+ \\gamma_{t+1}(\\| g(x_t) - \\hat{g} \\| + K_{0,t}) + LgD^2\\gamma^2 \\frac{2}{t+1} . (44)\n$$\n\nProof. (i) Based on the \\( L_f \\)-smoothness of the expected function \\( f \\) we show that \\( f(x_{t+1}) \\) is bounded by\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\nabla f(x_t)^T(x_{t+1} - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (45)\n$$\n\nReplace the terms \\( x_{t+1} - x_t \\) by \\( \\gamma_{t+1}(s_t - x_t) \\) and add and subtract the term \\( \\gamma_{t+1} \\nabla f_t (s_t - x_t) \\) to the right hand side to obtain,\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1} \\nabla f_t (s_t - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (46)\n$$\n\nBy Lemma 4.3, \\( X^* \\subseteq g \\subset X_t \\) with high probability \\( 1 - \\delta \\), for all \\( t = 1, ..., T \\). Note that if we define\n\n$$\ns'_t = \\arg \\max_{s \\in X_t} \\{ \\langle \\nabla f(x_t), x_t - s \\} \\}. \\text{ Recall that FW gap is } G(\\hat{x}) = \\max_{s \\in X^* g} \\{ \\langle \\nabla f(\\hat{x}), \\hat{x} - s \\} \\}. \\text{ We can replace the inner product } \\langle \\nabla f_t, s_t \\rangle \\text{ by its upper bound } \\langle \\nabla f_t, s'_t \\rangle. \\text{ Applying this substitution leads to}\n$$\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1} \\nabla f_t (s'_t - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2\n$$\n\n$$\n= f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1}(\\nabla f_t - \\nabla f(x_t))^T(s'_t - x_t) - \\gamma_{t+1}\\nabla f(x_t)^T(x_t - s'_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (47)\n$$\n\n$$\n\\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - s'_t) - \\gamma_{t+1}G(x_t) + Lf\\gamma^2 \\frac{2}{t+1}D^2 \\|x_{t+1} - x_t\\|^2\n$$\n\n$$\n\\leq f(x_t) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| - \\gamma_{t+1}G(x_t) + Lf\\gamma^2 \\frac{2}{t+1}D^2\n$$\n\nRearrange the terms for the inequality above, we can obtain,\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + Lf\\gamma^2 \\frac{2}{t+1} \\quad (48)\n$$\n\nAs a simple corollary, since \\( G(x_t) \\geq f(x_t) - f^* \\) when \\( f \\) is convex, we have,\n\n$$\nf(x_{t+1}) - f^* \\leq (1 - \\gamma_{t+1})(f(x_t) - f^*)) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\quad (49)\n$$\n\n23", "images": [], "items": [{"type": "text", "value": "(i) For all \\( t \\geq 0 \\), assume that \\( X^* \\subseteq g \\subset X_t \\). Then we have\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\quad (42)\n$$\nAs a corollary, if \\( f \\) is convex, we further have\n\n(ii) We have \\( f(x_{t+1}) - f^* \\leq (1 - \\gamma_{t+1})(f(x_t) - f^*)) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\) . (43)\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\| \\nabla g(x_t) - \\nabla g_t \\| + K_{1,t}) \\frac{t+1}{t+1}\n+ \\gamma_{t+1}(\\| g(x_t) - \\hat{g} \\| + K_{0,t}) + LgD^2\\gamma^2 \\frac{2}{t+1} . (44)\n$$\n\nProof. (i) Based on the \\( L_f \\)-smoothness of the expected function \\( f \\) we show that \\( f(x_{t+1}) \\) is bounded by\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\nabla f(x_t)^T(x_{t+1} - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (45)\n$$\n\nReplace the terms \\( x_{t+1} - x_t \\) by \\( \\gamma_{t+1}(s_t - x_t) \\) and add and subtract the term \\( \\gamma_{t+1} \\nabla f_t (s_t - x_t) \\) to the right hand side to obtain,\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1} \\nabla f_t (s_t - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (46)\n$$\n\nBy Lemma 4.3, \\( X^* \\subseteq g \\subset X_t \\) with high probability \\( 1 - \\delta \\), for all \\( t = 1, ..., T \\). Note that if we define\n\n$$\ns'_t = \\arg \\max_{s \\in X_t} \\{ \\langle \\nabla f(x_t), x_t - s \\} \\}. \\text{ Recall that FW gap is } G(\\hat{x}) = \\max_{s \\in X^* g} \\{ \\langle \\nabla f(\\hat{x}), \\hat{x} - s \\} \\}. \\text{ We can replace the inner product } \\langle \\nabla f_t, s_t \\rangle \\text{ by its upper bound } \\langle \\nabla f_t, s'_t \\rangle. \\text{ Applying this substitution leads to}\n$$\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1} \\nabla f_t (s'_t - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2\n$$\n\n$$\n= f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1}(\\nabla f_t - \\nabla f(x_t))^T(s'_t - x_t) - \\gamma_{t+1}\\nabla f(x_t)^T(x_t - s'_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (47)\n$$\n\n$$\n\\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - s'_t) - \\gamma_{t+1}G(x_t) + Lf\\gamma^2 \\frac{2}{t+1}D^2 \\|x_{t+1} - x_t\\|^2\n$$\n\n$$\n\\leq f(x_t) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| - \\gamma_{t+1}G(x_t) + Lf\\gamma^2 \\frac{2}{t+1}D^2\n$$\n\nRearrange the terms for the inequality above, we can obtain,\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + Lf\\gamma^2 \\frac{2}{t+1} \\quad (48)\n$$\n\nAs a simple corollary, since \\( G(x_t) \\geq f(x_t) - f^* \\) when \\( f \\) is convex, we have,\n\n$$\nf(x_{t+1}) - f^* \\leq (1 - \\gamma_{t+1})(f(x_t) - f^*)) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\quad (49)\n$$\n\n23", "md": "(i) For all \\( t \\geq 0 \\), assume that \\( X^* \\subseteq g \\subset X_t \\). Then we have\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\quad (42)\n$$\nAs a corollary, if \\( f \\) is convex, we further have\n\n(ii) We have \\( f(x_{t+1}) - f^* \\leq (1 - \\gamma_{t+1})(f(x_t) - f^*)) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\) . (43)\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\| \\nabla g(x_t) - \\nabla g_t \\| + K_{1,t}) \\frac{t+1}{t+1}\n+ \\gamma_{t+1}(\\| g(x_t) - \\hat{g} \\| + K_{0,t}) + LgD^2\\gamma^2 \\frac{2}{t+1} . (44)\n$$\n\nProof. (i) Based on the \\( L_f \\)-smoothness of the expected function \\( f \\) we show that \\( f(x_{t+1}) \\) is bounded by\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\nabla f(x_t)^T(x_{t+1} - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (45)\n$$\n\nReplace the terms \\( x_{t+1} - x_t \\) by \\( \\gamma_{t+1}(s_t - x_t) \\) and add and subtract the term \\( \\gamma_{t+1} \\nabla f_t (s_t - x_t) \\) to the right hand side to obtain,\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1} \\nabla f_t (s_t - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (46)\n$$\n\nBy Lemma 4.3, \\( X^* \\subseteq g \\subset X_t \\) with high probability \\( 1 - \\delta \\), for all \\( t = 1, ..., T \\). Note that if we define\n\n$$\ns'_t = \\arg \\max_{s \\in X_t} \\{ \\langle \\nabla f(x_t), x_t - s \\} \\}. \\text{ Recall that FW gap is } G(\\hat{x}) = \\max_{s \\in X^* g} \\{ \\langle \\nabla f(\\hat{x}), \\hat{x} - s \\} \\}. \\text{ We can replace the inner product } \\langle \\nabla f_t, s_t \\rangle \\text{ by its upper bound } \\langle \\nabla f_t, s'_t \\rangle. \\text{ Applying this substitution leads to}\n$$\n\n$$\nf(x_{t+1}) \\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1} \\nabla f_t (s'_t - x_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2\n$$\n\n$$\n= f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - x_t) + \\gamma_{t+1}(\\nabla f_t - \\nabla f(x_t))^T(s'_t - x_t) - \\gamma_{t+1}\\nabla f(x_t)^T(x_t - s'_t) + \\frac{Lf}{2} \\|x_{t+1} - x_t\\|^2 \\quad (47)\n$$\n\n$$\n\\leq f(x_t) + \\gamma_{t+1}(\\nabla f(x_t) - \\nabla f_t)^T(s_t - s'_t) - \\gamma_{t+1}G(x_t) + Lf\\gamma^2 \\frac{2}{t+1}D^2 \\|x_{t+1} - x_t\\|^2\n$$\n\n$$\n\\leq f(x_t) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| - \\gamma_{t+1}G(x_t) + Lf\\gamma^2 \\frac{2}{t+1}D^2\n$$\n\nRearrange the terms for the inequality above, we can obtain,\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + Lf\\gamma^2 \\frac{2}{t+1} \\quad (48)\n$$\n\nAs a simple corollary, since \\( G(x_t) \\geq f(x_t) - f^* \\) when \\( f \\) is convex, we have,\n\n$$\nf(x_{t+1}) - f^* \\leq (1 - \\gamma_{t+1})(f(x_t) - f^*)) + \\gamma_{t+1}D\\| \\nabla f(x_t) - \\nabla f_t \\| + LfD^2\\gamma^2 \\frac{2}{t+1} \\quad (49)\n$$\n\n23"}]}, {"page": 24, "text": "(ii) Based on the Lg-smoothness of the expected function g we show that g(xt+1) is bounded by\n                                g(xt+1) \u2264       g(xt) + \u2207g(xt)\u22a4(xt+1 \u2212               xt) + Lg   2 \u2225xt+1 \u2212       xt\u22252              \u22a4             (50)\nReplace the terms xt+1 \u2212                xt by \u03b3t+1(st \u2212          xt) and add and subtract the term \u03b3t+1                       \u2207g  t (st \u2212    xt) to\nthe right-hand side to obtain,\n                                                                                               \u22a4\n       g(xt+1) \u2264       g(xt) + \u03b3t+1(\u2207g(xt) \u2212             \u2207gt)\u22a4(st \u2212        xt) + \u03b3t+1     \u2207g   t (st \u2212    xt) + Lg  2 \u2225xt+1 \u2212       xt\u22252        (51)\nNow by definition of the set Xt, using \u27e8                     \u2207gt, st \u2212     xt\u27e9   \u2264   g(x0) \u2212     \u02c6\n                                                                                                 gt + K0,t + DK1,t. In addition, we\ncould use Cauchy\u2013Schwarz inequality to upper bound the second term. Then add and subtract\n\u03b3t+1g(x0) on the right hand side to obtain,\n                          g(xt+1) \u2264      g(xt) + \u03b3t+1(g(x0) \u2212             g(xt)) + \u03b3t+1D\u2225\u2207g(xt) \u2212                \u2207gt\u2225                           (52)\n                                      + \u03b3t+1(g(xt) \u2212         \u02c6\nThen subtract g(x0) on both sides,                           gt) + \u03b3t+1(K0       t + DK1t) + Lg       2 \u2225xt+1 \u2212       xt\u22252\n   g(xt+1) \u2212       g(x0) \u2264     (1 \u2212    \u03b3t+1)(g(xt) \u2212        g(x0))\n                            + \u03b3t+1(D\u2225\u2207g(xt) \u2212             \u2207gt\u2225     + \u2225g(xt) \u2212       \u02c6\nand the claim in the lemma follows.                                                 gt\u2225  + K0,t + DK1,t) + Lg           2 \u2225xt+1 \u2212      xt\u22252 (53)\nC        Proof of Theorem for Algorithm 1\nC.1        Proof of Theorem 4.4\nProof. For lower-level, by Lemma B.2, we have\n                 g(xt+1) \u2212      g(x0) \u2264      (1 \u2212   \u03b3t+1)(g(xt) \u2212        g(x0)) + D\u03b3t+1(\u2225\u2207g(xt) \u2212t+1              \u2207gt\u2225     + K1,t)              (54)\n                                         + \u03b3t+1(\u2225g(xt) \u2212          \u02c6\n                                                                  gt\u2225  + K0,t) + LgD2\u03b32       2                                                      \u2032\nBy Lemma 4.1, we have \u2225\u2207g(xt) \u2212                         \u2207gt\u2225     \u2264   K1,t and \u2225g(xt) \u2212           \u02c6                                                    .\nPlug them in the inequality above to obtain,                                                     gt\u2225   \u2264   K0,t with probability 1 \u2212               \u03b4\n               g(xt+1) \u2212      g(x0) \u2264      (1 \u2212   \u03b3t+1)(g(xt) \u2212         g(x0)) + 2\u03b3t+1(DK1,t + K0,t) + LgD2\u03b32                  2   t+1\n                                       \u2264   (1 \u2212    t +11)(g(xt) \u2212        g(x0))                                                                 (55)\n                                       + 2(DA1      1    log(6d/\u03b4     \u2032) + A1  0    log(6/\u03b4    \u2032))  +     L gD2\n                                                                (t + 1)3/2                              2(t + 1)2\n                                                                          24", "md": "(ii) Based on the Lg-smoothness of the expected function \\( g \\) we show that \\( g(x_{t+1}) \\) is bounded by\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\nabla g(x_{t})^{\\top}(x_{t+1} - x_{t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(50)}\n\\]\n\nReplace the terms \\( x_{t+1} - x_{t} \\) by \\( \\gamma_{t+1}(s_{t} - x_{t}) \\) and add and subtract the term \\( \\gamma_{t+1} \\nabla g_{t}(s_{t} - x_{t}) \\) to the right-hand side to obtain,\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\gamma_{t+1}(\\nabla g(x_{t}) - \\nabla g_{t})^{\\top}(s_{t} - x_{t}) + \\gamma_{t+1} \\nabla g_{t}(s_{t} - x_{t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(51)}\n\\]\n\nNow by definition of the set \\( X_{t} \\), using \\( \\langle \\nabla g_{t}, s_{t} - x_{t} \\rangle \\leq g(x_{0}) - \\hat{g}_{t} + K_{0,t} + DK_{1,t} \\). In addition, we could use Cauchy\u2013Schwarz inequality to upper bound the second term. Then add and subtract \\( \\gamma_{t+1}g(x_{0}) \\) on the right-hand side to obtain,\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\gamma_{t+1}(g(x_{0}) - g(x_{t})) + \\gamma_{t+1}D\\|\\nabla g(x_{t}) - \\nabla g_{t}\\| \\quad \\text{(52)}\n\\]\n\\[\n+ \\gamma_{t+1}(g(x_{t}) - \\hat{g}_{t}) + \\gamma_{t+1}(K_{0,t} + DK_{1,t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2}\n\\]\n\nThen subtract \\( g(x_{0}) \\) on both sides,\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + \\gamma_{t+1}(D\\|\\nabla g(x_{t}) - \\nabla g_{t}\\| + \\|g(x_{t}) - \\hat{g}_{t}\\|\n\\]\n\\[\n+ K_{0,t} + DK_{1,t}) + L_{g} \\frac{1}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(53)}\n\\]\n\n**Proof of Theorem for Algorithm 1**\n\n**Proof of Theorem 4.4**\n\n**Proof.** For lower-level, by Lemma B.2, we have\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + D\\gamma_{t+1}(\\|\\nabla g(x_{t}) - \\nabla g_{t+1}\\| + K_{1,t})\n\\]\n\\[\n+ \\gamma_{t+1}(\\|g(x_{t}) - \\hat{g}_{t}\\| + K_{0,t}) + L_{g}D^{2}\\gamma_{t+1}^{2} \\quad \\text{(54)}\n\\]\n\nBy Lemma 4.1, we have \\( \\|\\nabla g(x_{t}) - \\nabla g_{t}\\| \\leq K_{1,t} \\) and \\( \\|g(x_{t}) - \\hat{g}_{t}\\| \\leq K_{0,t} \\) with probability \\( 1 - \\delta \\). Plug them in the inequality above to obtain,\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + 2\\gamma_{t+1}(DK_{1,t} + K_{0,t}) + L_{g}D^{2}\\gamma_{t+1}^{2}\n\\]\n\\[\n\\leq (1 - \\gamma_{t+1})^{1}(g(x_{t}) - g(x_{0})) \\quad \\text{(55)}\n\\]\n\\[\n+ 2(DA_{1}^{1} \\log(6d/\\delta') + A_{1}^{0} \\log(6/\\delta')) + \\frac{L_{g}D^{2}}{(t + 1)^{3/2}} \\frac{1}{2(t + 1)^{2}} \\frac{24}{2}\n\\]", "images": [], "items": [{"type": "text", "value": "(ii) Based on the Lg-smoothness of the expected function \\( g \\) we show that \\( g(x_{t+1}) \\) is bounded by\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\nabla g(x_{t})^{\\top}(x_{t+1} - x_{t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(50)}\n\\]\n\nReplace the terms \\( x_{t+1} - x_{t} \\) by \\( \\gamma_{t+1}(s_{t} - x_{t}) \\) and add and subtract the term \\( \\gamma_{t+1} \\nabla g_{t}(s_{t} - x_{t}) \\) to the right-hand side to obtain,\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\gamma_{t+1}(\\nabla g(x_{t}) - \\nabla g_{t})^{\\top}(s_{t} - x_{t}) + \\gamma_{t+1} \\nabla g_{t}(s_{t} - x_{t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(51)}\n\\]\n\nNow by definition of the set \\( X_{t} \\), using \\( \\langle \\nabla g_{t}, s_{t} - x_{t} \\rangle \\leq g(x_{0}) - \\hat{g}_{t} + K_{0,t} + DK_{1,t} \\). In addition, we could use Cauchy\u2013Schwarz inequality to upper bound the second term. Then add and subtract \\( \\gamma_{t+1}g(x_{0}) \\) on the right-hand side to obtain,\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\gamma_{t+1}(g(x_{0}) - g(x_{t})) + \\gamma_{t+1}D\\|\\nabla g(x_{t}) - \\nabla g_{t}\\| \\quad \\text{(52)}\n\\]\n\\[\n+ \\gamma_{t+1}(g(x_{t}) - \\hat{g}_{t}) + \\gamma_{t+1}(K_{0,t} + DK_{1,t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2}\n\\]\n\nThen subtract \\( g(x_{0}) \\) on both sides,\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + \\gamma_{t+1}(D\\|\\nabla g(x_{t}) - \\nabla g_{t}\\| + \\|g(x_{t}) - \\hat{g}_{t}\\|\n\\]\n\\[\n+ K_{0,t} + DK_{1,t}) + L_{g} \\frac{1}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(53)}\n\\]\n\n**Proof of Theorem for Algorithm 1**\n\n**Proof of Theorem 4.4**\n\n**Proof.** For lower-level, by Lemma B.2, we have\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + D\\gamma_{t+1}(\\|\\nabla g(x_{t}) - \\nabla g_{t+1}\\| + K_{1,t})\n\\]\n\\[\n+ \\gamma_{t+1}(\\|g(x_{t}) - \\hat{g}_{t}\\| + K_{0,t}) + L_{g}D^{2}\\gamma_{t+1}^{2} \\quad \\text{(54)}\n\\]\n\nBy Lemma 4.1, we have \\( \\|\\nabla g(x_{t}) - \\nabla g_{t}\\| \\leq K_{1,t} \\) and \\( \\|g(x_{t}) - \\hat{g}_{t}\\| \\leq K_{0,t} \\) with probability \\( 1 - \\delta \\). Plug them in the inequality above to obtain,\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + 2\\gamma_{t+1}(DK_{1,t} + K_{0,t}) + L_{g}D^{2}\\gamma_{t+1}^{2}\n\\]\n\\[\n\\leq (1 - \\gamma_{t+1})^{1}(g(x_{t}) - g(x_{0})) \\quad \\text{(55)}\n\\]\n\\[\n+ 2(DA_{1}^{1} \\log(6d/\\delta') + A_{1}^{0} \\log(6/\\delta')) + \\frac{L_{g}D^{2}}{(t + 1)^{3/2}} \\frac{1}{2(t + 1)^{2}} \\frac{24}{2}\n\\]", "md": "(ii) Based on the Lg-smoothness of the expected function \\( g \\) we show that \\( g(x_{t+1}) \\) is bounded by\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\nabla g(x_{t})^{\\top}(x_{t+1} - x_{t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(50)}\n\\]\n\nReplace the terms \\( x_{t+1} - x_{t} \\) by \\( \\gamma_{t+1}(s_{t} - x_{t}) \\) and add and subtract the term \\( \\gamma_{t+1} \\nabla g_{t}(s_{t} - x_{t}) \\) to the right-hand side to obtain,\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\gamma_{t+1}(\\nabla g(x_{t}) - \\nabla g_{t})^{\\top}(s_{t} - x_{t}) + \\gamma_{t+1} \\nabla g_{t}(s_{t} - x_{t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(51)}\n\\]\n\nNow by definition of the set \\( X_{t} \\), using \\( \\langle \\nabla g_{t}, s_{t} - x_{t} \\rangle \\leq g(x_{0}) - \\hat{g}_{t} + K_{0,t} + DK_{1,t} \\). In addition, we could use Cauchy\u2013Schwarz inequality to upper bound the second term. Then add and subtract \\( \\gamma_{t+1}g(x_{0}) \\) on the right-hand side to obtain,\n\n\\[\ng(x_{t+1}) \\leq g(x_{t}) + \\gamma_{t+1}(g(x_{0}) - g(x_{t})) + \\gamma_{t+1}D\\|\\nabla g(x_{t}) - \\nabla g_{t}\\| \\quad \\text{(52)}\n\\]\n\\[\n+ \\gamma_{t+1}(g(x_{t}) - \\hat{g}_{t}) + \\gamma_{t+1}(K_{0,t} + DK_{1,t}) + \\frac{L_{g}}{2} \\|x_{t+1} - x_{t}\\|^{2}\n\\]\n\nThen subtract \\( g(x_{0}) \\) on both sides,\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + \\gamma_{t+1}(D\\|\\nabla g(x_{t}) - \\nabla g_{t}\\| + \\|g(x_{t}) - \\hat{g}_{t}\\|\n\\]\n\\[\n+ K_{0,t} + DK_{1,t}) + L_{g} \\frac{1}{2} \\|x_{t+1} - x_{t}\\|^{2} \\quad \\text{(53)}\n\\]\n\n**Proof of Theorem for Algorithm 1**\n\n**Proof of Theorem 4.4**\n\n**Proof.** For lower-level, by Lemma B.2, we have\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + D\\gamma_{t+1}(\\|\\nabla g(x_{t}) - \\nabla g_{t+1}\\| + K_{1,t})\n\\]\n\\[\n+ \\gamma_{t+1}(\\|g(x_{t}) - \\hat{g}_{t}\\| + K_{0,t}) + L_{g}D^{2}\\gamma_{t+1}^{2} \\quad \\text{(54)}\n\\]\n\nBy Lemma 4.1, we have \\( \\|\\nabla g(x_{t}) - \\nabla g_{t}\\| \\leq K_{1,t} \\) and \\( \\|g(x_{t}) - \\hat{g}_{t}\\| \\leq K_{0,t} \\) with probability \\( 1 - \\delta \\). Plug them in the inequality above to obtain,\n\n\\[\ng(x_{t+1}) - g(x_{0}) \\leq (1 - \\gamma_{t+1})(g(x_{t}) - g(x_{0})) + 2\\gamma_{t+1}(DK_{1,t} + K_{0,t}) + L_{g}D^{2}\\gamma_{t+1}^{2}\n\\]\n\\[\n\\leq (1 - \\gamma_{t+1})^{1}(g(x_{t}) - g(x_{0})) \\quad \\text{(55)}\n\\]\n\\[\n+ 2(DA_{1}^{1} \\log(6d/\\delta') + A_{1}^{0} \\log(6/\\delta')) + \\frac{L_{g}D^{2}}{(t + 1)^{3/2}} \\frac{1}{2(t + 1)^{2}} \\frac{24}{2}\n\\]"}]}, {"page": 25, "text": "with probability 1 \u2212             \u03b4 \u2032  for all t. Let C1 = 4(DA1               1 + A1   0) and \u03b4 = t\u03b4         \u2032. Then we can sum all the\ninequality up for all t to obtain,\n     g(xt+1) \u2212       g(x0) \u2264      (1 \u2212      1                                          log (6d/\u03b4     \u2032)  +     LgD2\n                                          t + 1)g(xt) \u2212        g(x0) + C1/2        (t + 1)3/2                2(t + 1)2\n                              =    t  (1 \u2212    i +11)(g(x0) \u2212         g(x0)) +         t   C1/2       log (6d/\u03b4     \u2032)     t   (1 \u2212    i +11)\n                                  i=1                                               k=1         (k + 1)3/2            i=k+1\n                              +    t      LgD2            t    (1 \u2212      1\n                                 k=1   2(k + 1)2       i=k+1           i + 1)                                                                     (56)\n                              \u2264   0 + C1/2         log (6d/\u03b4     \u2032)    t   \u221a   1             LgD2         t      1\n                                                  t + 1              k=1      k + 1 +      2(t + 1)     k=1   k + 1\n                              \u2264   C1     \u221alog (6d/\u03b4    \u2032)  +     LgD2\n                                            t + 1              2(t + 1)(1 + log t)\n                                       log (6td/\u03b4)\n                              \u2264   C1     \u221a                 + LgD2 log t\n                                            t + 1                  t + 1\nwith probability 1 \u2212             \u03b4.\nFor upper-level, by Lemma B.2, we have\n              f(xt+1) \u2212       f \u2217  \u2264   (1 \u2212   \u03b3t+1)(f(xt) \u2212         f \u2217) + D\u03b3t+1(\u2225\u2207f(xt) \u2212                \u2207f t\u2225) + LfD2\u03b32      2   t+1            (57)\n                                                          \u2207ft\u2225     \u2264    A12\u221a  log(6d/\u03b4\u2032 )   with probability 1 \u2212              \u03b4\u2032. Plug it in the\nBy Lemma 4.1, we have \u2225\u2207f(xt) \u2212                                             (t+1)1/2\ninequality above to obtain,\n                    f(xt+1) \u2212       f \u2217 \u2264   (1 \u2212       1                                   2    log(6d/\u03b4     \u2032)  +     LfD2                       (58)\n                                                    t + 1)(f(xt) \u2212         f \u2217) + DA1      (t + 1)3/2                2(t + 1)2\nwith probability 1 \u2212             \u03b4\u2032 for all t. Then we can sum all the inequality up for all t to obtain,\n            f(xt+1) \u2212       f \u2217  \u2264   (1 \u2212       1                                   2    log(6d/\u03b4     \u2032)  +     LfD2\n                                             t + 1)(f(xt) \u2212         f \u2217) + DA1      (t + 1)3/2               2(t + 1)2\n                                 =     t (1 \u2212    i +11)(f(x0) \u2212          f \u2217) +     t    DA1  2    log(6d/\u03b4     \u2032 )     t   (1 \u2212    i +11)\n                                     i=1                                          k=1         (k + 1)3/2            i=k+1\n                                 +    T      LfD2            T    (1 \u2212       1\n                                     k=1   2(k + 1)2      i=k+1           i + 1)                                                                  (59)\n                                 \u2264   f(x0) \u2212      f \u2217  + DA1     2    log(d/\u03b4    \u2032)   T    \u221a    1                         T      1\n                                          t + 1                     t + 1            k=1      k + 1 + LfD2 2(t + 1)     k=1   k + 1\n                                 \u2264   f(x0) \u2212      f \u2217  + 2DA1      2\u221a   log(6d/\u03b4     \u2032)  + LfD2\n                                          t + 1                        t + 1                 2(t + 1)(1 + log t)\n                                 \u2264   f(x0) \u2212      f \u2217  + 2DA1      2\u221alog(6td/\u03b4)          + LfD2 log t\n                                          t + 1                        t + 1                    (t + 1)\n                                                \u2032\nwith probability 1 \u2212             \u03b4 = 1 \u2212     t\u03b4  . Let C2 = 2DA1           2. The theorem is obtained.\n                                                                           25", "md": "# Math Equations\n\nwith probability 1 - $$\\delta'$$ for all t. Let C1 = 4(DA1$$^{1}$$ + A1$$^{0}$$) and $$\\delta = t\\delta'$$ . Then we can sum all the inequality up for all t to obtain,\n\n$$g(x_{t+1}) - g(x_{0}) \\leq (1 - 1$$ $$\\frac{log(6d/\\delta')}{t + 1} + LgD2$$\n\n$$t(1 - i + 11)(g(x_{0}) - g(x_{0})) + t\\frac{C1}{2}log(6d/\\delta')t(1 - i + 11)$$\n\n$$\\sum_{i=1}^{t}LgD2\\sum_{k=1}^{t}(1 - \\frac{1}{2}(k + 1)^{3/2}i=k+1)$$\n\n$$\\leq 0 + \\frac{C1}{2}log(6d/\\delta')t\\sqrt{1 + \\sum_{k=1}^{t}\\frac{LgD2}{t + 1}(k + 1 + 2(t + 1)\\sum_{k=1}^{t}k + 1}$$\n\n$$\\leq C1\\sqrt{log(6d/\\delta') + LgD2}{t + 1}{2(t + 1)(1 + log t)}log(6td/\\delta)$$\n\n$$\\leq C1\\sqrt{t + 1}{2(t + 1)(1 + log t)}$$ with probability 1 - $$\\delta$$.\n\nFor upper-level, by Lemma B.2, we have\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - \\gamma t + 1)(f(x_{t}) - f^{*}) + D\\gamma t + 1(\\| \\nabla f(x_{t}) - \\nabla f t\\|) + LfD2\\gamma^{2}2t + 1$$\n\n$$\\nabla ft\\| \\leq A1\\sqrt{log(6d/\\delta')$$ with probability 1 - $$\\delta'$$ . Plug it in the\n\nBy Lemma 4.1, we have $$\\| \\nabla f(x_{t}) - (t + 1)^{1/2}$$\n\ninequality above to obtain,\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - 1$$ $$\\frac{2log(6d/\\delta')}{t + 1} + LfD2$$\n\n$$DA1(t + 1)^{3/2}2(t + 1)^{2}$$ with probability 1 - $$\\delta'$$ for all t. Then we can sum all the inequality up for all t to obtain,\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - 1$$ $$\\frac{2log(6d/\\delta')}{t + 1} + LfD2$$\n\n$$t(1 - i + 11)(f(x_{0}) - f^{*}) + tDA1\\frac{2log(6d/\\delta')t(1 - i + 11)}$$\n\n$$\\sum_{i=1}^{T}LfD2\\sum_{T=1}^{T}(1 - \\frac{1}{2}(k + 1)^{3/2}i=k+1)$$\n\n$$\\leq f(x_{0}) - f^{*} + DA1\\frac{2\\sqrt{log(d/\\delta')}}{t + 1}\\sum_{k=1}^{t}(k + 1 + LfD2\\frac{2(t + 1)}{k=1}k + 1}$$\n\n$$\\leq f(x_{0}) - f^{*} + 2DA1\\frac{2\\sqrt{log(6d/\\delta')}}{t + 1}{t + 1}(1 + log t)$$\n\n$$\\leq f(x_{0}) - f^{*} + 2DA1\\frac{2\\sqrt{log(6td/\\delta)}}{t + 1}{t + 1}$$\n\nwith probability 1 - $$\\delta = 1 - t\\delta$$ . Let C2 = 2DA1$$^{2}$$. The theorem is obtained.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations", "md": "# Math Equations"}, {"type": "text", "value": "with probability 1 - $$\\delta'$$ for all t. Let C1 = 4(DA1$$^{1}$$ + A1$$^{0}$$) and $$\\delta = t\\delta'$$ . Then we can sum all the inequality up for all t to obtain,\n\n$$g(x_{t+1}) - g(x_{0}) \\leq (1 - 1$$ $$\\frac{log(6d/\\delta')}{t + 1} + LgD2$$\n\n$$t(1 - i + 11)(g(x_{0}) - g(x_{0})) + t\\frac{C1}{2}log(6d/\\delta')t(1 - i + 11)$$\n\n$$\\sum_{i=1}^{t}LgD2\\sum_{k=1}^{t}(1 - \\frac{1}{2}(k + 1)^{3/2}i=k+1)$$\n\n$$\\leq 0 + \\frac{C1}{2}log(6d/\\delta')t\\sqrt{1 + \\sum_{k=1}^{t}\\frac{LgD2}{t + 1}(k + 1 + 2(t + 1)\\sum_{k=1}^{t}k + 1}$$\n\n$$\\leq C1\\sqrt{log(6d/\\delta') + LgD2}{t + 1}{2(t + 1)(1 + log t)}log(6td/\\delta)$$\n\n$$\\leq C1\\sqrt{t + 1}{2(t + 1)(1 + log t)}$$ with probability 1 - $$\\delta$$.\n\nFor upper-level, by Lemma B.2, we have\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - \\gamma t + 1)(f(x_{t}) - f^{*}) + D\\gamma t + 1(\\| \\nabla f(x_{t}) - \\nabla f t\\|) + LfD2\\gamma^{2}2t + 1$$\n\n$$\\nabla ft\\| \\leq A1\\sqrt{log(6d/\\delta')$$ with probability 1 - $$\\delta'$$ . Plug it in the\n\nBy Lemma 4.1, we have $$\\| \\nabla f(x_{t}) - (t + 1)^{1/2}$$\n\ninequality above to obtain,\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - 1$$ $$\\frac{2log(6d/\\delta')}{t + 1} + LfD2$$\n\n$$DA1(t + 1)^{3/2}2(t + 1)^{2}$$ with probability 1 - $$\\delta'$$ for all t. Then we can sum all the inequality up for all t to obtain,\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - 1$$ $$\\frac{2log(6d/\\delta')}{t + 1} + LfD2$$\n\n$$t(1 - i + 11)(f(x_{0}) - f^{*}) + tDA1\\frac{2log(6d/\\delta')t(1 - i + 11)}$$\n\n$$\\sum_{i=1}^{T}LfD2\\sum_{T=1}^{T}(1 - \\frac{1}{2}(k + 1)^{3/2}i=k+1)$$\n\n$$\\leq f(x_{0}) - f^{*} + DA1\\frac{2\\sqrt{log(d/\\delta')}}{t + 1}\\sum_{k=1}^{t}(k + 1 + LfD2\\frac{2(t + 1)}{k=1}k + 1}$$\n\n$$\\leq f(x_{0}) - f^{*} + 2DA1\\frac{2\\sqrt{log(6d/\\delta')}}{t + 1}{t + 1}(1 + log t)$$\n\n$$\\leq f(x_{0}) - f^{*} + 2DA1\\frac{2\\sqrt{log(6td/\\delta)}}{t + 1}{t + 1}$$\n\nwith probability 1 - $$\\delta = 1 - t\\delta$$ . Let C2 = 2DA1$$^{2}$$. The theorem is obtained.", "md": "with probability 1 - $$\\delta'$$ for all t. Let C1 = 4(DA1$$^{1}$$ + A1$$^{0}$$) and $$\\delta = t\\delta'$$ . Then we can sum all the inequality up for all t to obtain,\n\n$$g(x_{t+1}) - g(x_{0}) \\leq (1 - 1$$ $$\\frac{log(6d/\\delta')}{t + 1} + LgD2$$\n\n$$t(1 - i + 11)(g(x_{0}) - g(x_{0})) + t\\frac{C1}{2}log(6d/\\delta')t(1 - i + 11)$$\n\n$$\\sum_{i=1}^{t}LgD2\\sum_{k=1}^{t}(1 - \\frac{1}{2}(k + 1)^{3/2}i=k+1)$$\n\n$$\\leq 0 + \\frac{C1}{2}log(6d/\\delta')t\\sqrt{1 + \\sum_{k=1}^{t}\\frac{LgD2}{t + 1}(k + 1 + 2(t + 1)\\sum_{k=1}^{t}k + 1}$$\n\n$$\\leq C1\\sqrt{log(6d/\\delta') + LgD2}{t + 1}{2(t + 1)(1 + log t)}log(6td/\\delta)$$\n\n$$\\leq C1\\sqrt{t + 1}{2(t + 1)(1 + log t)}$$ with probability 1 - $$\\delta$$.\n\nFor upper-level, by Lemma B.2, we have\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - \\gamma t + 1)(f(x_{t}) - f^{*}) + D\\gamma t + 1(\\| \\nabla f(x_{t}) - \\nabla f t\\|) + LfD2\\gamma^{2}2t + 1$$\n\n$$\\nabla ft\\| \\leq A1\\sqrt{log(6d/\\delta')$$ with probability 1 - $$\\delta'$$ . Plug it in the\n\nBy Lemma 4.1, we have $$\\| \\nabla f(x_{t}) - (t + 1)^{1/2}$$\n\ninequality above to obtain,\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - 1$$ $$\\frac{2log(6d/\\delta')}{t + 1} + LfD2$$\n\n$$DA1(t + 1)^{3/2}2(t + 1)^{2}$$ with probability 1 - $$\\delta'$$ for all t. Then we can sum all the inequality up for all t to obtain,\n\n$$f(x_{t+1}) - f^{*} \\leq (1 - 1$$ $$\\frac{2log(6d/\\delta')}{t + 1} + LfD2$$\n\n$$t(1 - i + 11)(f(x_{0}) - f^{*}) + tDA1\\frac{2log(6d/\\delta')t(1 - i + 11)}$$\n\n$$\\sum_{i=1}^{T}LfD2\\sum_{T=1}^{T}(1 - \\frac{1}{2}(k + 1)^{3/2}i=k+1)$$\n\n$$\\leq f(x_{0}) - f^{*} + DA1\\frac{2\\sqrt{log(d/\\delta')}}{t + 1}\\sum_{k=1}^{t}(k + 1 + LfD2\\frac{2(t + 1)}{k=1}k + 1}$$\n\n$$\\leq f(x_{0}) - f^{*} + 2DA1\\frac{2\\sqrt{log(6d/\\delta')}}{t + 1}{t + 1}(1 + log t)$$\n\n$$\\leq f(x_{0}) - f^{*} + 2DA1\\frac{2\\sqrt{log(6td/\\delta)}}{t + 1}{t + 1}$$\n\nwith probability 1 - $$\\delta = 1 - t\\delta$$ . Let C2 = 2DA1$$^{2}$$. The theorem is obtained."}]}, {"page": 26, "text": "C.2        Proof of Theorem 4.5\nProof. For lower-level, by Lemma B.2, we have\n                 g(xt+1) \u2212      g(x0) \u2264      (1 \u2212   \u03b3t+1)(g(xt) \u2212        g(x0)) + D\u03b3t+1(\u2225\u2207g(xt) \u2212t+1              \u2207gt\u2225     + K1,t)              (60)\n                                         + \u03b3t+1(\u2225g(xt) \u2212          \u02c6\n                                                                  gt\u2225  + K0,t) + LgD2\u03b32       2                                                      \u2032\nBy Lemma 4.1, we have \u2225\u2207g(xt) \u2212                         \u2207gt\u2225     \u2264   K1,t and \u2225g(xt) \u2212           \u02c6                                                    .\nPlug them in the inequality above to obtain,                                                     gt\u2225   \u2264   K0,t with probability 1 \u2212               \u03b4\n              g(xt+1) \u2212       g(x0) \u2264      (1 \u2212   \u03b3t+1)(g(xt) \u2212        g(x0)) + 2\u03b3T+1(DK1,t + K0,t) + LgD2\u03b32                   2   t+1\n                                                         1\n                                       \u2264   (1 \u2212   (T + 1)2/3 )g(xt) \u2212           g(x0)                                                           (61)\n                                       + 2D(A2/3   1       log(6d/\u03b4     \u2032) + A2/30       log(6d/\u03b4     \u2032)) +        LgD2\n                                                           (t + 1)1/3(T + 1)2/3                               2(T + 1)4/3\nwith probability 1 \u2212            \u03b4 \u2032 for all t. Let C3 = 2(DA2/3          1    + A2/3 0   ).Then we can sum all the inequality up\nfor all t to obtain,\n      g(xt+1) \u2212       g(x0) \u2264     (1 \u2212           1                                        C3      log(6d/\u03b4    \u2032)              LgD2\n                                          (T + 1)2/3 )(g(xt) \u2212           g(x0)) +      (t + 1)1/3(T + 1)2/3 +            2(T + 1)4/3\n                               \u2264  (1 \u2212           1                                          log(6Td/\u03b4) + LgD2/2                                 (62)\n                                          (T + 1)2/3 )(g(xt) \u2212           g(x0)) + C3        (t + 1)1/3(T + 1)2/3\nBy induction, we have for all t \u2265        g(xt+1) \u2212  1,  g(x0) \u2264      C3   log(6Td/\u03b4) + LgD2/2                                                   (63)\n                                                                                  (T + 1)1/3\n                                                         \u2032\nwith probability 1 \u2212            \u03b4, where \u03b4 = T\u03b4           .\nFor upper-level, by Lemma B.2, we have\n                                                                                                                     t+1D2\n                        \u03b3t+1G(xt) \u2264         f(xt) \u2212     f(xt+1) + \u03b3t+1D\u2225\u2207f(xt) \u2212                  \u2207ft\u2225     + Lf\u03b32    2                          (64)\n                                                                         2   \u221a log(6d/\u03b4\u2032)    with probability 1 \u2212             \u03b4 \u2032. Plug it and\nBy Lemma 4.1, we have \u2225\u2207f(xt) \u2212                          \u2207ft\u2225     \u2264    A2/3 (t+1)1/3\n\u03b3t+1 = 1/(T + 1)2/3 in inequality above to obtain,\n           T\u22121   \u03b3t+1G(xt) \u2264         f(x0) \u2212     f(xT ) + D       T\u22121   \u03b3t+1\u2225\u2207f(xt) \u2212           \u2207ft\u2225    + LfD2        T\u22121   \u03b32\n            t=0                                                    t=0                                         2      t=0    t+1\n                                                                  T\u22121      A2/3      log(6d/\u03b4     \u2032)                 T\u22121          1\n                                 \u2264   f(x0) \u2212     f(xT ) + D        t=0   (t +21)1/3(T + 1)2/3 + LfD2           2     t=0   (T + 1)4/3           (65)\n                                 \u2264   f(x0) \u2212     f(xT ) + 3    2DA2/3  2      log(6d/\u03b4     \u2032) + LfD2               1\n                                                                                                      2     (T + 1)1/3\n                                                                          26", "md": "C.2 Proof of Theorem 4.5\n\nProof. For lower-level, by Lemma B.2, we have\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\|\\nabla g(x_t) - \\nabla g_t\\| + K_{1,t})$$\n$$+ \\gamma_{t+1}(\\|g(x_t) - \\hat{g}_t\\| + K_{0,t}) + LgD^2\\gamma^2$$\nBy Lemma 4.1, we have $\\|\\nabla g(x_t) - \\nabla g_t\\| \\leq K_{1,t}$ and $\\|g(x_t) - \\hat{g}_t\\| \\leq K_{0,t}$ with probability $1 - \\delta$. Plug them in the inequality above to obtain,\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + 2\\gamma_{T+1}(DK_{1,t} + K_{0,t}) + LgD^2\\gamma^2$$\n$$\\leq (1 - (T + 1)^{2/3})g(x_t) - g(x_0)$$\n$$+ 2D(A^{2/3}_1 \\log(6d/\\delta') + A^{2/30}_0 \\log(6d/\\delta')) + LgD^2\\left(\\frac{t + 1}{3}(T + 1)^{2/3} + 2(T + 1)^{4/3}\\right)$$\nwith probability $1 - \\delta'$ for all $t$. Let $C3 = 2(DA^{2/3}_1 + A^{2/3}_0)$. Then we can sum all the inequality up for all $t$ to obtain,\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\frac{1}{(T + 1)^{2/3}})(g(x_t) - g(x_0)) + C3\\left(\\frac{t + 1}{3}(T + 1)^{2/3} + 2(T + 1)^{4/3}\\right)$$\n$$\\leq (1 - \\frac{1}{(T + 1)^{2/3}})(g(x_t) - g(x_0)) + C3\\left(\\frac{t + 1}{3}(T + 1)^{2/3}\\right)$$\nBy induction, we have for all $t \\geq 1$, $g(x_{t+1}) - g(x_0) \\leq C3 \\log(6Td/\\delta) + LgD^2/2(T + 1)^{1/3}$\n\nwith probability $1 - \\delta$, where $\\delta = T\\delta'$.\n\nFor upper-level, by Lemma B.2, we have\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\|\\nabla f(x_t) - \\nabla f_t\\| + Lf\\gamma^2$$\nwith probability $1 - \\delta'$. Plug it and by Lemma 4.1, we have $\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq A^{2/3}(t+1)^{1/3}$. Set $\\gamma_{t+1} = 1/(T + 1)^{2/3}$ in the inequality above to obtain,\n\n$$\n\\sum_{t=0}^{T-1} \\gamma_{t+1}G(x_t) \\leq f(x_0) - f(x_T) + D\\sum_{t=0}^{T-1} \\gamma_{t+1}\\|\\nabla f(x_t) - \\nabla f_t\\| + LfD^2\\sum_{t=0}^{T-1} \\gamma^2$$\n$$\\leq f(x_0) - f(x_T) + D\\sum_{t=0}^{T-1} (t + 2)^{1/3}(T + 1)^{2/3} + LfD^2\\sum_{t=0}^{T-1} (T + 1)^{4/3}$$\n$$\\leq f(x_0) - f(x_T) + 3\\sqrt{2}DA^{2/3}_2 \\log(6d/\\delta') + LfD^2\\sqrt{2}(T + 1)^{1/3}$$", "images": [], "items": [{"type": "text", "value": "C.2 Proof of Theorem 4.5\n\nProof. For lower-level, by Lemma B.2, we have\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\|\\nabla g(x_t) - \\nabla g_t\\| + K_{1,t})$$\n$$+ \\gamma_{t+1}(\\|g(x_t) - \\hat{g}_t\\| + K_{0,t}) + LgD^2\\gamma^2$$\nBy Lemma 4.1, we have $\\|\\nabla g(x_t) - \\nabla g_t\\| \\leq K_{1,t}$ and $\\|g(x_t) - \\hat{g}_t\\| \\leq K_{0,t}$ with probability $1 - \\delta$. Plug them in the inequality above to obtain,\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + 2\\gamma_{T+1}(DK_{1,t} + K_{0,t}) + LgD^2\\gamma^2$$\n$$\\leq (1 - (T + 1)^{2/3})g(x_t) - g(x_0)$$\n$$+ 2D(A^{2/3}_1 \\log(6d/\\delta') + A^{2/30}_0 \\log(6d/\\delta')) + LgD^2\\left(\\frac{t + 1}{3}(T + 1)^{2/3} + 2(T + 1)^{4/3}\\right)$$\nwith probability $1 - \\delta'$ for all $t$. Let $C3 = 2(DA^{2/3}_1 + A^{2/3}_0)$. Then we can sum all the inequality up for all $t$ to obtain,\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\frac{1}{(T + 1)^{2/3}})(g(x_t) - g(x_0)) + C3\\left(\\frac{t + 1}{3}(T + 1)^{2/3} + 2(T + 1)^{4/3}\\right)$$\n$$\\leq (1 - \\frac{1}{(T + 1)^{2/3}})(g(x_t) - g(x_0)) + C3\\left(\\frac{t + 1}{3}(T + 1)^{2/3}\\right)$$\nBy induction, we have for all $t \\geq 1$, $g(x_{t+1}) - g(x_0) \\leq C3 \\log(6Td/\\delta) + LgD^2/2(T + 1)^{1/3}$\n\nwith probability $1 - \\delta$, where $\\delta = T\\delta'$.\n\nFor upper-level, by Lemma B.2, we have\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\|\\nabla f(x_t) - \\nabla f_t\\| + Lf\\gamma^2$$\nwith probability $1 - \\delta'$. Plug it and by Lemma 4.1, we have $\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq A^{2/3}(t+1)^{1/3}$. Set $\\gamma_{t+1} = 1/(T + 1)^{2/3}$ in the inequality above to obtain,\n\n$$\n\\sum_{t=0}^{T-1} \\gamma_{t+1}G(x_t) \\leq f(x_0) - f(x_T) + D\\sum_{t=0}^{T-1} \\gamma_{t+1}\\|\\nabla f(x_t) - \\nabla f_t\\| + LfD^2\\sum_{t=0}^{T-1} \\gamma^2$$\n$$\\leq f(x_0) - f(x_T) + D\\sum_{t=0}^{T-1} (t + 2)^{1/3}(T + 1)^{2/3} + LfD^2\\sum_{t=0}^{T-1} (T + 1)^{4/3}$$\n$$\\leq f(x_0) - f(x_T) + 3\\sqrt{2}DA^{2/3}_2 \\log(6d/\\delta') + LfD^2\\sqrt{2}(T + 1)^{1/3}$$", "md": "C.2 Proof of Theorem 4.5\n\nProof. For lower-level, by Lemma B.2, we have\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\|\\nabla g(x_t) - \\nabla g_t\\| + K_{1,t})$$\n$$+ \\gamma_{t+1}(\\|g(x_t) - \\hat{g}_t\\| + K_{0,t}) + LgD^2\\gamma^2$$\nBy Lemma 4.1, we have $\\|\\nabla g(x_t) - \\nabla g_t\\| \\leq K_{1,t}$ and $\\|g(x_t) - \\hat{g}_t\\| \\leq K_{0,t}$ with probability $1 - \\delta$. Plug them in the inequality above to obtain,\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + 2\\gamma_{T+1}(DK_{1,t} + K_{0,t}) + LgD^2\\gamma^2$$\n$$\\leq (1 - (T + 1)^{2/3})g(x_t) - g(x_0)$$\n$$+ 2D(A^{2/3}_1 \\log(6d/\\delta') + A^{2/30}_0 \\log(6d/\\delta')) + LgD^2\\left(\\frac{t + 1}{3}(T + 1)^{2/3} + 2(T + 1)^{4/3}\\right)$$\nwith probability $1 - \\delta'$ for all $t$. Let $C3 = 2(DA^{2/3}_1 + A^{2/3}_0)$. Then we can sum all the inequality up for all $t$ to obtain,\n\n$$\ng(x_{t+1}) - g(x_0) \\leq (1 - \\frac{1}{(T + 1)^{2/3}})(g(x_t) - g(x_0)) + C3\\left(\\frac{t + 1}{3}(T + 1)^{2/3} + 2(T + 1)^{4/3}\\right)$$\n$$\\leq (1 - \\frac{1}{(T + 1)^{2/3}})(g(x_t) - g(x_0)) + C3\\left(\\frac{t + 1}{3}(T + 1)^{2/3}\\right)$$\nBy induction, we have for all $t \\geq 1$, $g(x_{t+1}) - g(x_0) \\leq C3 \\log(6Td/\\delta) + LgD^2/2(T + 1)^{1/3}$\n\nwith probability $1 - \\delta$, where $\\delta = T\\delta'$.\n\nFor upper-level, by Lemma B.2, we have\n\n$$\n\\gamma_{t+1}G(x_t) \\leq f(x_t) - f(x_{t+1}) + \\gamma_{t+1}D\\|\\nabla f(x_t) - \\nabla f_t\\| + Lf\\gamma^2$$\nwith probability $1 - \\delta'$. Plug it and by Lemma 4.1, we have $\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq A^{2/3}(t+1)^{1/3}$. Set $\\gamma_{t+1} = 1/(T + 1)^{2/3}$ in the inequality above to obtain,\n\n$$\n\\sum_{t=0}^{T-1} \\gamma_{t+1}G(x_t) \\leq f(x_0) - f(x_T) + D\\sum_{t=0}^{T-1} \\gamma_{t+1}\\|\\nabla f(x_t) - \\nabla f_t\\| + LfD^2\\sum_{t=0}^{T-1} \\gamma^2$$\n$$\\leq f(x_0) - f(x_T) + D\\sum_{t=0}^{T-1} (t + 2)^{1/3}(T + 1)^{2/3} + LfD^2\\sum_{t=0}^{T-1} (T + 1)^{4/3}$$\n$$\\leq f(x_0) - f(x_T) + 3\\sqrt{2}DA^{2/3}_2 \\log(6d/\\delta') + LfD^2\\sqrt{2}(T + 1)^{1/3}$$"}]}, {"page": 27, "text": "Let xt\u2217   = arg min    1\u2264t\u2264T G(xt), then\n            G(xt\u2217) \u2264      T\u22121  1        T\u22121  \u03b3t+1G(xt)\n                            t=0 \u03b3t+1    t=0\n                     \u2264         1                               2DA2/3 2      log(6Td/\u03b4) + LfD2    2           1               (66)\n                         (T + 1)1/3 (f(x0) \u2212       f(xT ) + 3                                           (T + 1)1/3 )\n                     \u2264         1                      + 32DA2/3 2     log(6Td/\u03b4) + LfD2     2          1\n                         (T + 1)1/3 (f(x0) \u2212     \u2032 f                                             (T + 1)1/3 )\nwith probability 1 \u2212       \u03b4, where \u03b4 = T\u03b4        . By letting C4 = 3     2DA2/3 2   , the theorem is obtained.\nD       Proof of Theorem for Algorithm 2\nD.1      Proof of Theorem 4.6\nProof. For lower-level By Lemma B.2, we have\n              g(xt+1) \u2212    g(x0) \u2264     (1 \u2212  \u03b3t+1)(g(xt) \u2212      g(x0)) + D\u03b3t+1(\u2225\u2207g(xt) \u2212            \u2207gt\u2225   + K1,t)            (67)\n                                   + \u03b3t+1(\u2225g(xt) \u2212       \u02c6                           t+1\n                                                         gt\u2225  + K0,t) + LgD2\u03b32   2\nBy Lemma 4.2, we have \u2225\u2207g(xt)\u2212              \u2207gt\u2225    \u2264  4LgD\u03b3       log(12/\u03b4    \u2032) and \u2225g(xt)\u2212\u02c6    gt\u2225  \u2264  4LlD\u03b3       log(12/\u03b4   \u2032)\nwith probability 1 \u2212        \u03b4\u2032. Let C5 = 8D(DLg + Ll) and \u03b4 = T\u03b4\u2032. Plug them in inequality above and\nlet \u03b3t = \u03b3 = log T/T to obtain,\n              g(xT+1) \u2212      g(x0) \u2264    (1 \u2212  \u03b3)(g(xT ) \u2212     g(x0)) + (C5        log(12/\u03b4   \u2032) + LgD2/2)\u03b32                   (68)\nwith probability 1 \u2212       \u03b4/T. Sum up the inequalities for all 1 \u2264               t \u2264  T to get,\n    g(xT+1) \u2212     g(x0) = (1 \u2212      \u03b3)T (g(x0) \u2212     g(x0)) + (C5       log(12/\u03b4   \u2032) + LgD2/2)\u03b32         T  (1 \u2212  \u03b3)k\n                                                                                                         k=1                  (69)\n                                          log(12/\u03b4   \u2032) + LgD2/2)\u03b3 \u2264         (C5     log(12T/\u03b4) + LgD2/2) log T\nwith probability 1 \u2212      \u2264\u03b4.0 + (C5                                                              T\nFor upper-level, by Lemma B.2, we have,\n              f(xT ) \u2212    f \u2217 \u2264  (1 \u2212   \u03b3T )f(xT\u22121) \u2212      f \u2217 + D\u03b3T \u2225\u2207f(xT\u22121) \u2212           \u2207ft\u22121\u2225    + LfD2\u03b32 2   T           (70)\nNow we proceed by replacing the terms \u2225\u2207f(xt) \u2212   \u2032),               \u2207ft\u2225    by its upper bounds from Lemma 4.2, i.e.\n\u2225\u2207f(xt) \u2212      \u2207ft\u2225   \u2264   4LfD\u03b3       log (12/\u03b4                                                     \u2032) + 1/2)\n                   f(xT ) \u2212    f \u2217 \u2264  (1 \u2212   \u03b3)(f(xT\u22121) \u2212      f \u2217) + LfD2\u03b32(4          log (12/\u03b4                             (71)\n                                                                27", "md": "Let $$x_{t^*} = \\text{arg min}_{1\\leq t\\leq T} G(x_t)$$, then\n$$G(x_{t^*}) \\leq \\sum_{t=0}^{T-1} \\frac{1}{\\gamma_{t+1}} \\sum_{t=0}^{T-1} \\gamma_{t+1} G(x_t)$$\n$$\\leq \\frac{1}{(T+1)^{1/3}} \\left(2DA^{2/3} \\log(6Td/\\delta) + LfD^2\\right)^2 + 32DA^{2/3} \\log(6Td/\\delta) + LfD^2$$\n$$\\leq \\frac{1}{(T+1)^{1/3}} \\left(f(x_0) - f(x_T) + 3\\right) + 32DA^{2/3} \\log(6Td/\\delta) + LfD^2$$\nwith probability $1 - \\delta$, where $\\delta = T\\delta'$. By letting $C_4 = \\frac{3}{2}DA^{2/3}$, the theorem is obtained.\n\n### Proof of Theorem for Algorithm 2\n\n#### Proof of Theorem 4.6\n**Proof.** For lower-level, By Lemma B.2, we have\n$$g(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\|\\nabla g(x_t) - \\nabla g_t\\| + K_{1,t})$$\n$$+ \\gamma_{t+1}(\\|g(x_t) - \\hat{g}_{t+1}\\| + K_{0,t}) + LgD^2\\gamma^2$$\nBy Lemma 4.2, we have $\\|\\nabla g(x_t) - \\nabla g_t\\| \\leq 4LgD\\gamma \\log(12/\\delta')$ and $\\|g(x_t) - \\hat{g}_t\\| \\leq 4LlD\\gamma \\log(12/\\delta')$\nwith probability $1 - \\delta'$. Let $C_5 = 8D(DLg + Ll)$ and $\\delta = T\\delta'$. Plug them in the inequality above and\nlet $\\gamma_t = \\gamma = \\log T/T$ to obtain,\n$$g(x_{T+1}) - g(x_0) \\leq (1 - \\gamma)(g(x_T) - g(x_0)) + (C_5 \\log(12/\\delta') + LgD^2/2)\\gamma^2$$\nwith probability $1 - \\delta/T$. Sum up the inequalities for all $1 \\leq t \\leq T$ to get,\n$$g(x_{T+1}) - g(x_0) = (1 - \\gamma)^T (g(x_0) - g(x_0)) + (C_5 \\log(12/\\delta') + LgD^2/2)\\gamma^2 \\sum_{k=1}^{T} (1 - \\gamma)^k$$\n$$\\leq (C_5 \\log(12T/\\delta) + LgD^2/2) \\log T$$\nwith probability $1 - \\delta_0 + (C_5/T)$.\n\nFor upper-level, by Lemma B.2, we have,\n$$f(x_T) - f^* \\leq (1 - \\gamma T)f(x_{T-1}) - f^* + D\\gamma T \\|\\nabla f(x_{T-1}) - \\nabla f_{T-1}\\| + LfD^2\\gamma^2 T$$\n\nNow we proceed by replacing the terms $\\|\\nabla f(x_t) - \\nabla f_t\\|$ by its upper bounds from Lemma 4.2, i.e.\n$$\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq 4LfD\\gamma \\log(12/\\delta') + 1/2$$\n$$f(x_T) - f^* \\leq (1 - \\gamma)(f(x_{T-1}) - f^*) + LfD^2\\gamma^2(4\\log(12/\\delta))$$", "images": [], "items": [{"type": "text", "value": "Let $$x_{t^*} = \\text{arg min}_{1\\leq t\\leq T} G(x_t)$$, then\n$$G(x_{t^*}) \\leq \\sum_{t=0}^{T-1} \\frac{1}{\\gamma_{t+1}} \\sum_{t=0}^{T-1} \\gamma_{t+1} G(x_t)$$\n$$\\leq \\frac{1}{(T+1)^{1/3}} \\left(2DA^{2/3} \\log(6Td/\\delta) + LfD^2\\right)^2 + 32DA^{2/3} \\log(6Td/\\delta) + LfD^2$$\n$$\\leq \\frac{1}{(T+1)^{1/3}} \\left(f(x_0) - f(x_T) + 3\\right) + 32DA^{2/3} \\log(6Td/\\delta) + LfD^2$$\nwith probability $1 - \\delta$, where $\\delta = T\\delta'$. By letting $C_4 = \\frac{3}{2}DA^{2/3}$, the theorem is obtained.", "md": "Let $$x_{t^*} = \\text{arg min}_{1\\leq t\\leq T} G(x_t)$$, then\n$$G(x_{t^*}) \\leq \\sum_{t=0}^{T-1} \\frac{1}{\\gamma_{t+1}} \\sum_{t=0}^{T-1} \\gamma_{t+1} G(x_t)$$\n$$\\leq \\frac{1}{(T+1)^{1/3}} \\left(2DA^{2/3} \\log(6Td/\\delta) + LfD^2\\right)^2 + 32DA^{2/3} \\log(6Td/\\delta) + LfD^2$$\n$$\\leq \\frac{1}{(T+1)^{1/3}} \\left(f(x_0) - f(x_T) + 3\\right) + 32DA^{2/3} \\log(6Td/\\delta) + LfD^2$$\nwith probability $1 - \\delta$, where $\\delta = T\\delta'$. By letting $C_4 = \\frac{3}{2}DA^{2/3}$, the theorem is obtained."}, {"type": "heading", "lvl": 3, "value": "Proof of Theorem for Algorithm 2", "md": "### Proof of Theorem for Algorithm 2"}, {"type": "heading", "lvl": 4, "value": "Proof of Theorem 4.6", "md": "#### Proof of Theorem 4.6"}, {"type": "text", "value": "**Proof.** For lower-level, By Lemma B.2, we have\n$$g(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\|\\nabla g(x_t) - \\nabla g_t\\| + K_{1,t})$$\n$$+ \\gamma_{t+1}(\\|g(x_t) - \\hat{g}_{t+1}\\| + K_{0,t}) + LgD^2\\gamma^2$$\nBy Lemma 4.2, we have $\\|\\nabla g(x_t) - \\nabla g_t\\| \\leq 4LgD\\gamma \\log(12/\\delta')$ and $\\|g(x_t) - \\hat{g}_t\\| \\leq 4LlD\\gamma \\log(12/\\delta')$\nwith probability $1 - \\delta'$. Let $C_5 = 8D(DLg + Ll)$ and $\\delta = T\\delta'$. Plug them in the inequality above and\nlet $\\gamma_t = \\gamma = \\log T/T$ to obtain,\n$$g(x_{T+1}) - g(x_0) \\leq (1 - \\gamma)(g(x_T) - g(x_0)) + (C_5 \\log(12/\\delta') + LgD^2/2)\\gamma^2$$\nwith probability $1 - \\delta/T$. Sum up the inequalities for all $1 \\leq t \\leq T$ to get,\n$$g(x_{T+1}) - g(x_0) = (1 - \\gamma)^T (g(x_0) - g(x_0)) + (C_5 \\log(12/\\delta') + LgD^2/2)\\gamma^2 \\sum_{k=1}^{T} (1 - \\gamma)^k$$\n$$\\leq (C_5 \\log(12T/\\delta) + LgD^2/2) \\log T$$\nwith probability $1 - \\delta_0 + (C_5/T)$.\n\nFor upper-level, by Lemma B.2, we have,\n$$f(x_T) - f^* \\leq (1 - \\gamma T)f(x_{T-1}) - f^* + D\\gamma T \\|\\nabla f(x_{T-1}) - \\nabla f_{T-1}\\| + LfD^2\\gamma^2 T$$\n\nNow we proceed by replacing the terms $\\|\\nabla f(x_t) - \\nabla f_t\\|$ by its upper bounds from Lemma 4.2, i.e.\n$$\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq 4LfD\\gamma \\log(12/\\delta') + 1/2$$\n$$f(x_T) - f^* \\leq (1 - \\gamma)(f(x_{T-1}) - f^*) + LfD^2\\gamma^2(4\\log(12/\\delta))$$", "md": "**Proof.** For lower-level, By Lemma B.2, we have\n$$g(x_{t+1}) - g(x_0) \\leq (1 - \\gamma_{t+1})(g(x_t) - g(x_0)) + D\\gamma_{t+1}(\\|\\nabla g(x_t) - \\nabla g_t\\| + K_{1,t})$$\n$$+ \\gamma_{t+1}(\\|g(x_t) - \\hat{g}_{t+1}\\| + K_{0,t}) + LgD^2\\gamma^2$$\nBy Lemma 4.2, we have $\\|\\nabla g(x_t) - \\nabla g_t\\| \\leq 4LgD\\gamma \\log(12/\\delta')$ and $\\|g(x_t) - \\hat{g}_t\\| \\leq 4LlD\\gamma \\log(12/\\delta')$\nwith probability $1 - \\delta'$. Let $C_5 = 8D(DLg + Ll)$ and $\\delta = T\\delta'$. Plug them in the inequality above and\nlet $\\gamma_t = \\gamma = \\log T/T$ to obtain,\n$$g(x_{T+1}) - g(x_0) \\leq (1 - \\gamma)(g(x_T) - g(x_0)) + (C_5 \\log(12/\\delta') + LgD^2/2)\\gamma^2$$\nwith probability $1 - \\delta/T$. Sum up the inequalities for all $1 \\leq t \\leq T$ to get,\n$$g(x_{T+1}) - g(x_0) = (1 - \\gamma)^T (g(x_0) - g(x_0)) + (C_5 \\log(12/\\delta') + LgD^2/2)\\gamma^2 \\sum_{k=1}^{T} (1 - \\gamma)^k$$\n$$\\leq (C_5 \\log(12T/\\delta) + LgD^2/2) \\log T$$\nwith probability $1 - \\delta_0 + (C_5/T)$.\n\nFor upper-level, by Lemma B.2, we have,\n$$f(x_T) - f^* \\leq (1 - \\gamma T)f(x_{T-1}) - f^* + D\\gamma T \\|\\nabla f(x_{T-1}) - \\nabla f_{T-1}\\| + LfD^2\\gamma^2 T$$\n\nNow we proceed by replacing the terms $\\|\\nabla f(x_t) - \\nabla f_t\\|$ by its upper bounds from Lemma 4.2, i.e.\n$$\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq 4LfD\\gamma \\log(12/\\delta') + 1/2$$\n$$f(x_T) - f^* \\leq (1 - \\gamma)(f(x_{T-1}) - f^*) + LfD^2\\gamma^2(4\\log(12/\\delta))$$"}]}, {"page": 28, "text": "with probability (1 \u2212             \u03b4 \u2032). And we can choose \u03b4 = 3T                    \u03b4\u2032 Then by telescope, with \u03b3 = log T                T , we can\nobtain,\n               f(xT ) \u2212      f \u2217 \u2264   (1 \u2212    \u03b3)T (f(x0) \u2212        f \u2217) + (4       log (12/\u03b4    \u2032 ) + 1/2)LfD2\u03b32             T  (1 \u2212    \u03b3)i\n                                 \u2264   (1 \u2212    \u03b3)T (f(x0) \u2212        f \u2217) + (4       log (12/\u03b4    \u2032) + 1/2)LfD2\u03b3             i=1                       (72)\n                                 \u2264   exp (\u2212\u03b3T       )(f(x0) \u2212       f \u2217) + (4       log (12/\u03b4     \u2032) + 1/2)Lf      D2\u03b3\n                                 \u2264   (f(x0) \u2212       f \u2217)/T + (4      log (12T/\u03b4) + 1/2)Lf                D2 log T/T\nwith probability 1 \u2212            \u03b4. Note that without loss of generality, we can assume f(x0) \u2212                                     f \u2217  \u2265   0. If it is\nless than 0, we can bound it by 0. By letting C6 = 5LfD2, the theorem is obtained.\nD.2        Proof of Theorem 4.7\nProof. For lower-level, by Lemma B.2, we have\n                 g(xt+1) \u2212      g(x0) \u2264       (1 \u2212   \u03b3t+1)(g(xt) \u2212         g(x0)) + D\u03b3t+1(\u2225\u2207g(xt) \u2212t+1               \u2207gt\u2225     + K1,t)              (73)\n                                          + \u03b3t+1(\u2225g(xt) \u2212          \u02c6\n                                                                   gt\u2225   + K0,t) + LgD2\u03b32      2\nBy Lemma 4.2, we have \u2225\u2207g(xt)\u2212    \u2032                 \u2207gt\u2225     \u2264   4LgD\u03b3         log(12/\u03b4     \u2032) and \u2225g(xt)\u2212\u02c6        gt\u2225  \u2264   4LlD\u03b3         log(12/\u03b4     \u2032)\nwith probability 1 \u2212             \u03b4 . Let C7 = 8D(DLg + Ll) and \u03b4 = T                          \u03b4\u2032. Plug them in inequality above and\nlet \u03b3t = 1/      \u221a  T to obtain,\n                    g(xt+1) \u2212       g(x0) \u2264      (1 \u2212      1                                         log(12/\u03b4     \u2032)  + LgD2\n                                                         T 1/2 )(g(xt) \u2212       g(x0)) + C7              T                   2T\n                                             \u2264   (1 \u2212      1                                         log(12/\u03b4     \u2032) + LgD2/2                      (74)\n                                                         T 1/2 )(g(xt) \u2212       g(x0)) + C7                      T\nwith probability 1 \u2212             \u03b4/T   . Sum up the inequalities for all t \u2265                    1 to get,\n  g(xt+1) \u2212       g(x0) = (1 \u2212           1                                              log(12/\u03b4   T \u2032) + LgD2/2)            t  (1 \u2212      1\n                                       T 1/2 )tE[g(x0) \u2212         g(x0)] + (C7                                              k=1          T 1/2 )k   (75)\n                           \u2264   C7    log(12T/\u03b4) + LgD2/2\n                                                 T 1/2\nwith probability 1 \u2212             \u03b4.\nFor upper-level, by Lemma B.2, we have\n                                                                                                                       t+1D2\n                         \u03b3t+1G(xt) \u2264        f(xt) \u2212      f(xt+1) + \u03b3t+1D\u2225\u2207f(xt) \u2212                   \u2207ft\u2225     + Lf\u03b32     2                          (76)\n                                                                           28", "md": "# Math Equations\n\nwith probability (1 - \u03b4'). And we can choose \u03b4 = 3T / \u03b4'. Then by telescope, with \u03b3 = log T / T, we can obtain,\n\n$$\n\\begin{align*}\n&f(xT) - f^* \\leq (1 - \\gamma)T(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma^2T(1 - \\gamma)i \\\\\n&\\leq (1 - \\gamma)T(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma i=1 \\\\\n&\\leq \\exp(-\\gamma T)(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma \\\\\n&\\leq (f(x0) - f^*)/T + (4\\log(12T/\\delta) + 1/2)LfD^2\\log T/T\n\\end{align*}\n$$\nwith probability 1 - \u03b4. Note that without loss of generality, we can assume f(x0) - f* \u2265 0. If it is less than 0, we can bound it by 0. By letting C6 = 5LfD^2, the theorem is obtained.\n\nProof of Theorem 4.7\n\nFor lower-level, by Lemma B.2, we have\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) \\leq (1 - \\gamma t+1)(g(xt) - g(x0)) + D\\gamma t+1(\\|\\nabla g(xt) - \\nabla g_t\\| + K1,t) \\\\\n&+ \\gamma t+1(\\|g(xt) - \\hat{g}_t\\| + K0,t) + LgD^2\\gamma^2 2\n\\end{align*}\n$$\nBy Lemma 4.2, we have $\\|\\nabla g(xt) - \\nabla g_t\\| \\leq 4LgD\\gamma \\log(12/\\delta')$ and $\\|g(xt) - \\hat{g}_t\\| \\leq 4LlD\\gamma \\log(12/\\delta')$ with probability 1 - \u03b4. Let C7 = 8D(DLg + Ll) and \u03b4 = T / \u03b4'. Plug them in inequality above and let \u03b3t = 1/\u221aT to obtain,\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) \\leq (1 - 1/T^{1/2})(g(xt) - g(x0)) + C7T^{1/2} \\\\\n&\\leq (1 - 1/T^{1/2})(g(xt) - g(x0)) + C7T\n\\end{align*}\n$$\nwith probability 1 - \u03b4/T. Sum up the inequalities for all t \u2265 1 to get,\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) = (1 - 1/T^{1/2})^tE[g(x0) - g(x0)] + (C7T^{1/2})k=1 \\\\\n&\\leq C7\\log(12T/\\delta) + LgD^2/2T^{1/2}\n\\end{align*}\n$$\nwith probability 1 - \u03b4.\n\nFor upper-level, by Lemma B.2, we have\n\n$$\n\\begin{align*}\n&\\gamma t+1G(xt) \\leq f(xt) - f(xt+1) + \\gamma t+1D\\|\\nabla f(xt) - \\nabla f_t\\| + Lf\\gamma^2 2\n\\end{align*}\n$$", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations", "md": "# Math Equations"}, {"type": "text", "value": "with probability (1 - \u03b4'). And we can choose \u03b4 = 3T / \u03b4'. Then by telescope, with \u03b3 = log T / T, we can obtain,\n\n$$\n\\begin{align*}\n&f(xT) - f^* \\leq (1 - \\gamma)T(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma^2T(1 - \\gamma)i \\\\\n&\\leq (1 - \\gamma)T(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma i=1 \\\\\n&\\leq \\exp(-\\gamma T)(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma \\\\\n&\\leq (f(x0) - f^*)/T + (4\\log(12T/\\delta) + 1/2)LfD^2\\log T/T\n\\end{align*}\n$$\nwith probability 1 - \u03b4. Note that without loss of generality, we can assume f(x0) - f* \u2265 0. If it is less than 0, we can bound it by 0. By letting C6 = 5LfD^2, the theorem is obtained.\n\nProof of Theorem 4.7\n\nFor lower-level, by Lemma B.2, we have\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) \\leq (1 - \\gamma t+1)(g(xt) - g(x0)) + D\\gamma t+1(\\|\\nabla g(xt) - \\nabla g_t\\| + K1,t) \\\\\n&+ \\gamma t+1(\\|g(xt) - \\hat{g}_t\\| + K0,t) + LgD^2\\gamma^2 2\n\\end{align*}\n$$\nBy Lemma 4.2, we have $\\|\\nabla g(xt) - \\nabla g_t\\| \\leq 4LgD\\gamma \\log(12/\\delta')$ and $\\|g(xt) - \\hat{g}_t\\| \\leq 4LlD\\gamma \\log(12/\\delta')$ with probability 1 - \u03b4. Let C7 = 8D(DLg + Ll) and \u03b4 = T / \u03b4'. Plug them in inequality above and let \u03b3t = 1/\u221aT to obtain,\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) \\leq (1 - 1/T^{1/2})(g(xt) - g(x0)) + C7T^{1/2} \\\\\n&\\leq (1 - 1/T^{1/2})(g(xt) - g(x0)) + C7T\n\\end{align*}\n$$\nwith probability 1 - \u03b4/T. Sum up the inequalities for all t \u2265 1 to get,\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) = (1 - 1/T^{1/2})^tE[g(x0) - g(x0)] + (C7T^{1/2})k=1 \\\\\n&\\leq C7\\log(12T/\\delta) + LgD^2/2T^{1/2}\n\\end{align*}\n$$\nwith probability 1 - \u03b4.\n\nFor upper-level, by Lemma B.2, we have\n\n$$\n\\begin{align*}\n&\\gamma t+1G(xt) \\leq f(xt) - f(xt+1) + \\gamma t+1D\\|\\nabla f(xt) - \\nabla f_t\\| + Lf\\gamma^2 2\n\\end{align*}\n$$", "md": "with probability (1 - \u03b4'). And we can choose \u03b4 = 3T / \u03b4'. Then by telescope, with \u03b3 = log T / T, we can obtain,\n\n$$\n\\begin{align*}\n&f(xT) - f^* \\leq (1 - \\gamma)T(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma^2T(1 - \\gamma)i \\\\\n&\\leq (1 - \\gamma)T(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma i=1 \\\\\n&\\leq \\exp(-\\gamma T)(f(x0) - f^*) + (4\\log(12/\\delta') + 1/2)LfD^2\\gamma \\\\\n&\\leq (f(x0) - f^*)/T + (4\\log(12T/\\delta) + 1/2)LfD^2\\log T/T\n\\end{align*}\n$$\nwith probability 1 - \u03b4. Note that without loss of generality, we can assume f(x0) - f* \u2265 0. If it is less than 0, we can bound it by 0. By letting C6 = 5LfD^2, the theorem is obtained.\n\nProof of Theorem 4.7\n\nFor lower-level, by Lemma B.2, we have\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) \\leq (1 - \\gamma t+1)(g(xt) - g(x0)) + D\\gamma t+1(\\|\\nabla g(xt) - \\nabla g_t\\| + K1,t) \\\\\n&+ \\gamma t+1(\\|g(xt) - \\hat{g}_t\\| + K0,t) + LgD^2\\gamma^2 2\n\\end{align*}\n$$\nBy Lemma 4.2, we have $\\|\\nabla g(xt) - \\nabla g_t\\| \\leq 4LgD\\gamma \\log(12/\\delta')$ and $\\|g(xt) - \\hat{g}_t\\| \\leq 4LlD\\gamma \\log(12/\\delta')$ with probability 1 - \u03b4. Let C7 = 8D(DLg + Ll) and \u03b4 = T / \u03b4'. Plug them in inequality above and let \u03b3t = 1/\u221aT to obtain,\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) \\leq (1 - 1/T^{1/2})(g(xt) - g(x0)) + C7T^{1/2} \\\\\n&\\leq (1 - 1/T^{1/2})(g(xt) - g(x0)) + C7T\n\\end{align*}\n$$\nwith probability 1 - \u03b4/T. Sum up the inequalities for all t \u2265 1 to get,\n\n$$\n\\begin{align*}\n&g(xt+1) - g(x0) = (1 - 1/T^{1/2})^tE[g(x0) - g(x0)] + (C7T^{1/2})k=1 \\\\\n&\\leq C7\\log(12T/\\delta) + LgD^2/2T^{1/2}\n\\end{align*}\n$$\nwith probability 1 - \u03b4.\n\nFor upper-level, by Lemma B.2, we have\n\n$$\n\\begin{align*}\n&\\gamma t+1G(xt) \\leq f(xt) - f(xt+1) + \\gamma t+1D\\|\\nabla f(xt) - \\nabla f_t\\| + Lf\\gamma^2 2\n\\end{align*}\n$$"}]}, {"page": 29, "text": " By Lemma 4.2, we have \u2225\u2207f(xt)\u2212              \u2207ft\u2225    \u2264  4LfD\u03b3       log(12/\u03b4  \u2032) with probability 1\u2212\u03b4       \u2032. Plug it and\n \u03b3t+1 = 1/   \u221a T in inequality above to obtain,\n              \u221a1T  T\u22121  G(xt) \u2264    f(x0) \u2212   f(xT ) + D    T\u22121  \u03b3t+1\u2225\u2207f(xt) \u2212       \u2207ft\u2225   + LfD22    T\u22121  \u03b32t+1         (77)\n                   t=0      \u221a   \u2264  f(x0) \u2212   f(xT ) + LfD2(4t=0      log(12\u03b4  \u2032) + 1/2)                t=0\n Divide both sides by         T, we can get, Let xt\u2217       \u225c  arg min   1\u2264t\u2264T G(xt), then\n                      G(xt\u2217) \u2264    1  T\u22121  G(xt) \u2264    f(x0) \u2212   f  + LfD2(4       log(12T/\u03b4) + 1/2)                       (78)\n                                  T  t=0                                    T 1/2\n with probability 1 \u2212      \u03b4. By letting C8 = 5LfD2, the theorem is obtained.\n E      Azuma-Hoeff              ding-type inequalities\n In this section, we present two useful vector versions of Azuma-Hoeffding-type concentration in-\n equalities with uniform bound assumption or sub-gaussian assumption. They are crucial in our\n high probability analysis.\n Proposition E.1. (Pinelis and other 1994 [Pin94], Theorem 3.5) Let \u03b61, . . . , \u03b6t \u2208                      Rd be a vector-\nvalued martingale difference sequence w.r.t. a fi             ltration {Ft}, i.e. for each \u03c4 \u2208          1, . . . , t, we have\n E[\u03b6\u03c4|F\u03c4\u22121] = 0. Suppose that \u2225\u03b6\u03c4\u2225           \u2264  c\u03c4 almost surely. Then \u2200t \u2265          1,\n                                       P(\u2225   T   \u03b6\u03c4\u2225  \u2265  \u03bb) \u2264  4 exp(\u2212   4  T \u03bb2    \u03c4 )                                  (79)\n                                            \u03c4=1                               \u03c4=1 c2\n Proposition E.2. (Jin et al. [JNGKJ19], Corollary 7) Let \u03b61, . . . , \u03b6t \u2208                  Rd be a vector-valued mar-\ntingale difference sequence w.r.t. a fi       ltration {Ft}, i.e. for each \u03c4 \u2208       1, . . . , t, we have E[\u03b6\u03c4|F\u03c4\u22121] = 0.\n Suppose that E[exp(\u2225\u03b6\u03c4\u22252/c2       \u03c4)] \u2264  exp(1). Then there exists a absolute constant c such that, for any\n \u03b4 > 0, with probability at least 1 \u2212        \u03b4,\n                                             \u2225  T  \u03b6\u03c4\u2225  \u2264  c \u00b7     T  c2\u03c4 log 2d                                         (80)\n                                               \u03c4=1                \u03c4=1          \u03b4\n This proposition was also used in previous literature including [Zha05] and [XSZWQ20].                                 It is\n common to use such martingale inequality to obtain some high-probability results recently.\n F      Experiment details\n In this section, we include more details about the numerical experiments in Section 5. For com-\n pleteness, we briefly introduce the update rules of aR-IP-SeG in [JY22] and DBGD in [GL21]. In\n                                                              29", "md": "# Math Equations and Tables\n\n## Math Equations:\n\nBy Lemma 4.2, we have $$\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq 4LfD\\gamma \\log\\left(\\frac{12}{\\delta'}\\right)$$ with probability $1-\\delta'$. Plug it and $\\gamma_{t+1} = \\frac{1}{\\sqrt{T}}$ in inequality above to obtain,\n\n$$\\sqrt{\\frac{1}{T} \\sum_{t=0}^{T-1} G(x_t)} \\leq f(x_0) - f(x_T) + \\frac{D}{T-1} \\gamma_{t+1} \\|\\nabla f(x_t) - \\nabla f_t\\| + \\frac{LfD^2}{2(T-1)} \\gamma_{2t+1} \\quad (77)$$\n\n$$\\leq f(x_0) - f(x_T) + LfD^2\\left(4\\sum_{t=0}^{T-1} \\log\\left(\\frac{12\\delta'}{T}\\right) + \\frac{1}{2}\\right) \\quad (78)$$ with probability $1 - \\delta$. By letting $C_8 = 5LfD^2$, the theorem is obtained.\n\nAzuma-Hoeffding-type inequalities\n\nProposition E.1. (Pinelis and other 1994 [Pin94], Theorem 3.5) Let $\\zeta_1, ..., \\zeta_t \\in \\mathbb{R}^d$ be a vector-valued martingale difference sequence w.r.t. a filtration $\\{F_t\\}$, i.e. for each $\\tau \\in 1, ..., t$, we have $E[\\zeta_\\tau | F_{\\tau-1}] = 0$. Suppose that $\\|\\zeta_\\tau\\| \\leq c\\tau$ almost surely. Then $\\forall t \\geq 1$,\n\n$$P\\left(\\|\\sum_{\\tau=1}^{t} \\zeta_\\tau\\| \\geq \\lambda\\right) \\leq 4 \\exp\\left(-\\frac{4}{c^2} \\sum_{\\tau=1}^{t} \\lambda^2\\right) \\quad (79)$$\n\nProposition E.2. (Jin et al. [JNGKJ19], Corollary 7) Let $\\zeta_1, ..., \\zeta_t \\in \\mathbb{R}^d$ be a vector-valued martingale difference sequence w.r.t. a filtration $\\{F_t\\}$, i.e. for each $\\tau \\in 1, ..., t$, we have $E[\\zeta_\\tau | F_{\\tau-1}] = 0$. Suppose that $E[\\exp(\\|\\zeta_\\tau\\|^2/c^2\\tau)] \\leq \\exp(1)$. Then there exists an absolute constant $c$ such that, for any $\\delta > 0$, with probability at least $1 - \\delta$,\n\n$$\\|\\sum_{\\tau=1}^{t} \\zeta_\\tau\\| \\leq c \\cdot \\sqrt{\\sum_{\\tau=1}^{t} \\frac{c^2\\tau \\log 2d}{\\delta}} \\quad (80)$$\n\nThis proposition was also used in previous literature including [Zha05] and [XSZWQ20]. It is common to use such martingale inequality to obtain some high-probability results recently.\n\n## Experiment Details:\n\nIn this section, we include more details about the numerical experiments in Section 5. For completeness, we briefly introduce the update rules of aR-IP-SeG in [JY22] and DBGD in [GL21].", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Tables", "md": "# Math Equations and Tables"}, {"type": "heading", "lvl": 2, "value": "Math Equations:", "md": "## Math Equations:"}, {"type": "text", "value": "By Lemma 4.2, we have $$\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq 4LfD\\gamma \\log\\left(\\frac{12}{\\delta'}\\right)$$ with probability $1-\\delta'$. Plug it and $\\gamma_{t+1} = \\frac{1}{\\sqrt{T}}$ in inequality above to obtain,\n\n$$\\sqrt{\\frac{1}{T} \\sum_{t=0}^{T-1} G(x_t)} \\leq f(x_0) - f(x_T) + \\frac{D}{T-1} \\gamma_{t+1} \\|\\nabla f(x_t) - \\nabla f_t\\| + \\frac{LfD^2}{2(T-1)} \\gamma_{2t+1} \\quad (77)$$\n\n$$\\leq f(x_0) - f(x_T) + LfD^2\\left(4\\sum_{t=0}^{T-1} \\log\\left(\\frac{12\\delta'}{T}\\right) + \\frac{1}{2}\\right) \\quad (78)$$ with probability $1 - \\delta$. By letting $C_8 = 5LfD^2$, the theorem is obtained.\n\nAzuma-Hoeffding-type inequalities\n\nProposition E.1. (Pinelis and other 1994 [Pin94], Theorem 3.5) Let $\\zeta_1, ..., \\zeta_t \\in \\mathbb{R}^d$ be a vector-valued martingale difference sequence w.r.t. a filtration $\\{F_t\\}$, i.e. for each $\\tau \\in 1, ..., t$, we have $E[\\zeta_\\tau | F_{\\tau-1}] = 0$. Suppose that $\\|\\zeta_\\tau\\| \\leq c\\tau$ almost surely. Then $\\forall t \\geq 1$,\n\n$$P\\left(\\|\\sum_{\\tau=1}^{t} \\zeta_\\tau\\| \\geq \\lambda\\right) \\leq 4 \\exp\\left(-\\frac{4}{c^2} \\sum_{\\tau=1}^{t} \\lambda^2\\right) \\quad (79)$$\n\nProposition E.2. (Jin et al. [JNGKJ19], Corollary 7) Let $\\zeta_1, ..., \\zeta_t \\in \\mathbb{R}^d$ be a vector-valued martingale difference sequence w.r.t. a filtration $\\{F_t\\}$, i.e. for each $\\tau \\in 1, ..., t$, we have $E[\\zeta_\\tau | F_{\\tau-1}] = 0$. Suppose that $E[\\exp(\\|\\zeta_\\tau\\|^2/c^2\\tau)] \\leq \\exp(1)$. Then there exists an absolute constant $c$ such that, for any $\\delta > 0$, with probability at least $1 - \\delta$,\n\n$$\\|\\sum_{\\tau=1}^{t} \\zeta_\\tau\\| \\leq c \\cdot \\sqrt{\\sum_{\\tau=1}^{t} \\frac{c^2\\tau \\log 2d}{\\delta}} \\quad (80)$$\n\nThis proposition was also used in previous literature including [Zha05] and [XSZWQ20]. It is common to use such martingale inequality to obtain some high-probability results recently.", "md": "By Lemma 4.2, we have $$\\|\\nabla f(x_t) - \\nabla f_t\\| \\leq 4LfD\\gamma \\log\\left(\\frac{12}{\\delta'}\\right)$$ with probability $1-\\delta'$. Plug it and $\\gamma_{t+1} = \\frac{1}{\\sqrt{T}}$ in inequality above to obtain,\n\n$$\\sqrt{\\frac{1}{T} \\sum_{t=0}^{T-1} G(x_t)} \\leq f(x_0) - f(x_T) + \\frac{D}{T-1} \\gamma_{t+1} \\|\\nabla f(x_t) - \\nabla f_t\\| + \\frac{LfD^2}{2(T-1)} \\gamma_{2t+1} \\quad (77)$$\n\n$$\\leq f(x_0) - f(x_T) + LfD^2\\left(4\\sum_{t=0}^{T-1} \\log\\left(\\frac{12\\delta'}{T}\\right) + \\frac{1}{2}\\right) \\quad (78)$$ with probability $1 - \\delta$. By letting $C_8 = 5LfD^2$, the theorem is obtained.\n\nAzuma-Hoeffding-type inequalities\n\nProposition E.1. (Pinelis and other 1994 [Pin94], Theorem 3.5) Let $\\zeta_1, ..., \\zeta_t \\in \\mathbb{R}^d$ be a vector-valued martingale difference sequence w.r.t. a filtration $\\{F_t\\}$, i.e. for each $\\tau \\in 1, ..., t$, we have $E[\\zeta_\\tau | F_{\\tau-1}] = 0$. Suppose that $\\|\\zeta_\\tau\\| \\leq c\\tau$ almost surely. Then $\\forall t \\geq 1$,\n\n$$P\\left(\\|\\sum_{\\tau=1}^{t} \\zeta_\\tau\\| \\geq \\lambda\\right) \\leq 4 \\exp\\left(-\\frac{4}{c^2} \\sum_{\\tau=1}^{t} \\lambda^2\\right) \\quad (79)$$\n\nProposition E.2. (Jin et al. [JNGKJ19], Corollary 7) Let $\\zeta_1, ..., \\zeta_t \\in \\mathbb{R}^d$ be a vector-valued martingale difference sequence w.r.t. a filtration $\\{F_t\\}$, i.e. for each $\\tau \\in 1, ..., t$, we have $E[\\zeta_\\tau | F_{\\tau-1}] = 0$. Suppose that $E[\\exp(\\|\\zeta_\\tau\\|^2/c^2\\tau)] \\leq \\exp(1)$. Then there exists an absolute constant $c$ such that, for any $\\delta > 0$, with probability at least $1 - \\delta$,\n\n$$\\|\\sum_{\\tau=1}^{t} \\zeta_\\tau\\| \\leq c \\cdot \\sqrt{\\sum_{\\tau=1}^{t} \\frac{c^2\\tau \\log 2d}{\\delta}} \\quad (80)$$\n\nThis proposition was also used in previous literature including [Zha05] and [XSZWQ20]. It is common to use such martingale inequality to obtain some high-probability results recently."}, {"type": "heading", "lvl": 2, "value": "Experiment Details:", "md": "## Experiment Details:"}, {"type": "text", "value": "In this section, we include more details about the numerical experiments in Section 5. For completeness, we briefly introduce the update rules of aR-IP-SeG in [JY22] and DBGD in [GL21].", "md": "In this section, we include more details about the numerical experiments in Section 5. For completeness, we briefly introduce the update rules of aR-IP-SeG in [JY22] and DBGD in [GL21]."}]}, {"page": 30, "text": "the following, we use the notation \u03a0Z                                              (\u00b7) to denote the Euclidean projection onto the set Z.\nThe aR-IP-SeG algorithm is given by,\n                                                          y  t+1 = \u03a0Z            (xt \u2212        \u03b3t(\u2207      f\u02dc (xt, \u03b8t)) + \u03c1t\u2207\u02dc               g(xt, \u03bet))\n                                                                                                                       \u2032                                \u2032\n                                                          x  t+1 = \u03a0Z            (xt \u2212        \u03b3t(\u2207      f\u02dc (yt, \u03b8     t)) + \u03c1t\u2207\u02dc          g(yt, \u03be       t))\n                                                          \u0393t+1 = \u0393t + (\u03b3t\u03c1t)r                                                                                                                    (81)\n                                                          \u00af                    y   t + (\u03b3t\u03c1t)ryt+1\n                                                          y  t+1 = \u0393t           \u00af         \u0393t+1\nwhere \u03b3t is the stepsize, \u03c1t is the regularization parameter, and \u00af                                                                          y  T is the output of the algorithm.\n In this experiment, we choose \u03b3t = \u03b30/(t + 1)3/4 and \u03c1t = \u03c10(t + 1)1/4 for some constants \u03b30 and\n \u03c10.\nThe DBGD-sto is a stochastic version of DBGD, which simply replaces the gradients in DBGD\nwith stochastic gradients. Although the stochastic version of DBGD does not have a theoretical\n guarantee, it has been used to solve stochastic simple bilevel optimization problems in [GL21],\nwhich worked pretty well empirically. Hence, we use it as a baseline for solving stochastic simple\nbilevel problems and compare it with our proposed algorithms. The DBGD algorithm is given by\nwhere \u03b3k is the stepsize and we set \u03bbk as                         x  k+1 = xk \u2212               \u03b3k (\u2207f (xk) + \u03bbk\u2207g (xk))\n                                  \u03c6 (xk) \u2212           \u27e8\u2207f (xk) , \u2207g (xk)\u27e9                      , 0             and            \u03c6(x) = min                   \u03b1(g(x) \u2212             \u02c6\n       \u03bbk = max                                     \u2225\u2207g (xk)\u22252                                                                                                                 g), \u03b2\u2225\u2207g(x)\u22252\nwhere \u03b1 and \u03b2 are hyperparameters and \u02c6                                                     g is a lower bound of g\u2217. In this experiment, we choose\ng\u02c6= 0. We also note that [GL21] only considered unconstrained simple bilevel optimization, i.e.\n Z = Rd. We further project xt onto Z for each iteration to ensure the constraints are satisfied.\n F.1           Over-parameterized regression\n Dataset generation. The original Wikipedia Math Essential dataset [Roz+21] composes of a\ndata matrix of size 1068 \u00d7 731. We randomly select one of the columns as the outcome vector\nb \u2208       R1068 and the rest to be a new matrix A \u2208                                                       R1068\u00d7731. We set constraint parameter \u03bb = 10 in\nthis experiment.\nInitialization. We run the algorithm, SPIDER-FW [YSC19], with stepsize chosen as \u03b3t = 0.1/(t                                                                                                          +\n1) on the lower-level problem in (1). We terminate the process to get x0 as the initial point for\nboth SBCGI 1 and SBCGF 2 after 105 stochastic oracle queries.\nImplementation details. We query stochastic oracle 9                                                                        \u00d7    105 times with stepsize \u03b3t = 0.01/(t                           +    1)\nand \u03b3 = 10\u22125 for SBCGI 1 and SBCGF 2 with Kt = 10\u22124/\u221at + 1, respectively. In each iteration,\nwe need to solve the following subproblem induced by the methods,\n                             mins     \u27e8\u2207f (\u03b2k) , s\u27e9                     s.t.          \u2225s\u22251 \u2264          \u03bb, \u27e8\u2207g (\u03b2k) , s \u2212                   \u03b2k\u27e9      \u2264    g (\u03b20) \u2212           g (\u03b2k) .              (82)\nIntroduce s+, s\u2212                      \u2265    0 such that s = s+ \u2212                         s\u2212. Then we can reformulate the problem above as follows,\n                   min          \u2207f (\u03b2k) , s+ \u2212                  s\u2212\n                  s+   ,s\u2212\n                    s.t. s+, s\u2212            \u2265     0,     s+, 1         +      s\u2212, 1          \u2264    \u03bb,     \u2207g (\u03b2k) , s+ \u2212                  s\u2212     \u2212    \u03b2k       \u2264     g (\u03b20) \u2212           g (\u03b2k) ,   (83)\n                                                                                                         30", "md": "In the following, we use the notation $$\\Pi_Z(\\cdot)$$ to denote the Euclidean projection onto the set Z.\n\nThe aR-IP-SeG algorithm is given by,\n\n$$\n\\begin{align*}\ny_{t+1} & = \\Pi_Z(x_t - \\gamma_t(\\nabla f^\\sim(x_t, \\theta_t)) + \\rho_t\\nabla^\\sim g(x_t, \\xi_t)) \\\\\nx_{t+1} & = \\Pi_Z(x_t - \\gamma_t(\\nabla f^\\sim(y_t, \\theta_t)) + \\rho_t\\nabla^\\sim g(y_t, \\xi_t)) \\\\\n\\Gamma_{t+1} & = \\Gamma_t + (\\gamma_t\\rho_t)r \\\\\n\\bar{y}_{t+1} & = \\Gamma_t \\bar{y}_t + (\\gamma_t\\rho_t)r y_{t+1}\n\\end{align*}\n$$\nwhere $$\\gamma_t$$ is the stepsize, $$\\rho_t$$ is the regularization parameter, and $$\\bar{y}_T$$ is the output of the algorithm.\n\nIn this experiment, we choose $$\\gamma_t = \\frac{\\gamma_0}{(t + 1)^{3/4}}$$ and $$\\rho_t = \\rho_0(t + 1)^{1/4}$$ for some constants $$\\gamma_0$$ and $$\\rho_0$$.\n\nThe DBGD-sto is a stochastic version of DBGD, which simply replaces the gradients in DBGD with stochastic gradients. Although the stochastic version of DBGD does not have a theoretical guarantee, it has been used to solve stochastic simple bilevel optimization problems in [GL21], which worked pretty well empirically. Hence, we use it as a baseline for solving stochastic simple bilevel problems and compare it with our proposed algorithms. The DBGD algorithm is given by\n\n$$\nx_{k+1} = x_k - \\gamma_k (\\nabla f(x_k) + \\lambda_k\\nabla g(x_k))\n$$\n$$\n\\phi(x_k) - \\langle\\nabla f(x_k), \\nabla g(x_k)\\rangle, 0 \\text{ and } \\phi(x) = \\min_\\alpha(g(x) - \\hat{g})\n$$\nwhere $$\\gamma_k$$ is the stepsize and we set $$\\lambda_k$$ as\n\n$$\n\\lambda_k = \\max\\left(\\frac{\\|\\nabla g(x_k)\\|^2}{\\alpha}, \\beta\\|\\nabla g(x)\\|^2\\right)\n$$\nwhere $$\\alpha$$ and $$\\beta$$ are hyperparameters and $$\\hat{g}$$ is a lower bound of $$g^*$\n\nIn this experiment, we choose $$\\hat{g} = 0$$. We also note that [GL21] only considered unconstrained simple bilevel optimization, i.e. $$Z = \\mathbb{R}^d$$. We further project $$x_t$$ onto Z for each iteration to ensure the constraints are satisfied.\n\n## F.1 Over-parameterized regression\n\nDataset generation. The original Wikipedia Math Essential dataset [Roz+21] composes of a data matrix of size 1068 \u00d7 731. We randomly select one of the columns as the outcome vector $$b \\in \\mathbb{R}^{1068}$$ and the rest to be a new matrix $$A \\in \\mathbb{R}^{1068\\times731}$$. We set constraint parameter $$\\lambda = 10$$ in this experiment.\n\nInitialization. We run the algorithm, SPIDER-FW [YSC19], with stepsize chosen as $$\\gamma_t = \\frac{0.1}{(t+1)}$$ on the lower-level problem in (1). We terminate the process to get $$x_0$$ as the initial point for both SBCGI 1 and SBCGF 2 after 105 stochastic oracle queries.\n\nImplementation details. We query stochastic oracle $$9 \\times 10^5$$ times with stepsize $$\\gamma_t = \\frac{0.01}{(t+1)}$$ and $$\\gamma = 10^{-5}$$ for SBCGI 1 and SBCGF 2 with $$K_t = \\frac{10^{-4}}{\\sqrt{t} + 1}$$, respectively. In each iteration, we need to solve the following subproblem induced by the methods,\n\n$$\n\\begin{align*}\n\\min_s & \\langle\\nabla f(\\beta_k), s\\rangle \\\\\n\\text{s.t.} & \\|\\mathbf{s}\\|_1 \\leq \\lambda, \\langle\\nabla g(\\beta_k), s - \\beta_k\\rangle \\leq g(\\beta_0) - g(\\beta_k) . (82)\n\\end{align*}\n$$\n\nIntroduce $$s^+, s^- \\geq 0$$ such that $$s = s^+ - s^-$$. Then we can reformulate the problem above as follows,\n\n$$\n\\begin{align*}\n\\min & \\langle\\nabla f(\\beta_k), s^+ - s^-\\rangle \\\\\n\\text{s.t.} & s^+, s^- \\geq 0, s^+ + s^- \\leq \\lambda, \\langle\\nabla g(\\beta_k), s^+ - s^- - \\beta_k\\rangle \\leq g(\\beta_0) - g(\\beta_k) . (83)\n\\end{align*}\n$$", "images": [], "items": [{"type": "text", "value": "In the following, we use the notation $$\\Pi_Z(\\cdot)$$ to denote the Euclidean projection onto the set Z.\n\nThe aR-IP-SeG algorithm is given by,\n\n$$\n\\begin{align*}\ny_{t+1} & = \\Pi_Z(x_t - \\gamma_t(\\nabla f^\\sim(x_t, \\theta_t)) + \\rho_t\\nabla^\\sim g(x_t, \\xi_t)) \\\\\nx_{t+1} & = \\Pi_Z(x_t - \\gamma_t(\\nabla f^\\sim(y_t, \\theta_t)) + \\rho_t\\nabla^\\sim g(y_t, \\xi_t)) \\\\\n\\Gamma_{t+1} & = \\Gamma_t + (\\gamma_t\\rho_t)r \\\\\n\\bar{y}_{t+1} & = \\Gamma_t \\bar{y}_t + (\\gamma_t\\rho_t)r y_{t+1}\n\\end{align*}\n$$\nwhere $$\\gamma_t$$ is the stepsize, $$\\rho_t$$ is the regularization parameter, and $$\\bar{y}_T$$ is the output of the algorithm.\n\nIn this experiment, we choose $$\\gamma_t = \\frac{\\gamma_0}{(t + 1)^{3/4}}$$ and $$\\rho_t = \\rho_0(t + 1)^{1/4}$$ for some constants $$\\gamma_0$$ and $$\\rho_0$$.\n\nThe DBGD-sto is a stochastic version of DBGD, which simply replaces the gradients in DBGD with stochastic gradients. Although the stochastic version of DBGD does not have a theoretical guarantee, it has been used to solve stochastic simple bilevel optimization problems in [GL21], which worked pretty well empirically. Hence, we use it as a baseline for solving stochastic simple bilevel problems and compare it with our proposed algorithms. The DBGD algorithm is given by\n\n$$\nx_{k+1} = x_k - \\gamma_k (\\nabla f(x_k) + \\lambda_k\\nabla g(x_k))\n$$\n$$\n\\phi(x_k) - \\langle\\nabla f(x_k), \\nabla g(x_k)\\rangle, 0 \\text{ and } \\phi(x) = \\min_\\alpha(g(x) - \\hat{g})\n$$\nwhere $$\\gamma_k$$ is the stepsize and we set $$\\lambda_k$$ as\n\n$$\n\\lambda_k = \\max\\left(\\frac{\\|\\nabla g(x_k)\\|^2}{\\alpha}, \\beta\\|\\nabla g(x)\\|^2\\right)\n$$\nwhere $$\\alpha$$ and $$\\beta$$ are hyperparameters and $$\\hat{g}$$ is a lower bound of $$g^*$\n\nIn this experiment, we choose $$\\hat{g} = 0$$. We also note that [GL21] only considered unconstrained simple bilevel optimization, i.e. $$Z = \\mathbb{R}^d$$. We further project $$x_t$$ onto Z for each iteration to ensure the constraints are satisfied.", "md": "In the following, we use the notation $$\\Pi_Z(\\cdot)$$ to denote the Euclidean projection onto the set Z.\n\nThe aR-IP-SeG algorithm is given by,\n\n$$\n\\begin{align*}\ny_{t+1} & = \\Pi_Z(x_t - \\gamma_t(\\nabla f^\\sim(x_t, \\theta_t)) + \\rho_t\\nabla^\\sim g(x_t, \\xi_t)) \\\\\nx_{t+1} & = \\Pi_Z(x_t - \\gamma_t(\\nabla f^\\sim(y_t, \\theta_t)) + \\rho_t\\nabla^\\sim g(y_t, \\xi_t)) \\\\\n\\Gamma_{t+1} & = \\Gamma_t + (\\gamma_t\\rho_t)r \\\\\n\\bar{y}_{t+1} & = \\Gamma_t \\bar{y}_t + (\\gamma_t\\rho_t)r y_{t+1}\n\\end{align*}\n$$\nwhere $$\\gamma_t$$ is the stepsize, $$\\rho_t$$ is the regularization parameter, and $$\\bar{y}_T$$ is the output of the algorithm.\n\nIn this experiment, we choose $$\\gamma_t = \\frac{\\gamma_0}{(t + 1)^{3/4}}$$ and $$\\rho_t = \\rho_0(t + 1)^{1/4}$$ for some constants $$\\gamma_0$$ and $$\\rho_0$$.\n\nThe DBGD-sto is a stochastic version of DBGD, which simply replaces the gradients in DBGD with stochastic gradients. Although the stochastic version of DBGD does not have a theoretical guarantee, it has been used to solve stochastic simple bilevel optimization problems in [GL21], which worked pretty well empirically. Hence, we use it as a baseline for solving stochastic simple bilevel problems and compare it with our proposed algorithms. The DBGD algorithm is given by\n\n$$\nx_{k+1} = x_k - \\gamma_k (\\nabla f(x_k) + \\lambda_k\\nabla g(x_k))\n$$\n$$\n\\phi(x_k) - \\langle\\nabla f(x_k), \\nabla g(x_k)\\rangle, 0 \\text{ and } \\phi(x) = \\min_\\alpha(g(x) - \\hat{g})\n$$\nwhere $$\\gamma_k$$ is the stepsize and we set $$\\lambda_k$$ as\n\n$$\n\\lambda_k = \\max\\left(\\frac{\\|\\nabla g(x_k)\\|^2}{\\alpha}, \\beta\\|\\nabla g(x)\\|^2\\right)\n$$\nwhere $$\\alpha$$ and $$\\beta$$ are hyperparameters and $$\\hat{g}$$ is a lower bound of $$g^*$\n\nIn this experiment, we choose $$\\hat{g} = 0$$. We also note that [GL21] only considered unconstrained simple bilevel optimization, i.e. $$Z = \\mathbb{R}^d$$. We further project $$x_t$$ onto Z for each iteration to ensure the constraints are satisfied."}, {"type": "heading", "lvl": 2, "value": "F.1 Over-parameterized regression", "md": "## F.1 Over-parameterized regression"}, {"type": "text", "value": "Dataset generation. The original Wikipedia Math Essential dataset [Roz+21] composes of a data matrix of size 1068 \u00d7 731. We randomly select one of the columns as the outcome vector $$b \\in \\mathbb{R}^{1068}$$ and the rest to be a new matrix $$A \\in \\mathbb{R}^{1068\\times731}$$. We set constraint parameter $$\\lambda = 10$$ in this experiment.\n\nInitialization. We run the algorithm, SPIDER-FW [YSC19], with stepsize chosen as $$\\gamma_t = \\frac{0.1}{(t+1)}$$ on the lower-level problem in (1). We terminate the process to get $$x_0$$ as the initial point for both SBCGI 1 and SBCGF 2 after 105 stochastic oracle queries.\n\nImplementation details. We query stochastic oracle $$9 \\times 10^5$$ times with stepsize $$\\gamma_t = \\frac{0.01}{(t+1)}$$ and $$\\gamma = 10^{-5}$$ for SBCGI 1 and SBCGF 2 with $$K_t = \\frac{10^{-4}}{\\sqrt{t} + 1}$$, respectively. In each iteration, we need to solve the following subproblem induced by the methods,\n\n$$\n\\begin{align*}\n\\min_s & \\langle\\nabla f(\\beta_k), s\\rangle \\\\\n\\text{s.t.} & \\|\\mathbf{s}\\|_1 \\leq \\lambda, \\langle\\nabla g(\\beta_k), s - \\beta_k\\rangle \\leq g(\\beta_0) - g(\\beta_k) . (82)\n\\end{align*}\n$$\n\nIntroduce $$s^+, s^- \\geq 0$$ such that $$s = s^+ - s^-$$. Then we can reformulate the problem above as follows,\n\n$$\n\\begin{align*}\n\\min & \\langle\\nabla f(\\beta_k), s^+ - s^-\\rangle \\\\\n\\text{s.t.} & s^+, s^- \\geq 0, s^+ + s^- \\leq \\lambda, \\langle\\nabla g(\\beta_k), s^+ - s^- - \\beta_k\\rangle \\leq g(\\beta_0) - g(\\beta_k) . (83)\n\\end{align*}\n$$", "md": "Dataset generation. The original Wikipedia Math Essential dataset [Roz+21] composes of a data matrix of size 1068 \u00d7 731. We randomly select one of the columns as the outcome vector $$b \\in \\mathbb{R}^{1068}$$ and the rest to be a new matrix $$A \\in \\mathbb{R}^{1068\\times731}$$. We set constraint parameter $$\\lambda = 10$$ in this experiment.\n\nInitialization. We run the algorithm, SPIDER-FW [YSC19], with stepsize chosen as $$\\gamma_t = \\frac{0.1}{(t+1)}$$ on the lower-level problem in (1). We terminate the process to get $$x_0$$ as the initial point for both SBCGI 1 and SBCGF 2 after 105 stochastic oracle queries.\n\nImplementation details. We query stochastic oracle $$9 \\times 10^5$$ times with stepsize $$\\gamma_t = \\frac{0.01}{(t+1)}$$ and $$\\gamma = 10^{-5}$$ for SBCGI 1 and SBCGF 2 with $$K_t = \\frac{10^{-4}}{\\sqrt{t} + 1}$$, respectively. In each iteration, we need to solve the following subproblem induced by the methods,\n\n$$\n\\begin{align*}\n\\min_s & \\langle\\nabla f(\\beta_k), s\\rangle \\\\\n\\text{s.t.} & \\|\\mathbf{s}\\|_1 \\leq \\lambda, \\langle\\nabla g(\\beta_k), s - \\beta_k\\rangle \\leq g(\\beta_0) - g(\\beta_k) . (82)\n\\end{align*}\n$$\n\nIntroduce $$s^+, s^- \\geq 0$$ such that $$s = s^+ - s^-$$. Then we can reformulate the problem above as follows,\n\n$$\n\\begin{align*}\n\\min & \\langle\\nabla f(\\beta_k), s^+ - s^-\\rangle \\\\\n\\text{s.t.} & s^+, s^- \\geq 0, s^+ + s^- \\leq \\lambda, \\langle\\nabla g(\\beta_k), s^+ - s^- - \\beta_k\\rangle \\leq g(\\beta_0) - g(\\beta_k) . (83)\n\\end{align*}\n$$"}]}, {"page": 31, "text": "where 1 \u2208        Rd is the all-one vector.\nFor aR-IP-SeG, we choose \u03b30 = 10\u22127 and \u03c10 = 103. For DBGD, we set \u03b1 = \u03b2 = 1 and \u03b3t = 10\u22126.\nF.2        Dictionary learning\nDataset generation.                    We generate 500 sparse coefficient vectors {xi}250                           i=1 and {x\u2032       k}250\n                                                                                                                                          k=1 with 5\nrandom nonzero entries, whose absolute values are drawn uniformly from [0.2, 1]. The entries of\nthe random noise vectors {ni}250                 i=1 and {n\u2032       k}250\n                                                                      k=1 are drawn from i.i.d. Gaussian distribution with\nmean 0 and standard deviation 0.01.\nInitialization. We use a similar initialization procedure as [JAMH23], which consists of two phases.\nIn the first phase, we run the standard Frank-Wolfe algorithm on both the variables D \u2208                                                          R25\u00d740\nand X \u2208        R40\u00d7250 for 104 iterations with the stepsize \u03b3t = 1/\u221at + 1. Next, in the second phase, we\nfix the variable X and only update D using the Frank-Wolfe algorithm with exact line search for\nadditional 104 iterations to obtain \u02c6                  D and \u02c6     X as the initial point for the full bilevel problem.\nImplementation Details. We choose \u03b4 = 3 in both problems (5). To be fair, all four algorithms\nstart from the same initial point. We slightly modify the initial point by letting \u02dc                                               D \u2208      R25\u00d750 be\nthe concatenation of \u02c6            D \u2208      R25\u00d740 and 10 columns of all zeros vectors. Furthermore, we initialize\nanother variable \u02dc          X randomly by choosing its entries from a standard Gaussian distribution and\nthen normalizing each column to have a \u21131-norm of \u03b4. We choose the stepsize as \u03b3t = 0.1/(t + 1)2/3\nand \u03b3 = 10\u22123 for our SBCGI 1 and SBCGF2 with Kt = 0.01/(t + 1)1/3, respectively. Empirically,\nwe observe that taking one sample per iteration leads to a very unstable process in this problem.\nIn this case, we choose a mini-batch of size 8 for SBCGI, aR-IP-SeG, and the stochastic version of\nDBGD. For each iteration, we will solve the following subproblem,\n                         \u02dc                                     d  i              \u2207g      \u02dc                                \u02dc               \u02dc\n              \u2207f \u02dc      Dk, \u02dc  X  k   , \u02dc\n                                        D          s.t.                                 Dk      , \u02dc\n     min\u02dc          D                                          \u02dc      2 \u2264   1,                     D \u2212    D\u02dc k    \u2264   g    D0     \u2212   g    Dk         (84)\n       D\nThe above problem can be reformulated by using the KKT condition, which is equivalent to get a\nroot of the following one-dimensional nonlinear equation involving \u03bb \u2265                                           0 :\n        \u02dc                         \u02dc                           \u02dc                        \u02dc                                \u02dc               \u02dc\n        D = \u03a0Z         \u2207f \u02dc D     Dk, \u02dc X  k    + \u03bb\u2207g        Dk        ,      \u2207g      Dk      ,D\u02dc\u2212     D\u02dc k    = g     D0      \u2212   g   Dk            (85)\nwhere the projection onto Z =                           \u02dc                      di                                     is equivalent to project\n                                                        D \u2208    R25\u00d750 :       \u02dc     2 \u2264    1, i = 1, . . . , 50\neach column on the Euclidean ball. In practice, the reformulated problem can be solved efficiently\nby MATLAB\u2019s root-finding solver.\nFor aR-IP-SeG, we choose \u03b30 = 10\u22124 and \u03c10 = 1. For the stochastic version of DBGD, we set\n\u03b1 = \u03b2 = 100 and \u03b3t = 5 \u00d7 10\u22123.\nAdditional plots illustrating the comparison of the studied methods in terms of runtime rather than\nthe number of sample used are provided in Figure 3 and Figure 4.\nF.3        Experiments with diff                     erent random seeds\nWe further repeat the experiment 10 times with different random seeds to see more realizations of\nthe stochastic algorithms. The results are reported in Figure 5 and Figure 6. The solid lines denote\nthe average statistics over 10 trials of the algorithms. While the shaded regions surrounding each\nline reflect the span of all the random instances involved. Figure 5 and Figure 6 present similar\nresults as Figure 1 and Figure 2, which eliminates the possibility of choosing a particularly good\ninstance.\n                                                                            31", "md": "# Document\n\nwhere \\(1 \\in \\mathbb{R}^d\\) is the all-one vector.\n\nFor aR-IP-SeG, we choose \\(\\gamma_0 = 10^{-7}\\) and \\(\\rho_0 = 10^3\\). For DBGD, we set \\(\\alpha = \\beta = 1\\) and \\(\\gamma_t = 10^{-6}\\).\n\n## Dictionary learning\n\nDataset generation. We generate 500 sparse coefficient vectors \\(\\{x_i\\}_{i=1}^{250}\\) and \\(\\{x'_k\\}_{k=1}^{250}\\) with 5 random nonzero entries, whose absolute values are drawn uniformly from [0.2, 1]. The entries of the random noise vectors \\(\\{n_i\\}_{i=1}^{250}\\) and \\(\\{n'_k\\}_{k=1}^{250}\\) are drawn from i.i.d. Gaussian distribution with mean 0 and standard deviation 0.01.\n\nInitialization. We use a similar initialization procedure as [JAMH23], which consists of two phases. In the first phase, we run the standard Frank-Wolfe algorithm on both the variables \\(D \\in \\mathbb{R}^{25 \\times 40}\\) and \\(X \\in \\mathbb{R}^{40 \\times 250}\\) for 10^4 iterations with the stepsize \\(\\gamma_t = \\frac{1}{\\sqrt{t} + 1}\\). Next, in the second phase, we fix the variable \\(X\\) and only update \\(D\\) using the Frank-Wolfe algorithm with exact line search for additional 10^4 iterations to obtain \\(\\hat{D}\\) and \\(\\hat{X}\\) as the initial point for the full bilevel problem.\n\nImplementation Details. We choose \\(\\delta = 3\\) in both problems (5). To be fair, all four algorithms start from the same initial point. We slightly modify the initial point by letting \\(\\tilde{D} \\in \\mathbb{R}^{25 \\times 50}\\) be the concatenation of \\(\\hat{D} \\in \\mathbb{R}^{25 \\times 40}\\) and 10 columns of all zeros vectors. Furthermore, we initialize another variable \\(\\tilde{X}\\) randomly by choosing its entries from a standard Gaussian distribution and then normalizing each column to have a \\(\\ell_1\\)-norm of \\(\\delta\\). We choose the stepsize as \\(\\gamma_t = \\frac{0.1}{(t + 1)^{2/3}}\\) and \\(\\gamma = 10^{-3}\\) for our SBCGI 1 and SBCGF2 with \\(K_t = \\frac{0.01}{(t + 1)^{1/3}}\\), respectively. Empirically, we observe that taking one sample per iteration leads to a very unstable process in this problem. In this case, we choose a mini-batch of size 8 for SBCGI, aR-IP-SeG, and the stochastic version of DBGD. For each iteration, we will solve the following subproblem,\n\n\\[\n\\min_{\\tilde{D}} \\nabla f(\\tilde{D}_k, \\tilde{X}_k) \\quad \\text{s.t.} \\quad \\|\\tilde{D}\\|_2 \\leq 1, \\quad \\tilde{D} - \\tilde{D}_k \\leq g(D_0) - g(D_k) \\quad (84)\n\\]\n\nThe above problem can be reformulated by using the KKT condition, which is equivalent to get a root of the following one-dimensional nonlinear equation involving \\(\\lambda \\geq 0\\):\n\n\\[\n\\tilde{D} = \\Pi_Z \\nabla f(\\tilde{D}_k, \\tilde{X}_k) + \\lambda \\nabla g(\\tilde{D}_k), \\nabla g(D_k), \\tilde{D} - \\tilde{D}_k = g(D_0) - g(D_k) \\quad (85)\n\\]\n\nwhere the projection onto \\(Z = \\{D \\in \\mathbb{R}^{25 \\times 50} : \\|\\tilde{D}\\|_2 \\leq 1, i = 1, ..., 50\\}\\) is equivalent to project each column on the Euclidean ball. In practice, the reformulated problem can be solved efficiently by MATLAB's root-finding solver.\n\nFor aR-IP-SeG, we choose \\(\\gamma_0 = 10^{-4}\\) and \\(\\rho_0 = 1\\). For the stochastic version of DBGD, we set \\(\\alpha = \\beta = 100\\) and \\(\\gamma_t = 5 \\times 10^{-3}\\).\n\nAdditional plots illustrating the comparison of the studied methods in terms of runtime rather than the number of sample used are provided in Figure 3 and Figure 4.\n\n### Experiments with different random seeds\n\nWe further repeat the experiment 10 times with different random seeds to see more realizations of the stochastic algorithms. The results are reported in Figure 5 and Figure 6. The solid lines denote the average statistics over 10 trials of the algorithms. While the shaded regions surrounding each line reflect the span of all the random instances involved. Figure 5 and Figure 6 present similar results as Figure 1 and Figure 2, which eliminates the possibility of choosing a particularly good instance.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "where \\(1 \\in \\mathbb{R}^d\\) is the all-one vector.\n\nFor aR-IP-SeG, we choose \\(\\gamma_0 = 10^{-7}\\) and \\(\\rho_0 = 10^3\\). For DBGD, we set \\(\\alpha = \\beta = 1\\) and \\(\\gamma_t = 10^{-6}\\).", "md": "where \\(1 \\in \\mathbb{R}^d\\) is the all-one vector.\n\nFor aR-IP-SeG, we choose \\(\\gamma_0 = 10^{-7}\\) and \\(\\rho_0 = 10^3\\). For DBGD, we set \\(\\alpha = \\beta = 1\\) and \\(\\gamma_t = 10^{-6}\\)."}, {"type": "heading", "lvl": 2, "value": "Dictionary learning", "md": "## Dictionary learning"}, {"type": "text", "value": "Dataset generation. We generate 500 sparse coefficient vectors \\(\\{x_i\\}_{i=1}^{250}\\) and \\(\\{x'_k\\}_{k=1}^{250}\\) with 5 random nonzero entries, whose absolute values are drawn uniformly from [0.2, 1]. The entries of the random noise vectors \\(\\{n_i\\}_{i=1}^{250}\\) and \\(\\{n'_k\\}_{k=1}^{250}\\) are drawn from i.i.d. Gaussian distribution with mean 0 and standard deviation 0.01.\n\nInitialization. We use a similar initialization procedure as [JAMH23], which consists of two phases. In the first phase, we run the standard Frank-Wolfe algorithm on both the variables \\(D \\in \\mathbb{R}^{25 \\times 40}\\) and \\(X \\in \\mathbb{R}^{40 \\times 250}\\) for 10^4 iterations with the stepsize \\(\\gamma_t = \\frac{1}{\\sqrt{t} + 1}\\). Next, in the second phase, we fix the variable \\(X\\) and only update \\(D\\) using the Frank-Wolfe algorithm with exact line search for additional 10^4 iterations to obtain \\(\\hat{D}\\) and \\(\\hat{X}\\) as the initial point for the full bilevel problem.\n\nImplementation Details. We choose \\(\\delta = 3\\) in both problems (5). To be fair, all four algorithms start from the same initial point. We slightly modify the initial point by letting \\(\\tilde{D} \\in \\mathbb{R}^{25 \\times 50}\\) be the concatenation of \\(\\hat{D} \\in \\mathbb{R}^{25 \\times 40}\\) and 10 columns of all zeros vectors. Furthermore, we initialize another variable \\(\\tilde{X}\\) randomly by choosing its entries from a standard Gaussian distribution and then normalizing each column to have a \\(\\ell_1\\)-norm of \\(\\delta\\). We choose the stepsize as \\(\\gamma_t = \\frac{0.1}{(t + 1)^{2/3}}\\) and \\(\\gamma = 10^{-3}\\) for our SBCGI 1 and SBCGF2 with \\(K_t = \\frac{0.01}{(t + 1)^{1/3}}\\), respectively. Empirically, we observe that taking one sample per iteration leads to a very unstable process in this problem. In this case, we choose a mini-batch of size 8 for SBCGI, aR-IP-SeG, and the stochastic version of DBGD. For each iteration, we will solve the following subproblem,\n\n\\[\n\\min_{\\tilde{D}} \\nabla f(\\tilde{D}_k, \\tilde{X}_k) \\quad \\text{s.t.} \\quad \\|\\tilde{D}\\|_2 \\leq 1, \\quad \\tilde{D} - \\tilde{D}_k \\leq g(D_0) - g(D_k) \\quad (84)\n\\]\n\nThe above problem can be reformulated by using the KKT condition, which is equivalent to get a root of the following one-dimensional nonlinear equation involving \\(\\lambda \\geq 0\\):\n\n\\[\n\\tilde{D} = \\Pi_Z \\nabla f(\\tilde{D}_k, \\tilde{X}_k) + \\lambda \\nabla g(\\tilde{D}_k), \\nabla g(D_k), \\tilde{D} - \\tilde{D}_k = g(D_0) - g(D_k) \\quad (85)\n\\]\n\nwhere the projection onto \\(Z = \\{D \\in \\mathbb{R}^{25 \\times 50} : \\|\\tilde{D}\\|_2 \\leq 1, i = 1, ..., 50\\}\\) is equivalent to project each column on the Euclidean ball. In practice, the reformulated problem can be solved efficiently by MATLAB's root-finding solver.\n\nFor aR-IP-SeG, we choose \\(\\gamma_0 = 10^{-4}\\) and \\(\\rho_0 = 1\\). For the stochastic version of DBGD, we set \\(\\alpha = \\beta = 100\\) and \\(\\gamma_t = 5 \\times 10^{-3}\\).\n\nAdditional plots illustrating the comparison of the studied methods in terms of runtime rather than the number of sample used are provided in Figure 3 and Figure 4.", "md": "Dataset generation. We generate 500 sparse coefficient vectors \\(\\{x_i\\}_{i=1}^{250}\\) and \\(\\{x'_k\\}_{k=1}^{250}\\) with 5 random nonzero entries, whose absolute values are drawn uniformly from [0.2, 1]. The entries of the random noise vectors \\(\\{n_i\\}_{i=1}^{250}\\) and \\(\\{n'_k\\}_{k=1}^{250}\\) are drawn from i.i.d. Gaussian distribution with mean 0 and standard deviation 0.01.\n\nInitialization. We use a similar initialization procedure as [JAMH23], which consists of two phases. In the first phase, we run the standard Frank-Wolfe algorithm on both the variables \\(D \\in \\mathbb{R}^{25 \\times 40}\\) and \\(X \\in \\mathbb{R}^{40 \\times 250}\\) for 10^4 iterations with the stepsize \\(\\gamma_t = \\frac{1}{\\sqrt{t} + 1}\\). Next, in the second phase, we fix the variable \\(X\\) and only update \\(D\\) using the Frank-Wolfe algorithm with exact line search for additional 10^4 iterations to obtain \\(\\hat{D}\\) and \\(\\hat{X}\\) as the initial point for the full bilevel problem.\n\nImplementation Details. We choose \\(\\delta = 3\\) in both problems (5). To be fair, all four algorithms start from the same initial point. We slightly modify the initial point by letting \\(\\tilde{D} \\in \\mathbb{R}^{25 \\times 50}\\) be the concatenation of \\(\\hat{D} \\in \\mathbb{R}^{25 \\times 40}\\) and 10 columns of all zeros vectors. Furthermore, we initialize another variable \\(\\tilde{X}\\) randomly by choosing its entries from a standard Gaussian distribution and then normalizing each column to have a \\(\\ell_1\\)-norm of \\(\\delta\\). We choose the stepsize as \\(\\gamma_t = \\frac{0.1}{(t + 1)^{2/3}}\\) and \\(\\gamma = 10^{-3}\\) for our SBCGI 1 and SBCGF2 with \\(K_t = \\frac{0.01}{(t + 1)^{1/3}}\\), respectively. Empirically, we observe that taking one sample per iteration leads to a very unstable process in this problem. In this case, we choose a mini-batch of size 8 for SBCGI, aR-IP-SeG, and the stochastic version of DBGD. For each iteration, we will solve the following subproblem,\n\n\\[\n\\min_{\\tilde{D}} \\nabla f(\\tilde{D}_k, \\tilde{X}_k) \\quad \\text{s.t.} \\quad \\|\\tilde{D}\\|_2 \\leq 1, \\quad \\tilde{D} - \\tilde{D}_k \\leq g(D_0) - g(D_k) \\quad (84)\n\\]\n\nThe above problem can be reformulated by using the KKT condition, which is equivalent to get a root of the following one-dimensional nonlinear equation involving \\(\\lambda \\geq 0\\):\n\n\\[\n\\tilde{D} = \\Pi_Z \\nabla f(\\tilde{D}_k, \\tilde{X}_k) + \\lambda \\nabla g(\\tilde{D}_k), \\nabla g(D_k), \\tilde{D} - \\tilde{D}_k = g(D_0) - g(D_k) \\quad (85)\n\\]\n\nwhere the projection onto \\(Z = \\{D \\in \\mathbb{R}^{25 \\times 50} : \\|\\tilde{D}\\|_2 \\leq 1, i = 1, ..., 50\\}\\) is equivalent to project each column on the Euclidean ball. In practice, the reformulated problem can be solved efficiently by MATLAB's root-finding solver.\n\nFor aR-IP-SeG, we choose \\(\\gamma_0 = 10^{-4}\\) and \\(\\rho_0 = 1\\). For the stochastic version of DBGD, we set \\(\\alpha = \\beta = 100\\) and \\(\\gamma_t = 5 \\times 10^{-3}\\).\n\nAdditional plots illustrating the comparison of the studied methods in terms of runtime rather than the number of sample used are provided in Figure 3 and Figure 4."}, {"type": "heading", "lvl": 3, "value": "Experiments with different random seeds", "md": "### Experiments with different random seeds"}, {"type": "text", "value": "We further repeat the experiment 10 times with different random seeds to see more realizations of the stochastic algorithms. The results are reported in Figure 5 and Figure 6. The solid lines denote the average statistics over 10 trials of the algorithms. While the shaded regions surrounding each line reflect the span of all the random instances involved. Figure 5 and Figure 6 present similar results as Figure 1 and Figure 2, which eliminates the possibility of choosing a particularly good instance.", "md": "We further repeat the experiment 10 times with different random seeds to see more realizations of the stochastic algorithms. The results are reported in Figure 5 and Figure 6. The solid lines denote the average statistics over 10 trials of the algorithms. While the shaded regions surrounding each line reflect the span of all the random instances involved. Figure 5 and Figure 6 present similar results as Figure 1 and Figure 2, which eliminates the possibility of choosing a particularly good instance."}]}, {"page": 32, "text": "                                                                                 102                                               101\n              100\n                                                                                 100\n             10-2                                                                                                                  100\n                                                                                10-2\n             10-4\n             10-6 0              100              200             300           10-4 0              100          200       300    10-1 0            100          200        300\n                        (a) Lower-level gap                                               (b) Upper-level gap                                   (c) Test error\nFigure 3: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for the over-parameterized\nregression problem\n               100                                                               100                                               1\n               10-2                                                                                                              0.8\n                                                                                                                                 0.6\n               10-4                                                             10-1\n                                                                                                                                 0.4\n               10-6                                                                                                              0.2\n               10-80       20      40      60       80      100     120         10-20       20      40       60  80   100   120    00     20       40      60   80    100  120\n                         (a) Lower-level gap                                              (b) Upper-level gap                              (c) Recovery rate\nFigure 4: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving the dictionary\nlearning problem.\n                                                                                         LiLI-\n                        (a) Lower-level gap                                               (b) Upper-level gap                                   (c) Test error\nFigure 5: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (3) with\n10 different random seeds\n                                                                                                          32", "md": "$$\\begin{array}{ccc}\n102 & & 101 \\\\\n100 & & \\\\\n& 100 & \\\\\n10^{-2} & & 100 \\\\\n& 10^{-2} & \\\\\n10^{-4} & & \\\\\n10^{-6} & 0 & 100 & 200 & 300 & 10^{-4} & 0 & 100 & 200 & 300 & 10^{-1} & 0 & 100 & 200 & 300 \\\\\n& & (a) \\text{ Lower-level gap} & & & & (b) \\text{ Upper-level gap} & & & & (c) \\text{ Test error} \\\\\n\\end{array}$$\n\n$$\\begin{array}{cccccccccccccccc}\n100 & & 100 & & 1 \\\\\n10^{-2} & & & & 0.8 \\\\\n& & & 10^{-1} & \\\\\n10^{-4} & & & & 0.6 \\\\\n10^{-6} & & & & 0.4 \\\\\n10^{-8} & 20 & 40 & 60 & 80 & 100 & 120 & 10^{-2} & 20 & 40 & 60 & 80 & 100 & 120 & 0 & 20 & 40 & 60 & 80 & 100 & 120 \\\\\n& & (a) \\text{ Lower-level gap} & & & & (b) \\text{ Upper-level gap} & & & & (c) \\text{ Recovery rate} \\\\\n\\end{array}$$\n\n$$\\begin{array}{ccc}\n& & \\\\\n& (a) \\text{ Lower-level gap} & \\\\\n& (b) \\text{ Upper-level gap} & \\\\\n& (c) \\text{ Test error} & \\\\\n\\end{array}$$", "images": [{"name": "page-32-4.jpg", "height": 101, "width": 135, "x": 235, "y": 541}, {"name": "page-32-8.jpg", "height": 101, "width": 135, "x": 379, "y": 541}, {"name": "page-32-0.jpg", "height": 101, "width": 135, "x": 91, "y": 541}], "items": [{"type": "text", "value": "$$\\begin{array}{ccc}\n102 & & 101 \\\\\n100 & & \\\\\n& 100 & \\\\\n10^{-2} & & 100 \\\\\n& 10^{-2} & \\\\\n10^{-4} & & \\\\\n10^{-6} & 0 & 100 & 200 & 300 & 10^{-4} & 0 & 100 & 200 & 300 & 10^{-1} & 0 & 100 & 200 & 300 \\\\\n& & (a) \\text{ Lower-level gap} & & & & (b) \\text{ Upper-level gap} & & & & (c) \\text{ Test error} \\\\\n\\end{array}$$\n\n$$\\begin{array}{cccccccccccccccc}\n100 & & 100 & & 1 \\\\\n10^{-2} & & & & 0.8 \\\\\n& & & 10^{-1} & \\\\\n10^{-4} & & & & 0.6 \\\\\n10^{-6} & & & & 0.4 \\\\\n10^{-8} & 20 & 40 & 60 & 80 & 100 & 120 & 10^{-2} & 20 & 40 & 60 & 80 & 100 & 120 & 0 & 20 & 40 & 60 & 80 & 100 & 120 \\\\\n& & (a) \\text{ Lower-level gap} & & & & (b) \\text{ Upper-level gap} & & & & (c) \\text{ Recovery rate} \\\\\n\\end{array}$$\n\n$$\\begin{array}{ccc}\n& & \\\\\n& (a) \\text{ Lower-level gap} & \\\\\n& (b) \\text{ Upper-level gap} & \\\\\n& (c) \\text{ Test error} & \\\\\n\\end{array}$$", "md": "$$\\begin{array}{ccc}\n102 & & 101 \\\\\n100 & & \\\\\n& 100 & \\\\\n10^{-2} & & 100 \\\\\n& 10^{-2} & \\\\\n10^{-4} & & \\\\\n10^{-6} & 0 & 100 & 200 & 300 & 10^{-4} & 0 & 100 & 200 & 300 & 10^{-1} & 0 & 100 & 200 & 300 \\\\\n& & (a) \\text{ Lower-level gap} & & & & (b) \\text{ Upper-level gap} & & & & (c) \\text{ Test error} \\\\\n\\end{array}$$\n\n$$\\begin{array}{cccccccccccccccc}\n100 & & 100 & & 1 \\\\\n10^{-2} & & & & 0.8 \\\\\n& & & 10^{-1} & \\\\\n10^{-4} & & & & 0.6 \\\\\n10^{-6} & & & & 0.4 \\\\\n10^{-8} & 20 & 40 & 60 & 80 & 100 & 120 & 10^{-2} & 20 & 40 & 60 & 80 & 100 & 120 & 0 & 20 & 40 & 60 & 80 & 100 & 120 \\\\\n& & (a) \\text{ Lower-level gap} & & & & (b) \\text{ Upper-level gap} & & & & (c) \\text{ Recovery rate} \\\\\n\\end{array}$$\n\n$$\\begin{array}{ccc}\n& & \\\\\n& (a) \\text{ Lower-level gap} & \\\\\n& (b) \\text{ Upper-level gap} & \\\\\n& (c) \\text{ Test error} & \\\\\n\\end{array}$$"}]}, {"page": 33, "text": "                          (a) Lower-level gap                                              (b) Upper-level gap                       (c) Recovery rate\nFigure 6: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (5) with\n10 different random seeds\n                100                                                              100                                       1\n               10-5                                                                                                       0.8\n                                                                                 10-1                                     0.6\n               10-10\n               10-15                                                             10-2                                     0.4\n                                                                                                                          0.2\n               10-200           2            4           6            8          10-30            2           4  6     8   0 0           2            4    6     8\n                                                                   105                                              105                                       105\n                          (a) Lower-level gap                                              (b) Upper-level gap                       (c) Recovery rate\nFigure 7: Comparison of SBCGI, SBCGF, SBCGI-M, SBCGF-M, STORM-FW, and SPIDER-FW\nfor solving Problem (5).\nF.4            Importance of the right cutting plane\nIn this section, we numerically illustrate the importance of choosing the right cutting plane on\nExample 2 (dictionary learning). Specifically, we compare our proposed methods with the ones\nwithout a cutting plane and with an unregularized cutting plane (without additional term Kt).\nIf we replace the stochastic cutting plane (9) with the unregularized cutting plane (8) in SBCGI\n1 and SBCGF 2, then the algorithm usually fail at some point in the process, depending on the\ndatasets and parameters chosen, based on our experimental observations. More specifically, algo-\nrithms\u2019 failure means that the subproblem of dictionary learning (85) is infeasible. So we slightly\nmodify it by adding a checkpoint before solving the subproblem. If the subproblem is infeasible\nat the current iteration, then we choose the update direction st =                                                          \u2207gt. This adjustment prevents\nunnecessary interruptions during the process and enforce the algorithms to focus only on the lower-\nlevel problem when the subproblem is infeasible. We denote the modified algorithms SBCGI-M and\nSBCGF-M. Moreover, we also take SBCGI and SBCGF without cutting planes into consideration,\ndenoted as STORM-FW and SPIDER-FW. In fact, in this case, the bilevel algorithms degenerate\nto single-level projection-free algorithms similar to algorithms in [XSZWQ20] and [YSC19].\nFigure 7 (a) indicates that SBCGI-M and SBCGF-M focus more on the lower-level problem due\nto the design of the algorithms and extremely unstable as we can see in Figure 7 (b)(c). While\nSTORM-FW and SPIDER-FW only focus on the upper-level problem, which leads to terrible\nresults on the lower-level gap and recovery rate.\n                                                                                                           33", "md": "(a) Lower-level gap (b) Upper-level gap (c) Recovery rate\n\nFigure 6: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (5) with 10 different random seeds\n\n| |100|100|1|\n|---|---|---|---|\n|10^-5| | |0.8|\n|10^-10| |10^-1|0.6|\n|10^-15| |10^-2|0.4|\n|10^-20|2|4|6|8|10^-30|2|4|6|8|0|0|2|4|6|8|105|105|105|\n\n(a) Lower-level gap (b) Upper-level gap (c) Recovery rate\n\nFigure 7: Comparison of SBCGI, SBCGF, SBCGI-M, SBCGF-M, STORM-FW, and SPIDER-FW for solving Problem (5).\n\nF.4 Importance of the right cutting plane\n\nIn this section, we numerically illustrate the importance of choosing the right cutting plane on Example 2 (dictionary learning). Specifically, we compare our proposed methods with the ones without a cutting plane and with an unregularized cutting plane (without additional term Kt). If we replace the stochastic cutting plane (9) with the unregularized cutting plane (8) in SBCGI 1 and SBCGF 2, then the algorithm usually fail at some point in the process, depending on the datasets and parameters chosen, based on our experimental observations. More specifically, algorithms\u2019 failure means that the subproblem of dictionary learning (85) is infeasible. So we slightly modify it by adding a checkpoint before solving the subproblem. If the subproblem is infeasible at the current iteration, then we choose the update direction st = $$\\nabla g_t$$. This adjustment prevents unnecessary interruptions during the process and enforce the algorithms to focus only on the lower-level problem when the subproblem is infeasible. We denote the modified algorithms SBCGI-M and SBCGF-M. Moreover, we also take SBCGI and SBCGF without cutting planes into consideration, denoted as STORM-FW and SPIDER-FW. In fact, in this case, the bilevel algorithms degenerate to single-level projection-free algorithms similar to algorithms in [XSZWQ20] and [YSC19]. Figure 7 (a) indicates that SBCGI-M and SBCGF-M focus more on the lower-level problem due to the design of the algorithms and extremely unstable as we can see in Figure 7 (b)(c). While STORM-FW and SPIDER-FW only focus on the upper-level problem, which leads to terrible results on the lower-level gap and recovery rate.\n\n33", "images": [{"name": "page-33-1.jpg", "height": 105, "width": 140, "x": 230, "y": 76}, {"name": "page-33-3.jpg", "height": 101, "width": 140, "x": 376, "y": 76}, {"name": "page-33-0.jpg", "height": 101, "width": 135, "x": 95, "y": 76}], "items": [{"type": "text", "value": "(a) Lower-level gap (b) Upper-level gap (c) Recovery rate\n\nFigure 6: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (5) with 10 different random seeds", "md": "(a) Lower-level gap (b) Upper-level gap (c) Recovery rate\n\nFigure 6: Comparison of SBCGI, SBCGF, aR-IP-SeG, and DBGD-Sto for solving Problem (5) with 10 different random seeds"}, {"type": "table", "rows": [["", "100", "100", "1"], ["10^-5", "", "", "0.8"], ["10^-10", "", "10^-1", "0.6"], ["10^-15", "", "10^-2", "0.4"], ["10^-20", "2", "4", "6", "8", "10^-30", "2", "4", "6", "8", "0", "0", "2", "4", "6", "8", "105", "105", "105"]], "md": "| |100|100|1|\n|---|---|---|---|\n|10^-5| | |0.8|\n|10^-10| |10^-1|0.6|\n|10^-15| |10^-2|0.4|\n|10^-20|2|4|6|8|10^-30|2|4|6|8|0|0|2|4|6|8|105|105|105|", "isPerfectTable": false, "csv": "\"\",\"100\",\"100\",\"1\"\n\"10^-5\",\"\",\"\",\"0.8\"\n\"10^-10\",\"\",\"10^-1\",\"0.6\"\n\"10^-15\",\"\",\"10^-2\",\"0.4\"\n\"10^-20\",\"2\",\"4\",\"6\",\"8\",\"10^-30\",\"2\",\"4\",\"6\",\"8\",\"0\",\"0\",\"2\",\"4\",\"6\",\"8\",\"105\",\"105\",\"105\""}, {"type": "text", "value": "(a) Lower-level gap (b) Upper-level gap (c) Recovery rate\n\nFigure 7: Comparison of SBCGI, SBCGF, SBCGI-M, SBCGF-M, STORM-FW, and SPIDER-FW for solving Problem (5).\n\nF.4 Importance of the right cutting plane\n\nIn this section, we numerically illustrate the importance of choosing the right cutting plane on Example 2 (dictionary learning). Specifically, we compare our proposed methods with the ones without a cutting plane and with an unregularized cutting plane (without additional term Kt). If we replace the stochastic cutting plane (9) with the unregularized cutting plane (8) in SBCGI 1 and SBCGF 2, then the algorithm usually fail at some point in the process, depending on the datasets and parameters chosen, based on our experimental observations. More specifically, algorithms\u2019 failure means that the subproblem of dictionary learning (85) is infeasible. So we slightly modify it by adding a checkpoint before solving the subproblem. If the subproblem is infeasible at the current iteration, then we choose the update direction st = $$\\nabla g_t$$. This adjustment prevents unnecessary interruptions during the process and enforce the algorithms to focus only on the lower-level problem when the subproblem is infeasible. We denote the modified algorithms SBCGI-M and SBCGF-M. Moreover, we also take SBCGI and SBCGF without cutting planes into consideration, denoted as STORM-FW and SPIDER-FW. In fact, in this case, the bilevel algorithms degenerate to single-level projection-free algorithms similar to algorithms in [XSZWQ20] and [YSC19]. Figure 7 (a) indicates that SBCGI-M and SBCGF-M focus more on the lower-level problem due to the design of the algorithms and extremely unstable as we can see in Figure 7 (b)(c). While STORM-FW and SPIDER-FW only focus on the upper-level problem, which leads to terrible results on the lower-level gap and recovery rate.\n\n33", "md": "(a) Lower-level gap (b) Upper-level gap (c) Recovery rate\n\nFigure 7: Comparison of SBCGI, SBCGF, SBCGI-M, SBCGF-M, STORM-FW, and SPIDER-FW for solving Problem (5).\n\nF.4 Importance of the right cutting plane\n\nIn this section, we numerically illustrate the importance of choosing the right cutting plane on Example 2 (dictionary learning). Specifically, we compare our proposed methods with the ones without a cutting plane and with an unregularized cutting plane (without additional term Kt). If we replace the stochastic cutting plane (9) with the unregularized cutting plane (8) in SBCGI 1 and SBCGF 2, then the algorithm usually fail at some point in the process, depending on the datasets and parameters chosen, based on our experimental observations. More specifically, algorithms\u2019 failure means that the subproblem of dictionary learning (85) is infeasible. So we slightly modify it by adding a checkpoint before solving the subproblem. If the subproblem is infeasible at the current iteration, then we choose the update direction st = $$\\nabla g_t$$. This adjustment prevents unnecessary interruptions during the process and enforce the algorithms to focus only on the lower-level problem when the subproblem is infeasible. We denote the modified algorithms SBCGI-M and SBCGF-M. Moreover, we also take SBCGI and SBCGF without cutting planes into consideration, denoted as STORM-FW and SPIDER-FW. In fact, in this case, the bilevel algorithms degenerate to single-level projection-free algorithms similar to algorithms in [XSZWQ20] and [YSC19]. Figure 7 (a) indicates that SBCGI-M and SBCGF-M focus more on the lower-level problem due to the design of the algorithms and extremely unstable as we can see in Figure 7 (b)(c). While STORM-FW and SPIDER-FW only focus on the upper-level problem, which leads to terrible results on the lower-level gap and recovery rate.\n\n33"}]}], "job_id": "0b7f58ed-9fbb-478f-a62f-ee24e3daaa0d", "file_path": "./corpus/2308.07536.pdf"}