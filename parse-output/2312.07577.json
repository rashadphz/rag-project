{"pages": [{"page": 1, "text": "                         Benchmarking Distribution Shift in Tabular Data\n                                                           with TableShift\n                                 Josh Gardner\u266e                 Zoran Popovi\u00b4   c\u266e             Ludwig Schmidt\u266e,\u266d\n                                            \u266e University of Washington         \u266dAllen Institute for AI\narXiv:2312.07577v2  [cs.LG]  14 Dec 2023     {jpgard, zoran, schmidt}@cs.washington.edu\n                                                                    Abstract\n                              Robustness to distribution shift has become a growing concern for text and im-\n                              age models as they transition from research subjects to deployment in the real\n                              world. However, high-quality benchmarks for distribution shift in tabular machine\n                              learning tasks are still lacking despite the widespread real-world use of tabular\n                              data and differences in the models used for tabular data in comparison to text and\n                              images. As a consequence, the robustness of tabular models to distribution shift is\n                              poorly understood. To address this issue, we introduce TABLESHIFT, a distribution\n                              shift benchmark for tabular data. TABLESHIFT contains 15 binary classification\n                              tasks in total, each with an associated shift, and includes a diverse set of data\n                              sources, prediction targets, and distribution shifts. The benchmark covers domains\n                              including finance, education, public policy, healthcare, and civic participation, and\n                              is accessible using only a few lines of Python code via the TABLESHIFT API. We\n                              conduct a large-scale study comparing several state-of-the-art tabular data models\n                              alongside robust learning and domain generalization methods on the benchmark\n                              tasks. Our study demonstrates (1) a linear trend between in-distribution (ID) and\n                              out-of-distribution (OOD) accuracy; (2) domain robustness methods can reduce\n                              shift gaps but at the cost of reduced ID accuracy; (3) a strong relationship between\n                              shift gap (difference between ID and OOD performance) and shifts in the label\n                              distribution.1\n                     1    Introduction\n                     Modern machine learning models have achieved near- or even super-human performance on many\n                     tasks. This has contributed to deployments of models across critical domains, including finance,\n                     public policy, and healthcare. However, in tandem with the growing deployment of machine learning\n                     models, researchers have also demonstrated concerning model performance drops under distribution\n                     shift \u2013 when the test/deployment data are not drawn from the same distribution as the training data.\n                     Analyses of these performance drops have primarily been confined to the domains of vision and\n                     language modeling (e.g. [38, 50], where effective benchmarks for distribution shift exist. Despite\n                     the widespread use of tabular data, the impact of distribution shift on tabular data has not been\n                     thoroughly investigated. While there are existing benchmarks for IID tabular classification, none of\n                     these focus on distribution shifts [36, 33].\n                     This is particularly concerning in light of the known differences between tabular data and the\n                     modalities mentioned above (images, text, audio). First, in contrast to these modalities, where large\n                     neural models are the undisputed state-of-the-art, there is considerable debate about whether deep\n                        1The benchmark data, Python package, model implementations, and more information about TABLESHIFT\n                     are available at https://github.com/mlfoundations/tableshift and https://tableshift.org.\n                     37th Conference on Neural Information Processing Systems (NeurIPS 2023).", "md": "# Benchmarking Distribution Shift in Tabular Data with TableShift\n\n# Benchmarking Distribution Shift in Tabular Data with TableShift\n\nJosh Gardner\u266e Zoran Popovi\u00b4 c\u266e Ludwig Schmidt\u266e,\u266d\n\nUniversity of Washington Allen Institute for AI\n\narXiv:2312.07577v2 [cs.LG] 14 Dec 2023\n\n## Abstract\n\nRobustness to distribution shift has become a growing concern for text and image models as they transition from research subjects to deployment in the real world. However, high-quality benchmarks for distribution shift in tabular machine learning tasks are still lacking despite the widespread real-world use of tabular data and differences in the models used for tabular data in comparison to text and images. As a consequence, the robustness of tabular models to distribution shift is poorly understood. To address this issue, we introduce TABLESHIFT, a distribution shift benchmark for tabular data. TABLESHIFT contains 15 binary classification tasks in total, each with an associated shift, and includes a diverse set of data sources, prediction targets, and distribution shifts. The benchmark covers domains including finance, education, public policy, healthcare, and civic participation, and is accessible using only a few lines of Python code via the TABLESHIFT API. We conduct a large-scale study comparing several state-of-the-art tabular data models alongside robust learning and domain generalization methods on the benchmark tasks. Our study demonstrates:\n\n1. a linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy;\n2. domain robustness methods can reduce shift gaps but at the cost of reduced ID accuracy;\n3. a strong relationship between shift gap (difference between ID and OOD performance) and shifts in the label distribution.\n\n## Introduction\n\nModern machine learning models have achieved near- or even super-human performance on many tasks. This has contributed to deployments of models across critical domains, including finance, public policy, and healthcare. However, in tandem with the growing deployment of machine learning models, researchers have also demonstrated concerning model performance drops under distribution shift \u2013 when the test/deployment data are not drawn from the same distribution as the training data. Analyses of these performance drops have primarily been confined to the domains of vision and language modeling (e.g. [38, 50], where effective benchmarks for distribution shift exist. Despite the widespread use of tabular data, the impact of distribution shift on tabular data has not been thoroughly investigated. While there are existing benchmarks for IID tabular classification, none of these focus on distribution shifts [36, 33].\n\nThis is particularly concerning in light of the known differences between tabular data and the modalities mentioned above (images, text, audio). First, in contrast to these modalities, where large neural models are the undisputed state-of-the-art, there is considerable debate about whether deep\n\n1The benchmark data, Python package, model implementations, and more information about TABLESHIFT are available at https://github.com/mlfoundations/tableshift and https://tableshift.org.\n\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Benchmarking Distribution Shift in Tabular Data with TableShift", "md": "# Benchmarking Distribution Shift in Tabular Data with TableShift"}, {"type": "heading", "lvl": 1, "value": "Benchmarking Distribution Shift in Tabular Data with TableShift", "md": "# Benchmarking Distribution Shift in Tabular Data with TableShift"}, {"type": "text", "value": "Josh Gardner\u266e Zoran Popovi\u00b4 c\u266e Ludwig Schmidt\u266e,\u266d\n\nUniversity of Washington Allen Institute for AI\n\narXiv:2312.07577v2 [cs.LG] 14 Dec 2023", "md": "Josh Gardner\u266e Zoran Popovi\u00b4 c\u266e Ludwig Schmidt\u266e,\u266d\n\nUniversity of Washington Allen Institute for AI\n\narXiv:2312.07577v2 [cs.LG] 14 Dec 2023"}, {"type": "heading", "lvl": 2, "value": "Abstract", "md": "## Abstract"}, {"type": "text", "value": "Robustness to distribution shift has become a growing concern for text and image models as they transition from research subjects to deployment in the real world. However, high-quality benchmarks for distribution shift in tabular machine learning tasks are still lacking despite the widespread real-world use of tabular data and differences in the models used for tabular data in comparison to text and images. As a consequence, the robustness of tabular models to distribution shift is poorly understood. To address this issue, we introduce TABLESHIFT, a distribution shift benchmark for tabular data. TABLESHIFT contains 15 binary classification tasks in total, each with an associated shift, and includes a diverse set of data sources, prediction targets, and distribution shifts. The benchmark covers domains including finance, education, public policy, healthcare, and civic participation, and is accessible using only a few lines of Python code via the TABLESHIFT API. We conduct a large-scale study comparing several state-of-the-art tabular data models alongside robust learning and domain generalization methods on the benchmark tasks. Our study demonstrates:\n\n1. a linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy;\n2. domain robustness methods can reduce shift gaps but at the cost of reduced ID accuracy;\n3. a strong relationship between shift gap (difference between ID and OOD performance) and shifts in the label distribution.", "md": "Robustness to distribution shift has become a growing concern for text and image models as they transition from research subjects to deployment in the real world. However, high-quality benchmarks for distribution shift in tabular machine learning tasks are still lacking despite the widespread real-world use of tabular data and differences in the models used for tabular data in comparison to text and images. As a consequence, the robustness of tabular models to distribution shift is poorly understood. To address this issue, we introduce TABLESHIFT, a distribution shift benchmark for tabular data. TABLESHIFT contains 15 binary classification tasks in total, each with an associated shift, and includes a diverse set of data sources, prediction targets, and distribution shifts. The benchmark covers domains including finance, education, public policy, healthcare, and civic participation, and is accessible using only a few lines of Python code via the TABLESHIFT API. We conduct a large-scale study comparing several state-of-the-art tabular data models alongside robust learning and domain generalization methods on the benchmark tasks. Our study demonstrates:\n\n1. a linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy;\n2. domain robustness methods can reduce shift gaps but at the cost of reduced ID accuracy;\n3. a strong relationship between shift gap (difference between ID and OOD performance) and shifts in the label distribution."}, {"type": "heading", "lvl": 2, "value": "Introduction", "md": "## Introduction"}, {"type": "text", "value": "Modern machine learning models have achieved near- or even super-human performance on many tasks. This has contributed to deployments of models across critical domains, including finance, public policy, and healthcare. However, in tandem with the growing deployment of machine learning models, researchers have also demonstrated concerning model performance drops under distribution shift \u2013 when the test/deployment data are not drawn from the same distribution as the training data. Analyses of these performance drops have primarily been confined to the domains of vision and language modeling (e.g. [38, 50], where effective benchmarks for distribution shift exist. Despite the widespread use of tabular data, the impact of distribution shift on tabular data has not been thoroughly investigated. While there are existing benchmarks for IID tabular classification, none of these focus on distribution shifts [36, 33].\n\nThis is particularly concerning in light of the known differences between tabular data and the modalities mentioned above (images, text, audio). First, in contrast to these modalities, where large neural models are the undisputed state-of-the-art, there is considerable debate about whether deep\n\n1The benchmark data, Python package, model implementations, and more information about TABLESHIFT are available at https://github.com/mlfoundations/tableshift and https://tableshift.org.\n\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).", "md": "Modern machine learning models have achieved near- or even super-human performance on many tasks. This has contributed to deployments of models across critical domains, including finance, public policy, and healthcare. However, in tandem with the growing deployment of machine learning models, researchers have also demonstrated concerning model performance drops under distribution shift \u2013 when the test/deployment data are not drawn from the same distribution as the training data. Analyses of these performance drops have primarily been confined to the domains of vision and language modeling (e.g. [38, 50], where effective benchmarks for distribution shift exist. Despite the widespread use of tabular data, the impact of distribution shift on tabular data has not been thoroughly investigated. While there are existing benchmarks for IID tabular classification, none of these focus on distribution shifts [36, 33].\n\nThis is particularly concerning in light of the known differences between tabular data and the modalities mentioned above (images, text, audio). First, in contrast to these modalities, where large neural models are the undisputed state-of-the-art, there is considerable debate about whether deep\n\n1The benchmark data, Python package, model implementations, and more information about TABLESHIFT are available at https://github.com/mlfoundations/tableshift and https://tableshift.org.\n\n37th Conference on Neural Information Processing Systems (NeurIPS 2023)."}]}, {"page": 2, "text": "                                           In- vs. Out-of-Distribution Accuracy\n                                          Over 15 TableShift Tasks (                                              = 0.81)\n                                              est Accuracy\n                                                1.0                                                                               10    1\n                                                0.9                                                                                          Change in Label Distribution\n                                                0.8                                                                                              yID||\n                                              Out-of-Distribution T\n                                                0.7                                                                               10    2         y = ||yOOD\n                                                0.6\n                                                0.5\n                                                0.4                                                                               10    3\n                                                           0.6             0.7            0.8             0.9    1.0\n                                                             In-Distribution Test Accuracy\n                                                      XGBoost                SAINT      Model        Group DRO  MMD\n                                                      LightGBM               NODE                    DANN       CORAL\n                                                      MLP                    TabTransformer          IRM        Label Group DRO\n                                                      FT-Transformer         CatBoost                MixUp      Adv. Label DRO\n                                                      ResNet                 DRO                     VREX       y=x\n Figure 1: In-domain (ID) and out-of-domain (OOD) accuracy show a linear trend across 15 TableShift\n tasks and 19 model types (\u03c1 = 0.81). ID accuracy (x-axis values) and change in the label distribution\n\u2206y (color) together explain 99% of the variance in OOD accuracy (R2 = 0.993). For exact results\n see Section E.3.\n learning models improve performance over non-neural baselines (e.g. XGBoost, LightGBM) for\n tabular data, even without the presence of distribution shift [46, 15, 78]. Second, tabular data tends\n to contain structured features extracted from raw data (e.g. counts of activities, coded responses to\n questions), as opposed to the raw signals (e.g. activity event streams, pixel values, audio of responses)\n where modern machine learning methods perform well and where previous studies of distribution\n shift have focused. Third, tabular data requires fundamentally different preprocessing procedures,\n and the impact of these decisions is not widely understood, despite being known to have empirical\n impact [31]. Finally, high-quality tabular datasets can be diffi                                                  cult to access [35]; for example, due\n to the personal nature of many tabular datasets, tabular data cannot simply be scraped at Internet\n scale as many text and image datasets are. This makes finding high-quality tabular distribution shift\n datasets particularly challenging.\n Thus, the machine learning research community currently lacks not only (1) an empirical understand-\n ing of the impact of distribution shift on tabular data models, but also (2) a shared set of accessible\n and high-quality benchmarks to enable such investigations. We address both gaps in this work. Our\n main contributions are:\n TableShift Benchmark: we introduce a curated, high-quality set of publicly-accessible benchmark\n tasks for (binary) tabular data classification under distribution shift. We describe the tasks in \u00a73.1\n and the API in \u00a73.2. TableShift includes a set of real-world tabular datasets from domains including\n finance [30], public policy [24], healthcare [19, 47, 18, 74, 87], and civic participation [5]. We select\n these datasets to ensure a diversity of tasks, distribution shifts, and dataset sizes.\n Large-scale empirical study of distribution shift in tabular data: We conduct a large-scale study\n in \u00a74, including state-of-the-art tree-based tabular models, tabular neural networks, distributional\n robustness methods, domain generalization methods, and label shift robustness methods. Our findings\n show (1) a strong linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy\n across benchmark tasks and models that was not previously identified for tabular data; (2) that no\n model consistently outperforms baseline methods, and (3) a correlation between the shift gap and the\n shift in label distribution, which is not ameliorated by label shift robustness methods included in our\n study.\n                                                                                                 2", "md": "## In- vs. Out-of-Distribution Accuracy Over 15 TableShift Tasks (\u03c1 = 0.81)\n\n$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n\\text{est Accuracy} & 1.0 & 10 & 1 \\\\\n\\hline\n0.9 & & & \\\\\n\\hline\n0.8 & & & \\\\\n\\hline\n\\text{Out-of-Distribution T} & 10 & 2 & y = ||y_{OOD} \\\\\n\\hline\n0.7 & & & \\\\\n\\hline\n0.6 & & & \\\\\n\\hline\n0.5 & & & \\\\\n\\hline\n0.4 & 10 & 3 & \\\\\n\\hline\n\\end{array}\n$$\n\nFigure 1: In-domain (ID) and out-of-domain (OOD) accuracy show a linear trend across 15 TableShift tasks and 19 model types (\u03c1 = 0.81). ID accuracy (x-axis values) and change in the label distribution \u2206y (color) together explain 99% of the variance in OOD accuracy (R2 = 0.993). For exact results see Section E.3.\n\nLearning models improve performance over non-neural baselines (e.g. XGBoost, LightGBM) for tabular data, even without the presence of distribution shift [46, 15, 78]. Second, tabular data tends to contain structured features extracted from raw data (e.g. counts of activities, coded responses to questions), as opposed to the raw signals (e.g. activity event streams, pixel values, audio of responses) where modern machine learning methods perform well and where previous studies of distribution shift have focused. Third, tabular data requires fundamentally different preprocessing procedures, and the impact of these decisions is not widely understood, despite being known to have empirical impact [31]. Finally, high-quality tabular datasets can be difficult to access [35]; for example, due to the personal nature of many tabular datasets, tabular data cannot simply be scraped at Internet scale as many text and image datasets are. This makes finding high-quality tabular distribution shift datasets particularly challenging.\n\nThus, the machine learning research community currently lacks not only (1) an empirical understanding of the impact of distribution shift on tabular data models, but also (2) a shared set of accessible and high-quality benchmarks to enable such investigations. We address both gaps in this work. Our main contributions are:\n\n- TableShift Benchmark: we introduce a curated, high-quality set of publicly-accessible benchmark tasks for (binary) tabular data classification under distribution shift. We describe the tasks in \u00a73.1 and the API in \u00a73.2. TableShift includes a set of real-world tabular datasets from domains including finance [30], public policy [24], healthcare [19, 47, 18, 74, 87], and civic participation [5]. We select these datasets to ensure a diversity of tasks, distribution shifts, and dataset sizes.\n- Large-scale empirical study of distribution shift in tabular data: We conduct a large-scale study in \u00a74, including state-of-the-art tree-based tabular models, tabular neural networks, distributional robustness methods, domain generalization methods, and label shift robustness methods. Our findings show (1) a strong linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy across benchmark tasks and models that was not previously identified for tabular data; (2) that no model consistently outperforms baseline methods, and (3) a correlation between the shift gap and the shift in label distribution, which is not ameliorated by label shift robustness methods included in our study.", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "In- vs. Out-of-Distribution Accuracy Over 15 TableShift Tasks (\u03c1 = 0.81)", "md": "## In- vs. Out-of-Distribution Accuracy Over 15 TableShift Tasks (\u03c1 = 0.81)"}, {"type": "text", "value": "$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n\\text{est Accuracy} & 1.0 & 10 & 1 \\\\\n\\hline\n0.9 & & & \\\\\n\\hline\n0.8 & & & \\\\\n\\hline\n\\text{Out-of-Distribution T} & 10 & 2 & y = ||y_{OOD} \\\\\n\\hline\n0.7 & & & \\\\\n\\hline\n0.6 & & & \\\\\n\\hline\n0.5 & & & \\\\\n\\hline\n0.4 & 10 & 3 & \\\\\n\\hline\n\\end{array}\n$$\n\nFigure 1: In-domain (ID) and out-of-domain (OOD) accuracy show a linear trend across 15 TableShift tasks and 19 model types (\u03c1 = 0.81). ID accuracy (x-axis values) and change in the label distribution \u2206y (color) together explain 99% of the variance in OOD accuracy (R2 = 0.993). For exact results see Section E.3.\n\nLearning models improve performance over non-neural baselines (e.g. XGBoost, LightGBM) for tabular data, even without the presence of distribution shift [46, 15, 78]. Second, tabular data tends to contain structured features extracted from raw data (e.g. counts of activities, coded responses to questions), as opposed to the raw signals (e.g. activity event streams, pixel values, audio of responses) where modern machine learning methods perform well and where previous studies of distribution shift have focused. Third, tabular data requires fundamentally different preprocessing procedures, and the impact of these decisions is not widely understood, despite being known to have empirical impact [31]. Finally, high-quality tabular datasets can be difficult to access [35]; for example, due to the personal nature of many tabular datasets, tabular data cannot simply be scraped at Internet scale as many text and image datasets are. This makes finding high-quality tabular distribution shift datasets particularly challenging.\n\nThus, the machine learning research community currently lacks not only (1) an empirical understanding of the impact of distribution shift on tabular data models, but also (2) a shared set of accessible and high-quality benchmarks to enable such investigations. We address both gaps in this work. Our main contributions are:\n\n- TableShift Benchmark: we introduce a curated, high-quality set of publicly-accessible benchmark tasks for (binary) tabular data classification under distribution shift. We describe the tasks in \u00a73.1 and the API in \u00a73.2. TableShift includes a set of real-world tabular datasets from domains including finance [30], public policy [24], healthcare [19, 47, 18, 74, 87], and civic participation [5]. We select these datasets to ensure a diversity of tasks, distribution shifts, and dataset sizes.\n- Large-scale empirical study of distribution shift in tabular data: We conduct a large-scale study in \u00a74, including state-of-the-art tree-based tabular models, tabular neural networks, distributional robustness methods, domain generalization methods, and label shift robustness methods. Our findings show (1) a strong linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy across benchmark tasks and models that was not previously identified for tabular data; (2) that no model consistently outperforms baseline methods, and (3) a correlation between the shift gap and the shift in label distribution, which is not ameliorated by label shift robustness methods included in our study.", "md": "$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n\\text{est Accuracy} & 1.0 & 10 & 1 \\\\\n\\hline\n0.9 & & & \\\\\n\\hline\n0.8 & & & \\\\\n\\hline\n\\text{Out-of-Distribution T} & 10 & 2 & y = ||y_{OOD} \\\\\n\\hline\n0.7 & & & \\\\\n\\hline\n0.6 & & & \\\\\n\\hline\n0.5 & & & \\\\\n\\hline\n0.4 & 10 & 3 & \\\\\n\\hline\n\\end{array}\n$$\n\nFigure 1: In-domain (ID) and out-of-domain (OOD) accuracy show a linear trend across 15 TableShift tasks and 19 model types (\u03c1 = 0.81). ID accuracy (x-axis values) and change in the label distribution \u2206y (color) together explain 99% of the variance in OOD accuracy (R2 = 0.993). For exact results see Section E.3.\n\nLearning models improve performance over non-neural baselines (e.g. XGBoost, LightGBM) for tabular data, even without the presence of distribution shift [46, 15, 78]. Second, tabular data tends to contain structured features extracted from raw data (e.g. counts of activities, coded responses to questions), as opposed to the raw signals (e.g. activity event streams, pixel values, audio of responses) where modern machine learning methods perform well and where previous studies of distribution shift have focused. Third, tabular data requires fundamentally different preprocessing procedures, and the impact of these decisions is not widely understood, despite being known to have empirical impact [31]. Finally, high-quality tabular datasets can be difficult to access [35]; for example, due to the personal nature of many tabular datasets, tabular data cannot simply be scraped at Internet scale as many text and image datasets are. This makes finding high-quality tabular distribution shift datasets particularly challenging.\n\nThus, the machine learning research community currently lacks not only (1) an empirical understanding of the impact of distribution shift on tabular data models, but also (2) a shared set of accessible and high-quality benchmarks to enable such investigations. We address both gaps in this work. Our main contributions are:\n\n- TableShift Benchmark: we introduce a curated, high-quality set of publicly-accessible benchmark tasks for (binary) tabular data classification under distribution shift. We describe the tasks in \u00a73.1 and the API in \u00a73.2. TableShift includes a set of real-world tabular datasets from domains including finance [30], public policy [24], healthcare [19, 47, 18, 74, 87], and civic participation [5]. We select these datasets to ensure a diversity of tasks, distribution shifts, and dataset sizes.\n- Large-scale empirical study of distribution shift in tabular data: We conduct a large-scale study in \u00a74, including state-of-the-art tree-based tabular models, tabular neural networks, distributional robustness methods, domain generalization methods, and label shift robustness methods. Our findings show (1) a strong linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy across benchmark tasks and models that was not previously identified for tabular data; (2) that no model consistently outperforms baseline methods, and (3) a correlation between the shift gap and the shift in label distribution, which is not ameliorated by label shift robustness methods included in our study."}]}, {"page": 3, "text": "Accessible TableShift API and baselines: We release a Python API for constructing rich datasets\ndirectly from their raw public forms. The API provides built-in documentation of data types and\nfeature codings, alongside standardized preprocessing and transformation pipelines, making the\ndatasets accessible in multiple formats suitable for training tabular models (e.g. in scikit-learn and\nPyTorch). We also release the set of baseline model implementations (including both state of the art\ntabular data models, robust learning models, and domain generalization methods) and end-to-end\ntraining code in order to facilitate future research on distribution shift in tabular data.\n2     Setup, Task, and Notation\n2.1    Task and Setting\nConsider a dataset composed of examples (x, y, d) \u223c               Pd where x is the input, y is the prediction\ntarget, and d the domain from which that example is drawn. All examples drawn from Pd have\ndomain label d. We can view the overall data distribution as a mixture of domains D = {d1, . . . , dD},\nwhere D \u2265      2. Training examples are drawn from the training distribution P train =                       d   Pd,\n                                                                                                       d\u2208D qtrain\nand testing examples from P test =                  d Pd, with domain weights qd \u2208          [0, 1]. We can define\n                                             d\u2208D qtest\nthe training and testing domains as Dtrain = {d \u2208             D : qtrain  > 0} and Dtest = d \u2208        D : qtest > 0,\n                                                                     d                                      d\nrespectively. We refer to cases where |Dtrain| \u2265        2 as \u201cdomain generalization\u201d tasks, because domain\ngeneralization models require at least two subdomains in the training data.\nIn a standard (IID) setting, our goal is to learn a classifier f\u03b8 that accurately predicts y using examples\nfrom Dtrain. A distribution shift (or domain shift) occurs due to the fact that P train \u0338= P test. As a\nconsequence of this shift, the joint distributions ptrain(x, y) \u0338= ptest(x, y) differ in training and testing.\nThis difference can be composed of one or more changes to the underlying data generating process.\nThis includes covariate shift, where p(x) changes; label shift, where p(y) changes, and concept shift,\nwhere p(y|x) changes. In almost all real-world scenarios, distribution shifts are composed of an\nunknown mixture of all three forms of shift2. For a fixed classifier f\u03b8, we refer to\n                                   \u2206Acc = Acc(f\u03b8, Dtest) \u2212       Acc(f\u03b8, Dtrain)                                  (1)\nas the \u201cshift gap\u201d (where both metrics are computed on examples not seen at training time). Note that\nthe shift gap can be affected by changes in p(y), p(y|x), and p(x). While disentangling the effects of\nthese forms of shift is not a focus of the current work, we provide initial exploratory results on the\nimpact of changes in p(y), p(y|x), and p(x) over the benchmark tasks in Sections 5 and E.\nIn our setting, we assume that no information about the target Dtest is available \u2013 i.e., there is no\nknowledge of the change in p(y), p(y|x), and p(x), and no unlabeled data from the target domain.\n2.2    Related Work\nHere we provide a brief overview of related work necessary to contextualize our benchmark and main\nresults. For a detailed overview of related work, see Section D.\nOur work is closely related to the literature on distribution shift in machine learning. A series of\nrecent works have demonstrated that even state-of-the-art models experience significant performance\ndrops under distribution shift in tasks including vision, language modeling, and question answering\n[61, 62, 38, 50, 9]. This has led to the development of methods to mitigate susceptibility to such shifts\n[76, 53, 1, 6, 90, 89, 54, 46]. High-quality benchmarks, specifically tailored to distribution shift, have\nbeen essential in both measuring these gaps and assessing progress toward closing them [38, 50]. The\nuse of tabular data is widespread in practice [15, 46, 78], including the use of sensitive personal data\n(race, gender, age) and for important tasks (credit scoring, medical diagnosis). However, the impact\nof distribution shift in the tabular domain has received little attention in the research literature. In\nparticular, benchmarks containing tabular distribution shifts are lacking (one notable exception is\nShifts [57] and Shifts 2.0 [57], a multimodal benchmark of fi          ve tasks, two of which are tabular; for a\nmore detailed overview of domain shift benchmarks and a comparison to TABLESHIFT, see Section\nG).\n    2We note that this is a slight abuse of the terminology, as e.g. \u201clabel shift\u201d typically refers to the case where\nonly p(y) changes.\n                                                          3", "md": "## Accessible TableShift API and baselines\n\nWe release a Python API for constructing rich datasets directly from their raw public forms. The API provides built-in documentation of data types and feature codings, alongside standardized preprocessing and transformation pipelines, making the datasets accessible in multiple formats suitable for training tabular models (e.g. in scikit-learn and PyTorch). We also release the set of baseline model implementations (including both state of the art tabular data models, robust learning models, and domain generalization methods) and end-to-end training code in order to facilitate future research on distribution shift in tabular data.\n\n## Setup, Task, and Notation\n\n### Task and Setting\n\nConsider a dataset composed of examples $$(x, y, d) \\sim P_d$$ where x is the input, y is the prediction target, and d the domain from which that example is drawn. All examples drawn from $$P_d$$ have domain label d. We can view the overall data distribution as a mixture of domains $$D = \\{d_1, ..., d_D\\}$$, where $$D \\geq 2$$. Training examples are drawn from the training distribution $$P_{\\text{train}} = \\sum_{d \\in D} q_{\\text{train}} P_d$$, and testing examples from $$P_{\\text{test}} = \\sum_{d \\in D} q_{\\text{test}} P_d$$, with domain weights $$q_d \\in [0, 1]$$. We can define the training and testing domains as $$D_{\\text{train}} = \\{d \\in D : q_{\\text{train}} > 0\\}$$ and $$D_{\\text{test}} = \\{d \\in D : q_{\\text{test}} > 0\\}$$, respectively. We refer to cases where $$|D_{\\text{train}}| \\geq 2$$ as \"domain generalization\" tasks, because domain generalization models require at least two subdomains in the training data.\n\nIn a standard (IID) setting, our goal is to learn a classifier $$f_{\\theta}$$ that accurately predicts y using examples from $$D_{\\text{train}}$$. A distribution shift (or domain shift) occurs due to the fact that $$P_{\\text{train}} \\neq P_{\\text{test}}$$. As a consequence of this shift, the joint distributions $$p_{\\text{train}}(x, y) \\neq p_{\\text{test}}(x, y)$$ differ in training and testing. This difference can be composed of one or more changes to the underlying data generating process. This includes covariate shift, where $$p(x)$$ changes; label shift, where $$p(y)$$ changes, and concept shift, where $$p(y|x)$$ changes. In almost all real-world scenarios, distribution shifts are composed of an unknown mixture of all three forms of shift. For a fixed classifier $$f_{\\theta}$$, we refer to\n\n$$\\Delta \\text{Acc} = \\text{Acc}(f_{\\theta}, D_{\\text{test}}) - \\text{Acc}(f_{\\theta}, D_{\\text{train}}) \\quad (1)$$\n\nas the \"shift gap\" (where both metrics are computed on examples not seen at training time). Note that the shift gap can be affected by changes in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$. While disentangling the effects of these forms of shift is not a focus of the current work, we provide initial exploratory results on the impact of changes in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$ over the benchmark tasks in Sections 5 and E.\n\nIn our setting, we assume that no information about the target $$D_{\\text{test}}$$ is available \u2013 i.e., there is no knowledge of the change in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$, and no unlabeled data from the target domain.\n\n### Related Work\n\nHere we provide a brief overview of related work necessary to contextualize our benchmark and main results. For a detailed overview of related work, see Section D.\n\nOur work is closely related to the literature on distribution shift in machine learning. A series of recent works have demonstrated that even state-of-the-art models experience significant performance drops under distribution shift in tasks including vision, language modeling, and question answering. This has led to the development of methods to mitigate susceptibility to such shifts. High-quality benchmarks, specifically tailored to distribution shift, have been essential in both measuring these gaps and assessing progress toward closing them. The use of tabular data is widespread in practice, including the use of sensitive personal data (race, gender, age) and for important tasks (credit scoring, medical diagnosis). However, the impact of distribution shift in the tabular domain has received little attention in the research literature. In particular, benchmarks containing tabular distribution shifts are lacking (one notable exception is Shifts and Shifts 2.0, a multimodal benchmark of five tasks, two of which are tabular; for a more detailed overview of domain shift benchmarks and a comparison to TABLESHIFT, see Section G).", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "Accessible TableShift API and baselines", "md": "## Accessible TableShift API and baselines"}, {"type": "text", "value": "We release a Python API for constructing rich datasets directly from their raw public forms. The API provides built-in documentation of data types and feature codings, alongside standardized preprocessing and transformation pipelines, making the datasets accessible in multiple formats suitable for training tabular models (e.g. in scikit-learn and PyTorch). We also release the set of baseline model implementations (including both state of the art tabular data models, robust learning models, and domain generalization methods) and end-to-end training code in order to facilitate future research on distribution shift in tabular data.", "md": "We release a Python API for constructing rich datasets directly from their raw public forms. The API provides built-in documentation of data types and feature codings, alongside standardized preprocessing and transformation pipelines, making the datasets accessible in multiple formats suitable for training tabular models (e.g. in scikit-learn and PyTorch). We also release the set of baseline model implementations (including both state of the art tabular data models, robust learning models, and domain generalization methods) and end-to-end training code in order to facilitate future research on distribution shift in tabular data."}, {"type": "heading", "lvl": 2, "value": "Setup, Task, and Notation", "md": "## Setup, Task, and Notation"}, {"type": "heading", "lvl": 3, "value": "Task and Setting", "md": "### Task and Setting"}, {"type": "text", "value": "Consider a dataset composed of examples $$(x, y, d) \\sim P_d$$ where x is the input, y is the prediction target, and d the domain from which that example is drawn. All examples drawn from $$P_d$$ have domain label d. We can view the overall data distribution as a mixture of domains $$D = \\{d_1, ..., d_D\\}$$, where $$D \\geq 2$$. Training examples are drawn from the training distribution $$P_{\\text{train}} = \\sum_{d \\in D} q_{\\text{train}} P_d$$, and testing examples from $$P_{\\text{test}} = \\sum_{d \\in D} q_{\\text{test}} P_d$$, with domain weights $$q_d \\in [0, 1]$$. We can define the training and testing domains as $$D_{\\text{train}} = \\{d \\in D : q_{\\text{train}} > 0\\}$$ and $$D_{\\text{test}} = \\{d \\in D : q_{\\text{test}} > 0\\}$$, respectively. We refer to cases where $$|D_{\\text{train}}| \\geq 2$$ as \"domain generalization\" tasks, because domain generalization models require at least two subdomains in the training data.\n\nIn a standard (IID) setting, our goal is to learn a classifier $$f_{\\theta}$$ that accurately predicts y using examples from $$D_{\\text{train}}$$. A distribution shift (or domain shift) occurs due to the fact that $$P_{\\text{train}} \\neq P_{\\text{test}}$$. As a consequence of this shift, the joint distributions $$p_{\\text{train}}(x, y) \\neq p_{\\text{test}}(x, y)$$ differ in training and testing. This difference can be composed of one or more changes to the underlying data generating process. This includes covariate shift, where $$p(x)$$ changes; label shift, where $$p(y)$$ changes, and concept shift, where $$p(y|x)$$ changes. In almost all real-world scenarios, distribution shifts are composed of an unknown mixture of all three forms of shift. For a fixed classifier $$f_{\\theta}$$, we refer to\n\n$$\\Delta \\text{Acc} = \\text{Acc}(f_{\\theta}, D_{\\text{test}}) - \\text{Acc}(f_{\\theta}, D_{\\text{train}}) \\quad (1)$$\n\nas the \"shift gap\" (where both metrics are computed on examples not seen at training time). Note that the shift gap can be affected by changes in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$. While disentangling the effects of these forms of shift is not a focus of the current work, we provide initial exploratory results on the impact of changes in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$ over the benchmark tasks in Sections 5 and E.\n\nIn our setting, we assume that no information about the target $$D_{\\text{test}}$$ is available \u2013 i.e., there is no knowledge of the change in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$, and no unlabeled data from the target domain.", "md": "Consider a dataset composed of examples $$(x, y, d) \\sim P_d$$ where x is the input, y is the prediction target, and d the domain from which that example is drawn. All examples drawn from $$P_d$$ have domain label d. We can view the overall data distribution as a mixture of domains $$D = \\{d_1, ..., d_D\\}$$, where $$D \\geq 2$$. Training examples are drawn from the training distribution $$P_{\\text{train}} = \\sum_{d \\in D} q_{\\text{train}} P_d$$, and testing examples from $$P_{\\text{test}} = \\sum_{d \\in D} q_{\\text{test}} P_d$$, with domain weights $$q_d \\in [0, 1]$$. We can define the training and testing domains as $$D_{\\text{train}} = \\{d \\in D : q_{\\text{train}} > 0\\}$$ and $$D_{\\text{test}} = \\{d \\in D : q_{\\text{test}} > 0\\}$$, respectively. We refer to cases where $$|D_{\\text{train}}| \\geq 2$$ as \"domain generalization\" tasks, because domain generalization models require at least two subdomains in the training data.\n\nIn a standard (IID) setting, our goal is to learn a classifier $$f_{\\theta}$$ that accurately predicts y using examples from $$D_{\\text{train}}$$. A distribution shift (or domain shift) occurs due to the fact that $$P_{\\text{train}} \\neq P_{\\text{test}}$$. As a consequence of this shift, the joint distributions $$p_{\\text{train}}(x, y) \\neq p_{\\text{test}}(x, y)$$ differ in training and testing. This difference can be composed of one or more changes to the underlying data generating process. This includes covariate shift, where $$p(x)$$ changes; label shift, where $$p(y)$$ changes, and concept shift, where $$p(y|x)$$ changes. In almost all real-world scenarios, distribution shifts are composed of an unknown mixture of all three forms of shift. For a fixed classifier $$f_{\\theta}$$, we refer to\n\n$$\\Delta \\text{Acc} = \\text{Acc}(f_{\\theta}, D_{\\text{test}}) - \\text{Acc}(f_{\\theta}, D_{\\text{train}}) \\quad (1)$$\n\nas the \"shift gap\" (where both metrics are computed on examples not seen at training time). Note that the shift gap can be affected by changes in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$. While disentangling the effects of these forms of shift is not a focus of the current work, we provide initial exploratory results on the impact of changes in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$ over the benchmark tasks in Sections 5 and E.\n\nIn our setting, we assume that no information about the target $$D_{\\text{test}}$$ is available \u2013 i.e., there is no knowledge of the change in $$p(y)$$, $$p(y|x)$$, and $$p(x)$$, and no unlabeled data from the target domain."}, {"type": "heading", "lvl": 3, "value": "Related Work", "md": "### Related Work"}, {"type": "text", "value": "Here we provide a brief overview of related work necessary to contextualize our benchmark and main results. For a detailed overview of related work, see Section D.\n\nOur work is closely related to the literature on distribution shift in machine learning. A series of recent works have demonstrated that even state-of-the-art models experience significant performance drops under distribution shift in tasks including vision, language modeling, and question answering. This has led to the development of methods to mitigate susceptibility to such shifts. High-quality benchmarks, specifically tailored to distribution shift, have been essential in both measuring these gaps and assessing progress toward closing them. The use of tabular data is widespread in practice, including the use of sensitive personal data (race, gender, age) and for important tasks (credit scoring, medical diagnosis). However, the impact of distribution shift in the tabular domain has received little attention in the research literature. In particular, benchmarks containing tabular distribution shifts are lacking (one notable exception is Shifts and Shifts 2.0, a multimodal benchmark of five tasks, two of which are tabular; for a more detailed overview of domain shift benchmarks and a comparison to TABLESHIFT, see Section G).", "md": "Here we provide a brief overview of related work necessary to contextualize our benchmark and main results. For a detailed overview of related work, see Section D.\n\nOur work is closely related to the literature on distribution shift in machine learning. A series of recent works have demonstrated that even state-of-the-art models experience significant performance drops under distribution shift in tasks including vision, language modeling, and question answering. This has led to the development of methods to mitigate susceptibility to such shifts. High-quality benchmarks, specifically tailored to distribution shift, have been essential in both measuring these gaps and assessing progress toward closing them. The use of tabular data is widespread in practice, including the use of sensitive personal data (race, gender, age) and for important tasks (credit scoring, medical diagnosis). However, the impact of distribution shift in the tabular domain has received little attention in the research literature. In particular, benchmarks containing tabular distribution shifts are lacking (one notable exception is Shifts and Shifts 2.0, a multimodal benchmark of five tasks, two of which are tabular; for a more detailed overview of domain shift benchmarks and a comparison to TABLESHIFT, see Section G)."}]}, {"page": 4, "text": "      3    Tableshift: A Distribution Shift Benchmark for Tabular Data\n      This work introduces the TABLESHIFT benchmark. TABLESHIFT contains a set of 15 curated tasks\n      designed to be a rigorous, challenging, diverse, and reliable benchmarking suite for tabular data under\n      distribution shift, and we encapsulate them within a Python API.\n      3.1    TableShift Benchmark Tasks\n      To select tasks for TABLESHIFT, we identified datasets meeting the following formal criteria:\n      Open source: datasets must be publicly available, including data dictionaries documenting the source\n      of the data (i.e. conditions of its collection), definitions of variables, and any preprocessing applied.\n      Real-world: does not contain simulated data.\n      Table 1: Summary of TABLESHIFT tasks and their associated distribution shifts. For details on\n      each task, see Section E. \u201cDomain Generalization\u201d indicates whether there are multiple training\n      subdomains (|Dtrain| \u2265     2) and thus whether domain generalization models can be applied to this\n      task. \u201cBaseline gap\u201d gives the \u201cshift gap\u201d \u2206Acc (difference between ID and OOD test accuracy, see\n      Equation (1)) of the tuned XGBoost or LightGBM model with the best validation accuracy after\n      following our hyperparameter tuning procedure (\u00a74.2).\nTask                Target                           Shift                  Domain              Baseline\n                                                                        Generalization         Gap \u2206Acc         SE(\u2206Acc)\nASSISTments         Next Answer Correct              School                     \u2713               \u221234.49 %           0.011\nCollege             Low Degree Completion            Institution                \u2713               \u221211.16 %           0.010\nScorecard           Rate                             Type\nICU Hospital        ICU patient expires in hos-      Insurance                  \u2713                \u22126.30 %           0.008\nMortality           pital during current visit       Type\nHospital            30-day readmission of dia-       Admission                  \u2713                \u22125.94 %           0.002\nReadmission         betic hospital patients          source\nDiabetes            Diabetes diagnosis               Race                       \u2713                \u22124.48 %           0.001\nICU Length          Length of stay >= 3 hrs in       Insurance                  \u2713                \u22123.39 %           0.015\nof Stay             ICU                              Type\nVoting              Voted in U.S. presidential       Geographic                 \u2713                \u22122.58 %           0.016\n                    election                         Region\nFood Stamps         Food stamp recipiency in         Geographic                 \u2713                \u22122.39 %           0.002\n                    past year for households         Region\n                    with child\nUnemployment Unemployment for non-                   Education                  \u2713                \u22121.28 %           0.001\n                    social     security-eligible     Level\n                    adults\nIncome              Income >= 56k for em-            Geographic                 \u2713                \u22121.25 %           0.002\n                    ployed adults                    Region\nFICO                Repayment of Home Equity         Est.      third-                           \u221222.58 %           0.029\nHELOC               Line of Credit loan              party risk level\nPublic Health       Coverage of non-Medicare         Disability Sta-                            \u221214.46 %           0.001\nInsurance           eligible low-income indi-        tus\n                    viduals\nSepsis              Sepsis onset within next         Length of Stay                              \u22126.05 %           0.001\n                    6hrs for hospital patients\nChildhood           Blood lead levels above          Poverty level                               \u22125.12 %           0.005\nLead                CDC Blood Level Refer-\n                    ence Value\nHypertension        Hypertension diagnosis for       BMI Category                                \u22124.36 %           0.003\n                    high-risk age (50+)\n                                                             4", "md": "# Tableshift: A Distribution Shift Benchmark for Tabular Data\n\n### Tableshift: A Distribution Shift Benchmark for Tabular Data\n\nThis work introduces the TABLESHIFT benchmark. TABLESHIFT contains a set of 15 curated tasks designed to be a rigorous, challenging, diverse, and reliable benchmarking suite for tabular data under distribution shift, and we encapsulate them within a Python API.\n\n#### TableShift Benchmark Tasks\n\nTo select tasks for TABLESHIFT, we identified datasets meeting the following formal criteria:\n\n- Open source: datasets must be publicly available, including data dictionaries documenting the source of the data (i.e. conditions of its collection), definitions of variables, and any preprocessing applied.\n- Real-world: does not contain simulated data.\n\n**Summary of TABLESHIFT tasks and their associated distribution shifts**\n|Task|Target|Shift|Domain Generalization|Baseline Gap \u2206Acc|SE(\u2206Acc)|\n|---|---|---|---|---|---|\n|ASSISTments|Next Answer Correct|School|\u2713|-34.49%|0.011|\n|College|Low Degree Completion|Institution|\u2713|-11.16%|0.010|\n|Scorecard|Rate|Type| | | |\n|ICU Hospital Mortality|ICU patient expires in hospital during current visit|Insurance Type|\u2713|-6.30%|0.008|\n|Hospital Readmission|30-day readmission of diabetic hospital patients|Admission source|\u2713|-5.94%|0.002|\n|Diabetes ICU Length of Stay|Diabetes diagnosis|Race|\u2713|-4.48%|0.001|\n|ICU Length of Stay|Length of stay >= 3 hrs in ICU|Insurance Type|\u2713|-3.39%|0.015|\n|Voting|Voted in U.S. presidential election|Geographic Region|\u2713|-2.58%|0.016|\n|Food Stamps|Food stamp recipiency in past year for households with child|Geographic Region|\u2713|-2.39%|0.002|\n|Unemployment|Unemployment for non-social security-eligible adults|Education Level|\u2713|-1.28%|0.001|\n|Income|Income >= 56k for employed adults|Geographic Region|\u2713|-1.25%|0.002|\n|FICO HELOC|Repayment of Home Equity Line of Credit loan|Est. third-party risk level| |-22.58%|0.029|\n|Public Health Insurance|Coverage of non-Medicare eligible low-income individuals|Disability Status| |-14.46%|0.001|\n|Sepsis|Sepsis onset within next 6hrs for hospital patients|Length of Stay| |-6.05%|0.001|\n|Childhood Lead|Blood lead levels above CDC Blood Level Reference Value|Poverty level| |-5.12%|0.005|\n|Hypertension|Hypertension diagnosis for high-risk age (50+)|BMI Category| |-4.36%|0.003|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Tableshift: A Distribution Shift Benchmark for Tabular Data", "md": "# Tableshift: A Distribution Shift Benchmark for Tabular Data"}, {"type": "heading", "lvl": 3, "value": "Tableshift: A Distribution Shift Benchmark for Tabular Data", "md": "### Tableshift: A Distribution Shift Benchmark for Tabular Data"}, {"type": "text", "value": "This work introduces the TABLESHIFT benchmark. TABLESHIFT contains a set of 15 curated tasks designed to be a rigorous, challenging, diverse, and reliable benchmarking suite for tabular data under distribution shift, and we encapsulate them within a Python API.", "md": "This work introduces the TABLESHIFT benchmark. TABLESHIFT contains a set of 15 curated tasks designed to be a rigorous, challenging, diverse, and reliable benchmarking suite for tabular data under distribution shift, and we encapsulate them within a Python API."}, {"type": "heading", "lvl": 4, "value": "TableShift Benchmark Tasks", "md": "#### TableShift Benchmark Tasks"}, {"type": "text", "value": "To select tasks for TABLESHIFT, we identified datasets meeting the following formal criteria:\n\n- Open source: datasets must be publicly available, including data dictionaries documenting the source of the data (i.e. conditions of its collection), definitions of variables, and any preprocessing applied.\n- Real-world: does not contain simulated data.\n\n**Summary of TABLESHIFT tasks and their associated distribution shifts**", "md": "To select tasks for TABLESHIFT, we identified datasets meeting the following formal criteria:\n\n- Open source: datasets must be publicly available, including data dictionaries documenting the source of the data (i.e. conditions of its collection), definitions of variables, and any preprocessing applied.\n- Real-world: does not contain simulated data.\n\n**Summary of TABLESHIFT tasks and their associated distribution shifts**"}, {"type": "table", "rows": [["Task", "Target", "Shift", "Domain Generalization", "Baseline Gap \u2206Acc", "SE(\u2206Acc)"], ["ASSISTments", "Next Answer Correct", "School", "\u2713", "-34.49%", "0.011"], ["College", "Low Degree Completion", "Institution", "\u2713", "-11.16%", "0.010"], ["Scorecard", "Rate", "Type", "", "", ""], ["ICU Hospital Mortality", "ICU patient expires in hospital during current visit", "Insurance Type", "\u2713", "-6.30%", "0.008"], ["Hospital Readmission", "30-day readmission of diabetic hospital patients", "Admission source", "\u2713", "-5.94%", "0.002"], ["Diabetes ICU Length of Stay", "Diabetes diagnosis", "Race", "\u2713", "-4.48%", "0.001"], ["ICU Length of Stay", "Length of stay >= 3 hrs in ICU", "Insurance Type", "\u2713", "-3.39%", "0.015"], ["Voting", "Voted in U.S. presidential election", "Geographic Region", "\u2713", "-2.58%", "0.016"], ["Food Stamps", "Food stamp recipiency in past year for households with child", "Geographic Region", "\u2713", "-2.39%", "0.002"], ["Unemployment", "Unemployment for non-social security-eligible adults", "Education Level", "\u2713", "-1.28%", "0.001"], ["Income", "Income >= 56k for employed adults", "Geographic Region", "\u2713", "-1.25%", "0.002"], ["FICO HELOC", "Repayment of Home Equity Line of Credit loan", "Est. third-party risk level", "", "-22.58%", "0.029"], ["Public Health Insurance", "Coverage of non-Medicare eligible low-income individuals", "Disability Status", "", "-14.46%", "0.001"], ["Sepsis", "Sepsis onset within next 6hrs for hospital patients", "Length of Stay", "", "-6.05%", "0.001"], ["Childhood Lead", "Blood lead levels above CDC Blood Level Reference Value", "Poverty level", "", "-5.12%", "0.005"], ["Hypertension", "Hypertension diagnosis for high-risk age (50+)", "BMI Category", "", "-4.36%", "0.003"]], "md": "|Task|Target|Shift|Domain Generalization|Baseline Gap \u2206Acc|SE(\u2206Acc)|\n|---|---|---|---|---|---|\n|ASSISTments|Next Answer Correct|School|\u2713|-34.49%|0.011|\n|College|Low Degree Completion|Institution|\u2713|-11.16%|0.010|\n|Scorecard|Rate|Type| | | |\n|ICU Hospital Mortality|ICU patient expires in hospital during current visit|Insurance Type|\u2713|-6.30%|0.008|\n|Hospital Readmission|30-day readmission of diabetic hospital patients|Admission source|\u2713|-5.94%|0.002|\n|Diabetes ICU Length of Stay|Diabetes diagnosis|Race|\u2713|-4.48%|0.001|\n|ICU Length of Stay|Length of stay >= 3 hrs in ICU|Insurance Type|\u2713|-3.39%|0.015|\n|Voting|Voted in U.S. presidential election|Geographic Region|\u2713|-2.58%|0.016|\n|Food Stamps|Food stamp recipiency in past year for households with child|Geographic Region|\u2713|-2.39%|0.002|\n|Unemployment|Unemployment for non-social security-eligible adults|Education Level|\u2713|-1.28%|0.001|\n|Income|Income >= 56k for employed adults|Geographic Region|\u2713|-1.25%|0.002|\n|FICO HELOC|Repayment of Home Equity Line of Credit loan|Est. third-party risk level| |-22.58%|0.029|\n|Public Health Insurance|Coverage of non-Medicare eligible low-income individuals|Disability Status| |-14.46%|0.001|\n|Sepsis|Sepsis onset within next 6hrs for hospital patients|Length of Stay| |-6.05%|0.001|\n|Childhood Lead|Blood lead levels above CDC Blood Level Reference Value|Poverty level| |-5.12%|0.005|\n|Hypertension|Hypertension diagnosis for high-risk age (50+)|BMI Category| |-4.36%|0.003|", "isPerfectTable": true, "csv": "\"Task\",\"Target\",\"Shift\",\"Domain Generalization\",\"Baseline Gap \u2206Acc\",\"SE(\u2206Acc)\"\n\"ASSISTments\",\"Next Answer Correct\",\"School\",\"\u2713\",\"-34.49%\",\"0.011\"\n\"College\",\"Low Degree Completion\",\"Institution\",\"\u2713\",\"-11.16%\",\"0.010\"\n\"Scorecard\",\"Rate\",\"Type\",\"\",\"\",\"\"\n\"ICU Hospital Mortality\",\"ICU patient expires in hospital during current visit\",\"Insurance Type\",\"\u2713\",\"-6.30%\",\"0.008\"\n\"Hospital Readmission\",\"30-day readmission of diabetic hospital patients\",\"Admission source\",\"\u2713\",\"-5.94%\",\"0.002\"\n\"Diabetes ICU Length of Stay\",\"Diabetes diagnosis\",\"Race\",\"\u2713\",\"-4.48%\",\"0.001\"\n\"ICU Length of Stay\",\"Length of stay >= 3 hrs in ICU\",\"Insurance Type\",\"\u2713\",\"-3.39%\",\"0.015\"\n\"Voting\",\"Voted in U.S. presidential election\",\"Geographic Region\",\"\u2713\",\"-2.58%\",\"0.016\"\n\"Food Stamps\",\"Food stamp recipiency in past year for households with child\",\"Geographic Region\",\"\u2713\",\"-2.39%\",\"0.002\"\n\"Unemployment\",\"Unemployment for non-social security-eligible adults\",\"Education Level\",\"\u2713\",\"-1.28%\",\"0.001\"\n\"Income\",\"Income >= 56k for employed adults\",\"Geographic Region\",\"\u2713\",\"-1.25%\",\"0.002\"\n\"FICO HELOC\",\"Repayment of Home Equity Line of Credit loan\",\"Est. third-party risk level\",\"\",\"-22.58%\",\"0.029\"\n\"Public Health Insurance\",\"Coverage of non-Medicare eligible low-income individuals\",\"Disability Status\",\"\",\"-14.46%\",\"0.001\"\n\"Sepsis\",\"Sepsis onset within next 6hrs for hospital patients\",\"Length of Stay\",\"\",\"-6.05%\",\"0.001\"\n\"Childhood Lead\",\"Blood lead levels above CDC Blood Level Reference Value\",\"Poverty level\",\"\",\"-5.12%\",\"0.005\"\n\"Hypertension\",\"Hypertension diagnosis for high-risk age (50+)\",\"BMI Category\",\"\",\"-4.36%\",\"0.003\""}]}, {"page": 5, "text": "Sufficient dimensionality and size: contains at least three features (in all cases, our benchmark\ndatasets contain many more than three features) and at least 1000 observations. In particular, having\nlarge test sets is critical for making reliable statistical comparisons between models.\nHeterogeneous: contains features of mixed types.\nBinary Classification: supports a meaningful binary classification task (regression tasks are not\nincluded).\nShift Gap: We explicitly select datasets where strong hyperparameter-tuned tabular baselines display\na statistically significant shift gap (\u2206Acc \u0338= 0, see Eqn. (1)).\nIn addition to these criteria, we selected benchmark tasks and data sources that were diverse. TA-\nBLESHIFT includes tasks from many domains (finance, policy, civic participation, medical diagnosis)\nand from a variety of raw data sources (electronic health records, surveys/questionnaires, etc.) and\nwith a diversity of shift gap (\u2206Acc) magnitudes.\nA summary of the benchmark tasks is shown in Table 1. We give a detailed overview of each task,\nincluding background and motivation, information on the data source, and distribution shifts, in\nSection B. Datasets and each individual feature of each task are also documented in the Python\npackage. One important aspect of TableShift\u2019s diversity, shown in Table 1, is that not all real-world\ntasks support domain generalization (i.e. not all tasks have multiple training subdomains, |Dtrain \u2265    2|).\nTo reflect this, we include both types of tasks in the TableShift benchmark.\nWhile the intended use of TableShift is for distribution shift, the package is also likely to be of high\nutility to all researchers studying tabular data modeling due to the data quality, detailed documentation,\nflexible preprocessing, and ease of use of the datasets in TableShift.\n3.2   TableShift API\nSuccessful existing benchmarks for distribution/domain shift in machine learning (e.g. WILDS,\nDomainBed) not only include high-quality datasets, but also make the data accessible by providing\na high-quality API as an interface to the otherwise-disparate sources. This section describes the\nTableShift API. Providing this API for tabular data is particularly important, for several reasons.\nFirst, the input and output of tabular data pipelines differ from other modalities: tabular datasets\nare stored in different formats from image and text datasets, and are used with a greater variety of\nmachine learning tools (e.g. scikit-learn). Second, the preprocessing operations used in tabular\ndata differ significantly from other data modalities. These preprocessing operations also require\nunique feature-level metadata such as data types (i.e. categorical vs. numeric; numeric values for\ncategorical features are a common encoding scheme in practice) and codings for categorical variables.\nFinally, raw sources used to build tabular datasets can be difficult to access. Datasets are often\nscattered across hundreds or even thousands of files (e.g., the Sepsis task dataset is constructed from\nover 40k data files; the Childhood Lead dataset is joined from nearly 100 files containing disjoint\nfeature sets provided by the National Health and Nutrition Examination Survey (NHANES)).\nThe TableShift API addresses each of these issues. It defines a set of primitives which allow for the\nconstruction of data pipelines which go from raw data sources to preprocessed data of any TableShift\nbenchmark task in a few lines of Python code3. The resulting data is documented \u2013 each feature in\nthe benchmark includes metadata which describes the feature and any encodings. The API natively\nsupports a set of common data transformations, including one-hot and label encoding for categorical\ndata; scaling and binning of numeric data; and handling of missing values. TableShift provides native\noutput in a variety of data formats, including PyTorch DataLoaders, Pandas DataFrames, and Ray\nDatasets. Finally, any dataset in the TableShift benchmark can be loaded with default preprocessing\nparameters with an identical call to the API, providing a unified interface.\nWe provide a a detailed comparison between TableShift and related existing benchmarks in Section G.\nHowever, we emphasize that there is no existing benchmark suite for distribution shift in tabular data,\nand existing distribution shift benchmarks are incompatible with the unique constraints of tabular\ndata discussed above.\n   3See https://tableshift.org and https://github.com/mlfoundations/tableshift\n                                                     5", "md": "Sufficient dimensionality and size: contains at least three features (in all cases, our benchmark datasets contain many more than three features) and at least 1000 observations. In particular, having large test sets is critical for making reliable statistical comparisons between models.\n\nHeterogeneous: contains features of mixed types.\n\nBinary Classification: supports a meaningful binary classification task (regression tasks are not included).\n\nShift Gap: We explicitly select datasets where strong hyperparameter-tuned tabular baselines display a statistically significant shift gap (\u2206Acc \u2260 0, see Eqn. (1)).\n\nIn addition to these criteria, we selected benchmark tasks and data sources that were diverse. TABLESHIFT includes tasks from many domains (finance, policy, civic participation, medical diagnosis) and from a variety of raw data sources (electronic health records, surveys/questionnaires, etc.) and with a diversity of shift gap (\u2206Acc) magnitudes.\n\nA summary of the benchmark tasks is shown in Table 1. We give a detailed overview of each task, including background and motivation, information on the data source, and distribution shifts, in Section B. Datasets and each individual feature of each task are also documented in the Python package. One important aspect of TableShift\u2019s diversity, shown in Table 1, is that not all real-world tasks support domain generalization (i.e. not all tasks have multiple training subdomains, |Dtrain| \u2265 2).\n\nTo reflect this, we include both types of tasks in the TableShift benchmark.\n\nWhile the intended use of TableShift is for distribution shift, the package is also likely to be of high utility to all researchers studying tabular data modeling due to the data quality, detailed documentation, flexible preprocessing, and ease of use of the datasets in TableShift.\n\n### TableShift API\n\nSuccessful existing benchmarks for distribution/domain shift in machine learning (e.g. WILDS, DomainBed) not only include high-quality datasets, but also make the data accessible by providing a high-quality API as an interface to the otherwise-disparate sources. This section describes the TableShift API. Providing this API for tabular data is particularly important, for several reasons.\n\nFirst, the input and output of tabular data pipelines differ from other modalities: tabular datasets are stored in different formats from image and text datasets, and are used with a greater variety of machine learning tools (e.g. scikit-learn). Second, the preprocessing operations used in tabular data differ significantly from other data modalities. These preprocessing operations also require unique feature-level metadata such as data types (i.e. categorical vs. numeric; numeric values for categorical features are a common encoding scheme in practice) and codings for categorical variables.\n\nFinally, raw sources used to build tabular datasets can be difficult to access. Datasets are often scattered across hundreds or even thousands of files (e.g., the Sepsis task dataset is constructed from over 40k data files; the Childhood Lead dataset is joined from nearly 100 files containing disjoint feature sets provided by the National Health and Nutrition Examination Survey (NHANES)).\n\nThe TableShift API addresses each of these issues. It defines a set of primitives which allow for the construction of data pipelines which go from raw data sources to preprocessed data of any TableShift benchmark task in a few lines of Python code. The resulting data is documented \u2013 each feature in the benchmark includes metadata which describes the feature and any encodings. The API natively supports a set of common data transformations, including one-hot and label encoding for categorical data; scaling and binning of numeric data; and handling of missing values. TableShift provides native output in a variety of data formats, including PyTorch DataLoaders, Pandas DataFrames, and Ray Datasets. Finally, any dataset in the TableShift benchmark can be loaded with default preprocessing parameters with an identical call to the API, providing a unified interface.\n\nWe provide a detailed comparison between TableShift and related existing benchmarks in Section G. However, we emphasize that there is no existing benchmark suite for distribution shift in tabular data, and existing distribution shift benchmarks are incompatible with the unique constraints of tabular data discussed above.\n\nSee https://tableshift.org and https://github.com/mlfoundations/tableshift", "images": [], "items": [{"type": "text", "value": "Sufficient dimensionality and size: contains at least three features (in all cases, our benchmark datasets contain many more than three features) and at least 1000 observations. In particular, having large test sets is critical for making reliable statistical comparisons between models.\n\nHeterogeneous: contains features of mixed types.\n\nBinary Classification: supports a meaningful binary classification task (regression tasks are not included).\n\nShift Gap: We explicitly select datasets where strong hyperparameter-tuned tabular baselines display a statistically significant shift gap (\u2206Acc \u2260 0, see Eqn. (1)).\n\nIn addition to these criteria, we selected benchmark tasks and data sources that were diverse. TABLESHIFT includes tasks from many domains (finance, policy, civic participation, medical diagnosis) and from a variety of raw data sources (electronic health records, surveys/questionnaires, etc.) and with a diversity of shift gap (\u2206Acc) magnitudes.\n\nA summary of the benchmark tasks is shown in Table 1. We give a detailed overview of each task, including background and motivation, information on the data source, and distribution shifts, in Section B. Datasets and each individual feature of each task are also documented in the Python package. One important aspect of TableShift\u2019s diversity, shown in Table 1, is that not all real-world tasks support domain generalization (i.e. not all tasks have multiple training subdomains, |Dtrain| \u2265 2).\n\nTo reflect this, we include both types of tasks in the TableShift benchmark.\n\nWhile the intended use of TableShift is for distribution shift, the package is also likely to be of high utility to all researchers studying tabular data modeling due to the data quality, detailed documentation, flexible preprocessing, and ease of use of the datasets in TableShift.", "md": "Sufficient dimensionality and size: contains at least three features (in all cases, our benchmark datasets contain many more than three features) and at least 1000 observations. In particular, having large test sets is critical for making reliable statistical comparisons between models.\n\nHeterogeneous: contains features of mixed types.\n\nBinary Classification: supports a meaningful binary classification task (regression tasks are not included).\n\nShift Gap: We explicitly select datasets where strong hyperparameter-tuned tabular baselines display a statistically significant shift gap (\u2206Acc \u2260 0, see Eqn. (1)).\n\nIn addition to these criteria, we selected benchmark tasks and data sources that were diverse. TABLESHIFT includes tasks from many domains (finance, policy, civic participation, medical diagnosis) and from a variety of raw data sources (electronic health records, surveys/questionnaires, etc.) and with a diversity of shift gap (\u2206Acc) magnitudes.\n\nA summary of the benchmark tasks is shown in Table 1. We give a detailed overview of each task, including background and motivation, information on the data source, and distribution shifts, in Section B. Datasets and each individual feature of each task are also documented in the Python package. One important aspect of TableShift\u2019s diversity, shown in Table 1, is that not all real-world tasks support domain generalization (i.e. not all tasks have multiple training subdomains, |Dtrain| \u2265 2).\n\nTo reflect this, we include both types of tasks in the TableShift benchmark.\n\nWhile the intended use of TableShift is for distribution shift, the package is also likely to be of high utility to all researchers studying tabular data modeling due to the data quality, detailed documentation, flexible preprocessing, and ease of use of the datasets in TableShift."}, {"type": "heading", "lvl": 3, "value": "TableShift API", "md": "### TableShift API"}, {"type": "text", "value": "Successful existing benchmarks for distribution/domain shift in machine learning (e.g. WILDS, DomainBed) not only include high-quality datasets, but also make the data accessible by providing a high-quality API as an interface to the otherwise-disparate sources. This section describes the TableShift API. Providing this API for tabular data is particularly important, for several reasons.\n\nFirst, the input and output of tabular data pipelines differ from other modalities: tabular datasets are stored in different formats from image and text datasets, and are used with a greater variety of machine learning tools (e.g. scikit-learn). Second, the preprocessing operations used in tabular data differ significantly from other data modalities. These preprocessing operations also require unique feature-level metadata such as data types (i.e. categorical vs. numeric; numeric values for categorical features are a common encoding scheme in practice) and codings for categorical variables.\n\nFinally, raw sources used to build tabular datasets can be difficult to access. Datasets are often scattered across hundreds or even thousands of files (e.g., the Sepsis task dataset is constructed from over 40k data files; the Childhood Lead dataset is joined from nearly 100 files containing disjoint feature sets provided by the National Health and Nutrition Examination Survey (NHANES)).\n\nThe TableShift API addresses each of these issues. It defines a set of primitives which allow for the construction of data pipelines which go from raw data sources to preprocessed data of any TableShift benchmark task in a few lines of Python code. The resulting data is documented \u2013 each feature in the benchmark includes metadata which describes the feature and any encodings. The API natively supports a set of common data transformations, including one-hot and label encoding for categorical data; scaling and binning of numeric data; and handling of missing values. TableShift provides native output in a variety of data formats, including PyTorch DataLoaders, Pandas DataFrames, and Ray Datasets. Finally, any dataset in the TableShift benchmark can be loaded with default preprocessing parameters with an identical call to the API, providing a unified interface.\n\nWe provide a detailed comparison between TableShift and related existing benchmarks in Section G. However, we emphasize that there is no existing benchmark suite for distribution shift in tabular data, and existing distribution shift benchmarks are incompatible with the unique constraints of tabular data discussed above.\n\nSee https://tableshift.org and https://github.com/mlfoundations/tableshift", "md": "Successful existing benchmarks for distribution/domain shift in machine learning (e.g. WILDS, DomainBed) not only include high-quality datasets, but also make the data accessible by providing a high-quality API as an interface to the otherwise-disparate sources. This section describes the TableShift API. Providing this API for tabular data is particularly important, for several reasons.\n\nFirst, the input and output of tabular data pipelines differ from other modalities: tabular datasets are stored in different formats from image and text datasets, and are used with a greater variety of machine learning tools (e.g. scikit-learn). Second, the preprocessing operations used in tabular data differ significantly from other data modalities. These preprocessing operations also require unique feature-level metadata such as data types (i.e. categorical vs. numeric; numeric values for categorical features are a common encoding scheme in practice) and codings for categorical variables.\n\nFinally, raw sources used to build tabular datasets can be difficult to access. Datasets are often scattered across hundreds or even thousands of files (e.g., the Sepsis task dataset is constructed from over 40k data files; the Childhood Lead dataset is joined from nearly 100 files containing disjoint feature sets provided by the National Health and Nutrition Examination Survey (NHANES)).\n\nThe TableShift API addresses each of these issues. It defines a set of primitives which allow for the construction of data pipelines which go from raw data sources to preprocessed data of any TableShift benchmark task in a few lines of Python code. The resulting data is documented \u2013 each feature in the benchmark includes metadata which describes the feature and any encodings. The API natively supports a set of common data transformations, including one-hot and label encoding for categorical data; scaling and binning of numeric data; and handling of missing values. TableShift provides native output in a variety of data formats, including PyTorch DataLoaders, Pandas DataFrames, and Ray Datasets. Finally, any dataset in the TableShift benchmark can be loaded with default preprocessing parameters with an identical call to the API, providing a unified interface.\n\nWe provide a detailed comparison between TableShift and related existing benchmarks in Section G. However, we emphasize that there is no existing benchmark suite for distribution shift in tabular data, and existing distribution shift benchmarks are incompatible with the unique constraints of tabular data discussed above.\n\nSee https://tableshift.org and https://github.com/mlfoundations/tableshift"}]}, {"page": 6, "text": " 4    Experiment Setup\n We conduct a set of experiments to demonstrate the potential insights to be gained from using\n TableShift. As previously mentioned, there has been considerable debate about whether tree-based\n models (XGBoost, LightGBM, etc.) or specialized deep learning-based models (i.e. ResNet- and\n Transformer-based architectures) are more effective for tabular data modeling. However, previous\n investigations have not explored how these models perform under distribution shift in tabular data.\n Additionally, many methods have been proposed for robust learning and domain generalization but\n also not rigorously evaluated on tabular data. We present a series of experiments to evaluate 19\n distinct methods using the TABLESHIFT benchmark.\n 4.1   Tabular Data Classification Techniques in our Comparison\n We train and evaluate a set of tabular data classifiers from several families. For each, we give additional\n details and description in Section F, and the full hyperparameter grids in Table 19. Implementations\n of these classifiers, including the hyperparameter tuning framework used to tune them, are available\n in the TABLESHIFT API. The classifiers compared in our experiments are:\n Baseline Models: These models do not include any intervention for robustness to domain shift, but\n are generally effective for tabular data in the IID setting. We evaluate multilayer perceptrons (MLP),\n XGBoost [20], LightGBM [48], and CatBoost [25] as baseline methods. While we refer to these as\n\u201cbaselines\u201d for convenience, we note that the methods based on gradient-boosted trees (XGBoost,\n LightGBM, CatBoost) are still considered state-of-the-art on many tasks [37].\n Tabular Neural Networks: We also include a set of state-of-the-art methods for modeling tabular\n data. The models we use are SAINT [79], TabTransformer [43], NODE [70], FT-Transformer, and\n tabular ResNet (the latter two via [36]).\n Domain Robustness Models: These models attempt to ensure good performance on distributions\n close to the training data. These models attempt to optimize an objective over a worst-case distribution\n with bounded distance from the training data. We evaluate distributionally robust optimization (DRO)\n with both \u03c72 and CVaR geometry [53], and group DRO (where the groups are domains) [76]. Both\n the DRO and group DRO models are parameterized over MLPs, as in both original works.\n Label Shift Robustness Models: These models attempt to ensure good performance when the label\n distribution P(y) changes. We evaluate Group DRO (where the groups are class labels) and the\n adversarial label robustness method of [92].\n Domain Generalization Models: These are models designed with the goal of achieving low error\n rates on unseen test domains. In practice, this is achieved by achieving low error disparity across\n the subdomains in Dtrain. These methods require domain labels at training time, and training data\n drawn from multiple different domains (|Dtrain| \u2265     2). Domain generalization models in our study are:\n Domain-Adversarial Neural Networks (DANN) [1], Invariant Risk Minimization (IRM) [6], Domain\n MixUp [90, 89], Risk Extrapolation (VReX) [52], DeepCORAL [82] and MMD [54].\n We note that our goal of the current study is not to propose novel methods for distributionally robust\n learning; it is to conduct a comprehensive comparison of a large set of existing methods, many of\n which have not been previously compared to each other, on a high-quality benchmark. For example,\n while domain generalization models have been applied to image and text classification tasks (e.g.\n [50, 38]), to our knowledge these methods have not been previously investigated for mitigating\n distribution shift in tabular data in a large-scale benchmarking study. Indeed, we are aware of no\n prior applications of many of these domain generalization methods to tabular data. As a result, it is\n not clear a priori how these methods might compare to existing robustness or baseline methods due\n to the aforementioned differences between tabular data and these other data modalities.\n The experiments described above cover both model architectures (different functional forms for the\n predictor f\u03b8) and loss functions (different objective functions L used to train the model by attempting\n to find min\u03b8 L(f\u03b8(Dtrain))). In order to train a classifier with gradient-based training, both are required.\n Except where noted otherwise, any method requiring gradient-based training (MLP, Tabular Neural\n Networks, Domain Generalization Models) is trained with standard empirical risk minimization and\n cross-entropy loss. Similarly, any method which itself is a loss function (i.e. all variants of DRO) is\n                                                      6", "md": "# Experiment Setup\n\n## Experiment Setup\n\nWe conduct a set of experiments to demonstrate the potential insights to be gained from using TableShift. As previously mentioned, there has been considerable debate about whether tree-based models (XGBoost, LightGBM, etc.) or specialized deep learning-based models (i.e. ResNet- and Transformer-based architectures) are more effective for tabular data modeling. However, previous investigations have not explored how these models perform under distribution shift in tabular data. Additionally, many methods have been proposed for robust learning and domain generalization but also not rigorously evaluated on tabular data. We present a series of experiments to evaluate 19 distinct methods using the TABLESHIFT benchmark.\n\n### Tabular Data Classification Techniques in our Comparison\n\nWe train and evaluate a set of tabular data classifiers from several families. For each, we give additional details and description in Section F, and the full hyperparameter grids in Table 19. Implementations of these classifiers, including the hyperparameter tuning framework used to tune them, are available in the TABLESHIFT API. The classifiers compared in our experiments are:\n\n- Baseline Models: These models do not include any intervention for robustness to domain shift, but are generally effective for tabular data in the IID setting. We evaluate multilayer perceptrons (MLP), XGBoost, LightGBM, and CatBoost as baseline methods. While we refer to these as \"baselines\" for convenience, we note that the methods based on gradient-boosted trees (XGBoost, LightGBM, CatBoost) are still considered state-of-the-art on many tasks.\n- Tabular Neural Networks: We also include a set of state-of-the-art methods for modeling tabular data. The models we use are SAINT, TabTransformer, NODE, FT-Transformer, and tabular ResNet.\n- Domain Robustness Models: These models attempt to ensure good performance on distributions close to the training data. We evaluate distributionally robust optimization (DRO) with both \u03c72 and CVaR geometry, and group DRO (where the groups are domains).\n- Label Shift Robustness Models: These models attempt to ensure good performance when the label distribution P(y) changes. We evaluate Group DRO (where the groups are class labels) and the adversarial label robustness method.\n- Domain Generalization Models: These are models designed with the goal of achieving low error rates on unseen test domains. The domain generalization models in our study are: Domain-Adversarial Neural Networks (DANN), Invariant Risk Minimization (IRM), Domain MixUp, Risk Extrapolation (VReX), DeepCORAL, and MMD.\n\nWe note that our goal of the current study is not to propose novel methods for distributionally robust learning; it is to conduct a comprehensive comparison of a large set of existing methods, many of which have not been previously compared to each other, on a high-quality benchmark. For example, while domain generalization models have been applied to image and text classification tasks, to our knowledge these methods have not been previously investigated for mitigating distribution shift in tabular data in a large-scale benchmarking study. Indeed, we are aware of no prior applications of many of these domain generalization methods to tabular data. As a result, it is not clear a priori how these methods might compare to existing robustness or baseline methods due to the aforementioned differences between tabular data and these other data modalities.\n\nThe experiments described above cover both model architectures (different functional forms for the predictor f\u03b8) and loss functions (different objective functions L used to train the model by attempting to find min\u03b8 L(f\u03b8(Dtrain))). In order to train a classifier with gradient-based training, both are required. Except where noted otherwise, any method requiring gradient-based training (MLP, Tabular Neural Networks, Domain Generalization Models) is trained with standard empirical risk minimization and cross-entropy loss. Similarly, any method which itself is a loss function (i.e. all variants of DRO) is trained with standard empirical risk minimization and cross-entropy loss.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Experiment Setup", "md": "# Experiment Setup"}, {"type": "heading", "lvl": 2, "value": "Experiment Setup", "md": "## Experiment Setup"}, {"type": "text", "value": "We conduct a set of experiments to demonstrate the potential insights to be gained from using TableShift. As previously mentioned, there has been considerable debate about whether tree-based models (XGBoost, LightGBM, etc.) or specialized deep learning-based models (i.e. ResNet- and Transformer-based architectures) are more effective for tabular data modeling. However, previous investigations have not explored how these models perform under distribution shift in tabular data. Additionally, many methods have been proposed for robust learning and domain generalization but also not rigorously evaluated on tabular data. We present a series of experiments to evaluate 19 distinct methods using the TABLESHIFT benchmark.", "md": "We conduct a set of experiments to demonstrate the potential insights to be gained from using TableShift. As previously mentioned, there has been considerable debate about whether tree-based models (XGBoost, LightGBM, etc.) or specialized deep learning-based models (i.e. ResNet- and Transformer-based architectures) are more effective for tabular data modeling. However, previous investigations have not explored how these models perform under distribution shift in tabular data. Additionally, many methods have been proposed for robust learning and domain generalization but also not rigorously evaluated on tabular data. We present a series of experiments to evaluate 19 distinct methods using the TABLESHIFT benchmark."}, {"type": "heading", "lvl": 3, "value": "Tabular Data Classification Techniques in our Comparison", "md": "### Tabular Data Classification Techniques in our Comparison"}, {"type": "text", "value": "We train and evaluate a set of tabular data classifiers from several families. For each, we give additional details and description in Section F, and the full hyperparameter grids in Table 19. Implementations of these classifiers, including the hyperparameter tuning framework used to tune them, are available in the TABLESHIFT API. The classifiers compared in our experiments are:\n\n- Baseline Models: These models do not include any intervention for robustness to domain shift, but are generally effective for tabular data in the IID setting. We evaluate multilayer perceptrons (MLP), XGBoost, LightGBM, and CatBoost as baseline methods. While we refer to these as \"baselines\" for convenience, we note that the methods based on gradient-boosted trees (XGBoost, LightGBM, CatBoost) are still considered state-of-the-art on many tasks.\n- Tabular Neural Networks: We also include a set of state-of-the-art methods for modeling tabular data. The models we use are SAINT, TabTransformer, NODE, FT-Transformer, and tabular ResNet.\n- Domain Robustness Models: These models attempt to ensure good performance on distributions close to the training data. We evaluate distributionally robust optimization (DRO) with both \u03c72 and CVaR geometry, and group DRO (where the groups are domains).\n- Label Shift Robustness Models: These models attempt to ensure good performance when the label distribution P(y) changes. We evaluate Group DRO (where the groups are class labels) and the adversarial label robustness method.\n- Domain Generalization Models: These are models designed with the goal of achieving low error rates on unseen test domains. The domain generalization models in our study are: Domain-Adversarial Neural Networks (DANN), Invariant Risk Minimization (IRM), Domain MixUp, Risk Extrapolation (VReX), DeepCORAL, and MMD.\n\nWe note that our goal of the current study is not to propose novel methods for distributionally robust learning; it is to conduct a comprehensive comparison of a large set of existing methods, many of which have not been previously compared to each other, on a high-quality benchmark. For example, while domain generalization models have been applied to image and text classification tasks, to our knowledge these methods have not been previously investigated for mitigating distribution shift in tabular data in a large-scale benchmarking study. Indeed, we are aware of no prior applications of many of these domain generalization methods to tabular data. As a result, it is not clear a priori how these methods might compare to existing robustness or baseline methods due to the aforementioned differences between tabular data and these other data modalities.\n\nThe experiments described above cover both model architectures (different functional forms for the predictor f\u03b8) and loss functions (different objective functions L used to train the model by attempting to find min\u03b8 L(f\u03b8(Dtrain))). In order to train a classifier with gradient-based training, both are required. Except where noted otherwise, any method requiring gradient-based training (MLP, Tabular Neural Networks, Domain Generalization Models) is trained with standard empirical risk minimization and cross-entropy loss. Similarly, any method which itself is a loss function (i.e. all variants of DRO) is trained with standard empirical risk minimization and cross-entropy loss.", "md": "We train and evaluate a set of tabular data classifiers from several families. For each, we give additional details and description in Section F, and the full hyperparameter grids in Table 19. Implementations of these classifiers, including the hyperparameter tuning framework used to tune them, are available in the TABLESHIFT API. The classifiers compared in our experiments are:\n\n- Baseline Models: These models do not include any intervention for robustness to domain shift, but are generally effective for tabular data in the IID setting. We evaluate multilayer perceptrons (MLP), XGBoost, LightGBM, and CatBoost as baseline methods. While we refer to these as \"baselines\" for convenience, we note that the methods based on gradient-boosted trees (XGBoost, LightGBM, CatBoost) are still considered state-of-the-art on many tasks.\n- Tabular Neural Networks: We also include a set of state-of-the-art methods for modeling tabular data. The models we use are SAINT, TabTransformer, NODE, FT-Transformer, and tabular ResNet.\n- Domain Robustness Models: These models attempt to ensure good performance on distributions close to the training data. We evaluate distributionally robust optimization (DRO) with both \u03c72 and CVaR geometry, and group DRO (where the groups are domains).\n- Label Shift Robustness Models: These models attempt to ensure good performance when the label distribution P(y) changes. We evaluate Group DRO (where the groups are class labels) and the adversarial label robustness method.\n- Domain Generalization Models: These are models designed with the goal of achieving low error rates on unseen test domains. The domain generalization models in our study are: Domain-Adversarial Neural Networks (DANN), Invariant Risk Minimization (IRM), Domain MixUp, Risk Extrapolation (VReX), DeepCORAL, and MMD.\n\nWe note that our goal of the current study is not to propose novel methods for distributionally robust learning; it is to conduct a comprehensive comparison of a large set of existing methods, many of which have not been previously compared to each other, on a high-quality benchmark. For example, while domain generalization models have been applied to image and text classification tasks, to our knowledge these methods have not been previously investigated for mitigating distribution shift in tabular data in a large-scale benchmarking study. Indeed, we are aware of no prior applications of many of these domain generalization methods to tabular data. As a result, it is not clear a priori how these methods might compare to existing robustness or baseline methods due to the aforementioned differences between tabular data and these other data modalities.\n\nThe experiments described above cover both model architectures (different functional forms for the predictor f\u03b8) and loss functions (different objective functions L used to train the model by attempting to find min\u03b8 L(f\u03b8(Dtrain))). In order to train a classifier with gradient-based training, both are required. Except where noted otherwise, any method requiring gradient-based training (MLP, Tabular Neural Networks, Domain Generalization Models) is trained with standard empirical risk minimization and cross-entropy loss. Similarly, any method which itself is a loss function (i.e. all variants of DRO) is trained with standard empirical risk minimization and cross-entropy loss."}]}, {"page": 7, "text": "trained with f parameterized as an MLP, as is standard in prior works implementing and comparing\nthese methods (e.g. [53, 76, 33]).\n4.2   Methods\nFor each task, we conduct the following procedure.\nFirst, we split the full dataset into Dtrain and Dtest. We summarize the domain splits in Tables 1,1\nand describe the splitting for each task in detail, along with background and motivation for each task\ndomain split, in Section B. Within each domain, we have both a validation and a test set. We use the\nsame domain splits, data preprocessing, and train/validation/test splits for all models and training\nruns, except where explicitly noted.\nSecond, we then conduct a hyperparameter sweep for each model described in Section 4.1. We\nuse HyperOpt [13] to sample from the model hyperparameter space, in accordance with previous\nworks (e.g. [36, 46]) which largely use adaptive hyperparameter optimization due to the variability in\neffective hyperparameter settings between datasets. We only train on the training set, and use the\nin-domain validation accuracy for hyperparameter tuning. We give the complete grid for each model\nin \u00a7I. Each model is tuned for 100 trials.\nFinally, we evaluate the trained models on the test splits of each dataset. As recommended in [50], we\nuse in-domain and out-of-domain test accuracy (not in-domain train accuracy) to evaluate the models.\nFor all results shown, we use the best model selected according to (in-domain) validation accuracy;\nthis follows the selection procedure used to study domain generalization in the image domain in [38].\n5    Empirical Results\nID and OOD Accuracy are Correlated. Our results show that, across all models and tasks, in-\ndistribution (ID) and out-of-distribution (OOD) accuracy are correlated: as ID performance improves,\nOOD performance also tends to improve (see Figure 1; \u03c1 = 0.81). This linear trend holds across\ndatasets and model classes. We note that, while this is consistent with findings for image [62] and\nquestion answering [61] models, the relationship between ID accuracy and OOD accuracy on tabular\ndata was previously unknown. This result suggests that, for a wide variety of tabular data tasks,\nimproving models\u2019 ID performance is likely to improve their OOD performance.\nNo Model Consistently Outperforms Baselines. While many models have been proposed for both\n(a) improving general performance on tabular data tasks over established baselines such as XGBoost\nand LightGBM, and (b) improving robustness to distribution shift, our results show that no model\nconsistently outperforms the standard tabular baselines of XGBoost, LightGBM, or CatBoost in either\nrespect. Figure 4a shows that, on average across all datasets, no model consistently achieves better\nperformance (as measured as a fraction of the maximum OOD accuracy achieved by any model)\ncompared to baseline methods. This finding has not been previously demonstrated in tabular data due\nto the lack of an existing benchmark.\nNo Method Eliminates Gaps. We investigate the empirical performance of several methods designed\nto improve robustness to distribution shift (described in Section 4.1). Our results shows that, on the\ndatasets where multiple training subdomains are available (and thus where domain generalization is\nviable), there is weak evidence that several techniques reduce gaps due to distribution shift, but no\ntechnique eliminates these gaps. However, it is important to note that this gap reduction comes at\nthe cost of in-distribution performance: as Figure 4b shows, all robustness-enhancing models tend\nto shrink gaps by reducing average ID performance, not by improving OOD performance. This is\nshown in Figure 4b by the two parallel lines: one set of blue points representing baselines + tabular\nNNs, and another, shifted left, representing robustness-engancing and domain generalization models.\nFurthermore, we note that all domain generalization and domain robustness methods evaluated\n(excluding DRO) require additional information that is only present for some datasets \u2013 namely, the\ndiscrete variable over which a shift will occur (e.g. \u201crace\u201d for diabetes task) and data from at least 2\ncategories of this variable.\nChange in label distribution is correlated with shift gap. We investigate the degree to which\nthe three factors mentioned previously (p(x), p(y|x), p(y)) are related to model performance. Our\nresults, in Figures 5 and 8, show that change in the label distribution \u2206y is correlated with shift gap\n                                                     7", "md": "Trained with \\( f \\) parameterized as an MLP, as is standard in prior works implementing and comparing these methods (e.g. [53, 76, 33]).\n\n#### Methods\n\nFor each task, we conduct the following procedure.\n\nFirst, we split the full dataset into \\( D_{\\text{train}} \\) and \\( D_{\\text{test}} \\). We summarize the domain splits in Tables 1,1 and describe the splitting for each task in detail, along with background and motivation for each task domain split, in Section B. Within each domain, we have both a validation and a test set. We use the same domain splits, data preprocessing, and train/validation/test splits for all models and training runs, except where explicitly noted.\n\nSecond, we then conduct a hyperparameter sweep for each model described in Section 4.1. We use HyperOpt [13] to sample from the model hyperparameter space, in accordance with previous works (e.g. [36, 46]) which largely use adaptive hyperparameter optimization due to the variability in effective hyperparameter settings between datasets. We only train on the training set, and use the in-domain validation accuracy for hyperparameter tuning. We give the complete grid for each model in \u00a7I. Each model is tuned for 100 trials.\n\nFinally, we evaluate the trained models on the test splits of each dataset. As recommended in [50], we use in-domain and out-of-domain test accuracy (not in-domain train accuracy) to evaluate the models. For all results shown, we use the best model selected according to (in-domain) validation accuracy; this follows the selection procedure used to study domain generalization in the image domain in [38].\n\n#### Empirical Results\n\nID and OOD Accuracy are Correlated. Our results show that, across all models and tasks, in-distribution (ID) and out-of-distribution (OOD) accuracy are correlated: as ID performance improves, OOD performance also tends to improve (see Figure 1; \\( \\rho = 0.81 \\)). This linear trend holds across datasets and model classes. We note that, while this is consistent with findings for image [62] and question answering [61] models, the relationship between ID accuracy and OOD accuracy on tabular data was previously unknown. This result suggests that, for a wide variety of tabular data tasks, improving models' ID performance is likely to improve their OOD performance.\n\nNo Model Consistently Outperforms Baselines. While many models have been proposed for both (a) improving general performance on tabular data tasks over established baselines such as XGBoost and LightGBM, and (b) improving robustness to distribution shift, our results show that no model consistently outperforms the standard tabular baselines of XGBoost, LightGBM, or CatBoost in either respect. Figure 4a shows that, on average across all datasets, no model consistently achieves better performance (as measured as a fraction of the maximum OOD accuracy achieved by any model) compared to baseline methods. This finding has not been previously demonstrated in tabular data due to the lack of an existing benchmark.\n\nNo Method Eliminates Gaps. We investigate the empirical performance of several methods designed to improve robustness to distribution shift (described in Section 4.1). Our results show that, on the datasets where multiple training subdomains are available (and thus where domain generalization is viable), there is weak evidence that several techniques reduce gaps due to distribution shift, but no technique eliminates these gaps. However, it is important to note that this gap reduction comes at the cost of in-distribution performance: as Figure 4b shows, all robustness-enhancing models tend to shrink gaps by reducing average ID performance, not by improving OOD performance. This is shown in Figure 4b by the two parallel lines: one set of blue points representing baselines + tabular NNs, and another, shifted left, representing robustness-enhancing and domain generalization models. Furthermore, we note that all domain generalization and domain robustness methods evaluated (excluding DRO) require additional information that is only present for some datasets \u2013 namely, the discrete variable over which a shift will occur (e.g. \"race\" for diabetes task) and data from at least 2 categories of this variable.\n\nChange in label distribution is correlated with shift gap. We investigate the degree to which the three factors mentioned previously (\\( p(x) \\), \\( p(y|x) \\), \\( p(y) \\)) are related to model performance. Our results, in Figures 5 and 8, show that change in the label distribution \\( \\Delta y \\) is correlated with shift gap.", "images": [], "items": [{"type": "text", "value": "Trained with \\( f \\) parameterized as an MLP, as is standard in prior works implementing and comparing these methods (e.g. [53, 76, 33]).", "md": "Trained with \\( f \\) parameterized as an MLP, as is standard in prior works implementing and comparing these methods (e.g. [53, 76, 33])."}, {"type": "heading", "lvl": 4, "value": "Methods", "md": "#### Methods"}, {"type": "text", "value": "For each task, we conduct the following procedure.\n\nFirst, we split the full dataset into \\( D_{\\text{train}} \\) and \\( D_{\\text{test}} \\). We summarize the domain splits in Tables 1,1 and describe the splitting for each task in detail, along with background and motivation for each task domain split, in Section B. Within each domain, we have both a validation and a test set. We use the same domain splits, data preprocessing, and train/validation/test splits for all models and training runs, except where explicitly noted.\n\nSecond, we then conduct a hyperparameter sweep for each model described in Section 4.1. We use HyperOpt [13] to sample from the model hyperparameter space, in accordance with previous works (e.g. [36, 46]) which largely use adaptive hyperparameter optimization due to the variability in effective hyperparameter settings between datasets. We only train on the training set, and use the in-domain validation accuracy for hyperparameter tuning. We give the complete grid for each model in \u00a7I. Each model is tuned for 100 trials.\n\nFinally, we evaluate the trained models on the test splits of each dataset. As recommended in [50], we use in-domain and out-of-domain test accuracy (not in-domain train accuracy) to evaluate the models. For all results shown, we use the best model selected according to (in-domain) validation accuracy; this follows the selection procedure used to study domain generalization in the image domain in [38].", "md": "For each task, we conduct the following procedure.\n\nFirst, we split the full dataset into \\( D_{\\text{train}} \\) and \\( D_{\\text{test}} \\). We summarize the domain splits in Tables 1,1 and describe the splitting for each task in detail, along with background and motivation for each task domain split, in Section B. Within each domain, we have both a validation and a test set. We use the same domain splits, data preprocessing, and train/validation/test splits for all models and training runs, except where explicitly noted.\n\nSecond, we then conduct a hyperparameter sweep for each model described in Section 4.1. We use HyperOpt [13] to sample from the model hyperparameter space, in accordance with previous works (e.g. [36, 46]) which largely use adaptive hyperparameter optimization due to the variability in effective hyperparameter settings between datasets. We only train on the training set, and use the in-domain validation accuracy for hyperparameter tuning. We give the complete grid for each model in \u00a7I. Each model is tuned for 100 trials.\n\nFinally, we evaluate the trained models on the test splits of each dataset. As recommended in [50], we use in-domain and out-of-domain test accuracy (not in-domain train accuracy) to evaluate the models. For all results shown, we use the best model selected according to (in-domain) validation accuracy; this follows the selection procedure used to study domain generalization in the image domain in [38]."}, {"type": "heading", "lvl": 4, "value": "Empirical Results", "md": "#### Empirical Results"}, {"type": "text", "value": "ID and OOD Accuracy are Correlated. Our results show that, across all models and tasks, in-distribution (ID) and out-of-distribution (OOD) accuracy are correlated: as ID performance improves, OOD performance also tends to improve (see Figure 1; \\( \\rho = 0.81 \\)). This linear trend holds across datasets and model classes. We note that, while this is consistent with findings for image [62] and question answering [61] models, the relationship between ID accuracy and OOD accuracy on tabular data was previously unknown. This result suggests that, for a wide variety of tabular data tasks, improving models' ID performance is likely to improve their OOD performance.\n\nNo Model Consistently Outperforms Baselines. While many models have been proposed for both (a) improving general performance on tabular data tasks over established baselines such as XGBoost and LightGBM, and (b) improving robustness to distribution shift, our results show that no model consistently outperforms the standard tabular baselines of XGBoost, LightGBM, or CatBoost in either respect. Figure 4a shows that, on average across all datasets, no model consistently achieves better performance (as measured as a fraction of the maximum OOD accuracy achieved by any model) compared to baseline methods. This finding has not been previously demonstrated in tabular data due to the lack of an existing benchmark.\n\nNo Method Eliminates Gaps. We investigate the empirical performance of several methods designed to improve robustness to distribution shift (described in Section 4.1). Our results show that, on the datasets where multiple training subdomains are available (and thus where domain generalization is viable), there is weak evidence that several techniques reduce gaps due to distribution shift, but no technique eliminates these gaps. However, it is important to note that this gap reduction comes at the cost of in-distribution performance: as Figure 4b shows, all robustness-enhancing models tend to shrink gaps by reducing average ID performance, not by improving OOD performance. This is shown in Figure 4b by the two parallel lines: one set of blue points representing baselines + tabular NNs, and another, shifted left, representing robustness-enhancing and domain generalization models. Furthermore, we note that all domain generalization and domain robustness methods evaluated (excluding DRO) require additional information that is only present for some datasets \u2013 namely, the discrete variable over which a shift will occur (e.g. \"race\" for diabetes task) and data from at least 2 categories of this variable.\n\nChange in label distribution is correlated with shift gap. We investigate the degree to which the three factors mentioned previously (\\( p(x) \\), \\( p(y|x) \\), \\( p(y) \\)) are related to model performance. Our results, in Figures 5 and 8, show that change in the label distribution \\( \\Delta y \\) is correlated with shift gap.", "md": "ID and OOD Accuracy are Correlated. Our results show that, across all models and tasks, in-distribution (ID) and out-of-distribution (OOD) accuracy are correlated: as ID performance improves, OOD performance also tends to improve (see Figure 1; \\( \\rho = 0.81 \\)). This linear trend holds across datasets and model classes. We note that, while this is consistent with findings for image [62] and question answering [61] models, the relationship between ID accuracy and OOD accuracy on tabular data was previously unknown. This result suggests that, for a wide variety of tabular data tasks, improving models' ID performance is likely to improve their OOD performance.\n\nNo Model Consistently Outperforms Baselines. While many models have been proposed for both (a) improving general performance on tabular data tasks over established baselines such as XGBoost and LightGBM, and (b) improving robustness to distribution shift, our results show that no model consistently outperforms the standard tabular baselines of XGBoost, LightGBM, or CatBoost in either respect. Figure 4a shows that, on average across all datasets, no model consistently achieves better performance (as measured as a fraction of the maximum OOD accuracy achieved by any model) compared to baseline methods. This finding has not been previously demonstrated in tabular data due to the lack of an existing benchmark.\n\nNo Method Eliminates Gaps. We investigate the empirical performance of several methods designed to improve robustness to distribution shift (described in Section 4.1). Our results show that, on the datasets where multiple training subdomains are available (and thus where domain generalization is viable), there is weak evidence that several techniques reduce gaps due to distribution shift, but no technique eliminates these gaps. However, it is important to note that this gap reduction comes at the cost of in-distribution performance: as Figure 4b shows, all robustness-enhancing models tend to shrink gaps by reducing average ID performance, not by improving OOD performance. This is shown in Figure 4b by the two parallel lines: one set of blue points representing baselines + tabular NNs, and another, shifted left, representing robustness-enhancing and domain generalization models. Furthermore, we note that all domain generalization and domain robustness methods evaluated (excluding DRO) require additional information that is only present for some datasets \u2013 namely, the discrete variable over which a shift will occur (e.g. \"race\" for diabetes task) and data from at least 2 categories of this variable.\n\nChange in label distribution is correlated with shift gap. We investigate the degree to which the three factors mentioned previously (\\( p(x) \\), \\( p(y|x) \\), \\( p(y) \\)) are related to model performance. Our results, in Figures 5 and 8, show that change in the label distribution \\( \\Delta y \\) is correlated with shift gap."}]}, {"page": 8, "text": "         est Accuracy           ASSISTments                                                            est Accuracy      College Scorecard                                  est Accuracy       Hospital Mortality\n                             Model                                                                                           Model                                                                Model\n                            XGBoost                                                                                         XGBoost                                           0.96               XGBoost\n                            LightGBM                                                                     0.95               LightGBM                                                             LightGBM\n           0.9              MLP                                                                                             MLP                                                                  MLP\n                            FT-Transformer                                                                                  FT-Transformer                                                       FT-Transformer\n                            ResNet                                                                                          ResNet                                            0.94               ResNet\n                            SAINT                                                                        0.90               SAINT                                                                SAINT\n                            NODE                                                                                            NODE                                                                 NODE\n         Out-of-Distribution T                                                                         Out-of-Distribution T                                                Out-of-Distribution T\n           0.8              TabTransformer                                                                                  TabTransformer                                                       TabTransformer\n                            CatBoost                                                                                        CatBoost                                          0.92               CatBoost\n                            DRO                                                                                             DRO                                                                  DRO\n                            Group DRO                                                                    0.85               Group DRO                                                            Group DRO\n                            DANN                                                                                            DANN                                                                 DANN\n           0.7              IRM                                                                                             IRM                                               0.90               IRM\n                            MixUp                                                                                           MixUp                                                                MixUp\n                            VREX                                                                         0.80               VREX                                                                 VREX\n                            MMD                                                                                             MMD                                                                  MMD\n                            CORAL                                                                                           CORAL                                             0.88               CORAL\n                            Label Group DRO                                                                                 Label Group DRO                                                      Label Group DRO\n           0.6              Adv. Label DRO                                                                                  Adv. Label DRO                                                       Adv. Label DRO\n                            y=x                                                                          0.75               y=x                                               0.86               y=x\n                            0.6                           0.8                                                                         0.8                0.9                                                    0.90                0.95\n                      In-Distribution Test Accuracy                                                                   In-Distribution Test Accuracy                                        In-Distribution Test Accuracy\n        est Accuracy Hospital Readmission                                                             est Accuracy                    Diabetes                              est Accuracy     ICU Length of Stay\n                              Model                                                                     0.90                Model                                                                                                 Model\n                             XGBoost                                                                                       XGBoost                                                                                                XGBoost\n                             LightGBM                                                                                      LightGBM                                                                                               LightGBM\n          0.65               MLP                                                                                           MLP                                                0.70                                                MLP\n                             FT-Transformer                                                                                                                                                                                       FT-Transformer\n                             ResNet                                                                     0.88               FT-Transformer                                                                                         ResNet\n                             SAINT                                                                                         ResNet                                                                                                 SAINT\n                             NODE                                                                                          SAINT                                                                                                  NODE\n        Out-of-Distribution TTabTransformer                                                           Out-of-Distribution TNODE                                             Out-of-Distribution T                                 TabTransformer\n          0.60               CatBoost                                                                   0.86               TabTransformer                                     0.65                                                CatBoost\n                             DRO                                                                                           CatBoost                                                                                               DRO\n                             Group DRO                                                                                     DRO                                                                                                    Group DRO\n                             DANN                                                                                          Group DRO                                                                                              DANN\n                             IRM                                                                                           DANN                                                                                                   IRM\n                             MixUp                                                                      0.84               IRM                                                0.60                                                MixUp\n          0.55               VREX                                                                                          MixUp                                                                                                  VREX\n                             MMD                                                                                           VREX                                                                                                   MMD\n                             CORAL                                                                                         MMD                                                                                                    CORAL\n                             Label Group DRO                                                            0.82               CORAL                                                                                                  Label Group DRO\n                                                                                                                           Label Group DRO\n                             Adv. Label DRO                                                                                Adv. Label DRO                                     0.55                                                Adv. Label DRO\n          0.50               y=x                                                                                           y=x                                                                                                    y=x\n                         0.5                             0.6                                                                                  0.85                    0.90                                      0.6                   0.7\n                       In-Distribution Test Accuracy                                                                In-Distribution Test Accuracy                                          In-Distribution Test Accuracy\n        est Accuracy                         Voting                                                   est Accuracy                 Food Stamps                              est Accuracy           Unemployment\n                              Model                                                                                            Model                                                              Model\n                             XGBoost                                                                                          XGBoost                                                            XGBoost\n          0.90               LightGBM                                                                                         LightGBM                                                           LightGBM\n                             MLP                                                                        0.850                 MLP                                             0.95               MLP\n                             FT-Transformer                                                                                   FT-Transformer                                                     FT-Transformer\n                             ResNet                                                                                           ResNet                                                             ResNet\n                             SAINT                                                                                            SAINT                                                              SAINT\n          0.85               NODE                                                                       0.825                 NODE                                                               NODE\n        Out-of-Distribution TTabTransformer                                                           Out-of-Distribution T                                                 Out-of-Distribution TTabTransformer\n                             CatBoost                                                                                         TabTransformer                                  0.90               CatBoost\n                                                                                                                              CatBoost\n                             DRO                                                                                              DRO                                                                DRO\n                             Group DRO                                                                  0.800                 Group DRO                                                          Group DRO\n                             DANN                                                                                             DANN                                                               DANN\n                             IRM                                                                                              IRM                                             0.85               IRM\n          0.80               MixUp                                                                                            MixUp                                                              MixUp\n                             VREX                                                                       0.775                 VREX                                                               VREX\n                             MMD                                                                                              MMD                                                                MMD\n                             CORAL                                                                                            CORAL                                                              CORAL\n                             Label Group DRO                                                                                  Label Group DRO                                 0.80               Label Group DRO\n                             Adv. Label DRO                                                             0.750                 Adv. Label DRO                                                     Adv. Label DRO\n          0.75               y=x                                                                                              y=x                                                                y=x\n                        0.75             0.80             0.85             0.90                                             0.75                  0.80           0.85                               0.8                      0.9\n                       In-Distribution Test Accuracy                                                                    In-Distribution Test Accuracy                                      In-Distribution Test Accuracy\n       est Accuracy                       Income                                                        est Accuracy                      HELOC                              est Accuracy       Public Coverage\n         0.85                Model                                                                                          Model                                                                Model\n                            XGBoost                                                                                        XGBoost                                              0.8             XGBoost\n                            LightGBM                                                                                       SAINT                                                                SAINT\n                            MLP                                                                                            DRO                                                                  DRO\n                            FT-Transformer                                                                 0.7             MLP                                                                  MLP\n         0.80               ResNet                                                                                         TabTransformer                                                       TabTransformer\n                            SAINT                                                                                          CatBoost                                             0.7             CatBoost\n                            NODE                                                                                           ResNet                                                               ResNet\n       Out-of-Distribution T                                                                            Out-of-Distribution T                                                Out-of-Distribution T\n                            TabTransformer                                                                                 Group DRO                                                            Group DRO\n                            CatBoost                                                                                       FT-Transformer                                                       FT-Transformer\n         0.75               DRO                                                                            0.6             LightGBM                                             0.6             LightGBM\n                            Group DRO                                                                                      Adv. Label DRO                                                       Adv. Label DRO\n                            DANN                                                                                           Label Group DRO                                                      Label Group DRO\n                            IRM                                                                                            NODE                                                                 NODE\n         0.70               MixUp                                                                                          y=x                                                                  y=x\n                            VREX                                                                                                                                                0.5\n                            MMD                                                                            0.5\n                            CORAL\n                            Label Group DRO\n         0.65               Adv. Label DRO                                                                                                                                      0.4\n                            y=x\n                                        0.7                        0.8                                     0.4   0.4              0.5               0.6       0.7                            0.4                        0.6               0.8\n                      In-Distribution Test Accuracy                                                                  In-Distribution Test Accuracy                                        In-Distribution Test Accuracy\nFigure 2: Results for baselines, robust learning, and domain generalization models across the 15\nTableShift benchmark tasks. The y = x line indicates a model with no shift gap, \u2206Acc = 0 (see\nEquation 1). Clopper-Pearson confidence intervals at \u03b1 = 0.05 shown for all points. Note that\ndomain generalization models are only used on domain generalization tasks (cf. Table 1). Results for\nthe remaining TABLESHIFT tasks are shown in Figure 3. For exact results see Section E.3.\n                                                                                                                                           8", "md": "# Results for baselines, robust learning, and domain generalization models\n\n## Results for baselines, robust learning, and domain generalization models\n\nFigure 2: Results for baselines, robust learning, and domain generalization models across the 15 TableShift benchmark tasks. The y = x line indicates a model with no shift gap, \u2206Acc = 0 (see Equation 1). Clopper-Pearson confidence intervals at \u03b1 = 0.05 shown for all points. Note that domain generalization models are only used on domain generalization tasks (cf. Table 1). Results for the remaining TABLESHIFT tasks are shown in Figure 3. For exact results see Section E.3.\n\n|est Accuracy|ASSISTments Model|College Scorecard Model|Hospital Mortality Model|\n|---|---|---|---|\n|XGBoost| |XGBoost|XGBoost|\n|LightGBM|0.95|LightGBM|LightGBM|\n|MLP| |MLP|MLP|\n|FT-Transformer| |FT-Transformer|FT-Transformer|\n|ResNet| |ResNet|ResNet|\n|SAINT|0.90|SAINT|SAINT|\n|NODE| |NODE|NODE|\n|Out-of-Distribution T| |Out-of-Distribution T|Out-of-Distribution T|\n|TabTransformer| |TabTransformer|TabTransformer|\n|CatBoost|0.92|CatBoost|CatBoost|\n|DRO| |DRO|DRO|\n|Group DRO|0.85|Group DRO|Group DRO|\n|DANN| |DANN|DANN|\n|IRM|0.90|IRM|IRM|\n|MixUp| |MixUp|MixUp|\n|VREX|0.80|VREX|VREX|\n|MMD| |MMD|MMD|\n|CORAL| |CORAL|CORAL|\n|Label Group DRO| |Label Group DRO|Label Group DRO|\n|Adv. Label DRO| |Adv. Label DRO|Adv. Label DRO|\n|y=x|0.75|y=x|y=x|\n\nIn-Distribution Test Accuracy\n\n$$\\text{est Accuracy Hospital Readmission Model}$$\n|est Accuracy|Diabetes Model|ICU Length of Stay Model|\n|---|---|---|\n|XGBoost| |XGBoost|\n|LightGBM| |LightGBM|\n|MLP|0.70|MLP|\n|FT-Transformer| |FT-Transformer|\n|ResNet|0.88|ResNet|\n|SAINT| |SAINT|\n|NODE| |NODE|\n|Out-of-Distribution T| |Out-of-Distribution T|\n|TabTransformer|0.86|TabTransformer|\n|CatBoost| |CatBoost|\n|DRO| |DRO|\n|Group DRO|0.85|Group DRO|\n|DANN| |DANN|\n|IRM|0.90|IRM|\n|MixUp|0.84|MixUp|\n|VREX|0.80|VREX|\n|MMD| |MMD|\n|CORAL|0.88|CORAL|\n|Label Group DRO| |Label Group DRO|\n|Adv. Label DRO|0.75|Adv. Label DRO|\n|y=x|0.75|y=x|\n\nIn-Distribution Test Accuracy\n\n$$\\text{est Accuracy Voting Model}$$\n\nest Accuracy\nFood Stamps Model\nUnemployment Model\n\nXGBoost\n\nXGBoost\n\nLightGBM\n\nLightGBM\n\nMLP\n0.85\nMLP\n\nFT-Transformer\n\nFT-Transformer", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Results for baselines, robust learning, and domain generalization models", "md": "# Results for baselines, robust learning, and domain generalization models"}, {"type": "heading", "lvl": 2, "value": "Results for baselines, robust learning, and domain generalization models", "md": "## Results for baselines, robust learning, and domain generalization models"}, {"type": "text", "value": "Figure 2: Results for baselines, robust learning, and domain generalization models across the 15 TableShift benchmark tasks. The y = x line indicates a model with no shift gap, \u2206Acc = 0 (see Equation 1). Clopper-Pearson confidence intervals at \u03b1 = 0.05 shown for all points. Note that domain generalization models are only used on domain generalization tasks (cf. Table 1). Results for the remaining TABLESHIFT tasks are shown in Figure 3. For exact results see Section E.3.", "md": "Figure 2: Results for baselines, robust learning, and domain generalization models across the 15 TableShift benchmark tasks. The y = x line indicates a model with no shift gap, \u2206Acc = 0 (see Equation 1). Clopper-Pearson confidence intervals at \u03b1 = 0.05 shown for all points. Note that domain generalization models are only used on domain generalization tasks (cf. Table 1). Results for the remaining TABLESHIFT tasks are shown in Figure 3. For exact results see Section E.3."}, {"type": "table", "rows": [["est Accuracy", "ASSISTments Model", "College Scorecard Model", "Hospital Mortality Model"], ["XGBoost", "", "XGBoost", "XGBoost"], ["LightGBM", "0.95", "LightGBM", "LightGBM"], ["MLP", "", "MLP", "MLP"], ["FT-Transformer", "", "FT-Transformer", "FT-Transformer"], ["ResNet", "", "ResNet", "ResNet"], ["SAINT", "0.90", "SAINT", "SAINT"], ["NODE", "", "NODE", "NODE"], ["Out-of-Distribution T", "", "Out-of-Distribution T", "Out-of-Distribution T"], ["TabTransformer", "", "TabTransformer", "TabTransformer"], ["CatBoost", "0.92", "CatBoost", "CatBoost"], ["DRO", "", "DRO", "DRO"], ["Group DRO", "0.85", "Group DRO", "Group DRO"], ["DANN", "", "DANN", "DANN"], ["IRM", "0.90", "IRM", "IRM"], ["MixUp", "", "MixUp", "MixUp"], ["VREX", "0.80", "VREX", "VREX"], ["MMD", "", "MMD", "MMD"], ["CORAL", "", "CORAL", "CORAL"], ["Label Group DRO", "", "Label Group DRO", "Label Group DRO"], ["Adv. Label DRO", "", "Adv. Label DRO", "Adv. Label DRO"], ["y=x", "0.75", "y=x", "y=x"]], "md": "|est Accuracy|ASSISTments Model|College Scorecard Model|Hospital Mortality Model|\n|---|---|---|---|\n|XGBoost| |XGBoost|XGBoost|\n|LightGBM|0.95|LightGBM|LightGBM|\n|MLP| |MLP|MLP|\n|FT-Transformer| |FT-Transformer|FT-Transformer|\n|ResNet| |ResNet|ResNet|\n|SAINT|0.90|SAINT|SAINT|\n|NODE| |NODE|NODE|\n|Out-of-Distribution T| |Out-of-Distribution T|Out-of-Distribution T|\n|TabTransformer| |TabTransformer|TabTransformer|\n|CatBoost|0.92|CatBoost|CatBoost|\n|DRO| |DRO|DRO|\n|Group DRO|0.85|Group DRO|Group DRO|\n|DANN| |DANN|DANN|\n|IRM|0.90|IRM|IRM|\n|MixUp| |MixUp|MixUp|\n|VREX|0.80|VREX|VREX|\n|MMD| |MMD|MMD|\n|CORAL| |CORAL|CORAL|\n|Label Group DRO| |Label Group DRO|Label Group DRO|\n|Adv. Label DRO| |Adv. Label DRO|Adv. Label DRO|\n|y=x|0.75|y=x|y=x|", "isPerfectTable": true, "csv": "\"est Accuracy\",\"ASSISTments Model\",\"College Scorecard Model\",\"Hospital Mortality Model\"\n\"XGBoost\",\"\",\"XGBoost\",\"XGBoost\"\n\"LightGBM\",\"0.95\",\"LightGBM\",\"LightGBM\"\n\"MLP\",\"\",\"MLP\",\"MLP\"\n\"FT-Transformer\",\"\",\"FT-Transformer\",\"FT-Transformer\"\n\"ResNet\",\"\",\"ResNet\",\"ResNet\"\n\"SAINT\",\"0.90\",\"SAINT\",\"SAINT\"\n\"NODE\",\"\",\"NODE\",\"NODE\"\n\"Out-of-Distribution T\",\"\",\"Out-of-Distribution T\",\"Out-of-Distribution T\"\n\"TabTransformer\",\"\",\"TabTransformer\",\"TabTransformer\"\n\"CatBoost\",\"0.92\",\"CatBoost\",\"CatBoost\"\n\"DRO\",\"\",\"DRO\",\"DRO\"\n\"Group DRO\",\"0.85\",\"Group DRO\",\"Group DRO\"\n\"DANN\",\"\",\"DANN\",\"DANN\"\n\"IRM\",\"0.90\",\"IRM\",\"IRM\"\n\"MixUp\",\"\",\"MixUp\",\"MixUp\"\n\"VREX\",\"0.80\",\"VREX\",\"VREX\"\n\"MMD\",\"\",\"MMD\",\"MMD\"\n\"CORAL\",\"\",\"CORAL\",\"CORAL\"\n\"Label Group DRO\",\"\",\"Label Group DRO\",\"Label Group DRO\"\n\"Adv. Label DRO\",\"\",\"Adv. Label DRO\",\"Adv. Label DRO\"\n\"y=x\",\"0.75\",\"y=x\",\"y=x\""}, {"type": "text", "value": "In-Distribution Test Accuracy\n\n$$\\text{est Accuracy Hospital Readmission Model}$$", "md": "In-Distribution Test Accuracy\n\n$$\\text{est Accuracy Hospital Readmission Model}$$"}, {"type": "table", "rows": [["est Accuracy", "Diabetes Model", "ICU Length of Stay Model"], ["XGBoost", "", "XGBoost"], ["LightGBM", "", "LightGBM"], ["MLP", "0.70", "MLP"], ["FT-Transformer", "", "FT-Transformer"], ["ResNet", "0.88", "ResNet"], ["SAINT", "", "SAINT"], ["NODE", "", "NODE"], ["Out-of-Distribution T", "", "Out-of-Distribution T"], ["TabTransformer", "0.86", "TabTransformer"], ["CatBoost", "", "CatBoost"], ["DRO", "", "DRO"], ["Group DRO", "0.85", "Group DRO"], ["DANN", "", "DANN"], ["IRM", "0.90", "IRM"], ["MixUp", "0.84", "MixUp"], ["VREX", "0.80", "VREX"], ["MMD", "", "MMD"], ["CORAL", "0.88", "CORAL"], ["Label Group DRO", "", "Label Group DRO"], ["Adv. Label DRO", "0.75", "Adv. Label DRO"], ["y=x", "0.75", "y=x"]], "md": "|est Accuracy|Diabetes Model|ICU Length of Stay Model|\n|---|---|---|\n|XGBoost| |XGBoost|\n|LightGBM| |LightGBM|\n|MLP|0.70|MLP|\n|FT-Transformer| |FT-Transformer|\n|ResNet|0.88|ResNet|\n|SAINT| |SAINT|\n|NODE| |NODE|\n|Out-of-Distribution T| |Out-of-Distribution T|\n|TabTransformer|0.86|TabTransformer|\n|CatBoost| |CatBoost|\n|DRO| |DRO|\n|Group DRO|0.85|Group DRO|\n|DANN| |DANN|\n|IRM|0.90|IRM|\n|MixUp|0.84|MixUp|\n|VREX|0.80|VREX|\n|MMD| |MMD|\n|CORAL|0.88|CORAL|\n|Label Group DRO| |Label Group DRO|\n|Adv. Label DRO|0.75|Adv. Label DRO|\n|y=x|0.75|y=x|", "isPerfectTable": true, "csv": "\"est Accuracy\",\"Diabetes Model\",\"ICU Length of Stay Model\"\n\"XGBoost\",\"\",\"XGBoost\"\n\"LightGBM\",\"\",\"LightGBM\"\n\"MLP\",\"0.70\",\"MLP\"\n\"FT-Transformer\",\"\",\"FT-Transformer\"\n\"ResNet\",\"0.88\",\"ResNet\"\n\"SAINT\",\"\",\"SAINT\"\n\"NODE\",\"\",\"NODE\"\n\"Out-of-Distribution T\",\"\",\"Out-of-Distribution T\"\n\"TabTransformer\",\"0.86\",\"TabTransformer\"\n\"CatBoost\",\"\",\"CatBoost\"\n\"DRO\",\"\",\"DRO\"\n\"Group DRO\",\"0.85\",\"Group DRO\"\n\"DANN\",\"\",\"DANN\"\n\"IRM\",\"0.90\",\"IRM\"\n\"MixUp\",\"0.84\",\"MixUp\"\n\"VREX\",\"0.80\",\"VREX\"\n\"MMD\",\"\",\"MMD\"\n\"CORAL\",\"0.88\",\"CORAL\"\n\"Label Group DRO\",\"\",\"Label Group DRO\"\n\"Adv. Label DRO\",\"0.75\",\"Adv. Label DRO\"\n\"y=x\",\"0.75\",\"y=x\""}, {"type": "text", "value": "In-Distribution Test Accuracy\n\n$$\\text{est Accuracy Voting Model}$$\n\nest Accuracy\nFood Stamps Model\nUnemployment Model\n\nXGBoost\n\nXGBoost\n\nLightGBM\n\nLightGBM\n\nMLP\n0.85\nMLP\n\nFT-Transformer\n\nFT-Transformer", "md": "In-Distribution Test Accuracy\n\n$$\\text{est Accuracy Voting Model}$$\n\nest Accuracy\nFood Stamps Model\nUnemployment Model\n\nXGBoost\n\nXGBoost\n\nLightGBM\n\nLightGBM\n\nMLP\n0.85\nMLP\n\nFT-Transformer\n\nFT-Transformer"}]}, {"page": 9, "text": "        est Accuracy                         Sepsis                                                      est Accuracy          Childhood Lead                                                         est Accuracy             Hypertension\n                                                                      Model                                                                                         Model                               0.70                Model\n                                                                     XGBoost                                                                                        XGBoost                                                 XGBoost\n          1.00                                                       SAINT                                                                                          SAINT                                                   SAINT\n                                                                     DRO                                   0.98                                                     DRO                                 0.65                DRO\n                                                                     MLP                                                                                            MLP                                                     MLP\n                                                                     TabTransformer                                                                                 TabTransformer                                          TabTransformer\n          0.98                                                       CatBoost                                                                                       CatBoost                                                CatBoost\n                                                                     ResNet                                0.96                                                     ResNet                              0.60                ResNet\n        Out-of-Distribution T                                        Group DRO                           Out-of-Distribution T                                      Group DRO                         Out-of-Distribution T Group DRO\n                                                                     FT-Transformer                                                                                 FT-Transformer                                          FT-Transformer\n          0.96                                                       LightGBM                                                                                       LightGBM                            0.55                LightGBM\n                                                                     Adv. Label DRO                                                                                 Adv. Label DRO                                          Adv. Label DRO\n                                                                     Label Group DRO                       0.94                                                     Label Group DRO                                         Label Group DRO\n                                                                     NODE                                                                                           NODE                                                    NODE\n          0.94                                                       y=x                                                                                            y=x                                 0.50                y=x\n          0.92                                                                                             0.92                                                                                         0.45\n          0.90   0.90                         0.95                         1.00                            0.90       0.90                            0.95                                              0.40       0.4                  0.5                 0.6     0.7\n                       In-Distribution Test Accuracy                                                                    In-Distribution Test Accuracy                                                                In-Distribution Test Accuracy\n                                  Figure 3: Additional results (cf. Figure 2). For exact results see Section E.3.\n                  Percentage of Max Accuracy (PMA-OOD)                                                                                                                        Average ID vs. OOD Accuracy\n                                     Across All TableShift Tasks*                                                                                                 Over 10 Domain Generalization Tasks\n                1                                      CatBoost\n                2                               FT-Transformer                                                                                                0.85\n                3                                      XGBoost                                                                                              est Accuracy\n                4                                    LightGBM\n                5                                        SAINT\n                6                                        NODE                                                                                                 0.80\n           Model7Rank                               Group DRO\n                8                                          MLP                                                                                              Out-of-Distribution T\n                9                                       ResNet\n              10                               Adv. Label DRO                                                                                                 0.75\n              11                                        CORAL\n              12                                         MMD\n              13                                          DRO\n              14                                        DANN                                                                                                  0.70\n              15                             TabTransformer\n              16                                       MixUp\n              17                           Label Group DRO\n              18                                         IRM                                                                                                  0.65\n              19                                      VREX                                                                                                                 0.65                0.70                0.75                0.80                 0.85\n                   0.0              0.2              0.4              0.6              0.8              1.0             1.2                                                                 In-Distribution Test Accuracy\n                            Percentage of Max Accuracy (PMA-OOD)                                                                                                                                                Model\n                                                                                                                                                                        XGBoost                              TabTransformer                        VREX\n                                                         Model Type                                                                                                     LightGBM                             CatBoost                              MMD\n                                                                                                                                                                        MLP                                  DRO                                   CORAL\n                           Baseline                                                    Domain Adaptation                                                                FT-Transformer                       Group DRO                             Label Group DRO\n                           Domain Robustness                                           Label Robustness                                                                 ResNet                               DANN                                  Adv. Label DRO\n                           Domain Generalization                                                                                                                        SAINT                                IRM                                   y=x\n                                                                                                                                                                        NODE                                 MixUp                                 Linear Fit\n                                                                 (a)                                                                                                                                               (b)\nFigure 4: (a): Percentage of Maximum OOD Accuracy (PMA-OOD) across tasks (see Table 14 for\nexact values). *: domain generalization models and Group DRO can only be trained on the subset of\n10 tasks with multiple training subdomains (see \u201cDomain Generalization\u201d column in Table 1). (b):\nAverage ID and OOD accuracy by model across domain generalization tasks only. We only show\ndomain generalization tasks in order to compare all models on the same set of tasks. See Figure 9 for\nresults on all tasks. Exact values in Table 15.\n                                                                                                                                             9", "md": "# OCR Text\n\n## OCR Text\n\n|est Accuracy|Sepsis|est Accuracy|Childhood Lead|est Accuracy|Hypertension|\n|---|---|---|---|---|---|\n|XGBoost|SAINT|XGBoost|SAINT|XGBoost|SAINT|\n|SAINT|DRO|0.98|DRO|0.65|DRO|\n|MLP|TabTransformer|MLP|TabTransformer|MLP|TabTransformer|\n|CatBoost|ResNet|CatBoost|ResNet|CatBoost|ResNet|\n|Out-of-Distribution T|Group DRO|Out-of-Distribution T|Group DRO|Out-of-Distribution T|Group DRO|\n|FT-Transformer|LightGBM|FT-Transformer|LightGBM|FT-Transformer|LightGBM|\n|Adv. Label DRO| |Label Group DRO|0.94|Label Group DRO|Label Group DRO|\n|NODE| |y=x|y=x|0.50| |\n|0.92| |0.92| |0.45| |\n|0.90|0.90|0.95|1.00|0.90|0.90|0.95|0.40|0.4|0.5|0.6|0.7|\n\n$$\\text{In-Distribution Test Accuracy}$$\n\nFigure 3: Additional results (cf. Figure 2). For exact results see Section E.3.\n\nPercentage of Max Accuracy (PMA-OOD) Across All TableShift Tasks*\n\nOver 10 Domain Generalization Tasks\n\n|1|CatBoost|\n|---|---|\n|2|FT-Transformer|0.85|\n|3|XGBoost|est Accuracy|\n|4|LightGBM|\n|5|SAINT|\n|6|NODE|0.80|\n|Model7Rank|Group DRO|\n|8|MLP|Out-of-Distribution T|\n| |9|ResNet|0.75|\n|10|Adv. Label DRO|\n|11|CORAL|\n|12|MMD|\n|13|DRO|\n|14|DANN|0.70|\n|15|TabTransformer|\n|16|MixUp|\n|17|Label Group DRO|\n|18|IRM|0.65|\n|19|VREX|0.65|0.70|0.75|0.80|0.85|\n\n$$\\text{In-Distribution Test Accuracy}$$\n\nModel\n\nXGBoost TabTransformer VREX\n\nLightGBM CatBoost MMD\n\nMLP DRO CORAL\n\nFT-Transformer Group DRO Label Group DRO\n\nResNet DANN Adv. Label DRO\n\nSAINT IRM y=x\n\nNODE MixUp Linear Fit\n\n(a)\n\n(b)\n\nFigure 4: (a): Percentage of Maximum OOD Accuracy (PMA-OOD) across tasks (see Table 14 for\nexact values). *: domain generalization models and Group DRO can only be trained on the subset of\n10 tasks with multiple training subdomains (see \u201cDomain Generalization\u201d column in Table 1). (b):\nAverage ID and OOD accuracy by model across domain generalization tasks only. We only show\ndomain generalization tasks in order to compare all models on the same set of tasks. See Figure 9 for\nresults on all tasks. Exact values in Table 15.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "OCR Text", "md": "# OCR Text"}, {"type": "heading", "lvl": 2, "value": "OCR Text", "md": "## OCR Text"}, {"type": "table", "rows": [["est Accuracy", "Sepsis", "est Accuracy", "Childhood Lead", "est Accuracy", "Hypertension"], ["XGBoost", "SAINT", "XGBoost", "SAINT", "XGBoost", "SAINT"], ["SAINT", "DRO", "0.98", "DRO", "0.65", "DRO"], ["MLP", "TabTransformer", "MLP", "TabTransformer", "MLP", "TabTransformer"], ["CatBoost", "ResNet", "CatBoost", "ResNet", "CatBoost", "ResNet"], ["Out-of-Distribution T", "Group DRO", "Out-of-Distribution T", "Group DRO", "Out-of-Distribution T", "Group DRO"], ["FT-Transformer", "LightGBM", "FT-Transformer", "LightGBM", "FT-Transformer", "LightGBM"], ["Adv. Label DRO", "", "Label Group DRO", "0.94", "Label Group DRO", "Label Group DRO"], ["NODE", "", "y=x", "y=x", "0.50", ""], ["0.92", "", "0.92", "", "0.45", ""], ["0.90", "0.90", "0.95", "1.00", "0.90", "0.90", "0.95", "0.40", "0.4", "0.5", "0.6", "0.7"]], "md": "|est Accuracy|Sepsis|est Accuracy|Childhood Lead|est Accuracy|Hypertension|\n|---|---|---|---|---|---|\n|XGBoost|SAINT|XGBoost|SAINT|XGBoost|SAINT|\n|SAINT|DRO|0.98|DRO|0.65|DRO|\n|MLP|TabTransformer|MLP|TabTransformer|MLP|TabTransformer|\n|CatBoost|ResNet|CatBoost|ResNet|CatBoost|ResNet|\n|Out-of-Distribution T|Group DRO|Out-of-Distribution T|Group DRO|Out-of-Distribution T|Group DRO|\n|FT-Transformer|LightGBM|FT-Transformer|LightGBM|FT-Transformer|LightGBM|\n|Adv. Label DRO| |Label Group DRO|0.94|Label Group DRO|Label Group DRO|\n|NODE| |y=x|y=x|0.50| |\n|0.92| |0.92| |0.45| |\n|0.90|0.90|0.95|1.00|0.90|0.90|0.95|0.40|0.4|0.5|0.6|0.7|", "isPerfectTable": false, "csv": "\"est Accuracy\",\"Sepsis\",\"est Accuracy\",\"Childhood Lead\",\"est Accuracy\",\"Hypertension\"\n\"XGBoost\",\"SAINT\",\"XGBoost\",\"SAINT\",\"XGBoost\",\"SAINT\"\n\"SAINT\",\"DRO\",\"0.98\",\"DRO\",\"0.65\",\"DRO\"\n\"MLP\",\"TabTransformer\",\"MLP\",\"TabTransformer\",\"MLP\",\"TabTransformer\"\n\"CatBoost\",\"ResNet\",\"CatBoost\",\"ResNet\",\"CatBoost\",\"ResNet\"\n\"Out-of-Distribution T\",\"Group DRO\",\"Out-of-Distribution T\",\"Group DRO\",\"Out-of-Distribution T\",\"Group DRO\"\n\"FT-Transformer\",\"LightGBM\",\"FT-Transformer\",\"LightGBM\",\"FT-Transformer\",\"LightGBM\"\n\"Adv. Label DRO\",\"\",\"Label Group DRO\",\"0.94\",\"Label Group DRO\",\"Label Group DRO\"\n\"NODE\",\"\",\"y=x\",\"y=x\",\"0.50\",\"\"\n\"0.92\",\"\",\"0.92\",\"\",\"0.45\",\"\"\n\"0.90\",\"0.90\",\"0.95\",\"1.00\",\"0.90\",\"0.90\",\"0.95\",\"0.40\",\"0.4\",\"0.5\",\"0.6\",\"0.7\""}, {"type": "text", "value": "$$\\text{In-Distribution Test Accuracy}$$\n\nFigure 3: Additional results (cf. Figure 2). For exact results see Section E.3.\n\nPercentage of Max Accuracy (PMA-OOD) Across All TableShift Tasks*\n\nOver 10 Domain Generalization Tasks", "md": "$$\\text{In-Distribution Test Accuracy}$$\n\nFigure 3: Additional results (cf. Figure 2). For exact results see Section E.3.\n\nPercentage of Max Accuracy (PMA-OOD) Across All TableShift Tasks*\n\nOver 10 Domain Generalization Tasks"}, {"type": "table", "rows": [["1", "CatBoost"], ["2", "FT-Transformer", "0.85"], ["3", "XGBoost", "est Accuracy"], ["4", "LightGBM"], ["5", "SAINT"], ["6", "NODE", "0.80"], ["Model7Rank", "Group DRO"], ["8", "MLP", "Out-of-Distribution T"], ["", "9", "ResNet", "0.75"], ["10", "Adv. Label DRO"], ["11", "CORAL"], ["12", "MMD"], ["13", "DRO"], ["14", "DANN", "0.70"], ["15", "TabTransformer"], ["16", "MixUp"], ["17", "Label Group DRO"], ["18", "IRM", "0.65"], ["19", "VREX", "0.65", "0.70", "0.75", "0.80", "0.85"]], "md": "|1|CatBoost|\n|---|---|\n|2|FT-Transformer|0.85|\n|3|XGBoost|est Accuracy|\n|4|LightGBM|\n|5|SAINT|\n|6|NODE|0.80|\n|Model7Rank|Group DRO|\n|8|MLP|Out-of-Distribution T|\n| |9|ResNet|0.75|\n|10|Adv. Label DRO|\n|11|CORAL|\n|12|MMD|\n|13|DRO|\n|14|DANN|0.70|\n|15|TabTransformer|\n|16|MixUp|\n|17|Label Group DRO|\n|18|IRM|0.65|\n|19|VREX|0.65|0.70|0.75|0.80|0.85|", "isPerfectTable": false, "csv": "\"1\",\"CatBoost\"\n\"2\",\"FT-Transformer\",\"0.85\"\n\"3\",\"XGBoost\",\"est Accuracy\"\n\"4\",\"LightGBM\"\n\"5\",\"SAINT\"\n\"6\",\"NODE\",\"0.80\"\n\"Model7Rank\",\"Group DRO\"\n\"8\",\"MLP\",\"Out-of-Distribution T\"\n\"\",\"9\",\"ResNet\",\"0.75\"\n\"10\",\"Adv. Label DRO\"\n\"11\",\"CORAL\"\n\"12\",\"MMD\"\n\"13\",\"DRO\"\n\"14\",\"DANN\",\"0.70\"\n\"15\",\"TabTransformer\"\n\"16\",\"MixUp\"\n\"17\",\"Label Group DRO\"\n\"18\",\"IRM\",\"0.65\"\n\"19\",\"VREX\",\"0.65\",\"0.70\",\"0.75\",\"0.80\",\"0.85\""}, {"type": "text", "value": "$$\\text{In-Distribution Test Accuracy}$$\n\nModel\n\nXGBoost TabTransformer VREX\n\nLightGBM CatBoost MMD\n\nMLP DRO CORAL\n\nFT-Transformer Group DRO Label Group DRO\n\nResNet DANN Adv. Label DRO\n\nSAINT IRM y=x\n\nNODE MixUp Linear Fit\n\n(a)\n\n(b)\n\nFigure 4: (a): Percentage of Maximum OOD Accuracy (PMA-OOD) across tasks (see Table 14 for\nexact values). *: domain generalization models and Group DRO can only be trained on the subset of\n10 tasks with multiple training subdomains (see \u201cDomain Generalization\u201d column in Table 1). (b):\nAverage ID and OOD accuracy by model across domain generalization tasks only. We only show\ndomain generalization tasks in order to compare all models on the same set of tasks. See Figure 9 for\nresults on all tasks. Exact values in Table 15.", "md": "$$\\text{In-Distribution Test Accuracy}$$\n\nModel\n\nXGBoost TabTransformer VREX\n\nLightGBM CatBoost MMD\n\nMLP DRO CORAL\n\nFT-Transformer Group DRO Label Group DRO\n\nResNet DANN Adv. Label DRO\n\nSAINT IRM y=x\n\nNODE MixUp Linear Fit\n\n(a)\n\n(b)\n\nFigure 4: (a): Percentage of Maximum OOD Accuracy (PMA-OOD) across tasks (see Table 14 for\nexact values). *: domain generalization models and Group DRO can only be trained on the subset of\n10 tasks with multiple training subdomains (see \u201cDomain Generalization\u201d column in Table 1). (b):\nAverage ID and OOD accuracy by model across domain generalization tasks only. We only show\ndomain generalization tasks in order to compare all models on the same set of tasks. See Figure 9 for\nresults on all tasks. Exact values in Table 15."}]}, {"page": 10, "text": "\u2206Acc (Pearson correlation \u03c1 = 0.71). This persists even after accounting for ID accuracy: a simple\nlinear regression of OOD accuracy on [ID accuracy, \u2206y] obtains R2 = 0.996. This suggests that the\nchange in the label distribution is an important factor in understanding tabular shifts (for example,\nthe outliers in Figure 1 are from the four tasks with largest label shift: Public Coverage, HELOC,\nASSISTments, College Scorecard; see Figures 2, 3 and Table 3). Label shift robustness methods in\nour study did not eliminate performance gaps under shift; in fact, label shift robustness methods often\ndegraded both ID and OOD accuracy (e.g. Figure 4b). We provide similar analyses relating shift gap\nto (i) covariate shift and (ii) concept shift in Figure 8, but find that they are not clearly related.\nChanges in predictions are related to covariate\nshift. As an exploratory finding, we find some evi-\ndence that changes in the predictions for OOD data                                                AccDtr|       Label Shift          y vs. Shift Gap |    Acc|\nare correlated with changes in p(x), shown in Figure                                                                 Linear Fit\n7a (\u03c1 = 0.99). This suggests that shift gaps in the                                                                  95% Prediction Interval\nbenchmark datasets not explained by the combina-                                                   Acc| = |AccDte    95% Confidence Interval\ntion of ID accuracy and \u2206y may be driven primarily                                                  10    1\nby covariate shift (changes in p(x)) as opposed to\nconcept shift (changes in p(y|x)). Further analysis\nis needed to confirm this exploratory finding. We                                                 Abs. Val. of Shift Gap |\nnote that relationships between other forms of shift\nshowed much weaker correlation, roughly \u03c1 \u2248                                      \u22120.2               10    2\n(see Figure 7).\n6       Limitations                                                                                 10    3            10   3              10   2       10   1\nThe conclusions in this study are limited to the spe-                                                                 Change in Label Distribution      y\ncific datasets and models evaluated. While we inten-\ntionally selected a diverse suite of benchmark datasets                                       Figure 5: Label shift (\u2206y, measured via Equa-\nalong several axes (domain, distribution shift, dataset\nsize, etc.), our conclusions can only be extended to                                          tion (3)) and absolute shift gap \u2206Acc show\nother distribution shifts insofar as they are similar to                                      moderate correlation across datasets and mod-\nthe shifts in TABLESHIFT. More empirical validation                                           els (Pearson correlation \u03c1 = 0.70). Exact \u2206y\nis needed, including studies comparing our fi                                 ndings          values in Table 3.\nto other tabular shifts.\nOur work does not exhaustively cover the space of all\npossible tabular data classifiers. In particular, \u201chybrid\u201d\nmethods combining some of the loss-based robust-\nness interventions (i.e. Group DRO) with various tabular data-specific model architectures (e.g.\nFT-Transformer, ResNet) might lead to different results. Our initial exploratory evaluation of hybrid\nmethods (see Section E.5), however, does not suggest that hybrid methods led to qualitative changes\nin our results, but these methods warrant a more extensive evaluation. Finally, our work does not\nestablish theoretical connections between the factors analyzed (ID accuracy, OOD accuracy, \u2206y).\n7       Conclusion\nWe introduce the TABLESHIFT benchmark for studying distribution shift in tabular data. TABLESHIFT\npresents a diverse set of tasks for reliable study and benchmarking of tabular data models under\ndistribution shift. We provide a Python API to access the datasets, along with implementations\nof several models including baselines, distributionally robust learners, and domain generalization\nmethods. Finally, we present empirical results which form the first large-scale study of tabular data\nmodeling under distribution shift.\nOur results suggest multiple potential avenues for future work: First, improvements to in-distribution\naccuracy are likely to drive OOD accuracy gains. Second, improved robustness to label shift may\nreduce shift gaps. Third, hybrid methods which combine robustness-enhancing losses (such as Group\nDRO) with improved neural network architectures may be able to further improve OOD performance.\nBeyond these proposed directions, we hope that TableShift opens new research frontiers for tabular\nmachine learning research beyond those addressed in the current work.\n                                                                                    10", "md": "# TABLESHIFT Study\n\n## Study Summary\n\nThe study conducted on TABLESHIFT benchmark reveals interesting findings related to distribution shift in tabular data modeling.\n\n### Key Findings:\n\n- Pearson correlation between ID accuracy and OOD accuracy: \u03c1 = 0.71\n- Regression analysis of OOD accuracy on ID accuracy and label distribution change: R2 = 0.996\n- Label shift robustness methods did not eliminate performance gaps under shift\n- Correlation between shift gap and covariate shift/concept shift\n- Correlation between changes in predictions for OOD data and changes in p(x)\n\n### Limitations:\n\nThe conclusions drawn are limited to the specific datasets and models evaluated. Further empirical validation is required to extend the findings to other tabular shifts.\n\n### Future Directions:\n\nPotential avenues for future work include improving in-distribution accuracy, enhancing robustness to label shift, and exploring hybrid methods combining robustness-enhancing losses with improved neural network architectures.\n\n### Conclusion:\n\nThe TABLESHIFT benchmark provides a valuable resource for studying distribution shift in tabular data modeling, offering diverse tasks for benchmarking models under distribution shift.\n\n### References:\n\nFor more details, refer to the complete study on TABLESHIFT.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "TABLESHIFT Study", "md": "# TABLESHIFT Study"}, {"type": "heading", "lvl": 2, "value": "Study Summary", "md": "## Study Summary"}, {"type": "text", "value": "The study conducted on TABLESHIFT benchmark reveals interesting findings related to distribution shift in tabular data modeling.", "md": "The study conducted on TABLESHIFT benchmark reveals interesting findings related to distribution shift in tabular data modeling."}, {"type": "heading", "lvl": 3, "value": "Key Findings:", "md": "### Key Findings:"}, {"type": "text", "value": "- Pearson correlation between ID accuracy and OOD accuracy: \u03c1 = 0.71\n- Regression analysis of OOD accuracy on ID accuracy and label distribution change: R2 = 0.996\n- Label shift robustness methods did not eliminate performance gaps under shift\n- Correlation between shift gap and covariate shift/concept shift\n- Correlation between changes in predictions for OOD data and changes in p(x)", "md": "- Pearson correlation between ID accuracy and OOD accuracy: \u03c1 = 0.71\n- Regression analysis of OOD accuracy on ID accuracy and label distribution change: R2 = 0.996\n- Label shift robustness methods did not eliminate performance gaps under shift\n- Correlation between shift gap and covariate shift/concept shift\n- Correlation between changes in predictions for OOD data and changes in p(x)"}, {"type": "heading", "lvl": 3, "value": "Limitations:", "md": "### Limitations:"}, {"type": "text", "value": "The conclusions drawn are limited to the specific datasets and models evaluated. Further empirical validation is required to extend the findings to other tabular shifts.", "md": "The conclusions drawn are limited to the specific datasets and models evaluated. Further empirical validation is required to extend the findings to other tabular shifts."}, {"type": "heading", "lvl": 3, "value": "Future Directions:", "md": "### Future Directions:"}, {"type": "text", "value": "Potential avenues for future work include improving in-distribution accuracy, enhancing robustness to label shift, and exploring hybrid methods combining robustness-enhancing losses with improved neural network architectures.", "md": "Potential avenues for future work include improving in-distribution accuracy, enhancing robustness to label shift, and exploring hybrid methods combining robustness-enhancing losses with improved neural network architectures."}, {"type": "heading", "lvl": 3, "value": "Conclusion:", "md": "### Conclusion:"}, {"type": "text", "value": "The TABLESHIFT benchmark provides a valuable resource for studying distribution shift in tabular data modeling, offering diverse tasks for benchmarking models under distribution shift.", "md": "The TABLESHIFT benchmark provides a valuable resource for studying distribution shift in tabular data modeling, offering diverse tasks for benchmarking models under distribution shift."}, {"type": "heading", "lvl": 3, "value": "References:", "md": "### References:"}, {"type": "text", "value": "For more details, refer to the complete study on TABLESHIFT.", "md": "For more details, refer to the complete study on TABLESHIFT."}]}, {"page": 11, "text": "References\n [1] Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, and Mario Marchand.\n     Domain-adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014.\n [2] David Alvarez-Melis and Nicolo Fusi. Geometric dataset distances via optimal transport.\n     Advances in Neural Information Processing Systems, 33:21428\u201321439, 2020.\n [3] American Heart Association.         The Facts About High Blood Pressure.              https:\n     //www.heart.org/en/health-topics/high-blood-pressure/the-facts-about-\n     high-blood-pressure, 2017. Accessed: 2023-01-06.\n [4] American Heart Association.        Health Threats from High Blood Pressure.           https:\n     //www.heart.org/en/health-topics/high-blood-pressure/health-threats-\n     from-high-blood-pressure, 2022. Accessed: 2023-01-06.\n [5] American National Election Studies (ANES). ANES Time Series Cumulative Data File, 1948-\n     2020, 2020.\n [6] Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk mini-\n     mization. arXiv preprint arXiv:1907.02893, 2019.\n [7] American Diabetes Association. Economic costs of diabetes in the us in 2017. Diabetes care,\n     41(5):917\u2013928, 2018.\n [8] Algernon Austin. A good credit score did not protect latino and black borrowers. 2012.\n [9] Anas Awadalla, Mitchell Wortsman, Gabriel Ilharco, Sewon Min, Ian Magnusson, Hannaneh\n     Hajishirzi, and Ludwig Schmidt. Exploring the landscape of distributional robustness for\n     question answering models. arXiv preprint arXiv:2210.12517, 2022.\n[10] Clare Bambra and Terje A Eikemo. Welfare state regimes, unemployment and health: a\n     comparative study of the relationship between unemployment and self-reported health in 23\n     european countries. Journal of Epidemiology & Community Health, 63(2):92\u201398, 2009.\n[11] Michelle Bao, Angela Zhou, Samantha Zottola, Brian Brubach, Sarah Desmarais, Aaron\n     Horowitz, Kristian Lum, and Suresh Venkatasubramanian. It\u2019s compaslicated: The messy\n     relationship between rai datasets and algorithmic fairness benchmarks.        arXiv preprint\n     arXiv:2106.05498, 2021.\n[12] Matias Barenstein. Propublica\u2019s compas data revisited. arXiv preprint arXiv:1906.04711, 2019.\n[13] James Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyper-\n     parameter optimization in hundreds of dimensions for vision architectures. In International\n     conference on machine learning, pages 115\u2013123. PMLR, 2013.\n[14] Tony A Blakely, Sunny CD Collings, and June Atkinson. Unemployment and suicide. evidence\n     for a causal association? Journal of Epidemiology & Community Health, 57(8):594\u2013600, 2003.\n[15] Vadim Borisov, Tobias Leemann, Kathrin Se\u00dfler, Johannes Haug, Martin Pawelczyk, and Gjergji\n     Kasneci. Deep neural networks and tabular data: A survey. arXiv preprint arXiv:2110.01889,\n     2021.\n[16] N Cable, A Sacker, and M Bartley. The effect of employment on psychological health in mid-\n     adulthood: findings from the 1970 british cohort study. Journal of Epidemiology & Community\n     Health, 62(5):e10\u2013e10, 2008.\n[17] Centers for Disease Control and Prevention. National Diabetes Statistics Report. https://\n     www.cdc.gov/diabetes/data/statistics-report/index.html, 2022. Accessed: 2023-\n     01-05.\n[18] Centers for Disease Control and Prevention (CDC). National Health and Nutrition Examination\n     Survey Questionnaire, Examination Protocol, and Laboratory Protocol (1999, 2001, 2003, 2005,\n     2007, 2009, 2011, 2013, 2015, 2017), 2017.\n[19] Centers for Disease Control and Prevention (CDC). BRFSS Survey Data (2015, 2017, 2019,\n     2021), 2021.\n[20] Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of\n     the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages\n     785\u2013794, 2016.\n                                                11", "md": "# References\n\n## References\n\n|[1]|Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, and Mario Marchand. Domain-adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014.|\n|---|---|\n|[2]|David Alvarez-Melis and Nicolo Fusi. Geometric dataset distances via optimal transport. Advances in Neural Information Processing Systems, 33:21428\u201321439, 2020.|\n|[3]|American Heart Association. The Facts About High Blood Pressure. Link, 2017. Accessed: 2023-01-06.|\n|[4]|American Heart Association. Health Threats from High Blood Pressure. Link, 2022. Accessed: 2023-01-06.|\n|[5]|American National Election Studies (ANES). ANES Time Series Cumulative Data File, 1948-2020, 2020.|\n|[6]|Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019.|\n|[7]|American Diabetes Association. Economic costs of diabetes in the US in 2017. Diabetes care, 41(5):917\u2013928, 2018.|\n|[8]|Algernon Austin. A good credit score did not protect Latino and Black borrowers. 2012.|\n|[9]|Anas Awadalla, Mitchell Wortsman, Gabriel Ilharco, Sewon Min, Ian Magnusson, Hannaneh Hajishirzi, and Ludwig Schmidt. Exploring the landscape of distributional robustness for question answering models. arXiv preprint arXiv:2210.12517, 2022.|\n|[10]|Clare Bambra and Terje A Eikemo. Welfare state regimes, unemployment and health: a comparative study of the relationship between unemployment and self-reported health in 23 European countries. Journal of Epidemiology & Community Health, 63(2):92\u201398, 2009.|\n|[11]|Michelle Bao, Angela Zhou, Samantha Zottola, Brian Brubach, Sarah Desmarais, Aaron Horowitz, Kristian Lum, and Suresh Venkatasubramanian. It\u2019s compaslicated: The messy relationship between rai datasets and algorithmic fairness benchmarks. arXiv preprint arXiv:2106.05498, 2021.|\n|[12]|Matias Barenstein. Propublica\u2019s compas data revisited. arXiv preprint arXiv:1906.04711, 2019.|\n|[13]|James Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyper-parameter optimization in hundreds of dimensions for vision architectures. In International conference on machine learning, pages 115\u2013123. PMLR, 2013.|\n|[14]|Tony A Blakely, Sunny CD Collings, and June Atkinson. Unemployment and suicide. evidence for a causal association? Journal of Epidemiology & Community Health, 57(8):594\u2013600, 2003.|\n|[15]|Vadim Borisov, Tobias Leemann, Kathrin Se\u00dfler, Johannes Haug, Martin Pawelczyk, and Gjergji Kasneci. Deep neural networks and tabular data: A survey. arXiv preprint arXiv:2110.01889, 2021.|\n|[16]|N Cable, A Sacker, and M Bartley. The effect of employment on psychological health in mid-adulthood: findings from the 1970 British cohort study. Journal of Epidemiology & Community Health, 62(5):e10\u2013e10, 2008.|\n|[17]|Centers for Disease Control and Prevention. National Diabetes Statistics Report. Link, 2022. Accessed: 2023-01-05.|\n|[18]|Centers for Disease Control and Prevention (CDC). National Health and Nutrition Examination Survey Questionnaire, Examination Protocol, and Laboratory Protocol (1999, 2001, 2003, 2005, 2007, 2009, 2011, 2013, 2015, 2017), 2017.|\n|[19]|Centers for Disease Control and Prevention (CDC). BRFSS Survey Data (2015, 2017, 2019, 2021), 2021.|\n|[20]|Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785\u2013794, 2016.|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 2, "value": "References", "md": "## References"}, {"type": "table", "rows": [["[1]", "Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, and Mario Marchand. Domain-adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014."], ["[2]", "David Alvarez-Melis and Nicolo Fusi. Geometric dataset distances via optimal transport. Advances in Neural Information Processing Systems, 33:21428\u201321439, 2020."], ["[3]", "American Heart Association. The Facts About High Blood Pressure. Link, 2017. Accessed: 2023-01-06."], ["[4]", "American Heart Association. Health Threats from High Blood Pressure. Link, 2022. Accessed: 2023-01-06."], ["[5]", "American National Election Studies (ANES). ANES Time Series Cumulative Data File, 1948-2020, 2020."], ["[6]", "Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019."], ["[7]", "American Diabetes Association. Economic costs of diabetes in the US in 2017. Diabetes care, 41(5):917\u2013928, 2018."], ["[8]", "Algernon Austin. A good credit score did not protect Latino and Black borrowers. 2012."], ["[9]", "Anas Awadalla, Mitchell Wortsman, Gabriel Ilharco, Sewon Min, Ian Magnusson, Hannaneh Hajishirzi, and Ludwig Schmidt. Exploring the landscape of distributional robustness for question answering models. arXiv preprint arXiv:2210.12517, 2022."], ["[10]", "Clare Bambra and Terje A Eikemo. Welfare state regimes, unemployment and health: a comparative study of the relationship between unemployment and self-reported health in 23 European countries. Journal of Epidemiology & Community Health, 63(2):92\u201398, 2009."], ["[11]", "Michelle Bao, Angela Zhou, Samantha Zottola, Brian Brubach, Sarah Desmarais, Aaron Horowitz, Kristian Lum, and Suresh Venkatasubramanian. It\u2019s compaslicated: The messy relationship between rai datasets and algorithmic fairness benchmarks. arXiv preprint arXiv:2106.05498, 2021."], ["[12]", "Matias Barenstein. Propublica\u2019s compas data revisited. arXiv preprint arXiv:1906.04711, 2019."], ["[13]", "James Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyper-parameter optimization in hundreds of dimensions for vision architectures. In International conference on machine learning, pages 115\u2013123. PMLR, 2013."], ["[14]", "Tony A Blakely, Sunny CD Collings, and June Atkinson. Unemployment and suicide. evidence for a causal association? Journal of Epidemiology & Community Health, 57(8):594\u2013600, 2003."], ["[15]", "Vadim Borisov, Tobias Leemann, Kathrin Se\u00dfler, Johannes Haug, Martin Pawelczyk, and Gjergji Kasneci. Deep neural networks and tabular data: A survey. arXiv preprint arXiv:2110.01889, 2021."], ["[16]", "N Cable, A Sacker, and M Bartley. The effect of employment on psychological health in mid-adulthood: findings from the 1970 British cohort study. Journal of Epidemiology & Community Health, 62(5):e10\u2013e10, 2008."], ["[17]", "Centers for Disease Control and Prevention. National Diabetes Statistics Report. Link, 2022. Accessed: 2023-01-05."], ["[18]", "Centers for Disease Control and Prevention (CDC). National Health and Nutrition Examination Survey Questionnaire, Examination Protocol, and Laboratory Protocol (1999, 2001, 2003, 2005, 2007, 2009, 2011, 2013, 2015, 2017), 2017."], ["[19]", "Centers for Disease Control and Prevention (CDC). BRFSS Survey Data (2015, 2017, 2019, 2021), 2021."], ["[20]", "Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785\u2013794, 2016."]], "md": "|[1]|Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, and Mario Marchand. Domain-adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014.|\n|---|---|\n|[2]|David Alvarez-Melis and Nicolo Fusi. Geometric dataset distances via optimal transport. Advances in Neural Information Processing Systems, 33:21428\u201321439, 2020.|\n|[3]|American Heart Association. The Facts About High Blood Pressure. Link, 2017. Accessed: 2023-01-06.|\n|[4]|American Heart Association. Health Threats from High Blood Pressure. Link, 2022. Accessed: 2023-01-06.|\n|[5]|American National Election Studies (ANES). ANES Time Series Cumulative Data File, 1948-2020, 2020.|\n|[6]|Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019.|\n|[7]|American Diabetes Association. Economic costs of diabetes in the US in 2017. Diabetes care, 41(5):917\u2013928, 2018.|\n|[8]|Algernon Austin. A good credit score did not protect Latino and Black borrowers. 2012.|\n|[9]|Anas Awadalla, Mitchell Wortsman, Gabriel Ilharco, Sewon Min, Ian Magnusson, Hannaneh Hajishirzi, and Ludwig Schmidt. Exploring the landscape of distributional robustness for question answering models. arXiv preprint arXiv:2210.12517, 2022.|\n|[10]|Clare Bambra and Terje A Eikemo. Welfare state regimes, unemployment and health: a comparative study of the relationship between unemployment and self-reported health in 23 European countries. Journal of Epidemiology & Community Health, 63(2):92\u201398, 2009.|\n|[11]|Michelle Bao, Angela Zhou, Samantha Zottola, Brian Brubach, Sarah Desmarais, Aaron Horowitz, Kristian Lum, and Suresh Venkatasubramanian. It\u2019s compaslicated: The messy relationship between rai datasets and algorithmic fairness benchmarks. arXiv preprint arXiv:2106.05498, 2021.|\n|[12]|Matias Barenstein. Propublica\u2019s compas data revisited. arXiv preprint arXiv:1906.04711, 2019.|\n|[13]|James Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyper-parameter optimization in hundreds of dimensions for vision architectures. In International conference on machine learning, pages 115\u2013123. PMLR, 2013.|\n|[14]|Tony A Blakely, Sunny CD Collings, and June Atkinson. Unemployment and suicide. evidence for a causal association? Journal of Epidemiology & Community Health, 57(8):594\u2013600, 2003.|\n|[15]|Vadim Borisov, Tobias Leemann, Kathrin Se\u00dfler, Johannes Haug, Martin Pawelczyk, and Gjergji Kasneci. Deep neural networks and tabular data: A survey. arXiv preprint arXiv:2110.01889, 2021.|\n|[16]|N Cable, A Sacker, and M Bartley. The effect of employment on psychological health in mid-adulthood: findings from the 1970 British cohort study. Journal of Epidemiology & Community Health, 62(5):e10\u2013e10, 2008.|\n|[17]|Centers for Disease Control and Prevention. National Diabetes Statistics Report. Link, 2022. Accessed: 2023-01-05.|\n|[18]|Centers for Disease Control and Prevention (CDC). National Health and Nutrition Examination Survey Questionnaire, Examination Protocol, and Laboratory Protocol (1999, 2001, 2003, 2005, 2007, 2009, 2011, 2013, 2015, 2017), 2017.|\n|[19]|Centers for Disease Control and Prevention (CDC). BRFSS Survey Data (2015, 2017, 2019, 2021), 2021.|\n|[20]|Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785\u2013794, 2016.|", "isPerfectTable": true, "csv": "\"[1]\",\"Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, and Mario Marchand. Domain-adversarial neural networks. arXiv preprint arXiv:1412.4446, 2014.\"\n\"[2]\",\"David Alvarez-Melis and Nicolo Fusi. Geometric dataset distances via optimal transport. Advances in Neural Information Processing Systems, 33:21428\u201321439, 2020.\"\n\"[3]\",\"American Heart Association. The Facts About High Blood Pressure. Link, 2017. Accessed: 2023-01-06.\"\n\"[4]\",\"American Heart Association. Health Threats from High Blood Pressure. Link, 2022. Accessed: 2023-01-06.\"\n\"[5]\",\"American National Election Studies (ANES). ANES Time Series Cumulative Data File, 1948-2020, 2020.\"\n\"[6]\",\"Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019.\"\n\"[7]\",\"American Diabetes Association. Economic costs of diabetes in the US in 2017. Diabetes care, 41(5):917\u2013928, 2018.\"\n\"[8]\",\"Algernon Austin. A good credit score did not protect Latino and Black borrowers. 2012.\"\n\"[9]\",\"Anas Awadalla, Mitchell Wortsman, Gabriel Ilharco, Sewon Min, Ian Magnusson, Hannaneh Hajishirzi, and Ludwig Schmidt. Exploring the landscape of distributional robustness for question answering models. arXiv preprint arXiv:2210.12517, 2022.\"\n\"[10]\",\"Clare Bambra and Terje A Eikemo. Welfare state regimes, unemployment and health: a comparative study of the relationship between unemployment and self-reported health in 23 European countries. Journal of Epidemiology & Community Health, 63(2):92\u201398, 2009.\"\n\"[11]\",\"Michelle Bao, Angela Zhou, Samantha Zottola, Brian Brubach, Sarah Desmarais, Aaron Horowitz, Kristian Lum, and Suresh Venkatasubramanian. It\u2019s compaslicated: The messy relationship between rai datasets and algorithmic fairness benchmarks. arXiv preprint arXiv:2106.05498, 2021.\"\n\"[12]\",\"Matias Barenstein. Propublica\u2019s compas data revisited. arXiv preprint arXiv:1906.04711, 2019.\"\n\"[13]\",\"James Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyper-parameter optimization in hundreds of dimensions for vision architectures. In International conference on machine learning, pages 115\u2013123. PMLR, 2013.\"\n\"[14]\",\"Tony A Blakely, Sunny CD Collings, and June Atkinson. Unemployment and suicide. evidence for a causal association? Journal of Epidemiology & Community Health, 57(8):594\u2013600, 2003.\"\n\"[15]\",\"Vadim Borisov, Tobias Leemann, Kathrin Se\u00dfler, Johannes Haug, Martin Pawelczyk, and Gjergji Kasneci. Deep neural networks and tabular data: A survey. arXiv preprint arXiv:2110.01889, 2021.\"\n\"[16]\",\"N Cable, A Sacker, and M Bartley. The effect of employment on psychological health in mid-adulthood: findings from the 1970 British cohort study. Journal of Epidemiology & Community Health, 62(5):e10\u2013e10, 2008.\"\n\"[17]\",\"Centers for Disease Control and Prevention. National Diabetes Statistics Report. Link, 2022. Accessed: 2023-01-05.\"\n\"[18]\",\"Centers for Disease Control and Prevention (CDC). National Health and Nutrition Examination Survey Questionnaire, Examination Protocol, and Laboratory Protocol (1999, 2001, 2003, 2005, 2007, 2009, 2011, 2013, 2015, 2017), 2017.\"\n\"[19]\",\"Centers for Disease Control and Prevention (CDC). BRFSS Survey Data (2015, 2017, 2019, 2021), 2021.\"\n\"[20]\",\"Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785\u2013794, 2016.\""}]}, {"page": 12, "text": "[21] Marshall H Chin, James X Zhang, and Katie Merrell. Diabetes in the african-american medicare\n      population: morbidity, quality of care, and resource utilization. Diabetes Care, 21(7):1090\u20131095,\n      1998.\n[22] Jung Hyun Choi, Alanna McCargo, Michael Neal, Laurie Goodman, and Caitlin Young. Ex-\n      plaining the black-white homeownership gap. Washington, DC: Urban Institute., 25:2021,\n      2019.\n[23] Giselle M Corbie-Smith. Minority recruitment and participation in health research. North\n      Carolina medical journal, 65(6):385\u2013387, 2004.\n[24] Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt. Retiring adult: New datasets\n      for fair machine learning. Advances in Neural Information Processing Systems, 34, 2021.\n[25] Anna Veronika Dorogush, Vasily Ershov, and Andrey Gulin. Catboost: gradient boosting with\n      categorical features support. arXiv preprint arXiv:1810.11363, 2018.\n[26] Scientific American Editors. Clinical trials have far too little racial and ethnic diversity. Scientific\n      American, 2018.\n[27] Edward Metz.            ASSISTments:        From Research to Practice at Scale in Educa-\n      tion. https://ies.ed.gov/blogs/research/post/assistments-from-research-to-\n      practice-at-scale-in-education, 2020. Accessed: 2023-06-01.\n[28] Federal Trade Commission. Press Release: Marketers of Blood-Pressure App Settle FTC\n      Charges Regarding Accuracy of App Readings.                https://www.ftc.gov/news-events/\n      news/press-releases/2016/12/marketers-blood-pressure-app-settle-ftc-\n      charges-regarding-accuracy-app-readings, 2016. Accessed: 2023-02-09.\n[29] Li Fei-Fei, Jia Deng, and Kai Li. Imagenet: Constructing a large-scale image database. Journal\n      of vision, 9(8):1037\u20131037, 2009.\n[30] FICO. The Explainable Machine Learning Challenge. https://community.fico.com/s/\n      explainable-machine-learning-challenge, 2019. Accessed: 2023-01-10.\n[31] Sorelle A Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam Choudhary, Evan P\n      Hamilton, and Derek Roth. A comparative study of fairness-enhancing interventions in machine\n      learning. In Proceedings of the conference on fairness, accountability, and transparency, pages\n      329\u2013338, 2019.\n[32] Fl\u00e1vio D Fuchs and Paul K Whelton. High blood pressure and cardiovascular disease. Hyper-\n      tension, 75(2):285\u2013292, 2020.\n[33] Joshua P Gardner, Zoran Popovi, and Ludwig Schmidt. Subgroup robustness grows on trees:\n      An empirical baseline investigation. In Advances in Neural Information Processing Systems,\n      2022.\n[34] Jort F Gemmeke, Daniel PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R Channing\n      Moore, Manoj Plakal, and Marvin Ritter. Audio set: An ontology and human-labeled dataset for\n      audio events. In 2017 IEEE international conference on acoustics, speech and signal processing\n      (ICASSP), pages 776\u2013780. IEEE, 2017.\n[35] Pieter Gijsbers, Erin LeDell, Janek Thomas, S\u00e9bastien Poirier, Bernd Bischl, and Joaquin\n      Vanschoren. An open source automl benchmark. arXiv preprint arXiv:1907.00909, 2019.\n[36] Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, and Artem Babenko. Revisiting deep\n      learning models for tabular data. Advances in Neural Information Processing Systems, 34:18932\u2013\n      18943, 2021.\n[37] L\u00e9o Grinsztajn, Edouard Oyallon, and Ga\u00ebl Varoquaux. Why do tree-based models still\n      outperform deep learning on tabular data? arXiv preprint arXiv:2207.08815, 2022.\n[38] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint\n      arXiv:2007.01434, 2020.\n[39] Hanson, Melanie.        Average Cost of College & Tuition.          https://educationdata.org/\n      average-cost-of-college, 2023. Accessed: 2023-06-01.\n[40] Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan.\n      Multitask learning and benchmarking with clinical time series data. Scientific data, 6(1):1\u201318,\n      2019.\n                                                     12", "md": "- Marshall H Chin, James X Zhang, and Katie Merrell. Diabetes in the African-American Medicare population: morbidity, quality of care, and resource utilization. Diabetes Care, 21(7):1090\u20131095, 1998.\n- Jung Hyun Choi, Alanna McCargo, Michael Neal, Laurie Goodman, and Caitlin Young. Explaining the black-white homeownership gap. Washington, DC: Urban Institute., 25:2021, 2019.\n- Giselle M Corbie-Smith. Minority recruitment and participation in health research. North Carolina Medical Journal, 65(6):385\u2013387, 2004.\n- Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt. Retiring adult: New datasets for fair machine learning. Advances in Neural Information Processing Systems, 34, 2021.\n- Anna Veronika Dorogush, Vasily Ershov, and Andrey Gulin. Catboost: gradient boosting with categorical features support. arXiv preprint arXiv:1810.11363, 2018.\n- Scientific American Editors. Clinical trials have far too little racial and ethnic diversity. Scientific American, 2018.\n- Edward Metz. ASSISTments: From Research to Practice at Scale in Education. Link, 2020. Accessed: 2023-06-01.\n- Federal Trade Commission. Press Release: Marketers of Blood-Pressure App Settle FTC Charges Regarding Accuracy of App Readings. Link, 2016. Accessed: 2023-02-09.\n- Li Fei-Fei, Jia Deng, and Kai Li. Imagenet: Constructing a large-scale image database. Journal of Vision, 9(8):1037\u20131037, 2009.\n- FICO. The Explainable Machine Learning Challenge. Link, 2019. Accessed: 2023-01-10.\n- Sorelle A Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam Choudhary, Evan P Hamilton, and Derek Roth. A comparative study of fairness-enhancing interventions in machine learning. In Proceedings of the conference on fairness, accountability, and transparency, pages 329\u2013338, 2019.\n- Fl\u00e1vio D Fuchs and Paul K Whelton. High blood pressure and cardiovascular disease. Hypertension, 75(2):285\u2013292, 2020.\n- Joshua P Gardner, Zoran Popovi, and Ludwig Schmidt. Subgroup robustness grows on trees: An empirical baseline investigation. In Advances in Neural Information Processing Systems, 2022.\n- Jort F Gemmeke, Daniel PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R Channing Moore, Manoj Plakal, and Marvin Ritter. Audio set: An ontology and human-labeled dataset for audio events. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 776\u2013780. IEEE, 2017.\n- Pieter Gijsbers, Erin LeDell, Janek Thomas, S\u00e9bastien Poirier, Bernd Bischl, and Joaquin Vanschoren. An open source automl benchmark. arXiv preprint arXiv:1907.00909, 2019.\n- Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, and Artem Babenko. Revisiting deep learning models for tabular data. Advances in Neural Information Processing Systems, 34:18932\u201318943, 2021.\n- L\u00e9o Grinsztajn, Edouard Oyallon, and Ga\u00ebl Varoquaux. Why do tree-based models still outperform deep learning on tabular data? arXiv preprint arXiv:2207.08815, 2022.\n- Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020.\n- Hanson, Melanie. Average Cost of College & Tuition. Link, 2023. Accessed: 2023-06-01.\n- Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan. Multitask learning and benchmarking with clinical time series data. Scientific Data, 6(1):1\u201318, 2019.", "images": [], "items": [{"type": "text", "value": "- Marshall H Chin, James X Zhang, and Katie Merrell. Diabetes in the African-American Medicare population: morbidity, quality of care, and resource utilization. Diabetes Care, 21(7):1090\u20131095, 1998.\n- Jung Hyun Choi, Alanna McCargo, Michael Neal, Laurie Goodman, and Caitlin Young. Explaining the black-white homeownership gap. Washington, DC: Urban Institute., 25:2021, 2019.\n- Giselle M Corbie-Smith. Minority recruitment and participation in health research. North Carolina Medical Journal, 65(6):385\u2013387, 2004.\n- Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt. Retiring adult: New datasets for fair machine learning. Advances in Neural Information Processing Systems, 34, 2021.\n- Anna Veronika Dorogush, Vasily Ershov, and Andrey Gulin. Catboost: gradient boosting with categorical features support. arXiv preprint arXiv:1810.11363, 2018.\n- Scientific American Editors. Clinical trials have far too little racial and ethnic diversity. Scientific American, 2018.\n- Edward Metz. ASSISTments: From Research to Practice at Scale in Education. Link, 2020. Accessed: 2023-06-01.\n- Federal Trade Commission. Press Release: Marketers of Blood-Pressure App Settle FTC Charges Regarding Accuracy of App Readings. Link, 2016. Accessed: 2023-02-09.\n- Li Fei-Fei, Jia Deng, and Kai Li. Imagenet: Constructing a large-scale image database. Journal of Vision, 9(8):1037\u20131037, 2009.\n- FICO. The Explainable Machine Learning Challenge. Link, 2019. Accessed: 2023-01-10.\n- Sorelle A Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam Choudhary, Evan P Hamilton, and Derek Roth. A comparative study of fairness-enhancing interventions in machine learning. In Proceedings of the conference on fairness, accountability, and transparency, pages 329\u2013338, 2019.\n- Fl\u00e1vio D Fuchs and Paul K Whelton. High blood pressure and cardiovascular disease. Hypertension, 75(2):285\u2013292, 2020.\n- Joshua P Gardner, Zoran Popovi, and Ludwig Schmidt. Subgroup robustness grows on trees: An empirical baseline investigation. In Advances in Neural Information Processing Systems, 2022.\n- Jort F Gemmeke, Daniel PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R Channing Moore, Manoj Plakal, and Marvin Ritter. Audio set: An ontology and human-labeled dataset for audio events. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 776\u2013780. IEEE, 2017.\n- Pieter Gijsbers, Erin LeDell, Janek Thomas, S\u00e9bastien Poirier, Bernd Bischl, and Joaquin Vanschoren. An open source automl benchmark. arXiv preprint arXiv:1907.00909, 2019.\n- Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, and Artem Babenko. Revisiting deep learning models for tabular data. Advances in Neural Information Processing Systems, 34:18932\u201318943, 2021.\n- L\u00e9o Grinsztajn, Edouard Oyallon, and Ga\u00ebl Varoquaux. Why do tree-based models still outperform deep learning on tabular data? arXiv preprint arXiv:2207.08815, 2022.\n- Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020.\n- Hanson, Melanie. Average Cost of College & Tuition. Link, 2023. Accessed: 2023-06-01.\n- Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan. Multitask learning and benchmarking with clinical time series data. Scientific Data, 6(1):1\u201318, 2019.", "md": "- Marshall H Chin, James X Zhang, and Katie Merrell. Diabetes in the African-American Medicare population: morbidity, quality of care, and resource utilization. Diabetes Care, 21(7):1090\u20131095, 1998.\n- Jung Hyun Choi, Alanna McCargo, Michael Neal, Laurie Goodman, and Caitlin Young. Explaining the black-white homeownership gap. Washington, DC: Urban Institute., 25:2021, 2019.\n- Giselle M Corbie-Smith. Minority recruitment and participation in health research. North Carolina Medical Journal, 65(6):385\u2013387, 2004.\n- Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt. Retiring adult: New datasets for fair machine learning. Advances in Neural Information Processing Systems, 34, 2021.\n- Anna Veronika Dorogush, Vasily Ershov, and Andrey Gulin. Catboost: gradient boosting with categorical features support. arXiv preprint arXiv:1810.11363, 2018.\n- Scientific American Editors. Clinical trials have far too little racial and ethnic diversity. Scientific American, 2018.\n- Edward Metz. ASSISTments: From Research to Practice at Scale in Education. Link, 2020. Accessed: 2023-06-01.\n- Federal Trade Commission. Press Release: Marketers of Blood-Pressure App Settle FTC Charges Regarding Accuracy of App Readings. Link, 2016. Accessed: 2023-02-09.\n- Li Fei-Fei, Jia Deng, and Kai Li. Imagenet: Constructing a large-scale image database. Journal of Vision, 9(8):1037\u20131037, 2009.\n- FICO. The Explainable Machine Learning Challenge. Link, 2019. Accessed: 2023-01-10.\n- Sorelle A Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam Choudhary, Evan P Hamilton, and Derek Roth. A comparative study of fairness-enhancing interventions in machine learning. In Proceedings of the conference on fairness, accountability, and transparency, pages 329\u2013338, 2019.\n- Fl\u00e1vio D Fuchs and Paul K Whelton. High blood pressure and cardiovascular disease. Hypertension, 75(2):285\u2013292, 2020.\n- Joshua P Gardner, Zoran Popovi, and Ludwig Schmidt. Subgroup robustness grows on trees: An empirical baseline investigation. In Advances in Neural Information Processing Systems, 2022.\n- Jort F Gemmeke, Daniel PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R Channing Moore, Manoj Plakal, and Marvin Ritter. Audio set: An ontology and human-labeled dataset for audio events. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 776\u2013780. IEEE, 2017.\n- Pieter Gijsbers, Erin LeDell, Janek Thomas, S\u00e9bastien Poirier, Bernd Bischl, and Joaquin Vanschoren. An open source automl benchmark. arXiv preprint arXiv:1907.00909, 2019.\n- Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, and Artem Babenko. Revisiting deep learning models for tabular data. Advances in Neural Information Processing Systems, 34:18932\u201318943, 2021.\n- L\u00e9o Grinsztajn, Edouard Oyallon, and Ga\u00ebl Varoquaux. Why do tree-based models still outperform deep learning on tabular data? arXiv preprint arXiv:2207.08815, 2022.\n- Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020.\n- Hanson, Melanie. Average Cost of College & Tuition. Link, 2023. Accessed: 2023-06-01.\n- Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan. Multitask learning and benchmarking with clinical time series data. Scientific Data, 6(1):1\u201318, 2019."}]}, {"page": 13, "text": "[41] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.\n      Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in\n      neural information processing systems, 30, 2017.\n[42] Julia Hippisley-Cox and Carol Coupland. Development and validation of qdiabetes-2018 risk\n      prediction algorithm to estimate future risk of type 2 diabetes: cohort study. bmj, 359, 2017.\n[43] Xin Huang, Ashish Khetan, Milan Cvitkovic, and Zohar Karnin. Tabtransformer: Tabular data\n      modeling using contextual embeddings. arXiv preprint arXiv:2012.06678, 2020.\n[44] Natalie Jacewicz. Why are health studies so white? The Atlantic, 2016.\n[45] Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad\n      Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii,\n      a freely accessible critical care database. Scientific data, 3(1):1\u20139, 2016.\n[46] Arlind Kadra, Marius Lindauer, Frank Hutter, and Josif Grabocka. Well-tuned simple nets excel\n      on tabular datasets. Advances in Neural Information Processing Systems, 34, 2021.\n[47] Michael Kahn. Diabetes Data Set, 1994.\n[48] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and\n      Tie-Yan Liu. Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural\n      information processing systems, 30, 2017.\n[49] Kevin L. Matthews II. There\u2019s a \u2019credit gap\u2019 between Black and white Americans, and it\u2019s\n      holding Black Americans back from building wealth. https://www.businessinsider.com/\n      personal-finance/credit-gap-black-americans-building-wealth-2021-1, 2021.\n      Accessed: 2023-01-10.\n[50] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay\n      Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al.\n      Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on Machine\n      Learning, pages 5637\u20135664. PMLR, 2021.\n[51] R. Kohavi and B. Becker. UCI adult data set., 1996.\n[52] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai\n      Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrap-\n      olation (rex). In International Conference on Machine Learning, pages 5815\u20135826. PMLR,\n      2021.\n[53] Daniel Levy, Yair Carmon, John C Duchi, and Aaron Sidford.               Large-scale methods for\n      distributionally robust optimization. Advances in Neural Information Processing Systems,\n      33:8847\u20138860, 2020.\n[54] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with\n      adversarial feature learning. In Proceedings of the IEEE conference on computer vision and\n      pattern recognition, pages 5400\u20135409, 2018.\n[55] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga,\n     Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. Holistic evaluation of\n      language models. arXiv preprint arXiv:2211.09110, 2022.\n[56] Thomas Liao, Rohan Taori, Inioluwa Deborah Raji, and Ludwig Schmidt. Are we learning\n      yet? a meta review of evaluation failures across machine learning. In Thirty-fifth Conference on\n      Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021.\n[57] Andrey Malinin, Neil Band, Yarin Gal, Mark Gales, Alexander Ganshin, German Chesnokov,\n      Alexey Noskov, Andrey Ploskonosov, Liudmila Prokhorenkova, Ivan Provilkov, et al. Shifts: A\n      dataset of real distributional shift across multiple large-scale tasks. In Thirty-fifth Conference\n      on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2022.\n[58] Kassandra Martinchek, Alex Carther, Breno Braga, Caleb Quakenbush, Signe-Mary McKernan,\n      Allison Feldman, JoElla Carman, Luis Melgar, Liza Hagerman, and Laura Swanson. Credit\n      health during the covid-19 pandemic. The Urban Data Institute, 2022.\n[59] Mark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan Karla\u0161, William Gaviria Rojas, Sudnya\n      Diamos, Greg Diamos, Lynn He, Douwe Kiela, David Jurado, et al. Dataperf: Benchmarks for\n      data-centric ai development. arXiv preprint arXiv:2207.10062, 2022.\n                                                   13", "md": "- Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.\n*Gans trained by a two time-scale update rule converge to a local nash equilibrium.*\n*Advances in neural information processing systems, 30*, 2017.\n- Julia Hippisley-Cox and Carol Coupland. Development and validation of qdiabetes-2018 risk\nprediction algorithm to estimate future risk of type 2 diabetes: cohort study. *bmj, 359*, 2017.\n- Xin Huang, Ashish Khetan, Milan Cvitkovic, and Zohar Karnin. Tabtransformer: Tabular data\nmodeling using contextual embeddings. *arXiv preprint arXiv:2012.06678*, 2020.\n- Natalie Jacewicz. *Why are health studies so white? The Atlantic*, 2016.\n- Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad\nGhassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii,\na freely accessible critical care database. *Scientific data, 3(1):1\u20139*, 2016.\n- Arlind Kadra, Marius Lindauer, Frank Hutter, and Josif Grabocka. Well-tuned simple nets excel\non tabular datasets. *Advances in Neural Information Processing Systems, 34*, 2021.\n- Michael Kahn. *Diabetes Data Set*, 1994.\n- Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and\nTie-Yan Liu. *Lightgbm: A highly efficient gradient boosting decision tree.* Advances in neural\ninformation processing systems, 30, 2017.\n- Kevin L. Matthews II. There\u2019s a \u2019credit gap\u2019 between Black and white Americans, and it\u2019s\nholding Black Americans back from building wealth. Link, 2021.\nAccessed: 2023-01-10.\n- Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay\nBalsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al.\n*Wilds: A benchmark of in-the-wild distribution shifts.* In International Conference on Machine\nLearning, pages 5637\u20135664. *PMLR*, 2021.\n- R. Kohavi and B. Becker. *UCI adult data set.*, 1996.\n- David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai\nZhang, Remi Le Priol, and Aaron Courville. *Out-of-distribution generalization via risk extrapolation (rex).*\nIn *International Conference on Machine Learning, pages 5815\u20135826. PMLR*, 2021.\n- Daniel Levy, Yair Carmon, John C Duchi, and Aaron Sidford. Large-scale methods for\ndistributionally robust optimization. Advances in Neural Information Processing Systems,\n33:8847\u20138860, 2020.\n- Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with\nadversarial feature learning. In Proceedings of the IEEE conference on computer vision and\npattern recognition, pages 5400\u20135409, 2018.\n- Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga,\nYian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. Holistic evaluation of\nlanguage models. *arXiv preprint arXiv:2211.09110*, 2022.\n- Thomas Liao, Rohan Taori, Inioluwa Deborah Raji, and Ludwig Schmidt. Are we learning\nyet? a meta review of evaluation failures across machine learning. In Thirty-fifth Conference on\nNeural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021.\n- Andrey Malinin, Neil Band, Yarin Gal, Mark Gales, Alexander Ganshin, German Chesnokov,\nAlexey Noskov, Andrey Ploskonosov, Liudmila Prokhorenkova, Ivan Provilkov, et al. Shifts: A\ndataset of real distributional shift across multiple large-scale tasks. In Thirty-fifth Conference\non Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2022.\n- Kassandra Martinchek, Alex Carther, Breno Braga, Caleb Quakenbush, Signe-Mary McKernan,\nAllison Feldman, JoElla Carman, Luis Melgar, Liza Hagerman, and Laura Swanson. Credit\nhealth during the covid-19 pandemic. *The Urban Data Institute*, 2022.\n- Mark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan Karla\u0161, William Gaviria Rojas, Sudnya\nDiamos, Greg Diamos, Lynn He, Douwe Kiela, David Jurado, et al. Dataperf: Benchmarks for\ndata-centric ai development. *arXiv preprint arXiv:2207.10062*, 2022.", "images": [], "items": [{"type": "text", "value": "- Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.\n*Gans trained by a two time-scale update rule converge to a local nash equilibrium.*\n*Advances in neural information processing systems, 30*, 2017.\n- Julia Hippisley-Cox and Carol Coupland. Development and validation of qdiabetes-2018 risk\nprediction algorithm to estimate future risk of type 2 diabetes: cohort study. *bmj, 359*, 2017.\n- Xin Huang, Ashish Khetan, Milan Cvitkovic, and Zohar Karnin. Tabtransformer: Tabular data\nmodeling using contextual embeddings. *arXiv preprint arXiv:2012.06678*, 2020.\n- Natalie Jacewicz. *Why are health studies so white? The Atlantic*, 2016.\n- Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad\nGhassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii,\na freely accessible critical care database. *Scientific data, 3(1):1\u20139*, 2016.\n- Arlind Kadra, Marius Lindauer, Frank Hutter, and Josif Grabocka. Well-tuned simple nets excel\non tabular datasets. *Advances in Neural Information Processing Systems, 34*, 2021.\n- Michael Kahn. *Diabetes Data Set*, 1994.\n- Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and\nTie-Yan Liu. *Lightgbm: A highly efficient gradient boosting decision tree.* Advances in neural\ninformation processing systems, 30, 2017.\n- Kevin L. Matthews II. There\u2019s a \u2019credit gap\u2019 between Black and white Americans, and it\u2019s\nholding Black Americans back from building wealth. Link, 2021.\nAccessed: 2023-01-10.\n- Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay\nBalsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al.\n*Wilds: A benchmark of in-the-wild distribution shifts.* In International Conference on Machine\nLearning, pages 5637\u20135664. *PMLR*, 2021.\n- R. Kohavi and B. Becker. *UCI adult data set.*, 1996.\n- David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai\nZhang, Remi Le Priol, and Aaron Courville. *Out-of-distribution generalization via risk extrapolation (rex).*\nIn *International Conference on Machine Learning, pages 5815\u20135826. PMLR*, 2021.\n- Daniel Levy, Yair Carmon, John C Duchi, and Aaron Sidford. Large-scale methods for\ndistributionally robust optimization. Advances in Neural Information Processing Systems,\n33:8847\u20138860, 2020.\n- Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with\nadversarial feature learning. In Proceedings of the IEEE conference on computer vision and\npattern recognition, pages 5400\u20135409, 2018.\n- Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga,\nYian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. Holistic evaluation of\nlanguage models. *arXiv preprint arXiv:2211.09110*, 2022.\n- Thomas Liao, Rohan Taori, Inioluwa Deborah Raji, and Ludwig Schmidt. Are we learning\nyet? a meta review of evaluation failures across machine learning. In Thirty-fifth Conference on\nNeural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021.\n- Andrey Malinin, Neil Band, Yarin Gal, Mark Gales, Alexander Ganshin, German Chesnokov,\nAlexey Noskov, Andrey Ploskonosov, Liudmila Prokhorenkova, Ivan Provilkov, et al. Shifts: A\ndataset of real distributional shift across multiple large-scale tasks. In Thirty-fifth Conference\non Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2022.\n- Kassandra Martinchek, Alex Carther, Breno Braga, Caleb Quakenbush, Signe-Mary McKernan,\nAllison Feldman, JoElla Carman, Luis Melgar, Liza Hagerman, and Laura Swanson. Credit\nhealth during the covid-19 pandemic. *The Urban Data Institute*, 2022.\n- Mark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan Karla\u0161, William Gaviria Rojas, Sudnya\nDiamos, Greg Diamos, Lynn He, Douwe Kiela, David Jurado, et al. Dataperf: Benchmarks for\ndata-centric ai development. *arXiv preprint arXiv:2207.10062*, 2022.", "md": "- Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.\n*Gans trained by a two time-scale update rule converge to a local nash equilibrium.*\n*Advances in neural information processing systems, 30*, 2017.\n- Julia Hippisley-Cox and Carol Coupland. Development and validation of qdiabetes-2018 risk\nprediction algorithm to estimate future risk of type 2 diabetes: cohort study. *bmj, 359*, 2017.\n- Xin Huang, Ashish Khetan, Milan Cvitkovic, and Zohar Karnin. Tabtransformer: Tabular data\nmodeling using contextual embeddings. *arXiv preprint arXiv:2012.06678*, 2020.\n- Natalie Jacewicz. *Why are health studies so white? The Atlantic*, 2016.\n- Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad\nGhassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii,\na freely accessible critical care database. *Scientific data, 3(1):1\u20139*, 2016.\n- Arlind Kadra, Marius Lindauer, Frank Hutter, and Josif Grabocka. Well-tuned simple nets excel\non tabular datasets. *Advances in Neural Information Processing Systems, 34*, 2021.\n- Michael Kahn. *Diabetes Data Set*, 1994.\n- Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and\nTie-Yan Liu. *Lightgbm: A highly efficient gradient boosting decision tree.* Advances in neural\ninformation processing systems, 30, 2017.\n- Kevin L. Matthews II. There\u2019s a \u2019credit gap\u2019 between Black and white Americans, and it\u2019s\nholding Black Americans back from building wealth. Link, 2021.\nAccessed: 2023-01-10.\n- Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay\nBalsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al.\n*Wilds: A benchmark of in-the-wild distribution shifts.* In International Conference on Machine\nLearning, pages 5637\u20135664. *PMLR*, 2021.\n- R. Kohavi and B. Becker. *UCI adult data set.*, 1996.\n- David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai\nZhang, Remi Le Priol, and Aaron Courville. *Out-of-distribution generalization via risk extrapolation (rex).*\nIn *International Conference on Machine Learning, pages 5815\u20135826. PMLR*, 2021.\n- Daniel Levy, Yair Carmon, John C Duchi, and Aaron Sidford. Large-scale methods for\ndistributionally robust optimization. Advances in Neural Information Processing Systems,\n33:8847\u20138860, 2020.\n- Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with\nadversarial feature learning. In Proceedings of the IEEE conference on computer vision and\npattern recognition, pages 5400\u20135409, 2018.\n- Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga,\nYian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. Holistic evaluation of\nlanguage models. *arXiv preprint arXiv:2211.09110*, 2022.\n- Thomas Liao, Rohan Taori, Inioluwa Deborah Raji, and Ludwig Schmidt. Are we learning\nyet? a meta review of evaluation failures across machine learning. In Thirty-fifth Conference on\nNeural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021.\n- Andrey Malinin, Neil Band, Yarin Gal, Mark Gales, Alexander Ganshin, German Chesnokov,\nAlexey Noskov, Andrey Ploskonosov, Liudmila Prokhorenkova, Ivan Provilkov, et al. Shifts: A\ndataset of real distributional shift across multiple large-scale tasks. In Thirty-fifth Conference\non Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2022.\n- Kassandra Martinchek, Alex Carther, Breno Braga, Caleb Quakenbush, Signe-Mary McKernan,\nAllison Feldman, JoElla Carman, Luis Melgar, Liza Hagerman, and Laura Swanson. Credit\nhealth during the covid-19 pandemic. *The Urban Data Institute*, 2022.\n- Mark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan Karla\u0161, William Gaviria Rojas, Sudnya\nDiamos, Greg Diamos, Lynn He, Douwe Kiela, David Jurado, et al. Dataperf: Benchmarks for\ndata-centric ai development. *arXiv preprint arXiv:2207.10062*, 2022."}]}, {"page": 14, "text": "[60] Megan Leonhart.      Black and Hispanic Americans often have lower credit scores\u2014here\u2019s\n      why they\u2019re hit harder.      https://www.cnbc.com/2021/01/28/black-and-hispanic-\n      americans-often-have-lower-credit-scores.html, 2021. Accessed: 2023-01-10.\n[61] John Miller, Karl Krauth, Benjamin Recht, and Ludwig Schmidt. The effect of natural distribu-\n      tion shift on question answering models. In International Conference on Machine Learning,\n      pages 6905\u20136916. PMLR, 2020.\n[62] John P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal\n      Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt. Accuracy on the line: on the strong\n      correlation between out-of-distribution and in-distribution generalization. In International\n      Conference on Machine Learning, pages 7721\u20137735. PMLR, 2021.\n[63] Scott M Montgomery, Mel J Bartley, Derek G Cook, and Michael Ej Wadsworth. Health and\n      social precursors of unemployment in young men in great britain. Journal of Epidemiology &\n      Community Health, 50(4):415\u2013422, 1996.\n[64] National Institutes of Health National Hearth, Lung, and Blood Institute. High Blood Pressure:\n      Causes and Risk Factors. https://www.nhlbi.nih.gov/health/high-blood-pressure/\n      causes, 2022. Accessed: 2023-01-08.\n[65] National Science Foundation. Directorate for Engineering Data Management Plans Guidance for\n      Principal Investigators. https://www.nsf.gov/eng/general/ENG_DMP_Policy.pdf, 2018.\n      Accessed: 2023-06-01.\n[66] Douglas Noble, Rohini Mathur, Tom Dent, Catherine Meads, and Trisha Greenhalgh. Risk\n      models and scores for type 2 diabetes: systematic review. Bmj, 343, 2011.\n[67] National Academies of Sciences Engineering, Medicine, et al. Health-care utilization as a proxy\n      in disability determination. 2018.\n[68] Sam S Oh, Joshua Galanter, Neeta Thakur, Maria Pino-Yanes, Nicolas E Barcelo, Marquitta J\n      White, Danielle M de Bruin, Ruth M Greenblatt, Kirsten Bibbins-Domingo, Alan HB Wu, et al.\n      Diversity in clinical and biomedical research: a promise yet to be fulfilled. PLoS medicine,\n      12(12):e1001918, 2015.\n[69] Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: an\n      asr corpus based on public domain audio books. In 2015 IEEE international conference on\n      acoustics, speech and signal processing (ICASSP), pages 5206\u20135210. IEEE, 2015.\n[70] Sergei Popov, Stanislav Morozov, and Artem Babenko. Neural oblivious decision ensembles\n      for deep learning on tabular data. arXiv preprint arXiv:1909.06312, 2019.\n[71] PR    Newswire.        Black   and   Hispanic   Americans     on  the   U.S.  financial  system:\n      \"The odds were always against me,\" new Credit Sesame survey finds.                       https:\n      //www.prnewswire.com/news-releases/black-and-hispanic-americans-on-the-\n      us-financial-system-the-odds-were-always-against-me-new-credit-sesame-\n      survey-finds-301215072.html, 2021. Accessed: 2023-01-10.\n[72] Sanjay Purushotham, Chuizheng Meng, Zhengping Che, and Yan Liu. Benchmarking deep\n      learning models on large healthcare datasets. Journal of biomedical informatics, 83:112\u2013134,\n      2018.\n[73] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet\n      classifiers generalize to imagenet? In International Conference on Machine Learning, pages\n      5389\u20135400. PMLR, 2019.\n[74] Matthew A Reyna, Chris Josef, Salman Seyedi, Russell Jeter, Supreeth P Shashikumar, M Bran-\n      don Westover, Ashish Sharma, Shamim Nemati, and Gari D Clifford. Early prediction of sepsis\n      from clinical data: the physionet/computing in cardiology challenge 2019. In 2019 Computing\n      in Cardiology (CinC), pages Page\u20131. IEEE, 2019.\n[75] Rebecca Roelofs, Vaishaal Shankar, Benjamin Recht, Sara Fridovich-Keil, Moritz Hardt, John\n      Miller, and Ludwig Schmidt. A meta-analysis of overfitting in machine learning. Advances in\n      Neural Information Processing Systems, 32, 2019.\n[76] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust\n      neural networks. In International Conference on Learning Representations, 2019.\n                                                  14", "md": "- [60] Megan Leonhart. Black and Hispanic Americans often have lower credit scores\u2014here\u2019s why they\u2019re hit harder. Link, 2021. Accessed: 2023-01-10.\n- [61] John Miller, Karl Krauth, Benjamin Recht, and Ludwig Schmidt. The effect of natural distribution shift on question answering models. In International Conference on Machine Learning, pages 6905\u20136916. PMLR, 2020.\n- [62] John P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt. Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization. In International Conference on Machine Learning, pages 7721\u20137735. PMLR, 2021.\n- [63] Scott M Montgomery, Mel J Bartley, Derek G Cook, and Michael Ej Wadsworth. Health and social precursors of unemployment in young men in Great Britain. Journal of Epidemiology & Community Health, 50(4):415\u2013422, 1996.\n- [64] National Institutes of Health National Hearth, Lung, and Blood Institute. High Blood Pressure: Causes and Risk Factors. Link, 2022. Accessed: 2023-01-08.\n- [65] National Science Foundation. Directorate for Engineering Data Management Plans Guidance for Principal Investigators. Link, 2018. Accessed: 2023-06-01.\n- [66] Douglas Noble, Rohini Mathur, Tom Dent, Catherine Meads, and Trisha Greenhalgh. Risk models and scores for type 2 diabetes: systematic review. Bmj, 343, 2011.\n- [67] National Academies of Sciences Engineering, Medicine, et al. Health-care utilization as a proxy in disability determination. 2018.\n- [68] Sam S Oh, Joshua Galanter, Neeta Thakur, Maria Pino-Yanes, Nicolas E Barcelo, Marquitta J White, Danielle M de Bruin, Ruth M Greenblatt, Kirsten Bibbins-Domingo, Alan HB Wu, et al. Diversity in clinical and biomedical research: a promise yet to be fulfilled. PLoS medicine, 12(12):e1001918, 2015.\n- [69] Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: an asr corpus based on public domain audio books. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP), pages 5206\u20135210. IEEE, 2015.\n- [70] Sergei Popov, Stanislav Morozov, and Artem Babenko. Neural oblivious decision ensembles for deep learning on tabular data. arXiv preprint arXiv:1909.06312, 2019.\n- [71] PR Newswire. Black and Hispanic Americans on the U.S. financial system: \"The odds were always against me,\" new Credit Sesame survey finds. Link, 2021. Accessed: 2023-01-10.\n- [72] Sanjay Purushotham, Chuizheng Meng, Zhengping Che, and Yan Liu. Benchmarking deep learning models on large healthcare datasets. Journal of biomedical informatics, 83:112\u2013134, 2018.\n- [73] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers generalize to imagenet? In International Conference on Machine Learning, pages 5389\u20135400. PMLR, 2019.\n- [74] Matthew A Reyna, Chris Josef, Salman Seyedi, Russell Jeter, Supreeth P Shashikumar, M Brandon Westover, Ashish Sharma, Shamim Nemati, and Gari D Clifford. Early prediction of sepsis from clinical data: the physionet/computing in cardiology challenge 2019. In 2019 Computing in Cardiology (CinC), pages Page\u20131. IEEE, 2019.\n- [75] Rebecca Roelofs, Vaishaal Shankar, Benjamin Recht, Sara Fridovich-Keil, Moritz Hardt, John Miller, and Ludwig Schmidt. A meta-analysis of overfitting in machine learning. Advances in Neural Information Processing Systems, 32, 2019.\n- [76] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks. In International Conference on Learning Representations, 2019.", "images": [], "items": [{"type": "text", "value": "- [60] Megan Leonhart. Black and Hispanic Americans often have lower credit scores\u2014here\u2019s why they\u2019re hit harder. Link, 2021. Accessed: 2023-01-10.\n- [61] John Miller, Karl Krauth, Benjamin Recht, and Ludwig Schmidt. The effect of natural distribution shift on question answering models. In International Conference on Machine Learning, pages 6905\u20136916. PMLR, 2020.\n- [62] John P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt. Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization. In International Conference on Machine Learning, pages 7721\u20137735. PMLR, 2021.\n- [63] Scott M Montgomery, Mel J Bartley, Derek G Cook, and Michael Ej Wadsworth. Health and social precursors of unemployment in young men in Great Britain. Journal of Epidemiology & Community Health, 50(4):415\u2013422, 1996.\n- [64] National Institutes of Health National Hearth, Lung, and Blood Institute. High Blood Pressure: Causes and Risk Factors. Link, 2022. Accessed: 2023-01-08.\n- [65] National Science Foundation. Directorate for Engineering Data Management Plans Guidance for Principal Investigators. Link, 2018. Accessed: 2023-06-01.\n- [66] Douglas Noble, Rohini Mathur, Tom Dent, Catherine Meads, and Trisha Greenhalgh. Risk models and scores for type 2 diabetes: systematic review. Bmj, 343, 2011.\n- [67] National Academies of Sciences Engineering, Medicine, et al. Health-care utilization as a proxy in disability determination. 2018.\n- [68] Sam S Oh, Joshua Galanter, Neeta Thakur, Maria Pino-Yanes, Nicolas E Barcelo, Marquitta J White, Danielle M de Bruin, Ruth M Greenblatt, Kirsten Bibbins-Domingo, Alan HB Wu, et al. Diversity in clinical and biomedical research: a promise yet to be fulfilled. PLoS medicine, 12(12):e1001918, 2015.\n- [69] Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: an asr corpus based on public domain audio books. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP), pages 5206\u20135210. IEEE, 2015.\n- [70] Sergei Popov, Stanislav Morozov, and Artem Babenko. Neural oblivious decision ensembles for deep learning on tabular data. arXiv preprint arXiv:1909.06312, 2019.\n- [71] PR Newswire. Black and Hispanic Americans on the U.S. financial system: \"The odds were always against me,\" new Credit Sesame survey finds. Link, 2021. Accessed: 2023-01-10.\n- [72] Sanjay Purushotham, Chuizheng Meng, Zhengping Che, and Yan Liu. Benchmarking deep learning models on large healthcare datasets. Journal of biomedical informatics, 83:112\u2013134, 2018.\n- [73] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers generalize to imagenet? In International Conference on Machine Learning, pages 5389\u20135400. PMLR, 2019.\n- [74] Matthew A Reyna, Chris Josef, Salman Seyedi, Russell Jeter, Supreeth P Shashikumar, M Brandon Westover, Ashish Sharma, Shamim Nemati, and Gari D Clifford. Early prediction of sepsis from clinical data: the physionet/computing in cardiology challenge 2019. In 2019 Computing in Cardiology (CinC), pages Page\u20131. IEEE, 2019.\n- [75] Rebecca Roelofs, Vaishaal Shankar, Benjamin Recht, Sara Fridovich-Keil, Moritz Hardt, John Miller, and Ludwig Schmidt. A meta-analysis of overfitting in machine learning. Advances in Neural Information Processing Systems, 32, 2019.\n- [76] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks. In International Conference on Learning Representations, 2019.", "md": "- [60] Megan Leonhart. Black and Hispanic Americans often have lower credit scores\u2014here\u2019s why they\u2019re hit harder. Link, 2021. Accessed: 2023-01-10.\n- [61] John Miller, Karl Krauth, Benjamin Recht, and Ludwig Schmidt. The effect of natural distribution shift on question answering models. In International Conference on Machine Learning, pages 6905\u20136916. PMLR, 2020.\n- [62] John P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt. Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization. In International Conference on Machine Learning, pages 7721\u20137735. PMLR, 2021.\n- [63] Scott M Montgomery, Mel J Bartley, Derek G Cook, and Michael Ej Wadsworth. Health and social precursors of unemployment in young men in Great Britain. Journal of Epidemiology & Community Health, 50(4):415\u2013422, 1996.\n- [64] National Institutes of Health National Hearth, Lung, and Blood Institute. High Blood Pressure: Causes and Risk Factors. Link, 2022. Accessed: 2023-01-08.\n- [65] National Science Foundation. Directorate for Engineering Data Management Plans Guidance for Principal Investigators. Link, 2018. Accessed: 2023-06-01.\n- [66] Douglas Noble, Rohini Mathur, Tom Dent, Catherine Meads, and Trisha Greenhalgh. Risk models and scores for type 2 diabetes: systematic review. Bmj, 343, 2011.\n- [67] National Academies of Sciences Engineering, Medicine, et al. Health-care utilization as a proxy in disability determination. 2018.\n- [68] Sam S Oh, Joshua Galanter, Neeta Thakur, Maria Pino-Yanes, Nicolas E Barcelo, Marquitta J White, Danielle M de Bruin, Ruth M Greenblatt, Kirsten Bibbins-Domingo, Alan HB Wu, et al. Diversity in clinical and biomedical research: a promise yet to be fulfilled. PLoS medicine, 12(12):e1001918, 2015.\n- [69] Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: an asr corpus based on public domain audio books. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP), pages 5206\u20135210. IEEE, 2015.\n- [70] Sergei Popov, Stanislav Morozov, and Artem Babenko. Neural oblivious decision ensembles for deep learning on tabular data. arXiv preprint arXiv:1909.06312, 2019.\n- [71] PR Newswire. Black and Hispanic Americans on the U.S. financial system: \"The odds were always against me,\" new Credit Sesame survey finds. Link, 2021. Accessed: 2023-01-10.\n- [72] Sanjay Purushotham, Chuizheng Meng, Zhengping Che, and Yan Liu. Benchmarking deep learning models on large healthcare datasets. Journal of biomedical informatics, 83:112\u2013134, 2018.\n- [73] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers generalize to imagenet? In International Conference on Machine Learning, pages 5389\u20135400. PMLR, 2019.\n- [74] Matthew A Reyna, Chris Josef, Salman Seyedi, Russell Jeter, Supreeth P Shashikumar, M Brandon Westover, Ashish Sharma, Shamim Nemati, and Gari D Clifford. Early prediction of sepsis from clinical data: the physionet/computing in cardiology challenge 2019. In 2019 Computing in Cardiology (CinC), pages Page\u20131. IEEE, 2019.\n- [75] Rebecca Roelofs, Vaishaal Shankar, Benjamin Recht, Sara Fridovich-Keil, Moritz Hardt, John Miller, and Ludwig Schmidt. A meta-analysis of overfitting in machine learning. Advances in Neural Information Processing Systems, 32, 2019.\n- [76] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks. In International Conference on Learning Representations, 2019."}]}, {"page": 15, "text": "[77] Satish Misra. Blood pressure app study shows that top health app was highly inaccurate. https:\n     //www.imedicalapps.com/2016/03/instant-blood-pressure-app-study/, 2016. Ac-\n     cessed: 2023-02-09.\n[78] Ravid Shwartz-Ziv and Amitai Armon. Tabular data: Deep learning is not all you need.\n     Information Fusion, 81:84\u201390, 2022.\n[79] Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C Bayan Bruss, and Tom Goldstein.\n     Saint: Improved neural networks for tabular data via row attention and contrastive pre-training.\n     arXiv preprint arXiv:2106.01342, 2021.\n[80] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid,\n     Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, et al.\n     Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.\n     arXiv preprint arXiv:2206.04615, 2022.\n[81] Beata Strack, Jonathan P DeShazo, Chris Gennings, Juan L Olmo, Sebastian Ventura,\n     Krzysztof J Cios, and John N Clore. Impact of hba1c measurement on hospital readmis-\n     sion rates: analysis of 70,000 clinical database patient records. BioMed research international,\n     2014, 2014.\n[82] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation.\n     In European conference on computer vision, pages 443\u2013450. Springer, 2016.\n[83] Guillermo E Umpierrez, Scott D Isaacs, Niloofar Bazargan, Xiangdong You, Leonard M Thaler,\n     and Abbas E Kitabchi. Hyperglycemia: an independent marker of in-hospital mortality in\n     patients with undiagnosed diabetes. The Journal of Clinical Endocrinology & Metabolism,\n     87(3):978\u2013982, 2002.\n[84] United States Department of Justice. Press Release: Justice Department Reaches $335 Mil-\n     lion Settlement to Resolve Allegations of Lending Discrimination by Countrywide Financial\n     Corporation. https://www.justice.gov/opa/pr/justice-department-reaches-335-\n     million-settlement-resolve-allegations-lending-discrimination, 2011.                           Ac-\n     cessed: 2023-01-10.\n[85] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n     Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information\n     processing systems, 30, 2017.\n[86] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman.\n     Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv\n     preprint arXiv:1804.07461, 2018.\n[87] Shirly Wang, Matthew BA McDermott, Geeticka Chauhan, Marzyeh Ghassemi, Michael C\n     Hughes, and Tristan Naumann. Mimic-extract: A data extraction, preprocessing, and represen-\n     tation pipeline for mimic-iii. In Proceedings of the ACM conference on health, inference, and\n     learning, pages 222\u2013235, 2020.\n[88] Zidian Xie, Olga Nikolayeva, Jiebo Luo, and Dongmei Li. Building risk prediction models for\n     type 2 diabetes using machine learning techniques. Preventing Chronic Disease, 16, 2019.\n[89] Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi Tian, and Wenjun Zhang.\n     Adversarial domain adaptation with domain mixup. In Proceedings of the AAAI Conference on\n     Artificial Intelligence, pages 6502\u20136509, 2020.\n[90] Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain\n     adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020.\n[91] Runtian Zhai, Chen Dan, Zico Kolter, and Pradeep Ravikumar. Doro: Distributional and outlier\n     robust optimization. In International Conference on Machine Learning, pages 12345\u201312355.\n     PMLR, 2021.\n[92] Jingzhao Zhang, Aditya Krishna Menon, Andreas Veit, Srinadh Bhojanapalli, Sanjiv Kumar,\n     and Suvrit Sra. Coping with label shift via distributionally robust optimisation. In International\n     Conference on Learning Representations, 2020.\n                                                  15", "md": "- [77] Satish Misra. Blood pressure app study shows that top health app was highly inaccurate. Link, 2016. Accessed: 2023-02-09.\n- [78] Ravid Shwartz-Ziv and Amitai Armon. Tabular data: Deep learning is not all you need. Information Fusion, 81:84\u201390, 2022.\n- [79] Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C Bayan Bruss, and Tom Goldstein. Saint: Improved neural networks for tabular data via row attention and contrastive pre-training. arXiv preprint arXiv:2106.01342, 2021.\n- [80] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.\n- [81] Beata Strack, Jonathan P DeShazo, Chris Gennings, Juan L Olmo, Sebastian Ventura, Krzysztof J Cios, and John N Clore. Impact of hba1c measurement on hospital readmission rates: analysis of 70,000 clinical database patient records. BioMed research international, 2014, 2014.\n- [82] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pages 443\u2013450. Springer, 2016.\n- [83] Guillermo E Umpierrez, Scott D Isaacs, Niloofar Bazargan, Xiangdong You, Leonard M Thaler, and Abbas E Kitabchi. Hyperglycemia: an independent marker of in-hospital mortality in patients with undiagnosed diabetes. The Journal of Clinical Endocrinology & Metabolism, 87(3):978\u2013982, 2002.\n- [84] United States Department of Justice. Press Release: Justice Department Reaches $335 Million Settlement to Resolve Allegations of Lending Discrimination by Countrywide Financial Corporation. Link, 2011. Accessed: 2023-01-10.\n- [85] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.\n- [86] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.\n- [87] Shirly Wang, Matthew BA McDermott, Geeticka Chauhan, Marzyeh Ghassemi, Michael C Hughes, and Tristan Naumann. Mimic-extract: A data extraction, preprocessing, and representation pipeline for mimic-iii. In Proceedings of the ACM conference on health, inference, and learning, pages 222\u2013235, 2020.\n- [88] Zidian Xie, Olga Nikolayeva, Jiebo Luo, and Dongmei Li. Building risk prediction models for type 2 diabetes using machine learning techniques. Preventing Chronic Disease, 16, 2019.\n- [89] Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi Tian, and Wenjun Zhang. Adversarial domain adaptation with domain mixup. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 6502\u20136509, 2020.\n- [90] Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020.\n- [91] Runtian Zhai, Chen Dan, Zico Kolter, and Pradeep Ravikumar. Doro: Distributional and outlier robust optimization. In International Conference on Machine Learning, pages 12345\u201312355. PMLR, 2021.\n- [92] Jingzhao Zhang, Aditya Krishna Menon, Andreas Veit, Srinadh Bhojanapalli, Sanjiv Kumar, and Suvrit Sra. Coping with label shift via distributionally robust optimisation. In International Conference on Learning Representations, 2020.", "images": [], "items": [{"type": "text", "value": "- [77] Satish Misra. Blood pressure app study shows that top health app was highly inaccurate. Link, 2016. Accessed: 2023-02-09.\n- [78] Ravid Shwartz-Ziv and Amitai Armon. Tabular data: Deep learning is not all you need. Information Fusion, 81:84\u201390, 2022.\n- [79] Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C Bayan Bruss, and Tom Goldstein. Saint: Improved neural networks for tabular data via row attention and contrastive pre-training. arXiv preprint arXiv:2106.01342, 2021.\n- [80] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.\n- [81] Beata Strack, Jonathan P DeShazo, Chris Gennings, Juan L Olmo, Sebastian Ventura, Krzysztof J Cios, and John N Clore. Impact of hba1c measurement on hospital readmission rates: analysis of 70,000 clinical database patient records. BioMed research international, 2014, 2014.\n- [82] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pages 443\u2013450. Springer, 2016.\n- [83] Guillermo E Umpierrez, Scott D Isaacs, Niloofar Bazargan, Xiangdong You, Leonard M Thaler, and Abbas E Kitabchi. Hyperglycemia: an independent marker of in-hospital mortality in patients with undiagnosed diabetes. The Journal of Clinical Endocrinology & Metabolism, 87(3):978\u2013982, 2002.\n- [84] United States Department of Justice. Press Release: Justice Department Reaches $335 Million Settlement to Resolve Allegations of Lending Discrimination by Countrywide Financial Corporation. Link, 2011. Accessed: 2023-01-10.\n- [85] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.\n- [86] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.\n- [87] Shirly Wang, Matthew BA McDermott, Geeticka Chauhan, Marzyeh Ghassemi, Michael C Hughes, and Tristan Naumann. Mimic-extract: A data extraction, preprocessing, and representation pipeline for mimic-iii. In Proceedings of the ACM conference on health, inference, and learning, pages 222\u2013235, 2020.\n- [88] Zidian Xie, Olga Nikolayeva, Jiebo Luo, and Dongmei Li. Building risk prediction models for type 2 diabetes using machine learning techniques. Preventing Chronic Disease, 16, 2019.\n- [89] Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi Tian, and Wenjun Zhang. Adversarial domain adaptation with domain mixup. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 6502\u20136509, 2020.\n- [90] Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020.\n- [91] Runtian Zhai, Chen Dan, Zico Kolter, and Pradeep Ravikumar. Doro: Distributional and outlier robust optimization. In International Conference on Machine Learning, pages 12345\u201312355. PMLR, 2021.\n- [92] Jingzhao Zhang, Aditya Krishna Menon, Andreas Veit, Srinadh Bhojanapalli, Sanjiv Kumar, and Suvrit Sra. Coping with label shift via distributionally robust optimisation. In International Conference on Learning Representations, 2020.", "md": "- [77] Satish Misra. Blood pressure app study shows that top health app was highly inaccurate. Link, 2016. Accessed: 2023-02-09.\n- [78] Ravid Shwartz-Ziv and Amitai Armon. Tabular data: Deep learning is not all you need. Information Fusion, 81:84\u201390, 2022.\n- [79] Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C Bayan Bruss, and Tom Goldstein. Saint: Improved neural networks for tabular data via row attention and contrastive pre-training. arXiv preprint arXiv:2106.01342, 2021.\n- [80] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.\n- [81] Beata Strack, Jonathan P DeShazo, Chris Gennings, Juan L Olmo, Sebastian Ventura, Krzysztof J Cios, and John N Clore. Impact of hba1c measurement on hospital readmission rates: analysis of 70,000 clinical database patient records. BioMed research international, 2014, 2014.\n- [82] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pages 443\u2013450. Springer, 2016.\n- [83] Guillermo E Umpierrez, Scott D Isaacs, Niloofar Bazargan, Xiangdong You, Leonard M Thaler, and Abbas E Kitabchi. Hyperglycemia: an independent marker of in-hospital mortality in patients with undiagnosed diabetes. The Journal of Clinical Endocrinology & Metabolism, 87(3):978\u2013982, 2002.\n- [84] United States Department of Justice. Press Release: Justice Department Reaches $335 Million Settlement to Resolve Allegations of Lending Discrimination by Countrywide Financial Corporation. Link, 2011. Accessed: 2023-01-10.\n- [85] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.\n- [86] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.\n- [87] Shirly Wang, Matthew BA McDermott, Geeticka Chauhan, Marzyeh Ghassemi, Michael C Hughes, and Tristan Naumann. Mimic-extract: A data extraction, preprocessing, and representation pipeline for mimic-iii. In Proceedings of the ACM conference on health, inference, and learning, pages 222\u2013235, 2020.\n- [88] Zidian Xie, Olga Nikolayeva, Jiebo Luo, and Dongmei Li. Building risk prediction models for type 2 diabetes using machine learning techniques. Preventing Chronic Disease, 16, 2019.\n- [89] Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi Tian, and Wenjun Zhang. Adversarial domain adaptation with domain mixup. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 6502\u20136509, 2020.\n- [90] Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020.\n- [91] Runtian Zhai, Chen Dan, Zico Kolter, and Pradeep Ravikumar. Doro: Distributional and outlier robust optimization. In International Conference on Machine Learning, pages 12345\u201312355. PMLR, 2021.\n- [92] Jingzhao Zhang, Aditya Krishna Menon, Andreas Veit, Srinadh Bhojanapalli, Sanjiv Kumar, and Suvrit Sra. Coping with label shift via distributionally robust optimisation. In International Conference on Learning Representations, 2020."}]}, {"page": 16, "text": " A    Acknowledgements\nThis work was supported by a Microsoft Grant for Customer Experience Innovation. This work\nwas also in part supported by the NSF AI Institute for Foundations of Machine Learning (IFML,\n CCF-2019844), Google, Open Philanthropy, and the Allen Institute for AI.\n Our research utilized computational resources and services provided by the Hyak computing cluster\n at the University of Washington.\n B    Benchmark Task Details\nThis section provides details on each of the benchmark tasks in TableShift. While we describe the\n data source for each task, we emphasize that TableShift does not host or distribute the data; each data\n source is publicly available (some require training or authorization, but all are available to the public).\n Based on our review of the datasets, we believe that the datasets do not contain personally identifiable\n information, offensive content, or proprietary information. For data collected from human subjects,\n the conditions of collection and the ethics approval under which the data were collected are described\n in the documentation associated with each dataset.\n B.1   Food Stamps\n Background: Food insecurity is a problem affecting more than 10% of households (13.5 million)\n across the United States in 20214. Various programs exist to provide families and individuals with\n supplemental income to reduce food insecurity. However, diminished social support services in\n many U.S. states limit the ability of outreach providers to ensure all aligible individuals are receiving\n available benefits. Low-cost, low-friction screening tools powered by machine learning models might\n provide useful information whether an individual is receiving food stamps in order to identify lilely\n candidates for both food security programs (\u201cfood stamps\u201d) and as a proxy for eligibility and need\n for additional support services.\n Data Source: We use person-level data from the American Community Survey (ACS)5. We filter the\n data for low-income adults aged 18-62 (i.e. selecting only adults below the social security eligibility\n age) in households with at least one child in the household. We use an income threshold of $30000\n based on the U.S. poverty threshold for a family with one child.\n Distribution Shift: In the United States, food stamps programs are managed at the state level. We\n apply domain shift over states, at the regional level. Specifically, we use the ACS census region as the\n split. The ACS includes 10 regions, which are: Puerto Rico; New England (Northeast region); Middle\nAtlantic (Northeast region); East North Central (Midwest region); West North Central (Midwest\n region); South Atlantic (South region); East South Central (South region); West South Central (South\n Region); Mountain (West region); Pacific (West region). We use East South Central (South region) as\n the holdout domain for this task.\nThis split parallels the case where a system is trained on a subset of states in a specific geographic\n area (perhaps in a localized study that draws participants or respondents from some geographic areas,\n but excludes other areas), and then applied to another. It also parallels the case where there is an\n interest in simulating the effect of a policy change. Finally, it mirrors the challenge of predicting an\n effect of a policy outcome (food stamps eligibility/recipiency) where differences in the underlying\n policy (different programs or eligibility across states) are a confounder.\n B.2   Income\n Background: Income is a widely-used measure of social stability. In addition, income is often used\n as a criteria for various social support programs. For example, in the United States, income is used\n to measure poverty, and can be used determine eligibility for various social services such as food\n stamps and medicaid. Income prediction has obvious commercial utility. Finally, income prediction\n    4https://www.ers.usda.gov/topics/food-nutrition-assistance/food-security-in-the-u-\n s/key-statistics-graphics/\n    5https://www.census.gov/programs-surveys/acs/about.html\n                                                    16", "md": "# Research Details\n\n## Acknowledgements\n\nThis work was supported by a Microsoft Grant for Customer Experience Innovation. This work was also in part supported by the NSF AI Institute for Foundations of Machine Learning (IFML, CCF-2019844), Google, Open Philanthropy, and the Allen Institute for AI. Our research utilized computational resources and services provided by the Hyak computing cluster at the University of Washington.\n\n## Benchmark Task Details\n\nThis section provides details on each of the benchmark tasks in TableShift. While we describe the data source for each task, we emphasize that TableShift does not host or distribute the data; each data source is publicly available (some require training or authorization, but all are available to the public). Based on our review of the datasets, we believe that the datasets do not contain personally identifiable information, offensive content, or proprietary information. For data collected from human subjects, the conditions of collection and the ethics approval under which the data were collected are described in the documentation associated with each dataset.\n\n### Food Stamps\n\nBackground: Food insecurity is a problem affecting more than 10% of households (13.5 million) across the United States in 20214. Various programs exist to provide families and individuals with supplemental income to reduce food insecurity. However, diminished social support services in many U.S. states limit the ability of outreach providers to ensure all eligible individuals are receiving available benefits. Low-cost, low-friction screening tools powered by machine learning models might provide useful information whether an individual is receiving food stamps in order to identify likely candidates for both food security programs (\"food stamps\") and as a proxy for eligibility and need for additional support services.\n\nData Source: We use person-level data from the American Community Survey (ACS)5. We filter the data for low-income adults aged 18-62 (i.e. selecting only adults below the social security eligibility age) in households with at least one child in the household. We use an income threshold of $30000 based on the U.S. poverty threshold for a family with one child.\n\nDistribution Shift: In the United States, food stamps programs are managed at the state level. We apply domain shift over states, at the regional level. Specifically, we use the ACS census region as the split. The ACS includes 10 regions, which are: Puerto Rico; New England (Northeast region); Middle Atlantic (Northeast region); East North Central (Midwest region); West North Central (Midwest region); South Atlantic (South region); East South Central (South region); West South Central (South Region); Mountain (West region); Pacific (West region). We use East South Central (South region) as the holdout domain for this task.\n\nThis split parallels the case where a system is trained on a subset of states in a specific geographic area (perhaps in a localized study that draws participants or respondents from some geographic areas, but excludes other areas), and then applied to another. It also parallels the case where there is an interest in simulating the effect of a policy change. Finally, it mirrors the challenge of predicting an effect of a policy outcome (food stamps eligibility/recipiency) where differences in the underlying policy (different programs or eligibility across states) are a confounder.\n\n### Income\n\nBackground: Income is a widely-used measure of social stability. In addition, income is often used as a criteria for various social support programs. For example, in the United States, income is used to measure poverty, and can be used determine eligibility for various social services such as food stamps and medicaid. Income prediction has obvious commercial utility. Finally, income prediction\n\nSources:\n- Food Security Statistics\n- American Community Survey", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Research Details", "md": "# Research Details"}, {"type": "heading", "lvl": 2, "value": "Acknowledgements", "md": "## Acknowledgements"}, {"type": "text", "value": "This work was supported by a Microsoft Grant for Customer Experience Innovation. This work was also in part supported by the NSF AI Institute for Foundations of Machine Learning (IFML, CCF-2019844), Google, Open Philanthropy, and the Allen Institute for AI. Our research utilized computational resources and services provided by the Hyak computing cluster at the University of Washington.", "md": "This work was supported by a Microsoft Grant for Customer Experience Innovation. This work was also in part supported by the NSF AI Institute for Foundations of Machine Learning (IFML, CCF-2019844), Google, Open Philanthropy, and the Allen Institute for AI. Our research utilized computational resources and services provided by the Hyak computing cluster at the University of Washington."}, {"type": "heading", "lvl": 2, "value": "Benchmark Task Details", "md": "## Benchmark Task Details"}, {"type": "text", "value": "This section provides details on each of the benchmark tasks in TableShift. While we describe the data source for each task, we emphasize that TableShift does not host or distribute the data; each data source is publicly available (some require training or authorization, but all are available to the public). Based on our review of the datasets, we believe that the datasets do not contain personally identifiable information, offensive content, or proprietary information. For data collected from human subjects, the conditions of collection and the ethics approval under which the data were collected are described in the documentation associated with each dataset.", "md": "This section provides details on each of the benchmark tasks in TableShift. While we describe the data source for each task, we emphasize that TableShift does not host or distribute the data; each data source is publicly available (some require training or authorization, but all are available to the public). Based on our review of the datasets, we believe that the datasets do not contain personally identifiable information, offensive content, or proprietary information. For data collected from human subjects, the conditions of collection and the ethics approval under which the data were collected are described in the documentation associated with each dataset."}, {"type": "heading", "lvl": 3, "value": "Food Stamps", "md": "### Food Stamps"}, {"type": "text", "value": "Background: Food insecurity is a problem affecting more than 10% of households (13.5 million) across the United States in 20214. Various programs exist to provide families and individuals with supplemental income to reduce food insecurity. However, diminished social support services in many U.S. states limit the ability of outreach providers to ensure all eligible individuals are receiving available benefits. Low-cost, low-friction screening tools powered by machine learning models might provide useful information whether an individual is receiving food stamps in order to identify likely candidates for both food security programs (\"food stamps\") and as a proxy for eligibility and need for additional support services.\n\nData Source: We use person-level data from the American Community Survey (ACS)5. We filter the data for low-income adults aged 18-62 (i.e. selecting only adults below the social security eligibility age) in households with at least one child in the household. We use an income threshold of $30000 based on the U.S. poverty threshold for a family with one child.\n\nDistribution Shift: In the United States, food stamps programs are managed at the state level. We apply domain shift over states, at the regional level. Specifically, we use the ACS census region as the split. The ACS includes 10 regions, which are: Puerto Rico; New England (Northeast region); Middle Atlantic (Northeast region); East North Central (Midwest region); West North Central (Midwest region); South Atlantic (South region); East South Central (South region); West South Central (South Region); Mountain (West region); Pacific (West region). We use East South Central (South region) as the holdout domain for this task.\n\nThis split parallels the case where a system is trained on a subset of states in a specific geographic area (perhaps in a localized study that draws participants or respondents from some geographic areas, but excludes other areas), and then applied to another. It also parallels the case where there is an interest in simulating the effect of a policy change. Finally, it mirrors the challenge of predicting an effect of a policy outcome (food stamps eligibility/recipiency) where differences in the underlying policy (different programs or eligibility across states) are a confounder.", "md": "Background: Food insecurity is a problem affecting more than 10% of households (13.5 million) across the United States in 20214. Various programs exist to provide families and individuals with supplemental income to reduce food insecurity. However, diminished social support services in many U.S. states limit the ability of outreach providers to ensure all eligible individuals are receiving available benefits. Low-cost, low-friction screening tools powered by machine learning models might provide useful information whether an individual is receiving food stamps in order to identify likely candidates for both food security programs (\"food stamps\") and as a proxy for eligibility and need for additional support services.\n\nData Source: We use person-level data from the American Community Survey (ACS)5. We filter the data for low-income adults aged 18-62 (i.e. selecting only adults below the social security eligibility age) in households with at least one child in the household. We use an income threshold of $30000 based on the U.S. poverty threshold for a family with one child.\n\nDistribution Shift: In the United States, food stamps programs are managed at the state level. We apply domain shift over states, at the regional level. Specifically, we use the ACS census region as the split. The ACS includes 10 regions, which are: Puerto Rico; New England (Northeast region); Middle Atlantic (Northeast region); East North Central (Midwest region); West North Central (Midwest region); South Atlantic (South region); East South Central (South region); West South Central (South Region); Mountain (West region); Pacific (West region). We use East South Central (South region) as the holdout domain for this task.\n\nThis split parallels the case where a system is trained on a subset of states in a specific geographic area (perhaps in a localized study that draws participants or respondents from some geographic areas, but excludes other areas), and then applied to another. It also parallels the case where there is an interest in simulating the effect of a policy change. Finally, it mirrors the challenge of predicting an effect of a policy outcome (food stamps eligibility/recipiency) where differences in the underlying policy (different programs or eligibility across states) are a confounder."}, {"type": "heading", "lvl": 3, "value": "Income", "md": "### Income"}, {"type": "text", "value": "Background: Income is a widely-used measure of social stability. In addition, income is often used as a criteria for various social support programs. For example, in the United States, income is used to measure poverty, and can be used determine eligibility for various social services such as food stamps and medicaid. Income prediction has obvious commercial utility. Finally, income prediction\n\nSources:\n- Food Security Statistics\n- American Community Survey", "md": "Background: Income is a widely-used measure of social stability. In addition, income is often used as a criteria for various social support programs. For example, in the United States, income is used to measure poverty, and can be used determine eligibility for various social services such as food stamps and medicaid. Income prediction has obvious commercial utility. Finally, income prediction\n\nSources:\n- Food Security Statistics\n- American Community Survey"}]}, {"page": 17, "text": "has a rich and unique history in the machine learning community, dating back to the \u201cadult income\u201d\ncensus dataset [51, 24].\nData Source: We use person-level data from the American Community Survey (ACS), as described\nin Task B.1. However, for the income prediction task, we use different filtering. We use the filtering\ndescribed in [24], which filters for adults aged at least 16 years old, who report working more than\nzero hours in the past month with reported income at least $100.00. We use an income threshold of\n$56, 000, which is the median income, as in [33].\nDistribution Shift: Income patterns can vary in many ways. Here, we focus on domain shift at\nthe regional level. We use the same splitting variable (US Census Region) described in Task B.1.\nHowever, for the income prediction task, we use New England (Northeast region) as the held-out\ndomain.\nB.3    Public Coverage\nBackground: People use health-care services to diagnose, cure, or treat disease or injury; to improve\nor maintain function; or to obtain information about their health status and prognosis [67]. In\nthe United States, health insurance is a critical component of individuals\u2019 ability to access health\ncare. Public health insurance exists, among other reasons, to provide affordable and accessible\nhealth insurance options for individuals not willing or able to purchase insurance through the private\ninsurance market. However, not all individuals have health insurance; only 88% of individuals in\nthe U.S had health insurance in 2019 according to the National Health Interview Survey (NHIS).\nIncreasing the proportion of people in the United States with health insurance is one of the four\nhealthcare objectives of the U.S. Department of Health and Human Services \u201cHealthy People 2030\u201d\ninitiative6. In this task, the goal is to predict whether an individual is covered by public health\ninsurance.\nData Source: We use person-level data from the American Community Survey (ACS), as described\nin Task B.1. However, for this task, we filter the data to include only low-income individuals (those\nwith income less than $30, 000) who are below the age of 65 (at which age all persons in the United\nStates are covered by Medicare). This is the same filtering used in [24, 33].\nDistribution Shift: Many factors can influence individuals\u2019 ability to access or utilize health\ninsurance and healthcare services. These include spoken language skills, mobility (whether an\nindividual has recently relocated), education, ease of obtaining services, and discriminatory practices\namong providers [67]. We focus on disability status, as this is a widely-known factor in obtaining\naccess to adequate health care [67]. Disability is also a particularly realistic factor in that disability\nstatus is likely to contribute to nonresponse to certain forms of data collection for many tabular data\nsources (including the four methods used to collect the ACS data: internet, mail, telephone, and\nin-person interviews) that can disadvantage persons with certain disabilities and decrease likelihood\nof participation or cause them to be excluded from study population.\nFor this task, the holdout domain Dtest consists of persons with disabilities; the training domain Dtrain\nconsists of persons who do not have disabilities. This simulates a situation where data collection\npractices excluded disabled persons, potentially through the factors described above.\nB.4    ACS Unemployment\nBackground: Unemployment is a key macroeconomic indicator and a measure of individual well-\nbeing. Unemployment is also linked to a variety of adverse outcomes, including socioeconomic,\npsychological, and health impacts [10, 16, 14, 63].\nData Source: We use person-level data from the American Community Survey (ACS), as described\nin Task B.1. However, for this task, we filter the data to include only individuals over the age of\n18 and below the age of 62 (at which age persons in the United States are eligible to receive Social\nSecurity income).\nDistribution Shift: Many factors are known to be related to unemployment. We focus on a form of\nsubpopulation shift, and use education level as the domain split. We use individuals with educational\n    6https://health.gov/healthypeople/objectives-and-data/browse-objectives/health-\ncare-access-and-quality/increase-proportion-people-health-insurance-ahs-01\n                                                    17", "md": "# Document\n\nhas a rich and unique history in the machine learning community, dating back to the \u201cadult income\u201d census dataset [51, 24].\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for the income prediction task, we use different filtering. We use the filtering described in [24], which filters for adults aged at least 16 years old, who report working more than zero hours in the past month with reported income at least $100.00. We use an income threshold of $56,000, which is the median income, as in [33].\n\nDistribution Shift: Income patterns can vary in many ways. Here, we focus on domain shift at the regional level. We use the same splitting variable (US Census Region) described in Task B.1. However, for the income prediction task, we use New England (Northeast region) as the held-out domain.\n\n### B.3 Public Coverage\n\nBackground: People use health-care services to diagnose, cure, or treat disease or injury; to improve or maintain function; or to obtain information about their health status and prognosis [67]. In the United States, health insurance is a critical component of individuals\u2019 ability to access health care. Public health insurance exists, among other reasons, to provide affordable and accessible health insurance options for individuals not willing or able to purchase insurance through the private insurance market. However, not all individuals have health insurance; only 88% of individuals in the U.S had health insurance in 2019 according to the National Health Interview Survey (NHIS). Increasing the proportion of people in the United States with health insurance is one of the four healthcare objectives of the U.S. Department of Health and Human Services \u201cHealthy People 2030\u201d initiative.\n\nIn this task, the goal is to predict whether an individual is covered by public health insurance.\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for this task, we filter the data to include only low-income individuals (those with income less than $30,000) who are below the age of 65 (at which age all persons in the United States are covered by Medicare). This is the same filtering used in [24, 33].\n\nDistribution Shift: Many factors can influence individuals\u2019 ability to access or utilize health insurance and healthcare services. These include spoken language skills, mobility (whether an individual has recently relocated), education, ease of obtaining services, and discriminatory practices among providers [67]. We focus on disability status, as this is a widely-known factor in obtaining access to adequate health care [67]. Disability is also a particularly realistic factor in that disability status is likely to contribute to nonresponse to certain forms of data collection for many tabular data sources (including the four methods used to collect the ACS data: internet, mail, telephone, and in-person interviews) that can disadvantage persons with certain disabilities and decrease likelihood of participation or cause them to be excluded from study population.\n\nFor this task, the holdout domain Dtest consists of persons with disabilities; the training domain Dtrain consists of persons who do not have disabilities. This simulates a situation where data collection practices excluded disabled persons, potentially through the factors described above.\n\n### B.4 ACS Unemployment\n\nBackground: Unemployment is a key macroeconomic indicator and a measure of individual well-being. Unemployment is also linked to a variety of adverse outcomes, including socioeconomic, psychological, and health impacts.\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for this task, we filter the data to include only individuals over the age of 18 and below the age of 62 (at which age persons in the United States are eligible to receive Social Security income).\n\nDistribution Shift: Many factors are known to be related to unemployment. We focus on a form of subpopulation shift, and use education level as the domain split. We use individuals with educational\n\nHealthy People 2030 initiative", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "has a rich and unique history in the machine learning community, dating back to the \u201cadult income\u201d census dataset [51, 24].\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for the income prediction task, we use different filtering. We use the filtering described in [24], which filters for adults aged at least 16 years old, who report working more than zero hours in the past month with reported income at least $100.00. We use an income threshold of $56,000, which is the median income, as in [33].\n\nDistribution Shift: Income patterns can vary in many ways. Here, we focus on domain shift at the regional level. We use the same splitting variable (US Census Region) described in Task B.1. However, for the income prediction task, we use New England (Northeast region) as the held-out domain.", "md": "has a rich and unique history in the machine learning community, dating back to the \u201cadult income\u201d census dataset [51, 24].\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for the income prediction task, we use different filtering. We use the filtering described in [24], which filters for adults aged at least 16 years old, who report working more than zero hours in the past month with reported income at least $100.00. We use an income threshold of $56,000, which is the median income, as in [33].\n\nDistribution Shift: Income patterns can vary in many ways. Here, we focus on domain shift at the regional level. We use the same splitting variable (US Census Region) described in Task B.1. However, for the income prediction task, we use New England (Northeast region) as the held-out domain."}, {"type": "heading", "lvl": 3, "value": "B.3 Public Coverage", "md": "### B.3 Public Coverage"}, {"type": "text", "value": "Background: People use health-care services to diagnose, cure, or treat disease or injury; to improve or maintain function; or to obtain information about their health status and prognosis [67]. In the United States, health insurance is a critical component of individuals\u2019 ability to access health care. Public health insurance exists, among other reasons, to provide affordable and accessible health insurance options for individuals not willing or able to purchase insurance through the private insurance market. However, not all individuals have health insurance; only 88% of individuals in the U.S had health insurance in 2019 according to the National Health Interview Survey (NHIS). Increasing the proportion of people in the United States with health insurance is one of the four healthcare objectives of the U.S. Department of Health and Human Services \u201cHealthy People 2030\u201d initiative.\n\nIn this task, the goal is to predict whether an individual is covered by public health insurance.\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for this task, we filter the data to include only low-income individuals (those with income less than $30,000) who are below the age of 65 (at which age all persons in the United States are covered by Medicare). This is the same filtering used in [24, 33].\n\nDistribution Shift: Many factors can influence individuals\u2019 ability to access or utilize health insurance and healthcare services. These include spoken language skills, mobility (whether an individual has recently relocated), education, ease of obtaining services, and discriminatory practices among providers [67]. We focus on disability status, as this is a widely-known factor in obtaining access to adequate health care [67]. Disability is also a particularly realistic factor in that disability status is likely to contribute to nonresponse to certain forms of data collection for many tabular data sources (including the four methods used to collect the ACS data: internet, mail, telephone, and in-person interviews) that can disadvantage persons with certain disabilities and decrease likelihood of participation or cause them to be excluded from study population.\n\nFor this task, the holdout domain Dtest consists of persons with disabilities; the training domain Dtrain consists of persons who do not have disabilities. This simulates a situation where data collection practices excluded disabled persons, potentially through the factors described above.", "md": "Background: People use health-care services to diagnose, cure, or treat disease or injury; to improve or maintain function; or to obtain information about their health status and prognosis [67]. In the United States, health insurance is a critical component of individuals\u2019 ability to access health care. Public health insurance exists, among other reasons, to provide affordable and accessible health insurance options for individuals not willing or able to purchase insurance through the private insurance market. However, not all individuals have health insurance; only 88% of individuals in the U.S had health insurance in 2019 according to the National Health Interview Survey (NHIS). Increasing the proportion of people in the United States with health insurance is one of the four healthcare objectives of the U.S. Department of Health and Human Services \u201cHealthy People 2030\u201d initiative.\n\nIn this task, the goal is to predict whether an individual is covered by public health insurance.\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for this task, we filter the data to include only low-income individuals (those with income less than $30,000) who are below the age of 65 (at which age all persons in the United States are covered by Medicare). This is the same filtering used in [24, 33].\n\nDistribution Shift: Many factors can influence individuals\u2019 ability to access or utilize health insurance and healthcare services. These include spoken language skills, mobility (whether an individual has recently relocated), education, ease of obtaining services, and discriminatory practices among providers [67]. We focus on disability status, as this is a widely-known factor in obtaining access to adequate health care [67]. Disability is also a particularly realistic factor in that disability status is likely to contribute to nonresponse to certain forms of data collection for many tabular data sources (including the four methods used to collect the ACS data: internet, mail, telephone, and in-person interviews) that can disadvantage persons with certain disabilities and decrease likelihood of participation or cause them to be excluded from study population.\n\nFor this task, the holdout domain Dtest consists of persons with disabilities; the training domain Dtrain consists of persons who do not have disabilities. This simulates a situation where data collection practices excluded disabled persons, potentially through the factors described above."}, {"type": "heading", "lvl": 3, "value": "B.4 ACS Unemployment", "md": "### B.4 ACS Unemployment"}, {"type": "text", "value": "Background: Unemployment is a key macroeconomic indicator and a measure of individual well-being. Unemployment is also linked to a variety of adverse outcomes, including socioeconomic, psychological, and health impacts.\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for this task, we filter the data to include only individuals over the age of 18 and below the age of 62 (at which age persons in the United States are eligible to receive Social Security income).\n\nDistribution Shift: Many factors are known to be related to unemployment. We focus on a form of subpopulation shift, and use education level as the domain split. We use individuals with educational\n\nHealthy People 2030 initiative", "md": "Background: Unemployment is a key macroeconomic indicator and a measure of individual well-being. Unemployment is also linked to a variety of adverse outcomes, including socioeconomic, psychological, and health impacts.\n\nData Source: We use person-level data from the American Community Survey (ACS), as described in Task B.1. However, for this task, we filter the data to include only individuals over the age of 18 and below the age of 62 (at which age persons in the United States are eligible to receive Social Security income).\n\nDistribution Shift: Many factors are known to be related to unemployment. We focus on a form of subpopulation shift, and use education level as the domain split. We use individuals with educational\n\nHealthy People 2030 initiative"}]}, {"page": 18, "text": "attainment of GED (high school diploma equivalent) or higher as the training population Dtrain, and\nindividuals without high school-level education as Dtest. This simulates a survey collection with a\nbiased sample that systematically excludes such persons.\nB.5    Diabetes\nBackground: Diabetes is a chronic disease that affects at least 37.7million people in the United States\n(11.3% of the U.S population); it is estimated that an additional 96 million adults have prediabetes.7\nDiabetes increases the risk of a variety of other health conditions, including stroke, kidney failure,\nrenal complications, peripheral vascular disease, heart disease, and death. The economic cost of\ndiabetes is also significant: The total estimated cost of diagnosed diabetes in 2017 is $327 billion [7].\nCare for people with diagnosed diabetes accounts for 1 in 4 health care dollars in the U.S. \u2013 more\nthan half of that expenditure is directly attributable to diabetes [7].\nEarly detection of diabetes thus stands to have a significant impact, allowing for clinical intervention\nand potentially reducing the prevalence of diabetes. Further, even prediabetes is ackowledged to have\nsignificant impacts both on health outcomes and quality of life [7], and early detection if high diabetes\nrisk could serve to identify prediabetic individuals. There exists a considerable prior literature on\nmodels for early diabetes prediction, e.g. [88, 66, 42]\nData Source: We use data provided by the Behavioral Risk Factors Surveillance System (BRFSS)8.\nBRFSS is a large-scale telephone survey conducted by the Centers of Disease Control and Prevention.\nBRFSS collects data about U.S. residents regarding their health-related risk behaviors, chronic health\nconditions, and use of preventive services. BRFSS collects data in all 50 states as well as the District\nof Columbia and three U.S. territories. BRFSS completes more than 400,000 adult interviews each\nyear, making it the largest continuously conducted health survey system in the world. BRFSS annual\nsurvey data from 2017-2021 is currently available from the CDC.\nThe BRFSS is composed of three components: \u2019fixed core\u2019 questions, asked every year, \u2019rotating\ncore\u2019, asked every other year, and \u2019emerging core\u2019. Since some of our features come from the rotating\ncore, we only use every-other-year data sources; otherwise many features would be empty for the\nintervening years.\nFor the Diabetes prediction task, we use a set of features related to several known indicators for dia-\nbetes derived from [88]. These risk factors are general physical health, high cholesterol, BMI/obesity,\nsmoking, the presence of other chronic health conditions (stroke, coronary heart diseas), diet, alcohol\nconsumption, exercise, household income, marital status, time since last checkup, education level,\nhealth care coverage, and mental health. For each risk factor, we extract a set of relevant features from\nthe BRFSS foxed core and rotating core questionnaires. We also use a shared set of demographic\nindicators (race, sex, state, survey year, and a question related to income level). The prediction target\nis a binary indicator for whether the respondent has ever been told they have diabetes.\nDistribution Shift: While diabetes affects a large fraction of the overall population, diabetes risk\nvaries according to several demographic factors. One such factor is race/ethnicity [42, 17], with all\nother race-ethnicity groups reported in the 2022 CDC National Diabetes Statistics Report displaying\nhigher risk than \u2018White non-Hispanic\u2019 individuals[17]. Compounding this issue, it has been widely\nacknowledged that health studiy populations tend to be biased toward white European-Americans\n[23, 68, 26, 44]. As a result, these studies have tended to focus on risk factors affecting white\npopulations at the expense of identifying risk factors for nonwhite populations [44], despite distinct\ndifferences in how these populations are affected by various disease risk factors, differences in\nindividuals\u2019 genetic factors, and differences in how they respond to medication across racial and\nethnic populations. This disparity is a contributing factor to race-based disparities in treatment for\ndiabetes [21].\nIn order to simulate the domain gap induced by these real-world differences in study vs. deployment\npopulations, we partition the benchmark task by race/ethnicity. We use \u201cWhite non-Hispanic\u201d-\nidentified individuals as the training domain, and all other race/ethnicity groups as the target domain.\n    7https://www.cdc.gov/diabetes/health-equity/diabetes-by-the-numbers.html\n    8https://www.cdc.gov/brfss/index.html\n                                                    18", "md": "# Diabetes Prediction Task\n\n## Attainment of GED (high school diploma equivalent) or higher\n\nWe consider individuals with the attainment of GED (high school diploma equivalent) or higher as the training population Dtrain, and individuals without high school-level education as Dtest. This simulates a survey collection with a biased sample that systematically excludes such persons.\n\n## Diabetes\n\nBackground: Diabetes is a chronic disease that affects at least 37.7 million people in the United States (11.3% of the U.S population); it is estimated that an additional 96 million adults have prediabetes. Diabetes increases the risk of a variety of other health conditions, including stroke, kidney failure, renal complications, peripheral vascular disease, heart disease, and death. The economic cost of diabetes is also significant: The total estimated cost of diagnosed diabetes in 2017 is $327 billion. Care for people with diagnosed diabetes accounts for 1 in 4 health care dollars in the U.S. \u2013 more than half of that expenditure is directly attributable to diabetes.\n\nEarly detection of diabetes thus stands to have a significant impact, allowing for clinical intervention and potentially reducing the prevalence of diabetes. Even prediabetes is acknowledged to have significant impacts both on health outcomes and quality of life, and early detection of high diabetes risk could serve to identify prediabetic individuals. There exists a considerable prior literature on models for early diabetes prediction.\n\nData Source: We use data provided by the Behavioral Risk Factors Surveillance System (BRFSS). BRFSS is a large-scale telephone survey conducted by the Centers of Disease Control and Prevention. BRFSS collects data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world. BRFSS annual survey data from 2017-2021 is currently available from the CDC.\n\nDistribution Shift: While diabetes affects a large fraction of the overall population, diabetes risk varies according to several demographic factors. One such factor is race/ethnicity, with all other race-ethnicity groups reported in the 2022 CDC National Diabetes Statistics Report displaying higher risk than \u2018White non-Hispanic\u2019 individuals. In order to simulate the domain gap induced by these real-world differences in study vs. deployment populations, we partition the benchmark task by race/ethnicity. We use \u201cWhite non-Hispanic\u201d-identified individuals as the training domain, and all other race/ethnicity groups as the target domain.\n\nSources: CDC Diabetes Statistics, BRFSS", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Diabetes Prediction Task", "md": "# Diabetes Prediction Task"}, {"type": "heading", "lvl": 2, "value": "Attainment of GED (high school diploma equivalent) or higher", "md": "## Attainment of GED (high school diploma equivalent) or higher"}, {"type": "text", "value": "We consider individuals with the attainment of GED (high school diploma equivalent) or higher as the training population Dtrain, and individuals without high school-level education as Dtest. This simulates a survey collection with a biased sample that systematically excludes such persons.", "md": "We consider individuals with the attainment of GED (high school diploma equivalent) or higher as the training population Dtrain, and individuals without high school-level education as Dtest. This simulates a survey collection with a biased sample that systematically excludes such persons."}, {"type": "heading", "lvl": 2, "value": "Diabetes", "md": "## Diabetes"}, {"type": "text", "value": "Background: Diabetes is a chronic disease that affects at least 37.7 million people in the United States (11.3% of the U.S population); it is estimated that an additional 96 million adults have prediabetes. Diabetes increases the risk of a variety of other health conditions, including stroke, kidney failure, renal complications, peripheral vascular disease, heart disease, and death. The economic cost of diabetes is also significant: The total estimated cost of diagnosed diabetes in 2017 is $327 billion. Care for people with diagnosed diabetes accounts for 1 in 4 health care dollars in the U.S. \u2013 more than half of that expenditure is directly attributable to diabetes.\n\nEarly detection of diabetes thus stands to have a significant impact, allowing for clinical intervention and potentially reducing the prevalence of diabetes. Even prediabetes is acknowledged to have significant impacts both on health outcomes and quality of life, and early detection of high diabetes risk could serve to identify prediabetic individuals. There exists a considerable prior literature on models for early diabetes prediction.\n\nData Source: We use data provided by the Behavioral Risk Factors Surveillance System (BRFSS). BRFSS is a large-scale telephone survey conducted by the Centers of Disease Control and Prevention. BRFSS collects data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world. BRFSS annual survey data from 2017-2021 is currently available from the CDC.\n\nDistribution Shift: While diabetes affects a large fraction of the overall population, diabetes risk varies according to several demographic factors. One such factor is race/ethnicity, with all other race-ethnicity groups reported in the 2022 CDC National Diabetes Statistics Report displaying higher risk than \u2018White non-Hispanic\u2019 individuals. In order to simulate the domain gap induced by these real-world differences in study vs. deployment populations, we partition the benchmark task by race/ethnicity. We use \u201cWhite non-Hispanic\u201d-identified individuals as the training domain, and all other race/ethnicity groups as the target domain.\n\nSources: CDC Diabetes Statistics, BRFSS", "md": "Background: Diabetes is a chronic disease that affects at least 37.7 million people in the United States (11.3% of the U.S population); it is estimated that an additional 96 million adults have prediabetes. Diabetes increases the risk of a variety of other health conditions, including stroke, kidney failure, renal complications, peripheral vascular disease, heart disease, and death. The economic cost of diabetes is also significant: The total estimated cost of diagnosed diabetes in 2017 is $327 billion. Care for people with diagnosed diabetes accounts for 1 in 4 health care dollars in the U.S. \u2013 more than half of that expenditure is directly attributable to diabetes.\n\nEarly detection of diabetes thus stands to have a significant impact, allowing for clinical intervention and potentially reducing the prevalence of diabetes. Even prediabetes is acknowledged to have significant impacts both on health outcomes and quality of life, and early detection of high diabetes risk could serve to identify prediabetic individuals. There exists a considerable prior literature on models for early diabetes prediction.\n\nData Source: We use data provided by the Behavioral Risk Factors Surveillance System (BRFSS). BRFSS is a large-scale telephone survey conducted by the Centers of Disease Control and Prevention. BRFSS collects data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world. BRFSS annual survey data from 2017-2021 is currently available from the CDC.\n\nDistribution Shift: While diabetes affects a large fraction of the overall population, diabetes risk varies according to several demographic factors. One such factor is race/ethnicity, with all other race-ethnicity groups reported in the 2022 CDC National Diabetes Statistics Report displaying higher risk than \u2018White non-Hispanic\u2019 individuals. In order to simulate the domain gap induced by these real-world differences in study vs. deployment populations, we partition the benchmark task by race/ethnicity. We use \u201cWhite non-Hispanic\u201d-identified individuals as the training domain, and all other race/ethnicity groups as the target domain.\n\nSources: CDC Diabetes Statistics, BRFSS"}]}, {"page": 19, "text": "B.6   Hypertension\nBackground: Hypertension, or systolic blood pressure (typically systolic pressure 130 mm Hg or\nhigher or diastolic 80 or higher) affects nearly half of Americans [3]. Hypertension is sometimes\ncalled a \u201csilent killer\u201d because in most cases, there are no obvious symptoms of hypertension [3];\nthis would make an accurate at-risk model of hypertension useful. When left untreated, hypertension\nis associated with the strongest evidence for causation of all risk factors for heart attack and other\ncardiovascular disease [32]. Hypertension also increases the risk of stroke, kidney damage, vision\nloss, insulin resistance, and other adverse outcomes [4]. While existing tools have attempted to\npredict blood pressure without the use of a cuff (the gold-standard measurement of blood pressure),\nthese tools are still significantly less accurate (see e.g. [77, 28]), and there is an ongoing need for\neffective blood pressure measurement.\nData Source: We use BRFSS as the raw data source, as described in Task B.5 above. However,\nfor the hypertension prediction task, we use features related to the following set of risk factors for\nhypertension via [64]: Age, family history and genetics, other medical conditions (e.g. diabetes,\nvarious forms of cancer), race/ethnicity, sex, and social and economic factors (income, employment\nstatus). We collect all survey questions related to these risk factors and use them as the predictors\nfor this task, along with a shared set of demographic indicators (race, sex, state, survey year, and a\nquestion related to income level).\nDistribution Shift: We use BMI category as the domain splitting variable. Individuals with BMI\nidentified as \u201coverweight\u201d or \u201cobese\u201d are in the held-out domain, and those identified as \u201cunder-\nweight\u201d or \u201cnormal weight\u201d are in the training domain. This simulates a model being deployed\nunder subpopulation shift, where the target population has different (higher) BMI than the training\npopulation.\nB.7   Voting\nBackground Understanding participation in elections is a critical task for policymakers, politicians,\nand those with an interest in democracy. In the 2020 United States presidential election, for example,\nvoter turnout reached record levels, but it is estimated that only 66.8% of eligible individuals voted\naccording to the U.S. Census9. Additionally, so-called \u201clikely voter models,\u201d that predict which\nindividuals will vote in an electio, are widely acknowledged as critical to polling and campaigning in\nU.S. politics. Predicting whether an individual will vote is notoriously diffi  cult; one reason for this\nchallenge is that domain shift is a fundamental reality of such modeling (presidential elections only\noccur every four years, after which significant political and demographic changes occur prior to the\nnext presidential election).\nThe prediction target for this dataset is to determine whether an individual will vote in the U.S\npresidential election, from a detailed questionnaire.\nData Source We use data from the American National Election Studies (ANES)10. Since 1948,\nANES has conducted surveys, usually administered as in-person interviews, during most years of\nnational elections. This series of studies, known as the ANES \u201cTime Series,\u201d constitutes a pre-election\ninterview and a post-election interview during years of Presidential elections, along with other data\nsources. Topics cover voting behavior and the elections, together with questions on public opinion\nand attitudes.\nWe use features derived from the ANES Time Series. From the pool of over 500 questions in the\nANES Time Series, we extract a set of features related to Americans\u2019 voting behavior, including their\nsocial and political attitudes, opinions about elected leaders, and media consumption habits.\nDomain Shift We introduce a domain split by geographic region. We use the ANES Census Region\nfeature, where the out-of-domain region is the region representing the southern United States (AL,\nAR, DE, D.C., FL, GA, KY, LA, MD, MS, NC, OK, SC,TN, TX, VA, WV). This simulates a study in\nwhich voter data is collected in one part of the country, and the goal is to infer voting behavior in\nanother geographic region; this is a common occurence with polling data, particularly during the U.S.\nprimaries, which occur over a period of several weeks at the state level.\n   9https://www.census.gov/library/stories/2021/04/record-high-turnout-in-2020-\ngeneral-election.html\n   10\n    https://electionstudies.org/\n                                                   19", "md": "# Hypertension and Voting\n\n## Hypertension\n\nBackground: Hypertension, or systolic blood pressure (typically systolic pressure 130 mm Hg or higher or diastolic 80 or higher) affects nearly half of Americans [3]. Hypertension is sometimes called a \u201csilent killer\u201d because in most cases, there are no obvious symptoms of hypertension [3]; this would make an accurate at-risk model of hypertension useful. When left untreated, hypertension is associated with the strongest evidence for causation of all risk factors for heart attack and other cardiovascular disease [32]. Hypertension also increases the risk of stroke, kidney damage, vision loss, insulin resistance, and other adverse outcomes [4]. While existing tools have attempted to predict blood pressure without the use of a cuff (the gold-standard measurement of blood pressure), these tools are still significantly less accurate (see e.g. [77, 28]), and there is an ongoing need for effective blood pressure measurement.\n\nData Source: We use BRFSS as the raw data source, as described in Task B.5 above. However, for the hypertension prediction task, we use features related to the following set of risk factors for hypertension via [64]: Age, family history and genetics, other medical conditions (e.g. diabetes, various forms of cancer), race/ethnicity, sex, and social and economic factors (income, employment status). We collect all survey questions related to these risk factors and use them as the predictors for this task, along with a shared set of demographic indicators (race, sex, state, survey year, and a question related to income level).\n\nDistribution Shift: We use BMI category as the domain splitting variable. Individuals with BMI identified as \u201coverweight\u201d or \u201cobese\u201d are in the held-out domain, and those identified as \u201cunderweight\u201d or \u201cnormal weight\u201d are in the training domain. This simulates a model being deployed under subpopulation shift, where the target population has different (higher) BMI than the training population.\n\n## Voting\n\nBackground: Understanding participation in elections is a critical task for policymakers, politicians, and those with an interest in democracy. In the 2020 United States presidential election, for example, voter turnout reached record levels, but it is estimated that only 66.8% of eligible individuals voted according to the U.S. Census[9]. Additionally, so-called \u201clikely voter models,\u201d that predict which individuals will vote in an election, are widely acknowledged as critical to polling and campaigning in U.S. politics. Predicting whether an individual will vote is notoriously difficult; one reason for this challenge is that domain shift is a fundamental reality of such modeling (presidential elections only occur every four years, after which significant political and demographic changes occur prior to the next presidential election).\n\nData Source: We use data from the American National Election Studies (ANES)[10]. Since 1948, ANES has conducted surveys, usually administered as in-person interviews, during most years of national elections. This series of studies, known as the ANES \u201cTime Series,\u201d constitutes a pre-election interview and a post-election interview during years of Presidential elections, along with other data sources. Topics cover voting behavior and the elections, together with questions on public opinion and attitudes.\n\nDomain Shift: We introduce a domain split by geographic region. We use the ANES Census Region feature, where the out-of-domain region is the region representing the southern United States (AL, AR, DE, D.C., FL, GA, KY, LA, MD, MS, NC, OK, SC, TN, TX, VA, WV). This simulates a study in which voter data is collected in one part of the country, and the goal is to infer voting behavior in another geographic region; this is a common occurrence with polling data, particularly during the U.S. primaries, which occur over a period of several weeks at the state level.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Hypertension and Voting", "md": "# Hypertension and Voting"}, {"type": "heading", "lvl": 2, "value": "Hypertension", "md": "## Hypertension"}, {"type": "text", "value": "Background: Hypertension, or systolic blood pressure (typically systolic pressure 130 mm Hg or higher or diastolic 80 or higher) affects nearly half of Americans [3]. Hypertension is sometimes called a \u201csilent killer\u201d because in most cases, there are no obvious symptoms of hypertension [3]; this would make an accurate at-risk model of hypertension useful. When left untreated, hypertension is associated with the strongest evidence for causation of all risk factors for heart attack and other cardiovascular disease [32]. Hypertension also increases the risk of stroke, kidney damage, vision loss, insulin resistance, and other adverse outcomes [4]. While existing tools have attempted to predict blood pressure without the use of a cuff (the gold-standard measurement of blood pressure), these tools are still significantly less accurate (see e.g. [77, 28]), and there is an ongoing need for effective blood pressure measurement.\n\nData Source: We use BRFSS as the raw data source, as described in Task B.5 above. However, for the hypertension prediction task, we use features related to the following set of risk factors for hypertension via [64]: Age, family history and genetics, other medical conditions (e.g. diabetes, various forms of cancer), race/ethnicity, sex, and social and economic factors (income, employment status). We collect all survey questions related to these risk factors and use them as the predictors for this task, along with a shared set of demographic indicators (race, sex, state, survey year, and a question related to income level).\n\nDistribution Shift: We use BMI category as the domain splitting variable. Individuals with BMI identified as \u201coverweight\u201d or \u201cobese\u201d are in the held-out domain, and those identified as \u201cunderweight\u201d or \u201cnormal weight\u201d are in the training domain. This simulates a model being deployed under subpopulation shift, where the target population has different (higher) BMI than the training population.", "md": "Background: Hypertension, or systolic blood pressure (typically systolic pressure 130 mm Hg or higher or diastolic 80 or higher) affects nearly half of Americans [3]. Hypertension is sometimes called a \u201csilent killer\u201d because in most cases, there are no obvious symptoms of hypertension [3]; this would make an accurate at-risk model of hypertension useful. When left untreated, hypertension is associated with the strongest evidence for causation of all risk factors for heart attack and other cardiovascular disease [32]. Hypertension also increases the risk of stroke, kidney damage, vision loss, insulin resistance, and other adverse outcomes [4]. While existing tools have attempted to predict blood pressure without the use of a cuff (the gold-standard measurement of blood pressure), these tools are still significantly less accurate (see e.g. [77, 28]), and there is an ongoing need for effective blood pressure measurement.\n\nData Source: We use BRFSS as the raw data source, as described in Task B.5 above. However, for the hypertension prediction task, we use features related to the following set of risk factors for hypertension via [64]: Age, family history and genetics, other medical conditions (e.g. diabetes, various forms of cancer), race/ethnicity, sex, and social and economic factors (income, employment status). We collect all survey questions related to these risk factors and use them as the predictors for this task, along with a shared set of demographic indicators (race, sex, state, survey year, and a question related to income level).\n\nDistribution Shift: We use BMI category as the domain splitting variable. Individuals with BMI identified as \u201coverweight\u201d or \u201cobese\u201d are in the held-out domain, and those identified as \u201cunderweight\u201d or \u201cnormal weight\u201d are in the training domain. This simulates a model being deployed under subpopulation shift, where the target population has different (higher) BMI than the training population."}, {"type": "heading", "lvl": 2, "value": "Voting", "md": "## Voting"}, {"type": "text", "value": "Background: Understanding participation in elections is a critical task for policymakers, politicians, and those with an interest in democracy. In the 2020 United States presidential election, for example, voter turnout reached record levels, but it is estimated that only 66.8% of eligible individuals voted according to the U.S. Census[9]. Additionally, so-called \u201clikely voter models,\u201d that predict which individuals will vote in an election, are widely acknowledged as critical to polling and campaigning in U.S. politics. Predicting whether an individual will vote is notoriously difficult; one reason for this challenge is that domain shift is a fundamental reality of such modeling (presidential elections only occur every four years, after which significant political and demographic changes occur prior to the next presidential election).\n\nData Source: We use data from the American National Election Studies (ANES)[10]. Since 1948, ANES has conducted surveys, usually administered as in-person interviews, during most years of national elections. This series of studies, known as the ANES \u201cTime Series,\u201d constitutes a pre-election interview and a post-election interview during years of Presidential elections, along with other data sources. Topics cover voting behavior and the elections, together with questions on public opinion and attitudes.\n\nDomain Shift: We introduce a domain split by geographic region. We use the ANES Census Region feature, where the out-of-domain region is the region representing the southern United States (AL, AR, DE, D.C., FL, GA, KY, LA, MD, MS, NC, OK, SC, TN, TX, VA, WV). This simulates a study in which voter data is collected in one part of the country, and the goal is to infer voting behavior in another geographic region; this is a common occurrence with polling data, particularly during the U.S. primaries, which occur over a period of several weeks at the state level.", "md": "Background: Understanding participation in elections is a critical task for policymakers, politicians, and those with an interest in democracy. In the 2020 United States presidential election, for example, voter turnout reached record levels, but it is estimated that only 66.8% of eligible individuals voted according to the U.S. Census[9]. Additionally, so-called \u201clikely voter models,\u201d that predict which individuals will vote in an election, are widely acknowledged as critical to polling and campaigning in U.S. politics. Predicting whether an individual will vote is notoriously difficult; one reason for this challenge is that domain shift is a fundamental reality of such modeling (presidential elections only occur every four years, after which significant political and demographic changes occur prior to the next presidential election).\n\nData Source: We use data from the American National Election Studies (ANES)[10]. Since 1948, ANES has conducted surveys, usually administered as in-person interviews, during most years of national elections. This series of studies, known as the ANES \u201cTime Series,\u201d constitutes a pre-election interview and a post-election interview during years of Presidential elections, along with other data sources. Topics cover voting behavior and the elections, together with questions on public opinion and attitudes.\n\nDomain Shift: We introduce a domain split by geographic region. We use the ANES Census Region feature, where the out-of-domain region is the region representing the southern United States (AL, AR, DE, D.C., FL, GA, KY, LA, MD, MS, NC, OK, SC, TN, TX, VA, WV). This simulates a study in which voter data is collected in one part of the country, and the goal is to infer voting behavior in another geographic region; this is a common occurrence with polling data, particularly during the U.S. primaries, which occur over a period of several weeks at the state level."}]}, {"page": 20, "text": "B.8    Childhood Lead Exposure\nIn this task, the goal is to identify children 18 or younger with elevated lead blood levels.\nBackground: Lead is a known environmental toxin that has been shown to affect deleteriously\nthe nervous, hematopoietic, endocrine, renal, and reproductive systems11. In young children, lead\nexposure is a particular hazard because children more readily absorb lead than adults, and children\u2019s\ndeveloping nervous systems also make them more susceptible to the effects of lead. However, most\nchildren with any lead in their blood have no obvious immediate symptoms.12 The risk for lead\nexposure is disproportionately higher for children who are poor, non-Hispanic black, living in large\nmetropolitan areas, or living in older housing.\nThe CDC sets a national standard for blood lead levels in children. This value was established\nin 2012 to be 3.5 micrograms per decileter (\u00b5g/dL) of blood.13 This value, called the blood lead\nreference value (BLRV) for children, corresponds to the 97.5 percentile and is intended to identify\nlead exposure in order to allow parents, doctors, public health officials, and communities to act early\nto reduce harmful exposure to lead in children. Thus, early prediction of childhood lead exposure,\nas well as accurate just-in-time prediction for children where obtaining actual laboratory blood test\nresults is too costly or infeasible, is of high utility to many stakeholders.\nEarly detection of lead exposure can trigger many potentially impactful interventions, including:\nenvironmental and home analysis for early identification of sources of lead; testing and treatment\nfor nutritional factors influencing susceptibility to lead exposure (such as calcium and iron intake);\ndevelopmental analysis and support; and additional medical diagnostic tests.14\nUsing the laboratory blood test results from the NHANES (see \u2018Data Source\u2019 below), the task is to\nidentify whether a respondents\u2019 blood level exceeds the BLRV using only questionnaire data. We\nuse respondents of age 18 or younger as the target population (note that respondent data for ages\n1-5 is restricted and thus not available to our benchmarking study). This simulates the prediction\nof expensive and time-consuming laboratory testing using a quick and inexpensive questionnaire.\nLaboratory testing is conducted by the CDC at the National Center for Environmental Health, Centers\nfor Disease Control and Prevention, Atlanta, GA15\nData Source: The data are drawn from the CDC National Health and Nutrition Examination Survey\n(NHANES)16, a program of the National Center for Health Statistics (NCHS) within the Centers\nfor Disease Control and Prevention (CDC). NHANES is a program of studies designed to assess\nthe health and nutritional status of adults and children in the United States. The survey is unique\nin that it combines extensive interviews with physical examinations and high-quality laboratory\ntesting. The NHANES interview includes demographic, socioeconomic, dietary, and health-related\nquestions. The survey examines a nationally representative sample of about 5,000 persons each year.\nThe examination component consists of medical, dental, and physiological measurements, as well as\nlaboratory tests administered by highly trained medical personnel.\nFindings from NHANES are used to determine the prevalence of major diseases and risk factors for\ndiseases; to assess nutritional status and its association with health promotion and disease prevention;\nand are the basis for national standards for such measurements as height, weight, and blood pressure.\nData from this survey are widely used in epidemiological studies and health sciences research.\nWe use only questionnaire-based NHANES features as the predictors, but use a prediction target from\nthe NHANES\u2019 lab-based component. This simulates the development of a screening questionnaire to\npredict blood lead levels.\nDistribution Shift: We use poverty as a domain-splitting variable. Children from low-income\nhouseholds and those who live in housing built before 1978 are at the greatest risk of lead exposure17.\n   11https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_PBCD.htm\n   12https://www.cdc.gov/nceh/lead/prevention/blood-lead-levels.htm\n   13https://www.cdc.gov/nceh/lead/data/blood-lead-reference-value.htm\n   14https://www.cdc.gov/nceh/lead/advisory/acclpp/actions-blls.htm\n   15\n    A detailed description of the methods and procedures used for laboratory testing for lead in the 2017-\n2018 NHANES survey is given at https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_PBCD.htm; similar\ndescriptions are available for each year of data collection.\n   16https://wwwn.cdc.gov/Nchs/Nhanes/\n   17https://www.cdc.gov/nceh/lead/prevention/populations.htm\n                                                        20", "md": "# Childhood Lead Exposure\n\n# Childhood Lead Exposure\n\nIn this task, the goal is to identify children 18 or younger with elevated lead blood levels.\n\n## Background\n\nLead is a known environmental toxin that has been shown to affect deleteriously the nervous, hematopoietic, endocrine, renal, and reproductive systems. In young children, lead exposure is a particular hazard because children more readily absorb lead than adults, and children\u2019s developing nervous systems also make them more susceptible to the effects of lead. However, most children with any lead in their blood have no obvious immediate symptoms. The risk for lead exposure is disproportionately higher for children who are poor, non-Hispanic black, living in large metropolitan areas, or living in older housing.\n\n## CDC Blood Lead Levels Standard\n\nThe CDC sets a national standard for blood lead levels in children. This value was established in 2012 to be $$3.5 \\, \\text{micrograms per deciliter (\u00b5g/dL)}$$ of blood. This value, called the blood lead reference value (BLRV) for children, corresponds to the 97.5 percentile and is intended to identify lead exposure in order to allow parents, doctors, public health officials, and communities to act early to reduce harmful exposure to lead in children.\n\n## Interventions for Lead Exposure\n\nEarly detection of lead exposure can trigger many potentially impactful interventions, including:\n\n- Environmental and home analysis for early identification of sources of lead\n- Testing and treatment for nutritional factors influencing susceptibility to lead exposure (such as calcium and iron intake)\n- Developmental analysis and support\n- Additional medical diagnostic tests\n\n## Data Source\n\nThe data are drawn from the CDC National Health and Nutrition Examination Survey (NHANES), a program of the National Center for Health Statistics (NCHS) within the Centers for Disease Control and Prevention (CDC). NHANES is a program of studies designed to assess the health and nutritional status of adults and children in the United States.\n\n## Distribution Shift\n\nWe use poverty as a domain-splitting variable. Children from low-income households and those who live in housing built before 1978 are at the greatest risk of lead exposure.\n\n### References:\n\n1. CDC - NHANES 2017-2018\n2. CDC - Blood Lead Levels\n3. CDC - Blood Lead Reference Value\n4. CDC - Actions for BLLs\n5. CDC - Laboratory Testing Methods\n6. CDC - NHANES\n7. CDC - Lead Exposure Populations", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Childhood Lead Exposure", "md": "# Childhood Lead Exposure"}, {"type": "heading", "lvl": 1, "value": "Childhood Lead Exposure", "md": "# Childhood Lead Exposure"}, {"type": "text", "value": "In this task, the goal is to identify children 18 or younger with elevated lead blood levels.", "md": "In this task, the goal is to identify children 18 or younger with elevated lead blood levels."}, {"type": "heading", "lvl": 2, "value": "Background", "md": "## Background"}, {"type": "text", "value": "Lead is a known environmental toxin that has been shown to affect deleteriously the nervous, hematopoietic, endocrine, renal, and reproductive systems. In young children, lead exposure is a particular hazard because children more readily absorb lead than adults, and children\u2019s developing nervous systems also make them more susceptible to the effects of lead. However, most children with any lead in their blood have no obvious immediate symptoms. The risk for lead exposure is disproportionately higher for children who are poor, non-Hispanic black, living in large metropolitan areas, or living in older housing.", "md": "Lead is a known environmental toxin that has been shown to affect deleteriously the nervous, hematopoietic, endocrine, renal, and reproductive systems. In young children, lead exposure is a particular hazard because children more readily absorb lead than adults, and children\u2019s developing nervous systems also make them more susceptible to the effects of lead. However, most children with any lead in their blood have no obvious immediate symptoms. The risk for lead exposure is disproportionately higher for children who are poor, non-Hispanic black, living in large metropolitan areas, or living in older housing."}, {"type": "heading", "lvl": 2, "value": "CDC Blood Lead Levels Standard", "md": "## CDC Blood Lead Levels Standard"}, {"type": "text", "value": "The CDC sets a national standard for blood lead levels in children. This value was established in 2012 to be $$3.5 \\, \\text{micrograms per deciliter (\u00b5g/dL)}$$ of blood. This value, called the blood lead reference value (BLRV) for children, corresponds to the 97.5 percentile and is intended to identify lead exposure in order to allow parents, doctors, public health officials, and communities to act early to reduce harmful exposure to lead in children.", "md": "The CDC sets a national standard for blood lead levels in children. This value was established in 2012 to be $$3.5 \\, \\text{micrograms per deciliter (\u00b5g/dL)}$$ of blood. This value, called the blood lead reference value (BLRV) for children, corresponds to the 97.5 percentile and is intended to identify lead exposure in order to allow parents, doctors, public health officials, and communities to act early to reduce harmful exposure to lead in children."}, {"type": "heading", "lvl": 2, "value": "Interventions for Lead Exposure", "md": "## Interventions for Lead Exposure"}, {"type": "text", "value": "Early detection of lead exposure can trigger many potentially impactful interventions, including:\n\n- Environmental and home analysis for early identification of sources of lead\n- Testing and treatment for nutritional factors influencing susceptibility to lead exposure (such as calcium and iron intake)\n- Developmental analysis and support\n- Additional medical diagnostic tests", "md": "Early detection of lead exposure can trigger many potentially impactful interventions, including:\n\n- Environmental and home analysis for early identification of sources of lead\n- Testing and treatment for nutritional factors influencing susceptibility to lead exposure (such as calcium and iron intake)\n- Developmental analysis and support\n- Additional medical diagnostic tests"}, {"type": "heading", "lvl": 2, "value": "Data Source", "md": "## Data Source"}, {"type": "text", "value": "The data are drawn from the CDC National Health and Nutrition Examination Survey (NHANES), a program of the National Center for Health Statistics (NCHS) within the Centers for Disease Control and Prevention (CDC). NHANES is a program of studies designed to assess the health and nutritional status of adults and children in the United States.", "md": "The data are drawn from the CDC National Health and Nutrition Examination Survey (NHANES), a program of the National Center for Health Statistics (NCHS) within the Centers for Disease Control and Prevention (CDC). NHANES is a program of studies designed to assess the health and nutritional status of adults and children in the United States."}, {"type": "heading", "lvl": 2, "value": "Distribution Shift", "md": "## Distribution Shift"}, {"type": "text", "value": "We use poverty as a domain-splitting variable. Children from low-income households and those who live in housing built before 1978 are at the greatest risk of lead exposure.", "md": "We use poverty as a domain-splitting variable. Children from low-income households and those who live in housing built before 1978 are at the greatest risk of lead exposure."}, {"type": "heading", "lvl": 3, "value": "References:", "md": "### References:"}, {"type": "text", "value": "1. CDC - NHANES 2017-2018\n2. CDC - Blood Lead Levels\n3. CDC - Blood Lead Reference Value\n4. CDC - Actions for BLLs\n5. CDC - Laboratory Testing Methods\n6. CDC - NHANES\n7. CDC - Lead Exposure Populations", "md": "1. CDC - NHANES 2017-2018\n2. CDC - Blood Lead Levels\n3. CDC - Blood Lead Reference Value\n4. CDC - Actions for BLLs\n5. CDC - Laboratory Testing Methods\n6. CDC - NHANES\n7. CDC - Lead Exposure Populations"}]}, {"page": 21, "text": "However, due to factors mentioned above, impoverished populations can be less likely to be included\nin medical studies, including those that may involve in-person visits for blood laboratory testing,\nwhich is the primary method for lead exposure detection. We use the poverty-income ratio (PIR)\nmeasurement in NHANES. The PIR is calculated by dividing total annual family (or individual)\nincome by the poverty guidelines specific to the survey year. The Department of Health and Human\nServices (HHS) poverty guidelines are used as the poverty measure to calculate this ratio. These\nguidelines are issued each year, in the Federal Register, for determining financial eligibility for certain\nfederal programs, such as Head Start, Supplemental Nutrition Assistance Program (SNAP), Special\nSupplemental Nutrition Program for Women, Infants, and Children (WIC), and the National School\nLunch Program. The poverty guidelines vary by family size and geographic location (with different\nguidelines for the 48 contiguous states and the District of Columbia; Alaska; and Hawaii).\nThe training domain is composed of individuals with PIR of at least 1.3; persons with PIR \u2264                1.3\nare in the held-out domain. The threshold of 1.3 is selected based on the PIR categorization used in\nNHANES, where PIR \u2264         1.3 is the lowest level.\nB.9    Hospital Readmission\nBackground: Effective management and treatment of diabetic patients admitted to the hospital can\nhave a significant impact on their health outcomes, both short-term and long-term [83]. Several\nfactors can affect the quality of treatment patients receive [81]. One of the costliest and potentially\nmost adverse outcomes after a patient is released from the hospital is for that patient to be readmitted\nsoon after their initial release; this can both be a sign of a condition that is not improving, and, at\ntimes, ineffective initial treatment. Thus, predicting the readmission of patients is a priority from\nboth a medical and economic perspective.\nIn this task, the goal is to predict whether a diabetic patient is readmitted to the hospital within 30\ndays of their initial release.\nData Source: We use the dataset provided by [81]18. The dataset represents 10 years (1999-2008) of\nclinical care at 130 US medical facilities, including hospitals and other networks. It includes over 50\nfeatures representing patient and hospital outcomes. The dataset includes observations for records\nwhich meet the following criteria: (1) It is an inpatient encounter (a hospital admission). (2) It is\na diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a\ndiagnosis. (3) The length of stay was at least 1 day and at most 14 days. (4) Laboratory tests were\nperformed during the encounter. (5) Medications were administered during the encounter.\nThe data contains such attributes as patient number, race, gender, age, admission type, time in hospital,\nmedical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis,\nnumber of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in\nthe year before the hospitalization, etc. We use the full set of features in the initial dataset, which is\ndescribed in [81].\nDistribution Shift: Patients can be (re)admitted to hospitals from a variety of sources. The source\nof a patient admission canbe correlated with many demographic and other risk factors known to be\nrelated to health outcomes (e.g. race, income level, etc.).\nWe use the \u201cadmission source\u201d as the domain split for TableShift. There are 21 distinct admission\nsources in the dataset, including \u201ctransfer from a hospital\u201d, \u201cphysician referral\u201d, etc. After conducting\na sweep over various held-out values, we use \u201cemergency room\u201d as the held-out domain split. This\nmatches a potential scenario where a model is constructed using a variety of admission sources, but a\npatient from a novel source is added; it is also possible e.g. that data from emergent patients could not\nbe collected when training a readmission model. We note that this domain split provides 20 unique\ntraining subdomains (the other admission sources), which is the largest |Dtrain| in TableShift.\nB.10     Sepsis\nBackground: Sepsis is a life-threatening condition that arises when the body\u2019s response to infection\ncauses injury to its own tissues and organs. Sepsis is a major public health concern with significant\n   18https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-\n2008\n                                                      21", "md": "However, due to factors mentioned above, impoverished populations can be less likely to be included\nin medical studies, including those that may involve in-person visits for blood laboratory testing,\nwhich is the primary method for lead exposure detection. We use the poverty-income ratio (PIR)\nmeasurement in NHANES. The PIR is calculated by dividing total annual family (or individual)\nincome by the poverty guidelines specific to the survey year. The Department of Health and Human\nServices (HHS) poverty guidelines are used as the poverty measure to calculate this ratio. These\nguidelines are issued each year, in the Federal Register, for determining financial eligibility for certain\nfederal programs, such as Head Start, Supplemental Nutrition Assistance Program (SNAP), Special\nSupplemental Nutrition Program for Women, Infants, and Children (WIC), and the National School\nLunch Program. The poverty guidelines vary by family size and geographic location (with different\nguidelines for the 48 contiguous states and the District of Columbia; Alaska; and Hawaii).\n\nThe training domain is composed of individuals with PIR of at least 1.3; persons with PIR \u2264 1.3\nare in the held-out domain. The threshold of 1.3 is selected based on the PIR categorization used in\nNHANES, where PIR \u2264 1.3 is the lowest level.\n\n## Hospital Readmission\n\nBackground: Effective management and treatment of diabetic patients admitted to the hospital can\nhave a significant impact on their health outcomes, both short-term and long-term [83]. Several\nfactors can affect the quality of treatment patients receive [81]. One of the costliest and potentially\nmost adverse outcomes after a patient is released from the hospital is for that patient to be readmitted\nsoon after their initial release; this can both be a sign of a condition that is not improving, and, at\ntimes, ineffective initial treatment. Thus, predicting the readmission of patients is a priority from\nboth a medical and economic perspective.\n\nIn this task, the goal is to predict whether a diabetic patient is readmitted to the hospital within 30\ndays of their initial release.\n\nData Source: We use the dataset provided by [81]18. The dataset represents 10 years (1999-2008) of\nclinical care at 130 US medical facilities, including hospitals and other networks. It includes over 50\nfeatures representing patient and hospital outcomes. The dataset includes observations for records\nwhich meet the following criteria: (1) It is an inpatient encounter (a hospital admission). (2) It is\na diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a\ndiagnosis. (3) The length of stay was at least 1 day and at most 14 days. (4) Laboratory tests were\nperformed during the encounter. (5) Medications were administered during the encounter.\n\nThe data contains such attributes as patient number, race, gender, age, admission type, time in hospital,\nmedical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis,\nnumber of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in\nthe year before the hospitalization, etc. We use the full set of features in the initial dataset, which is\ndescribed in [81].\n\nDistribution Shift: Patients can be (re)admitted to hospitals from a variety of sources. The source\nof a patient admission can be correlated with many demographic and other risk factors known to be\nrelated to health outcomes (e.g. race, income level, etc.).\n\nWe use the \u201cadmission source\u201d as the domain split for TableShift. There are 21 distinct admission\nsources in the dataset, including \u201ctransfer from a hospital\u201d, \u201cphysician referral\u201d, etc. After conducting\na sweep over various held-out values, we use \u201cemergency room\u201d as the held-out domain split. This\nmatches a potential scenario where a model is constructed using a variety of admission sources, but a\npatient from a novel source is added; it is also possible e.g. that data from emergent patients could not\nbe collected when training a readmission model. We note that this domain split provides 20 unique\ntraining subdomains (the other admission sources), which is the largest |Dtrain| in TableShift.\n\n## Sepsis\n\nBackground: Sepsis is a life-threatening condition that arises when the body\u2019s response to infection\ncauses injury to its own tissues and organs. Sepsis is a major public health concern with significant\n\n18source", "images": [], "items": [{"type": "text", "value": "However, due to factors mentioned above, impoverished populations can be less likely to be included\nin medical studies, including those that may involve in-person visits for blood laboratory testing,\nwhich is the primary method for lead exposure detection. We use the poverty-income ratio (PIR)\nmeasurement in NHANES. The PIR is calculated by dividing total annual family (or individual)\nincome by the poverty guidelines specific to the survey year. The Department of Health and Human\nServices (HHS) poverty guidelines are used as the poverty measure to calculate this ratio. These\nguidelines are issued each year, in the Federal Register, for determining financial eligibility for certain\nfederal programs, such as Head Start, Supplemental Nutrition Assistance Program (SNAP), Special\nSupplemental Nutrition Program for Women, Infants, and Children (WIC), and the National School\nLunch Program. The poverty guidelines vary by family size and geographic location (with different\nguidelines for the 48 contiguous states and the District of Columbia; Alaska; and Hawaii).\n\nThe training domain is composed of individuals with PIR of at least 1.3; persons with PIR \u2264 1.3\nare in the held-out domain. The threshold of 1.3 is selected based on the PIR categorization used in\nNHANES, where PIR \u2264 1.3 is the lowest level.", "md": "However, due to factors mentioned above, impoverished populations can be less likely to be included\nin medical studies, including those that may involve in-person visits for blood laboratory testing,\nwhich is the primary method for lead exposure detection. We use the poverty-income ratio (PIR)\nmeasurement in NHANES. The PIR is calculated by dividing total annual family (or individual)\nincome by the poverty guidelines specific to the survey year. The Department of Health and Human\nServices (HHS) poverty guidelines are used as the poverty measure to calculate this ratio. These\nguidelines are issued each year, in the Federal Register, for determining financial eligibility for certain\nfederal programs, such as Head Start, Supplemental Nutrition Assistance Program (SNAP), Special\nSupplemental Nutrition Program for Women, Infants, and Children (WIC), and the National School\nLunch Program. The poverty guidelines vary by family size and geographic location (with different\nguidelines for the 48 contiguous states and the District of Columbia; Alaska; and Hawaii).\n\nThe training domain is composed of individuals with PIR of at least 1.3; persons with PIR \u2264 1.3\nare in the held-out domain. The threshold of 1.3 is selected based on the PIR categorization used in\nNHANES, where PIR \u2264 1.3 is the lowest level."}, {"type": "heading", "lvl": 2, "value": "Hospital Readmission", "md": "## Hospital Readmission"}, {"type": "text", "value": "Background: Effective management and treatment of diabetic patients admitted to the hospital can\nhave a significant impact on their health outcomes, both short-term and long-term [83]. Several\nfactors can affect the quality of treatment patients receive [81]. One of the costliest and potentially\nmost adverse outcomes after a patient is released from the hospital is for that patient to be readmitted\nsoon after their initial release; this can both be a sign of a condition that is not improving, and, at\ntimes, ineffective initial treatment. Thus, predicting the readmission of patients is a priority from\nboth a medical and economic perspective.\n\nIn this task, the goal is to predict whether a diabetic patient is readmitted to the hospital within 30\ndays of their initial release.\n\nData Source: We use the dataset provided by [81]18. The dataset represents 10 years (1999-2008) of\nclinical care at 130 US medical facilities, including hospitals and other networks. It includes over 50\nfeatures representing patient and hospital outcomes. The dataset includes observations for records\nwhich meet the following criteria: (1) It is an inpatient encounter (a hospital admission). (2) It is\na diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a\ndiagnosis. (3) The length of stay was at least 1 day and at most 14 days. (4) Laboratory tests were\nperformed during the encounter. (5) Medications were administered during the encounter.\n\nThe data contains such attributes as patient number, race, gender, age, admission type, time in hospital,\nmedical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis,\nnumber of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in\nthe year before the hospitalization, etc. We use the full set of features in the initial dataset, which is\ndescribed in [81].\n\nDistribution Shift: Patients can be (re)admitted to hospitals from a variety of sources. The source\nof a patient admission can be correlated with many demographic and other risk factors known to be\nrelated to health outcomes (e.g. race, income level, etc.).\n\nWe use the \u201cadmission source\u201d as the domain split for TableShift. There are 21 distinct admission\nsources in the dataset, including \u201ctransfer from a hospital\u201d, \u201cphysician referral\u201d, etc. After conducting\na sweep over various held-out values, we use \u201cemergency room\u201d as the held-out domain split. This\nmatches a potential scenario where a model is constructed using a variety of admission sources, but a\npatient from a novel source is added; it is also possible e.g. that data from emergent patients could not\nbe collected when training a readmission model. We note that this domain split provides 20 unique\ntraining subdomains (the other admission sources), which is the largest |Dtrain| in TableShift.", "md": "Background: Effective management and treatment of diabetic patients admitted to the hospital can\nhave a significant impact on their health outcomes, both short-term and long-term [83]. Several\nfactors can affect the quality of treatment patients receive [81]. One of the costliest and potentially\nmost adverse outcomes after a patient is released from the hospital is for that patient to be readmitted\nsoon after their initial release; this can both be a sign of a condition that is not improving, and, at\ntimes, ineffective initial treatment. Thus, predicting the readmission of patients is a priority from\nboth a medical and economic perspective.\n\nIn this task, the goal is to predict whether a diabetic patient is readmitted to the hospital within 30\ndays of their initial release.\n\nData Source: We use the dataset provided by [81]18. The dataset represents 10 years (1999-2008) of\nclinical care at 130 US medical facilities, including hospitals and other networks. It includes over 50\nfeatures representing patient and hospital outcomes. The dataset includes observations for records\nwhich meet the following criteria: (1) It is an inpatient encounter (a hospital admission). (2) It is\na diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a\ndiagnosis. (3) The length of stay was at least 1 day and at most 14 days. (4) Laboratory tests were\nperformed during the encounter. (5) Medications were administered during the encounter.\n\nThe data contains such attributes as patient number, race, gender, age, admission type, time in hospital,\nmedical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis,\nnumber of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in\nthe year before the hospitalization, etc. We use the full set of features in the initial dataset, which is\ndescribed in [81].\n\nDistribution Shift: Patients can be (re)admitted to hospitals from a variety of sources. The source\nof a patient admission can be correlated with many demographic and other risk factors known to be\nrelated to health outcomes (e.g. race, income level, etc.).\n\nWe use the \u201cadmission source\u201d as the domain split for TableShift. There are 21 distinct admission\nsources in the dataset, including \u201ctransfer from a hospital\u201d, \u201cphysician referral\u201d, etc. After conducting\na sweep over various held-out values, we use \u201cemergency room\u201d as the held-out domain split. This\nmatches a potential scenario where a model is constructed using a variety of admission sources, but a\npatient from a novel source is added; it is also possible e.g. that data from emergent patients could not\nbe collected when training a readmission model. We note that this domain split provides 20 unique\ntraining subdomains (the other admission sources), which is the largest |Dtrain| in TableShift."}, {"type": "heading", "lvl": 2, "value": "Sepsis", "md": "## Sepsis"}, {"type": "text", "value": "Background: Sepsis is a life-threatening condition that arises when the body\u2019s response to infection\ncauses injury to its own tissues and organs. Sepsis is a major public health concern with significant\n\n18source", "md": "Background: Sepsis is a life-threatening condition that arises when the body\u2019s response to infection\ncauses injury to its own tissues and organs. Sepsis is a major public health concern with significant\n\n18source"}]}, {"page": 22, "text": "morbidity, mortality, and healthcare expenses; each year, 1.7 million adults in America develop sepsis,\nof which at least 350, 000 die during their hospitalization or are discharged to hospice. The CDC\nestimates that 1 in 3 people who dies in a hospital had sepsis during that hospitalization19.\nEarly detection and antibiotic treatment of sepsis improve patient outcomes. While advances have\nbeen made in early sepsis prediction, there is a fundamental unmet clinical need for improved\nprediction [74]. The goal in this task is to predict, from a set of fine-grained ICU data (including\nlaboratory measurements, sensor data, and patient demographic information), whether a patient will\nexperience sepsis onset within the next 6 hours.\nData Source: We use the data source from the PhysioNet/Computing in Cardiology Challenge\n[74], which was designed by clinicians and other healthcare experts to facilitate the development of\nautomated, open-source algorithms for the early detection of sepsis from clinical data. The dataset is\nderived from ICU patient records for over 60, 000 patients from two hospitals with up to 40 clinical\nvariables collected during each hour of the patient\u2019s ICU stay.\nDistribution Shift: We explored multiple domain shifts for this dataset; we note that, in particular,\nsplitting domains by hospital did not lead to a shift gap for tuned baseline models (although there\nis a third, held-out hospital that was used in the original challenge for this dataset, it is not publicly\navailable and is not part of the TableShift benchmark). Instead, we use \u201clength of stay\u201d as a domain\nshift variable. We bifurcate the dataset based on how long a patient has been in the ICU, with patients\nhaving been in ICU for \u2264     47 hours in the training domain, and patients having been in ICU more\nthan 47 hours in the test domain. This matches a scenario where a medical model is trained only\non observed stays of a fixed duration (no more than two full days), but then used beyond its initial\nobservation window to predict sepsis in patients with longer stays. We note that length of stay of 47\nhours corresponds to the 80th percentile of the data for that feature.\nB.11    ICU Patient Length-of-Stay\nBackground: According to [72], length of hospital stay is, along with patient mortality, \u201cthe most\nimportant clinical outcome\u201d for an ICU admission. Accurately predicting the length of stay of a\npatient can aid in assessment of the severity of a patient\u2019s condition. Of particular clinical relevance,\nmaking these predictions early and with a non-zero time gapbetween the prediction and the outcome\nis of real-world importance: predictions must be made sufficiently early such that a patient\u2019s treatment\ncan be adjusted to potentially avoid a negative outcome. The importance of this prediction task\nfor real-world clinical care is underscored by the many previous works in the medical literature\naddressing this prediction topic (see e.g. [40, 72, 87].\nIn our benchmark, the specific task is to predict, from the first 24 hours of patient data, an ICU\npatient\u2019s stay will exceed 3 days (a binary indicator for whether length of stay > 3). We note that this\nis directly adopted from MIMIC-extract.\nData Source: We use the MIMIC-extract dataset [87]. MIMIC-extract is an open-source pipeline\nfor transforming raw electronic health record (EHR) data from the Medical Information Mart for\nIntensive Care (MIMIC-III) dataset [45].\nMIMIC-III, the underlying data source, captures over a decade of intensive care unit (ICU) patient\nstays at Beth Israel Deaconess Medical Center in Boston, USA. An individual patient might be\nadmitted to the ICU at multiple times in the dataset; however, MIMIC-extract focuses on each subject\u2019s\nfirst UCI visit only, since those who make repeat visits typically require additional considerations with\nrespect to modeling and care [87]. MIMIC-extract includes all patient ICU stays in the MIMIC-III\ndatabase that where the following criteria are met: (i) the subject is an adult (age of at least 15 at\ntime of admission), (ii) the stay is the first known ICU admission for the subject, and (iii) the total\nduration of the stay is at least 12 hours and less than 10 days.\nMIMIC-extract is designed by EHR domain experts with clinical validity (of data) and relevance\n(of prediction tasks) in mind. In addition to the filtering described above, MIMIC-extract\u2019s pipeline\nincludes steps to standardize units of measurement, detect and correct outliers, and select a curated set\nof features that reduce data missingness in the preprocessed data; for details on the steps taken by the\noriginal authors to achieve this, see [87]. We use the preprocessed version of MIMIC-extract made\n   19https://www.cdc.gov/sepsis/what-is-sepsis.html\n                                                    22", "md": "morbidity, mortality, and healthcare expenses; each year, 1.7 million adults in America develop sepsis,\nof which at least 350,000 die during their hospitalization or are discharged to hospice. The CDC\nestimates that 1 in 3 people who dies in a hospital had sepsis during that hospitalization19.\nEarly detection and antibiotic treatment of sepsis improve patient outcomes. While advances have\nbeen made in early sepsis prediction, there is a fundamental unmet clinical need for improved\nprediction [74]. The goal in this task is to predict, from a set of fine-grained ICU data (including\nlaboratory measurements, sensor data, and patient demographic information), whether a patient will\nexperience sepsis onset within the next 6 hours.\n\nData Source: We use the data source from the PhysioNet/Computing in Cardiology Challenge\n[74], which was designed by clinicians and other healthcare experts to facilitate the development of\nautomated, open-source algorithms for the early detection of sepsis from clinical data. The dataset is\nderived from ICU patient records for over 60,000 patients from two hospitals with up to 40 clinical\nvariables collected during each hour of the patient\u2019s ICU stay.\n\nDistribution Shift: We explored multiple domain shifts for this dataset; we note that, in particular,\nsplitting domains by hospital did not lead to a shift gap for tuned baseline models (although there\nis a third, held-out hospital that was used in the original challenge for this dataset, it is not publicly\navailable and is not part of the TableShift benchmark). Instead, we use \u201clength of stay\u201d as a domain\nshift variable. We bifurcate the dataset based on how long a patient has been in the ICU, with patients\nhaving been in ICU for \u2264 47 hours in the training domain, and patients having been in ICU more\nthan 47 hours in the test domain. This matches a scenario where a medical model is trained only\non observed stays of a fixed duration (no more than two full days), but then used beyond its initial\nobservation window to predict sepsis in patients with longer stays. We note that length of stay of 47\nhours corresponds to the 80th percentile of the data for that feature.\n\n## ICU Patient Length-of-Stay\n\nBackground: According to [72], length of hospital stay is, along with patient mortality, \u201cthe most\nimportant clinical outcome\u201d for an ICU admission. Accurately predicting the length of stay of a\npatient can aid in assessment of the severity of a patient\u2019s condition. Of particular clinical relevance,\nmaking these predictions early and with a non-zero time gap between the prediction and the outcome\nis of real-world importance: predictions must be made sufficiently early such that a patient\u2019s treatment\ncan be adjusted to potentially avoid a negative outcome. The importance of this prediction task\nfor real-world clinical care is underscored by the many previous works in the medical literature\naddressing this prediction topic (see e.g. [40, 72, 87]).\n\nIn our benchmark, the specific task is to predict, from the first 24 hours of patient data, an ICU\npatient\u2019s stay will exceed 3 days (a binary indicator for whether length of stay > 3). We note that this\nis directly adopted from MIMIC-extract.\n\nData Source: We use the MIMIC-extract dataset [87]. MIMIC-extract is an open-source pipeline\nfor transforming raw electronic health record (EHR) data from the Medical Information Mart for\nIntensive Care (MIMIC-III) dataset [45].\n\nMIMIC-III, the underlying data source, captures over a decade of intensive care unit (ICU) patient\nstays at Beth Israel Deaconess Medical Center in Boston, USA. An individual patient might be\nadmitted to the ICU at multiple times in the dataset; however, MIMIC-extract focuses on each subject\u2019s\nfirst UCI visit only, since those who make repeat visits typically require additional considerations with\nrespect to modeling and care [87]. MIMIC-extract includes all patient ICU stays in the MIMIC-III\ndatabase that where the following criteria are met: (i) the subject is an adult (age of at least 15 at\ntime of admission), (ii) the stay is the first known ICU admission for the subject, and (iii) the total\nduration of the stay is at least 12 hours and less than 10 days.\n\nMIMIC-extract is designed by EHR domain experts with clinical validity (of data) and relevance\n(of prediction tasks) in mind. In addition to the filtering described above, MIMIC-extract\u2019s pipeline\nincludes steps to standardize units of measurement, detect and correct outliers, and select a curated set\nof features that reduce data missingness in the preprocessed data; for details on the steps taken by the\noriginal authors to achieve this, see [87]. We use the preprocessed version of MIMIC-extract made", "images": [], "items": [{"type": "text", "value": "morbidity, mortality, and healthcare expenses; each year, 1.7 million adults in America develop sepsis,\nof which at least 350,000 die during their hospitalization or are discharged to hospice. The CDC\nestimates that 1 in 3 people who dies in a hospital had sepsis during that hospitalization19.\nEarly detection and antibiotic treatment of sepsis improve patient outcomes. While advances have\nbeen made in early sepsis prediction, there is a fundamental unmet clinical need for improved\nprediction [74]. The goal in this task is to predict, from a set of fine-grained ICU data (including\nlaboratory measurements, sensor data, and patient demographic information), whether a patient will\nexperience sepsis onset within the next 6 hours.\n\nData Source: We use the data source from the PhysioNet/Computing in Cardiology Challenge\n[74], which was designed by clinicians and other healthcare experts to facilitate the development of\nautomated, open-source algorithms for the early detection of sepsis from clinical data. The dataset is\nderived from ICU patient records for over 60,000 patients from two hospitals with up to 40 clinical\nvariables collected during each hour of the patient\u2019s ICU stay.\n\nDistribution Shift: We explored multiple domain shifts for this dataset; we note that, in particular,\nsplitting domains by hospital did not lead to a shift gap for tuned baseline models (although there\nis a third, held-out hospital that was used in the original challenge for this dataset, it is not publicly\navailable and is not part of the TableShift benchmark). Instead, we use \u201clength of stay\u201d as a domain\nshift variable. We bifurcate the dataset based on how long a patient has been in the ICU, with patients\nhaving been in ICU for \u2264 47 hours in the training domain, and patients having been in ICU more\nthan 47 hours in the test domain. This matches a scenario where a medical model is trained only\non observed stays of a fixed duration (no more than two full days), but then used beyond its initial\nobservation window to predict sepsis in patients with longer stays. We note that length of stay of 47\nhours corresponds to the 80th percentile of the data for that feature.", "md": "morbidity, mortality, and healthcare expenses; each year, 1.7 million adults in America develop sepsis,\nof which at least 350,000 die during their hospitalization or are discharged to hospice. The CDC\nestimates that 1 in 3 people who dies in a hospital had sepsis during that hospitalization19.\nEarly detection and antibiotic treatment of sepsis improve patient outcomes. While advances have\nbeen made in early sepsis prediction, there is a fundamental unmet clinical need for improved\nprediction [74]. The goal in this task is to predict, from a set of fine-grained ICU data (including\nlaboratory measurements, sensor data, and patient demographic information), whether a patient will\nexperience sepsis onset within the next 6 hours.\n\nData Source: We use the data source from the PhysioNet/Computing in Cardiology Challenge\n[74], which was designed by clinicians and other healthcare experts to facilitate the development of\nautomated, open-source algorithms for the early detection of sepsis from clinical data. The dataset is\nderived from ICU patient records for over 60,000 patients from two hospitals with up to 40 clinical\nvariables collected during each hour of the patient\u2019s ICU stay.\n\nDistribution Shift: We explored multiple domain shifts for this dataset; we note that, in particular,\nsplitting domains by hospital did not lead to a shift gap for tuned baseline models (although there\nis a third, held-out hospital that was used in the original challenge for this dataset, it is not publicly\navailable and is not part of the TableShift benchmark). Instead, we use \u201clength of stay\u201d as a domain\nshift variable. We bifurcate the dataset based on how long a patient has been in the ICU, with patients\nhaving been in ICU for \u2264 47 hours in the training domain, and patients having been in ICU more\nthan 47 hours in the test domain. This matches a scenario where a medical model is trained only\non observed stays of a fixed duration (no more than two full days), but then used beyond its initial\nobservation window to predict sepsis in patients with longer stays. We note that length of stay of 47\nhours corresponds to the 80th percentile of the data for that feature."}, {"type": "heading", "lvl": 2, "value": "ICU Patient Length-of-Stay", "md": "## ICU Patient Length-of-Stay"}, {"type": "text", "value": "Background: According to [72], length of hospital stay is, along with patient mortality, \u201cthe most\nimportant clinical outcome\u201d for an ICU admission. Accurately predicting the length of stay of a\npatient can aid in assessment of the severity of a patient\u2019s condition. Of particular clinical relevance,\nmaking these predictions early and with a non-zero time gap between the prediction and the outcome\nis of real-world importance: predictions must be made sufficiently early such that a patient\u2019s treatment\ncan be adjusted to potentially avoid a negative outcome. The importance of this prediction task\nfor real-world clinical care is underscored by the many previous works in the medical literature\naddressing this prediction topic (see e.g. [40, 72, 87]).\n\nIn our benchmark, the specific task is to predict, from the first 24 hours of patient data, an ICU\npatient\u2019s stay will exceed 3 days (a binary indicator for whether length of stay > 3). We note that this\nis directly adopted from MIMIC-extract.\n\nData Source: We use the MIMIC-extract dataset [87]. MIMIC-extract is an open-source pipeline\nfor transforming raw electronic health record (EHR) data from the Medical Information Mart for\nIntensive Care (MIMIC-III) dataset [45].\n\nMIMIC-III, the underlying data source, captures over a decade of intensive care unit (ICU) patient\nstays at Beth Israel Deaconess Medical Center in Boston, USA. An individual patient might be\nadmitted to the ICU at multiple times in the dataset; however, MIMIC-extract focuses on each subject\u2019s\nfirst UCI visit only, since those who make repeat visits typically require additional considerations with\nrespect to modeling and care [87]. MIMIC-extract includes all patient ICU stays in the MIMIC-III\ndatabase that where the following criteria are met: (i) the subject is an adult (age of at least 15 at\ntime of admission), (ii) the stay is the first known ICU admission for the subject, and (iii) the total\nduration of the stay is at least 12 hours and less than 10 days.\n\nMIMIC-extract is designed by EHR domain experts with clinical validity (of data) and relevance\n(of prediction tasks) in mind. In addition to the filtering described above, MIMIC-extract\u2019s pipeline\nincludes steps to standardize units of measurement, detect and correct outliers, and select a curated set\nof features that reduce data missingness in the preprocessed data; for details on the steps taken by the\noriginal authors to achieve this, see [87]. We use the preprocessed version of MIMIC-extract made", "md": "Background: According to [72], length of hospital stay is, along with patient mortality, \u201cthe most\nimportant clinical outcome\u201d for an ICU admission. Accurately predicting the length of stay of a\npatient can aid in assessment of the severity of a patient\u2019s condition. Of particular clinical relevance,\nmaking these predictions early and with a non-zero time gap between the prediction and the outcome\nis of real-world importance: predictions must be made sufficiently early such that a patient\u2019s treatment\ncan be adjusted to potentially avoid a negative outcome. The importance of this prediction task\nfor real-world clinical care is underscored by the many previous works in the medical literature\naddressing this prediction topic (see e.g. [40, 72, 87]).\n\nIn our benchmark, the specific task is to predict, from the first 24 hours of patient data, an ICU\npatient\u2019s stay will exceed 3 days (a binary indicator for whether length of stay > 3). We note that this\nis directly adopted from MIMIC-extract.\n\nData Source: We use the MIMIC-extract dataset [87]. MIMIC-extract is an open-source pipeline\nfor transforming raw electronic health record (EHR) data from the Medical Information Mart for\nIntensive Care (MIMIC-III) dataset [45].\n\nMIMIC-III, the underlying data source, captures over a decade of intensive care unit (ICU) patient\nstays at Beth Israel Deaconess Medical Center in Boston, USA. An individual patient might be\nadmitted to the ICU at multiple times in the dataset; however, MIMIC-extract focuses on each subject\u2019s\nfirst UCI visit only, since those who make repeat visits typically require additional considerations with\nrespect to modeling and care [87]. MIMIC-extract includes all patient ICU stays in the MIMIC-III\ndatabase that where the following criteria are met: (i) the subject is an adult (age of at least 15 at\ntime of admission), (ii) the stay is the first known ICU admission for the subject, and (iii) the total\nduration of the stay is at least 12 hours and less than 10 days.\n\nMIMIC-extract is designed by EHR domain experts with clinical validity (of data) and relevance\n(of prediction tasks) in mind. In addition to the filtering described above, MIMIC-extract\u2019s pipeline\nincludes steps to standardize units of measurement, detect and correct outliers, and select a curated set\nof features that reduce data missingness in the preprocessed data; for details on the steps taken by the\noriginal authors to achieve this, see [87]. We use the preprocessed version of MIMIC-extract made"}]}, {"page": 23, "text": " available by the authors 20. This includes the static demographic variables, alongside the time-varying\n vitals and labs described in [45]. Because event he preprocessed data contains missing values, we use\n the authors\u2019 default methods for handling missing data.\nThe resulting dataset contains approximately 24, 000 observations.\n Distribution Shift: We split the domains by health insurance type. We train on patients with all\n insurance types except Medicare, and use patients with Medicare insurance as the target domain.\n B.12   ICU Patient In-Hospital Mortality\n Background: As discussed in the background of \u00a7B.11, hospital mortality is considered to be one\n of the most important outcomes for ICU patients. The clinical relevance of hospital mortality is\n perhaps even more clear than for length-of-stay prediction, as preventing patient mortality is one of\n the primary goals for many patients. Again, as discussed in \u00a7B.11, making this prediction early is of\n particular importance, as early predictions can provide a proxy for overall patient risk and can be\n used to intervene to avoid mortality.\nWe note that in this task, we are predicting hospital morality (that the patient dies at any point\n during this visit, even if they are discharged from the ICU to another unit in the hospital). Hospital\n mortality events are distinct from (and a superset of) ICU mortality events. As mentioned above, the\n importance of this prediction task for real-world clinical care is underscored by the many previous\nworks addressing this prediction topic (see e.g. [40, 72, 87].\n Data Source: This task uses the same data source and feature set from MIMIC-extract described\n above in \u00a7B.11.\n Distribution Shift: We split the domains by health insurance type. We train on patients with\n all insurance types except { Medicare, Medicaid } and use patients with { Medicare, Medicaid }\n insurance as the target domain.\n B.13   FICO Home Equity Line of Credit (HELOC)\n Background: FICO (legal name: Fair Isaac Corporation) is a US-based company that provides credit\n scoring services. The FICO score, a measure of consumer credit risk, is a widely used risk assessment\n measure for consumer lending in the united states.\nThe Home Equity Line of Credit (HELOC) is a line of credit, secured by the applicant\u2019s home.\nA HELOC provides access to a revolving credit line to use for large expenses or to consolidate\n higher-interest rate debt on other loans such as credit cards. A HELOC often has a lower interest\n rate than some other common types of loans. To assess an applicant\u2019s suitability for a HELOC, a\n lender evaluates an applicants\u2019 financial background, including credit score and financial history. The\n lender\u2019s goal is to predict, using this historical customer information, whether a given applicant is\n likely to repay a line of credit and, if so, how much credit should be extended.\n In addition to desiring accurate credit risk predictions for their overall utility for both lenders and\n borrowers, lending institutions are incentivized (and, in some cases, legally required) to use models\nwhich achieve some degree of robustness: institutions can face severe penalties when borrowers are\n not treated equitably (e.g. [84]).\n Data Source: We use the dataset from the FICO Commmunity Explainable AI Challenge21, an\n open-source dataset containing features derived from anonymized credit bureau data. The binary\n prediction target is an indicator for whether a consumer was 90 days past due or worse at least once\n over a period of 24 months from when the credit account was opened. The features represent various\n aspects of an applicant\u2019s existing financial profile, including recent financial activity, number of\n various transactions and credit inquiries, credit balance, and number of delinquent accounts.\n Distribution Shift: It is widely acknowledged that the dominant approach to credit scoring using\n financial profiles can unintentionally discriminate against historically marginalized groups (credit\n bureau data do not include explicit information about race [58]). For example, since FICO scores are\n   20The publicly-accessible dataset (which requires credentialed MIMIC-III access through PhysioNet due to\n privacy restrictions) is described at https://github.com/MLforHealth/MIMIC_Extract\n   21https://community.fico.com/s/explainable-machine-learning-challenge\n                                                     23", "md": "Available by the authors 20. This includes the static demographic variables, alongside the time-varying\nvitals and labs described in [45]. Because even the preprocessed data contains missing values, we use\nthe authors\u2019 default methods for handling missing data.\n\nThe resulting dataset contains approximately 24,000 observations.\n\nDistribution Shift: We split the domains by health insurance type. We train on patients with all\ninsurance types except Medicare, and use patients with Medicare insurance as the target domain.\n\n## B.12 ICU Patient In-Hospital Mortality\n\nBackground: As discussed in the background of \u00a7B.11, hospital mortality is considered to be one\nof the most important outcomes for ICU patients. The clinical relevance of hospital mortality is\nperhaps even more clear than for length-of-stay prediction, as preventing patient mortality is one of\nthe primary goals for many patients. Again, as discussed in \u00a7B.11, making this prediction early is of\nparticular importance, as early predictions can provide a proxy for overall patient risk and can be\nused to intervene to avoid mortality.\n\nWe note that in this task, we are predicting hospital morality (that the patient dies at any point\nduring this visit, even if they are discharged from the ICU to another unit in the hospital). Hospital\nmortality events are distinct from (and a superset of) ICU mortality events. As mentioned above, the\nimportance of this prediction task for real-world clinical care is underscored by the many previous\nworks addressing this prediction topic (see e.g. [40, 72, 87]).\n\nData Source: This task uses the same data source and feature set from MIMIC-extract described\nabove in \u00a7B.11.\n\nDistribution Shift: We split the domains by health insurance type. We train on patients with\nall insurance types except { Medicare, Medicaid } and use patients with { Medicare, Medicaid }\ninsurance as the target domain.\n\n## B.13 FICO Home Equity Line of Credit (HELOC)\n\nBackground: FICO (legal name: Fair Isaac Corporation) is a US-based company that provides credit\nscoring services. The FICO score, a measure of consumer credit risk, is a widely used risk assessment\nmeasure for consumer lending in the United States.\n\nThe Home Equity Line of Credit (HELOC) is a line of credit, secured by the applicant\u2019s home.\nA HELOC provides access to a revolving credit line to use for large expenses or to consolidate\nhigher-interest rate debt on other loans such as credit cards. A HELOC often has a lower interest\nrate than some other common types of loans. To assess an applicant\u2019s suitability for a HELOC, a\nlender evaluates an applicants\u2019 financial background, including credit score and financial history. The\nlender\u2019s goal is to predict, using this historical customer information, whether a given applicant is\nlikely to repay a line of credit and, if so, how much credit should be extended.\n\nIn addition to desiring accurate credit risk predictions for their overall utility for both lenders and\nborrowers, lending institutions are incentivized (and, in some cases, legally required) to use models\nwhich achieve some degree of robustness: institutions can face severe penalties when borrowers are\nnot treated equitably (e.g. [84]).\n\nData Source: We use the dataset from the FICO Community Explainable AI Challenge21, an\nopen-source dataset containing features derived from anonymized credit bureau data. The binary\nprediction target is an indicator for whether a consumer was 90 days past due or worse at least once\nover a period of 24 months from when the credit account was opened. The features represent various\naspects of an applicant\u2019s existing financial profile, including recent financial activity, number of\nvarious transactions and credit inquiries, credit balance, and number of delinquent accounts.\n\nDistribution Shift: It is widely acknowledged that the dominant approach to credit scoring using\nfinancial profiles can unintentionally discriminate against historically marginalized groups (credit\nbureau data do not include explicit information about race [58]). For example, since FICO scores are", "images": [], "items": [{"type": "text", "value": "Available by the authors 20. This includes the static demographic variables, alongside the time-varying\nvitals and labs described in [45]. Because even the preprocessed data contains missing values, we use\nthe authors\u2019 default methods for handling missing data.\n\nThe resulting dataset contains approximately 24,000 observations.\n\nDistribution Shift: We split the domains by health insurance type. We train on patients with all\ninsurance types except Medicare, and use patients with Medicare insurance as the target domain.", "md": "Available by the authors 20. This includes the static demographic variables, alongside the time-varying\nvitals and labs described in [45]. Because even the preprocessed data contains missing values, we use\nthe authors\u2019 default methods for handling missing data.\n\nThe resulting dataset contains approximately 24,000 observations.\n\nDistribution Shift: We split the domains by health insurance type. We train on patients with all\ninsurance types except Medicare, and use patients with Medicare insurance as the target domain."}, {"type": "heading", "lvl": 2, "value": "B.12 ICU Patient In-Hospital Mortality", "md": "## B.12 ICU Patient In-Hospital Mortality"}, {"type": "text", "value": "Background: As discussed in the background of \u00a7B.11, hospital mortality is considered to be one\nof the most important outcomes for ICU patients. The clinical relevance of hospital mortality is\nperhaps even more clear than for length-of-stay prediction, as preventing patient mortality is one of\nthe primary goals for many patients. Again, as discussed in \u00a7B.11, making this prediction early is of\nparticular importance, as early predictions can provide a proxy for overall patient risk and can be\nused to intervene to avoid mortality.\n\nWe note that in this task, we are predicting hospital morality (that the patient dies at any point\nduring this visit, even if they are discharged from the ICU to another unit in the hospital). Hospital\nmortality events are distinct from (and a superset of) ICU mortality events. As mentioned above, the\nimportance of this prediction task for real-world clinical care is underscored by the many previous\nworks addressing this prediction topic (see e.g. [40, 72, 87]).\n\nData Source: This task uses the same data source and feature set from MIMIC-extract described\nabove in \u00a7B.11.\n\nDistribution Shift: We split the domains by health insurance type. We train on patients with\nall insurance types except { Medicare, Medicaid } and use patients with { Medicare, Medicaid }\ninsurance as the target domain.", "md": "Background: As discussed in the background of \u00a7B.11, hospital mortality is considered to be one\nof the most important outcomes for ICU patients. The clinical relevance of hospital mortality is\nperhaps even more clear than for length-of-stay prediction, as preventing patient mortality is one of\nthe primary goals for many patients. Again, as discussed in \u00a7B.11, making this prediction early is of\nparticular importance, as early predictions can provide a proxy for overall patient risk and can be\nused to intervene to avoid mortality.\n\nWe note that in this task, we are predicting hospital morality (that the patient dies at any point\nduring this visit, even if they are discharged from the ICU to another unit in the hospital). Hospital\nmortality events are distinct from (and a superset of) ICU mortality events. As mentioned above, the\nimportance of this prediction task for real-world clinical care is underscored by the many previous\nworks addressing this prediction topic (see e.g. [40, 72, 87]).\n\nData Source: This task uses the same data source and feature set from MIMIC-extract described\nabove in \u00a7B.11.\n\nDistribution Shift: We split the domains by health insurance type. We train on patients with\nall insurance types except { Medicare, Medicaid } and use patients with { Medicare, Medicaid }\ninsurance as the target domain."}, {"type": "heading", "lvl": 2, "value": "B.13 FICO Home Equity Line of Credit (HELOC)", "md": "## B.13 FICO Home Equity Line of Credit (HELOC)"}, {"type": "text", "value": "Background: FICO (legal name: Fair Isaac Corporation) is a US-based company that provides credit\nscoring services. The FICO score, a measure of consumer credit risk, is a widely used risk assessment\nmeasure for consumer lending in the United States.\n\nThe Home Equity Line of Credit (HELOC) is a line of credit, secured by the applicant\u2019s home.\nA HELOC provides access to a revolving credit line to use for large expenses or to consolidate\nhigher-interest rate debt on other loans such as credit cards. A HELOC often has a lower interest\nrate than some other common types of loans. To assess an applicant\u2019s suitability for a HELOC, a\nlender evaluates an applicants\u2019 financial background, including credit score and financial history. The\nlender\u2019s goal is to predict, using this historical customer information, whether a given applicant is\nlikely to repay a line of credit and, if so, how much credit should be extended.\n\nIn addition to desiring accurate credit risk predictions for their overall utility for both lenders and\nborrowers, lending institutions are incentivized (and, in some cases, legally required) to use models\nwhich achieve some degree of robustness: institutions can face severe penalties when borrowers are\nnot treated equitably (e.g. [84]).\n\nData Source: We use the dataset from the FICO Community Explainable AI Challenge21, an\nopen-source dataset containing features derived from anonymized credit bureau data. The binary\nprediction target is an indicator for whether a consumer was 90 days past due or worse at least once\nover a period of 24 months from when the credit account was opened. The features represent various\naspects of an applicant\u2019s existing financial profile, including recent financial activity, number of\nvarious transactions and credit inquiries, credit balance, and number of delinquent accounts.\n\nDistribution Shift: It is widely acknowledged that the dominant approach to credit scoring using\nfinancial profiles can unintentionally discriminate against historically marginalized groups (credit\nbureau data do not include explicit information about race [58]). For example, since FICO scores are", "md": "Background: FICO (legal name: Fair Isaac Corporation) is a US-based company that provides credit\nscoring services. The FICO score, a measure of consumer credit risk, is a widely used risk assessment\nmeasure for consumer lending in the United States.\n\nThe Home Equity Line of Credit (HELOC) is a line of credit, secured by the applicant\u2019s home.\nA HELOC provides access to a revolving credit line to use for large expenses or to consolidate\nhigher-interest rate debt on other loans such as credit cards. A HELOC often has a lower interest\nrate than some other common types of loans. To assess an applicant\u2019s suitability for a HELOC, a\nlender evaluates an applicants\u2019 financial background, including credit score and financial history. The\nlender\u2019s goal is to predict, using this historical customer information, whether a given applicant is\nlikely to repay a line of credit and, if so, how much credit should be extended.\n\nIn addition to desiring accurate credit risk predictions for their overall utility for both lenders and\nborrowers, lending institutions are incentivized (and, in some cases, legally required) to use models\nwhich achieve some degree of robustness: institutions can face severe penalties when borrowers are\nnot treated equitably (e.g. [84]).\n\nData Source: We use the dataset from the FICO Community Explainable AI Challenge21, an\nopen-source dataset containing features derived from anonymized credit bureau data. The binary\nprediction target is an indicator for whether a consumer was 90 days past due or worse at least once\nover a period of 24 months from when the credit account was opened. The features represent various\naspects of an applicant\u2019s existing financial profile, including recent financial activity, number of\nvarious transactions and credit inquiries, credit balance, and number of delinquent accounts.\n\nDistribution Shift: It is widely acknowledged that the dominant approach to credit scoring using\nfinancial profiles can unintentionally discriminate against historically marginalized groups (credit\nbureau data do not include explicit information about race [58]). For example, since FICO scores are"}]}, {"page": 24, "text": "based on payment history and credit use and many marginalized groups in the United States have\nlower or less reliable incomes, these marginalized groups can suffer from systematically lower credit\nscores [60, 71, 8, 58]; this has been referred to as the \u201ccredit gap\u201d [49, 22]. In particular, debt and\nsavings level play a role in credit scores and can systematically disadvantage Black and Hispanic\napplicants, even when demographic data are not formally used in the credit rating process [60, 58].\nFor this task, we partition the dataset based on the \u2018External Risk Estimate\u2019, a feature in the dataset\ncorresponding to the risk estimate assigned to an applicant by a third-party service. This estimate\nwas identified in the original FICO explanable ML challenge 22. We use individuals with a high\nexternal risk estimate (where \u201chigh\u201d estimate is defined as exceeding an external risk estimate of 63,\na threshold identified in the original challenge-winning model linked above) as the training domain,\nand individuals with estimate \u2264    63 as the held-out domain.\nB.14    College Scorecard Degree Completion Rate\nBackground: Higher education is increasingly critical to securing strong job and income opportu-\nnities for persons in the United States. At the same time, the cost of obtaining a four-year college\ndegree is extremely high: The average cost of college* in the United States is $35, 551 per student\nper year, including books, supplies, and daily living expenses and this cost has more than doubled in\nthe 21st century alone, with an annual growth rate of 7.1% [39].\nHowever, not all institutions have similar outcomes for students. Graduation rates across institutions\nin the U.S. vary widely, and failure to complete a degree can leave a student with significant debt and\na reduced ability to repay it. Understanding factors related to degree completion is an area of active\nresearch.\nFor this task, our goal is to predict whether an institution has a low completion rate, based on other\ncharacteristics of that institution. While the definition of a \u201clow\u201d completion rate is ultimately\nsubjective and context-dependent, we use a thredhold of 50%, which is approximately equivalent\nto the median graduate rate across the institutions in the dataset. We use the completion rate for\nfirst-time, full-time students at four-year institutions (150% of expected time to completion/6 years).\nData Source: We use the College Scorecard23. The College Scorecard is an institution-level dataset\ncompiled by the U.S. Department of Education from 1996-present. The College scorecard includes\ndetailed institutional factors, including information about each institutions\u2019 student population, course\nofferings, and outcomes.\nDistribution Shift: Institutions vary widely in their profiles, student populations, educational\napproach, and target industries or student pathways. We partition universities according to the\nCCBASIC variable24, which gives the Carnegie Classification (Basic)25. This classification uses\na framework developed by the Carnegie Commission on Higher Education in the early 1970s to\nsupport its research program. Partitioning our data according to this variable measures the robustness\nover institutional subpopulations, and is thus a form of subpopulation shift. We use the following\nset of institutions as the target domain (all other institutional types are in the training domain):\n\u2019Special Focus Institutions\u2013Other special-focus institutions\u2019, \u2019Special Focus Institutions\u2013Theological\nseminaries, Bible colleges, and other faith-related institutions\u2019, \"Associate\u2019s\u2013Private For-profit 4-year\nPrimarily Associate\u2019s\", \u2019Baccalaureate Colleges\u2013Diverse Fields\u2019, \u2019Special Focus Institutions\u2013Schools\nof art, music, and design\u2019, \"Associate\u2019s\u2013Private Not-for-profit\", \"Baccalaureate/Associate\u2019s Colleges\",\n\"Master\u2019s Colleges and Universities (larger programs)\". Exact definitions of each institution class are\navailable via the Carnegie Commission on Higher Education26.\n   22\n    https://community.fico.com/s/blog-post/a5Q2E0000001czyUAA/fico1670\n   23\n    https://collegescorecard.ed.gov\n   24\n    The data dictionary for the College Scorecard is available at https://collegescorecard.ed.gov/\nassets/CollegeScorecardDataDictionary.xlsx\n   25\n    https://carnegieclassifications.acenet.edu\n   26\n    https://carnegieclassifications.acenet.edu\n                                                   24", "md": "Based on payment history and credit use and many marginalized groups in the United States have lower or less reliable incomes, these marginalized groups can suffer from systematically lower credit scores [60, 71, 8, 58]; this has been referred to as the \u201ccredit gap\u201d [49, 22]. In particular, debt and savings level play a role in credit scores and can systematically disadvantage Black and Hispanic applicants, even when demographic data are not formally used in the credit rating process [60, 58].\n\nFor this task, we partition the dataset based on the \u2018External Risk Estimate\u2019, a feature in the dataset corresponding to the risk estimate assigned to an applicant by a third-party service. This estimate was identified in the original FICO explanable ML challenge 22. We use individuals with a high external risk estimate (where \u201chigh\u201d estimate is defined as exceeding an external risk estimate of 63, a threshold identified in the original challenge-winning model linked above) as the training domain, and individuals with estimate \u2264 63 as the held-out domain.\n\n## College Scorecard Degree Completion Rate\n\nBackground: Higher education is increasingly critical to securing strong job and income opportunities for persons in the United States. At the same time, the cost of obtaining a four-year college degree is extremely high: The average cost of college* in the United States is $35,551 per student per year, including books, supplies, and daily living expenses and this cost has more than doubled in the 21st century alone, with an annual growth rate of 7.1% [39].\n\nHowever, not all institutions have similar outcomes for students. Graduation rates across institutions in the U.S. vary widely, and failure to complete a degree can leave a student with significant debt and a reduced ability to repay it. Understanding factors related to degree completion is an area of active research.\n\nFor this task, our goal is to predict whether an institution has a low completion rate, based on other characteristics of that institution. While the definition of a \u201clow\u201d completion rate is ultimately subjective and context-dependent, we use a threshold of 50%, which is approximately equivalent to the median graduate rate across the institutions in the dataset. We use the completion rate for first-time, full-time students at four-year institutions (150% of expected time to completion/6 years).\n\nData Source: We use the College Scorecard 23. The College Scorecard is an institution-level dataset compiled by the U.S. Department of Education from 1996-present. The College scorecard includes detailed institutional factors, including information about each institutions\u2019 student population, course offerings, and outcomes.\n\nDistribution Shift: Institutions vary widely in their profiles, student populations, educational approach, and target industries or student pathways. We partition universities according to the CCBASIC variable 24, which gives the Carnegie Classification (Basic) 25. This classification uses a framework developed by the Carnegie Commission on Higher Education in the early 1970s to support its research program. Partitioning our data according to this variable measures the robustness over institutional subpopulations, and is thus a form of subpopulation shift. We use the following set of institutions as the target domain (all other institutional types are in the training domain):\n\n- 'Special Focus Institutions\u2013Other special-focus institutions'\n- 'Special Focus Institutions\u2013Theological seminaries, Bible colleges, and other faith-related institutions'\n- 'Associate\u2019s\u2013Private For-profit 4-year Primarily Associate\u2019s'\n- 'Baccalaureate Colleges\u2013Diverse Fields'\n- 'Special Focus Institutions\u2013Schools of art, music, and design'\n- 'Associate\u2019s\u2013Private Not-for-profit'\n- 'Baccalaureate/Associate\u2019s Colleges'\n- 'Master\u2019s Colleges and Universities (larger programs)'\n\nExact definitions of each institution class are available via the Carnegie Commission on Higher Education 26.", "images": [], "items": [{"type": "text", "value": "Based on payment history and credit use and many marginalized groups in the United States have lower or less reliable incomes, these marginalized groups can suffer from systematically lower credit scores [60, 71, 8, 58]; this has been referred to as the \u201ccredit gap\u201d [49, 22]. In particular, debt and savings level play a role in credit scores and can systematically disadvantage Black and Hispanic applicants, even when demographic data are not formally used in the credit rating process [60, 58].\n\nFor this task, we partition the dataset based on the \u2018External Risk Estimate\u2019, a feature in the dataset corresponding to the risk estimate assigned to an applicant by a third-party service. This estimate was identified in the original FICO explanable ML challenge 22. We use individuals with a high external risk estimate (where \u201chigh\u201d estimate is defined as exceeding an external risk estimate of 63, a threshold identified in the original challenge-winning model linked above) as the training domain, and individuals with estimate \u2264 63 as the held-out domain.", "md": "Based on payment history and credit use and many marginalized groups in the United States have lower or less reliable incomes, these marginalized groups can suffer from systematically lower credit scores [60, 71, 8, 58]; this has been referred to as the \u201ccredit gap\u201d [49, 22]. In particular, debt and savings level play a role in credit scores and can systematically disadvantage Black and Hispanic applicants, even when demographic data are not formally used in the credit rating process [60, 58].\n\nFor this task, we partition the dataset based on the \u2018External Risk Estimate\u2019, a feature in the dataset corresponding to the risk estimate assigned to an applicant by a third-party service. This estimate was identified in the original FICO explanable ML challenge 22. We use individuals with a high external risk estimate (where \u201chigh\u201d estimate is defined as exceeding an external risk estimate of 63, a threshold identified in the original challenge-winning model linked above) as the training domain, and individuals with estimate \u2264 63 as the held-out domain."}, {"type": "heading", "lvl": 2, "value": "College Scorecard Degree Completion Rate", "md": "## College Scorecard Degree Completion Rate"}, {"type": "text", "value": "Background: Higher education is increasingly critical to securing strong job and income opportunities for persons in the United States. At the same time, the cost of obtaining a four-year college degree is extremely high: The average cost of college* in the United States is $35,551 per student per year, including books, supplies, and daily living expenses and this cost has more than doubled in the 21st century alone, with an annual growth rate of 7.1% [39].\n\nHowever, not all institutions have similar outcomes for students. Graduation rates across institutions in the U.S. vary widely, and failure to complete a degree can leave a student with significant debt and a reduced ability to repay it. Understanding factors related to degree completion is an area of active research.\n\nFor this task, our goal is to predict whether an institution has a low completion rate, based on other characteristics of that institution. While the definition of a \u201clow\u201d completion rate is ultimately subjective and context-dependent, we use a threshold of 50%, which is approximately equivalent to the median graduate rate across the institutions in the dataset. We use the completion rate for first-time, full-time students at four-year institutions (150% of expected time to completion/6 years).\n\nData Source: We use the College Scorecard 23. The College Scorecard is an institution-level dataset compiled by the U.S. Department of Education from 1996-present. The College scorecard includes detailed institutional factors, including information about each institutions\u2019 student population, course offerings, and outcomes.\n\nDistribution Shift: Institutions vary widely in their profiles, student populations, educational approach, and target industries or student pathways. We partition universities according to the CCBASIC variable 24, which gives the Carnegie Classification (Basic) 25. This classification uses a framework developed by the Carnegie Commission on Higher Education in the early 1970s to support its research program. Partitioning our data according to this variable measures the robustness over institutional subpopulations, and is thus a form of subpopulation shift. We use the following set of institutions as the target domain (all other institutional types are in the training domain):\n\n- 'Special Focus Institutions\u2013Other special-focus institutions'\n- 'Special Focus Institutions\u2013Theological seminaries, Bible colleges, and other faith-related institutions'\n- 'Associate\u2019s\u2013Private For-profit 4-year Primarily Associate\u2019s'\n- 'Baccalaureate Colleges\u2013Diverse Fields'\n- 'Special Focus Institutions\u2013Schools of art, music, and design'\n- 'Associate\u2019s\u2013Private Not-for-profit'\n- 'Baccalaureate/Associate\u2019s Colleges'\n- 'Master\u2019s Colleges and Universities (larger programs)'\n\nExact definitions of each institution class are available via the Carnegie Commission on Higher Education 26.", "md": "Background: Higher education is increasingly critical to securing strong job and income opportunities for persons in the United States. At the same time, the cost of obtaining a four-year college degree is extremely high: The average cost of college* in the United States is $35,551 per student per year, including books, supplies, and daily living expenses and this cost has more than doubled in the 21st century alone, with an annual growth rate of 7.1% [39].\n\nHowever, not all institutions have similar outcomes for students. Graduation rates across institutions in the U.S. vary widely, and failure to complete a degree can leave a student with significant debt and a reduced ability to repay it. Understanding factors related to degree completion is an area of active research.\n\nFor this task, our goal is to predict whether an institution has a low completion rate, based on other characteristics of that institution. While the definition of a \u201clow\u201d completion rate is ultimately subjective and context-dependent, we use a threshold of 50%, which is approximately equivalent to the median graduate rate across the institutions in the dataset. We use the completion rate for first-time, full-time students at four-year institutions (150% of expected time to completion/6 years).\n\nData Source: We use the College Scorecard 23. The College Scorecard is an institution-level dataset compiled by the U.S. Department of Education from 1996-present. The College scorecard includes detailed institutional factors, including information about each institutions\u2019 student population, course offerings, and outcomes.\n\nDistribution Shift: Institutions vary widely in their profiles, student populations, educational approach, and target industries or student pathways. We partition universities according to the CCBASIC variable 24, which gives the Carnegie Classification (Basic) 25. This classification uses a framework developed by the Carnegie Commission on Higher Education in the early 1970s to support its research program. Partitioning our data according to this variable measures the robustness over institutional subpopulations, and is thus a form of subpopulation shift. We use the following set of institutions as the target domain (all other institutional types are in the training domain):\n\n- 'Special Focus Institutions\u2013Other special-focus institutions'\n- 'Special Focus Institutions\u2013Theological seminaries, Bible colleges, and other faith-related institutions'\n- 'Associate\u2019s\u2013Private For-profit 4-year Primarily Associate\u2019s'\n- 'Baccalaureate Colleges\u2013Diverse Fields'\n- 'Special Focus Institutions\u2013Schools of art, music, and design'\n- 'Associate\u2019s\u2013Private Not-for-profit'\n- 'Baccalaureate/Associate\u2019s Colleges'\n- 'Master\u2019s Colleges and Universities (larger programs)'\n\nExact definitions of each institution class are available via the Carnegie Commission on Higher Education 26."}]}, {"page": 25, "text": "  B.15    ASSISTments Tutoring System Correct Answer Prediction\n  Background: Machine learning systems are increasingly being adopted in digital learning tools for\n  students of all ages. The ASSISTments tutoring platform27 is a free, web-based, data-driven tutoring\n  platform for students in grades 3-12. As of 2020, ASSISTments has been used by approximately\n  60,000 students with over 12 million problems solved [27]. ASSISTments also periodically releases\n  open-source data snapshots from their platform to support educational research.\n  Data Source: We use the open-source ASSISTments 2012-2013 dataset. This is a dataset from\n  school year 2012-2013 which contains submission-level features (each row in the dataset represents\n  one submission by a student attempting to answer a problem on the ASSISTments tutoring platform).\n  In addition to containing student-, problem-, and school-level features, the dataset also contains affect\n  predictions for students based on an experimental affect detector implemented in ASSISTments.\n  (These affect predictions are intended to be useful in identifying affective states such as boredom,\n  confusion, frustration, and engaged problem-solving behavior).\n  Distribution Shift: We partition the datasets by school. Approximately 700 schools are in the\n  training set, and 10 schools are used as the target distribution. This simulates the process of deploying\n  ASSISTments at a new school.\n  C     Dataset Availability\n  All datasets in TABLESHIFT meet the definition of \u201cavailable and accessible\u201d as described in [65];\n  namely, the data can be obtained without a personal request to the PI. All datasets are obtained from\n  reliable, high-quality sources (United States government agencies, UCI Machine Learning Repository,\n  Kaggle). We selected high-quality data sources which we expect to ensure keep the relevant data\n  available for the foreseeable future. We provide a single script that can be used to download and\n  preprocess TABLESHIFT data for all tasks in the git repository.\n  The data sources used to construct the TABLESHIFT benchmark datasets vary, and necessarily so\n  do the restrictions or agreements required to access this data. All data sources have an established\n  credentialization procedure that is open to the public, provides rapid access to the data, and is\n  expected to be maintained for many years. An overview of the restrictions for each dataset is given\n  below. A link to the data use agreement or credentialization procedure for each dataset marked \u201copen\n  credentialized access\u201d is available in the README of our github repo; we will maintain this list over\n  time if the access agreements change.\n                                        Table 2: Dataset availability.\nTask                         Public     Open Credentialized         Source\n                             Access     Access\nASSISTments                  \u2713                                      Kaggle\nCollege Scorecard            \u2713                                      Department of Education\nICU Hospital Mortality                  \u2713                           MIMIC Clinical Database\nHospital Readmission         \u2713                                      UCI Machine Learning Repository\nDiabetes                     \u2713                                      Centers for Disease Control/BRFSS\nICU Length of Stay                      \u2713                           MIMIC Clinical Database\nVoting                                  \u2713                           American National Election Survey\nFood Stamps                  \u2713                                      American Community Survey\nUnemployment                 \u2713                                      American Community Survey\nIncome                       \u2713                                      American Community Survey\nFICO HELOC                              \u2713                           FICO\nPublic Health Ins.           \u2713                                      American Community Survey\nSepsis                                  \u2713                           PhysioNet\nChildhood Lead               \u2713                                      Centers for Disease Control/NHANES\nHypertension                 \u2713                                      Centers for Disease Control/BRFSS\n     27\n      https://new.assistments.org\n                                                     25", "md": "## B.15    ASSISTments Tutoring System Correct Answer Prediction\n\nBackground: Machine learning systems are increasingly being adopted in digital learning tools for students of all ages. The ASSISTments tutoring platform27 is a free, web-based, data-driven tutoring platform for students in grades 3-12. As of 2020, ASSISTments has been used by approximately 60,000 students with over 12 million problems solved [27]. ASSISTments also periodically releases open-source data snapshots from their platform to support educational research.\n\nData Source: We use the open-source ASSISTments 2012-2013 dataset. This is a dataset from school year 2012-2013 which contains submission-level features (each row in the dataset represents one submission by a student attempting to answer a problem on the ASSISTments tutoring platform). In addition to containing student-, problem-, and school-level features, the dataset also contains affect predictions for students based on an experimental affect detector implemented in ASSISTments. (These affect predictions are intended to be useful in identifying affective states such as boredom, confusion, frustration, and engaged problem-solving behavior).\n\nDistribution Shift: We partition the datasets by school. Approximately 700 schools are in the training set, and 10 schools are used as the target distribution. This simulates the process of deploying ASSISTments at a new school.\n\n## C     Dataset Availability\n\nAll datasets in TABLESHIFT meet the definition of \u201cavailable and accessible\u201d as described in [65]; namely, the data can be obtained without a personal request to the PI. All datasets are obtained from reliable, high-quality sources (United States government agencies, UCI Machine Learning Repository, Kaggle). We selected high-quality data sources which we expect to ensure keep the relevant data available for the foreseeable future. We provide a single script that can be used to download and preprocess TABLESHIFT data for all tasks in the git repository.\n\nThe data sources used to construct the TABLESHIFT benchmark datasets vary, and necessarily so do the restrictions or agreements required to access this data. All data sources have an established credentialization procedure that is open to the public, provides rapid access to the data, and is expected to be maintained for many years. An overview of the restrictions for each dataset is given below. A link to the data use agreement or credentialization procedure for each dataset marked \u201copen credentialized access\u201d is available in the README of our github repo; we will maintain this list over time if the access agreements change.\n\n**Table 2: Dataset availability.**\n|Task|Public Access|Open Credentialized Access|Source|\n|---|---|---|---|\n|ASSISTments|\u2713| |Kaggle|\n|College Scorecard|\u2713| |Department of Education|\n|ICU Hospital Mortality| |\u2713|MIMIC Clinical Database|\n|Hospital Readmission|\u2713| |UCI Machine Learning Repository|\n|Diabetes|\u2713| |Centers for Disease Control/BRFSS|\n|ICU Length of Stay| |\u2713|MIMIC Clinical Database|\n|Voting| |\u2713|American National Election Survey|\n|Food Stamps|\u2713| |American Community Survey|\n|Unemployment|\u2713| |American Community Survey|\n|Income|\u2713| |American Community Survey|\n|FICO HELOC| |\u2713|FICO|\n|Public Health Ins.|\u2713| |American Community Survey|\n|Sepsis| |\u2713|PhysioNet|\n|Childhood Lead|\u2713| |Centers for Disease Control/NHANES|\n|Hypertension|\u2713| |Centers for Disease Control/BRFSS|\n\n27 https://new.assistments.org", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "B.15    ASSISTments Tutoring System Correct Answer Prediction", "md": "## B.15    ASSISTments Tutoring System Correct Answer Prediction"}, {"type": "text", "value": "Background: Machine learning systems are increasingly being adopted in digital learning tools for students of all ages. The ASSISTments tutoring platform27 is a free, web-based, data-driven tutoring platform for students in grades 3-12. As of 2020, ASSISTments has been used by approximately 60,000 students with over 12 million problems solved [27]. ASSISTments also periodically releases open-source data snapshots from their platform to support educational research.\n\nData Source: We use the open-source ASSISTments 2012-2013 dataset. This is a dataset from school year 2012-2013 which contains submission-level features (each row in the dataset represents one submission by a student attempting to answer a problem on the ASSISTments tutoring platform). In addition to containing student-, problem-, and school-level features, the dataset also contains affect predictions for students based on an experimental affect detector implemented in ASSISTments. (These affect predictions are intended to be useful in identifying affective states such as boredom, confusion, frustration, and engaged problem-solving behavior).\n\nDistribution Shift: We partition the datasets by school. Approximately 700 schools are in the training set, and 10 schools are used as the target distribution. This simulates the process of deploying ASSISTments at a new school.", "md": "Background: Machine learning systems are increasingly being adopted in digital learning tools for students of all ages. The ASSISTments tutoring platform27 is a free, web-based, data-driven tutoring platform for students in grades 3-12. As of 2020, ASSISTments has been used by approximately 60,000 students with over 12 million problems solved [27]. ASSISTments also periodically releases open-source data snapshots from their platform to support educational research.\n\nData Source: We use the open-source ASSISTments 2012-2013 dataset. This is a dataset from school year 2012-2013 which contains submission-level features (each row in the dataset represents one submission by a student attempting to answer a problem on the ASSISTments tutoring platform). In addition to containing student-, problem-, and school-level features, the dataset also contains affect predictions for students based on an experimental affect detector implemented in ASSISTments. (These affect predictions are intended to be useful in identifying affective states such as boredom, confusion, frustration, and engaged problem-solving behavior).\n\nDistribution Shift: We partition the datasets by school. Approximately 700 schools are in the training set, and 10 schools are used as the target distribution. This simulates the process of deploying ASSISTments at a new school."}, {"type": "heading", "lvl": 2, "value": "C     Dataset Availability", "md": "## C     Dataset Availability"}, {"type": "text", "value": "All datasets in TABLESHIFT meet the definition of \u201cavailable and accessible\u201d as described in [65]; namely, the data can be obtained without a personal request to the PI. All datasets are obtained from reliable, high-quality sources (United States government agencies, UCI Machine Learning Repository, Kaggle). We selected high-quality data sources which we expect to ensure keep the relevant data available for the foreseeable future. We provide a single script that can be used to download and preprocess TABLESHIFT data for all tasks in the git repository.\n\nThe data sources used to construct the TABLESHIFT benchmark datasets vary, and necessarily so do the restrictions or agreements required to access this data. All data sources have an established credentialization procedure that is open to the public, provides rapid access to the data, and is expected to be maintained for many years. An overview of the restrictions for each dataset is given below. A link to the data use agreement or credentialization procedure for each dataset marked \u201copen credentialized access\u201d is available in the README of our github repo; we will maintain this list over time if the access agreements change.\n\n**Table 2: Dataset availability.**", "md": "All datasets in TABLESHIFT meet the definition of \u201cavailable and accessible\u201d as described in [65]; namely, the data can be obtained without a personal request to the PI. All datasets are obtained from reliable, high-quality sources (United States government agencies, UCI Machine Learning Repository, Kaggle). We selected high-quality data sources which we expect to ensure keep the relevant data available for the foreseeable future. We provide a single script that can be used to download and preprocess TABLESHIFT data for all tasks in the git repository.\n\nThe data sources used to construct the TABLESHIFT benchmark datasets vary, and necessarily so do the restrictions or agreements required to access this data. All data sources have an established credentialization procedure that is open to the public, provides rapid access to the data, and is expected to be maintained for many years. An overview of the restrictions for each dataset is given below. A link to the data use agreement or credentialization procedure for each dataset marked \u201copen credentialized access\u201d is available in the README of our github repo; we will maintain this list over time if the access agreements change.\n\n**Table 2: Dataset availability.**"}, {"type": "table", "rows": [["Task", "Public Access", "Open Credentialized Access", "Source"], ["ASSISTments", "\u2713", "", "Kaggle"], ["College Scorecard", "\u2713", "", "Department of Education"], ["ICU Hospital Mortality", "", "\u2713", "MIMIC Clinical Database"], ["Hospital Readmission", "\u2713", "", "UCI Machine Learning Repository"], ["Diabetes", "\u2713", "", "Centers for Disease Control/BRFSS"], ["ICU Length of Stay", "", "\u2713", "MIMIC Clinical Database"], ["Voting", "", "\u2713", "American National Election Survey"], ["Food Stamps", "\u2713", "", "American Community Survey"], ["Unemployment", "\u2713", "", "American Community Survey"], ["Income", "\u2713", "", "American Community Survey"], ["FICO HELOC", "", "\u2713", "FICO"], ["Public Health Ins.", "\u2713", "", "American Community Survey"], ["Sepsis", "", "\u2713", "PhysioNet"], ["Childhood Lead", "\u2713", "", "Centers for Disease Control/NHANES"], ["Hypertension", "\u2713", "", "Centers for Disease Control/BRFSS"]], "md": "|Task|Public Access|Open Credentialized Access|Source|\n|---|---|---|---|\n|ASSISTments|\u2713| |Kaggle|\n|College Scorecard|\u2713| |Department of Education|\n|ICU Hospital Mortality| |\u2713|MIMIC Clinical Database|\n|Hospital Readmission|\u2713| |UCI Machine Learning Repository|\n|Diabetes|\u2713| |Centers for Disease Control/BRFSS|\n|ICU Length of Stay| |\u2713|MIMIC Clinical Database|\n|Voting| |\u2713|American National Election Survey|\n|Food Stamps|\u2713| |American Community Survey|\n|Unemployment|\u2713| |American Community Survey|\n|Income|\u2713| |American Community Survey|\n|FICO HELOC| |\u2713|FICO|\n|Public Health Ins.|\u2713| |American Community Survey|\n|Sepsis| |\u2713|PhysioNet|\n|Childhood Lead|\u2713| |Centers for Disease Control/NHANES|\n|Hypertension|\u2713| |Centers for Disease Control/BRFSS|", "isPerfectTable": true, "csv": "\"Task\",\"Public Access\",\"Open Credentialized Access\",\"Source\"\n\"ASSISTments\",\"\u2713\",\"\",\"Kaggle\"\n\"College Scorecard\",\"\u2713\",\"\",\"Department of Education\"\n\"ICU Hospital Mortality\",\"\",\"\u2713\",\"MIMIC Clinical Database\"\n\"Hospital Readmission\",\"\u2713\",\"\",\"UCI Machine Learning Repository\"\n\"Diabetes\",\"\u2713\",\"\",\"Centers for Disease Control/BRFSS\"\n\"ICU Length of Stay\",\"\",\"\u2713\",\"MIMIC Clinical Database\"\n\"Voting\",\"\",\"\u2713\",\"American National Election Survey\"\n\"Food Stamps\",\"\u2713\",\"\",\"American Community Survey\"\n\"Unemployment\",\"\u2713\",\"\",\"American Community Survey\"\n\"Income\",\"\u2713\",\"\",\"American Community Survey\"\n\"FICO HELOC\",\"\",\"\u2713\",\"FICO\"\n\"Public Health Ins.\",\"\u2713\",\"\",\"American Community Survey\"\n\"Sepsis\",\"\",\"\u2713\",\"PhysioNet\"\n\"Childhood Lead\",\"\u2713\",\"\",\"Centers for Disease Control/NHANES\"\n\"Hypertension\",\"\u2713\",\"\",\"Centers for Disease Control/BRFSS\""}, {"type": "text", "value": "27 https://new.assistments.org", "md": "27 https://new.assistments.org"}]}, {"page": 26, "text": "D      Related Work\nD.1     Distribution/Domain Shift\nThe (non)robustness of modern machine learning models to distribution shift has been extensively\nstudied, but primarily in non-tabular domains, such as vision and language [62, 61]. Through the use\nof diverse and high-quality benchmarking suites, several recent works have demonstrated that many\nexisting robust learning or domain generalization methods do not outperform standard supervised\ntraining such as SGD [38, 50]. Recent evidence has also suggested that in-distribution (ID) test\nperformance is a very strong predictor of out-of-distribution (OOD) test performance in the domains\nof image classification [62], language modeling [55], and question answering [9], but whether these\nrelationships hold for tabular data is unknown.\nSeveral families of methods have been proposed to address this sensitivity to distribution shifts,\nincluding methods for distributional robustness [76, 53] and domain generalization [1, 6, 90, 89, 54,\n46] . However, these methods are largely evaluated in non-tabular domains, and several \u201cstandard\u201d\ndomain generalization methods have never been applied to tabular data, to our knowledge. Formal\nanalyses of robustness to any kind of shift in the tabular domain have been lacking [33].\nD.2     Tabular Data Modeling\nTabular data \u2013 data defined by structured, heterogeneous features \u2013 is common in many real-world\napplications, including medical diagnosis, finance, social science, and recommender systems [15, 46,\n78]. In many respects, tabular data is different from the other modalities where deep learning models\nhave had great success in the past decade. In contrast to these other modalities, where deep learning\nis the undisputed state of the art, deep learning-based models have tended to underperform on tabular\ndata, and the state of the art is often considered to be tree-based ensemble models, such as XGBoost,\nLightGBM, or CatBoost [15, 36, 78, 33].\nDeep learning-based models have been proposed for tabular data modeling, including carefully-\nregularized deep multilayer perceptrons (MLPs) [46], tabular variants of ResNet [36] and Transformer\narchitectures [43, 36, 79], and differentiable tree-inspired models [70]. However, it is unclear whether\nthere is any benefit from these sophisticated architectures, which are often derived from models which\nwere designed for non-tabular tasks. Subsequent evaluations of deep learning-based tabular data\nmodels have often shown tree-based models to achieve superior performance [78, 15, 33]. However,\ntheir robustness to distribution shift has not been thoroughly evaluated (a notable exception is [33],\nwhich strictly evaluates subgroup robustness).\nD.3     Benchmarking for Machine Learning\nBenchmarking \u2013 the use of standardized, publicly-available, high-quality datasets to evaluate perfor-\nmance on one or more tasks \u2013 is a critical practice contributing to progress the machine learning [56].\nDistribution shift benchmarks in particular have been critical in assessing progress in the robustness\nof vision and language models, e.g. [50, 38, 80]. Because these benchmarks often require interfacing\nwith many distinct data sources, successful and widely-used benchmarks also typically include a\nlightweight software API for interfacing with benchmarking datasets in a consistent manner28. In\nthe IID setting, benchmark datasets have also been crucial to assessing and driving progress, such\nas ImageNet [29] for vision, LibriSpeech [69] for speech, AudioSet [34] for audio classification, or\nGLUE for NLP [86]. Critically, evaluations have shown that reuse of these high-quality benchmarks\nsuch as CIFAR-10, ImageNet, and even widely-used Kaggle datasets has not led to \u201coverfitting\u201d to\nperformance on the benchmarks [75], and, in fact, progress on these benchmarks generalizes beyond\nthe benchmark tasks [73].\nHigh-quality benchmarks for tabular data are lacking, as has been noted in many previous works\n[36, 15, 33, 37, 78, 57, 35]. Existing datasets used for de facto tabular data \u201cbenchmarking\u201d are often\nof low quality. For example, the German Credit dataset contains only 1k observations; the COMPAS\nand Adult datasets have data quality and bias issues [11, 12, 24]. While a small number of general\ntabular benchmarks have been proposed [15, 37], they have not seen widespread adoption, do not\n   28e.g.      DomainBed       https://github.com/facebookresearch/DomainBed,                      WILDS  https://\nwilds.stanford.edu/, BIG-bench https://github.com/google/BIG-bench\n                                                           26", "md": "# Related Work\n\n## Distribution/Domain Shift\n\nThe (non)robustness of modern machine learning models to distribution shift has been extensively studied, but primarily in non-tabular domains, such as vision and language [62]. Through the use of diverse and high-quality benchmarking suites, several recent works have demonstrated that many existing robust learning or domain generalization methods do not outperform standard supervised training such as SGD [38], [50]. Recent evidence has also suggested that in-distribution (ID) test performance is a very strong predictor of out-of-distribution (OOD) test performance in the domains of image classification [62], language modeling [55], and question answering [9], but whether these relationships hold for tabular data is unknown.\n\nSeveral families of methods have been proposed to address this sensitivity to distribution shifts, including methods for distributional robustness [76], [53] and domain generalization [1], [6], [90], [89], [54], [46]. However, these methods are largely evaluated in non-tabular domains, and several \u201cstandard\u201d domain generalization methods have never been applied to tabular data, to our knowledge. Formal analyses of robustness to any kind of shift in the tabular domain have been lacking [33].\n\n## Tabular Data Modeling\n\nTabular data \u2013 data defined by structured, heterogeneous features \u2013 is common in many real-world applications, including medical diagnosis, finance, social science, and recommender systems [15], [46], [78]. In many respects, tabular data is different from the other modalities where deep learning models have had great success in the past decade. In contrast to these other modalities, where deep learning is the undisputed state of the art, deep learning-based models have tended to underperform on tabular data, and the state of the art is often considered to be tree-based ensemble models, such as XGBoost, LightGBM, or CatBoost [15], [36], [78], [33].\n\nDeep learning-based models have been proposed for tabular data modeling, including carefully-regularized deep multilayer perceptrons (MLPs) [46], tabular variants of ResNet [36] and Transformer architectures [43], [36], [79], and differentiable tree-inspired models [70]. However, it is unclear whether there is any benefit from these sophisticated architectures, which are often derived from models which were designed for non-tabular tasks. Subsequent evaluations of deep learning-based tabular data models have often shown tree-based models to achieve superior performance [78], [15], [33]. However, their robustness to distribution shift has not been thoroughly evaluated (a notable exception is [33], which strictly evaluates subgroup robustness).\n\n## Benchmarking for Machine Learning\n\nBenchmarking \u2013 the use of standardized, publicly-available, high-quality datasets to evaluate performance on one or more tasks \u2013 is a critical practice contributing to progress the machine learning [56]. Distribution shift benchmarks in particular have been critical in assessing progress in the robustness of vision and language models, e.g. [50], [38], [80]. Because these benchmarks often require interfacing with many distinct data sources, successful and widely-used benchmarks also typically include a lightweight software API for interfacing with benchmarking datasets in a consistent manner28. In the IID setting, benchmark datasets have also been crucial to assessing and driving progress, such as ImageNet [29] for vision, LibriSpeech [69] for speech, AudioSet [34] for audio classification, or GLUE for NLP [86]. Critically, evaluations have shown that reuse of these high-quality benchmarks such as CIFAR-10, ImageNet, and even widely-used Kaggle datasets has not led to \u201coverfitting\u201d to performance on the benchmarks [75], and, in fact, progress on these benchmarks generalizes beyond the benchmark tasks [73].\n\nHigh-quality benchmarks for tabular data are lacking, as has been noted in many previous works [36], [15], [33], [37], [78], [57], [35]. Existing datasets used for de facto tabular data \u201cbenchmarking\u201d are often of low quality. For example, the German Credit dataset contains only 1k observations; the COMPAS and Adult datasets have data quality and bias issues [11], [12], [24]. While a small number of general tabular benchmarks have been proposed [15], [37], they have not seen widespread adoption, do not\n\n28e.g. DomainBed https://github.com/facebookresearch/DomainBed, WILDS https://wilds.stanford.edu/, BIG-bench https://github.com/google/BIG-bench", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Related Work", "md": "# Related Work"}, {"type": "heading", "lvl": 2, "value": "Distribution/Domain Shift", "md": "## Distribution/Domain Shift"}, {"type": "text", "value": "The (non)robustness of modern machine learning models to distribution shift has been extensively studied, but primarily in non-tabular domains, such as vision and language [62]. Through the use of diverse and high-quality benchmarking suites, several recent works have demonstrated that many existing robust learning or domain generalization methods do not outperform standard supervised training such as SGD [38], [50]. Recent evidence has also suggested that in-distribution (ID) test performance is a very strong predictor of out-of-distribution (OOD) test performance in the domains of image classification [62], language modeling [55], and question answering [9], but whether these relationships hold for tabular data is unknown.\n\nSeveral families of methods have been proposed to address this sensitivity to distribution shifts, including methods for distributional robustness [76], [53] and domain generalization [1], [6], [90], [89], [54], [46]. However, these methods are largely evaluated in non-tabular domains, and several \u201cstandard\u201d domain generalization methods have never been applied to tabular data, to our knowledge. Formal analyses of robustness to any kind of shift in the tabular domain have been lacking [33].", "md": "The (non)robustness of modern machine learning models to distribution shift has been extensively studied, but primarily in non-tabular domains, such as vision and language [62]. Through the use of diverse and high-quality benchmarking suites, several recent works have demonstrated that many existing robust learning or domain generalization methods do not outperform standard supervised training such as SGD [38], [50]. Recent evidence has also suggested that in-distribution (ID) test performance is a very strong predictor of out-of-distribution (OOD) test performance in the domains of image classification [62], language modeling [55], and question answering [9], but whether these relationships hold for tabular data is unknown.\n\nSeveral families of methods have been proposed to address this sensitivity to distribution shifts, including methods for distributional robustness [76], [53] and domain generalization [1], [6], [90], [89], [54], [46]. However, these methods are largely evaluated in non-tabular domains, and several \u201cstandard\u201d domain generalization methods have never been applied to tabular data, to our knowledge. Formal analyses of robustness to any kind of shift in the tabular domain have been lacking [33]."}, {"type": "heading", "lvl": 2, "value": "Tabular Data Modeling", "md": "## Tabular Data Modeling"}, {"type": "text", "value": "Tabular data \u2013 data defined by structured, heterogeneous features \u2013 is common in many real-world applications, including medical diagnosis, finance, social science, and recommender systems [15], [46], [78]. In many respects, tabular data is different from the other modalities where deep learning models have had great success in the past decade. In contrast to these other modalities, where deep learning is the undisputed state of the art, deep learning-based models have tended to underperform on tabular data, and the state of the art is often considered to be tree-based ensemble models, such as XGBoost, LightGBM, or CatBoost [15], [36], [78], [33].\n\nDeep learning-based models have been proposed for tabular data modeling, including carefully-regularized deep multilayer perceptrons (MLPs) [46], tabular variants of ResNet [36] and Transformer architectures [43], [36], [79], and differentiable tree-inspired models [70]. However, it is unclear whether there is any benefit from these sophisticated architectures, which are often derived from models which were designed for non-tabular tasks. Subsequent evaluations of deep learning-based tabular data models have often shown tree-based models to achieve superior performance [78], [15], [33]. However, their robustness to distribution shift has not been thoroughly evaluated (a notable exception is [33], which strictly evaluates subgroup robustness).", "md": "Tabular data \u2013 data defined by structured, heterogeneous features \u2013 is common in many real-world applications, including medical diagnosis, finance, social science, and recommender systems [15], [46], [78]. In many respects, tabular data is different from the other modalities where deep learning models have had great success in the past decade. In contrast to these other modalities, where deep learning is the undisputed state of the art, deep learning-based models have tended to underperform on tabular data, and the state of the art is often considered to be tree-based ensemble models, such as XGBoost, LightGBM, or CatBoost [15], [36], [78], [33].\n\nDeep learning-based models have been proposed for tabular data modeling, including carefully-regularized deep multilayer perceptrons (MLPs) [46], tabular variants of ResNet [36] and Transformer architectures [43], [36], [79], and differentiable tree-inspired models [70]. However, it is unclear whether there is any benefit from these sophisticated architectures, which are often derived from models which were designed for non-tabular tasks. Subsequent evaluations of deep learning-based tabular data models have often shown tree-based models to achieve superior performance [78], [15], [33]. However, their robustness to distribution shift has not been thoroughly evaluated (a notable exception is [33], which strictly evaluates subgroup robustness)."}, {"type": "heading", "lvl": 2, "value": "Benchmarking for Machine Learning", "md": "## Benchmarking for Machine Learning"}, {"type": "text", "value": "Benchmarking \u2013 the use of standardized, publicly-available, high-quality datasets to evaluate performance on one or more tasks \u2013 is a critical practice contributing to progress the machine learning [56]. Distribution shift benchmarks in particular have been critical in assessing progress in the robustness of vision and language models, e.g. [50], [38], [80]. Because these benchmarks often require interfacing with many distinct data sources, successful and widely-used benchmarks also typically include a lightweight software API for interfacing with benchmarking datasets in a consistent manner28. In the IID setting, benchmark datasets have also been crucial to assessing and driving progress, such as ImageNet [29] for vision, LibriSpeech [69] for speech, AudioSet [34] for audio classification, or GLUE for NLP [86]. Critically, evaluations have shown that reuse of these high-quality benchmarks such as CIFAR-10, ImageNet, and even widely-used Kaggle datasets has not led to \u201coverfitting\u201d to performance on the benchmarks [75], and, in fact, progress on these benchmarks generalizes beyond the benchmark tasks [73].\n\nHigh-quality benchmarks for tabular data are lacking, as has been noted in many previous works [36], [15], [33], [37], [78], [57], [35]. Existing datasets used for de facto tabular data \u201cbenchmarking\u201d are often of low quality. For example, the German Credit dataset contains only 1k observations; the COMPAS and Adult datasets have data quality and bias issues [11], [12], [24]. While a small number of general tabular benchmarks have been proposed [15], [37], they have not seen widespread adoption, do not\n\n28e.g. DomainBed https://github.com/facebookresearch/DomainBed, WILDS https://wilds.stanford.edu/, BIG-bench https://github.com/google/BIG-bench", "md": "Benchmarking \u2013 the use of standardized, publicly-available, high-quality datasets to evaluate performance on one or more tasks \u2013 is a critical practice contributing to progress the machine learning [56]. Distribution shift benchmarks in particular have been critical in assessing progress in the robustness of vision and language models, e.g. [50], [38], [80]. Because these benchmarks often require interfacing with many distinct data sources, successful and widely-used benchmarks also typically include a lightweight software API for interfacing with benchmarking datasets in a consistent manner28. In the IID setting, benchmark datasets have also been crucial to assessing and driving progress, such as ImageNet [29] for vision, LibriSpeech [69] for speech, AudioSet [34] for audio classification, or GLUE for NLP [86]. Critically, evaluations have shown that reuse of these high-quality benchmarks such as CIFAR-10, ImageNet, and even widely-used Kaggle datasets has not led to \u201coverfitting\u201d to performance on the benchmarks [75], and, in fact, progress on these benchmarks generalizes beyond the benchmark tasks [73].\n\nHigh-quality benchmarks for tabular data are lacking, as has been noted in many previous works [36], [15], [33], [37], [78], [57], [35]. Existing datasets used for de facto tabular data \u201cbenchmarking\u201d are often of low quality. For example, the German Credit dataset contains only 1k observations; the COMPAS and Adult datasets have data quality and bias issues [11], [12], [24]. While a small number of general tabular benchmarks have been proposed [15], [37], they have not seen widespread adoption, do not\n\n28e.g. DomainBed https://github.com/facebookresearch/DomainBed, WILDS https://wilds.stanford.edu/, BIG-bench https://github.com/google/BIG-bench"}]}, {"page": 27, "text": "     TableShift: Out-of-Distribution Accuracy vs. Domain Gap                                                                                                                                                                       Percentage of Max Accuracy (PMA-ID)\n                      0.0                        Across 15 Benchmark Tasks                                                                                               10       1                                         1                         Across All TableShift Tasks*     SAINT\n                                                                                                                                                                                           Change in Label Distribution     2                                                       XGBoost\n                                                                                                                                                                                                                            3                                                   Group DRO\n               Acc    0.1                                                                                                                                                                        yID||                      4                                                          NODE\n                                                                                                                                                                                                                            5                                                     LightGBM\n              Domain Gap                                                                                                                                                                                                    6                                             FT-Transformer\n                                                                                                                                                                                                  y = ||yOOD                7                                                        ResNet\n                      0.2                                                                                                                                                                                           Model Rank\n                                                                                                                                                                         10       2                                         8                                                            MLP\n                                                                                                                                                                                                                            9                                            TabTransformer\n                                                                                                                                                                                                                        10                                               Adv. Label DRO\n                      0.3                                                                                                                                                                                               11                                                              DRO\n                                                                                                                                                                                                                        12                                            Label Group DRO\n                                                                                                                                                                                                                        13                                                          CORAL\n                                                                                                                                                                                                                        14                                                             MMD\n                      0.4                                                                                                                                                                                               15                                                           DANN\n                                                                                                                                                                         10       3                                     16                                                          MixUp\n                                   0.0                    0.2                   0.4                   0.6                   0.8                   1.0                                                                   17                                                             IRM\n                                                  Out-of-Distribution Test Accuracy                                                                                                                                     18                                                          VREX\n                            XGBoost                                SAINT             Model                Group DRO                        MMD                                                                                 0.0                     0.2                     0.4            0.6           0.8                     1.0\n                            LightGBM                               NODE                                   DANN                             CORAL\n                            MLP                                    TabTransformer                         IRM                              Label Group DRO                                                                                    Percentage of Max Accuracy (PMA-ID)\n                            FT-Transformer                         CatBoost                               MixUp                            Adv. Label DRO\n                            ResNet                                 DRO                                    VREX                               Acc = 0\n                                                                                                                                                                                                                                         Baseline                               Model Type           Domain Adaptation\n (a) Out-of-Distribution Accuracy vs. Shift Gap                                                                                                                                                                                          Domain Robustness                                           Label Robustness\n\u2206Acc across all TABLESHIFT tasks.                                                                                                                                                                                                        Domain Generalization\n                                                                                                                                                                                                           (b) Percentage of Maximum In-Distribution Accu-\n                                                                                                                                                                                                           racy (PMA-ID) across all TABLESHIFT tasks.\n                                                                                                                                    Figure 6: Additional results.\n            Covariate Shift                          x vs. Concept Shift                               y|x          Covariate Shift                          x vs. Label Shift                          y              Concept Shift                         y|x vs. Label Shift                  y\n           1011                                                                                                                                                                                                                                                                                                          Task\n             109                                                                                             10      1                                                                                          10      1                                                                                    Food Stamps\n                                                                                                                                                                                                                                                                                                             Income\n                                                                                                                                                                                                                                                                                                             Public Health Ins.\n       y|x   107                                                                                          y                                                                                                  y                                                                                               Unemployment\n       Concept Shift                                                                                      Label Shift                                                                                        Label Shift                                                                                     ANES\n             105                                                                                             10      2                                                                                          10      2                                                                                    Diabetes\n                                                                                                                                                                                                                                                                                                             Hypertension\n             103                                                                                                                                                                                                                                                                                             Hospital Readmission\n                                                                                                                                                                                                                                                                                                             Childhood Lead\n             101                                                                                                                                                                                                                                                                                             Sepsis\n                                                                                                             10      3                                                                                          10      3                                                                                    ICU Length of Stay\n          10      1                                                                                                                                                                                                                                                                                          ICU Hospital Mortality\n                                                                                                                                                                                                                                                                                                             FICO HELOC\n                                                                                                                                                                                                                                                                                                             College Scorecard\n                                   102                105                108               1011                                       102                105                108               1011                                     100             103             106             109                   ASSISTments\n                                          Covariate Shift                   x                                                                Covariate Shift                   x                                                                Concept Shift                   y|x\n Figure 7: Pairwise scatterplots of shifts. Each point represents one dataset. Metrics are computed\n according to the domain split for each dataset (ID test vs. OOD test) according to the metric definitions\n for \u2206x, \u2206y|x, \u2206y in Section E. (a) left: Covariate shift \u2206x (computed via Optimal Transport Data\n Distance) vs. concept shift \u2206y|x (computed via Frechet Dataset Distance); \u03c1 = 0.99. (b) center:\n Covariate shift \u2206x vs. label shift \u2206y                                                                                                       ; \u03c1 = \u22120.20. (c) left: Concept shift \u2206y|x vs. label shift \u2206y                                                                                                                                ;\n \u03c1 = \u22120.20.\n include the software utilities that have driven adoption of benchmarks in language and vision [50, 38],\n and do not contain distribution shifts (we make more detailed comparisons between TableShift and\n existing benchmarks in Section G). Critically, these tabular benchmarks also often lack feature-level\n documentation, which can be critical for tabular data.\n Thus, while limited individual benchmarks do exist for tabular data modeling (without distribution\n shift) or for distribution shift (without tabular data), there is no existing benchmark that provides a\n high-quality set of tabular datasets and associated distribution shifts.\n                                                                                                                                                                                    27", "md": "# TableShift: Out-of-Distribution Accuracy vs. Domain Gap\n\n## TableShift: Out-of-Distribution Accuracy vs. Domain Gap\n\nPercentage of Max Accuracy (PMA-ID)\n\n| |0.0|Across 15 Benchmark Tasks|10|1|\n|---|---|---|---|---|\n|Acc|0.1| | | |\n| |Domain Gap|0.2| | |\n| |0.3| | | |\n| |0.4| | | |\n\nOut-of-Distribution Test Accuracy\n\n| |0.0|0.2|0.4|0.6|0.8|1.0|\n|---|---|---|---|---|---|---|\n| |XGBoost|SAINT|Model|Group DRO| |MMD|\n| |LightGBM|NODE| |DANN| |CORAL|\n| |MLP|TabTransformer| |IRM| |Label Group DRO|\n| |FT-Transformer|CatBoost| |MixUp| |Adv. Label DRO|\n| |ResNet|DRO| |VREX| |Acc = 0|\n\n(a) Out-of-Distribution Accuracy vs. Shift Gap\n\n\u2206Acc across all TABLESHIFT tasks.\n\n(b) Percentage of Maximum In-Distribution Accuracy (PMA-ID) across all TABLESHIFT tasks.\n\nFigure 6: Additional results.\n\n### Covariate Shift x vs. Concept Shift y|x\n\n1011\n\n109\n\n107\n\nConcept Shift\n\n105\n\n103\n\n101\n\n10 1\n\n102 105 108 1011\n\n102 105 108 1011\n\n100 103 106 109\n\nASSISTments\n\nCovariate Shift x\n\nFigure 7: Pairwise scatterplots of shifts. Each point represents one dataset. Metrics are computed according to the domain split for each dataset (ID test vs. OOD test) according to the metric definitions for \u2206x, \u2206y|x, \u2206y in Section E. (a) left: Covariate shift \u2206x (computed via Optimal Transport Data Distance) vs. concept shift \u2206y|x (computed via Frechet Dataset Distance); \u03c1 = 0.99. (b) center: Covariate shift \u2206x vs. label shift \u2206y; \u03c1 = \u22120.20. (c) left: Concept shift \u2206y|x vs. label shift \u2206y; \u03c1 = \u22120.20.\n\ninclude the software utilities that have driven adoption of benchmarks in language and vision [50, 38], and do not contain distribution shifts (we make more detailed comparisons between TableShift and existing benchmarks in Section G). Critically, these tabular benchmarks also often lack feature-level documentation, which can be critical for tabular data.\n\nThus, while limited individual benchmarks do exist for tabular data modeling (without distribution shift) or for distribution shift (without tabular data), there is no existing benchmark that provides a high-quality set of tabular datasets and associated distribution shifts.\n\n27", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "TableShift: Out-of-Distribution Accuracy vs. Domain Gap", "md": "# TableShift: Out-of-Distribution Accuracy vs. Domain Gap"}, {"type": "heading", "lvl": 2, "value": "TableShift: Out-of-Distribution Accuracy vs. Domain Gap", "md": "## TableShift: Out-of-Distribution Accuracy vs. Domain Gap"}, {"type": "text", "value": "Percentage of Max Accuracy (PMA-ID)", "md": "Percentage of Max Accuracy (PMA-ID)"}, {"type": "table", "rows": [["", "0.0", "Across 15 Benchmark Tasks", "10", "1"], ["Acc", "0.1", "", "", ""], ["", "Domain Gap", "0.2", "", ""], ["", "0.3", "", "", ""], ["", "0.4", "", "", ""]], "md": "| |0.0|Across 15 Benchmark Tasks|10|1|\n|---|---|---|---|---|\n|Acc|0.1| | | |\n| |Domain Gap|0.2| | |\n| |0.3| | | |\n| |0.4| | | |", "isPerfectTable": true, "csv": "\"\",\"0.0\",\"Across 15 Benchmark Tasks\",\"10\",\"1\"\n\"Acc\",\"0.1\",\"\",\"\",\"\"\n\"\",\"Domain Gap\",\"0.2\",\"\",\"\"\n\"\",\"0.3\",\"\",\"\",\"\"\n\"\",\"0.4\",\"\",\"\",\"\""}, {"type": "text", "value": "Out-of-Distribution Test Accuracy", "md": "Out-of-Distribution Test Accuracy"}, {"type": "table", "rows": [["", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0"], ["", "XGBoost", "SAINT", "Model", "Group DRO", "", "MMD"], ["", "LightGBM", "NODE", "", "DANN", "", "CORAL"], ["", "MLP", "TabTransformer", "", "IRM", "", "Label Group DRO"], ["", "FT-Transformer", "CatBoost", "", "MixUp", "", "Adv. Label DRO"], ["", "ResNet", "DRO", "", "VREX", "", "Acc = 0"]], "md": "| |0.0|0.2|0.4|0.6|0.8|1.0|\n|---|---|---|---|---|---|---|\n| |XGBoost|SAINT|Model|Group DRO| |MMD|\n| |LightGBM|NODE| |DANN| |CORAL|\n| |MLP|TabTransformer| |IRM| |Label Group DRO|\n| |FT-Transformer|CatBoost| |MixUp| |Adv. Label DRO|\n| |ResNet|DRO| |VREX| |Acc = 0|", "isPerfectTable": true, "csv": "\"\",\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\"\n\"\",\"XGBoost\",\"SAINT\",\"Model\",\"Group DRO\",\"\",\"MMD\"\n\"\",\"LightGBM\",\"NODE\",\"\",\"DANN\",\"\",\"CORAL\"\n\"\",\"MLP\",\"TabTransformer\",\"\",\"IRM\",\"\",\"Label Group DRO\"\n\"\",\"FT-Transformer\",\"CatBoost\",\"\",\"MixUp\",\"\",\"Adv. Label DRO\"\n\"\",\"ResNet\",\"DRO\",\"\",\"VREX\",\"\",\"Acc = 0\""}, {"type": "text", "value": "(a) Out-of-Distribution Accuracy vs. Shift Gap\n\n\u2206Acc across all TABLESHIFT tasks.\n\n(b) Percentage of Maximum In-Distribution Accuracy (PMA-ID) across all TABLESHIFT tasks.\n\nFigure 6: Additional results.", "md": "(a) Out-of-Distribution Accuracy vs. Shift Gap\n\n\u2206Acc across all TABLESHIFT tasks.\n\n(b) Percentage of Maximum In-Distribution Accuracy (PMA-ID) across all TABLESHIFT tasks.\n\nFigure 6: Additional results."}, {"type": "heading", "lvl": 3, "value": "Covariate Shift x vs. Concept Shift y|x", "md": "### Covariate Shift x vs. Concept Shift y|x"}, {"type": "text", "value": "1011\n\n109\n\n107\n\nConcept Shift\n\n105\n\n103\n\n101\n\n10 1\n\n102 105 108 1011\n\n102 105 108 1011\n\n100 103 106 109\n\nASSISTments\n\nCovariate Shift x\n\nFigure 7: Pairwise scatterplots of shifts. Each point represents one dataset. Metrics are computed according to the domain split for each dataset (ID test vs. OOD test) according to the metric definitions for \u2206x, \u2206y|x, \u2206y in Section E. (a) left: Covariate shift \u2206x (computed via Optimal Transport Data Distance) vs. concept shift \u2206y|x (computed via Frechet Dataset Distance); \u03c1 = 0.99. (b) center: Covariate shift \u2206x vs. label shift \u2206y; \u03c1 = \u22120.20. (c) left: Concept shift \u2206y|x vs. label shift \u2206y; \u03c1 = \u22120.20.\n\ninclude the software utilities that have driven adoption of benchmarks in language and vision [50, 38], and do not contain distribution shifts (we make more detailed comparisons between TableShift and existing benchmarks in Section G). Critically, these tabular benchmarks also often lack feature-level documentation, which can be critical for tabular data.\n\nThus, while limited individual benchmarks do exist for tabular data modeling (without distribution shift) or for distribution shift (without tabular data), there is no existing benchmark that provides a high-quality set of tabular datasets and associated distribution shifts.\n\n27", "md": "1011\n\n109\n\n107\n\nConcept Shift\n\n105\n\n103\n\n101\n\n10 1\n\n102 105 108 1011\n\n102 105 108 1011\n\n100 103 106 109\n\nASSISTments\n\nCovariate Shift x\n\nFigure 7: Pairwise scatterplots of shifts. Each point represents one dataset. Metrics are computed according to the domain split for each dataset (ID test vs. OOD test) according to the metric definitions for \u2206x, \u2206y|x, \u2206y in Section E. (a) left: Covariate shift \u2206x (computed via Optimal Transport Data Distance) vs. concept shift \u2206y|x (computed via Frechet Dataset Distance); \u03c1 = 0.99. (b) center: Covariate shift \u2206x vs. label shift \u2206y; \u03c1 = \u22120.20. (c) left: Concept shift \u2206y|x vs. label shift \u2206y; \u03c1 = \u22120.20.\n\ninclude the software utilities that have driven adoption of benchmarks in language and vision [50, 38], and do not contain distribution shifts (we make more detailed comparisons between TableShift and existing benchmarks in Section G). Critically, these tabular benchmarks also often lack feature-level documentation, which can be critical for tabular data.\n\nThus, while limited individual benchmarks do exist for tabular data modeling (without distribution shift) or for distribution shift (without tabular data), there is no existing benchmark that provides a high-quality set of tabular datasets and associated distribution shifts.\n\n27"}]}, {"page": 28, "text": "             Covariate Shift              x vs. Shift Gap                          Concept Shift             y|x vs. Shift Gap                             Label Shift          y vs. Shift Gap\n    AccDtr|            Correlation           =-0.16                       AccDtr|          Correlation           =-0.157                      AccDtr|           Correlation           =0.695                                    Task Title\n                                                                                                                                                                                                                           Food Stamps\n     Acc| = |AccDte                                                       Acc| = |AccDte                                                       Acc| = |AccDte                                                              Income\n      10   1                                                                10   1                                                              10   1                                                                     Public Health Ins.\n                                                                                                                                                                                                                           Unemployment\n                                                                                                                                                                                                                           ANES\n                                                                                                                                                                                                                           ASSISTments\n    Abs. Val. of Shift Gap |                                              Abs. Val. of Shift Gap |                                            Abs. Val. of Shift Gap |                                                     Hypertension\n      10   2                                                                10   2                                                              10   2                                                                     Diabetes\n                                                                                                                                                                                                                           College Scorecard\n                                                                                                                                                                                                                           Hospital Readmission\n                                                                                                                                                                                                                           FICO HELOC\n                                                                                                                                                                                                                           ICU Hospital Mortality\n                                                                                                                                                                                                                           ICU Length of Stay\n      10   3                                                                10   3                                                              10   3                                                                     Childhood Lead\n                      102          105          108         1011                           100        103        106       109                                  10   3           10   2          10   1                    Sepsis\n                           Covariate Shift         x                                             Concept Shift        y|x                                               Label Shift       y\nFigure 8: Domain shift metrics vs. (absolute) shift gap. Each point represents a tuned model on a\ngiven dataset. Only Label shift shows a strong correlation with shift gap (\u03c1 = 0.73).\n                                       Average ID vs. OOD Accuracy Across TableShift Benchmark Tasks\n                   All TableShift Tasks (15 Tasks)*                                            Non-Domain Generalization (5 Tasks)                                                  Domain Generalization (10 Tasks)\n     est Accuracy                                                                       est Accuracy                                                                      est Accuracy\n       0.85                                                                               0.85                                                                              0.85\n       0.80                                                                               0.80                                                                              0.80\n     Out-of-Distribution T                                                              Out-of-Distribution T                                                             Out-of-Distribution T\n       0.75                                                                               0.75                                                                              0.75\n       0.70                                                                               0.70                                                                              0.70\n       0.65                                                                               0.65                                                                              0.65\n                 0.65         0.70          0.75          0.80          0.85                       0.65          0.70          0.75         0.80          0.85                       0.65          0.70          0.75          0.80          0.85\n                          In-Distribution Test Accuracy                                                      In-Distribution Test Accuracy                                                     In-Distribution Test Accuracy\n                                                                            XGBoost                           SAINT             Model          Group DRO                    MMD\n                                                                            LightGBM                          NODE                             DANN                         CORAL\n                                                                            MLP                               TabTransformer                   IRM                          Label Group DRO\n                                                                            FT-Transformer                    CatBoost                         MixUp                        Adv. Label DRO\n                                                                            ResNet                            DRO                              VREX                         y=x\nFigure 9: TableShift benchmark results, mean per model (left: non-domain generalization tasks,\n\u03c1 = 0.834; right: domain generalization tasks, \u03c1 = 963). In-domain and out-of-domain accuracy\nshow a general linear trend. Baseline models (blue) consistently match or outperform domain\nrobustness and domain generalization methods.\nE            Additional Dataset Details and Results\nIn this section we provide a brief tour of exploratory results regarding the domain shift datasets in\nTableShift, and additional expeirmental results.\nE.1            Domain Split Selection\nFor many tasks in TableShift, there exist clear motivations for selecting certain splitting variables,\nand for selecting which values of these variables to use as out-of-domain value(s) for our benchmarks.\nHowever, for oehters, there might bemultiple plausible splitting variables, or no obvious way to\nchoose which specific value(s) to use as out of domain (e.g., any geographic region in ACS might be\nequallyplausible as a holdout domain for the Feed Stamps task).\nFor tasks where there were known domain splits that were likely to induce performance gaps that\nmatches a real-world domain shift scenario, we began by selecting these. When tuned baselines\n(LightGBM and XGBoost) showed a shift gap \u2206Acc of at least 1%, we used that split. However,\nfor tasks without a clear domain split or where mutliple plausible splitting values exist, we do the\nfollowing. First, we identified a variable(s) that was likely to contribute to an actual shift in a real-\nworld production through reviewing the relevant literature. Then, for each value d \u2208                                                                                                                                  {d1, . . . dD} =\n                                                                                                                            28", "md": "# Domain Shift Analysis\n\n## Covariate Shift\n\n|x vs. Shift Gap|Concept Shift|y|x vs. Shift Gap|Label Shift|y vs. Shift Gap|\n|---|---|---|---|---|\n|AccDtr| Correlation = -0.16|AccDtr| Correlation = -0.157|AccDtr| Correlation = 0.695| |Task Title|\n\n## Task Details\n\n- Food Stamps\n- Income\n- Public Health Ins.\n- Unemployment\n- ANES\n- ASSISTments\n- Hypertension\n- Diabetes\n- College Scorecard\n- Hospital Readmission\n- FICO HELOC\n- ICU Hospital Mortality\n- ICU Length of Stay\n- Childhood Lead\n- Sepsis\n\n## Domain Shift Metrics\n\nFigure 8: Domain shift metrics vs. (absolute) shift gap. Each point represents a tuned model on a given dataset. Only Label shift shows a strong correlation with shift gap (\u03c1 = 0.73).\n\n## Accuracy Comparison\n\n| |All TableShift Tasks (15 Tasks)*|Non-Domain Generalization (5 Tasks)|Domain Generalization (10 Tasks)|\n|---|---|---|---|\n|est Accuracy|0.85|0.85|0.85|\n|Out-of-Distribution T|0.75|0.75|0.75|\n|In-Distribution Test Accuracy|0.65 0.70 0.75 0.80 0.85|0.65 0.70 0.75 0.80 0.85|0.65 0.70 0.75 0.80 0.85|\n\n## Model Comparison\n\nFigure 9: TableShift benchmark results, mean per model (left: non-domain generalization tasks, \u03c1 = 0.834; right: domain generalization tasks, \u03c1 = 963). In-domain and out-of-domain accuracy show a general linear trend. Baseline models (blue) consistently match or outperform domain robustness and domain generalization methods.\n\n## Additional Dataset Details and Results\n\n### Domain Split Selection\n\nIn this section we provide a brief tour of exploratory results regarding the domain shift datasets in TableShift, and additional experimental results.\n\n#### For many tasks in TableShift:\n\nThere exist clear motivations for selecting certain splitting variables, and for selecting which values of these variables to use as out-of-domain value(s) for our benchmarks.\n\n#### For others:\n\nThere might be multiple plausible splitting variables, or no obvious way to choose which specific value(s) to use as out of domain (e.g., any geographic region in ACS might be equally plausible as a holdout domain for the Food Stamps task).\n\nFor tasks where there were known domain splits that were likely to induce performance gaps that match a real-world domain shift scenario, we began by selecting these. When tuned baselines (LightGBM and XGBoost) showed a shift gap \u2206Acc of at least 1%, we used that split. However, for tasks without a clear domain split or where multiple plausible splitting values exist, we do the following. First, we identified a variable(s) that was likely to contribute to an actual shift in a real-world production through reviewing the relevant literature. Then, for each value d \u2208 {d1, . . . dD} = 28", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Domain Shift Analysis", "md": "# Domain Shift Analysis"}, {"type": "heading", "lvl": 2, "value": "Covariate Shift", "md": "## Covariate Shift"}, {"type": "table", "rows": [["x vs. Shift Gap", "Concept Shift", "y", "x vs. Shift Gap", "Label Shift", "y vs. Shift Gap"], ["AccDtr", "Correlation = -0.16", "AccDtr", "Correlation = -0.157", "AccDtr", "Correlation = 0.695", "", "Task Title"]], "md": "|x vs. Shift Gap|Concept Shift|y|x vs. Shift Gap|Label Shift|y vs. Shift Gap|\n|---|---|---|---|---|\n|AccDtr| Correlation = -0.16|AccDtr| Correlation = -0.157|AccDtr| Correlation = 0.695| |Task Title|", "isPerfectTable": false, "csv": "\"x vs. Shift Gap\",\"Concept Shift\",\"y\",\"x vs. Shift Gap\",\"Label Shift\",\"y vs. Shift Gap\"\n\"AccDtr\",\"Correlation = -0.16\",\"AccDtr\",\"Correlation = -0.157\",\"AccDtr\",\"Correlation = 0.695\",\"\",\"Task Title\""}, {"type": "heading", "lvl": 2, "value": "Task Details", "md": "## Task Details"}, {"type": "text", "value": "- Food Stamps\n- Income\n- Public Health Ins.\n- Unemployment\n- ANES\n- ASSISTments\n- Hypertension\n- Diabetes\n- College Scorecard\n- Hospital Readmission\n- FICO HELOC\n- ICU Hospital Mortality\n- ICU Length of Stay\n- Childhood Lead\n- Sepsis", "md": "- Food Stamps\n- Income\n- Public Health Ins.\n- Unemployment\n- ANES\n- ASSISTments\n- Hypertension\n- Diabetes\n- College Scorecard\n- Hospital Readmission\n- FICO HELOC\n- ICU Hospital Mortality\n- ICU Length of Stay\n- Childhood Lead\n- Sepsis"}, {"type": "heading", "lvl": 2, "value": "Domain Shift Metrics", "md": "## Domain Shift Metrics"}, {"type": "text", "value": "Figure 8: Domain shift metrics vs. (absolute) shift gap. Each point represents a tuned model on a given dataset. Only Label shift shows a strong correlation with shift gap (\u03c1 = 0.73).", "md": "Figure 8: Domain shift metrics vs. (absolute) shift gap. Each point represents a tuned model on a given dataset. Only Label shift shows a strong correlation with shift gap (\u03c1 = 0.73)."}, {"type": "heading", "lvl": 2, "value": "Accuracy Comparison", "md": "## Accuracy Comparison"}, {"type": "table", "rows": [["", "All TableShift Tasks (15 Tasks)*", "Non-Domain Generalization (5 Tasks)", "Domain Generalization (10 Tasks)"], ["est Accuracy", "0.85", "0.85", "0.85"], ["Out-of-Distribution T", "0.75", "0.75", "0.75"], ["In-Distribution Test Accuracy", "0.65 0.70 0.75 0.80 0.85", "0.65 0.70 0.75 0.80 0.85", "0.65 0.70 0.75 0.80 0.85"]], "md": "| |All TableShift Tasks (15 Tasks)*|Non-Domain Generalization (5 Tasks)|Domain Generalization (10 Tasks)|\n|---|---|---|---|\n|est Accuracy|0.85|0.85|0.85|\n|Out-of-Distribution T|0.75|0.75|0.75|\n|In-Distribution Test Accuracy|0.65 0.70 0.75 0.80 0.85|0.65 0.70 0.75 0.80 0.85|0.65 0.70 0.75 0.80 0.85|", "isPerfectTable": true, "csv": "\"\",\"All TableShift Tasks (15 Tasks)*\",\"Non-Domain Generalization (5 Tasks)\",\"Domain Generalization (10 Tasks)\"\n\"est Accuracy\",\"0.85\",\"0.85\",\"0.85\"\n\"Out-of-Distribution T\",\"0.75\",\"0.75\",\"0.75\"\n\"In-Distribution Test Accuracy\",\"0.65 0.70 0.75 0.80 0.85\",\"0.65 0.70 0.75 0.80 0.85\",\"0.65 0.70 0.75 0.80 0.85\""}, {"type": "heading", "lvl": 2, "value": "Model Comparison", "md": "## Model Comparison"}, {"type": "text", "value": "Figure 9: TableShift benchmark results, mean per model (left: non-domain generalization tasks, \u03c1 = 0.834; right: domain generalization tasks, \u03c1 = 963). In-domain and out-of-domain accuracy show a general linear trend. Baseline models (blue) consistently match or outperform domain robustness and domain generalization methods.", "md": "Figure 9: TableShift benchmark results, mean per model (left: non-domain generalization tasks, \u03c1 = 0.834; right: domain generalization tasks, \u03c1 = 963). In-domain and out-of-domain accuracy show a general linear trend. Baseline models (blue) consistently match or outperform domain robustness and domain generalization methods."}, {"type": "heading", "lvl": 2, "value": "Additional Dataset Details and Results", "md": "## Additional Dataset Details and Results"}, {"type": "heading", "lvl": 3, "value": "Domain Split Selection", "md": "### Domain Split Selection"}, {"type": "text", "value": "In this section we provide a brief tour of exploratory results regarding the domain shift datasets in TableShift, and additional experimental results.", "md": "In this section we provide a brief tour of exploratory results regarding the domain shift datasets in TableShift, and additional experimental results."}, {"type": "heading", "lvl": 4, "value": "For many tasks in TableShift:", "md": "#### For many tasks in TableShift:"}, {"type": "text", "value": "There exist clear motivations for selecting certain splitting variables, and for selecting which values of these variables to use as out-of-domain value(s) for our benchmarks.", "md": "There exist clear motivations for selecting certain splitting variables, and for selecting which values of these variables to use as out-of-domain value(s) for our benchmarks."}, {"type": "heading", "lvl": 4, "value": "For others:", "md": "#### For others:"}, {"type": "text", "value": "There might be multiple plausible splitting variables, or no obvious way to choose which specific value(s) to use as out of domain (e.g., any geographic region in ACS might be equally plausible as a holdout domain for the Food Stamps task).\n\nFor tasks where there were known domain splits that were likely to induce performance gaps that match a real-world domain shift scenario, we began by selecting these. When tuned baselines (LightGBM and XGBoost) showed a shift gap \u2206Acc of at least 1%, we used that split. However, for tasks without a clear domain split or where multiple plausible splitting values exist, we do the following. First, we identified a variable(s) that was likely to contribute to an actual shift in a real-world production through reviewing the relevant literature. Then, for each value d \u2208 {d1, . . . dD} = 28", "md": "There might be multiple plausible splitting variables, or no obvious way to choose which specific value(s) to use as out of domain (e.g., any geographic region in ACS might be equally plausible as a holdout domain for the Food Stamps task).\n\nFor tasks where there were known domain splits that were likely to induce performance gaps that match a real-world domain shift scenario, we began by selecting these. When tuned baselines (LightGBM and XGBoost) showed a shift gap \u2206Acc of at least 1%, we used that split. However, for tasks without a clear domain split or where multiple plausible splitting values exist, we do the following. First, we identified a variable(s) that was likely to contribute to an actual shift in a real-world production through reviewing the relevant literature. Then, for each value d \u2208 {d1, . . . dD} = 28"}]}, {"page": 29, "text": "      Table 3: Summary of tasks in the TableShift benchmark and their associated distribution shifts.\nTask                                   \u2206x (Eqn. (2))                       \u2206y|x (Eqn (3))              \u2206y (Eqn (3))\nFood Stamps                                14.20                               640.82                       0.0008\nIncome                                     30.60                                 1.40                       0.0060\nPublic Health Ins.                          5.79                                 4.06                       0.1701\nUnemployment                               75.47                       13,389,512.51                        0.0003\nANES                                       13.60                                 2.23                       0.0025\nDiabetes                                   12.28                                 0.10                       0.0332\nHypertension                                4.69                                 0.04                       0.0022\nHospital Readmission                       42.37                                 1.30                       0.0060\nChildhood Lead                              1.30                                 0.01                       0.0026\nSepsis                                   6609.73                                 8.44                       0.0040\nICU Length of Stay           56,439,324,672.00                    47,042,729,585.25                         0.0033\nICU Hospital                 64,479,092,736.00                    42,639,188,407.47                         0.0015\nMortality\nFICO HELOC                                 19.35                                 0.73                       0.0983\nASSISTments                            24,054.59                             1137.42                        0.0670\nCollege Scorecard                      43,566.39                             2116.63                        0.0337\n    D, we train on {D \\ d} and evaluate on d. We select the split(s) that induced the highest performance\n    gap in our baseline tree methods). We repeat this process for each dataset until a split that is both\n    real-world relevant and also leads to a shift gap is found.\n    E.2   Domain Shift Metrics (Covariate, Concept, and Label Shift)\n    As noted above, the domain shift \u2206Acc incurred when training a classifier is comprised of three\n    distinct forms of shift: changes in p(x) (\u201ccovariate shift\u201d), changes in p(y|x) (\u201cconcept shift\u201d), and\n    changes in p(y) (\u201clabel shift\u201d). It is not possible to measure the true shifts for any given dataset,\n    because doing so would require knowing the true (ID, OOD) distributions. As a result, in order to\n    still explore the influence of these various forms of shift on tabular data models, we propose metrics\n    to approximately measure each form of shift.\n    We propose these metrics while noting that each is only an approximation of the actual degree of\n    a certain form of shift in our dataset; measuring the actual underlying shift (e.g. the true change in\n    p(x) for covariate shift) is not possible from a finite sample. Thus, while these metrics can provide\n    exploratory evidence of the relationship between a given type of shift (covariate, comcept, label) and\n    model performance, they cannot provide direct evidence that any given shift type is (not) causing\n    changes in model performance.\n    Table 13 gives the exact In- and Out-of-Distribution label proportions for each task, which are used\n    to compute the label shift \u2206y.\n    Measuring covariate shift with OTDD: We propose to use the following measure to approximate\n    the degree of covariate shift between the (ID, OOD) test sets of a given task:\n                                          \u2206x = OTDD(Dtrain, Dtest)                                       (2)\n    where Dtrain, Dtest are the holdout (test) sets from the source and target domains, respectively. Here\n    OTDD represents the Optimal Transport Dataset Distance with the Gaussian approximation as\n    described in [2].\n    Measuring concept shift with Frechet Dataset Distance (FDD): We propose a straightforward\n    measure of the change in p(y|x) across two distributions. Inspired by measures of distributional\n    difference widely used in the machine learning (Frechet Inception Distance, [41]) which leverage\n    changes in the intermediate representations of a reference classifier for comparing distributions, we\n    propose \u2018Frechet dataset distance\u201d (FDD) for comparing two distributions.\n    This metric is computed as follows: First, we train a classifier on the source domain using the best\n    tuned hyperparameters from our hyperparameter sweep to obtain a fixed classifier f\u03b8. Then, for each\n                                                      29", "md": "|Task|\u2206x (Eqn. (2))|\u2206y|x (Eqn (3))|\u2206y (Eqn (3))|\n|---|---|---|---|\n|Food Stamps|14.20|640.82|0.0008|\n|Income|30.60|1.40|0.0060|\n|Public Health Ins.|5.79|4.06|0.1701|\n|Unemployment|75.47|13,389,512.51|0.0003|\n|ANES|13.60|2.23|0.0025|\n|Diabetes|12.28|0.10|0.0332|\n|Hypertension|4.69|0.04|0.0022|\n|Hospital Readmission|42.37|1.30|0.0060|\n|Childhood Lead|1.30|0.01|0.0026|\n|Sepsis|6609.73|8.44|0.0040|\n|ICU Length of Stay|56,439,324,672.00|47,042,729,585.25|0.0033|\n|ICU Hospital|64,479,092,736.00|42,639,188,407.47|0.0015|\n|Mortality| | | |\n|FICO HELOC|19.35|0.73|0.0983|\n|ASSISTments|24,054.59|1137.42|0.0670|\n|College Scorecard|43,566.39|2116.63|0.0337|\n\nD, we train on {D \\ d} and evaluate on d. We select the split(s) that induced the highest performance gap in our baseline tree methods). We repeat this process for each dataset until a split that is both real-world relevant and also leads to a shift gap is found.\n\nE.2 Domain Shift Metrics (Covariate, Concept, and Label Shift)\n\nAs noted above, the domain shift \u2206Acc incurred when training a classifier is comprised of three distinct forms of shift: changes in p(x) (\u201ccovariate shift\u201d), changes in p(y|x) (\u201cconcept shift\u201d), and changes in p(y) (\u201clabel shift\u201d). It is not possible to measure the true shifts for any given dataset, because doing so would require knowing the true (ID, OOD) distributions. As a result, in order to still explore the influence of these various forms of shift on tabular data models, we propose metrics to approximately measure each form of shift.\n\nWe propose these metrics while noting that each is only an approximation of the actual degree of a certain form of shift in our dataset; measuring the actual underlying shift (e.g. the true change in p(x) for covariate shift) is not possible from a finite sample. Thus, while these metrics can provide exploratory evidence of the relationship between a given type of shift (covariate, comcept, label) and model performance, they cannot provide direct evidence that any given shift type is (not) causing changes in model performance.\n\n|Task|In-Distribution Label Proportion|Out-of-Distribution Label Proportion|\n|---|---|---|\n|Food Stamps| | |\n|Income| | |\n|Public Health Ins.| | |\n|Unemployment| | |\n|ANES| | |\n|Diabetes| | |\n|Hypertension| | |\n|Hospital Readmission| | |\n|Childhood Lead| | |\n|Sepsis| | |\n|ICU Length of Stay| | |\n|ICU Hospital| | |\n|Mortality| | |\n|FICO HELOC| | |\n|ASSISTments| | |\n|College Scorecard| | |\n\nMeasuring covariate shift with OTDD: We propose to use the following measure to approximate the degree of covariate shift between the (ID, OOD) test sets of a given task:\n\n$$\\Delta x = OTDD(D_{\\text{train}}, D_{\\text{test}}) \\quad \\text{(2)}$$\n\nwhere \\(D_{\\text{train}}, D_{\\text{test}}\\) are the holdout (test) sets from the source and target domains, respectively. Here OTDD represents the Optimal Transport Dataset Distance with the Gaussian approximation as described in [2].\n\nMeasuring concept shift with Frechet Dataset Distance (FDD): We propose a straightforward measure of the change in \\(p(y|x)\\) across two distributions. Inspired by measures of distributional difference widely used in the machine learning (Frechet Inception Distance, [41]) which leverage changes in the intermediate representations of a reference classifier for comparing distributions, we propose \u2018Frechet dataset distance\u201d (FDD) for comparing two distributions.\n\nThis metric is computed as follows: First, we train a classifier on the source domain using the best tuned hyperparameters from our hyperparameter sweep to obtain a fixed classifier \\(f_{\\theta}\\). Then, for each", "images": [], "items": [{"type": "table", "rows": [["Task", "\u2206x (Eqn. (2))", "\u2206y", "x (Eqn (3))", "\u2206y (Eqn (3))"], ["Food Stamps", "14.20", "640.82", "0.0008"], ["Income", "30.60", "1.40", "0.0060"], ["Public Health Ins.", "5.79", "4.06", "0.1701"], ["Unemployment", "75.47", "13,389,512.51", "0.0003"], ["ANES", "13.60", "2.23", "0.0025"], ["Diabetes", "12.28", "0.10", "0.0332"], ["Hypertension", "4.69", "0.04", "0.0022"], ["Hospital Readmission", "42.37", "1.30", "0.0060"], ["Childhood Lead", "1.30", "0.01", "0.0026"], ["Sepsis", "6609.73", "8.44", "0.0040"], ["ICU Length of Stay", "56,439,324,672.00", "47,042,729,585.25", "0.0033"], ["ICU Hospital", "64,479,092,736.00", "42,639,188,407.47", "0.0015"], ["Mortality", "", "", ""], ["FICO HELOC", "19.35", "0.73", "0.0983"], ["ASSISTments", "24,054.59", "1137.42", "0.0670"], ["College Scorecard", "43,566.39", "2116.63", "0.0337"]], "md": "|Task|\u2206x (Eqn. (2))|\u2206y|x (Eqn (3))|\u2206y (Eqn (3))|\n|---|---|---|---|\n|Food Stamps|14.20|640.82|0.0008|\n|Income|30.60|1.40|0.0060|\n|Public Health Ins.|5.79|4.06|0.1701|\n|Unemployment|75.47|13,389,512.51|0.0003|\n|ANES|13.60|2.23|0.0025|\n|Diabetes|12.28|0.10|0.0332|\n|Hypertension|4.69|0.04|0.0022|\n|Hospital Readmission|42.37|1.30|0.0060|\n|Childhood Lead|1.30|0.01|0.0026|\n|Sepsis|6609.73|8.44|0.0040|\n|ICU Length of Stay|56,439,324,672.00|47,042,729,585.25|0.0033|\n|ICU Hospital|64,479,092,736.00|42,639,188,407.47|0.0015|\n|Mortality| | | |\n|FICO HELOC|19.35|0.73|0.0983|\n|ASSISTments|24,054.59|1137.42|0.0670|\n|College Scorecard|43,566.39|2116.63|0.0337|", "isPerfectTable": false, "csv": "\"Task\",\"\u2206x (Eqn. (2))\",\"\u2206y\",\"x (Eqn (3))\",\"\u2206y (Eqn (3))\"\n\"Food Stamps\",\"14.20\",\"640.82\",\"0.0008\"\n\"Income\",\"30.60\",\"1.40\",\"0.0060\"\n\"Public Health Ins.\",\"5.79\",\"4.06\",\"0.1701\"\n\"Unemployment\",\"75.47\",\"13,389,512.51\",\"0.0003\"\n\"ANES\",\"13.60\",\"2.23\",\"0.0025\"\n\"Diabetes\",\"12.28\",\"0.10\",\"0.0332\"\n\"Hypertension\",\"4.69\",\"0.04\",\"0.0022\"\n\"Hospital Readmission\",\"42.37\",\"1.30\",\"0.0060\"\n\"Childhood Lead\",\"1.30\",\"0.01\",\"0.0026\"\n\"Sepsis\",\"6609.73\",\"8.44\",\"0.0040\"\n\"ICU Length of Stay\",\"56,439,324,672.00\",\"47,042,729,585.25\",\"0.0033\"\n\"ICU Hospital\",\"64,479,092,736.00\",\"42,639,188,407.47\",\"0.0015\"\n\"Mortality\",\"\",\"\",\"\"\n\"FICO HELOC\",\"19.35\",\"0.73\",\"0.0983\"\n\"ASSISTments\",\"24,054.59\",\"1137.42\",\"0.0670\"\n\"College Scorecard\",\"43,566.39\",\"2116.63\",\"0.0337\""}, {"type": "text", "value": "D, we train on {D \\ d} and evaluate on d. We select the split(s) that induced the highest performance gap in our baseline tree methods). We repeat this process for each dataset until a split that is both real-world relevant and also leads to a shift gap is found.\n\nE.2 Domain Shift Metrics (Covariate, Concept, and Label Shift)\n\nAs noted above, the domain shift \u2206Acc incurred when training a classifier is comprised of three distinct forms of shift: changes in p(x) (\u201ccovariate shift\u201d), changes in p(y|x) (\u201cconcept shift\u201d), and changes in p(y) (\u201clabel shift\u201d). It is not possible to measure the true shifts for any given dataset, because doing so would require knowing the true (ID, OOD) distributions. As a result, in order to still explore the influence of these various forms of shift on tabular data models, we propose metrics to approximately measure each form of shift.\n\nWe propose these metrics while noting that each is only an approximation of the actual degree of a certain form of shift in our dataset; measuring the actual underlying shift (e.g. the true change in p(x) for covariate shift) is not possible from a finite sample. Thus, while these metrics can provide exploratory evidence of the relationship between a given type of shift (covariate, comcept, label) and model performance, they cannot provide direct evidence that any given shift type is (not) causing changes in model performance.", "md": "D, we train on {D \\ d} and evaluate on d. We select the split(s) that induced the highest performance gap in our baseline tree methods). We repeat this process for each dataset until a split that is both real-world relevant and also leads to a shift gap is found.\n\nE.2 Domain Shift Metrics (Covariate, Concept, and Label Shift)\n\nAs noted above, the domain shift \u2206Acc incurred when training a classifier is comprised of three distinct forms of shift: changes in p(x) (\u201ccovariate shift\u201d), changes in p(y|x) (\u201cconcept shift\u201d), and changes in p(y) (\u201clabel shift\u201d). It is not possible to measure the true shifts for any given dataset, because doing so would require knowing the true (ID, OOD) distributions. As a result, in order to still explore the influence of these various forms of shift on tabular data models, we propose metrics to approximately measure each form of shift.\n\nWe propose these metrics while noting that each is only an approximation of the actual degree of a certain form of shift in our dataset; measuring the actual underlying shift (e.g. the true change in p(x) for covariate shift) is not possible from a finite sample. Thus, while these metrics can provide exploratory evidence of the relationship between a given type of shift (covariate, comcept, label) and model performance, they cannot provide direct evidence that any given shift type is (not) causing changes in model performance."}, {"type": "table", "rows": [["Task", "In-Distribution Label Proportion", "Out-of-Distribution Label Proportion"], ["Food Stamps", "", ""], ["Income", "", ""], ["Public Health Ins.", "", ""], ["Unemployment", "", ""], ["ANES", "", ""], ["Diabetes", "", ""], ["Hypertension", "", ""], ["Hospital Readmission", "", ""], ["Childhood Lead", "", ""], ["Sepsis", "", ""], ["ICU Length of Stay", "", ""], ["ICU Hospital", "", ""], ["Mortality", "", ""], ["FICO HELOC", "", ""], ["ASSISTments", "", ""], ["College Scorecard", "", ""]], "md": "|Task|In-Distribution Label Proportion|Out-of-Distribution Label Proportion|\n|---|---|---|\n|Food Stamps| | |\n|Income| | |\n|Public Health Ins.| | |\n|Unemployment| | |\n|ANES| | |\n|Diabetes| | |\n|Hypertension| | |\n|Hospital Readmission| | |\n|Childhood Lead| | |\n|Sepsis| | |\n|ICU Length of Stay| | |\n|ICU Hospital| | |\n|Mortality| | |\n|FICO HELOC| | |\n|ASSISTments| | |\n|College Scorecard| | |", "isPerfectTable": true, "csv": "\"Task\",\"In-Distribution Label Proportion\",\"Out-of-Distribution Label Proportion\"\n\"Food Stamps\",\"\",\"\"\n\"Income\",\"\",\"\"\n\"Public Health Ins.\",\"\",\"\"\n\"Unemployment\",\"\",\"\"\n\"ANES\",\"\",\"\"\n\"Diabetes\",\"\",\"\"\n\"Hypertension\",\"\",\"\"\n\"Hospital Readmission\",\"\",\"\"\n\"Childhood Lead\",\"\",\"\"\n\"Sepsis\",\"\",\"\"\n\"ICU Length of Stay\",\"\",\"\"\n\"ICU Hospital\",\"\",\"\"\n\"Mortality\",\"\",\"\"\n\"FICO HELOC\",\"\",\"\"\n\"ASSISTments\",\"\",\"\"\n\"College Scorecard\",\"\",\"\""}, {"type": "text", "value": "Measuring covariate shift with OTDD: We propose to use the following measure to approximate the degree of covariate shift between the (ID, OOD) test sets of a given task:\n\n$$\\Delta x = OTDD(D_{\\text{train}}, D_{\\text{test}}) \\quad \\text{(2)}$$\n\nwhere \\(D_{\\text{train}}, D_{\\text{test}}\\) are the holdout (test) sets from the source and target domains, respectively. Here OTDD represents the Optimal Transport Dataset Distance with the Gaussian approximation as described in [2].\n\nMeasuring concept shift with Frechet Dataset Distance (FDD): We propose a straightforward measure of the change in \\(p(y|x)\\) across two distributions. Inspired by measures of distributional difference widely used in the machine learning (Frechet Inception Distance, [41]) which leverage changes in the intermediate representations of a reference classifier for comparing distributions, we propose \u2018Frechet dataset distance\u201d (FDD) for comparing two distributions.\n\nThis metric is computed as follows: First, we train a classifier on the source domain using the best tuned hyperparameters from our hyperparameter sweep to obtain a fixed classifier \\(f_{\\theta}\\). Then, for each", "md": "Measuring covariate shift with OTDD: We propose to use the following measure to approximate the degree of covariate shift between the (ID, OOD) test sets of a given task:\n\n$$\\Delta x = OTDD(D_{\\text{train}}, D_{\\text{test}}) \\quad \\text{(2)}$$\n\nwhere \\(D_{\\text{train}}, D_{\\text{test}}\\) are the holdout (test) sets from the source and target domains, respectively. Here OTDD represents the Optimal Transport Dataset Distance with the Gaussian approximation as described in [2].\n\nMeasuring concept shift with Frechet Dataset Distance (FDD): We propose a straightforward measure of the change in \\(p(y|x)\\) across two distributions. Inspired by measures of distributional difference widely used in the machine learning (Frechet Inception Distance, [41]) which leverage changes in the intermediate representations of a reference classifier for comparing distributions, we propose \u2018Frechet dataset distance\u201d (FDD) for comparing two distributions.\n\nThis metric is computed as follows: First, we train a classifier on the source domain using the best tuned hyperparameters from our hyperparameter sweep to obtain a fixed classifier \\(f_{\\theta}\\). Then, for each"}]}, {"page": 30, "text": "domain, we compute \u02dc       x := f  \u03b8[i](x), for each x \u2208    D, where i indicates that we compute the activations\nat the ith layer of the model (this is sometimes referred to as the coding vector or feature vector for an\ninput). Finally, we compute the Frechet dataset distance, which measures the distance between these\ntwo distributions (also called the Wasserstein-2 distance), as:\n            DFD(Dtrain, Dtest) = ||\u00b5Dtrain\u02d8\u00b5Dtest||2 + Tr(\u03a3Dtrain + \u03a3Dtest\u02d82 \u2217                \u03a3Dtrain \u2217  \u03a3Dtest)\nwhere \u00b5D indicates the set of feature vectors from dimain D and \u03a3D indicates the covariance matrix\nof \u00b5D. We refer to this measure as \u2206y|x below. A lower FDD score indicates a smaller distance\nbetween xi : xi \u2208       Dtrain and xj : xj \u2208     Dtest.\nWe parameterize the models used for FDD as MLPs. For each dataset, we use the MLP hyperparam-\neters associated with the best validation accuracy for that model over our experiments; the model\ntrained using these parameters is used for computing the feature activations for FDD.\nMeasuring label shift: We propose a simple measure of label shift. While label shift is clearly\none factor influencing shift gaps and is perhaps the most straightforward to empirically estimate,\nit receives surprisingly little attention in existing literature on domain shift. We use the following\nmeasure to quantify the label shift between the source and target distributions:\n                                                \u2206y = ||\u00af  y         yDtest||2                                     (3)\n                                                           Dtrain \u2212 \u00af\nwhere \u00af  yD =       1     i\u2208D yi is the empirical sample mean of a given domain. Since all tasks in\n                   |D|\nTableShift are binary classification tasks, this measures the L2 difference in the base rates across the\ntwo domains.\nUsing these metrics, we provide one perspective on the amount of each respective form of shift in\nTable 3. Additionally, we provide scatter plots showing the pairwise relationships between these\nmetrics in Figure 7, and scatter plots showing the relationship between each individual metric and the\nshift gap in Figure 8 (see also Figure 5 discussed in Section 5).\nE.3     Detailed Results Per Task\nWe provide detailed task-specific results and data in this section. In particular, we list the complete\nset of main results for the (In-Distribution, Out-Of-Distribution) scatter plots shown in Figures 1, 2,\n3, along with the 95% Clopper-Pearson confidence intervals for these results, in Tables 4, 5, 6, 8, 9, 7,\n10, 11. We also give summary metrics describing the size of each dataset split in Table 12.\n                                                             30", "md": "# Document\n\nIn the domain, we compute $$\\tilde{x} := f_{\\theta[i]}(x)$$, for each $$x \\in D$$, where i indicates that we compute the activations\nat the ith layer of the model (this is sometimes referred to as the coding vector or feature vector for an\ninput). Finally, we compute the Frechet dataset distance, which measures the distance between these\ntwo distributions (also called the Wasserstein-2 distance), as:\n\n$$DFD(D_{train}, D_{test}) = ||\\mu_{D_{train}} - \\mu_{D_{test}}||_2 + Tr(\\Sigma_{D_{train}} + \\Sigma_{D_{test}})^2 * \\Sigma_{D_{train}} * \\Sigma_{D_{test}}$$\n\nwhere $$\\mu_{D}$$ indicates the set of feature vectors from domain D and $$\\Sigma_{D}$$ indicates the covariance matrix\nof $$\\mu_{D}$$. We refer to this measure as $$\\Delta y|x$$ below. A lower FDD score indicates a smaller distance\nbetween $$x_i : x_i \\in D_{train}$$ and $$x_j : x_j \\in D_{test}$$.\n\nWe parameterize the models used for FDD as MLPs. For each dataset, we use the MLP hyperparameters associated with the best validation accuracy for that model over our experiments; the model trained using these parameters is used for computing the feature activations for FDD.\n\nMeasuring label shift: We propose a simple measure of label shift. While label shift is clearly\none factor influencing shift gaps and is perhaps the most straightforward to empirically estimate,\nit receives surprisingly little attention in existing literature on domain shift. We use the following\nmeasure to quantify the label shift between the source and target distributions:\n\n$$\\Delta y = ||\\bar{y}_{D_{train}} - \\bar{y}_{D_{test}}||_2$$\n\nwhere $$\\bar{y}_{D} = \\frac{1}{|D|} \\sum_{i \\in D} y_i$$ is the empirical sample mean of a given domain. Since all tasks in\nTableShift are binary classification tasks, this measures the L2 difference in the base rates across the\ntwo domains.\n\nUsing these metrics, we provide one perspective on the amount of each respective form of shift in\nTable 3. Additionally, we provide scatter plots showing the pairwise relationships between these\nmetrics in Figure 7, and scatter plots showing the relationship between each individual metric and the\nshift gap in Figure 8 (see also Figure 5 discussed in Section 5).\n\n### Detailed Results Per Task\n\nWe provide detailed task-specific results and data in this section. In particular, we list the complete\nset of main results for the (In-Distribution, Out-Of-Distribution) scatter plots shown in Figures 1, 2,\n3, along with the 95% Clopper-Pearson confidence intervals for these results, in Tables 4, 5, 6, 8, 9, 7,\n10, 11. We also give summary metrics describing the size of each dataset split in Table 12.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "In the domain, we compute $$\\tilde{x} := f_{\\theta[i]}(x)$$, for each $$x \\in D$$, where i indicates that we compute the activations\nat the ith layer of the model (this is sometimes referred to as the coding vector or feature vector for an\ninput). Finally, we compute the Frechet dataset distance, which measures the distance between these\ntwo distributions (also called the Wasserstein-2 distance), as:\n\n$$DFD(D_{train}, D_{test}) = ||\\mu_{D_{train}} - \\mu_{D_{test}}||_2 + Tr(\\Sigma_{D_{train}} + \\Sigma_{D_{test}})^2 * \\Sigma_{D_{train}} * \\Sigma_{D_{test}}$$\n\nwhere $$\\mu_{D}$$ indicates the set of feature vectors from domain D and $$\\Sigma_{D}$$ indicates the covariance matrix\nof $$\\mu_{D}$$. We refer to this measure as $$\\Delta y|x$$ below. A lower FDD score indicates a smaller distance\nbetween $$x_i : x_i \\in D_{train}$$ and $$x_j : x_j \\in D_{test}$$.\n\nWe parameterize the models used for FDD as MLPs. For each dataset, we use the MLP hyperparameters associated with the best validation accuracy for that model over our experiments; the model trained using these parameters is used for computing the feature activations for FDD.\n\nMeasuring label shift: We propose a simple measure of label shift. While label shift is clearly\none factor influencing shift gaps and is perhaps the most straightforward to empirically estimate,\nit receives surprisingly little attention in existing literature on domain shift. We use the following\nmeasure to quantify the label shift between the source and target distributions:\n\n$$\\Delta y = ||\\bar{y}_{D_{train}} - \\bar{y}_{D_{test}}||_2$$\n\nwhere $$\\bar{y}_{D} = \\frac{1}{|D|} \\sum_{i \\in D} y_i$$ is the empirical sample mean of a given domain. Since all tasks in\nTableShift are binary classification tasks, this measures the L2 difference in the base rates across the\ntwo domains.\n\nUsing these metrics, we provide one perspective on the amount of each respective form of shift in\nTable 3. Additionally, we provide scatter plots showing the pairwise relationships between these\nmetrics in Figure 7, and scatter plots showing the relationship between each individual metric and the\nshift gap in Figure 8 (see also Figure 5 discussed in Section 5).", "md": "In the domain, we compute $$\\tilde{x} := f_{\\theta[i]}(x)$$, for each $$x \\in D$$, where i indicates that we compute the activations\nat the ith layer of the model (this is sometimes referred to as the coding vector or feature vector for an\ninput). Finally, we compute the Frechet dataset distance, which measures the distance between these\ntwo distributions (also called the Wasserstein-2 distance), as:\n\n$$DFD(D_{train}, D_{test}) = ||\\mu_{D_{train}} - \\mu_{D_{test}}||_2 + Tr(\\Sigma_{D_{train}} + \\Sigma_{D_{test}})^2 * \\Sigma_{D_{train}} * \\Sigma_{D_{test}}$$\n\nwhere $$\\mu_{D}$$ indicates the set of feature vectors from domain D and $$\\Sigma_{D}$$ indicates the covariance matrix\nof $$\\mu_{D}$$. We refer to this measure as $$\\Delta y|x$$ below. A lower FDD score indicates a smaller distance\nbetween $$x_i : x_i \\in D_{train}$$ and $$x_j : x_j \\in D_{test}$$.\n\nWe parameterize the models used for FDD as MLPs. For each dataset, we use the MLP hyperparameters associated with the best validation accuracy for that model over our experiments; the model trained using these parameters is used for computing the feature activations for FDD.\n\nMeasuring label shift: We propose a simple measure of label shift. While label shift is clearly\none factor influencing shift gaps and is perhaps the most straightforward to empirically estimate,\nit receives surprisingly little attention in existing literature on domain shift. We use the following\nmeasure to quantify the label shift between the source and target distributions:\n\n$$\\Delta y = ||\\bar{y}_{D_{train}} - \\bar{y}_{D_{test}}||_2$$\n\nwhere $$\\bar{y}_{D} = \\frac{1}{|D|} \\sum_{i \\in D} y_i$$ is the empirical sample mean of a given domain. Since all tasks in\nTableShift are binary classification tasks, this measures the L2 difference in the base rates across the\ntwo domains.\n\nUsing these metrics, we provide one perspective on the amount of each respective form of shift in\nTable 3. Additionally, we provide scatter plots showing the pairwise relationships between these\nmetrics in Figure 7, and scatter plots showing the relationship between each individual metric and the\nshift gap in Figure 8 (see also Figure 5 discussed in Section 5)."}, {"type": "heading", "lvl": 3, "value": "Detailed Results Per Task", "md": "### Detailed Results Per Task"}, {"type": "text", "value": "We provide detailed task-specific results and data in this section. In particular, we list the complete\nset of main results for the (In-Distribution, Out-Of-Distribution) scatter plots shown in Figures 1, 2,\n3, along with the 95% Clopper-Pearson confidence intervals for these results, in Tables 4, 5, 6, 8, 9, 7,\n10, 11. We also give summary metrics describing the size of each dataset split in Table 12.", "md": "We provide detailed task-specific results and data in this section. In particular, we list the complete\nset of main results for the (In-Distribution, Out-Of-Distribution) scatter plots shown in Figures 1, 2,\n3, along with the 95% Clopper-Pearson confidence intervals for these results, in Tables 4, 5, 6, 8, 9, 7,\n10, 11. We also give summary metrics describing the size of each dataset split in Table 12."}]}, {"page": 31, "text": "         Table 4: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark\n         task. Note that domain generalization models can only be trained on datasets with more than one\n         training subdomain (see Table 1 for domain generalization datasets and Section 4.1 for a list of\n         domain generalization models). \u22c6: domain generalization models cannot be trained when only one\n         training subdomain is present. See also Figures 1, 2,3. \u2662: the large number of training subdomains\n         (over 700 for ASSISTments) makes training domain generalization models impractical. \u25a1: the large\n         dataset size makes training adversarial label DRO models impractical (since per-example gradients\n         must be computed). We leave these experiments to future work.\nEstimator                               ASSISTments                                        Childhood Lead\n                        ID Acc. (95% CI)         OOD Acc. (95% CI)            ID Acc. (95% CI)        OOD Acc. (95% CI)\nAdv. Label DRO        \u25a1        \u25a1                 \u25a1        \u25a1                 0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nCatBoost              0.943    (0.942, 0.944)    0.584    (0.562, 0.607)    0.971   (0.961, 0.979)    0.92    (0.914, 0.925)\nDRO                   0.932    (0.931, 0.933)    0.583    (0.561, 0.606)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nFT-Transformer        0.939    (0.938, 0.94)     0.592    (0.569, 0.614)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nLabel Group DRO       0.928    (0.927, 0.929)    0.574    (0.551, 0.596)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nLightGBM              0.936    (0.935, 0.937)    0.591    (0.568, 0.613)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nMLP                   0.933    (0.932, 0.934)    0.583    (0.561, 0.606)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nNODE                  0.935    (0.934, 0.936)    0.583    (0.561, 0.606)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nResNet                0.933    (0.932, 0.934)    0.583    (0.561, 0.606)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nSAINT                 0.935    (0.934, 0.936)    0.584    (0.562, 0.607)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nTabTransformer        0.93     (0.929, 0.93)     0.551    (0.529, 0.574)    0.971   (0.961, 0.979)    0.92    (0.915, 0.925)\nXGBoost               0.93     (0.929, 0.931)    0.591    (0.568, 0.613)    0.971   (0.961, 0.979)    0.92    (0.914, 0.925)\nCORAL                 \u2662        \u2662                 \u2662        \u2662                 \u22c6       \u22c6                 \u22c6       \u22c6\nDANN                  \u2662        \u2662                 \u2662        \u2662                 \u22c6       \u22c6                 \u22c6       \u22c6\nGroup DRO             \u2662        \u2662                 \u2662        \u2662                 \u22c6       \u22c6                 \u22c6       \u22c6\nIRM                   \u2662        \u2662                 \u2662        \u2662                 \u22c6       \u22c6                 \u22c6       \u22c6\nMMD                   \u2662        \u2662                 \u2662        \u2662                 \u22c6       \u22c6                 \u22c6       \u22c6\nMixUp                 \u2662        \u2662                 \u2662        \u2662                 \u22c6       \u22c6                 \u22c6       \u22c6\nVREX                  \u2662        \u2662                 \u2662        \u2662                 \u22c6       \u22c6                 \u22c6       \u22c6\n         Table 5: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark\n         task. Note that domain generalization models can only be trained on datasets with more than one\n         training subdomain (see Table 1 for domain generalization datasets and Section 4.1 for a list of\n         domain generalization models). \u22c6: domain generalization models cannot be trained when only one\n         training subdomain is present. See also Figures 1, 2,3.\nEstimator                            College Scorecard                                          Diabetes\n                        ID Acc. (95% CI)         OOD Acc. (95% CI)            ID Acc. (95% CI)         OOD Acc. (95% CI)\nAdv. Label DRO        0.937    (0.933, 0.942)    0.826    (0.805, 0.846)    0.877   (0.875, 0.878)    0.832    (0.83, 0.833)\nCatBoost              0.957    (0.954, 0.961)    0.885    (0.866, 0.901)    0.877   (0.876, 0.879)    0.833    (0.831, 0.835)\nDRO                   0.95     (0.946, 0.954)    0.862    (0.842, 0.88)     0.876   (0.875, 0.878)    0.832    (0.83, 0.834)\nFT-Transformer        0.948    (0.944, 0.952)    0.859    (0.839, 0.877)    0.877   (0.875, 0.879)    0.832    (0.831, 0.834)\nLabel Group DRO       0.928    (0.924, 0.933)    0.817    (0.796, 0.838)    0.876   (0.874, 0.878)    0.831    (0.83, 0.833)\nLightGBM              0.939    (0.935, 0.943)    0.822    (0.8, 0.841)      0.876   (0.874, 0.878)    0.833    (0.831, 0.835)\nMLP                   0.947    (0.942, 0.95)     0.845    (0.825, 0.864)    0.877   (0.875, 0.879)    0.832    (0.83, 0.833)\nNODE                  0.944    (0.939, 0.948)    0.844    (0.823, 0.863)    0.877   (0.875, 0.879)    0.833    (0.832, 0.835)\nResNet                0.947    (0.943, 0.951)    0.854    (0.834, 0.872)    0.874   (0.872, 0.876)    0.829    (0.828, 0.831)\nSAINT                 0.936    (0.931, 0.94)     0.814    (0.792, 0.834)    0.877   (0.875, 0.879)    0.833    (0.831, 0.834)\nTabTransformer        0.942    (0.938, 0.946)    0.845    (0.825, 0.864)    0.875   (0.873, 0.877)    0.83     (0.829, 0.832)\nXGBoost               0.942    (0.938, 0.946)    0.83     (0.809, 0.85)     0.877   (0.875, 0.879)    0.832    (0.83, 0.834)\nCORAL                 0.922    (0.917, 0.926)    0.795    (0.773, 0.816)    0.874   (0.872, 0.875)    0.832    (0.83, 0.834)\nDANN                  0.894    (0.889, 0.9)      0.78     (0.757, 0.802)    0.873   (0.871, 0.875)    0.826    (0.824, 0.827)\nGroup DRO             0.944    (0.939, 0.948)    0.829    (0.808, 0.849)    0.877   (0.875, 0.879)    0.832    (0.83, 0.833)\nIRM                   0.879    (0.873, 0.885)    0.746    (0.721, 0.769)    0.873   (0.871, 0.875)    0.826    (0.824, 0.827)\nMMD                   0.925    (0.92, 0.929)     0.795    (0.773, 0.816)    0.873   (0.871, 0.875)    0.826    (0.825, 0.828)\nMixUp                 0.912    (0.907, 0.917)    0.746    (0.721, 0.769)    0.873   (0.871, 0.875)    0.826    (0.824, 0.827)\nVREX                  0.907    (0.902, 0.912)    0.754    (0.731, 0.777)    0.873   (0.871, 0.875)    0.826    (0.824, 0.827)\n                                                           31", "md": "**Table 4: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task.**\n|Estimator|ASSISTments| | |Childhood Lead|\n|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)|\n|Adv. Label DRO|\u25a1|\u25a1|\u25a1|\u25a1|\n|CatBoost|0.943 (0.942, 0.944)|0.584 (0.562, 0.607)|0.971 (0.961, 0.979)|0.92 (0.914, 0.925)|\n|DRO|0.932 (0.931, 0.933)|0.583 (0.561, 0.606)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|FT-Transformer|0.939 (0.938, 0.94)|0.592 (0.569, 0.614)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|Label Group DRO|0.928 (0.927, 0.929)|0.574 (0.551, 0.596)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|LightGBM|0.936 (0.935, 0.937)|0.591 (0.568, 0.613)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|MLP|0.933 (0.932, 0.934)|0.583 (0.561, 0.606)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|NODE|0.935 (0.934, 0.936)|0.583 (0.561, 0.606)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|ResNet|0.933 (0.932, 0.934)|0.583 (0.561, 0.606)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|SAINT|0.935 (0.934, 0.936)|0.584 (0.562, 0.607)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|TabTransformer|0.93 (0.929, 0.93)|0.551 (0.529, 0.574)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|XGBoost|0.93 (0.929, 0.931)|0.591 (0.568, 0.613)|0.971 (0.961, 0.979)|0.92 (0.914, 0.925)|\n|CORAL|\u2662|\u2662|\u2662|\u2662|\n|DANN|\u2662|\u2662|\u2662|\u2662|\n|Group DRO|\u2662|\u2662|\u2662|\u2662|\n|IRM|\u2662|\u2662|\u2662|\u2662|\n|MMD|\u2662|\u2662|\u2662|\u2662|\n|MixUp|\u2662|\u2662|\u2662|\u2662|\n|VREX|\u2662|\u2662|\u2662|\u2662|\n\n**Table 5: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task.**\n|Estimator|College Scorecard| | |Diabetes|\n|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)|\n|Adv. Label DRO|0.937 (0.933, 0.942)|0.826 (0.805, 0.846)|0.877 (0.875, 0.878)|0.832 (0.83, 0.833)|\n|CatBoost|0.957 (0.954, 0.961)|0.885 (0.866, 0.901)|0.877 (0.876, 0.879)|0.833 (0.831, 0.835)|\n|DRO|0.95 (0.946, 0.954)|0.862 (0.842, 0.88)|0.876 (0.875, 0.878)|0.832 (0.83, 0.834)|\n|FT-Transformer|0.948 (0.944, 0.952)|0.859 (0.839, 0.877)|0.877 (0.875, 0.879)|0.832 (0.831, 0.834)|\n|Label Group DRO|0.928 (0.924, 0.933)|0.817 (0.796, 0.838)|0.876 (0.874, 0.878)|0.831 (0.83, 0.833)|\n|LightGBM|0.939 (0.935, 0.943)|0.822 (0.8, 0.841)|0.876 (0.874, 0.878)|0.833 (0.831, 0.835)|\n|MLP|0.947 (0.942, 0.95)|0.845 (0.825, 0.864)|0.877 (0.875, 0.879)|0.832 (0.83, 0.833)|\n|NODE|0.944 (0.939, 0.948)|0.844 (0.823, 0.863)|0.877 (0.875, 0.879)|0.833 (0.832, 0.835)|\n|ResNet|0.947 (0.943, 0.951)|0.854 (0.834, 0.872)|0.874 (0.872, 0.876)|0.829 (0.828, 0.831)|\n|SAINT|0.936 (0.931, 0.94)|0.814 (0.792, 0.834)|0.877 (0.875, 0.879)|0.833 (0.831, 0.834)|\n|TabTransformer|0.942 (0.938, 0.946)|0.845 (0.825, 0.864)|0.875 (0.873, 0.877)|0.83 (0.829, 0.832)|\n|XGBoost|0.942 (0.938, 0.946)|0.83 (0.809, 0.85)|0.877 (0.875, 0.879)|0.832 (0.83, 0.834)|\n|CORAL|0.922 (0.917, 0.926)|0.795 (0.773, 0.816)|0.874 (0.872, 0.875)|0.832 (0.83, 0.834)|\n|DANN|0.894 (0.889, 0.9)|0.78 (0.757, 0.802)|0.873 (0.871, 0.875)|0.826 (0.824, 0.827)|\n|Group DRO|0.944 (0.939, 0.948)|0.829 (0.808, 0.849)|0.877 (0.875, 0.879)|0.832 (0.83, 0.833)|\n|IRM|0.879 (0.873, 0.885)|0.746 (0.721, 0.769)|0.873 (0.871, 0.875)|0.826 (0.824, 0.827)|\n|MMD|0.925 (0.92, 0.929)|0.795 (0.773, 0.816)|0.873 (0.871, 0.875)|0.826 (0.825, 0.828)|\n|MixUp|0.912 (0.907, 0.917)|0.746 (0.721, 0.769)|0.873 (0.871, 0.875)|0.826 (0.824, 0.827)|\n|VREX|0.907 (0.902, 0.912)|0.754 (0.731, 0.777)|0.873 (0.871, 0.875)|0.826 (0.824, 0.827)|", "images": [], "items": [{"type": "text", "value": "**Table 4: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task.**", "md": "**Table 4: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task.**"}, {"type": "table", "rows": [["Estimator", "ASSISTments", "", "", "Childhood Lead"], ["", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "ID Acc. (95% CI)", "OOD Acc. (95% CI)"], ["Adv. Label DRO", "\u25a1", "\u25a1", "\u25a1", "\u25a1"], ["CatBoost", "0.943 (0.942, 0.944)", "0.584 (0.562, 0.607)", "0.971 (0.961, 0.979)", "0.92 (0.914, 0.925)"], ["DRO", "0.932 (0.931, 0.933)", "0.583 (0.561, 0.606)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["FT-Transformer", "0.939 (0.938, 0.94)", "0.592 (0.569, 0.614)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["Label Group DRO", "0.928 (0.927, 0.929)", "0.574 (0.551, 0.596)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["LightGBM", "0.936 (0.935, 0.937)", "0.591 (0.568, 0.613)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["MLP", "0.933 (0.932, 0.934)", "0.583 (0.561, 0.606)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["NODE", "0.935 (0.934, 0.936)", "0.583 (0.561, 0.606)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["ResNet", "0.933 (0.932, 0.934)", "0.583 (0.561, 0.606)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["SAINT", "0.935 (0.934, 0.936)", "0.584 (0.562, 0.607)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["TabTransformer", "0.93 (0.929, 0.93)", "0.551 (0.529, 0.574)", "0.971 (0.961, 0.979)", "0.92 (0.915, 0.925)"], ["XGBoost", "0.93 (0.929, 0.931)", "0.591 (0.568, 0.613)", "0.971 (0.961, 0.979)", "0.92 (0.914, 0.925)"], ["CORAL", "\u2662", "\u2662", "\u2662", "\u2662"], ["DANN", "\u2662", "\u2662", "\u2662", "\u2662"], ["Group DRO", "\u2662", "\u2662", "\u2662", "\u2662"], ["IRM", "\u2662", "\u2662", "\u2662", "\u2662"], ["MMD", "\u2662", "\u2662", "\u2662", "\u2662"], ["MixUp", "\u2662", "\u2662", "\u2662", "\u2662"], ["VREX", "\u2662", "\u2662", "\u2662", "\u2662"]], "md": "|Estimator|ASSISTments| | |Childhood Lead|\n|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)|\n|Adv. Label DRO|\u25a1|\u25a1|\u25a1|\u25a1|\n|CatBoost|0.943 (0.942, 0.944)|0.584 (0.562, 0.607)|0.971 (0.961, 0.979)|0.92 (0.914, 0.925)|\n|DRO|0.932 (0.931, 0.933)|0.583 (0.561, 0.606)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|FT-Transformer|0.939 (0.938, 0.94)|0.592 (0.569, 0.614)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|Label Group DRO|0.928 (0.927, 0.929)|0.574 (0.551, 0.596)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|LightGBM|0.936 (0.935, 0.937)|0.591 (0.568, 0.613)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|MLP|0.933 (0.932, 0.934)|0.583 (0.561, 0.606)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|NODE|0.935 (0.934, 0.936)|0.583 (0.561, 0.606)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|ResNet|0.933 (0.932, 0.934)|0.583 (0.561, 0.606)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|SAINT|0.935 (0.934, 0.936)|0.584 (0.562, 0.607)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|TabTransformer|0.93 (0.929, 0.93)|0.551 (0.529, 0.574)|0.971 (0.961, 0.979)|0.92 (0.915, 0.925)|\n|XGBoost|0.93 (0.929, 0.931)|0.591 (0.568, 0.613)|0.971 (0.961, 0.979)|0.92 (0.914, 0.925)|\n|CORAL|\u2662|\u2662|\u2662|\u2662|\n|DANN|\u2662|\u2662|\u2662|\u2662|\n|Group DRO|\u2662|\u2662|\u2662|\u2662|\n|IRM|\u2662|\u2662|\u2662|\u2662|\n|MMD|\u2662|\u2662|\u2662|\u2662|\n|MixUp|\u2662|\u2662|\u2662|\u2662|\n|VREX|\u2662|\u2662|\u2662|\u2662|", "isPerfectTable": true, "csv": "\"Estimator\",\"ASSISTments\",\"\",\"\",\"Childhood Lead\"\n\"\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\"\n\"Adv. Label DRO\",\"\u25a1\",\"\u25a1\",\"\u25a1\",\"\u25a1\"\n\"CatBoost\",\"0.943 (0.942, 0.944)\",\"0.584 (0.562, 0.607)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.914, 0.925)\"\n\"DRO\",\"0.932 (0.931, 0.933)\",\"0.583 (0.561, 0.606)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"FT-Transformer\",\"0.939 (0.938, 0.94)\",\"0.592 (0.569, 0.614)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"Label Group DRO\",\"0.928 (0.927, 0.929)\",\"0.574 (0.551, 0.596)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"LightGBM\",\"0.936 (0.935, 0.937)\",\"0.591 (0.568, 0.613)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"MLP\",\"0.933 (0.932, 0.934)\",\"0.583 (0.561, 0.606)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"NODE\",\"0.935 (0.934, 0.936)\",\"0.583 (0.561, 0.606)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"ResNet\",\"0.933 (0.932, 0.934)\",\"0.583 (0.561, 0.606)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"SAINT\",\"0.935 (0.934, 0.936)\",\"0.584 (0.562, 0.607)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"TabTransformer\",\"0.93 (0.929, 0.93)\",\"0.551 (0.529, 0.574)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.915, 0.925)\"\n\"XGBoost\",\"0.93 (0.929, 0.931)\",\"0.591 (0.568, 0.613)\",\"0.971 (0.961, 0.979)\",\"0.92 (0.914, 0.925)\"\n\"CORAL\",\"\u2662\",\"\u2662\",\"\u2662\",\"\u2662\"\n\"DANN\",\"\u2662\",\"\u2662\",\"\u2662\",\"\u2662\"\n\"Group DRO\",\"\u2662\",\"\u2662\",\"\u2662\",\"\u2662\"\n\"IRM\",\"\u2662\",\"\u2662\",\"\u2662\",\"\u2662\"\n\"MMD\",\"\u2662\",\"\u2662\",\"\u2662\",\"\u2662\"\n\"MixUp\",\"\u2662\",\"\u2662\",\"\u2662\",\"\u2662\"\n\"VREX\",\"\u2662\",\"\u2662\",\"\u2662\",\"\u2662\""}, {"type": "text", "value": "**Table 5: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task.**", "md": "**Table 5: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task.**"}, {"type": "table", "rows": [["Estimator", "College Scorecard", "", "", "Diabetes"], ["", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "ID Acc. (95% CI)", "OOD Acc. (95% CI)"], ["Adv. Label DRO", "0.937 (0.933, 0.942)", "0.826 (0.805, 0.846)", "0.877 (0.875, 0.878)", "0.832 (0.83, 0.833)"], ["CatBoost", "0.957 (0.954, 0.961)", "0.885 (0.866, 0.901)", "0.877 (0.876, 0.879)", "0.833 (0.831, 0.835)"], ["DRO", "0.95 (0.946, 0.954)", "0.862 (0.842, 0.88)", "0.876 (0.875, 0.878)", "0.832 (0.83, 0.834)"], ["FT-Transformer", "0.948 (0.944, 0.952)", "0.859 (0.839, 0.877)", "0.877 (0.875, 0.879)", "0.832 (0.831, 0.834)"], ["Label Group DRO", "0.928 (0.924, 0.933)", "0.817 (0.796, 0.838)", "0.876 (0.874, 0.878)", "0.831 (0.83, 0.833)"], ["LightGBM", "0.939 (0.935, 0.943)", "0.822 (0.8, 0.841)", "0.876 (0.874, 0.878)", "0.833 (0.831, 0.835)"], ["MLP", "0.947 (0.942, 0.95)", "0.845 (0.825, 0.864)", "0.877 (0.875, 0.879)", "0.832 (0.83, 0.833)"], ["NODE", "0.944 (0.939, 0.948)", "0.844 (0.823, 0.863)", "0.877 (0.875, 0.879)", "0.833 (0.832, 0.835)"], ["ResNet", "0.947 (0.943, 0.951)", "0.854 (0.834, 0.872)", "0.874 (0.872, 0.876)", "0.829 (0.828, 0.831)"], ["SAINT", "0.936 (0.931, 0.94)", "0.814 (0.792, 0.834)", "0.877 (0.875, 0.879)", "0.833 (0.831, 0.834)"], ["TabTransformer", "0.942 (0.938, 0.946)", "0.845 (0.825, 0.864)", "0.875 (0.873, 0.877)", "0.83 (0.829, 0.832)"], ["XGBoost", "0.942 (0.938, 0.946)", "0.83 (0.809, 0.85)", "0.877 (0.875, 0.879)", "0.832 (0.83, 0.834)"], ["CORAL", "0.922 (0.917, 0.926)", "0.795 (0.773, 0.816)", "0.874 (0.872, 0.875)", "0.832 (0.83, 0.834)"], ["DANN", "0.894 (0.889, 0.9)", "0.78 (0.757, 0.802)", "0.873 (0.871, 0.875)", "0.826 (0.824, 0.827)"], ["Group DRO", "0.944 (0.939, 0.948)", "0.829 (0.808, 0.849)", "0.877 (0.875, 0.879)", "0.832 (0.83, 0.833)"], ["IRM", "0.879 (0.873, 0.885)", "0.746 (0.721, 0.769)", "0.873 (0.871, 0.875)", "0.826 (0.824, 0.827)"], ["MMD", "0.925 (0.92, 0.929)", "0.795 (0.773, 0.816)", "0.873 (0.871, 0.875)", "0.826 (0.825, 0.828)"], ["MixUp", "0.912 (0.907, 0.917)", "0.746 (0.721, 0.769)", "0.873 (0.871, 0.875)", "0.826 (0.824, 0.827)"], ["VREX", "0.907 (0.902, 0.912)", "0.754 (0.731, 0.777)", "0.873 (0.871, 0.875)", "0.826 (0.824, 0.827)"]], "md": "|Estimator|College Scorecard| | |Diabetes|\n|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)|\n|Adv. Label DRO|0.937 (0.933, 0.942)|0.826 (0.805, 0.846)|0.877 (0.875, 0.878)|0.832 (0.83, 0.833)|\n|CatBoost|0.957 (0.954, 0.961)|0.885 (0.866, 0.901)|0.877 (0.876, 0.879)|0.833 (0.831, 0.835)|\n|DRO|0.95 (0.946, 0.954)|0.862 (0.842, 0.88)|0.876 (0.875, 0.878)|0.832 (0.83, 0.834)|\n|FT-Transformer|0.948 (0.944, 0.952)|0.859 (0.839, 0.877)|0.877 (0.875, 0.879)|0.832 (0.831, 0.834)|\n|Label Group DRO|0.928 (0.924, 0.933)|0.817 (0.796, 0.838)|0.876 (0.874, 0.878)|0.831 (0.83, 0.833)|\n|LightGBM|0.939 (0.935, 0.943)|0.822 (0.8, 0.841)|0.876 (0.874, 0.878)|0.833 (0.831, 0.835)|\n|MLP|0.947 (0.942, 0.95)|0.845 (0.825, 0.864)|0.877 (0.875, 0.879)|0.832 (0.83, 0.833)|\n|NODE|0.944 (0.939, 0.948)|0.844 (0.823, 0.863)|0.877 (0.875, 0.879)|0.833 (0.832, 0.835)|\n|ResNet|0.947 (0.943, 0.951)|0.854 (0.834, 0.872)|0.874 (0.872, 0.876)|0.829 (0.828, 0.831)|\n|SAINT|0.936 (0.931, 0.94)|0.814 (0.792, 0.834)|0.877 (0.875, 0.879)|0.833 (0.831, 0.834)|\n|TabTransformer|0.942 (0.938, 0.946)|0.845 (0.825, 0.864)|0.875 (0.873, 0.877)|0.83 (0.829, 0.832)|\n|XGBoost|0.942 (0.938, 0.946)|0.83 (0.809, 0.85)|0.877 (0.875, 0.879)|0.832 (0.83, 0.834)|\n|CORAL|0.922 (0.917, 0.926)|0.795 (0.773, 0.816)|0.874 (0.872, 0.875)|0.832 (0.83, 0.834)|\n|DANN|0.894 (0.889, 0.9)|0.78 (0.757, 0.802)|0.873 (0.871, 0.875)|0.826 (0.824, 0.827)|\n|Group DRO|0.944 (0.939, 0.948)|0.829 (0.808, 0.849)|0.877 (0.875, 0.879)|0.832 (0.83, 0.833)|\n|IRM|0.879 (0.873, 0.885)|0.746 (0.721, 0.769)|0.873 (0.871, 0.875)|0.826 (0.824, 0.827)|\n|MMD|0.925 (0.92, 0.929)|0.795 (0.773, 0.816)|0.873 (0.871, 0.875)|0.826 (0.825, 0.828)|\n|MixUp|0.912 (0.907, 0.917)|0.746 (0.721, 0.769)|0.873 (0.871, 0.875)|0.826 (0.824, 0.827)|\n|VREX|0.907 (0.902, 0.912)|0.754 (0.731, 0.777)|0.873 (0.871, 0.875)|0.826 (0.824, 0.827)|", "isPerfectTable": true, "csv": "\"Estimator\",\"College Scorecard\",\"\",\"\",\"Diabetes\"\n\"\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\"\n\"Adv. Label DRO\",\"0.937 (0.933, 0.942)\",\"0.826 (0.805, 0.846)\",\"0.877 (0.875, 0.878)\",\"0.832 (0.83, 0.833)\"\n\"CatBoost\",\"0.957 (0.954, 0.961)\",\"0.885 (0.866, 0.901)\",\"0.877 (0.876, 0.879)\",\"0.833 (0.831, 0.835)\"\n\"DRO\",\"0.95 (0.946, 0.954)\",\"0.862 (0.842, 0.88)\",\"0.876 (0.875, 0.878)\",\"0.832 (0.83, 0.834)\"\n\"FT-Transformer\",\"0.948 (0.944, 0.952)\",\"0.859 (0.839, 0.877)\",\"0.877 (0.875, 0.879)\",\"0.832 (0.831, 0.834)\"\n\"Label Group DRO\",\"0.928 (0.924, 0.933)\",\"0.817 (0.796, 0.838)\",\"0.876 (0.874, 0.878)\",\"0.831 (0.83, 0.833)\"\n\"LightGBM\",\"0.939 (0.935, 0.943)\",\"0.822 (0.8, 0.841)\",\"0.876 (0.874, 0.878)\",\"0.833 (0.831, 0.835)\"\n\"MLP\",\"0.947 (0.942, 0.95)\",\"0.845 (0.825, 0.864)\",\"0.877 (0.875, 0.879)\",\"0.832 (0.83, 0.833)\"\n\"NODE\",\"0.944 (0.939, 0.948)\",\"0.844 (0.823, 0.863)\",\"0.877 (0.875, 0.879)\",\"0.833 (0.832, 0.835)\"\n\"ResNet\",\"0.947 (0.943, 0.951)\",\"0.854 (0.834, 0.872)\",\"0.874 (0.872, 0.876)\",\"0.829 (0.828, 0.831)\"\n\"SAINT\",\"0.936 (0.931, 0.94)\",\"0.814 (0.792, 0.834)\",\"0.877 (0.875, 0.879)\",\"0.833 (0.831, 0.834)\"\n\"TabTransformer\",\"0.942 (0.938, 0.946)\",\"0.845 (0.825, 0.864)\",\"0.875 (0.873, 0.877)\",\"0.83 (0.829, 0.832)\"\n\"XGBoost\",\"0.942 (0.938, 0.946)\",\"0.83 (0.809, 0.85)\",\"0.877 (0.875, 0.879)\",\"0.832 (0.83, 0.834)\"\n\"CORAL\",\"0.922 (0.917, 0.926)\",\"0.795 (0.773, 0.816)\",\"0.874 (0.872, 0.875)\",\"0.832 (0.83, 0.834)\"\n\"DANN\",\"0.894 (0.889, 0.9)\",\"0.78 (0.757, 0.802)\",\"0.873 (0.871, 0.875)\",\"0.826 (0.824, 0.827)\"\n\"Group DRO\",\"0.944 (0.939, 0.948)\",\"0.829 (0.808, 0.849)\",\"0.877 (0.875, 0.879)\",\"0.832 (0.83, 0.833)\"\n\"IRM\",\"0.879 (0.873, 0.885)\",\"0.746 (0.721, 0.769)\",\"0.873 (0.871, 0.875)\",\"0.826 (0.824, 0.827)\"\n\"MMD\",\"0.925 (0.92, 0.929)\",\"0.795 (0.773, 0.816)\",\"0.873 (0.871, 0.875)\",\"0.826 (0.825, 0.828)\"\n\"MixUp\",\"0.912 (0.907, 0.917)\",\"0.746 (0.721, 0.769)\",\"0.873 (0.871, 0.875)\",\"0.826 (0.824, 0.827)\"\n\"VREX\",\"0.907 (0.902, 0.912)\",\"0.754 (0.731, 0.777)\",\"0.873 (0.871, 0.875)\",\"0.826 (0.824, 0.827)\""}]}, {"page": 32, "text": "         Table 6: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark\n         task. Note that domain generalization models can only be trained on datasets with more than one\n         training subdomain (see Table 1 for domain generalization datasets and Section 4.1 for a list of\n         domain generalization models). \u22c6: domain generalization models cannot be trained when only one\n         training subdomain is present. See also Figures 1, 2,3.\nEstimator                              FICO HELOC                                            Food Stamps\n                        ID Acc. (95% CI)         OOD Acc. (95% CI)            ID Acc. (95% CI)         OOD Acc. (95% CI)\nAdv. Label DRO        0.745    (0.689, 0.795)    0.431    (0.419, 0.443)    0.843   (0.84, 0.846)     0.812    (0.808, 0.815)\nCatBoost              0.727    (0.67, 0.778)     0.582    (0.57, 0.594)     0.849   (0.847, 0.852)    0.825    (0.821, 0.828)\nDRO                   0.745    (0.689, 0.795)    0.431    (0.419, 0.443)    0.844   (0.841, 0.846)    0.819    (0.815, 0.822)\nFT-Transformer        0.745    (0.689, 0.795)    0.431    (0.419, 0.443)    0.843   (0.841, 0.846)    0.816    (0.812, 0.819)\nLabel Group DRO       0.745    (0.689, 0.795)    0.431    (0.419, 0.443)    0.771   (0.768, 0.774)    0.752    (0.748, 0.756)\nLightGBM              0.647    (0.584, 0.7)      0.421    (0.409, 0.433)    0.836   (0.833, 0.838)    0.808    (0.805, 0.812)\nMLP                   0.734    (0.678, 0.785)    0.538    (0.526, 0.55)     0.841   (0.838, 0.844)    0.815    (0.812, 0.819)\nNODE                  0.745    (0.689, 0.795)    0.431    (0.419, 0.443)    0.849   (0.847, 0.852)    0.822    (0.819, 0.825)\nResNet                0.748    (0.693, 0.798)    0.431    (0.42, 0.443)     0.843   (0.84, 0.845)     0.82     (0.817, 0.824)\nSAINT                 0.745    (0.689, 0.795)    0.431    (0.419, 0.443)    0.849   (0.846, 0.851)    0.821    (0.818, 0.825)\nTabTransformer        0.745    (0.689, 0.795)    0.431    (0.419, 0.443)    0.836   (0.834, 0.839)    0.807    (0.803, 0.81)\nXGBoost               0.745    (0.689, 0.795)    0.431    (0.419, 0.443)    0.844   (0.842, 0.847)    0.82     (0.817, 0.824)\nCORAL                 \u22c6        \u22c6                 \u22c6        \u22c6                 0.818   (0.815, 0.82)     0.793    (0.79, 0.797)\nDANN                  \u22c6        \u22c6                 \u22c6        \u22c6                 0.809   (0.806, 0.812)    0.78     (0.776, 0.784)\nGroup DRO             \u22c6        \u22c6                 \u22c6        \u22c6                 0.84    (0.838, 0.843)    0.817    (0.814, 0.821)\nIRM                   \u22c6        \u22c6                 \u22c6        \u22c6                 0.812   (0.81, 0.815)     0.795    (0.791, 0.798)\nMMD                   \u22c6        \u22c6                 \u22c6        \u22c6                 0.813   (0.81, 0.816)     0.786    (0.782, 0.789)\nMixUp                 \u22c6        \u22c6                 \u22c6        \u22c6                 0.819   (0.816, 0.821)    0.785    (0.782, 0.789)\nVREX                  \u22c6        \u22c6                 \u22c6        \u22c6                 0.809   (0.806, 0.812)    0.78     (0.776, 0.784)\n         Table 7: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark\n         task. Note that domain generalization models can only be trained on datasets with more than one\n         training subdomain (see Table 1 for domain generalization datasets and Section 4.1 for a list of\n         domain generalization models). \u22c6: domain generalization models cannot be trained when only one\n         training subdomain is present. See also Figures 1, 2,3.\nEstimator                          Hospital Readmission                                      Hypertension\n                        ID Acc. (95% CI)         OOD Acc. (95% CI)            ID Acc. (95% CI)         OOD Acc. (95% CI)\nAdv. Label DRO        0.655    (0.641, 0.669)    0.603    (0.599, 0.607)    0.666   (0.66, 0.672)     0.601    (0.6, 0.603)\nCatBoost              0.659    (0.645, 0.674)    0.618    (0.614, 0.623)    0.67    (0.665, 0.676)    0.599    (0.597, 0.6)\nDRO                   0.628    (0.613, 0.642)    0.578    (0.574, 0.582)    0.598   (0.592, 0.604)    0.416    (0.414, 0.417)\nFT-Transformer        0.648    (0.633, 0.662)    0.618    (0.614, 0.622)    0.666   (0.661, 0.672)    0.604    (0.603, 0.605)\nLabel Group DRO       0.652    (0.637, 0.666)    0.616    (0.612, 0.62)     0.665   (0.659, 0.671)    0.604    (0.603, 0.605)\nLightGBM              0.658    (0.643, 0.672)    0.598    (0.594, 0.602)    0.678   (0.672, 0.683)    0.634    (0.633, 0.635)\nMLP                   0.648    (0.633, 0.662)    0.612    (0.608, 0.617)    0.664   (0.658, 0.67)     0.583    (0.582, 0.584)\nNODE                  0.659    (0.645, 0.673)    0.624    (0.62, 0.628)     0.67    (0.664, 0.676)    0.597    (0.596, 0.599)\nResNet                0.639    (0.624, 0.653)    0.581    (0.577, 0.586)    0.667   (0.661, 0.672)    0.608    (0.606, 0.609)\nSAINT                 0.654    (0.639, 0.668)    0.61     (0.606, 0.615)    0.669   (0.664, 0.675)    0.595    (0.594, 0.596)\nTabTransformer        0.584    (0.569, 0.599)    0.507    (0.502, 0.511)    0.624   (0.618, 0.63)     0.499    (0.498, 0.501)\nXGBoost               0.651    (0.636, 0.665)    0.605    (0.601, 0.61)     0.671   (0.665, 0.677)    0.588    (0.587, 0.59)\nCORAL                 0.622    (0.607, 0.637)    0.571    (0.567, 0.576)    \u22c6       \u22c6                 \u22c6        \u22c6\nDANN                  0.584    (0.569, 0.599)    0.506    (0.502, 0.51)     \u22c6       \u22c6                 \u22c6        \u22c6\nGroup DRO             0.639    (0.624, 0.653)    0.6      (0.596, 0.605)    \u22c6       \u22c6                 \u22c6        \u22c6\nIRM                   0.595    (0.58, 0.61)      0.55     (0.546, 0.555)    \u22c6       \u22c6                 \u22c6        \u22c6\nMMD                   0.626    (0.611, 0.64)     0.57     (0.565, 0.574)    \u22c6       \u22c6                 \u22c6        \u22c6\nMixUp                 0.589    (0.574, 0.604)    0.567    (0.563, 0.572)    \u22c6       \u22c6                 \u22c6        \u22c6\nVREX                  0.584    (0.569, 0.599)    0.506    (0.502, 0.51)     \u22c6       \u22c6                 \u22c6        \u22c6\n                                                           32", "md": "|Estimator|FICO HELOC| | |Food Stamps| | |\n|---|---|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)| | |\n|Adv. Label DRO|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.843 (0.84, 0.846)|0.812 (0.808, 0.815)| | |\n|CatBoost|0.727 (0.67, 0.778)|0.582 (0.57, 0.594)|0.849 (0.847, 0.852)|0.825 (0.821, 0.828)| | |\n|DRO|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.844 (0.841, 0.846)|0.819 (0.815, 0.822)| | |\n|FT-Transformer|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.843 (0.841, 0.846)|0.816 (0.812, 0.819)| | |\n|Label Group DRO|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.771 (0.768, 0.774)|0.752 (0.748, 0.756)| | |\n|LightGBM|0.647 (0.584, 0.7)|0.421 (0.409, 0.433)|0.836 (0.833, 0.838)|0.808 (0.805, 0.812)| | |\n|MLP|0.734 (0.678, 0.785)|0.538 (0.526, 0.55)|0.841 (0.838, 0.844)|0.815 (0.812, 0.819)| | |\n|NODE|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.849 (0.847, 0.852)|0.822 (0.819, 0.825)| | |\n|ResNet|0.748 (0.693, 0.798)|0.431 (0.42, 0.443)|0.843 (0.84, 0.845)|0.82 (0.817, 0.824)| | |\n|SAINT|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.849 (0.846, 0.851)|0.821 (0.818, 0.825)| | |\n|TabTransformer|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.836 (0.834, 0.839)|0.807 (0.803, 0.81)| | |\n|XGBoost|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.844 (0.842, 0.847)|0.82 (0.817, 0.824)| | |\n|CORAL|\u22c6|\u22c6|0.818 (0.815, 0.82)|0.793 (0.79, 0.797)| | |\n|DANN|\u22c6|\u22c6|0.809 (0.806, 0.812)|0.78 (0.776, 0.784)| | |\n|Group DRO|\u22c6|\u22c6|0.84 (0.838, 0.843)|0.817 (0.814, 0.821)| | |\n|IRM|\u22c6|\u22c6|0.812 (0.81, 0.815)|0.795 (0.791, 0.798)| | |\n|MMD|\u22c6|\u22c6|0.813 (0.81, 0.816)|0.786 (0.782, 0.789)| | |\n|MixUp|\u22c6|\u22c6|0.819 (0.816, 0.821)|0.785 (0.782, 0.789)| | |\n|VREX|\u22c6|\u22c6|0.809 (0.806, 0.812)|0.78 (0.776, 0.784)| | |\n\n|Estimator|Hospital Readmission| | |Hypertension| | |\n|---|---|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)| | |\n|Adv. Label DRO|0.655 (0.641, 0.669)|0.603 (0.599, 0.607)|0.666 (0.66, 0.672)|0.601 (0.6, 0.603)| | |\n|CatBoost|0.659 (0.645, 0.674)|0.618 (0.614, 0.623)|0.67 (0.665, 0.676)|0.599 (0.597, 0.6)| | |\n|DRO|0.628 (0.613, 0.642)|0.578 (0.574, 0.582)|0.598 (0.592, 0.604)|0.416 (0.414, 0.417)| | |\n|FT-Transformer|0.648 (0.633, 0.662)|0.618 (0.614, 0.622)|0.666 (0.661, 0.672)|0.604 (0.603, 0.605)| | |\n|Label Group DRO|0.652 (0.637, 0.666)|0.616 (0.612, 0.62)|0.665 (0.659, 0.671)|0.604 (0.603, 0.605)| | |\n|LightGBM|0.658 (0.643, 0.672)|0.598 (0.594, 0.602)|0.678 (0.672, 0.683)|0.634 (0.633, 0.635)| | |\n|MLP|0.648 (0.633, 0.662)|0.612 (0.608, 0.617)|0.664 (0.658, 0.67)|0.583 (0.582, 0.584)| | |\n|NODE|0.659 (0.645, 0.673)|0.624 (0.62, 0.628)|0.67 (0.664, 0.676)|0.597 (0.596, 0.599)| | |\n|ResNet|0.639 (0.624, 0.653)|0.581 (0.577, 0.586)|0.667 (0.661, 0.672)|0.608 (0.606, 0.609)| | |\n|SAINT|0.654 (0.639, 0.668)|0.61 (0.606, 0.615)|0.669 (0.664, 0.675)|0.595 (0.594, 0.596)| | |\n|TabTransformer|0.584 (0.569, 0.599)|0.507 (0.502, 0.511)|0.624 (0.618, 0.63)|0.499 (0.498, 0.501)| | |\n|XGBoost|0.651 (0.636, 0.665)|0.605 (0.601, 0.61)|0.671 (0.665, 0.677)|0.588 (0.587, 0.59)| | |\n|CORAL|0.622 (0.607, 0.637)|0.571 (0.567, 0.576)|\u22c6|\u22c6| | |\n|DANN|0.584 (0.569, 0.599)|0.506 (0.502, 0.51)|\u22c6|\u22c6| | |\n|Group DRO|0.639 (0.624, 0.653)|0.6 (0.596, 0.605)|\u22c6|\u22c6| | |\n|IRM|0.595 (0.58, 0.61)|0.55 (0.546, 0.555)|\u22c6|\u22c6| | |\n|MMD|0.626 (0.611, 0.64)|0.57 (0.565, 0.574)|\u22c6|\u22c6| | |\n|MixUp|0.589 (0.574, 0.604)|0.567 (0.563, 0.572)|\u22c6|\u22c6| | |\n|VREX|0.584 (0.569, 0.599)|0.506 (0.502, 0.51)|\u22c6|\u22c6| | |", "images": [], "items": [{"type": "table", "rows": [["Estimator", "FICO HELOC", "", "", "Food Stamps", "", ""], ["", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "", ""], ["Adv. Label DRO", "0.745 (0.689, 0.795)", "0.431 (0.419, 0.443)", "0.843 (0.84, 0.846)", "0.812 (0.808, 0.815)", "", ""], ["CatBoost", "0.727 (0.67, 0.778)", "0.582 (0.57, 0.594)", "0.849 (0.847, 0.852)", "0.825 (0.821, 0.828)", "", ""], ["DRO", "0.745 (0.689, 0.795)", "0.431 (0.419, 0.443)", "0.844 (0.841, 0.846)", "0.819 (0.815, 0.822)", "", ""], ["FT-Transformer", "0.745 (0.689, 0.795)", "0.431 (0.419, 0.443)", "0.843 (0.841, 0.846)", "0.816 (0.812, 0.819)", "", ""], ["Label Group DRO", "0.745 (0.689, 0.795)", "0.431 (0.419, 0.443)", "0.771 (0.768, 0.774)", "0.752 (0.748, 0.756)", "", ""], ["LightGBM", "0.647 (0.584, 0.7)", "0.421 (0.409, 0.433)", "0.836 (0.833, 0.838)", "0.808 (0.805, 0.812)", "", ""], ["MLP", "0.734 (0.678, 0.785)", "0.538 (0.526, 0.55)", "0.841 (0.838, 0.844)", "0.815 (0.812, 0.819)", "", ""], ["NODE", "0.745 (0.689, 0.795)", "0.431 (0.419, 0.443)", "0.849 (0.847, 0.852)", "0.822 (0.819, 0.825)", "", ""], ["ResNet", "0.748 (0.693, 0.798)", "0.431 (0.42, 0.443)", "0.843 (0.84, 0.845)", "0.82 (0.817, 0.824)", "", ""], ["SAINT", "0.745 (0.689, 0.795)", "0.431 (0.419, 0.443)", "0.849 (0.846, 0.851)", "0.821 (0.818, 0.825)", "", ""], ["TabTransformer", "0.745 (0.689, 0.795)", "0.431 (0.419, 0.443)", "0.836 (0.834, 0.839)", "0.807 (0.803, 0.81)", "", ""], ["XGBoost", "0.745 (0.689, 0.795)", "0.431 (0.419, 0.443)", "0.844 (0.842, 0.847)", "0.82 (0.817, 0.824)", "", ""], ["CORAL", "\u22c6", "\u22c6", "0.818 (0.815, 0.82)", "0.793 (0.79, 0.797)", "", ""], ["DANN", "\u22c6", "\u22c6", "0.809 (0.806, 0.812)", "0.78 (0.776, 0.784)", "", ""], ["Group DRO", "\u22c6", "\u22c6", "0.84 (0.838, 0.843)", "0.817 (0.814, 0.821)", "", ""], ["IRM", "\u22c6", "\u22c6", "0.812 (0.81, 0.815)", "0.795 (0.791, 0.798)", "", ""], ["MMD", "\u22c6", "\u22c6", "0.813 (0.81, 0.816)", "0.786 (0.782, 0.789)", "", ""], ["MixUp", "\u22c6", "\u22c6", "0.819 (0.816, 0.821)", "0.785 (0.782, 0.789)", "", ""], ["VREX", "\u22c6", "\u22c6", "0.809 (0.806, 0.812)", "0.78 (0.776, 0.784)", "", ""]], "md": "|Estimator|FICO HELOC| | |Food Stamps| | |\n|---|---|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)| | |\n|Adv. Label DRO|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.843 (0.84, 0.846)|0.812 (0.808, 0.815)| | |\n|CatBoost|0.727 (0.67, 0.778)|0.582 (0.57, 0.594)|0.849 (0.847, 0.852)|0.825 (0.821, 0.828)| | |\n|DRO|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.844 (0.841, 0.846)|0.819 (0.815, 0.822)| | |\n|FT-Transformer|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.843 (0.841, 0.846)|0.816 (0.812, 0.819)| | |\n|Label Group DRO|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.771 (0.768, 0.774)|0.752 (0.748, 0.756)| | |\n|LightGBM|0.647 (0.584, 0.7)|0.421 (0.409, 0.433)|0.836 (0.833, 0.838)|0.808 (0.805, 0.812)| | |\n|MLP|0.734 (0.678, 0.785)|0.538 (0.526, 0.55)|0.841 (0.838, 0.844)|0.815 (0.812, 0.819)| | |\n|NODE|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.849 (0.847, 0.852)|0.822 (0.819, 0.825)| | |\n|ResNet|0.748 (0.693, 0.798)|0.431 (0.42, 0.443)|0.843 (0.84, 0.845)|0.82 (0.817, 0.824)| | |\n|SAINT|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.849 (0.846, 0.851)|0.821 (0.818, 0.825)| | |\n|TabTransformer|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.836 (0.834, 0.839)|0.807 (0.803, 0.81)| | |\n|XGBoost|0.745 (0.689, 0.795)|0.431 (0.419, 0.443)|0.844 (0.842, 0.847)|0.82 (0.817, 0.824)| | |\n|CORAL|\u22c6|\u22c6|0.818 (0.815, 0.82)|0.793 (0.79, 0.797)| | |\n|DANN|\u22c6|\u22c6|0.809 (0.806, 0.812)|0.78 (0.776, 0.784)| | |\n|Group DRO|\u22c6|\u22c6|0.84 (0.838, 0.843)|0.817 (0.814, 0.821)| | |\n|IRM|\u22c6|\u22c6|0.812 (0.81, 0.815)|0.795 (0.791, 0.798)| | |\n|MMD|\u22c6|\u22c6|0.813 (0.81, 0.816)|0.786 (0.782, 0.789)| | |\n|MixUp|\u22c6|\u22c6|0.819 (0.816, 0.821)|0.785 (0.782, 0.789)| | |\n|VREX|\u22c6|\u22c6|0.809 (0.806, 0.812)|0.78 (0.776, 0.784)| | |", "isPerfectTable": true, "csv": "\"Estimator\",\"FICO HELOC\",\"\",\"\",\"Food Stamps\",\"\",\"\"\n\"\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"\",\"\"\n\"Adv. Label DRO\",\"0.745 (0.689, 0.795)\",\"0.431 (0.419, 0.443)\",\"0.843 (0.84, 0.846)\",\"0.812 (0.808, 0.815)\",\"\",\"\"\n\"CatBoost\",\"0.727 (0.67, 0.778)\",\"0.582 (0.57, 0.594)\",\"0.849 (0.847, 0.852)\",\"0.825 (0.821, 0.828)\",\"\",\"\"\n\"DRO\",\"0.745 (0.689, 0.795)\",\"0.431 (0.419, 0.443)\",\"0.844 (0.841, 0.846)\",\"0.819 (0.815, 0.822)\",\"\",\"\"\n\"FT-Transformer\",\"0.745 (0.689, 0.795)\",\"0.431 (0.419, 0.443)\",\"0.843 (0.841, 0.846)\",\"0.816 (0.812, 0.819)\",\"\",\"\"\n\"Label Group DRO\",\"0.745 (0.689, 0.795)\",\"0.431 (0.419, 0.443)\",\"0.771 (0.768, 0.774)\",\"0.752 (0.748, 0.756)\",\"\",\"\"\n\"LightGBM\",\"0.647 (0.584, 0.7)\",\"0.421 (0.409, 0.433)\",\"0.836 (0.833, 0.838)\",\"0.808 (0.805, 0.812)\",\"\",\"\"\n\"MLP\",\"0.734 (0.678, 0.785)\",\"0.538 (0.526, 0.55)\",\"0.841 (0.838, 0.844)\",\"0.815 (0.812, 0.819)\",\"\",\"\"\n\"NODE\",\"0.745 (0.689, 0.795)\",\"0.431 (0.419, 0.443)\",\"0.849 (0.847, 0.852)\",\"0.822 (0.819, 0.825)\",\"\",\"\"\n\"ResNet\",\"0.748 (0.693, 0.798)\",\"0.431 (0.42, 0.443)\",\"0.843 (0.84, 0.845)\",\"0.82 (0.817, 0.824)\",\"\",\"\"\n\"SAINT\",\"0.745 (0.689, 0.795)\",\"0.431 (0.419, 0.443)\",\"0.849 (0.846, 0.851)\",\"0.821 (0.818, 0.825)\",\"\",\"\"\n\"TabTransformer\",\"0.745 (0.689, 0.795)\",\"0.431 (0.419, 0.443)\",\"0.836 (0.834, 0.839)\",\"0.807 (0.803, 0.81)\",\"\",\"\"\n\"XGBoost\",\"0.745 (0.689, 0.795)\",\"0.431 (0.419, 0.443)\",\"0.844 (0.842, 0.847)\",\"0.82 (0.817, 0.824)\",\"\",\"\"\n\"CORAL\",\"\u22c6\",\"\u22c6\",\"0.818 (0.815, 0.82)\",\"0.793 (0.79, 0.797)\",\"\",\"\"\n\"DANN\",\"\u22c6\",\"\u22c6\",\"0.809 (0.806, 0.812)\",\"0.78 (0.776, 0.784)\",\"\",\"\"\n\"Group DRO\",\"\u22c6\",\"\u22c6\",\"0.84 (0.838, 0.843)\",\"0.817 (0.814, 0.821)\",\"\",\"\"\n\"IRM\",\"\u22c6\",\"\u22c6\",\"0.812 (0.81, 0.815)\",\"0.795 (0.791, 0.798)\",\"\",\"\"\n\"MMD\",\"\u22c6\",\"\u22c6\",\"0.813 (0.81, 0.816)\",\"0.786 (0.782, 0.789)\",\"\",\"\"\n\"MixUp\",\"\u22c6\",\"\u22c6\",\"0.819 (0.816, 0.821)\",\"0.785 (0.782, 0.789)\",\"\",\"\"\n\"VREX\",\"\u22c6\",\"\u22c6\",\"0.809 (0.806, 0.812)\",\"0.78 (0.776, 0.784)\",\"\",\"\""}, {"type": "table", "rows": [["Estimator", "Hospital Readmission", "", "", "Hypertension", "", ""], ["", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "", ""], ["Adv. Label DRO", "0.655 (0.641, 0.669)", "0.603 (0.599, 0.607)", "0.666 (0.66, 0.672)", "0.601 (0.6, 0.603)", "", ""], ["CatBoost", "0.659 (0.645, 0.674)", "0.618 (0.614, 0.623)", "0.67 (0.665, 0.676)", "0.599 (0.597, 0.6)", "", ""], ["DRO", "0.628 (0.613, 0.642)", "0.578 (0.574, 0.582)", "0.598 (0.592, 0.604)", "0.416 (0.414, 0.417)", "", ""], ["FT-Transformer", "0.648 (0.633, 0.662)", "0.618 (0.614, 0.622)", "0.666 (0.661, 0.672)", "0.604 (0.603, 0.605)", "", ""], ["Label Group DRO", "0.652 (0.637, 0.666)", "0.616 (0.612, 0.62)", "0.665 (0.659, 0.671)", "0.604 (0.603, 0.605)", "", ""], ["LightGBM", "0.658 (0.643, 0.672)", "0.598 (0.594, 0.602)", "0.678 (0.672, 0.683)", "0.634 (0.633, 0.635)", "", ""], ["MLP", "0.648 (0.633, 0.662)", "0.612 (0.608, 0.617)", "0.664 (0.658, 0.67)", "0.583 (0.582, 0.584)", "", ""], ["NODE", "0.659 (0.645, 0.673)", "0.624 (0.62, 0.628)", "0.67 (0.664, 0.676)", "0.597 (0.596, 0.599)", "", ""], ["ResNet", "0.639 (0.624, 0.653)", "0.581 (0.577, 0.586)", "0.667 (0.661, 0.672)", "0.608 (0.606, 0.609)", "", ""], ["SAINT", "0.654 (0.639, 0.668)", "0.61 (0.606, 0.615)", "0.669 (0.664, 0.675)", "0.595 (0.594, 0.596)", "", ""], ["TabTransformer", "0.584 (0.569, 0.599)", "0.507 (0.502, 0.511)", "0.624 (0.618, 0.63)", "0.499 (0.498, 0.501)", "", ""], ["XGBoost", "0.651 (0.636, 0.665)", "0.605 (0.601, 0.61)", "0.671 (0.665, 0.677)", "0.588 (0.587, 0.59)", "", ""], ["CORAL", "0.622 (0.607, 0.637)", "0.571 (0.567, 0.576)", "\u22c6", "\u22c6", "", ""], ["DANN", "0.584 (0.569, 0.599)", "0.506 (0.502, 0.51)", "\u22c6", "\u22c6", "", ""], ["Group DRO", "0.639 (0.624, 0.653)", "0.6 (0.596, 0.605)", "\u22c6", "\u22c6", "", ""], ["IRM", "0.595 (0.58, 0.61)", "0.55 (0.546, 0.555)", "\u22c6", "\u22c6", "", ""], ["MMD", "0.626 (0.611, 0.64)", "0.57 (0.565, 0.574)", "\u22c6", "\u22c6", "", ""], ["MixUp", "0.589 (0.574, 0.604)", "0.567 (0.563, 0.572)", "\u22c6", "\u22c6", "", ""], ["VREX", "0.584 (0.569, 0.599)", "0.506 (0.502, 0.51)", "\u22c6", "\u22c6", "", ""]], "md": "|Estimator|Hospital Readmission| | |Hypertension| | |\n|---|---|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)| | |\n|Adv. Label DRO|0.655 (0.641, 0.669)|0.603 (0.599, 0.607)|0.666 (0.66, 0.672)|0.601 (0.6, 0.603)| | |\n|CatBoost|0.659 (0.645, 0.674)|0.618 (0.614, 0.623)|0.67 (0.665, 0.676)|0.599 (0.597, 0.6)| | |\n|DRO|0.628 (0.613, 0.642)|0.578 (0.574, 0.582)|0.598 (0.592, 0.604)|0.416 (0.414, 0.417)| | |\n|FT-Transformer|0.648 (0.633, 0.662)|0.618 (0.614, 0.622)|0.666 (0.661, 0.672)|0.604 (0.603, 0.605)| | |\n|Label Group DRO|0.652 (0.637, 0.666)|0.616 (0.612, 0.62)|0.665 (0.659, 0.671)|0.604 (0.603, 0.605)| | |\n|LightGBM|0.658 (0.643, 0.672)|0.598 (0.594, 0.602)|0.678 (0.672, 0.683)|0.634 (0.633, 0.635)| | |\n|MLP|0.648 (0.633, 0.662)|0.612 (0.608, 0.617)|0.664 (0.658, 0.67)|0.583 (0.582, 0.584)| | |\n|NODE|0.659 (0.645, 0.673)|0.624 (0.62, 0.628)|0.67 (0.664, 0.676)|0.597 (0.596, 0.599)| | |\n|ResNet|0.639 (0.624, 0.653)|0.581 (0.577, 0.586)|0.667 (0.661, 0.672)|0.608 (0.606, 0.609)| | |\n|SAINT|0.654 (0.639, 0.668)|0.61 (0.606, 0.615)|0.669 (0.664, 0.675)|0.595 (0.594, 0.596)| | |\n|TabTransformer|0.584 (0.569, 0.599)|0.507 (0.502, 0.511)|0.624 (0.618, 0.63)|0.499 (0.498, 0.501)| | |\n|XGBoost|0.651 (0.636, 0.665)|0.605 (0.601, 0.61)|0.671 (0.665, 0.677)|0.588 (0.587, 0.59)| | |\n|CORAL|0.622 (0.607, 0.637)|0.571 (0.567, 0.576)|\u22c6|\u22c6| | |\n|DANN|0.584 (0.569, 0.599)|0.506 (0.502, 0.51)|\u22c6|\u22c6| | |\n|Group DRO|0.639 (0.624, 0.653)|0.6 (0.596, 0.605)|\u22c6|\u22c6| | |\n|IRM|0.595 (0.58, 0.61)|0.55 (0.546, 0.555)|\u22c6|\u22c6| | |\n|MMD|0.626 (0.611, 0.64)|0.57 (0.565, 0.574)|\u22c6|\u22c6| | |\n|MixUp|0.589 (0.574, 0.604)|0.567 (0.563, 0.572)|\u22c6|\u22c6| | |\n|VREX|0.584 (0.569, 0.599)|0.506 (0.502, 0.51)|\u22c6|\u22c6| | |", "isPerfectTable": true, "csv": "\"Estimator\",\"Hospital Readmission\",\"\",\"\",\"Hypertension\",\"\",\"\"\n\"\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"\",\"\"\n\"Adv. Label DRO\",\"0.655 (0.641, 0.669)\",\"0.603 (0.599, 0.607)\",\"0.666 (0.66, 0.672)\",\"0.601 (0.6, 0.603)\",\"\",\"\"\n\"CatBoost\",\"0.659 (0.645, 0.674)\",\"0.618 (0.614, 0.623)\",\"0.67 (0.665, 0.676)\",\"0.599 (0.597, 0.6)\",\"\",\"\"\n\"DRO\",\"0.628 (0.613, 0.642)\",\"0.578 (0.574, 0.582)\",\"0.598 (0.592, 0.604)\",\"0.416 (0.414, 0.417)\",\"\",\"\"\n\"FT-Transformer\",\"0.648 (0.633, 0.662)\",\"0.618 (0.614, 0.622)\",\"0.666 (0.661, 0.672)\",\"0.604 (0.603, 0.605)\",\"\",\"\"\n\"Label Group DRO\",\"0.652 (0.637, 0.666)\",\"0.616 (0.612, 0.62)\",\"0.665 (0.659, 0.671)\",\"0.604 (0.603, 0.605)\",\"\",\"\"\n\"LightGBM\",\"0.658 (0.643, 0.672)\",\"0.598 (0.594, 0.602)\",\"0.678 (0.672, 0.683)\",\"0.634 (0.633, 0.635)\",\"\",\"\"\n\"MLP\",\"0.648 (0.633, 0.662)\",\"0.612 (0.608, 0.617)\",\"0.664 (0.658, 0.67)\",\"0.583 (0.582, 0.584)\",\"\",\"\"\n\"NODE\",\"0.659 (0.645, 0.673)\",\"0.624 (0.62, 0.628)\",\"0.67 (0.664, 0.676)\",\"0.597 (0.596, 0.599)\",\"\",\"\"\n\"ResNet\",\"0.639 (0.624, 0.653)\",\"0.581 (0.577, 0.586)\",\"0.667 (0.661, 0.672)\",\"0.608 (0.606, 0.609)\",\"\",\"\"\n\"SAINT\",\"0.654 (0.639, 0.668)\",\"0.61 (0.606, 0.615)\",\"0.669 (0.664, 0.675)\",\"0.595 (0.594, 0.596)\",\"\",\"\"\n\"TabTransformer\",\"0.584 (0.569, 0.599)\",\"0.507 (0.502, 0.511)\",\"0.624 (0.618, 0.63)\",\"0.499 (0.498, 0.501)\",\"\",\"\"\n\"XGBoost\",\"0.651 (0.636, 0.665)\",\"0.605 (0.601, 0.61)\",\"0.671 (0.665, 0.677)\",\"0.588 (0.587, 0.59)\",\"\",\"\"\n\"CORAL\",\"0.622 (0.607, 0.637)\",\"0.571 (0.567, 0.576)\",\"\u22c6\",\"\u22c6\",\"\",\"\"\n\"DANN\",\"0.584 (0.569, 0.599)\",\"0.506 (0.502, 0.51)\",\"\u22c6\",\"\u22c6\",\"\",\"\"\n\"Group DRO\",\"0.639 (0.624, 0.653)\",\"0.6 (0.596, 0.605)\",\"\u22c6\",\"\u22c6\",\"\",\"\"\n\"IRM\",\"0.595 (0.58, 0.61)\",\"0.55 (0.546, 0.555)\",\"\u22c6\",\"\u22c6\",\"\",\"\"\n\"MMD\",\"0.626 (0.611, 0.64)\",\"0.57 (0.565, 0.574)\",\"\u22c6\",\"\u22c6\",\"\",\"\"\n\"MixUp\",\"0.589 (0.574, 0.604)\",\"0.567 (0.563, 0.572)\",\"\u22c6\",\"\u22c6\",\"\",\"\"\n\"VREX\",\"0.584 (0.569, 0.599)\",\"0.506 (0.502, 0.51)\",\"\u22c6\",\"\u22c6\",\"\",\"\""}]}, {"page": 33, "text": "         Table 8: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark\n         task. Note that domain generalization models can only be trained on datasets with more than one\n         training subdomain (see Table 1 for domain generalization datasets and Section 4.1 for a list of\n         domain generalization models). \u22c6: domain generalization models cannot be trained when only one\n         training subdomain is present. See also Figures 1, 2,3. \u2661: the large feature dimensionality of both\n         ICU datasets makes training Transformer-based models impractical (e.g. even a single-layer SAINT\n         model requires >13B trainable parameters on both ICU datasets)\nEstimator                         ICU Hospital Mortality                                  ICU Length of Stay\n                        ID Acc. (95% CI)         OOD Acc. (95% CI)            ID Acc. (95% CI)         OOD Acc. (95% CI)\nAdv. Label DRO        0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.602   (0.572, 0.631)    0.544    (0.535, 0.553)\nCatBoost              0.934    (0.914, 0.948)    0.892    (0.887, 0.897)    0.71    (0.682, 0.737)    0.674    (0.665, 0.682)\nDRO                   0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.601   (0.571, 0.63)     0.544    (0.535, 0.553)\nFT-Transformer        \u2661        \u2661                 \u2661        \u2661                 \u2661       \u2661                 \u2661        \u2661\nLabel Group DRO       0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.59    (0.56, 0.619)     0.542    (0.533, 0.551)\nLightGBM              0.946    (0.928, 0.959)    0.883    (0.877, 0.888)    0.689   (0.66, 0.716)     0.655    (0.646, 0.663)\nMLP                   0.912    (0.891, 0.929)    0.877    (0.871, 0.882)    0.599   (0.569, 0.628)    0.544    (0.535, 0.553)\nNODE                  0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.661   (0.632, 0.689)    0.609    (0.6, 0.618)\nResNet                0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.606   (0.576, 0.635)    0.577    (0.568, 0.586)\nSAINT                 \u2661        \u2661                 \u2661        \u2661                 \u2661       \u2661                 \u2661        \u2661\nTabTransformer        0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.604   (0.574, 0.633)    0.549    (0.54, 0.558)\nXGBoost               0.927    (0.908, 0.943)    0.882    (0.876, 0.887)    0.71    (0.682, 0.737)    0.669    (0.66, 0.677)\nCORAL                 0.915    (0.893, 0.931)    0.875    (0.869, 0.881)    0.603   (0.573, 0.632)    0.544    (0.535, 0.553)\nDANN                  0.915    (0.893, 0.931)    0.876    (0.871, 0.882)    0.594   (0.564, 0.624)    0.545    (0.536, 0.554)\nGroup DRO             0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.602   (0.572, 0.631)    0.544    (0.535, 0.553)\nIRM                   0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.601   (0.571, 0.63)     0.544    (0.535, 0.553)\nMMD                   0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.602   (0.572, 0.631)    0.544    (0.535, 0.553)\nMixUp                 0.915    (0.893, 0.931)    0.876    (0.87, 0.882)     0.602   (0.572, 0.631)    0.544    (0.535, 0.553)\nVREX                  0.913    (0.893, 0.931)    0.876    (0.87, 0.882)     0.597   (0.567, 0.627)    0.545    (0.536, 0.554)\n                                                           33", "md": "|Estimator|ICU Hospital Mortality| |ICU Length of Stay|\n|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)|\n|Adv. Label DRO|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.602 (0.572, 0.631)|0.544 (0.535, 0.553)|\n|CatBoost|0.934 (0.914, 0.948)|0.892 (0.887, 0.897)|0.71 (0.682, 0.737)|0.674 (0.665, 0.682)|\n|DRO|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.601 (0.571, 0.63)|0.544 (0.535, 0.553)|\n|FT-Transformer|\u2661|\u2661|\u2661|\u2661|\n|Label Group DRO|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.59 (0.56, 0.619)|0.542 (0.533, 0.551)|\n|LightGBM|0.946 (0.928, 0.959)|0.883 (0.877, 0.888)|0.689 (0.66, 0.716)|0.655 (0.646, 0.663)|\n|MLP|0.912 (0.891, 0.929)|0.877 (0.871, 0.882)|0.599 (0.569, 0.628)|0.544 (0.535, 0.553)|\n|NODE|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.661 (0.632, 0.689)|0.609 (0.6, 0.618)|\n|ResNet|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.606 (0.576, 0.635)|0.577 (0.568, 0.586)|\n|SAINT|\u2661|\u2661|\u2661|\u2661|\n|TabTransformer|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.604 (0.574, 0.633)|0.549 (0.54, 0.558)|\n|XGBoost|0.927 (0.908, 0.943)|0.882 (0.876, 0.887)|0.71 (0.682, 0.737)|0.669 (0.66, 0.677)|\n|CORAL|0.915 (0.893, 0.931)|0.875 (0.869, 0.881)|0.603 (0.573, 0.632)|0.544 (0.535, 0.553)|\n|DANN|0.915 (0.893, 0.931)|0.876 (0.871, 0.882)|0.594 (0.564, 0.624)|0.545 (0.536, 0.554)|\n|Group DRO|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.602 (0.572, 0.631)|0.544 (0.535, 0.553)|\n|IRM|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.601 (0.571, 0.63)|0.544 (0.535, 0.553)|\n|MMD|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.602 (0.572, 0.631)|0.544 (0.535, 0.553)|\n|MixUp|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.602 (0.572, 0.631)|0.544 (0.535, 0.553)|\n|VREX|0.913 (0.893, 0.931)|0.876 (0.87, 0.882)|0.597 (0.567, 0.627)|0.545 (0.536, 0.554)|", "images": [], "items": [{"type": "table", "rows": [["Estimator", "ICU Hospital Mortality", "", "ICU Length of Stay"], ["", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "ID Acc. (95% CI)", "OOD Acc. (95% CI)"], ["Adv. Label DRO", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.602 (0.572, 0.631)", "0.544 (0.535, 0.553)"], ["CatBoost", "0.934 (0.914, 0.948)", "0.892 (0.887, 0.897)", "0.71 (0.682, 0.737)", "0.674 (0.665, 0.682)"], ["DRO", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.601 (0.571, 0.63)", "0.544 (0.535, 0.553)"], ["FT-Transformer", "\u2661", "\u2661", "\u2661", "\u2661"], ["Label Group DRO", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.59 (0.56, 0.619)", "0.542 (0.533, 0.551)"], ["LightGBM", "0.946 (0.928, 0.959)", "0.883 (0.877, 0.888)", "0.689 (0.66, 0.716)", "0.655 (0.646, 0.663)"], ["MLP", "0.912 (0.891, 0.929)", "0.877 (0.871, 0.882)", "0.599 (0.569, 0.628)", "0.544 (0.535, 0.553)"], ["NODE", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.661 (0.632, 0.689)", "0.609 (0.6, 0.618)"], ["ResNet", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.606 (0.576, 0.635)", "0.577 (0.568, 0.586)"], ["SAINT", "\u2661", "\u2661", "\u2661", "\u2661"], ["TabTransformer", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.604 (0.574, 0.633)", "0.549 (0.54, 0.558)"], ["XGBoost", "0.927 (0.908, 0.943)", "0.882 (0.876, 0.887)", "0.71 (0.682, 0.737)", "0.669 (0.66, 0.677)"], ["CORAL", "0.915 (0.893, 0.931)", "0.875 (0.869, 0.881)", "0.603 (0.573, 0.632)", "0.544 (0.535, 0.553)"], ["DANN", "0.915 (0.893, 0.931)", "0.876 (0.871, 0.882)", "0.594 (0.564, 0.624)", "0.545 (0.536, 0.554)"], ["Group DRO", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.602 (0.572, 0.631)", "0.544 (0.535, 0.553)"], ["IRM", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.601 (0.571, 0.63)", "0.544 (0.535, 0.553)"], ["MMD", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.602 (0.572, 0.631)", "0.544 (0.535, 0.553)"], ["MixUp", "0.915 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.602 (0.572, 0.631)", "0.544 (0.535, 0.553)"], ["VREX", "0.913 (0.893, 0.931)", "0.876 (0.87, 0.882)", "0.597 (0.567, 0.627)", "0.545 (0.536, 0.554)"]], "md": "|Estimator|ICU Hospital Mortality| |ICU Length of Stay|\n|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)|\n|Adv. Label DRO|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.602 (0.572, 0.631)|0.544 (0.535, 0.553)|\n|CatBoost|0.934 (0.914, 0.948)|0.892 (0.887, 0.897)|0.71 (0.682, 0.737)|0.674 (0.665, 0.682)|\n|DRO|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.601 (0.571, 0.63)|0.544 (0.535, 0.553)|\n|FT-Transformer|\u2661|\u2661|\u2661|\u2661|\n|Label Group DRO|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.59 (0.56, 0.619)|0.542 (0.533, 0.551)|\n|LightGBM|0.946 (0.928, 0.959)|0.883 (0.877, 0.888)|0.689 (0.66, 0.716)|0.655 (0.646, 0.663)|\n|MLP|0.912 (0.891, 0.929)|0.877 (0.871, 0.882)|0.599 (0.569, 0.628)|0.544 (0.535, 0.553)|\n|NODE|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.661 (0.632, 0.689)|0.609 (0.6, 0.618)|\n|ResNet|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.606 (0.576, 0.635)|0.577 (0.568, 0.586)|\n|SAINT|\u2661|\u2661|\u2661|\u2661|\n|TabTransformer|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.604 (0.574, 0.633)|0.549 (0.54, 0.558)|\n|XGBoost|0.927 (0.908, 0.943)|0.882 (0.876, 0.887)|0.71 (0.682, 0.737)|0.669 (0.66, 0.677)|\n|CORAL|0.915 (0.893, 0.931)|0.875 (0.869, 0.881)|0.603 (0.573, 0.632)|0.544 (0.535, 0.553)|\n|DANN|0.915 (0.893, 0.931)|0.876 (0.871, 0.882)|0.594 (0.564, 0.624)|0.545 (0.536, 0.554)|\n|Group DRO|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.602 (0.572, 0.631)|0.544 (0.535, 0.553)|\n|IRM|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.601 (0.571, 0.63)|0.544 (0.535, 0.553)|\n|MMD|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.602 (0.572, 0.631)|0.544 (0.535, 0.553)|\n|MixUp|0.915 (0.893, 0.931)|0.876 (0.87, 0.882)|0.602 (0.572, 0.631)|0.544 (0.535, 0.553)|\n|VREX|0.913 (0.893, 0.931)|0.876 (0.87, 0.882)|0.597 (0.567, 0.627)|0.545 (0.536, 0.554)|", "isPerfectTable": false, "csv": "\"Estimator\",\"ICU Hospital Mortality\",\"\",\"ICU Length of Stay\"\n\"\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\"\n\"Adv. Label DRO\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.602 (0.572, 0.631)\",\"0.544 (0.535, 0.553)\"\n\"CatBoost\",\"0.934 (0.914, 0.948)\",\"0.892 (0.887, 0.897)\",\"0.71 (0.682, 0.737)\",\"0.674 (0.665, 0.682)\"\n\"DRO\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.601 (0.571, 0.63)\",\"0.544 (0.535, 0.553)\"\n\"FT-Transformer\",\"\u2661\",\"\u2661\",\"\u2661\",\"\u2661\"\n\"Label Group DRO\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.59 (0.56, 0.619)\",\"0.542 (0.533, 0.551)\"\n\"LightGBM\",\"0.946 (0.928, 0.959)\",\"0.883 (0.877, 0.888)\",\"0.689 (0.66, 0.716)\",\"0.655 (0.646, 0.663)\"\n\"MLP\",\"0.912 (0.891, 0.929)\",\"0.877 (0.871, 0.882)\",\"0.599 (0.569, 0.628)\",\"0.544 (0.535, 0.553)\"\n\"NODE\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.661 (0.632, 0.689)\",\"0.609 (0.6, 0.618)\"\n\"ResNet\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.606 (0.576, 0.635)\",\"0.577 (0.568, 0.586)\"\n\"SAINT\",\"\u2661\",\"\u2661\",\"\u2661\",\"\u2661\"\n\"TabTransformer\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.604 (0.574, 0.633)\",\"0.549 (0.54, 0.558)\"\n\"XGBoost\",\"0.927 (0.908, 0.943)\",\"0.882 (0.876, 0.887)\",\"0.71 (0.682, 0.737)\",\"0.669 (0.66, 0.677)\"\n\"CORAL\",\"0.915 (0.893, 0.931)\",\"0.875 (0.869, 0.881)\",\"0.603 (0.573, 0.632)\",\"0.544 (0.535, 0.553)\"\n\"DANN\",\"0.915 (0.893, 0.931)\",\"0.876 (0.871, 0.882)\",\"0.594 (0.564, 0.624)\",\"0.545 (0.536, 0.554)\"\n\"Group DRO\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.602 (0.572, 0.631)\",\"0.544 (0.535, 0.553)\"\n\"IRM\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.601 (0.571, 0.63)\",\"0.544 (0.535, 0.553)\"\n\"MMD\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.602 (0.572, 0.631)\",\"0.544 (0.535, 0.553)\"\n\"MixUp\",\"0.915 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.602 (0.572, 0.631)\",\"0.544 (0.535, 0.553)\"\n\"VREX\",\"0.913 (0.893, 0.931)\",\"0.876 (0.87, 0.882)\",\"0.597 (0.567, 0.627)\",\"0.545 (0.536, 0.554)\""}]}, {"page": 34, "text": "         Table 9: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark\n         task. Note that domain generalization models can only be trained on datasets with more than one\n         training subdomain (see Table 1 for domain generalization datasets and Section 4.1 for a list of\n         domain generalization models). \u22c6: domain generalization models cannot be trained when only one\n         training subdomain is present. \u25a1: the large dataset size makes training adversarial label DRO models\n         impractical (since per-example gradients must be computed). We leave these experiments to future\n         work. See also Figures 1, 2,3.\nEstimator                                  Income                                        Public Health Ins.\n                        ID Acc. (95% CI)         OOD Acc. (95% CI)          ID Acc. (95% CI)         OOD Acc. (95% CI)\nAdv. Label DRO        0.829    (0.827, 0.83)    0.819    (0.816, 0.822)   \u25a1        \u25a1                \u25a1        \u25a1\nCatBoost              0.832    (0.83, 0.834)    0.814    (0.811, 0.817)   0.814    (0.812, 0.815)   0.69     (0.689, 0.691)\nDRO                   0.828    (0.826, 0.83)    0.818    (0.816, 0.821)   0.809    (0.808, 0.81)    0.647    (0.646, 0.648)\nFT-Transformer        0.825    (0.823, 0.827)   0.818    (0.815, 0.821)   0.807    (0.806, 0.808)   0.662    (0.661, 0.663)\nLabel Group DRO       0.819    (0.817, 0.821)   0.818    (0.815, 0.821)   0.776    (0.775, 0.777)   0.364    (0.363, 0.365)\nLightGBM              0.822    (0.82, 0.824)    0.809    (0.806, 0.812)   0.803    (0.802, 0.804)   0.639    (0.638, 0.64)\nMLP                   0.828    (0.826, 0.829)   0.813    (0.81, 0.816)    0.808    (0.806, 0.809)   0.612    (0.611, 0.613)\nNODE                  0.831    (0.829, 0.833)   0.81     (0.807, 0.813)   0.811    (0.81, 0.812)    0.662    (0.661, 0.663)\nResNet                0.826    (0.824, 0.828)   0.815    (0.812, 0.818)   0.81     (0.809, 0.811)   0.672    (0.671, 0.673)\nSAINT                 0.829    (0.827, 0.831)   0.81     (0.807, 0.812)   0.811    (0.81, 0.812)    0.68     (0.679, 0.681)\nTabTransformer        0.818    (0.816, 0.82)    0.801    (0.798, 0.804)   0.803    (0.802, 0.804)   0.588    (0.587, 0.589)\nXGBoost               0.821    (0.819, 0.823)   0.792    (0.789, 0.795)   0.805    (0.804, 0.806)   0.661    (0.66, 0.662)\nCORAL                 0.817    (0.815, 0.819)   0.791    (0.788, 0.793)   \u22c6        \u22c6                \u22c6        \u22c6\nDANN                  0.815    (0.813, 0.817)   0.812    (0.809, 0.815)   \u22c6        \u22c6                \u22c6        \u22c6\nGroup DRO             0.827    (0.826, 0.829)   0.813    (0.81, 0.815)    \u22c6        \u22c6                \u22c6        \u22c6\nIRM                   0.756    (0.754, 0.758)   0.699    (0.696, 0.702)   \u22c6        \u22c6                \u22c6        \u22c6\nMMD                   0.816    (0.814, 0.818)   0.768    (0.765, 0.771)   \u22c6        \u22c6                \u22c6        \u22c6\nMixUp                 0.821    (0.819, 0.823)   0.794    (0.791, 0.797)   \u22c6        \u22c6                \u22c6        \u22c6\nVREX                  0.714    (0.712, 0.716)   0.64     (0.637, 0.644)   \u22c6        \u22c6                \u22c6        \u22c6\n         Table 10: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark\n         task. Note that domain generalization models can only be trained on datasets with more than one\n         training subdomain (see Table 1 for domain generalization datasets and Section 4.1 for a list of\n         domain generalization models). \u22c6: domain generalization models cannot be trained when only one\n         training subdomain is present. See also Figures 1, 2,3.\nEstimator                                  Sepsis                                          Unemployment\n                        ID Acc. (95% CI)         OOD Acc. (95% CI)          ID Acc. (95% CI)         OOD Acc. (95% CI)\nAdv. Label DRO        0.988    (0.987, 0.989)   0.925    (0.924, 0.926)   0.972    (0.971, 0.973)   0.96     (0.959, 0.961)\nCatBoost              0.988    (0.987, 0.989)   0.925    (0.923, 0.926)   0.973    (0.973, 0.974)   0.962    (0.961, 0.963)\nDRO                   0.988    (0.987, 0.989)   0.925    (0.924, 0.926)   0.973    (0.972, 0.973)   0.961    (0.96, 0.962)\nFT-Transformer        0.988    (0.987, 0.989)   0.925    (0.924, 0.926)   0.973    (0.972, 0.974)   0.962    (0.961, 0.962)\nLabel Group DRO       0.988    (0.987, 0.989)   0.925    (0.924, 0.926)   0.947    (0.946, 0.948)   0.926    (0.925, 0.927)\nLightGBM              0.988    (0.987, 0.989)   0.928    (0.926, 0.929)   0.973    (0.972, 0.974)   0.96     (0.96, 0.961)\nMLP                   0.988    (0.987, 0.989)   0.925    (0.923, 0.926)   0.973    (0.972, 0.973)   0.96     (0.959, 0.961)\nNODE                  0.988    (0.987, 0.989)   0.925    (0.924, 0.926)   0.973    (0.972, 0.974)   0.962    (0.961, 0.963)\nResNet                0.988    (0.987, 0.989)   0.925    (0.924, 0.926)   0.972    (0.971, 0.972)   0.959    (0.958, 0.96)\nSAINT                 0.988    (0.987, 0.989)   0.925    (0.924, 0.926)   0.973    (0.972, 0.974)   0.962    (0.961, 0.963)\nTabTransformer        0.988    (0.987, 0.989)   0.925    (0.924, 0.926)   0.972    (0.971, 0.973)   0.961    (0.96, 0.962)\nXGBoost               0.988    (0.987, 0.989)   0.925    (0.923, 0.926)   0.973    (0.972, 0.973)   0.961    (0.961, 0.962)\nCORAL                 \u22c6        \u22c6                \u22c6        \u22c6                0.964    (0.963, 0.965)   0.95     (0.949, 0.951)\nDANN                  \u22c6        \u22c6                \u22c6        \u22c6                0.966    (0.965, 0.967)   0.948    (0.947, 0.95)\nGroup DRO             \u22c6        \u22c6                \u22c6        \u22c6                0.971    (0.97, 0.972)    0.958    (0.957, 0.959)\nIRM                   \u22c6        \u22c6                \u22c6        \u22c6                0.966    (0.965, 0.967)   0.948    (0.947, 0.95)\nMMD                   \u22c6        \u22c6                \u22c6        \u22c6                0.966    (0.966, 0.967)   0.953    (0.952, 0.954)\nMixUp                 \u22c6        \u22c6                \u22c6        \u22c6                0.844    (0.842, 0.846)   0.776    (0.774, 0.778)\nVREX                  \u22c6        \u22c6                \u22c6        \u22c6                0.873    (0.871, 0.874)   0.8      (0.798, 0.802)\n                                                          34", "md": "|Estimator|Income| | |Public Health Ins.| | |\n|---|---|---|---|---|---|---|\n| |ID Acc. (95% CI)| |OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)| |\n|Adv. Label DRO|0.829 (0.827, 0.83)|0.819 (0.816, 0.822)|\u25a1|\u25a1|\u25a1|\u25a1|\n|CatBoost|0.832 (0.83, 0.834)|0.814 (0.811, 0.817)|0.814 (0.812, 0.815)|0.69 (0.689, 0.691)| | |\n| | | |DRO|0.828 (0.826, 0.83)|0.818 (0.816, 0.821)|0.809 (0.808, 0.81)|0.647 (0.646, 0.648)|\n|FT-Transformer|0.825 (0.823, 0.827)|0.818 (0.815, 0.821)|0.807 (0.806, 0.808)|0.662 (0.661, 0.663)| | |\n|Label Group DRO|0.819 (0.817, 0.821)|0.818 (0.815, 0.821)|0.776 (0.775, 0.777)|0.364 (0.363, 0.365)| | |\n|LightGBM|0.822 (0.82, 0.824)|0.809 (0.806, 0.812)|0.803 (0.802, 0.804)|0.639 (0.638, 0.64)| | |\n|MLP|0.828 (0.826, 0.829)|0.813 (0.81, 0.816)|0.808 (0.806, 0.809)|0.612 (0.611, 0.613)| | |\n|NODE|0.831 (0.829, 0.833)|0.81 (0.807, 0.813)|0.811 (0.81, 0.812)|0.662 (0.661, 0.663)| | |\n|ResNet|0.826 (0.824, 0.828)|0.815 (0.812, 0.818)|0.81 (0.809, 0.811)|0.672 (0.671, 0.673)| | |\n|SAINT|0.829 (0.827, 0.831)|0.81 (0.807, 0.812)|0.811 (0.81, 0.812)|0.68 (0.679, 0.681)| | |\n|TabTransformer|0.818 (0.816, 0.82)|0.801 (0.798, 0.804)|0.803 (0.802, 0.804)|0.588 (0.587, 0.589)| | |\n|XGBoost|0.821 (0.819, 0.823)|0.792 (0.789, 0.795)|0.805 (0.804, 0.806)|0.661 (0.66, 0.662)| | |\n|CORAL|0.817 (0.815, 0.819)|0.791 (0.788, 0.793)|\u22c6|\u22c6|\u22c6|\u22c6|\n|DANN|0.815 (0.813, 0.817)|0.812 (0.809, 0.815)|\u22c6|\u22c6|\u22c6|\u22c6|\n|Group DRO|0.827 (0.826, 0.829)|0.813 (0.81, 0.815)|\u22c6|\u22c6|\u22c6|\u22c6|\n|IRM|0.756 (0.754, 0.758)|0.699 (0.696, 0.702)|\u22c6|\u22c6|\u22c6|\u22c6|\n|MMD|0.816 (0.814, 0.818)|0.768 (0.765, 0.771)|\u22c6|\u22c6|\u22c6|\u22c6|\n|MixUp|0.821 (0.819, 0.823)|0.794 (0.791, 0.797)|\u22c6|\u22c6|\u22c6|\u22c6|\n|VREX|0.714 (0.712, 0.716)|0.64 (0.637, 0.644)|\u22c6|\u22c6|\u22c6|\u22c6|\n\n|Estimator|Sepsis| | |Unemployment| | |\n|---|---|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)| | |\n|Adv. Label DRO|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.972 (0.971, 0.973)|0.96 (0.959, 0.961)| | |\n|CatBoost|0.988 (0.987, 0.989)|0.925 (0.923, 0.926)|0.973 (0.973, 0.974)|0.962 (0.961, 0.963)| | |\n|DRO|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.973 (0.972, 0.973)|0.961 (0.96, 0.962)| | |\n|FT-Transformer|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.973 (0.972, 0.974)|0.962 (0.961, 0.962)| | |\n|Label Group DRO|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.947 (0.946, 0.948)|0.926 (0.925, 0.927)| | |\n|LightGBM|0.988 (0.987, 0.989)|0.928 (0.926, 0.929)|0.973 (0.972, 0.974)|0.96 (0.96, 0.961)| | |\n|MLP|0.988 (0.987, 0.989)|0.925 (0.923, 0.926)|0.973 (0.972, 0.973)|0.96 (0.959, 0.961)| | |\n|NODE|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.973 (0.972, 0.974)|0.962 (0.961, 0.963)| | |\n|ResNet|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.972 (0.971, 0.972)|0.959 (0.958, 0.96)| | |\n|SAINT|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.973 (0.972, 0.974)|0.962 (0.961, 0.963)| | |\n|TabTransformer|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.972 (0.971, 0.973)|0.961 (0.96, 0.962)| | |\n|XGBoost|0.988 (0.987, 0.989)|0.925 (0.923, 0.926)|0.973 (0.972, 0.973)|0.961 (0.961, 0.962)| | |\n|CORAL|\u22c6|\u22c6|0.964 (0.963, 0.965)|0.95 (0.949, 0.951)| | |\n|DANN|\u22c6|\u22c6|0.966 (0.965, 0.967)|0.948 (0.947, 0.95)| | |\n|Group DRO|\u22c6|\u22c6|0.971 (0.97, 0.972)|0.958 (0.957, 0.959)| | |\n|IRM|\u22c6|\u22c6|0.966 (0.965, 0.967)|0.948 (0.947, 0.95)| | |\n|MMD|\u22c6|\u22c6|0.966 (0.966, 0.967)|0.953 (0.952, 0.954)| | |\n|MixUp|\u22c6|\u22c6|0.844 (0.842, 0.846)|0.776 (0.774, 0.778)| | |\n|VREX|\u22c6|\u22c6|0.873 (0.871, 0.874)|0.8 (0.798, 0.802)| | |", "images": [], "items": [{"type": "table", "rows": [["Estimator", "Income", "", "", "Public Health Ins.", "", ""], ["", "ID Acc. (95% CI)", "", "OOD Acc. (95% CI)", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", ""], ["Adv. Label DRO", "0.829 (0.827, 0.83)", "0.819 (0.816, 0.822)", "\u25a1", "\u25a1", "\u25a1", "\u25a1"], ["CatBoost", "0.832 (0.83, 0.834)", "0.814 (0.811, 0.817)", "0.814 (0.812, 0.815)", "0.69 (0.689, 0.691)", "", ""], ["", "", "", "DRO", "0.828 (0.826, 0.83)", "0.818 (0.816, 0.821)", "0.809 (0.808, 0.81)", "0.647 (0.646, 0.648)"], ["FT-Transformer", "0.825 (0.823, 0.827)", "0.818 (0.815, 0.821)", "0.807 (0.806, 0.808)", "0.662 (0.661, 0.663)", "", ""], ["Label Group DRO", "0.819 (0.817, 0.821)", "0.818 (0.815, 0.821)", "0.776 (0.775, 0.777)", "0.364 (0.363, 0.365)", "", ""], ["LightGBM", "0.822 (0.82, 0.824)", "0.809 (0.806, 0.812)", "0.803 (0.802, 0.804)", "0.639 (0.638, 0.64)", "", ""], ["MLP", "0.828 (0.826, 0.829)", "0.813 (0.81, 0.816)", "0.808 (0.806, 0.809)", "0.612 (0.611, 0.613)", "", ""], ["NODE", "0.831 (0.829, 0.833)", "0.81 (0.807, 0.813)", "0.811 (0.81, 0.812)", "0.662 (0.661, 0.663)", "", ""], ["ResNet", "0.826 (0.824, 0.828)", "0.815 (0.812, 0.818)", "0.81 (0.809, 0.811)", "0.672 (0.671, 0.673)", "", ""], ["SAINT", "0.829 (0.827, 0.831)", "0.81 (0.807, 0.812)", "0.811 (0.81, 0.812)", "0.68 (0.679, 0.681)", "", ""], ["TabTransformer", "0.818 (0.816, 0.82)", "0.801 (0.798, 0.804)", "0.803 (0.802, 0.804)", "0.588 (0.587, 0.589)", "", ""], ["XGBoost", "0.821 (0.819, 0.823)", "0.792 (0.789, 0.795)", "0.805 (0.804, 0.806)", "0.661 (0.66, 0.662)", "", ""], ["CORAL", "0.817 (0.815, 0.819)", "0.791 (0.788, 0.793)", "\u22c6", "\u22c6", "\u22c6", "\u22c6"], ["DANN", "0.815 (0.813, 0.817)", "0.812 (0.809, 0.815)", "\u22c6", "\u22c6", "\u22c6", "\u22c6"], ["Group DRO", "0.827 (0.826, 0.829)", "0.813 (0.81, 0.815)", "\u22c6", "\u22c6", "\u22c6", "\u22c6"], ["IRM", "0.756 (0.754, 0.758)", "0.699 (0.696, 0.702)", "\u22c6", "\u22c6", "\u22c6", "\u22c6"], ["MMD", "0.816 (0.814, 0.818)", "0.768 (0.765, 0.771)", "\u22c6", "\u22c6", "\u22c6", "\u22c6"], ["MixUp", "0.821 (0.819, 0.823)", "0.794 (0.791, 0.797)", "\u22c6", "\u22c6", "\u22c6", "\u22c6"], ["VREX", "0.714 (0.712, 0.716)", "0.64 (0.637, 0.644)", "\u22c6", "\u22c6", "\u22c6", "\u22c6"]], "md": "|Estimator|Income| | |Public Health Ins.| | |\n|---|---|---|---|---|---|---|\n| |ID Acc. (95% CI)| |OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)| |\n|Adv. Label DRO|0.829 (0.827, 0.83)|0.819 (0.816, 0.822)|\u25a1|\u25a1|\u25a1|\u25a1|\n|CatBoost|0.832 (0.83, 0.834)|0.814 (0.811, 0.817)|0.814 (0.812, 0.815)|0.69 (0.689, 0.691)| | |\n| | | |DRO|0.828 (0.826, 0.83)|0.818 (0.816, 0.821)|0.809 (0.808, 0.81)|0.647 (0.646, 0.648)|\n|FT-Transformer|0.825 (0.823, 0.827)|0.818 (0.815, 0.821)|0.807 (0.806, 0.808)|0.662 (0.661, 0.663)| | |\n|Label Group DRO|0.819 (0.817, 0.821)|0.818 (0.815, 0.821)|0.776 (0.775, 0.777)|0.364 (0.363, 0.365)| | |\n|LightGBM|0.822 (0.82, 0.824)|0.809 (0.806, 0.812)|0.803 (0.802, 0.804)|0.639 (0.638, 0.64)| | |\n|MLP|0.828 (0.826, 0.829)|0.813 (0.81, 0.816)|0.808 (0.806, 0.809)|0.612 (0.611, 0.613)| | |\n|NODE|0.831 (0.829, 0.833)|0.81 (0.807, 0.813)|0.811 (0.81, 0.812)|0.662 (0.661, 0.663)| | |\n|ResNet|0.826 (0.824, 0.828)|0.815 (0.812, 0.818)|0.81 (0.809, 0.811)|0.672 (0.671, 0.673)| | |\n|SAINT|0.829 (0.827, 0.831)|0.81 (0.807, 0.812)|0.811 (0.81, 0.812)|0.68 (0.679, 0.681)| | |\n|TabTransformer|0.818 (0.816, 0.82)|0.801 (0.798, 0.804)|0.803 (0.802, 0.804)|0.588 (0.587, 0.589)| | |\n|XGBoost|0.821 (0.819, 0.823)|0.792 (0.789, 0.795)|0.805 (0.804, 0.806)|0.661 (0.66, 0.662)| | |\n|CORAL|0.817 (0.815, 0.819)|0.791 (0.788, 0.793)|\u22c6|\u22c6|\u22c6|\u22c6|\n|DANN|0.815 (0.813, 0.817)|0.812 (0.809, 0.815)|\u22c6|\u22c6|\u22c6|\u22c6|\n|Group DRO|0.827 (0.826, 0.829)|0.813 (0.81, 0.815)|\u22c6|\u22c6|\u22c6|\u22c6|\n|IRM|0.756 (0.754, 0.758)|0.699 (0.696, 0.702)|\u22c6|\u22c6|\u22c6|\u22c6|\n|MMD|0.816 (0.814, 0.818)|0.768 (0.765, 0.771)|\u22c6|\u22c6|\u22c6|\u22c6|\n|MixUp|0.821 (0.819, 0.823)|0.794 (0.791, 0.797)|\u22c6|\u22c6|\u22c6|\u22c6|\n|VREX|0.714 (0.712, 0.716)|0.64 (0.637, 0.644)|\u22c6|\u22c6|\u22c6|\u22c6|", "isPerfectTable": false, "csv": "\"Estimator\",\"Income\",\"\",\"\",\"Public Health Ins.\",\"\",\"\"\n\"\",\"ID Acc. (95% CI)\",\"\",\"OOD Acc. (95% CI)\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"\"\n\"Adv. Label DRO\",\"0.829 (0.827, 0.83)\",\"0.819 (0.816, 0.822)\",\"\u25a1\",\"\u25a1\",\"\u25a1\",\"\u25a1\"\n\"CatBoost\",\"0.832 (0.83, 0.834)\",\"0.814 (0.811, 0.817)\",\"0.814 (0.812, 0.815)\",\"0.69 (0.689, 0.691)\",\"\",\"\"\n\"\",\"\",\"\",\"DRO\",\"0.828 (0.826, 0.83)\",\"0.818 (0.816, 0.821)\",\"0.809 (0.808, 0.81)\",\"0.647 (0.646, 0.648)\"\n\"FT-Transformer\",\"0.825 (0.823, 0.827)\",\"0.818 (0.815, 0.821)\",\"0.807 (0.806, 0.808)\",\"0.662 (0.661, 0.663)\",\"\",\"\"\n\"Label Group DRO\",\"0.819 (0.817, 0.821)\",\"0.818 (0.815, 0.821)\",\"0.776 (0.775, 0.777)\",\"0.364 (0.363, 0.365)\",\"\",\"\"\n\"LightGBM\",\"0.822 (0.82, 0.824)\",\"0.809 (0.806, 0.812)\",\"0.803 (0.802, 0.804)\",\"0.639 (0.638, 0.64)\",\"\",\"\"\n\"MLP\",\"0.828 (0.826, 0.829)\",\"0.813 (0.81, 0.816)\",\"0.808 (0.806, 0.809)\",\"0.612 (0.611, 0.613)\",\"\",\"\"\n\"NODE\",\"0.831 (0.829, 0.833)\",\"0.81 (0.807, 0.813)\",\"0.811 (0.81, 0.812)\",\"0.662 (0.661, 0.663)\",\"\",\"\"\n\"ResNet\",\"0.826 (0.824, 0.828)\",\"0.815 (0.812, 0.818)\",\"0.81 (0.809, 0.811)\",\"0.672 (0.671, 0.673)\",\"\",\"\"\n\"SAINT\",\"0.829 (0.827, 0.831)\",\"0.81 (0.807, 0.812)\",\"0.811 (0.81, 0.812)\",\"0.68 (0.679, 0.681)\",\"\",\"\"\n\"TabTransformer\",\"0.818 (0.816, 0.82)\",\"0.801 (0.798, 0.804)\",\"0.803 (0.802, 0.804)\",\"0.588 (0.587, 0.589)\",\"\",\"\"\n\"XGBoost\",\"0.821 (0.819, 0.823)\",\"0.792 (0.789, 0.795)\",\"0.805 (0.804, 0.806)\",\"0.661 (0.66, 0.662)\",\"\",\"\"\n\"CORAL\",\"0.817 (0.815, 0.819)\",\"0.791 (0.788, 0.793)\",\"\u22c6\",\"\u22c6\",\"\u22c6\",\"\u22c6\"\n\"DANN\",\"0.815 (0.813, 0.817)\",\"0.812 (0.809, 0.815)\",\"\u22c6\",\"\u22c6\",\"\u22c6\",\"\u22c6\"\n\"Group DRO\",\"0.827 (0.826, 0.829)\",\"0.813 (0.81, 0.815)\",\"\u22c6\",\"\u22c6\",\"\u22c6\",\"\u22c6\"\n\"IRM\",\"0.756 (0.754, 0.758)\",\"0.699 (0.696, 0.702)\",\"\u22c6\",\"\u22c6\",\"\u22c6\",\"\u22c6\"\n\"MMD\",\"0.816 (0.814, 0.818)\",\"0.768 (0.765, 0.771)\",\"\u22c6\",\"\u22c6\",\"\u22c6\",\"\u22c6\"\n\"MixUp\",\"0.821 (0.819, 0.823)\",\"0.794 (0.791, 0.797)\",\"\u22c6\",\"\u22c6\",\"\u22c6\",\"\u22c6\"\n\"VREX\",\"0.714 (0.712, 0.716)\",\"0.64 (0.637, 0.644)\",\"\u22c6\",\"\u22c6\",\"\u22c6\",\"\u22c6\""}, {"type": "table", "rows": [["Estimator", "Sepsis", "", "", "Unemployment", "", ""], ["", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "ID Acc. (95% CI)", "OOD Acc. (95% CI)", "", ""], ["Adv. Label DRO", "0.988 (0.987, 0.989)", "0.925 (0.924, 0.926)", "0.972 (0.971, 0.973)", "0.96 (0.959, 0.961)", "", ""], ["CatBoost", "0.988 (0.987, 0.989)", "0.925 (0.923, 0.926)", "0.973 (0.973, 0.974)", "0.962 (0.961, 0.963)", "", ""], ["DRO", "0.988 (0.987, 0.989)", "0.925 (0.924, 0.926)", "0.973 (0.972, 0.973)", "0.961 (0.96, 0.962)", "", ""], ["FT-Transformer", "0.988 (0.987, 0.989)", "0.925 (0.924, 0.926)", "0.973 (0.972, 0.974)", "0.962 (0.961, 0.962)", "", ""], ["Label Group DRO", "0.988 (0.987, 0.989)", "0.925 (0.924, 0.926)", "0.947 (0.946, 0.948)", "0.926 (0.925, 0.927)", "", ""], ["LightGBM", "0.988 (0.987, 0.989)", "0.928 (0.926, 0.929)", "0.973 (0.972, 0.974)", "0.96 (0.96, 0.961)", "", ""], ["MLP", "0.988 (0.987, 0.989)", "0.925 (0.923, 0.926)", "0.973 (0.972, 0.973)", "0.96 (0.959, 0.961)", "", ""], ["NODE", "0.988 (0.987, 0.989)", "0.925 (0.924, 0.926)", "0.973 (0.972, 0.974)", "0.962 (0.961, 0.963)", "", ""], ["ResNet", "0.988 (0.987, 0.989)", "0.925 (0.924, 0.926)", "0.972 (0.971, 0.972)", "0.959 (0.958, 0.96)", "", ""], ["SAINT", "0.988 (0.987, 0.989)", "0.925 (0.924, 0.926)", "0.973 (0.972, 0.974)", "0.962 (0.961, 0.963)", "", ""], ["TabTransformer", "0.988 (0.987, 0.989)", "0.925 (0.924, 0.926)", "0.972 (0.971, 0.973)", "0.961 (0.96, 0.962)", "", ""], ["XGBoost", "0.988 (0.987, 0.989)", "0.925 (0.923, 0.926)", "0.973 (0.972, 0.973)", "0.961 (0.961, 0.962)", "", ""], ["CORAL", "\u22c6", "\u22c6", "0.964 (0.963, 0.965)", "0.95 (0.949, 0.951)", "", ""], ["DANN", "\u22c6", "\u22c6", "0.966 (0.965, 0.967)", "0.948 (0.947, 0.95)", "", ""], ["Group DRO", "\u22c6", "\u22c6", "0.971 (0.97, 0.972)", "0.958 (0.957, 0.959)", "", ""], ["IRM", "\u22c6", "\u22c6", "0.966 (0.965, 0.967)", "0.948 (0.947, 0.95)", "", ""], ["MMD", "\u22c6", "\u22c6", "0.966 (0.966, 0.967)", "0.953 (0.952, 0.954)", "", ""], ["MixUp", "\u22c6", "\u22c6", "0.844 (0.842, 0.846)", "0.776 (0.774, 0.778)", "", ""], ["VREX", "\u22c6", "\u22c6", "0.873 (0.871, 0.874)", "0.8 (0.798, 0.802)", "", ""]], "md": "|Estimator|Sepsis| | |Unemployment| | |\n|---|---|---|---|---|---|---|\n| |ID Acc. (95% CI)|OOD Acc. (95% CI)|ID Acc. (95% CI)|OOD Acc. (95% CI)| | |\n|Adv. Label DRO|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.972 (0.971, 0.973)|0.96 (0.959, 0.961)| | |\n|CatBoost|0.988 (0.987, 0.989)|0.925 (0.923, 0.926)|0.973 (0.973, 0.974)|0.962 (0.961, 0.963)| | |\n|DRO|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.973 (0.972, 0.973)|0.961 (0.96, 0.962)| | |\n|FT-Transformer|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.973 (0.972, 0.974)|0.962 (0.961, 0.962)| | |\n|Label Group DRO|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.947 (0.946, 0.948)|0.926 (0.925, 0.927)| | |\n|LightGBM|0.988 (0.987, 0.989)|0.928 (0.926, 0.929)|0.973 (0.972, 0.974)|0.96 (0.96, 0.961)| | |\n|MLP|0.988 (0.987, 0.989)|0.925 (0.923, 0.926)|0.973 (0.972, 0.973)|0.96 (0.959, 0.961)| | |\n|NODE|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.973 (0.972, 0.974)|0.962 (0.961, 0.963)| | |\n|ResNet|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.972 (0.971, 0.972)|0.959 (0.958, 0.96)| | |\n|SAINT|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.973 (0.972, 0.974)|0.962 (0.961, 0.963)| | |\n|TabTransformer|0.988 (0.987, 0.989)|0.925 (0.924, 0.926)|0.972 (0.971, 0.973)|0.961 (0.96, 0.962)| | |\n|XGBoost|0.988 (0.987, 0.989)|0.925 (0.923, 0.926)|0.973 (0.972, 0.973)|0.961 (0.961, 0.962)| | |\n|CORAL|\u22c6|\u22c6|0.964 (0.963, 0.965)|0.95 (0.949, 0.951)| | |\n|DANN|\u22c6|\u22c6|0.966 (0.965, 0.967)|0.948 (0.947, 0.95)| | |\n|Group DRO|\u22c6|\u22c6|0.971 (0.97, 0.972)|0.958 (0.957, 0.959)| | |\n|IRM|\u22c6|\u22c6|0.966 (0.965, 0.967)|0.948 (0.947, 0.95)| | |\n|MMD|\u22c6|\u22c6|0.966 (0.966, 0.967)|0.953 (0.952, 0.954)| | |\n|MixUp|\u22c6|\u22c6|0.844 (0.842, 0.846)|0.776 (0.774, 0.778)| | |\n|VREX|\u22c6|\u22c6|0.873 (0.871, 0.874)|0.8 (0.798, 0.802)| | |", "isPerfectTable": true, "csv": "\"Estimator\",\"Sepsis\",\"\",\"\",\"Unemployment\",\"\",\"\"\n\"\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\",\"\",\"\"\n\"Adv. Label DRO\",\"0.988 (0.987, 0.989)\",\"0.925 (0.924, 0.926)\",\"0.972 (0.971, 0.973)\",\"0.96 (0.959, 0.961)\",\"\",\"\"\n\"CatBoost\",\"0.988 (0.987, 0.989)\",\"0.925 (0.923, 0.926)\",\"0.973 (0.973, 0.974)\",\"0.962 (0.961, 0.963)\",\"\",\"\"\n\"DRO\",\"0.988 (0.987, 0.989)\",\"0.925 (0.924, 0.926)\",\"0.973 (0.972, 0.973)\",\"0.961 (0.96, 0.962)\",\"\",\"\"\n\"FT-Transformer\",\"0.988 (0.987, 0.989)\",\"0.925 (0.924, 0.926)\",\"0.973 (0.972, 0.974)\",\"0.962 (0.961, 0.962)\",\"\",\"\"\n\"Label Group DRO\",\"0.988 (0.987, 0.989)\",\"0.925 (0.924, 0.926)\",\"0.947 (0.946, 0.948)\",\"0.926 (0.925, 0.927)\",\"\",\"\"\n\"LightGBM\",\"0.988 (0.987, 0.989)\",\"0.928 (0.926, 0.929)\",\"0.973 (0.972, 0.974)\",\"0.96 (0.96, 0.961)\",\"\",\"\"\n\"MLP\",\"0.988 (0.987, 0.989)\",\"0.925 (0.923, 0.926)\",\"0.973 (0.972, 0.973)\",\"0.96 (0.959, 0.961)\",\"\",\"\"\n\"NODE\",\"0.988 (0.987, 0.989)\",\"0.925 (0.924, 0.926)\",\"0.973 (0.972, 0.974)\",\"0.962 (0.961, 0.963)\",\"\",\"\"\n\"ResNet\",\"0.988 (0.987, 0.989)\",\"0.925 (0.924, 0.926)\",\"0.972 (0.971, 0.972)\",\"0.959 (0.958, 0.96)\",\"\",\"\"\n\"SAINT\",\"0.988 (0.987, 0.989)\",\"0.925 (0.924, 0.926)\",\"0.973 (0.972, 0.974)\",\"0.962 (0.961, 0.963)\",\"\",\"\"\n\"TabTransformer\",\"0.988 (0.987, 0.989)\",\"0.925 (0.924, 0.926)\",\"0.972 (0.971, 0.973)\",\"0.961 (0.96, 0.962)\",\"\",\"\"\n\"XGBoost\",\"0.988 (0.987, 0.989)\",\"0.925 (0.923, 0.926)\",\"0.973 (0.972, 0.973)\",\"0.961 (0.961, 0.962)\",\"\",\"\"\n\"CORAL\",\"\u22c6\",\"\u22c6\",\"0.964 (0.963, 0.965)\",\"0.95 (0.949, 0.951)\",\"\",\"\"\n\"DANN\",\"\u22c6\",\"\u22c6\",\"0.966 (0.965, 0.967)\",\"0.948 (0.947, 0.95)\",\"\",\"\"\n\"Group DRO\",\"\u22c6\",\"\u22c6\",\"0.971 (0.97, 0.972)\",\"0.958 (0.957, 0.959)\",\"\",\"\"\n\"IRM\",\"\u22c6\",\"\u22c6\",\"0.966 (0.965, 0.967)\",\"0.948 (0.947, 0.95)\",\"\",\"\"\n\"MMD\",\"\u22c6\",\"\u22c6\",\"0.966 (0.966, 0.967)\",\"0.953 (0.952, 0.954)\",\"\",\"\"\n\"MixUp\",\"\u22c6\",\"\u22c6\",\"0.844 (0.842, 0.846)\",\"0.776 (0.774, 0.778)\",\"\",\"\"\n\"VREX\",\"\u22c6\",\"\u22c6\",\"0.873 (0.871, 0.874)\",\"0.8 (0.798, 0.802)\",\"\",\"\""}]}, {"page": 35, "text": "      Table 11: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark\n      task. See also Figures 1, 2,3.\n                  Estimator                                   Voting\n                                          ID Acc. (95% CI)          OOD Acc. (95% CI)\n                  Adv. Label DRO        0.875    (0.843, 0.902)    0.852    (0.839, 0.865)\n                  CatBoost              0.883    (0.852, 0.909)    0.855    (0.842, 0.868)\n                  DRO                   0.881    (0.85, 0.907)     0.853    (0.839, 0.866)\n                  FT-Transformer        0.879    (0.848, 0.906)    0.855    (0.841, 0.868)\n                  Label Group DRO       0.862    (0.829, 0.89)     0.839    (0.825, 0.852)\n                  LightGBM              0.881    (0.85, 0.907)     0.855    (0.841, 0.868)\n                  MLP                   0.892    (0.862, 0.918)    0.86     (0.847, 0.873)\n                  NODE                  0.885    (0.854, 0.911)    0.851    (0.838, 0.864)\n                  ResNet                0.887    (0.856, 0.912)    0.836    (0.822, 0.849)\n                  SAINT                 0.888    (0.858, 0.914)    0.858    (0.845, 0.871)\n                  TabTransformer        0.877    (0.846, 0.904)    0.859    (0.845, 0.872)\n                  XGBoost               0.898    (0.869, 0.923)    0.851    (0.838, 0.864)\n                  CORAL                 0.883    (0.852, 0.909)    0.846    (0.832, 0.859)\n                  DANN                  0.892    (0.862, 0.918)    0.852    (0.838, 0.865)\n                  Group DRO             0.877    (0.846, 0.904)    0.852    (0.839, 0.865)\n                  IRM                   0.804    (0.767, 0.837)    0.758    (0.742, 0.774)\n                  MMD                   0.892    (0.862, 0.918)    0.849    (0.835, 0.862)\n                  MixUp                 0.892    (0.862, 0.918)    0.851    (0.837, 0.864)\n                  VREX                  0.804    (0.767, 0.837)    0.754    (0.737, 0.77)\n      Table 12: Sample sizes by split. In particular, large test sizes are desirable for benchmarking, as they\n      reduce the statistical uncertainty of comparing model performance.\nTask                           ID Test       OOD Test      OOD Validation           Train       Validation        Total\nFood Stamps                       78,628         48,878              5431           629,018         78,627        840,582\nIncome                           158,016         75,911              8435         1,264,123        158,015      1,664,500\nPublic Coverage                  500,782        817,877            90,876         4,006,249        500,781      5,916,565\nUnemployment                     161,365        163,611            18,180         1,290,914        161,364      1,795,434\nVoting                               520           2772                309             4159             520           8280\nHypertension                      27,052        518,622            57,625           216,411         27,051        846,761\nDiabetes                         121,154        209,375            23,264           969,229        121,154      1,444,176\nReadmission                         4287         50,968              5664            34,288           4286         99,493\nHELOC                                278           6914                769             2220             278        10,459\nICU Length of Stay                  1080         11,835              1316              8634           1079         23,944\nICU Hospital Mortality               890         13,544              1505              7116             889        23,944\nSepsis                           140,288        134,402            14,934         1,122,299        140,287      1,552,210\nChildhood Lead                      1476         11,466              1274            11,807           1476         27,499\nASSISTments                      266,566           1906                212        2,132,526        266,566      2,667,776\nCollege Scorecard                 12,320           1352                151           98,556         12,320        124,699\n                                                        35", "md": "table {\nwidth: 100%;\nborder-collapse: collapse;\n}\ntable, th, td {\nborder: 1px solid black;\n}\nth, td {\npadding: 8px;\ntext-align: left;\n}\nth {\nbackground-color: #f2f2f2;\n}\n\n## Table 11: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task\n\n|Estimator|Voting|ID Acc. (95% CI)|OOD Acc. (95% CI)|\n|---|---|---|---|\n|Adv. Label DRO|Voting|$0.875 \\ (0.843, 0.902)$|$0.852 \\ (0.839, 0.865)$|\n|CatBoost|Voting|$0.883 \\ (0.852, 0.909)$|$0.855 \\ (0.842, 0.868)$|\n|DRO|Voting|$0.881 \\ (0.85, 0.907)$|$0.853 \\ (0.839, 0.866)$|\n|FT-Transformer|Voting|$0.879 \\ (0.848, 0.906)$|$0.855 \\ (0.841, 0.868)$|\n|Label Group DRO|Voting|$0.862 \\ (0.829, 0.89)$|$0.839 \\ (0.825, 0.852)$|\n|LightGBM|Voting|$0.881 \\ (0.85, 0.907)$|$0.855 \\ (0.841, 0.868)$|\n|MLP|Voting|$0.892 \\ (0.862, 0.918)$|$0.86 \\ (0.847, 0.873)$|\n|NODE|Voting|$0.885 \\ (0.854, 0.911)$|$0.851 \\ (0.838, 0.864)$|\n|ResNet|Voting|$0.887 \\ (0.856, 0.912)$|$0.836 \\ (0.822, 0.849)$|\n|SAINT|Voting|$0.888 \\ (0.858, 0.914)$|$0.858 \\ (0.845, 0.871)$|\n|TabTransformer|Voting|$0.877 \\ (0.846, 0.904)$|$0.859 \\ (0.845, 0.872)$|\n|XGBoost|Voting|$0.898 \\ (0.869, 0.923)$|$0.851 \\ (0.838, 0.864)$|\n|CORAL|Voting|$0.883 \\ (0.852, 0.909)$|$0.846 \\ (0.832, 0.859)$|\n|DANN|Voting|$0.892 \\ (0.862, 0.918)$|$0.852 \\ (0.838, 0.865)$|\n|Group DRO|Voting|$0.877 \\ (0.846, 0.904)$|$0.852 \\ (0.839, 0.865)$|\n|IRM|Voting|$0.804 \\ (0.767, 0.837)$|$0.758 \\ (0.742, 0.774)$|\n|MMD|Voting|$0.892 \\ (0.862, 0.918)$|$0.849 \\ (0.835, 0.862)$|\n|MixUp|Voting|$0.892 \\ (0.862, 0.918)$|$0.851 \\ (0.837, 0.864)$|\n|VREX|Voting|$0.804 \\ (0.767, 0.837)$|$0.754 \\ (0.737, 0.77)$|\n\n## Table 12: Sample sizes by split\n\n|Task|ID Test|OOD Test|OOD Validation|Train|Validation|Total|\n|---|---|---|---|---|---|---|\n|Food Stamps|78,628|48,878|5,431|629,018|78,627|840,582|\n|Income|158,016|75,911|8,435|1,264,123|158,015|1,664,500|\n|Public Coverage|500,782|817,877|90,876|4,006,249|500,781|5,916,565|\n|Unemployment|161,365|163,611|18,180|1,290,914|161,364|1,795,434|\n|Voting|520|2,772|309|4,159|520|8,280|\n|Hypertension|27,052|518,622|57,625|216,411|27,051|846,761|\n|Diabetes|121,154|209,375|23,264|969,229|121,154|1,444,176|\n|Readmission|4,287|50,968|5,664|34,288|4,286|99,493|\n|HELOC|278|6,914|769|2,220|278|10,459|\n|ICU Length of Stay|1,080|11,835|1,316|8,634|1,079|23,944|\n|ICU Hospital Mortality|890|13,544|1,505|7,116|889|23,944|\n|Sepsis|140,288|134,402|14,934|1,122,299|140,287|1,552,210|\n|Childhood Lead|1,476|11,466|1,274|11,807|1,476|27,499|\n|ASSISTments|266,566|1,906|212|2,132,526|266,566|2,667,776|\n|College Scorecard|12,320|1,352|151|98,556|12,320|124,699|", "images": [], "items": [{"type": "text", "value": "table {\nwidth: 100%;\nborder-collapse: collapse;\n}\ntable, th, td {\nborder: 1px solid black;\n}\nth, td {\npadding: 8px;\ntext-align: left;\n}\nth {\nbackground-color: #f2f2f2;\n}", "md": "table {\nwidth: 100%;\nborder-collapse: collapse;\n}\ntable, th, td {\nborder: 1px solid black;\n}\nth, td {\npadding: 8px;\ntext-align: left;\n}\nth {\nbackground-color: #f2f2f2;\n}"}, {"type": "heading", "lvl": 2, "value": "Table 11: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task", "md": "## Table 11: Best (In-Distribution and Out-Of-Distribution) accuracy pair observed on each benchmark task"}, {"type": "table", "rows": [["Estimator", "Voting", "ID Acc. (95% CI)", "OOD Acc. (95% CI)"], ["Adv. Label DRO", "Voting", "$0.875 \\ (0.843, 0.902)$", "$0.852 \\ (0.839, 0.865)$"], ["CatBoost", "Voting", "$0.883 \\ (0.852, 0.909)$", "$0.855 \\ (0.842, 0.868)$"], ["DRO", "Voting", "$0.881 \\ (0.85, 0.907)$", "$0.853 \\ (0.839, 0.866)$"], ["FT-Transformer", "Voting", "$0.879 \\ (0.848, 0.906)$", "$0.855 \\ (0.841, 0.868)$"], ["Label Group DRO", "Voting", "$0.862 \\ (0.829, 0.89)$", "$0.839 \\ (0.825, 0.852)$"], ["LightGBM", "Voting", "$0.881 \\ (0.85, 0.907)$", "$0.855 \\ (0.841, 0.868)$"], ["MLP", "Voting", "$0.892 \\ (0.862, 0.918)$", "$0.86 \\ (0.847, 0.873)$"], ["NODE", "Voting", "$0.885 \\ (0.854, 0.911)$", "$0.851 \\ (0.838, 0.864)$"], ["ResNet", "Voting", "$0.887 \\ (0.856, 0.912)$", "$0.836 \\ (0.822, 0.849)$"], ["SAINT", "Voting", "$0.888 \\ (0.858, 0.914)$", "$0.858 \\ (0.845, 0.871)$"], ["TabTransformer", "Voting", "$0.877 \\ (0.846, 0.904)$", "$0.859 \\ (0.845, 0.872)$"], ["XGBoost", "Voting", "$0.898 \\ (0.869, 0.923)$", "$0.851 \\ (0.838, 0.864)$"], ["CORAL", "Voting", "$0.883 \\ (0.852, 0.909)$", "$0.846 \\ (0.832, 0.859)$"], ["DANN", "Voting", "$0.892 \\ (0.862, 0.918)$", "$0.852 \\ (0.838, 0.865)$"], ["Group DRO", "Voting", "$0.877 \\ (0.846, 0.904)$", "$0.852 \\ (0.839, 0.865)$"], ["IRM", "Voting", "$0.804 \\ (0.767, 0.837)$", "$0.758 \\ (0.742, 0.774)$"], ["MMD", "Voting", "$0.892 \\ (0.862, 0.918)$", "$0.849 \\ (0.835, 0.862)$"], ["MixUp", "Voting", "$0.892 \\ (0.862, 0.918)$", "$0.851 \\ (0.837, 0.864)$"], ["VREX", "Voting", "$0.804 \\ (0.767, 0.837)$", "$0.754 \\ (0.737, 0.77)$"]], "md": "|Estimator|Voting|ID Acc. (95% CI)|OOD Acc. (95% CI)|\n|---|---|---|---|\n|Adv. Label DRO|Voting|$0.875 \\ (0.843, 0.902)$|$0.852 \\ (0.839, 0.865)$|\n|CatBoost|Voting|$0.883 \\ (0.852, 0.909)$|$0.855 \\ (0.842, 0.868)$|\n|DRO|Voting|$0.881 \\ (0.85, 0.907)$|$0.853 \\ (0.839, 0.866)$|\n|FT-Transformer|Voting|$0.879 \\ (0.848, 0.906)$|$0.855 \\ (0.841, 0.868)$|\n|Label Group DRO|Voting|$0.862 \\ (0.829, 0.89)$|$0.839 \\ (0.825, 0.852)$|\n|LightGBM|Voting|$0.881 \\ (0.85, 0.907)$|$0.855 \\ (0.841, 0.868)$|\n|MLP|Voting|$0.892 \\ (0.862, 0.918)$|$0.86 \\ (0.847, 0.873)$|\n|NODE|Voting|$0.885 \\ (0.854, 0.911)$|$0.851 \\ (0.838, 0.864)$|\n|ResNet|Voting|$0.887 \\ (0.856, 0.912)$|$0.836 \\ (0.822, 0.849)$|\n|SAINT|Voting|$0.888 \\ (0.858, 0.914)$|$0.858 \\ (0.845, 0.871)$|\n|TabTransformer|Voting|$0.877 \\ (0.846, 0.904)$|$0.859 \\ (0.845, 0.872)$|\n|XGBoost|Voting|$0.898 \\ (0.869, 0.923)$|$0.851 \\ (0.838, 0.864)$|\n|CORAL|Voting|$0.883 \\ (0.852, 0.909)$|$0.846 \\ (0.832, 0.859)$|\n|DANN|Voting|$0.892 \\ (0.862, 0.918)$|$0.852 \\ (0.838, 0.865)$|\n|Group DRO|Voting|$0.877 \\ (0.846, 0.904)$|$0.852 \\ (0.839, 0.865)$|\n|IRM|Voting|$0.804 \\ (0.767, 0.837)$|$0.758 \\ (0.742, 0.774)$|\n|MMD|Voting|$0.892 \\ (0.862, 0.918)$|$0.849 \\ (0.835, 0.862)$|\n|MixUp|Voting|$0.892 \\ (0.862, 0.918)$|$0.851 \\ (0.837, 0.864)$|\n|VREX|Voting|$0.804 \\ (0.767, 0.837)$|$0.754 \\ (0.737, 0.77)$|", "isPerfectTable": true, "csv": "\"Estimator\",\"Voting\",\"ID Acc. (95% CI)\",\"OOD Acc. (95% CI)\"\n\"Adv. Label DRO\",\"Voting\",\"$0.875 \\ (0.843, 0.902)$\",\"$0.852 \\ (0.839, 0.865)$\"\n\"CatBoost\",\"Voting\",\"$0.883 \\ (0.852, 0.909)$\",\"$0.855 \\ (0.842, 0.868)$\"\n\"DRO\",\"Voting\",\"$0.881 \\ (0.85, 0.907)$\",\"$0.853 \\ (0.839, 0.866)$\"\n\"FT-Transformer\",\"Voting\",\"$0.879 \\ (0.848, 0.906)$\",\"$0.855 \\ (0.841, 0.868)$\"\n\"Label Group DRO\",\"Voting\",\"$0.862 \\ (0.829, 0.89)$\",\"$0.839 \\ (0.825, 0.852)$\"\n\"LightGBM\",\"Voting\",\"$0.881 \\ (0.85, 0.907)$\",\"$0.855 \\ (0.841, 0.868)$\"\n\"MLP\",\"Voting\",\"$0.892 \\ (0.862, 0.918)$\",\"$0.86 \\ (0.847, 0.873)$\"\n\"NODE\",\"Voting\",\"$0.885 \\ (0.854, 0.911)$\",\"$0.851 \\ (0.838, 0.864)$\"\n\"ResNet\",\"Voting\",\"$0.887 \\ (0.856, 0.912)$\",\"$0.836 \\ (0.822, 0.849)$\"\n\"SAINT\",\"Voting\",\"$0.888 \\ (0.858, 0.914)$\",\"$0.858 \\ (0.845, 0.871)$\"\n\"TabTransformer\",\"Voting\",\"$0.877 \\ (0.846, 0.904)$\",\"$0.859 \\ (0.845, 0.872)$\"\n\"XGBoost\",\"Voting\",\"$0.898 \\ (0.869, 0.923)$\",\"$0.851 \\ (0.838, 0.864)$\"\n\"CORAL\",\"Voting\",\"$0.883 \\ (0.852, 0.909)$\",\"$0.846 \\ (0.832, 0.859)$\"\n\"DANN\",\"Voting\",\"$0.892 \\ (0.862, 0.918)$\",\"$0.852 \\ (0.838, 0.865)$\"\n\"Group DRO\",\"Voting\",\"$0.877 \\ (0.846, 0.904)$\",\"$0.852 \\ (0.839, 0.865)$\"\n\"IRM\",\"Voting\",\"$0.804 \\ (0.767, 0.837)$\",\"$0.758 \\ (0.742, 0.774)$\"\n\"MMD\",\"Voting\",\"$0.892 \\ (0.862, 0.918)$\",\"$0.849 \\ (0.835, 0.862)$\"\n\"MixUp\",\"Voting\",\"$0.892 \\ (0.862, 0.918)$\",\"$0.851 \\ (0.837, 0.864)$\"\n\"VREX\",\"Voting\",\"$0.804 \\ (0.767, 0.837)$\",\"$0.754 \\ (0.737, 0.77)$\""}, {"type": "heading", "lvl": 2, "value": "Table 12: Sample sizes by split", "md": "## Table 12: Sample sizes by split"}, {"type": "table", "rows": [["Task", "ID Test", "OOD Test", "OOD Validation", "Train", "Validation", "Total"], ["Food Stamps", "78,628", "48,878", "5,431", "629,018", "78,627", "840,582"], ["Income", "158,016", "75,911", "8,435", "1,264,123", "158,015", "1,664,500"], ["Public Coverage", "500,782", "817,877", "90,876", "4,006,249", "500,781", "5,916,565"], ["Unemployment", "161,365", "163,611", "18,180", "1,290,914", "161,364", "1,795,434"], ["Voting", "520", "2,772", "309", "4,159", "520", "8,280"], ["Hypertension", "27,052", "518,622", "57,625", "216,411", "27,051", "846,761"], ["Diabetes", "121,154", "209,375", "23,264", "969,229", "121,154", "1,444,176"], ["Readmission", "4,287", "50,968", "5,664", "34,288", "4,286", "99,493"], ["HELOC", "278", "6,914", "769", "2,220", "278", "10,459"], ["ICU Length of Stay", "1,080", "11,835", "1,316", "8,634", "1,079", "23,944"], ["ICU Hospital Mortality", "890", "13,544", "1,505", "7,116", "889", "23,944"], ["Sepsis", "140,288", "134,402", "14,934", "1,122,299", "140,287", "1,552,210"], ["Childhood Lead", "1,476", "11,466", "1,274", "11,807", "1,476", "27,499"], ["ASSISTments", "266,566", "1,906", "212", "2,132,526", "266,566", "2,667,776"], ["College Scorecard", "12,320", "1,352", "151", "98,556", "12,320", "124,699"]], "md": "|Task|ID Test|OOD Test|OOD Validation|Train|Validation|Total|\n|---|---|---|---|---|---|---|\n|Food Stamps|78,628|48,878|5,431|629,018|78,627|840,582|\n|Income|158,016|75,911|8,435|1,264,123|158,015|1,664,500|\n|Public Coverage|500,782|817,877|90,876|4,006,249|500,781|5,916,565|\n|Unemployment|161,365|163,611|18,180|1,290,914|161,364|1,795,434|\n|Voting|520|2,772|309|4,159|520|8,280|\n|Hypertension|27,052|518,622|57,625|216,411|27,051|846,761|\n|Diabetes|121,154|209,375|23,264|969,229|121,154|1,444,176|\n|Readmission|4,287|50,968|5,664|34,288|4,286|99,493|\n|HELOC|278|6,914|769|2,220|278|10,459|\n|ICU Length of Stay|1,080|11,835|1,316|8,634|1,079|23,944|\n|ICU Hospital Mortality|890|13,544|1,505|7,116|889|23,944|\n|Sepsis|140,288|134,402|14,934|1,122,299|140,287|1,552,210|\n|Childhood Lead|1,476|11,466|1,274|11,807|1,476|27,499|\n|ASSISTments|266,566|1,906|212|2,132,526|266,566|2,667,776|\n|College Scorecard|12,320|1,352|151|98,556|12,320|124,699|", "isPerfectTable": true, "csv": "\"Task\",\"ID Test\",\"OOD Test\",\"OOD Validation\",\"Train\",\"Validation\",\"Total\"\n\"Food Stamps\",\"78,628\",\"48,878\",\"5,431\",\"629,018\",\"78,627\",\"840,582\"\n\"Income\",\"158,016\",\"75,911\",\"8,435\",\"1,264,123\",\"158,015\",\"1,664,500\"\n\"Public Coverage\",\"500,782\",\"817,877\",\"90,876\",\"4,006,249\",\"500,781\",\"5,916,565\"\n\"Unemployment\",\"161,365\",\"163,611\",\"18,180\",\"1,290,914\",\"161,364\",\"1,795,434\"\n\"Voting\",\"520\",\"2,772\",\"309\",\"4,159\",\"520\",\"8,280\"\n\"Hypertension\",\"27,052\",\"518,622\",\"57,625\",\"216,411\",\"27,051\",\"846,761\"\n\"Diabetes\",\"121,154\",\"209,375\",\"23,264\",\"969,229\",\"121,154\",\"1,444,176\"\n\"Readmission\",\"4,287\",\"50,968\",\"5,664\",\"34,288\",\"4,286\",\"99,493\"\n\"HELOC\",\"278\",\"6,914\",\"769\",\"2,220\",\"278\",\"10,459\"\n\"ICU Length of Stay\",\"1,080\",\"11,835\",\"1,316\",\"8,634\",\"1,079\",\"23,944\"\n\"ICU Hospital Mortality\",\"890\",\"13,544\",\"1,505\",\"7,116\",\"889\",\"23,944\"\n\"Sepsis\",\"140,288\",\"134,402\",\"14,934\",\"1,122,299\",\"140,287\",\"1,552,210\"\n\"Childhood Lead\",\"1,476\",\"11,466\",\"1,274\",\"11,807\",\"1,476\",\"27,499\"\n\"ASSISTments\",\"266,566\",\"1,906\",\"212\",\"2,132,526\",\"266,566\",\"2,667,776\"\n\"College Scorecard\",\"12,320\",\"1,352\",\"151\",\"98,556\",\"12,320\",\"124,699\""}]}, {"page": 36, "text": " est Accuracy         Model      ASSISTments                                                                  est Accuracy             College Scorecard                                          est Accuracy           Hospital Mortality\n                      XGBoost                                                                                    0.900                Model                                                                            Model\n                                                                                                                                      XGBoost                                                                          XGBoost\n   0.90               LightGBM                                                                                                        LightGBM                                                       0.91              LightGBM\n                      MLP                                                                                                             MLP                                                                              MLP\n                      FT-Transformer                                                                                                                                                                                   FT-Transformer\n                      ResNet                                                                                     0.875                FT-Transformer\n   0.85               SAINT                                                                                                           ResNet                                                                           ResNet\n                      NODE                                                                                                            SAINT                                                                            SAINT\n                      TabTransformer                                                                                                  NODE                                                                             NODE\n                                                                                                                 0.850                TabTransformer                                                 0.90              TabTransformer\n   0.80               CatBoost                                                                                                        CatBoost                                                                         CatBoost\n Out-of-Distribution TDRO                                                                                                             DRO                                                         Out-of-Distribution TDRO\n                      Group DRO                                                                               Out-of-Distribution T   Group DRO                                                                        Group DRO\n   0.75               DANN                                                                                       0.825                DANN                                                                             DANN\n                      IRM                                                                                                             IRM                                                                              IRM\n                      MixUp                                                                                                           MixUp                                                                            MixUp\n                      VREX                                                                                                            VREX                                                           0.89              VREX\n   0.70               MMD                                                                                        0.800                MMD                                                                              MMD\n                      CORAL                                                                                                           CORAL                                                                            CORAL\n                      Label Group DRO                                                                                                 Label Group DRO                                                                  Label Group DRO\n   0.65               Adv. Label DRO                                                                                                  Adv. Label DRO                                                                   Adv. Label DRO\n                      y=x                                                                                        0.775                y=x                                                            0.88              y=x\n   0.60                                                                                                          0.750\n   0.55                                                                                                          0.725                                                                               0.87\n                             0.930                  0.935                  0.940                                                    0.88              0.90         0.92        0.94         0.96                           0.90                   0.92                0.94                 0.96\n                   In-Distribution Test Accuracy                                                                                   In-Distribution Test Accuracy                                                     In-Distribution Test Accuracy\n est Accuracy    Hospital Readmission                                                                         est Accuracy                             Diabetes                                   est Accuracy          ICU Length of Stay\n                      Model                                                                                                         Model                                                            0.68              Model\n                      XGBoost                                                                                                       XGBoost                                                                             XGBoost\n   0.62               LightGBM                                                                                   0.87               LightGBM                                                                            LightGBM\n                      MLP                                                                                                           MLP                                                                                 MLP\n                      FT-Transformer                                                                                                FT-Transformer                                                   0.66               FT-Transformer\n                      ResNet                                                                                                        ResNet                                                                              ResNet\n   0.60               SAINT                                                                                                         SAINT                                                                               SAINT\n                      NODE                                                                                       0.86               NODE                                                                                NODE\n                      TabTransformer                                                                                                TabTransformer                                                   0.64               TabTransformer\n                      CatBoost                                                                                                      CatBoost                                                                            CatBoost\n   0.58               DRO                                                                                                           DRO                                                                                 DRO\n Out-of-Distribution TGroup DRO                                                                               Out-of-Distribution T Group DRO                                                     Out-of-Distribution T Group DRO\n                      DANN                                                                                                          DANN                                                             0.62               DANN\n                      IRM                                                                                        0.85               IRM                                                                                 IRM\n                      MixUp                                                                                                         MixUp                                                                               MixUp\n   0.56               VREX                                                                                                          VREX                                                             0.60               VREX\n                      MMD                                                                                                           MMD                                                                                 MMD\n                      CORAL                                                                                                         CORAL                                                                               CORAL\n                      Label Group DRO                                                                                               Label Group DRO                                                                     Label Group DRO\n   0.54               Adv. Label DRO                                                                             0.84               Adv. Label DRO                                                   0.58               Adv. Label DRO\n                      y=x                                                                                                           y=x                                                                                 y=x\n   0.52                                                                                                          0.83                                                                                0.56\n                                                                                                                                                                                                     0.54\n   0.50\n             0.58                0.60                0.62                0.64                0.66                                     0.872              0.874         0.876        0.878                                         0.60                   0.65               0.70\n                   In-Distribution Test Accuracy                                                                                 In-Distribution Test Accuracy                                                       In-Distribution Test Accuracy\n                                             Voting                                                           est Accuracy                     Food Stamps                                                                     Unemployment\nest Accuracy                                                                                                     0.83               Model                                                         est Accuracy\n                     Model                                                                                                          XGBoost                                                                              Model\n                      XGBoost                                                                                                       LightGBM                                                                             XGBoost\n                      LightGBM                                                                                   0.82               MLP                                                             0.950                LightGBM\n   0.86               MLP                                                                                                           FT-Transformer                                                                       MLP\n                      FT-Transformer                                                                                                ResNet                                                                               FT-Transformer\n                      ResNet\n                      SAINT                                                                                      0.81               SAINT                                                           0.925                ResNet\n   0.84               NODE                                                                                                          NODE                                                                                 SAINT\n                                                                                                                                    TabTransformer                                                                       NODE\n                      TabTransformer                                                                                                CatBoost                                                                             TabTransformer\n                      CatBoost                                                                                   0.80               DRO                                                             0.900                CatBoost\nOut-of-Distribution T DRO                                                                                     Out-of-Distribution T Group DRO                                                                            DRO\n   0.82               Group DRO                                                                                                     DANN                                                          Out-of-Distribution T  Group DRO\n                      DANN                                                                                       0.79               IRM                                                                                  DANN\n                      IRM                                                                                                           MixUp                                                           0.875                IRM\n                      MixUp                                                                                                         VREX                                                                                 MixUp\n   0.80               VREX                                                                                                          MMD                                                                                  VREX\n                      MMD                                                                                        0.78               CORAL                                                           0.850                MMD\n                      CORAL                                                                                                         Label Group DRO                                                                      CORAL\n                      Label Group DRO                                                                                               Adv. Label DRO                                                                       Label Group DRO\n   0.78               Adv. Label DRO                                                                                                                                                                                     Adv. Label DRO\n                      y=x                                                                                        0.77               y=x                                                             0.825                y=x\n   0.76                                                                                                          0.76                                                                               0.800\n   0.74                                                                                                          0.75                                                                               0.775\n                 0.775 0.800 0.825 0.850 0.875 0.900 0.925                                                                              0.78               0.80          0.82         0.84                           0.850          0.875         0.900        0.925        0.950        0.975\n                   In-Distribution Test Accuracy                                                                                 In-Distribution Test Accuracy                                                        In-Distribution Test Accuracy\n                                              Income                                                          est Accuracy                                 HELOC                                  est Accuracy        ModelPublic Coverage\nest Accuracy                                                                                                     0.65              Model                                                                              FT-Transformer\n   0.825                Model                                                                                                       FT-Transformer                                                                    SAINT\n                        XGBoost\n                        LightGBM                                                                                                    SAINT                                                                             CatBoost\n                        MLP                                                                                                         CatBoost                                                                          TabTransformer\n   0.800                FT-Transformer                                                                                              TabTransformer                                                   0.7              DRO\n                        ResNet                                                                                   0.60               DRO                                                                               ResNet\n                        SAINT                                                                                                       ResNet                                                                            Label Group DRO\n   0.775                NODE                                                                                                        Label Group DRO                                                                   LightGBM\n                        TabTransformer                                                                                              LightGBM                                                                          Group DRO\n                        CatBoost                                                                                                    Group DRO                                                                         NODE\n                                                                                                                                    NODE                                                          Out-of-Distribution T\nOut-of-Distribution T   DRO                                                                                   Out-of-Distribution T MLP                                                                               MLP\n   0.750                Group DRO                                                                                0.55               Adv. Label DRO                                                   0.6              Adv. Label DRO\n                        DANN                                                                                                                                                                                          XGBoost\n                        IRM                                                                                                         XGBoost                                                                           y=x\n   0.725                MixUp                                                                                                       y=x\n                        VREX\n                        MMD\n                        CORAL                                                                                    0.50\n   0.700                Label Group DRO                                                                                                                                                              0.5\n                        Adv. Label DRO\n                        y=x\n   0.675                                                                                                         0.45\n   0.650                                                                                                                                                                                             0.4\n                      0.72         0.74         0.76         0.78        0.80         0.82                       0.40             0.60              0.65          0.70         0.75         0.80                        0.78                 0.79               0.80               0.81\n                     In-Distribution Test Accuracy                                                                               In-Distribution Test Accuracy                                                     In-Distribution Test Accuracy\n                        Figure 10: Alternate version of Figure 2 with adjusted scaling for increased detail.\n                                                                                                                                                           36", "md": "| |ASSISTments| |College Scorecard| |Hospital Mortality|\n|---|---|---|---|---|---|\n|XGBoost| | |0.90|Model|Model|\n|LightGBM|0.90|LightGBM|0.91|LightGBM| |\n|MLP| |MLP| |MLP| |\n|FT-Transformer| |FT-Transformer| |FT-Transformer| |\n|ResNet| | |0.875|FT-Transformer| |ResNet|\n|SAINT| | |ResNet| |SAINT|\n|NODE| | |SAINT| |NODE|\n| | | |TabTransformer|0.850|TabTransformer|0.90|TabTransformer|\n|CatBoost| |CatBoost| |CatBoost| |\n|Out-of-Distribution TDRO| |DRO| |Out-of-Distribution TDRO| |\n|Group DRO| |Group DRO| |Group DRO| |\n|DANN| | |0.825|DANN| |DANN|\n|IRM| |IRM| |IRM| |\n|MixUp| |MixUp| |MixUp| |\n|VREX| | |0.89|VREX| |VREX|\n|MMD| | |0.800|MMD| |MMD|\n|CORAL| |CORAL| |CORAL| |\n|Label Group DRO| |Label Group DRO| |Label Group DRO| |\n|Adv. Label DRO| |Adv. Label DRO| |Adv. Label DRO| |\n|y=x| | |0.775|y=x|0.88|y=x|\n\n$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.88} & \\text{0.90} & \\text{0.92} & \\text{0.94} & \\text{0.96} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\n| |Hospital Readmission| |Diabetes| |ICU Length of Stay|\n|---|---|---|---|---|---|\n|Model| |Model| |Model| |\n|XGBoost|0.62|XGBoost|0.87|XGBoost| |\n|LightGBM| |LightGBM| |LightGBM| |\n|MLP| |MLP| |MLP| |\n|FT-Transformer| |FT-Transformer| |FT-Transformer| |\n|ResNet| | |0.60|DRO| |ResNet|\n|SAINT| | |ResNet| |SAINT|\n|NODE| |NODE| |NODE| |\n|TabTransformer| | |0.64|TabTransformer|0.66|TabTransformer|\n|CatBoost| |CatBoost| |CatBoost| |\n|Out-of-Distribution TGroup DRO| |DANN|0.62|DANN| |\n|IRM| |IRM| |IRM| |\n|MixUp| |MixUp| |MixUp| |\n|VREX| | |0.60|VREX| |VREX|\n|MMD| |MMD| |MMD| |\n|CORAL| |CORAL| |CORAL| |\n|Label Group DRO| |Label Group DRO| |Label Group DRO| |\n|Adv. Label DRO| | |0.84|Adv. Label DRO|0.58|Adv. Label DRO|\n|y=x|0.83|y=x|0.56|y=x| |\n\n$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.60} & \\text{0.65} & \\text{0.70} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & \\\\\n\\hline\n\\end{array}\n$$\n\n| |Food Stamps| |Unemployment|\n|---|---|---|---|\n|Model| |Model| |\n|XGBoost|0.83|Model| |\n|LightGBM|0.82|MLP|0.950|LightGBM|\n|MLP| |FT-Transformer|0.925|MLP|\n| |FT-Transformer|0.800|SAINT| |FT-Transformer|\n| |ResNet|0.775|Label Group DRO|LightGBM|ResNet|\n|SAINT|0.81|TabTransformer|0.7|SAINT|\n| |NODE| |CatBoost| |NODE|\n| |TabTransformer|0.80|DRO|0.900|TabTransformer|\n|CatBoost| |Group DRO| |CatBoost|\n|Out-of-Distribution T DRO| |DANN|0.62|Out-of-Distribution T Group DRO|\n|Group DRO| |IRM| |Group DRO|\n|DANN|0.79|MixUp|0.875|DANN|\n|IRM| |VREX| |IRM|\n|MixUp| |MMD|0.850|MixUp|\n|VREX|0.78|CORAL| |VREX|\n|MMD| |Label Group DRO| |MMD|\n|CORAL| |Adv. Label DRO| |CORAL|\n|Label Group DRO| |y=x|0.825|Label Group DRO|\n|Adv. Label DRO|0.77| |0.800|Adv. Label DRO|\n|y=x| | | |y=x|\n\n$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.850} & \\text{0.875} & \\text{0.900} & \\text{0.925} & \\text{0.950} & \\text{0.975} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\n| |HELOC| |ModelPublic Coverage|\n|---|---|---|---|\n|Model| |FT-Transformer| |SAINT|\n|XGBoost| |SAINT| |CatBoost|\n|LightGBM|0.60|DRO|0.7|ResNet|\n| |FT-Transformer| |ResNet| |Label Group DRO|\n|SAINT|0.775|LightGBM| |Group DRO|\n|NODE| |Group DRO| |NODE|\n|TabTransformer| |NODE| |Out-of-Distribution T MLP|\n|CatBoost|0.55|Adv. Label DRO|0.6|Adv. Label DRO|\n|Out-of-Distribution T Group DRO| |XGBoost| |y=x|\n\n$$\n\\begin{array}{|c|c|c|c|}\n\\hline\n& \\text{0.40} & \\text{0.60} & \\text{0.65} & \\text{0.70} & \\text{0.75} & \\text{0.80} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & & \\\\\n\\hline\n\\end{array}\n$$", "images": [], "items": [{"type": "table", "rows": [["", "ASSISTments", "", "College Scorecard", "", "Hospital Mortality"], ["XGBoost", "", "", "0.90", "Model", "Model"], ["LightGBM", "0.90", "LightGBM", "0.91", "LightGBM", ""], ["MLP", "", "MLP", "", "MLP", ""], ["FT-Transformer", "", "FT-Transformer", "", "FT-Transformer", ""], ["ResNet", "", "", "0.875", "FT-Transformer", "", "ResNet"], ["SAINT", "", "", "ResNet", "", "SAINT"], ["NODE", "", "", "SAINT", "", "NODE"], ["", "", "", "TabTransformer", "0.850", "TabTransformer", "0.90", "TabTransformer"], ["CatBoost", "", "CatBoost", "", "CatBoost", ""], ["Out-of-Distribution TDRO", "", "DRO", "", "Out-of-Distribution TDRO", ""], ["Group DRO", "", "Group DRO", "", "Group DRO", ""], ["DANN", "", "", "0.825", "DANN", "", "DANN"], ["IRM", "", "IRM", "", "IRM", ""], ["MixUp", "", "MixUp", "", "MixUp", ""], ["VREX", "", "", "0.89", "VREX", "", "VREX"], ["MMD", "", "", "0.800", "MMD", "", "MMD"], ["CORAL", "", "CORAL", "", "CORAL", ""], ["Label Group DRO", "", "Label Group DRO", "", "Label Group DRO", ""], ["Adv. Label DRO", "", "Adv. Label DRO", "", "Adv. Label DRO", ""], ["y=x", "", "", "0.775", "y=x", "0.88", "y=x"]], "md": "| |ASSISTments| |College Scorecard| |Hospital Mortality|\n|---|---|---|---|---|---|\n|XGBoost| | |0.90|Model|Model|\n|LightGBM|0.90|LightGBM|0.91|LightGBM| |\n|MLP| |MLP| |MLP| |\n|FT-Transformer| |FT-Transformer| |FT-Transformer| |\n|ResNet| | |0.875|FT-Transformer| |ResNet|\n|SAINT| | |ResNet| |SAINT|\n|NODE| | |SAINT| |NODE|\n| | | |TabTransformer|0.850|TabTransformer|0.90|TabTransformer|\n|CatBoost| |CatBoost| |CatBoost| |\n|Out-of-Distribution TDRO| |DRO| |Out-of-Distribution TDRO| |\n|Group DRO| |Group DRO| |Group DRO| |\n|DANN| | |0.825|DANN| |DANN|\n|IRM| |IRM| |IRM| |\n|MixUp| |MixUp| |MixUp| |\n|VREX| | |0.89|VREX| |VREX|\n|MMD| | |0.800|MMD| |MMD|\n|CORAL| |CORAL| |CORAL| |\n|Label Group DRO| |Label Group DRO| |Label Group DRO| |\n|Adv. Label DRO| |Adv. Label DRO| |Adv. Label DRO| |\n|y=x| | |0.775|y=x|0.88|y=x|", "isPerfectTable": false, "csv": "\"\",\"ASSISTments\",\"\",\"College Scorecard\",\"\",\"Hospital Mortality\"\n\"XGBoost\",\"\",\"\",\"0.90\",\"Model\",\"Model\"\n\"LightGBM\",\"0.90\",\"LightGBM\",\"0.91\",\"LightGBM\",\"\"\n\"MLP\",\"\",\"MLP\",\"\",\"MLP\",\"\"\n\"FT-Transformer\",\"\",\"FT-Transformer\",\"\",\"FT-Transformer\",\"\"\n\"ResNet\",\"\",\"\",\"0.875\",\"FT-Transformer\",\"\",\"ResNet\"\n\"SAINT\",\"\",\"\",\"ResNet\",\"\",\"SAINT\"\n\"NODE\",\"\",\"\",\"SAINT\",\"\",\"NODE\"\n\"\",\"\",\"\",\"TabTransformer\",\"0.850\",\"TabTransformer\",\"0.90\",\"TabTransformer\"\n\"CatBoost\",\"\",\"CatBoost\",\"\",\"CatBoost\",\"\"\n\"Out-of-Distribution TDRO\",\"\",\"DRO\",\"\",\"Out-of-Distribution TDRO\",\"\"\n\"Group DRO\",\"\",\"Group DRO\",\"\",\"Group DRO\",\"\"\n\"DANN\",\"\",\"\",\"0.825\",\"DANN\",\"\",\"DANN\"\n\"IRM\",\"\",\"IRM\",\"\",\"IRM\",\"\"\n\"MixUp\",\"\",\"MixUp\",\"\",\"MixUp\",\"\"\n\"VREX\",\"\",\"\",\"0.89\",\"VREX\",\"\",\"VREX\"\n\"MMD\",\"\",\"\",\"0.800\",\"MMD\",\"\",\"MMD\"\n\"CORAL\",\"\",\"CORAL\",\"\",\"CORAL\",\"\"\n\"Label Group DRO\",\"\",\"Label Group DRO\",\"\",\"Label Group DRO\",\"\"\n\"Adv. Label DRO\",\"\",\"Adv. Label DRO\",\"\",\"Adv. Label DRO\",\"\"\n\"y=x\",\"\",\"\",\"0.775\",\"y=x\",\"0.88\",\"y=x\""}, {"type": "text", "value": "$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.88} & \\text{0.90} & \\text{0.92} & \\text{0.94} & \\text{0.96} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & \\\\\n\\hline\n\\end{array}\n$$", "md": "$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.88} & \\text{0.90} & \\text{0.92} & \\text{0.94} & \\text{0.96} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & \\\\\n\\hline\n\\end{array}\n$$"}, {"type": "table", "rows": [["", "Hospital Readmission", "", "Diabetes", "", "ICU Length of Stay"], ["Model", "", "Model", "", "Model", ""], ["XGBoost", "0.62", "XGBoost", "0.87", "XGBoost", ""], ["LightGBM", "", "LightGBM", "", "LightGBM", ""], ["MLP", "", "MLP", "", "MLP", ""], ["FT-Transformer", "", "FT-Transformer", "", "FT-Transformer", ""], ["ResNet", "", "", "0.60", "DRO", "", "ResNet"], ["SAINT", "", "", "ResNet", "", "SAINT"], ["NODE", "", "NODE", "", "NODE", ""], ["TabTransformer", "", "", "0.64", "TabTransformer", "0.66", "TabTransformer"], ["CatBoost", "", "CatBoost", "", "CatBoost", ""], ["Out-of-Distribution TGroup DRO", "", "DANN", "0.62", "DANN", ""], ["IRM", "", "IRM", "", "IRM", ""], ["MixUp", "", "MixUp", "", "MixUp", ""], ["VREX", "", "", "0.60", "VREX", "", "VREX"], ["MMD", "", "MMD", "", "MMD", ""], ["CORAL", "", "CORAL", "", "CORAL", ""], ["Label Group DRO", "", "Label Group DRO", "", "Label Group DRO", ""], ["Adv. Label DRO", "", "", "0.84", "Adv. Label DRO", "0.58", "Adv. Label DRO"], ["y=x", "0.83", "y=x", "0.56", "y=x", ""]], "md": "| |Hospital Readmission| |Diabetes| |ICU Length of Stay|\n|---|---|---|---|---|---|\n|Model| |Model| |Model| |\n|XGBoost|0.62|XGBoost|0.87|XGBoost| |\n|LightGBM| |LightGBM| |LightGBM| |\n|MLP| |MLP| |MLP| |\n|FT-Transformer| |FT-Transformer| |FT-Transformer| |\n|ResNet| | |0.60|DRO| |ResNet|\n|SAINT| | |ResNet| |SAINT|\n|NODE| |NODE| |NODE| |\n|TabTransformer| | |0.64|TabTransformer|0.66|TabTransformer|\n|CatBoost| |CatBoost| |CatBoost| |\n|Out-of-Distribution TGroup DRO| |DANN|0.62|DANN| |\n|IRM| |IRM| |IRM| |\n|MixUp| |MixUp| |MixUp| |\n|VREX| | |0.60|VREX| |VREX|\n|MMD| |MMD| |MMD| |\n|CORAL| |CORAL| |CORAL| |\n|Label Group DRO| |Label Group DRO| |Label Group DRO| |\n|Adv. Label DRO| | |0.84|Adv. Label DRO|0.58|Adv. Label DRO|\n|y=x|0.83|y=x|0.56|y=x| |", "isPerfectTable": false, "csv": "\"\",\"Hospital Readmission\",\"\",\"Diabetes\",\"\",\"ICU Length of Stay\"\n\"Model\",\"\",\"Model\",\"\",\"Model\",\"\"\n\"XGBoost\",\"0.62\",\"XGBoost\",\"0.87\",\"XGBoost\",\"\"\n\"LightGBM\",\"\",\"LightGBM\",\"\",\"LightGBM\",\"\"\n\"MLP\",\"\",\"MLP\",\"\",\"MLP\",\"\"\n\"FT-Transformer\",\"\",\"FT-Transformer\",\"\",\"FT-Transformer\",\"\"\n\"ResNet\",\"\",\"\",\"0.60\",\"DRO\",\"\",\"ResNet\"\n\"SAINT\",\"\",\"\",\"ResNet\",\"\",\"SAINT\"\n\"NODE\",\"\",\"NODE\",\"\",\"NODE\",\"\"\n\"TabTransformer\",\"\",\"\",\"0.64\",\"TabTransformer\",\"0.66\",\"TabTransformer\"\n\"CatBoost\",\"\",\"CatBoost\",\"\",\"CatBoost\",\"\"\n\"Out-of-Distribution TGroup DRO\",\"\",\"DANN\",\"0.62\",\"DANN\",\"\"\n\"IRM\",\"\",\"IRM\",\"\",\"IRM\",\"\"\n\"MixUp\",\"\",\"MixUp\",\"\",\"MixUp\",\"\"\n\"VREX\",\"\",\"\",\"0.60\",\"VREX\",\"\",\"VREX\"\n\"MMD\",\"\",\"MMD\",\"\",\"MMD\",\"\"\n\"CORAL\",\"\",\"CORAL\",\"\",\"CORAL\",\"\"\n\"Label Group DRO\",\"\",\"Label Group DRO\",\"\",\"Label Group DRO\",\"\"\n\"Adv. Label DRO\",\"\",\"\",\"0.84\",\"Adv. Label DRO\",\"0.58\",\"Adv. Label DRO\"\n\"y=x\",\"0.83\",\"y=x\",\"0.56\",\"y=x\",\"\""}, {"type": "text", "value": "$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.60} & \\text{0.65} & \\text{0.70} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & \\\\\n\\hline\n\\end{array}\n$$", "md": "$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.60} & \\text{0.65} & \\text{0.70} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & \\\\\n\\hline\n\\end{array}\n$$"}, {"type": "table", "rows": [["", "Food Stamps", "", "Unemployment"], ["Model", "", "Model", ""], ["XGBoost", "0.83", "Model", ""], ["LightGBM", "0.82", "MLP", "0.950", "LightGBM"], ["MLP", "", "FT-Transformer", "0.925", "MLP"], ["", "FT-Transformer", "0.800", "SAINT", "", "FT-Transformer"], ["", "ResNet", "0.775", "Label Group DRO", "LightGBM", "ResNet"], ["SAINT", "0.81", "TabTransformer", "0.7", "SAINT"], ["", "NODE", "", "CatBoost", "", "NODE"], ["", "TabTransformer", "0.80", "DRO", "0.900", "TabTransformer"], ["CatBoost", "", "Group DRO", "", "CatBoost"], ["Out-of-Distribution T DRO", "", "DANN", "0.62", "Out-of-Distribution T Group DRO"], ["Group DRO", "", "IRM", "", "Group DRO"], ["DANN", "0.79", "MixUp", "0.875", "DANN"], ["IRM", "", "VREX", "", "IRM"], ["MixUp", "", "MMD", "0.850", "MixUp"], ["VREX", "0.78", "CORAL", "", "VREX"], ["MMD", "", "Label Group DRO", "", "MMD"], ["CORAL", "", "Adv. Label DRO", "", "CORAL"], ["Label Group DRO", "", "y=x", "0.825", "Label Group DRO"], ["Adv. Label DRO", "0.77", "", "0.800", "Adv. Label DRO"], ["y=x", "", "", "", "y=x"]], "md": "| |Food Stamps| |Unemployment|\n|---|---|---|---|\n|Model| |Model| |\n|XGBoost|0.83|Model| |\n|LightGBM|0.82|MLP|0.950|LightGBM|\n|MLP| |FT-Transformer|0.925|MLP|\n| |FT-Transformer|0.800|SAINT| |FT-Transformer|\n| |ResNet|0.775|Label Group DRO|LightGBM|ResNet|\n|SAINT|0.81|TabTransformer|0.7|SAINT|\n| |NODE| |CatBoost| |NODE|\n| |TabTransformer|0.80|DRO|0.900|TabTransformer|\n|CatBoost| |Group DRO| |CatBoost|\n|Out-of-Distribution T DRO| |DANN|0.62|Out-of-Distribution T Group DRO|\n|Group DRO| |IRM| |Group DRO|\n|DANN|0.79|MixUp|0.875|DANN|\n|IRM| |VREX| |IRM|\n|MixUp| |MMD|0.850|MixUp|\n|VREX|0.78|CORAL| |VREX|\n|MMD| |Label Group DRO| |MMD|\n|CORAL| |Adv. Label DRO| |CORAL|\n|Label Group DRO| |y=x|0.825|Label Group DRO|\n|Adv. Label DRO|0.77| |0.800|Adv. Label DRO|\n|y=x| | | |y=x|", "isPerfectTable": false, "csv": "\"\",\"Food Stamps\",\"\",\"Unemployment\"\n\"Model\",\"\",\"Model\",\"\"\n\"XGBoost\",\"0.83\",\"Model\",\"\"\n\"LightGBM\",\"0.82\",\"MLP\",\"0.950\",\"LightGBM\"\n\"MLP\",\"\",\"FT-Transformer\",\"0.925\",\"MLP\"\n\"\",\"FT-Transformer\",\"0.800\",\"SAINT\",\"\",\"FT-Transformer\"\n\"\",\"ResNet\",\"0.775\",\"Label Group DRO\",\"LightGBM\",\"ResNet\"\n\"SAINT\",\"0.81\",\"TabTransformer\",\"0.7\",\"SAINT\"\n\"\",\"NODE\",\"\",\"CatBoost\",\"\",\"NODE\"\n\"\",\"TabTransformer\",\"0.80\",\"DRO\",\"0.900\",\"TabTransformer\"\n\"CatBoost\",\"\",\"Group DRO\",\"\",\"CatBoost\"\n\"Out-of-Distribution T DRO\",\"\",\"DANN\",\"0.62\",\"Out-of-Distribution T Group DRO\"\n\"Group DRO\",\"\",\"IRM\",\"\",\"Group DRO\"\n\"DANN\",\"0.79\",\"MixUp\",\"0.875\",\"DANN\"\n\"IRM\",\"\",\"VREX\",\"\",\"IRM\"\n\"MixUp\",\"\",\"MMD\",\"0.850\",\"MixUp\"\n\"VREX\",\"0.78\",\"CORAL\",\"\",\"VREX\"\n\"MMD\",\"\",\"Label Group DRO\",\"\",\"MMD\"\n\"CORAL\",\"\",\"Adv. Label DRO\",\"\",\"CORAL\"\n\"Label Group DRO\",\"\",\"y=x\",\"0.825\",\"Label Group DRO\"\n\"Adv. Label DRO\",\"0.77\",\"\",\"0.800\",\"Adv. Label DRO\"\n\"y=x\",\"\",\"\",\"\",\"y=x\""}, {"type": "text", "value": "$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.850} & \\text{0.875} & \\text{0.900} & \\text{0.925} & \\text{0.950} & \\text{0.975} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & & \\\\\n\\hline\n\\end{array}\n$$", "md": "$$\n\\begin{array}{|c|c|c|c|c|c|}\n\\hline\n& \\text{0.850} & \\text{0.875} & \\text{0.900} & \\text{0.925} & \\text{0.950} & \\text{0.975} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & & \\\\\n\\hline\n\\end{array}\n$$"}, {"type": "table", "rows": [["", "HELOC", "", "ModelPublic Coverage"], ["Model", "", "FT-Transformer", "", "SAINT"], ["XGBoost", "", "SAINT", "", "CatBoost"], ["LightGBM", "0.60", "DRO", "0.7", "ResNet"], ["", "FT-Transformer", "", "ResNet", "", "Label Group DRO"], ["SAINT", "0.775", "LightGBM", "", "Group DRO"], ["NODE", "", "Group DRO", "", "NODE"], ["TabTransformer", "", "NODE", "", "Out-of-Distribution T MLP"], ["CatBoost", "0.55", "Adv. Label DRO", "0.6", "Adv. Label DRO"], ["Out-of-Distribution T Group DRO", "", "XGBoost", "", "y=x"]], "md": "| |HELOC| |ModelPublic Coverage|\n|---|---|---|---|\n|Model| |FT-Transformer| |SAINT|\n|XGBoost| |SAINT| |CatBoost|\n|LightGBM|0.60|DRO|0.7|ResNet|\n| |FT-Transformer| |ResNet| |Label Group DRO|\n|SAINT|0.775|LightGBM| |Group DRO|\n|NODE| |Group DRO| |NODE|\n|TabTransformer| |NODE| |Out-of-Distribution T MLP|\n|CatBoost|0.55|Adv. Label DRO|0.6|Adv. Label DRO|\n|Out-of-Distribution T Group DRO| |XGBoost| |y=x|", "isPerfectTable": false, "csv": "\"\",\"HELOC\",\"\",\"ModelPublic Coverage\"\n\"Model\",\"\",\"FT-Transformer\",\"\",\"SAINT\"\n\"XGBoost\",\"\",\"SAINT\",\"\",\"CatBoost\"\n\"LightGBM\",\"0.60\",\"DRO\",\"0.7\",\"ResNet\"\n\"\",\"FT-Transformer\",\"\",\"ResNet\",\"\",\"Label Group DRO\"\n\"SAINT\",\"0.775\",\"LightGBM\",\"\",\"Group DRO\"\n\"NODE\",\"\",\"Group DRO\",\"\",\"NODE\"\n\"TabTransformer\",\"\",\"NODE\",\"\",\"Out-of-Distribution T MLP\"\n\"CatBoost\",\"0.55\",\"Adv. Label DRO\",\"0.6\",\"Adv. Label DRO\"\n\"Out-of-Distribution T Group DRO\",\"\",\"XGBoost\",\"\",\"y=x\""}, {"type": "text", "value": "$$\n\\begin{array}{|c|c|c|c|}\n\\hline\n& \\text{0.40} & \\text{0.60} & \\text{0.65} & \\text{0.70} & \\text{0.75} & \\text{0.80} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & & \\\\\n\\hline\n\\end{array}\n$$", "md": "$$\n\\begin{array}{|c|c|c|c|}\n\\hline\n& \\text{0.40} & \\text{0.60} & \\text{0.65} & \\text{0.70} & \\text{0.75} & \\text{0.80} \\\\\n\\hline\n\\text{In-Distribution Test Accuracy} & & & & & & \\\\\n\\hline\n\\end{array}\n$$"}]}, {"page": 37, "text": "       est Accuracy                                Sepsis                                                          est Accuracy               Childhood Lead                                                             est Accuracy                  Hypertension\n         0.99              Model                                                                                      0.97              Model                                                                                                Model\n                            FT-Transformer                                                                                              FT-Transformer                                                                                       FT-Transformer\n                            SAINT                                                                                                       SAINT                                                                                                SAINT\n                            CatBoost                                                                                                    CatBoost                                                                                             CatBoost\n         0.98               TabTransformer                                                                                              TabTransformer                                                                     0.60              TabTransformer\n                            DRO                                                                                       0.96              DRO                                                                                                  DRO\n                            ResNet                                                                                                      ResNet                                                                                               ResNet\n                            Label Group DRO                                                                                             Label Group DRO                                                                                      Label Group DRO\n         0.97               LightGBM                                                                                                    LightGBM                                                                                             LightGBM\n                            Group DRO                                                                                                   Group DRO                                                                                            Group DRO\n                            NODE                                                                                      0.95              NODE                                                                                                 NODE\n                                                                                                                   Out-of-Distribution T                                                                                 Out-of-Distribution T\n       Out-of-Distribution TMLP                                                                                                         MLP                                                                                0.55              MLP\n         0.96               Adv. Label DRO                                                                                              Adv. Label DRO                                                                                       Adv. Label DRO\n                            XGBoost                                                                                                     XGBoost                                                                                              XGBoost\n                            y=x                                                                                                         y=x                                                                                                  y=x\n         0.95                                                                                                         0.94                                                                                                 0.50\n         0.94                                                                                                         0.93\n         0.93                                                                                                         0.92                                                                                                 0.45\n                  0.9870            0.9875             0.9880             0.9885             0.9890                                              0.965                 0.970               0.975                                             0.60             0.62        0.64  0.66  0.68\n                         In-Distribution Test Accuracy                                                                               In-Distribution Test Accuracy                                                                         In-Distribution Test Accuracy\n                             Figure 11: Alternate version of Figure 3 with adjusted scaling for increased detail.\nTable 13: Label summary statistics for test sets in TABLESHIFT. \u00af                                                                                                                                         Y gives the proportion of positive\nlabels for the respective split, and Var( \u00af                                                                                  Y ) the variance of the sample proportion.\n                                                        Task                                                                                        \u00af                   ID Var( \u00af        YID)         \u00af                     OOD   Var( \u00af         YOOD)\n                                                                                                                                                   YID                                               YOOD\n                                                        Voting                                                                                   0.804                            0.017                0.754                                 0.008\n                                                        ASSISTments                                                                              0.695                            0.001                0.437                                 0.011\n                                                        Childhood Lead                                                                           0.029                            0.004                0.080                                 0.003\n                                                        College Scorecard                                                                        0.127                            0.003                0.311                                 0.013\n                                                        Diabetes                                                                                 0.127                            0.001                0.174                                 0.001\n                                                        FICO HELOC                                                                               0.255                            0.026                0.569                                 0.006\n                                                        Food Stamps                                                                              0.191                            0.001                0.220                                 0.002\n                                                        Hospital Readmission                                                                     0.416                            0.008                0.494                                 0.002\n                                                        Hypertension                                                                             0.402                            0.003                0.584                                 0.001\n                                                        ICU Hospital Mortality                                                                   0.085                            0.009                0.124                                 0.003\n                                                        ICU Length of Stay                                                                       0.398                            0.015                0.456                                 0.005\n                                                        Income                                                                                   0.321                            0.001                0.398                                 0.002\n                                                        Public Health Ins.                                                                       0.224                            0.001                0.636                                 0.001\n                                                        Sepsis                                                                                   0.012                            0.000                0.075                                 0.001\n                                                        Unemployment                                                                             0.034                            0.000                0.052                                 0.001\nTable 14: PMA-OOD results (cf. Figure ) and standard deviation of PMA-OOD over benchmark\ntasks. (Cf. Figure 4a.)\n                                                                  Estimator                                                          PMA-OOD Mean                                                 PMA-OOD Std.\n                                                                  VREX                                                                                        0.876                                                    0.076\n                                                                  IRM                                                                                         0.910                                                    0.069\n                                                                  Label Group DRO                                                                             0.915                                                    0.129\n                                                                  MixUp                                                                                       0.917                                                    0.076\n                                                                  TabTransformer                                                                              0.922                                                    0.091\n                                                                  DANN                                                                                        0.932                                                    0.075\n                                                                  DRO                                                                                         0.932                                                    0.107\n                                                                  MMD                                                                                         0.940                                                    0.059\n                                                                  CORAL                                                                                       0.944                                                    0.059\n                                                                  Adv. Label DRO                                                                              0.950                                                    0.080\n                                                                  ResNet                                                                                      0.956                                                    0.069\n                                                                  MLP                                                                                         0.961                                                    0.054\n                                                                  Group DRO                                                                                   0.962                                                    0.059\n                                                                  NODE                                                                                        0.963                                                    0.066\n                                                                  SAINT                                                                                       0.964                                                    0.070\n                                                                  LightGBM                                                                                    0.964                                                    0.070\n                                                                  XGBoost                                                                                     0.964                                                    0.065\n                                                                  FT-Transformer                                                                              0.968                                                    0.069\n                                                                  CatBoost                                                                                    0.994                                                    0.014\n                                                                                                                                                              37", "md": "# OCR Text\n\n## Accuracy Results:\n\n| |est Accuracy|Model|\n|---|---|---|\n|FT-Transformer|0.99|FT-Transformer|\n|SAINT| |SAINT|\n|CatBoost| |CatBoost|\n|TabTransformer|0.98|TabTransformer|\n|DRO| |DRO|\n|ResNet| |ResNet|\n|Label Group DRO| |Label Group DRO|\n|LightGBM|0.97|LightGBM|\n|Group DRO| |Group DRO|\n|NODE| |NODE|\n|Out-of-Distribution TMLP| |MLP|\n|Adv. Label DRO|0.96|Adv. Label DRO|\n|XGBoost| |XGBoost|\n|y=x| |y=x|\n\n## Table 13: Label summary statistics for test sets in TABLESHIFT\n\n|Task|\u00af ID|Var(\u00af YID)|\u00af OOD|Var(\u00af YOOD)|\n|---|---|---|---|---|\n|Voting|0.804|0.017|0.754|0.008|\n|ASSISTments|0.695|0.001|0.437|0.011|\n|Childhood Lead|0.029|0.004|0.080|0.003|\n|College Scorecard|0.127|0.003|0.311|0.013|\n|Diabetes|0.127|0.001|0.174|0.001|\n|FICO HELOC|0.255|0.026|0.569|0.006|\n|Food Stamps|0.191|0.001|0.220|0.002|\n|Hospital Readmission|0.416|0.008|0.494|0.002|\n|Hypertension|0.402|0.003|0.584|0.001|\n|ICU Hospital Mortality|0.085|0.009|0.124|0.003|\n|ICU Length of Stay|0.398|0.015|0.456|0.005|\n|Income|0.321|0.001|0.398|0.002|\n|Public Health Ins.|0.224|0.001|0.636|0.001|\n|Sepsis|0.012|0.000|0.075|0.001|\n|Unemployment|0.034|0.000|0.052|0.001|\n\n## Table 14: PMA-OOD results and standard deviation\n\n|Estimator|PMA-OOD Mean|PMA-OOD Std.|\n|---|---|---|\n|VREX|0.876|0.076|\n|IRM|0.910|0.069|\n|Label Group DRO|0.915|0.129|\n|MixUp|0.917|0.076|\n|TabTransformer|0.922|0.091|\n|DANN|0.932|0.075|\n|DRO|0.932|0.107|\n|MMD|0.940|0.059|\n|CORAL|0.944|0.059|\n|Adv. Label DRO|0.950|0.080|\n|ResNet|0.956|0.069|\n|MLP|0.961|0.054|\n|Group DRO|0.962|0.059|\n|NODE|0.963|0.066|\n|SAINT|0.964|0.070|\n|LightGBM|0.964|0.070|\n|XGBoost|0.964|0.065|\n|FT-Transformer|0.968|0.069|\n|CatBoost|0.994|0.014|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "OCR Text", "md": "# OCR Text"}, {"type": "heading", "lvl": 2, "value": "Accuracy Results:", "md": "## Accuracy Results:"}, {"type": "table", "rows": [["", "est Accuracy", "Model"], ["FT-Transformer", "0.99", "FT-Transformer"], ["SAINT", "", "SAINT"], ["CatBoost", "", "CatBoost"], ["TabTransformer", "0.98", "TabTransformer"], ["DRO", "", "DRO"], ["ResNet", "", "ResNet"], ["Label Group DRO", "", "Label Group DRO"], ["LightGBM", "0.97", "LightGBM"], ["Group DRO", "", "Group DRO"], ["NODE", "", "NODE"], ["Out-of-Distribution TMLP", "", "MLP"], ["Adv. Label DRO", "0.96", "Adv. Label DRO"], ["XGBoost", "", "XGBoost"], ["y=x", "", "y=x"]], "md": "| |est Accuracy|Model|\n|---|---|---|\n|FT-Transformer|0.99|FT-Transformer|\n|SAINT| |SAINT|\n|CatBoost| |CatBoost|\n|TabTransformer|0.98|TabTransformer|\n|DRO| |DRO|\n|ResNet| |ResNet|\n|Label Group DRO| |Label Group DRO|\n|LightGBM|0.97|LightGBM|\n|Group DRO| |Group DRO|\n|NODE| |NODE|\n|Out-of-Distribution TMLP| |MLP|\n|Adv. Label DRO|0.96|Adv. Label DRO|\n|XGBoost| |XGBoost|\n|y=x| |y=x|", "isPerfectTable": true, "csv": "\"\",\"est Accuracy\",\"Model\"\n\"FT-Transformer\",\"0.99\",\"FT-Transformer\"\n\"SAINT\",\"\",\"SAINT\"\n\"CatBoost\",\"\",\"CatBoost\"\n\"TabTransformer\",\"0.98\",\"TabTransformer\"\n\"DRO\",\"\",\"DRO\"\n\"ResNet\",\"\",\"ResNet\"\n\"Label Group DRO\",\"\",\"Label Group DRO\"\n\"LightGBM\",\"0.97\",\"LightGBM\"\n\"Group DRO\",\"\",\"Group DRO\"\n\"NODE\",\"\",\"NODE\"\n\"Out-of-Distribution TMLP\",\"\",\"MLP\"\n\"Adv. Label DRO\",\"0.96\",\"Adv. Label DRO\"\n\"XGBoost\",\"\",\"XGBoost\"\n\"y=x\",\"\",\"y=x\""}, {"type": "heading", "lvl": 2, "value": "Table 13: Label summary statistics for test sets in TABLESHIFT", "md": "## Table 13: Label summary statistics for test sets in TABLESHIFT"}, {"type": "table", "rows": [["Task", "\u00af ID", "Var(\u00af YID)", "\u00af OOD", "Var(\u00af YOOD)"], ["Voting", "0.804", "0.017", "0.754", "0.008"], ["ASSISTments", "0.695", "0.001", "0.437", "0.011"], ["Childhood Lead", "0.029", "0.004", "0.080", "0.003"], ["College Scorecard", "0.127", "0.003", "0.311", "0.013"], ["Diabetes", "0.127", "0.001", "0.174", "0.001"], ["FICO HELOC", "0.255", "0.026", "0.569", "0.006"], ["Food Stamps", "0.191", "0.001", "0.220", "0.002"], ["Hospital Readmission", "0.416", "0.008", "0.494", "0.002"], ["Hypertension", "0.402", "0.003", "0.584", "0.001"], ["ICU Hospital Mortality", "0.085", "0.009", "0.124", "0.003"], ["ICU Length of Stay", "0.398", "0.015", "0.456", "0.005"], ["Income", "0.321", "0.001", "0.398", "0.002"], ["Public Health Ins.", "0.224", "0.001", "0.636", "0.001"], ["Sepsis", "0.012", "0.000", "0.075", "0.001"], ["Unemployment", "0.034", "0.000", "0.052", "0.001"]], "md": "|Task|\u00af ID|Var(\u00af YID)|\u00af OOD|Var(\u00af YOOD)|\n|---|---|---|---|---|\n|Voting|0.804|0.017|0.754|0.008|\n|ASSISTments|0.695|0.001|0.437|0.011|\n|Childhood Lead|0.029|0.004|0.080|0.003|\n|College Scorecard|0.127|0.003|0.311|0.013|\n|Diabetes|0.127|0.001|0.174|0.001|\n|FICO HELOC|0.255|0.026|0.569|0.006|\n|Food Stamps|0.191|0.001|0.220|0.002|\n|Hospital Readmission|0.416|0.008|0.494|0.002|\n|Hypertension|0.402|0.003|0.584|0.001|\n|ICU Hospital Mortality|0.085|0.009|0.124|0.003|\n|ICU Length of Stay|0.398|0.015|0.456|0.005|\n|Income|0.321|0.001|0.398|0.002|\n|Public Health Ins.|0.224|0.001|0.636|0.001|\n|Sepsis|0.012|0.000|0.075|0.001|\n|Unemployment|0.034|0.000|0.052|0.001|", "isPerfectTable": true, "csv": "\"Task\",\"\u00af ID\",\"Var(\u00af YID)\",\"\u00af OOD\",\"Var(\u00af YOOD)\"\n\"Voting\",\"0.804\",\"0.017\",\"0.754\",\"0.008\"\n\"ASSISTments\",\"0.695\",\"0.001\",\"0.437\",\"0.011\"\n\"Childhood Lead\",\"0.029\",\"0.004\",\"0.080\",\"0.003\"\n\"College Scorecard\",\"0.127\",\"0.003\",\"0.311\",\"0.013\"\n\"Diabetes\",\"0.127\",\"0.001\",\"0.174\",\"0.001\"\n\"FICO HELOC\",\"0.255\",\"0.026\",\"0.569\",\"0.006\"\n\"Food Stamps\",\"0.191\",\"0.001\",\"0.220\",\"0.002\"\n\"Hospital Readmission\",\"0.416\",\"0.008\",\"0.494\",\"0.002\"\n\"Hypertension\",\"0.402\",\"0.003\",\"0.584\",\"0.001\"\n\"ICU Hospital Mortality\",\"0.085\",\"0.009\",\"0.124\",\"0.003\"\n\"ICU Length of Stay\",\"0.398\",\"0.015\",\"0.456\",\"0.005\"\n\"Income\",\"0.321\",\"0.001\",\"0.398\",\"0.002\"\n\"Public Health Ins.\",\"0.224\",\"0.001\",\"0.636\",\"0.001\"\n\"Sepsis\",\"0.012\",\"0.000\",\"0.075\",\"0.001\"\n\"Unemployment\",\"0.034\",\"0.000\",\"0.052\",\"0.001\""}, {"type": "heading", "lvl": 2, "value": "Table 14: PMA-OOD results and standard deviation", "md": "## Table 14: PMA-OOD results and standard deviation"}, {"type": "table", "rows": [["Estimator", "PMA-OOD Mean", "PMA-OOD Std."], ["VREX", "0.876", "0.076"], ["IRM", "0.910", "0.069"], ["Label Group DRO", "0.915", "0.129"], ["MixUp", "0.917", "0.076"], ["TabTransformer", "0.922", "0.091"], ["DANN", "0.932", "0.075"], ["DRO", "0.932", "0.107"], ["MMD", "0.940", "0.059"], ["CORAL", "0.944", "0.059"], ["Adv. Label DRO", "0.950", "0.080"], ["ResNet", "0.956", "0.069"], ["MLP", "0.961", "0.054"], ["Group DRO", "0.962", "0.059"], ["NODE", "0.963", "0.066"], ["SAINT", "0.964", "0.070"], ["LightGBM", "0.964", "0.070"], ["XGBoost", "0.964", "0.065"], ["FT-Transformer", "0.968", "0.069"], ["CatBoost", "0.994", "0.014"]], "md": "|Estimator|PMA-OOD Mean|PMA-OOD Std.|\n|---|---|---|\n|VREX|0.876|0.076|\n|IRM|0.910|0.069|\n|Label Group DRO|0.915|0.129|\n|MixUp|0.917|0.076|\n|TabTransformer|0.922|0.091|\n|DANN|0.932|0.075|\n|DRO|0.932|0.107|\n|MMD|0.940|0.059|\n|CORAL|0.944|0.059|\n|Adv. Label DRO|0.950|0.080|\n|ResNet|0.956|0.069|\n|MLP|0.961|0.054|\n|Group DRO|0.962|0.059|\n|NODE|0.963|0.066|\n|SAINT|0.964|0.070|\n|LightGBM|0.964|0.070|\n|XGBoost|0.964|0.065|\n|FT-Transformer|0.968|0.069|\n|CatBoost|0.994|0.014|", "isPerfectTable": true, "csv": "\"Estimator\",\"PMA-OOD Mean\",\"PMA-OOD Std.\"\n\"VREX\",\"0.876\",\"0.076\"\n\"IRM\",\"0.910\",\"0.069\"\n\"Label Group DRO\",\"0.915\",\"0.129\"\n\"MixUp\",\"0.917\",\"0.076\"\n\"TabTransformer\",\"0.922\",\"0.091\"\n\"DANN\",\"0.932\",\"0.075\"\n\"DRO\",\"0.932\",\"0.107\"\n\"MMD\",\"0.940\",\"0.059\"\n\"CORAL\",\"0.944\",\"0.059\"\n\"Adv. Label DRO\",\"0.950\",\"0.080\"\n\"ResNet\",\"0.956\",\"0.069\"\n\"MLP\",\"0.961\",\"0.054\"\n\"Group DRO\",\"0.962\",\"0.059\"\n\"NODE\",\"0.963\",\"0.066\"\n\"SAINT\",\"0.964\",\"0.070\"\n\"LightGBM\",\"0.964\",\"0.070\"\n\"XGBoost\",\"0.964\",\"0.065\"\n\"FT-Transformer\",\"0.968\",\"0.069\"\n\"CatBoost\",\"0.994\",\"0.014\""}]}, {"page": 38, "text": "Table 15: Label summary statistics for test sets in TABLESHIFT. \u00af     Y gives the proportion of positive\nlabels for the respective split, and Var( \u00af\n                                          Y ) the variance of the sample proportion. (Cf. Figure 4b.)\n                                                  ID                       OOD\n                 Method                 ID Accuracy       Std.   OOD Accuracy        Std.\n                 Adv. Label DRO              0.834       0.125         0.792         0.132\n                 CatBoost                    0.862       0.105         0.794         0.126\n                 DANN                        0.816       0.137         0.770         0.148\n                 CORAL                       0.824       0.129         0.777         0.134\n                 DRO                         0.843       0.129         0.773         0.147\n                 FT-Transformer              0.866       0.103         0.794         0.126\n                 Group DRO                   0.832       0.129         0.791         0.133\n                 IRM                         0.800       0.130         0.749         0.136\n                 Label Group DRO             0.829       0.123         0.759         0.134\n                 LightGBM                    0.856       0.108         0.781         0.124\n                 MixUp                       0.807       0.125         0.752         0.118\n                 MLP                         0.845       0.126         0.774         0.141\n                 MMD                         0.825       0.130         0.774         0.135\n                 NODE                        0.853       0.110         0.781         0.129\n                 ResNet                      0.844       0.126         0.773         0.139\n                 SAINT                       0.868       0.099         0.787         0.127\n                 TabTransformer              0.835       0.136         0.759         0.160\n                 VREX                        0.786       0.127         0.720         0.128\n                 XGBoost                     0.857       0.105         0.783         0.122\n                                                    38", "md": "|Method|ID Accuracy|Std.|OOD Accuracy|Std.|\n|---|---|---|---|---|\n|Adv. Label DRO|0.834|0.125|0.792|0.132|\n|CatBoost|0.862|0.105|0.794|0.126|\n|DANN|0.816|0.137|0.770|0.148|\n|CORAL|0.824|0.129|0.777|0.134|\n|DRO|0.843|0.129|0.773|0.147|\n|FT-Transformer|0.866|0.103|0.794|0.126|\n|Group DRO|0.832|0.129|0.791|0.133|\n|IRM|0.800|0.130|0.749|0.136|\n|Label Group DRO|0.829|0.123|0.759|0.134|\n|LightGBM|0.856|0.108|0.781|0.124|\n|MixUp|0.807|0.125|0.752|0.118|\n|MLP|0.845|0.126|0.774|0.141|\n|MMD|0.825|0.130|0.774|0.135|\n|NODE|0.853|0.110|0.781|0.129|\n|ResNet|0.844|0.126|0.773|0.139|\n|SAINT|0.868|0.099|0.787|0.127|\n|TabTransformer|0.835|0.136|0.759|0.160|\n|VREX|0.786|0.127|0.720|0.128|\n|XGBoost|0.857|0.105|0.783|0.122|", "images": [], "items": [{"type": "table", "rows": [["Method", "ID Accuracy", "Std.", "OOD Accuracy", "Std."], ["Adv. Label DRO", "0.834", "0.125", "0.792", "0.132"], ["CatBoost", "0.862", "0.105", "0.794", "0.126"], ["DANN", "0.816", "0.137", "0.770", "0.148"], ["CORAL", "0.824", "0.129", "0.777", "0.134"], ["DRO", "0.843", "0.129", "0.773", "0.147"], ["FT-Transformer", "0.866", "0.103", "0.794", "0.126"], ["Group DRO", "0.832", "0.129", "0.791", "0.133"], ["IRM", "0.800", "0.130", "0.749", "0.136"], ["Label Group DRO", "0.829", "0.123", "0.759", "0.134"], ["LightGBM", "0.856", "0.108", "0.781", "0.124"], ["MixUp", "0.807", "0.125", "0.752", "0.118"], ["MLP", "0.845", "0.126", "0.774", "0.141"], ["MMD", "0.825", "0.130", "0.774", "0.135"], ["NODE", "0.853", "0.110", "0.781", "0.129"], ["ResNet", "0.844", "0.126", "0.773", "0.139"], ["SAINT", "0.868", "0.099", "0.787", "0.127"], ["TabTransformer", "0.835", "0.136", "0.759", "0.160"], ["VREX", "0.786", "0.127", "0.720", "0.128"], ["XGBoost", "0.857", "0.105", "0.783", "0.122"]], "md": "|Method|ID Accuracy|Std.|OOD Accuracy|Std.|\n|---|---|---|---|---|\n|Adv. Label DRO|0.834|0.125|0.792|0.132|\n|CatBoost|0.862|0.105|0.794|0.126|\n|DANN|0.816|0.137|0.770|0.148|\n|CORAL|0.824|0.129|0.777|0.134|\n|DRO|0.843|0.129|0.773|0.147|\n|FT-Transformer|0.866|0.103|0.794|0.126|\n|Group DRO|0.832|0.129|0.791|0.133|\n|IRM|0.800|0.130|0.749|0.136|\n|Label Group DRO|0.829|0.123|0.759|0.134|\n|LightGBM|0.856|0.108|0.781|0.124|\n|MixUp|0.807|0.125|0.752|0.118|\n|MLP|0.845|0.126|0.774|0.141|\n|MMD|0.825|0.130|0.774|0.135|\n|NODE|0.853|0.110|0.781|0.129|\n|ResNet|0.844|0.126|0.773|0.139|\n|SAINT|0.868|0.099|0.787|0.127|\n|TabTransformer|0.835|0.136|0.759|0.160|\n|VREX|0.786|0.127|0.720|0.128|\n|XGBoost|0.857|0.105|0.783|0.122|", "isPerfectTable": true, "csv": "\"Method\",\"ID Accuracy\",\"Std.\",\"OOD Accuracy\",\"Std.\"\n\"Adv. Label DRO\",\"0.834\",\"0.125\",\"0.792\",\"0.132\"\n\"CatBoost\",\"0.862\",\"0.105\",\"0.794\",\"0.126\"\n\"DANN\",\"0.816\",\"0.137\",\"0.770\",\"0.148\"\n\"CORAL\",\"0.824\",\"0.129\",\"0.777\",\"0.134\"\n\"DRO\",\"0.843\",\"0.129\",\"0.773\",\"0.147\"\n\"FT-Transformer\",\"0.866\",\"0.103\",\"0.794\",\"0.126\"\n\"Group DRO\",\"0.832\",\"0.129\",\"0.791\",\"0.133\"\n\"IRM\",\"0.800\",\"0.130\",\"0.749\",\"0.136\"\n\"Label Group DRO\",\"0.829\",\"0.123\",\"0.759\",\"0.134\"\n\"LightGBM\",\"0.856\",\"0.108\",\"0.781\",\"0.124\"\n\"MixUp\",\"0.807\",\"0.125\",\"0.752\",\"0.118\"\n\"MLP\",\"0.845\",\"0.126\",\"0.774\",\"0.141\"\n\"MMD\",\"0.825\",\"0.130\",\"0.774\",\"0.135\"\n\"NODE\",\"0.853\",\"0.110\",\"0.781\",\"0.129\"\n\"ResNet\",\"0.844\",\"0.126\",\"0.773\",\"0.139\"\n\"SAINT\",\"0.868\",\"0.099\",\"0.787\",\"0.127\"\n\"TabTransformer\",\"0.835\",\"0.136\",\"0.759\",\"0.160\"\n\"VREX\",\"0.786\",\"0.127\",\"0.720\",\"0.128\"\n\"XGBoost\",\"0.857\",\"0.105\",\"0.783\",\"0.122\""}]}, {"page": 39, "text": "E.4    Results with Additional Random Seeds\nOur experiments on each model-dataset pair comprise a single run of 100 rounds of our hyperparame-\nter tuning protocol described in Section 4.2. Here, we provide the results of additional experiments\nconducted using different random seeds, in order to evaluate the sensitivity of our results to the\nrandom variation inherent in the training and hyperparameter tuning process.\nFor these experiments, we conduct an identical procedure to the experiments described in the main\ntext of our paper, but only change the random seed. This process affects the random initialization of\nmodel weights, random initialization of hyperparameter tuning, and training data shuffling, among\nother procedures. We note that it does not affect the train/test splitting in our datasets, as the train/test\nsplits are defined by distribution shifts and are fixed to ensure comparability of the benchmark across\nexperiments.\nThe results are shown in Table 16. Table 16 shows that, across the fi        ve models and three datasets\nevaluated, there is minimal variation in performance due to random seeds. Of the 90 measurements\ncovering 45 trials represented in Table 16, the 95% Clopper-Pearson CIs for both ID and OOD\naccuracy overlap in all cases, with only four exceptions (LightGBM, iteration 0, Food Stamps ID and\nOOD accuracy; LightGBM, iteration 2, Hypertension OOD accuracy; MLP, Hypertension, iteration\n0, OOD accuracy; FT-Transformer, iteration 0, OOD accuracy). These results provide evidence that\nour results are robust to variation due to random seed.\nE.5    Results with Hybrid Methods\nOur main study design is focused on benchmarking existing previously-proposed methods for tabular\nmodeling. The methods we evlauate span models, which prescribe the functional form of a predictor\nf\u03b8, and also objective functions, which describe the loss L to be minimized while learning the\nparameters \u03b8 of a fixed predictor f. Concretely, for example, FT-Transformer or MLP specify the\nform of f, while some robustness interventions, such as Group DRO, specify an objective that can be\nmonimized over any smooth continuous function.\nOur study does not explore potential combinations of different models and objective functions from\nthe preexisting literature. In this section, we conduct an exploratory investigation into whether\n\u201chybrid methods\u201d \u2013 combinations of different models and objective functions explored in our study \u2013\nmight improve robustness, for the best-performing compatible combinations of models and objective\nfunctions in our study.\nIn particular, our hybrid model study explores the use of the Group DRO objective function, in\ncombination with three models from our study: FT-Transformer, NODE, and ResNet. Group DRO\nwas selected as it is the highest-performing objective-based technique in our study (see Figure 4a),\nand the three models were selected as they are the highest-performing Transformer-based model,\ntree-based model, and baseline supervised model, repsectively, in our study. We note that Group\nDRO cannot be easily combined with CatBoost, XGBoost, or LightGBM, as these are not smooth\ndifferentiable continuous functions, which is a requirement for the use of the Group DRO objective.\nOur methodology in this section is as follows: for each estimator (FT-Transformer, NODE, ResNet),\nwe train the model with both ERM (the standard procedure used in our main experiments above)\nand Group DRO. We follow the same hyperparameter tuning procedure as described in Section 4.2)\nabove. We use the same hyperparameter grid defined in Section I for each model, but also include a\nfull sweep over the Group DRO step size parameter, using the Group DRO grid described in Section I\n(thus, for model X, we take the union of the two hyperparameter grids: { grid(X) \u222a        grid(Group DRO)\n} ). We conduct this procedure for fi    ve benchmark datasets: Childhood Lead, College Scorecard,\nFood Stamps, Hypertension, and Voting.\nThe results of our hybrid model experiments are shown in Table 17. The results show little or no\nevidence that Group DRO reduces shift gaps for the models evaluated, as indicated by the fact that\nOOD test accuracy intervals tend to be overlapping, or higher, for ERM relative to Group DRO.\nKeeping in mind that Group DRO was parameterized over MLP models in our main experiments (as\nall prior works only use Group DRO with MLP), the results in Table 17 suggest that Group DRO\nmay primarily improve weak (MLP) models but does not improve robustness for stronger models,\nexplaining the improvements for Group DRO over vanilla MLP models in the main text.\n                                                     39", "md": "# Results with Additional Random Seeds and Hybrid Methods\n\n## Results with Additional Random Seeds\n\nOur experiments on each model-dataset pair comprise a single run of 100 rounds of our hyperparameter tuning protocol described in Section 4.2. Here, we provide the results of additional experiments conducted using different random seeds, in order to evaluate the sensitivity of our results to the random variation inherent in the training and hyperparameter tuning process.\n\nFor these experiments, we conduct an identical procedure to the experiments described in the main text of our paper, but only change the random seed. This process affects the random initialization of model weights, random initialization of hyperparameter tuning, and training data shuffling, among other procedures. We note that it does not affect the train/test splitting in our datasets, as the train/test splits are defined by distribution shifts and are fixed to ensure comparability of the benchmark across experiments.\n\nThe results are shown in Table 16. Table 16 shows that, across the five models and three datasets evaluated, there is minimal variation in performance due to random seeds. Of the 90 measurements covering 45 trials represented in Table 16, the 95% Clopper-Pearson CIs for both ID and OOD accuracy overlap in all cases, with only four exceptions (LightGBM, iteration 0, Food Stamps ID and OOD accuracy; LightGBM, iteration 2, Hypertension OOD accuracy; MLP, Hypertension, iteration 0, OOD accuracy; FT-Transformer, iteration 0, OOD accuracy). These results provide evidence that our results are robust to variation due to random seed.\n\n## Results with Hybrid Methods\n\nOur main study design is focused on benchmarking existing previously-proposed methods for tabular modeling. The methods we evaluate span models, which prescribe the functional form of a predictor f\u03b8, and also objective functions, which describe the loss L to be minimized while learning the parameters \u03b8 of a fixed predictor f. Concretely, for example, FT-Transformer or MLP specify the form of f, while some robustness interventions, such as Group DRO, specify an objective that can be minimized over any smooth continuous function.\n\nOur study does not explore potential combinations of different models and objective functions from the preexisting literature. In this section, we conduct an exploratory investigation into whether \u201chybrid methods\u201d \u2013 combinations of different models and objective functions explored in our study \u2013 might improve robustness, for the best-performing compatible combinations of models and objective functions in our study.\n\nIn particular, our hybrid model study explores the use of the Group DRO objective function, in combination with three models from our study: FT-Transformer, NODE, and ResNet. Group DRO was selected as it is the highest-performing objective-based technique in our study (see Figure 4a), and the three models were selected as they are the highest-performing Transformer-based model, tree-based model, and baseline supervised model, respectively, in our study. We note that Group DRO cannot be easily combined with CatBoost, XGBoost, or LightGBM, as these are not smooth differentiable continuous functions, which is a requirement for the use of the Group DRO objective.\n\nOur methodology in this section is as follows: for each estimator (FT-Transformer, NODE, ResNet), we train the model with both ERM (the standard procedure used in our main experiments above) and Group DRO. We follow the same hyperparameter tuning procedure as described in Section 4.2 above. We use the same hyperparameter grid defined in Section I for each model, but also include a full sweep over the Group DRO step size parameter, using the Group DRO grid described in Section I (thus, for model X, we take the union of the two hyperparameter grids: { grid(X) \u222a grid(Group DRO) }). We conduct this procedure for five benchmark datasets: Childhood Lead, College Scorecard, Food Stamps, Hypertension, and Voting.\n\nThe results of our hybrid model experiments are shown in Table 17. The results show little or no evidence that Group DRO reduces shift gaps for the models evaluated, as indicated by the fact that OOD test accuracy intervals tend to be overlapping, or higher, for ERM relative to Group DRO.\n\nKeeping in mind that Group DRO was parameterized over MLP models in our main experiments (as all prior works only use Group DRO with MLP), the results in Table 17 suggest that Group DRO may primarily improve weak (MLP) models but does not improve robustness for stronger models, explaining the improvements for Group DRO over vanilla MLP models in the main text.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Results with Additional Random Seeds and Hybrid Methods", "md": "# Results with Additional Random Seeds and Hybrid Methods"}, {"type": "heading", "lvl": 2, "value": "Results with Additional Random Seeds", "md": "## Results with Additional Random Seeds"}, {"type": "text", "value": "Our experiments on each model-dataset pair comprise a single run of 100 rounds of our hyperparameter tuning protocol described in Section 4.2. Here, we provide the results of additional experiments conducted using different random seeds, in order to evaluate the sensitivity of our results to the random variation inherent in the training and hyperparameter tuning process.\n\nFor these experiments, we conduct an identical procedure to the experiments described in the main text of our paper, but only change the random seed. This process affects the random initialization of model weights, random initialization of hyperparameter tuning, and training data shuffling, among other procedures. We note that it does not affect the train/test splitting in our datasets, as the train/test splits are defined by distribution shifts and are fixed to ensure comparability of the benchmark across experiments.\n\nThe results are shown in Table 16. Table 16 shows that, across the five models and three datasets evaluated, there is minimal variation in performance due to random seeds. Of the 90 measurements covering 45 trials represented in Table 16, the 95% Clopper-Pearson CIs for both ID and OOD accuracy overlap in all cases, with only four exceptions (LightGBM, iteration 0, Food Stamps ID and OOD accuracy; LightGBM, iteration 2, Hypertension OOD accuracy; MLP, Hypertension, iteration 0, OOD accuracy; FT-Transformer, iteration 0, OOD accuracy). These results provide evidence that our results are robust to variation due to random seed.", "md": "Our experiments on each model-dataset pair comprise a single run of 100 rounds of our hyperparameter tuning protocol described in Section 4.2. Here, we provide the results of additional experiments conducted using different random seeds, in order to evaluate the sensitivity of our results to the random variation inherent in the training and hyperparameter tuning process.\n\nFor these experiments, we conduct an identical procedure to the experiments described in the main text of our paper, but only change the random seed. This process affects the random initialization of model weights, random initialization of hyperparameter tuning, and training data shuffling, among other procedures. We note that it does not affect the train/test splitting in our datasets, as the train/test splits are defined by distribution shifts and are fixed to ensure comparability of the benchmark across experiments.\n\nThe results are shown in Table 16. Table 16 shows that, across the five models and three datasets evaluated, there is minimal variation in performance due to random seeds. Of the 90 measurements covering 45 trials represented in Table 16, the 95% Clopper-Pearson CIs for both ID and OOD accuracy overlap in all cases, with only four exceptions (LightGBM, iteration 0, Food Stamps ID and OOD accuracy; LightGBM, iteration 2, Hypertension OOD accuracy; MLP, Hypertension, iteration 0, OOD accuracy; FT-Transformer, iteration 0, OOD accuracy). These results provide evidence that our results are robust to variation due to random seed."}, {"type": "heading", "lvl": 2, "value": "Results with Hybrid Methods", "md": "## Results with Hybrid Methods"}, {"type": "text", "value": "Our main study design is focused on benchmarking existing previously-proposed methods for tabular modeling. The methods we evaluate span models, which prescribe the functional form of a predictor f\u03b8, and also objective functions, which describe the loss L to be minimized while learning the parameters \u03b8 of a fixed predictor f. Concretely, for example, FT-Transformer or MLP specify the form of f, while some robustness interventions, such as Group DRO, specify an objective that can be minimized over any smooth continuous function.\n\nOur study does not explore potential combinations of different models and objective functions from the preexisting literature. In this section, we conduct an exploratory investigation into whether \u201chybrid methods\u201d \u2013 combinations of different models and objective functions explored in our study \u2013 might improve robustness, for the best-performing compatible combinations of models and objective functions in our study.\n\nIn particular, our hybrid model study explores the use of the Group DRO objective function, in combination with three models from our study: FT-Transformer, NODE, and ResNet. Group DRO was selected as it is the highest-performing objective-based technique in our study (see Figure 4a), and the three models were selected as they are the highest-performing Transformer-based model, tree-based model, and baseline supervised model, respectively, in our study. We note that Group DRO cannot be easily combined with CatBoost, XGBoost, or LightGBM, as these are not smooth differentiable continuous functions, which is a requirement for the use of the Group DRO objective.\n\nOur methodology in this section is as follows: for each estimator (FT-Transformer, NODE, ResNet), we train the model with both ERM (the standard procedure used in our main experiments above) and Group DRO. We follow the same hyperparameter tuning procedure as described in Section 4.2 above. We use the same hyperparameter grid defined in Section I for each model, but also include a full sweep over the Group DRO step size parameter, using the Group DRO grid described in Section I (thus, for model X, we take the union of the two hyperparameter grids: { grid(X) \u222a grid(Group DRO) }). We conduct this procedure for five benchmark datasets: Childhood Lead, College Scorecard, Food Stamps, Hypertension, and Voting.\n\nThe results of our hybrid model experiments are shown in Table 17. The results show little or no evidence that Group DRO reduces shift gaps for the models evaluated, as indicated by the fact that OOD test accuracy intervals tend to be overlapping, or higher, for ERM relative to Group DRO.\n\nKeeping in mind that Group DRO was parameterized over MLP models in our main experiments (as all prior works only use Group DRO with MLP), the results in Table 17 suggest that Group DRO may primarily improve weak (MLP) models but does not improve robustness for stronger models, explaining the improvements for Group DRO over vanilla MLP models in the main text.", "md": "Our main study design is focused on benchmarking existing previously-proposed methods for tabular modeling. The methods we evaluate span models, which prescribe the functional form of a predictor f\u03b8, and also objective functions, which describe the loss L to be minimized while learning the parameters \u03b8 of a fixed predictor f. Concretely, for example, FT-Transformer or MLP specify the form of f, while some robustness interventions, such as Group DRO, specify an objective that can be minimized over any smooth continuous function.\n\nOur study does not explore potential combinations of different models and objective functions from the preexisting literature. In this section, we conduct an exploratory investigation into whether \u201chybrid methods\u201d \u2013 combinations of different models and objective functions explored in our study \u2013 might improve robustness, for the best-performing compatible combinations of models and objective functions in our study.\n\nIn particular, our hybrid model study explores the use of the Group DRO objective function, in combination with three models from our study: FT-Transformer, NODE, and ResNet. Group DRO was selected as it is the highest-performing objective-based technique in our study (see Figure 4a), and the three models were selected as they are the highest-performing Transformer-based model, tree-based model, and baseline supervised model, respectively, in our study. We note that Group DRO cannot be easily combined with CatBoost, XGBoost, or LightGBM, as these are not smooth differentiable continuous functions, which is a requirement for the use of the Group DRO objective.\n\nOur methodology in this section is as follows: for each estimator (FT-Transformer, NODE, ResNet), we train the model with both ERM (the standard procedure used in our main experiments above) and Group DRO. We follow the same hyperparameter tuning procedure as described in Section 4.2 above. We use the same hyperparameter grid defined in Section I for each model, but also include a full sweep over the Group DRO step size parameter, using the Group DRO grid described in Section I (thus, for model X, we take the union of the two hyperparameter grids: { grid(X) \u222a grid(Group DRO) }). We conduct this procedure for five benchmark datasets: Childhood Lead, College Scorecard, Food Stamps, Hypertension, and Voting.\n\nThe results of our hybrid model experiments are shown in Table 17. The results show little or no evidence that Group DRO reduces shift gaps for the models evaluated, as indicated by the fact that OOD test accuracy intervals tend to be overlapping, or higher, for ERM relative to Group DRO.\n\nKeeping in mind that Group DRO was parameterized over MLP models in our main experiments (as all prior works only use Group DRO with MLP), the results in Table 17 suggest that Group DRO may primarily improve weak (MLP) models but does not improve robustness for stronger models, explaining the improvements for Group DRO over vanilla MLP models in the main text."}]}, {"page": 40, "text": " Table 16: Results with additional random seeds. Varying random seeds has a minimal impact on\n the final results of our hyperparameter tuning procedure, indicating that our findings are robust to\n variation due to random seeds. See Section E.4 for details on experimental design.\n                                                         ID Test Accuracy         OOD Test Accuracy\nTask                  Base Estimator      Iteration    Value    95% CI            Value    95% CI\n                                          0            0.957    (0.954, 0.961)    0.885    (0.866, 0.901)\n                      CatBoost            1            0.959    (0.955, 0.962)    0.879    (0.861, 0.896)\n                                          2            0.959    (0.956, 0.963)    0.882    (0.863, 0.898)\n                                          0            0.948    (0.944, 0.952)    0.859    (0.839, 0.877)\n                      FT-Transformer      1            0.946    (0.942, 0.95)     0.850    (0.83, 0.868)\n                                          2            0.940    (0.936, 0.945)    0.830    (0.809, 0.85)\nCollege Scorecard                         0            0.939    (0.935, 0.943)    0.822    (0.8, 0.841)\n                      LightGBM            1            0.943    (0.938, 0.947)    0.839    (0.819, 0.859)\n                                          2            0.943    (0.939, 0.947)    0.837    (0.816, 0.856)\n                                          0            0.947    (0.942, 0.95)     0.845    (0.825, 0.864)\n                      MLP                 1            0.949    (0.944, 0.952)    0.859    (0.84, 0.878)\n                                          2            0.945    (0.941, 0.949)    0.859    (0.839, 0.877)\n                                          0            0.942    (0.938, 0.946)    0.830    (0.809, 0.85)\n                      XGBoost             1            0.946    (0.942, 0.95)     0.842    (0.821, 0.861)\n                                          2            0.947    (0.943, 0.951)    0.845    (0.824, 0.864)\n                                          0            0.849    (0.847, 0.852)    0.825    (0.821, 0.828)\n                      CatBoost            1            0.850    (0.847, 0.852)    0.824    (0.821, 0.827)\n                                          2            0.849    (0.847, 0.852)    0.824    (0.82, 0.827)\n                                          0            0.843    (0.841, 0.846)    0.816    (0.812, 0.819)\n                      FT-Transformer      1            0.848    (0.846, 0.851)    0.824    (0.82, 0.827)\n                                          2            0.844    (0.842, 0.847)    0.817    (0.814, 0.82)\nFood Stamps                               0            0.836    (0.833, 0.838)    0.808    (0.805, 0.812)\n                      LightGBM            1            0.844    (0.841, 0.846)    0.818    (0.814, 0.821)\n                                          2            0.843    (0.84, 0.846)     0.817    (0.814, 0.821)\n                                          0            0.841    (0.838, 0.844)    0.815    (0.812, 0.819)\n                      MLP                 1            0.845    (0.842, 0.847)    0.817    (0.814, 0.821)\n                                          2            0.844    (0.841, 0.846)    0.811    (0.808, 0.815)\n                                          0            0.844    (0.842, 0.847)    0.820    (0.817, 0.824)\n                      XGBoost             1            0.843    (0.84, 0.845)     0.819    (0.815, 0.822)\n                                          2            0.845    (0.842, 0.847)    0.820    (0.816, 0.823)\n                                          0            0.670    (0.665, 0.676)    0.599    (0.597, 0.6)\n                      CatBoost            1            0.671    (0.665, 0.676)    0.599    (0.597, 0.6)\n                                          2            0.671    (0.666, 0.677)    0.600    (0.598, 0.601)\n                                          0            0.666    (0.661, 0.672)    0.604    (0.603, 0.605)\n                      FT-Transformer      1            0.670    (0.665, 0.676)    0.594    (0.593, 0.596)\nHypertension                              2            0.672    (0.666, 0.677)    0.595    (0.594, 0.596)\n                                          0            0.678    (0.672, 0.683)    0.634    (0.633, 0.635)\n                      LightGBM            1            0.672    (0.666, 0.677)    0.636    (0.635, 0.637)\n                                          2            0.672    (0.667, 0.678)    0.628    (0.627, 0.629)\n                                          0            0.664    (0.658, 0.67)     0.583    (0.582, 0.584)\n                      MLP                 1            0.669    (0.663, 0.674)    0.597    (0.596, 0.599)\n                                          2            0.668    (0.662, 0.673)    0.598    (0.597, 0.599)\n                                          0            0.671    (0.665, 0.677)    0.588    (0.587, 0.59)\n                      XGBoost             1            0.669    (0.664, 0.675)    0.586    (0.584, 0.587)\n                                          2            0.669    (0.664, 0.675)    0.586    (0.584, 0.587)\n                                                   40", "md": "|Task|Base Estimator|Iteration|ID Test Accuracy|OOD Test Accuracy|\n|---|---|---|---|---|\n| |CatBoost|0|0.957 $\\pm$ (0.954, 0.961)|0.885 $\\pm$ (0.866, 0.901)|\n|1|0.959 $\\pm$ (0.955, 0.962)|0.879 $\\pm$ (0.861, 0.896)| | |\n| | |2|0.959 $\\pm$ (0.956, 0.963)|0.882 $\\pm$ (0.863, 0.898)|\n| |FT-Transformer|0|0.948 $\\pm$ (0.944, 0.952)|0.859 $\\pm$ (0.839, 0.877)|\n|1|0.946 $\\pm$ (0.942, 0.95)|0.850 $\\pm$ (0.83, 0.868)| | |\n| | |2|0.940 $\\pm$ (0.936, 0.945)|0.830 $\\pm$ (0.809, 0.85)|\n|College Scorecard|LightGBM|0|0.939 $\\pm$ (0.935, 0.943)|0.822 $\\pm$ (0.8, 0.841)|\n|1|0.943 $\\pm$ (0.938, 0.947)|0.839 $\\pm$ (0.819, 0.859)| | |\n| | |2|0.943 $\\pm$ (0.939, 0.947)|0.837 $\\pm$ (0.816, 0.856)|\n| |MLP|0|0.947 $\\pm$ (0.942, 0.95)|0.845 $\\pm$ (0.825, 0.864)|\n|1|0.949 $\\pm$ (0.944, 0.952)|0.859 $\\pm$ (0.84, 0.878)| | |\n| | |2|0.945 $\\pm$ (0.941, 0.949)|0.859 $\\pm$ (0.839, 0.877)|\n| |XGBoost|0|0.942 $\\pm$ (0.938, 0.946)|0.830 $\\pm$ (0.809, 0.85)|\n|1|0.946 $\\pm$ (0.942, 0.95)|0.842 $\\pm$ (0.821, 0.861)| | |\n| | |2|0.947 $\\pm$ (0.943, 0.951)|0.845 $\\pm$ (0.824, 0.864)|\n| |CatBoost|0|0.849 $\\pm$ (0.847, 0.852)|0.825 $\\pm$ (0.821, 0.828)|\n|1|0.850 $\\pm$ (0.847, 0.852)|0.824 $\\pm$ (0.821, 0.827)| | |\n| | |2|0.849 $\\pm$ (0.847, 0.852)|0.824 $\\pm$ (0.82, 0.827)|\n| |FT-Transformer|0|0.843 $\\pm$ (0.841, 0.846)|0.816 $\\pm$ (0.812, 0.819)|\n|1|0.848 $\\pm$ (0.846, 0.851)|0.824 $\\pm$ (0.82, 0.827)| | |\n| | |2|0.844 $\\pm$ (0.842, 0.847)|0.817 $\\pm$ (0.814, 0.82)|\n|Food Stamps|LightGBM|0|0.836 $\\pm$ (0.833, 0.838)|0.808 $\\pm$ (0.805, 0.812)|\n|1|0.844 $\\pm$ (0.841, 0.846)|0.818 $\\pm$ (0.814, 0.821)| | |\n| | |2|0.843 $\\pm$ (0.84, 0.846)|0.817 $\\pm$ (0.814, 0.821)|\n| |MLP|0|0.844 $\\pm$ (0.842, 0.847)|0.820 $\\pm$ (0.817, 0.824)|\n|1|0.845 $\\pm$ (0.842, 0.847)|0.817 $\\pm$ (0.814, 0.821)| | |\n| | |2|0.844 $\\pm$ (0.841, 0.846)|0.811 $\\pm$ (0.808, 0.815)|\n| |XGBoost|0|0.843 $\\pm$ (0.84, 0.845)|0.819 $\\pm$ (0.815, 0.822)|\n|1|0.845 $\\pm$ (0.842, 0.847)|0.820 $\\pm$ (0.816, 0.823)| | |\n| | |2|0.670 $\\pm$ (0.665, 0.676)|0.599 $\\pm$ (0.597, 0.6)|\n| |CatBoost|0|0.671 $\\pm$ (0.665, 0.676)|0.599 $\\pm$ (0.597, 0.6)|\n|1|0.671 $\\pm$ (0.665, 0.676)|0.599 $\\pm$ (0.597, 0.6)| | |\n| | |2|0.671 $\\pm$ (0.666, 0.677)|0.600 $\\pm$ (0.598, 0.601)|\n|Hypertension|LightGBM|0|0.678 $\\pm$ (0.672, 0.683)|0.634 $\\pm$ (0.633, 0.635)|\n|1|0.672 $\\pm$ (0.666, 0.677)|0.636 $\\pm$ (0.635, 0.637)| | |\n| | |2|0.672 $\\pm$ (0.667, 0.678)|0.628 $\\pm$ (0.627, 0.629)|", "images": [], "items": [{"type": "table", "rows": [["Task", "Base Estimator", "Iteration", "ID Test Accuracy", "OOD Test Accuracy"], ["", "CatBoost", "0", "0.957 $\\pm$ (0.954, 0.961)", "0.885 $\\pm$ (0.866, 0.901)"], ["1", "0.959 $\\pm$ (0.955, 0.962)", "0.879 $\\pm$ (0.861, 0.896)", "", ""], ["", "", "2", "0.959 $\\pm$ (0.956, 0.963)", "0.882 $\\pm$ (0.863, 0.898)"], ["", "FT-Transformer", "0", "0.948 $\\pm$ (0.944, 0.952)", "0.859 $\\pm$ (0.839, 0.877)"], ["1", "0.946 $\\pm$ (0.942, 0.95)", "0.850 $\\pm$ (0.83, 0.868)", "", ""], ["", "", "2", "0.940 $\\pm$ (0.936, 0.945)", "0.830 $\\pm$ (0.809, 0.85)"], ["College Scorecard", "LightGBM", "0", "0.939 $\\pm$ (0.935, 0.943)", "0.822 $\\pm$ (0.8, 0.841)"], ["1", "0.943 $\\pm$ (0.938, 0.947)", "0.839 $\\pm$ (0.819, 0.859)", "", ""], ["", "", "2", "0.943 $\\pm$ (0.939, 0.947)", "0.837 $\\pm$ (0.816, 0.856)"], ["", "MLP", "0", "0.947 $\\pm$ (0.942, 0.95)", "0.845 $\\pm$ (0.825, 0.864)"], ["1", "0.949 $\\pm$ (0.944, 0.952)", "0.859 $\\pm$ (0.84, 0.878)", "", ""], ["", "", "2", "0.945 $\\pm$ (0.941, 0.949)", "0.859 $\\pm$ (0.839, 0.877)"], ["", "XGBoost", "0", "0.942 $\\pm$ (0.938, 0.946)", "0.830 $\\pm$ (0.809, 0.85)"], ["1", "0.946 $\\pm$ (0.942, 0.95)", "0.842 $\\pm$ (0.821, 0.861)", "", ""], ["", "", "2", "0.947 $\\pm$ (0.943, 0.951)", "0.845 $\\pm$ (0.824, 0.864)"], ["", "CatBoost", "0", "0.849 $\\pm$ (0.847, 0.852)", "0.825 $\\pm$ (0.821, 0.828)"], ["1", "0.850 $\\pm$ (0.847, 0.852)", "0.824 $\\pm$ (0.821, 0.827)", "", ""], ["", "", "2", "0.849 $\\pm$ (0.847, 0.852)", "0.824 $\\pm$ (0.82, 0.827)"], ["", "FT-Transformer", "0", "0.843 $\\pm$ (0.841, 0.846)", "0.816 $\\pm$ (0.812, 0.819)"], ["1", "0.848 $\\pm$ (0.846, 0.851)", "0.824 $\\pm$ (0.82, 0.827)", "", ""], ["", "", "2", "0.844 $\\pm$ (0.842, 0.847)", "0.817 $\\pm$ (0.814, 0.82)"], ["Food Stamps", "LightGBM", "0", "0.836 $\\pm$ (0.833, 0.838)", "0.808 $\\pm$ (0.805, 0.812)"], ["1", "0.844 $\\pm$ (0.841, 0.846)", "0.818 $\\pm$ (0.814, 0.821)", "", ""], ["", "", "2", "0.843 $\\pm$ (0.84, 0.846)", "0.817 $\\pm$ (0.814, 0.821)"], ["", "MLP", "0", "0.844 $\\pm$ (0.842, 0.847)", "0.820 $\\pm$ (0.817, 0.824)"], ["1", "0.845 $\\pm$ (0.842, 0.847)", "0.817 $\\pm$ (0.814, 0.821)", "", ""], ["", "", "2", "0.844 $\\pm$ (0.841, 0.846)", "0.811 $\\pm$ (0.808, 0.815)"], ["", "XGBoost", "0", "0.843 $\\pm$ (0.84, 0.845)", "0.819 $\\pm$ (0.815, 0.822)"], ["1", "0.845 $\\pm$ (0.842, 0.847)", "0.820 $\\pm$ (0.816, 0.823)", "", ""], ["", "", "2", "0.670 $\\pm$ (0.665, 0.676)", "0.599 $\\pm$ (0.597, 0.6)"], ["", "CatBoost", "0", "0.671 $\\pm$ (0.665, 0.676)", "0.599 $\\pm$ (0.597, 0.6)"], ["1", "0.671 $\\pm$ (0.665, 0.676)", "0.599 $\\pm$ (0.597, 0.6)", "", ""], ["", "", "2", "0.671 $\\pm$ (0.666, 0.677)", "0.600 $\\pm$ (0.598, 0.601)"], ["Hypertension", "LightGBM", "0", "0.678 $\\pm$ (0.672, 0.683)", "0.634 $\\pm$ (0.633, 0.635)"], ["1", "0.672 $\\pm$ (0.666, 0.677)", "0.636 $\\pm$ (0.635, 0.637)", "", ""], ["", "", "2", "0.672 $\\pm$ (0.667, 0.678)", "0.628 $\\pm$ (0.627, 0.629)"]], "md": "|Task|Base Estimator|Iteration|ID Test Accuracy|OOD Test Accuracy|\n|---|---|---|---|---|\n| |CatBoost|0|0.957 $\\pm$ (0.954, 0.961)|0.885 $\\pm$ (0.866, 0.901)|\n|1|0.959 $\\pm$ (0.955, 0.962)|0.879 $\\pm$ (0.861, 0.896)| | |\n| | |2|0.959 $\\pm$ (0.956, 0.963)|0.882 $\\pm$ (0.863, 0.898)|\n| |FT-Transformer|0|0.948 $\\pm$ (0.944, 0.952)|0.859 $\\pm$ (0.839, 0.877)|\n|1|0.946 $\\pm$ (0.942, 0.95)|0.850 $\\pm$ (0.83, 0.868)| | |\n| | |2|0.940 $\\pm$ (0.936, 0.945)|0.830 $\\pm$ (0.809, 0.85)|\n|College Scorecard|LightGBM|0|0.939 $\\pm$ (0.935, 0.943)|0.822 $\\pm$ (0.8, 0.841)|\n|1|0.943 $\\pm$ (0.938, 0.947)|0.839 $\\pm$ (0.819, 0.859)| | |\n| | |2|0.943 $\\pm$ (0.939, 0.947)|0.837 $\\pm$ (0.816, 0.856)|\n| |MLP|0|0.947 $\\pm$ (0.942, 0.95)|0.845 $\\pm$ (0.825, 0.864)|\n|1|0.949 $\\pm$ (0.944, 0.952)|0.859 $\\pm$ (0.84, 0.878)| | |\n| | |2|0.945 $\\pm$ (0.941, 0.949)|0.859 $\\pm$ (0.839, 0.877)|\n| |XGBoost|0|0.942 $\\pm$ (0.938, 0.946)|0.830 $\\pm$ (0.809, 0.85)|\n|1|0.946 $\\pm$ (0.942, 0.95)|0.842 $\\pm$ (0.821, 0.861)| | |\n| | |2|0.947 $\\pm$ (0.943, 0.951)|0.845 $\\pm$ (0.824, 0.864)|\n| |CatBoost|0|0.849 $\\pm$ (0.847, 0.852)|0.825 $\\pm$ (0.821, 0.828)|\n|1|0.850 $\\pm$ (0.847, 0.852)|0.824 $\\pm$ (0.821, 0.827)| | |\n| | |2|0.849 $\\pm$ (0.847, 0.852)|0.824 $\\pm$ (0.82, 0.827)|\n| |FT-Transformer|0|0.843 $\\pm$ (0.841, 0.846)|0.816 $\\pm$ (0.812, 0.819)|\n|1|0.848 $\\pm$ (0.846, 0.851)|0.824 $\\pm$ (0.82, 0.827)| | |\n| | |2|0.844 $\\pm$ (0.842, 0.847)|0.817 $\\pm$ (0.814, 0.82)|\n|Food Stamps|LightGBM|0|0.836 $\\pm$ (0.833, 0.838)|0.808 $\\pm$ (0.805, 0.812)|\n|1|0.844 $\\pm$ (0.841, 0.846)|0.818 $\\pm$ (0.814, 0.821)| | |\n| | |2|0.843 $\\pm$ (0.84, 0.846)|0.817 $\\pm$ (0.814, 0.821)|\n| |MLP|0|0.844 $\\pm$ (0.842, 0.847)|0.820 $\\pm$ (0.817, 0.824)|\n|1|0.845 $\\pm$ (0.842, 0.847)|0.817 $\\pm$ (0.814, 0.821)| | |\n| | |2|0.844 $\\pm$ (0.841, 0.846)|0.811 $\\pm$ (0.808, 0.815)|\n| |XGBoost|0|0.843 $\\pm$ (0.84, 0.845)|0.819 $\\pm$ (0.815, 0.822)|\n|1|0.845 $\\pm$ (0.842, 0.847)|0.820 $\\pm$ (0.816, 0.823)| | |\n| | |2|0.670 $\\pm$ (0.665, 0.676)|0.599 $\\pm$ (0.597, 0.6)|\n| |CatBoost|0|0.671 $\\pm$ (0.665, 0.676)|0.599 $\\pm$ (0.597, 0.6)|\n|1|0.671 $\\pm$ (0.665, 0.676)|0.599 $\\pm$ (0.597, 0.6)| | |\n| | |2|0.671 $\\pm$ (0.666, 0.677)|0.600 $\\pm$ (0.598, 0.601)|\n|Hypertension|LightGBM|0|0.678 $\\pm$ (0.672, 0.683)|0.634 $\\pm$ (0.633, 0.635)|\n|1|0.672 $\\pm$ (0.666, 0.677)|0.636 $\\pm$ (0.635, 0.637)| | |\n| | |2|0.672 $\\pm$ (0.667, 0.678)|0.628 $\\pm$ (0.627, 0.629)|", "isPerfectTable": true, "csv": "\"Task\",\"Base Estimator\",\"Iteration\",\"ID Test Accuracy\",\"OOD Test Accuracy\"\n\"\",\"CatBoost\",\"0\",\"0.957 $\\pm$ (0.954, 0.961)\",\"0.885 $\\pm$ (0.866, 0.901)\"\n\"1\",\"0.959 $\\pm$ (0.955, 0.962)\",\"0.879 $\\pm$ (0.861, 0.896)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.959 $\\pm$ (0.956, 0.963)\",\"0.882 $\\pm$ (0.863, 0.898)\"\n\"\",\"FT-Transformer\",\"0\",\"0.948 $\\pm$ (0.944, 0.952)\",\"0.859 $\\pm$ (0.839, 0.877)\"\n\"1\",\"0.946 $\\pm$ (0.942, 0.95)\",\"0.850 $\\pm$ (0.83, 0.868)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.940 $\\pm$ (0.936, 0.945)\",\"0.830 $\\pm$ (0.809, 0.85)\"\n\"College Scorecard\",\"LightGBM\",\"0\",\"0.939 $\\pm$ (0.935, 0.943)\",\"0.822 $\\pm$ (0.8, 0.841)\"\n\"1\",\"0.943 $\\pm$ (0.938, 0.947)\",\"0.839 $\\pm$ (0.819, 0.859)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.943 $\\pm$ (0.939, 0.947)\",\"0.837 $\\pm$ (0.816, 0.856)\"\n\"\",\"MLP\",\"0\",\"0.947 $\\pm$ (0.942, 0.95)\",\"0.845 $\\pm$ (0.825, 0.864)\"\n\"1\",\"0.949 $\\pm$ (0.944, 0.952)\",\"0.859 $\\pm$ (0.84, 0.878)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.945 $\\pm$ (0.941, 0.949)\",\"0.859 $\\pm$ (0.839, 0.877)\"\n\"\",\"XGBoost\",\"0\",\"0.942 $\\pm$ (0.938, 0.946)\",\"0.830 $\\pm$ (0.809, 0.85)\"\n\"1\",\"0.946 $\\pm$ (0.942, 0.95)\",\"0.842 $\\pm$ (0.821, 0.861)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.947 $\\pm$ (0.943, 0.951)\",\"0.845 $\\pm$ (0.824, 0.864)\"\n\"\",\"CatBoost\",\"0\",\"0.849 $\\pm$ (0.847, 0.852)\",\"0.825 $\\pm$ (0.821, 0.828)\"\n\"1\",\"0.850 $\\pm$ (0.847, 0.852)\",\"0.824 $\\pm$ (0.821, 0.827)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.849 $\\pm$ (0.847, 0.852)\",\"0.824 $\\pm$ (0.82, 0.827)\"\n\"\",\"FT-Transformer\",\"0\",\"0.843 $\\pm$ (0.841, 0.846)\",\"0.816 $\\pm$ (0.812, 0.819)\"\n\"1\",\"0.848 $\\pm$ (0.846, 0.851)\",\"0.824 $\\pm$ (0.82, 0.827)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.844 $\\pm$ (0.842, 0.847)\",\"0.817 $\\pm$ (0.814, 0.82)\"\n\"Food Stamps\",\"LightGBM\",\"0\",\"0.836 $\\pm$ (0.833, 0.838)\",\"0.808 $\\pm$ (0.805, 0.812)\"\n\"1\",\"0.844 $\\pm$ (0.841, 0.846)\",\"0.818 $\\pm$ (0.814, 0.821)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.843 $\\pm$ (0.84, 0.846)\",\"0.817 $\\pm$ (0.814, 0.821)\"\n\"\",\"MLP\",\"0\",\"0.844 $\\pm$ (0.842, 0.847)\",\"0.820 $\\pm$ (0.817, 0.824)\"\n\"1\",\"0.845 $\\pm$ (0.842, 0.847)\",\"0.817 $\\pm$ (0.814, 0.821)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.844 $\\pm$ (0.841, 0.846)\",\"0.811 $\\pm$ (0.808, 0.815)\"\n\"\",\"XGBoost\",\"0\",\"0.843 $\\pm$ (0.84, 0.845)\",\"0.819 $\\pm$ (0.815, 0.822)\"\n\"1\",\"0.845 $\\pm$ (0.842, 0.847)\",\"0.820 $\\pm$ (0.816, 0.823)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.670 $\\pm$ (0.665, 0.676)\",\"0.599 $\\pm$ (0.597, 0.6)\"\n\"\",\"CatBoost\",\"0\",\"0.671 $\\pm$ (0.665, 0.676)\",\"0.599 $\\pm$ (0.597, 0.6)\"\n\"1\",\"0.671 $\\pm$ (0.665, 0.676)\",\"0.599 $\\pm$ (0.597, 0.6)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.671 $\\pm$ (0.666, 0.677)\",\"0.600 $\\pm$ (0.598, 0.601)\"\n\"Hypertension\",\"LightGBM\",\"0\",\"0.678 $\\pm$ (0.672, 0.683)\",\"0.634 $\\pm$ (0.633, 0.635)\"\n\"1\",\"0.672 $\\pm$ (0.666, 0.677)\",\"0.636 $\\pm$ (0.635, 0.637)\",\"\",\"\"\n\"\",\"\",\"2\",\"0.672 $\\pm$ (0.667, 0.678)\",\"0.628 $\\pm$ (0.627, 0.629)\""}]}, {"page": 41, "text": "   Table 17: Hybrid method results. We compare Group DRO to standard ERM for the highest-\n   performing Transformer, tree-based, and baseline models in our study (FT-Transformer, NODE, and\n   ResNet, respectively) over fi\n                               ve TABLESHIFT tasks, following our hyperparameter tuning procedure.\n   There is little or no evidence that Group DRO reduces shift gaps for these models, indicating that\n   Group DRO may primarily improve weak (MLP) models but does not improve robustness for stronger\n   models. See Section E.5 for details on experimental design.\n                                                           ID Test Accuracy         OOD Test Accuracy\nTask                  Base Estimator     Method          Value    95% CI           Value    95% CI\n                      FT-Transformer     ERM             0.971    (0.961, 0.979)   0.920    (0.915, 0.925)\n                                         Group DRO       0.971    (0.961, 0.979)   0.920    (0.915, 0.925)\nChildhood Lead        NODE               ERM             0.971    (0.961, 0.979)   0.920    (0.915, 0.925)\n                                         Group DRO       0.971    (0.961, 0.979)   0.920    (0.915, 0.925)\n                      ResNet             ERM             0.971    (0.961, 0.979)   0.920    (0.915, 0.925)\n                                         Group DRO       0.971    (0.961, 0.979)   0.920    (0.915, 0.925)\n                      FT-Transformer     ERM             0.948    (0.944, 0.952)   0.859    (0.839, 0.877)\n                                         Group DRO       0.935    (0.93, 0.939)    0.815    (0.793, 0.835)\nCollege Scorecard     NODE               ERM             0.944    (0.939, 0.948)   0.844    (0.823, 0.863)\n                                         Group DRO       0.946    (0.942, 0.95)    0.835    (0.814, 0.854)\n                      ResNet             ERM             0.947    (0.943, 0.951)   0.854    (0.834, 0.872)\n                                         Group DRO       0.947    (0.942, 0.95)    0.824    (0.803, 0.844)\n                      FT-Transformer     ERM             0.843    (0.841, 0.846)   0.816    (0.812, 0.819)\n                                         Group DRO       0.826    (0.823, 0.829)   0.795    (0.792, 0.799)\nFood Stamps           NODE               ERM             0.849    (0.847, 0.852)   0.822    (0.819, 0.825)\n                                         Group DRO       0.845    (0.842, 0.847)   0.822    (0.819, 0.825)\n                      ResNet             ERM             0.843    (0.84, 0.845)    0.820    (0.817, 0.824)\n                                         Group DRO       0.848    (0.846, 0.851)   0.818    (0.815, 0.822)\n                      FT-Transformer     ERM             0.666    (0.661, 0.672)   0.604    (0.603, 0.605)\n                                         Group DRO       0.665    (0.659, 0.67)    0.608    (0.607, 0.609)\nHypertension          NODE               ERM             0.670    (0.664, 0.676)   0.597    (0.596, 0.599)\n                                         Group DRO       0.671    (0.665, 0.676)   0.592    (0.591, 0.593)\n                      ResNet             ERM             0.667    (0.661, 0.672)   0.608    (0.606, 0.609)\n                                         Group DRO       0.663    (0.658, 0.669)   0.590    (0.589, 0.592)\n                      FT-Transformer     ERM             0.879    (0.848, 0.906)   0.855    (0.841, 0.868)\n                                         Group DRO       0.894    (0.865, 0.919)   0.858    (0.844, 0.87)\nVoting                NODE               ERM             0.885    (0.854, 0.911)   0.851    (0.838, 0.864)\n                                         Group DRO       0.898    (0.869, 0.923)   0.860    (0.847, 0.873)\n                      ResNet             ERM             0.887    (0.856, 0.912)   0.836    (0.822, 0.849)\n                                         Group DRO       0.898    (0.869, 0.923)   0.847    (0.833, 0.861)\n                                                    41", "md": "|Task|Base Estimator|Method|ID Test Accuracy Value|ID Test Accuracy 95% CI|OOD Test Accuracy Value|OOD Test Accuracy 95% CI|\n|---|---|---|---|---|---|---|\n|Childhood Lead|FT-Transformer|ERM|0.971|(0.961, 0.979)|0.920|(0.915, 0.925)|\n| |FT-Transformer|Group DRO|0.971|(0.961, 0.979)|0.920|(0.915, 0.925)|\n|College Scorecard|NODE|ERM|0.944|(0.939, 0.948)|0.844|(0.823, 0.863)|\n|NODE| |Group DRO|0.946|(0.942, 0.95)|0.835|(0.814, 0.854)|\n|Food Stamps|ResNet|ERM|0.843|(0.84, 0.845)|0.820|(0.817, 0.824)|\n|ResNet| |Group DRO|0.848|(0.846, 0.851)|0.818|(0.815, 0.822)|\n|Hypertension|FT-Transformer|ERM|0.879|(0.848, 0.906)|0.855|(0.841, 0.868)|\n|FT-Transformer| |Group DRO|0.894|(0.865, 0.919)|0.858|(0.844, 0.87)|\n|Voting|ResNet|ERM|0.887|(0.856, 0.912)|0.836|(0.822, 0.849)|\n|ResNet| |Group DRO|0.898|(0.869, 0.923)|0.847|(0.833, 0.861)|", "images": [], "items": [{"type": "table", "rows": [["Task", "Base Estimator", "Method", "ID Test Accuracy Value", "ID Test Accuracy 95% CI", "OOD Test Accuracy Value", "OOD Test Accuracy 95% CI"], ["Childhood Lead", "FT-Transformer", "ERM", "0.971", "(0.961, 0.979)", "0.920", "(0.915, 0.925)"], ["", "FT-Transformer", "Group DRO", "0.971", "(0.961, 0.979)", "0.920", "(0.915, 0.925)"], ["College Scorecard", "NODE", "ERM", "0.944", "(0.939, 0.948)", "0.844", "(0.823, 0.863)"], ["NODE", "", "Group DRO", "0.946", "(0.942, 0.95)", "0.835", "(0.814, 0.854)"], ["Food Stamps", "ResNet", "ERM", "0.843", "(0.84, 0.845)", "0.820", "(0.817, 0.824)"], ["ResNet", "", "Group DRO", "0.848", "(0.846, 0.851)", "0.818", "(0.815, 0.822)"], ["Hypertension", "FT-Transformer", "ERM", "0.879", "(0.848, 0.906)", "0.855", "(0.841, 0.868)"], ["FT-Transformer", "", "Group DRO", "0.894", "(0.865, 0.919)", "0.858", "(0.844, 0.87)"], ["Voting", "ResNet", "ERM", "0.887", "(0.856, 0.912)", "0.836", "(0.822, 0.849)"], ["ResNet", "", "Group DRO", "0.898", "(0.869, 0.923)", "0.847", "(0.833, 0.861)"]], "md": "|Task|Base Estimator|Method|ID Test Accuracy Value|ID Test Accuracy 95% CI|OOD Test Accuracy Value|OOD Test Accuracy 95% CI|\n|---|---|---|---|---|---|---|\n|Childhood Lead|FT-Transformer|ERM|0.971|(0.961, 0.979)|0.920|(0.915, 0.925)|\n| |FT-Transformer|Group DRO|0.971|(0.961, 0.979)|0.920|(0.915, 0.925)|\n|College Scorecard|NODE|ERM|0.944|(0.939, 0.948)|0.844|(0.823, 0.863)|\n|NODE| |Group DRO|0.946|(0.942, 0.95)|0.835|(0.814, 0.854)|\n|Food Stamps|ResNet|ERM|0.843|(0.84, 0.845)|0.820|(0.817, 0.824)|\n|ResNet| |Group DRO|0.848|(0.846, 0.851)|0.818|(0.815, 0.822)|\n|Hypertension|FT-Transformer|ERM|0.879|(0.848, 0.906)|0.855|(0.841, 0.868)|\n|FT-Transformer| |Group DRO|0.894|(0.865, 0.919)|0.858|(0.844, 0.87)|\n|Voting|ResNet|ERM|0.887|(0.856, 0.912)|0.836|(0.822, 0.849)|\n|ResNet| |Group DRO|0.898|(0.869, 0.923)|0.847|(0.833, 0.861)|", "isPerfectTable": true, "csv": "\"Task\",\"Base Estimator\",\"Method\",\"ID Test Accuracy Value\",\"ID Test Accuracy 95% CI\",\"OOD Test Accuracy Value\",\"OOD Test Accuracy 95% CI\"\n\"Childhood Lead\",\"FT-Transformer\",\"ERM\",\"0.971\",\"(0.961, 0.979)\",\"0.920\",\"(0.915, 0.925)\"\n\"\",\"FT-Transformer\",\"Group DRO\",\"0.971\",\"(0.961, 0.979)\",\"0.920\",\"(0.915, 0.925)\"\n\"College Scorecard\",\"NODE\",\"ERM\",\"0.944\",\"(0.939, 0.948)\",\"0.844\",\"(0.823, 0.863)\"\n\"NODE\",\"\",\"Group DRO\",\"0.946\",\"(0.942, 0.95)\",\"0.835\",\"(0.814, 0.854)\"\n\"Food Stamps\",\"ResNet\",\"ERM\",\"0.843\",\"(0.84, 0.845)\",\"0.820\",\"(0.817, 0.824)\"\n\"ResNet\",\"\",\"Group DRO\",\"0.848\",\"(0.846, 0.851)\",\"0.818\",\"(0.815, 0.822)\"\n\"Hypertension\",\"FT-Transformer\",\"ERM\",\"0.879\",\"(0.848, 0.906)\",\"0.855\",\"(0.841, 0.868)\"\n\"FT-Transformer\",\"\",\"Group DRO\",\"0.894\",\"(0.865, 0.919)\",\"0.858\",\"(0.844, 0.87)\"\n\"Voting\",\"ResNet\",\"ERM\",\"0.887\",\"(0.856, 0.912)\",\"0.836\",\"(0.822, 0.849)\"\n\"ResNet\",\"\",\"Group DRO\",\"0.898\",\"(0.869, 0.923)\",\"0.847\",\"(0.833, 0.861)\""}]}, {"page": 42, "text": "F    Model Details\nThis section describes the models used in our study. For the hyperparameters used in our experiments,\nsee Section I.\nOur implementations of these models, along with associated code to train models with fixed\nhyperparameters or to tune hyperparameters at scale via the Ray framework, are available at\nhttps://github.com/mlfoundations/tableshift.\nF.1   Baseline Models\nXGBoost: XGBoost is a popular library for learning gradient-boosted trees. We use the original\nXGBoost implementation [20]. XGBoost introduced column subsampling, weight regularization,\nand introduced major improvements in effi     ciency for training gradient boosted models on large or\nout-of-core datasets.\nLightGBM: LightGBM is a library for learning gradient-boosted trees which extends the success\nof XGBoost in working fast and with large datasets [48]. LightGBM introduces novel techniques\nsuch as converting continuous features to histograms (for computational efficiency and for to reduce\noverfitting), combining certain features using Exclusive Feature Bundling (EFB), and through the use\nof Gradient-based One-Side Sampling (GOSS).\nCatBoost: CatBoost [25] is a library for learning gradient-boosted trees which includes novel\ntechniques for leveraging categorical features. This includes heuristics to replace numeric or one-hot\nencoding of categorical features with label-derived heuristics; \"appearance\" (count) features for\ncategorical features; and efficient greedy feature recombination techniques.\nMLP: We use standard multilayer perceptrons, via the implementation in RTDL29. MLPs have been\nshown to be highly effective models for tabuilar data, particularly when a large model search space is\nused and regularization is carefully tuned [46].\nF.2   Tabular Neural Networks\nFT-Transformer: FT-Transformer is a transformer-based model that learns separate feature tok-\nenizers for numeric and categorical data, and applies a transformer model [85] to the tokenized\nfeatures.\nTabular ResNet: We use the version of Tabular ResNet proposed in [36]. We note that, despite the\nfact that this approach is shown to have competitive performance with many existing tabular data\nmodels in [36], it has not been widely used in the literature.\nNODE Neural Oblivious Decision Ensembles (NODE) [70] is a method that leverages oblivious\nensembling methods to train \u201ctree-like\u201d neural networks.\nTabTransformer: TabTransformers [43] is a model that uses learned embeddings of categorical\nfeatures, which are then passed through standard Transformer layers, alongside layer normalization\nof continuous features.\nSAINT: SAINT [79] uses an enhanced embedding method for categorical features, alongside (op-\ntional) attention over both rows and columns, in a Transformer architecture. We note that, due to its\nuse of featurewise feedforward layers, SAINT was impractical to use for our datasets with the largest\nnumbers of features (ICU Hospital Mortality, ICU Length of Stay; both contain over 1000 features\nwhich resulted in over 13B parameters for even a single-layer SAINT model).\nF.3   Robustness Models\nDistributionally Robust Optimization (DRO): We use two variants of DRO, both via [53]. For\nboth methods, the model attempts to optimize a worst-care risk within a bounded distribution of the\ntraining data via a projected gradient descent procedure.\nGroup DRO: Originally introduced as a subgroup robustness method in [76], Group DRO is a DRO\nmethod which attempts to optimize the worst-group loss during training. Group DRO can also,\n   29\n    https://github.com/Yura52/rtdl\n                                                   42", "md": "# Model Details\n\n## Model Details\n\nThis section describes the models used in our study. For the hyperparameters used in our experiments, see Section I.\n\nOur implementations of these models, along with associated code to train models with fixed hyperparameters or to tune hyperparameters at scale via the Ray framework, are available at https://github.com/mlfoundations/tableshift.\n\n### Baseline Models\n\n- XGBoost: XGBoost is a popular library for learning gradient-boosted trees. We use the original XGBoost implementation [20]. XGBoost introduced column subsampling, weight regularization, and introduced major improvements in efficiency for training gradient boosted models on large or out-of-core datasets.\n- LightGBM: LightGBM is a library for learning gradient-boosted trees which extends the success of XGBoost in working fast and with large datasets [48]. LightGBM introduces novel techniques such as converting continuous features to histograms (for computational efficiency and for to reduce overfitting), combining certain features using Exclusive Feature Bundling (EFB), and through the use of Gradient-based One-Side Sampling (GOSS).\n- CatBoost: CatBoost [25] is a library for learning gradient-boosted trees which includes novel techniques for leveraging categorical features. This includes heuristics to replace numeric or one-hot encoding of categorical features with label-derived heuristics; \"appearance\" (count) features for categorical features; and efficient greedy feature recombination techniques.\n- MLP: We use standard multilayer perceptrons, via the implementation in RTDL29. MLPs have been shown to be highly effective models for tabular data, particularly when a large model search space is used and regularization is carefully tuned [46].\n\n### Tabular Neural Networks\n\n- FT-Transformer: FT-Transformer is a transformer-based model that learns separate feature tokenizers for numeric and categorical data, and applies a transformer model [85] to the tokenized features.\n- Tabular ResNet: We use the version of Tabular ResNet proposed in [36]. We note that, despite the fact that this approach is shown to have competitive performance with many existing tabular data models in [36], it has not been widely used in the literature.\n- NODE: Neural Oblivious Decision Ensembles (NODE) [70] is a method that leverages oblivious ensembling methods to train \u201ctree-like\u201d neural networks.\n- TabTransformer: TabTransformers [43] is a model that uses learned embeddings of categorical features, which are then passed through standard Transformer layers, alongside layer normalization of continuous features.\n- SAINT: SAINT [79] uses an enhanced embedding method for categorical features, alongside (optional) attention over both rows and columns, in a Transformer architecture. We note that, due to its use of featurewise feedforward layers, SAINT was impractical to use for our datasets with the largest numbers of features (ICU Hospital Mortality, ICU Length of Stay; both contain over 1000 features which resulted in over 13B parameters for even a single-layer SAINT model).\n\n### Robustness Models\n\n- Distributionally Robust Optimization (DRO): We use two variants of DRO, both via [53]. For both methods, the model attempts to optimize a worst-care risk within a bounded distribution of the training data via a projected gradient descent procedure.\n- Group DRO: Originally introduced as a subgroup robustness method in [76], Group DRO is a DRO method which attempts to optimize the worst-group loss during training. Group DRO can also.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Model Details", "md": "# Model Details"}, {"type": "heading", "lvl": 2, "value": "Model Details", "md": "## Model Details"}, {"type": "text", "value": "This section describes the models used in our study. For the hyperparameters used in our experiments, see Section I.\n\nOur implementations of these models, along with associated code to train models with fixed hyperparameters or to tune hyperparameters at scale via the Ray framework, are available at https://github.com/mlfoundations/tableshift.", "md": "This section describes the models used in our study. For the hyperparameters used in our experiments, see Section I.\n\nOur implementations of these models, along with associated code to train models with fixed hyperparameters or to tune hyperparameters at scale via the Ray framework, are available at https://github.com/mlfoundations/tableshift."}, {"type": "heading", "lvl": 3, "value": "Baseline Models", "md": "### Baseline Models"}, {"type": "text", "value": "- XGBoost: XGBoost is a popular library for learning gradient-boosted trees. We use the original XGBoost implementation [20]. XGBoost introduced column subsampling, weight regularization, and introduced major improvements in efficiency for training gradient boosted models on large or out-of-core datasets.\n- LightGBM: LightGBM is a library for learning gradient-boosted trees which extends the success of XGBoost in working fast and with large datasets [48]. LightGBM introduces novel techniques such as converting continuous features to histograms (for computational efficiency and for to reduce overfitting), combining certain features using Exclusive Feature Bundling (EFB), and through the use of Gradient-based One-Side Sampling (GOSS).\n- CatBoost: CatBoost [25] is a library for learning gradient-boosted trees which includes novel techniques for leveraging categorical features. This includes heuristics to replace numeric or one-hot encoding of categorical features with label-derived heuristics; \"appearance\" (count) features for categorical features; and efficient greedy feature recombination techniques.\n- MLP: We use standard multilayer perceptrons, via the implementation in RTDL29. MLPs have been shown to be highly effective models for tabular data, particularly when a large model search space is used and regularization is carefully tuned [46].", "md": "- XGBoost: XGBoost is a popular library for learning gradient-boosted trees. We use the original XGBoost implementation [20]. XGBoost introduced column subsampling, weight regularization, and introduced major improvements in efficiency for training gradient boosted models on large or out-of-core datasets.\n- LightGBM: LightGBM is a library for learning gradient-boosted trees which extends the success of XGBoost in working fast and with large datasets [48]. LightGBM introduces novel techniques such as converting continuous features to histograms (for computational efficiency and for to reduce overfitting), combining certain features using Exclusive Feature Bundling (EFB), and through the use of Gradient-based One-Side Sampling (GOSS).\n- CatBoost: CatBoost [25] is a library for learning gradient-boosted trees which includes novel techniques for leveraging categorical features. This includes heuristics to replace numeric or one-hot encoding of categorical features with label-derived heuristics; \"appearance\" (count) features for categorical features; and efficient greedy feature recombination techniques.\n- MLP: We use standard multilayer perceptrons, via the implementation in RTDL29. MLPs have been shown to be highly effective models for tabular data, particularly when a large model search space is used and regularization is carefully tuned [46]."}, {"type": "heading", "lvl": 3, "value": "Tabular Neural Networks", "md": "### Tabular Neural Networks"}, {"type": "text", "value": "- FT-Transformer: FT-Transformer is a transformer-based model that learns separate feature tokenizers for numeric and categorical data, and applies a transformer model [85] to the tokenized features.\n- Tabular ResNet: We use the version of Tabular ResNet proposed in [36]. We note that, despite the fact that this approach is shown to have competitive performance with many existing tabular data models in [36], it has not been widely used in the literature.\n- NODE: Neural Oblivious Decision Ensembles (NODE) [70] is a method that leverages oblivious ensembling methods to train \u201ctree-like\u201d neural networks.\n- TabTransformer: TabTransformers [43] is a model that uses learned embeddings of categorical features, which are then passed through standard Transformer layers, alongside layer normalization of continuous features.\n- SAINT: SAINT [79] uses an enhanced embedding method for categorical features, alongside (optional) attention over both rows and columns, in a Transformer architecture. We note that, due to its use of featurewise feedforward layers, SAINT was impractical to use for our datasets with the largest numbers of features (ICU Hospital Mortality, ICU Length of Stay; both contain over 1000 features which resulted in over 13B parameters for even a single-layer SAINT model).", "md": "- FT-Transformer: FT-Transformer is a transformer-based model that learns separate feature tokenizers for numeric and categorical data, and applies a transformer model [85] to the tokenized features.\n- Tabular ResNet: We use the version of Tabular ResNet proposed in [36]. We note that, despite the fact that this approach is shown to have competitive performance with many existing tabular data models in [36], it has not been widely used in the literature.\n- NODE: Neural Oblivious Decision Ensembles (NODE) [70] is a method that leverages oblivious ensembling methods to train \u201ctree-like\u201d neural networks.\n- TabTransformer: TabTransformers [43] is a model that uses learned embeddings of categorical features, which are then passed through standard Transformer layers, alongside layer normalization of continuous features.\n- SAINT: SAINT [79] uses an enhanced embedding method for categorical features, alongside (optional) attention over both rows and columns, in a Transformer architecture. We note that, due to its use of featurewise feedforward layers, SAINT was impractical to use for our datasets with the largest numbers of features (ICU Hospital Mortality, ICU Length of Stay; both contain over 1000 features which resulted in over 13B parameters for even a single-layer SAINT model)."}, {"type": "heading", "lvl": 3, "value": "Robustness Models", "md": "### Robustness Models"}, {"type": "text", "value": "- Distributionally Robust Optimization (DRO): We use two variants of DRO, both via [53]. For both methods, the model attempts to optimize a worst-care risk within a bounded distribution of the training data via a projected gradient descent procedure.\n- Group DRO: Originally introduced as a subgroup robustness method in [76], Group DRO is a DRO method which attempts to optimize the worst-group loss during training. Group DRO can also.", "md": "- Distributionally Robust Optimization (DRO): We use two variants of DRO, both via [53]. For both methods, the model attempts to optimize a worst-care risk within a bounded distribution of the training data via a projected gradient descent procedure.\n- Group DRO: Originally introduced as a subgroup robustness method in [76], Group DRO is a DRO method which attempts to optimize the worst-group loss during training. Group DRO can also."}]}, {"page": 43, "text": "however, be used as a domain robustness method by treating the domains as \u201cgroup labels\u201d, which is\nhow we use it in our study. We note that this use of Group DRO has been applied previously; e.g.\n[38].\nF.4   Domain Generalization Models\nInvariant Risk Minimization (IRM): IRM [6] uses a modified training objective to learn models\nwhich a feature representation such that the optimal linear classifier on top of that representation\nmatches across domains.\nMixUp: Inter-Domain MixUp [90, 89] uses combinations of data points from random pairs of\ndomains and their labels during training.\nDomain-Adversarial Neural Networks (DANN): DANN [1] uses adversarial training to achieve\ndomain robustness, where a discriminator attempts to predict the domain of a training example in\norder to match feature distributions across domains.\nRisk Extrapolation (REx): REx [52] attempts to reduce differences in risk across training domains,\nin order to reduce a model\u2019s sensitivity to distributional shifts.\nCORAL: CORAL (CORrelation ALignment) [82] attempts to ensure that feature activations are\nsimilar across domains; this can be used as either a domain generalization method or a domain\nadaptation method.\nMMD: Similar to CORAL using a different kernel, MMD attempts to minimize the Maximum Mean\nDiscrepancy (MMD) between domains.\nF.5   Label Shift Robustness Models\nGroup DRO: here, we use Group DRO [76] with class labels as the grouping attribute.\nAdversarial Label DRO: This method, proposed in [92], uses a distributionally robust objective\nto optimize for the worst-case weighting over label groupings. We note that this approach is\ncomputationally expensive, requiring sample-level gradients even following the authors\u2019 original\nimplementation, and so was not practical for our datasets with very large n (ASSISTments, Public\nHealth Insurance).\nG     Comparison To Other Benchmarking Toolkits\nIn this section, we provide a brief comparison of TableShift to other relevant benchmarking toolkits.\nWe note that our goal in this section is not to fully characterize the functionality of other benchmarking\nplatforms; it is only to compare and contrast their relevant attributes with TableShift and to motivate\nthe creation of a novel benchmark and API for TableShift (as opposed to incorporating TableShift\ninto an existing toolkit).\nAs noted above, there is no existing benchmark for domain shift in tabular data. However, in this\nsection we compare to three main categories of relevant related toolkits: (1) domain shift benchmarks\nfor non-tabular data (DomainBed, WILDS); (2) IID (non-domain-shift) benchmarks for tabular data\n([37], OpenML); and (3) generic data-hosting platforms (Huggingface Datasets, TensorFlow Datasets.\nWe briefly introduce and compare to each of these below.\nG.1    Domain Shift Benchmarks for Non-Tabular Data\nWILDS: WILDS30 is perhaps the closest benchmark to TableShift, but only uses non-tabular data.\nWILDS demonstrates a lightweight, useful set of programming abstractions for benchmarking models\nand sharing results across a diverse set of datasets for domain shift. WILDS interfaces with image\nand text datasets, and includes a rich variety of datasets with real-world sensitive attributes, carefully\nselected domain shifts, and has wide adoption in the robustness community. WILDS includes a\nhigh-quality Python API, which has led to wide integration with researchers\u2019 open-source code and\nwidespread adoption. However, WILDS is currently not compatible with tabular datasets and does not\n  30See https://wilds.stanford.edu/ and [50].\n                                                    43", "md": "## Domain Generalization Models\n\n- Invariant Risk Minimization (IRM): IRM [6] uses a modified training objective to learn models which a feature representation such that the optimal linear classifier on top of that representation matches across domains.\n- MixUp: Inter-Domain MixUp [90, 89] uses combinations of data points from random pairs of domains and their labels during training.\n- Domain-Adversarial Neural Networks (DANN): DANN [1] uses adversarial training to achieve domain robustness, where a discriminator attempts to predict the domain of a training example in order to match feature distributions across domains.\n- Risk Extrapolation (REx): REx [52] attempts to reduce differences in risk across training domains, in order to reduce a model\u2019s sensitivity to distributional shifts.\n- CORAL: CORAL (CORrelation ALignment) [82] attempts to ensure that feature activations are similar across domains; this can be used as either a domain generalization method or a domain adaptation method.\n- MMD: Similar to CORAL using a different kernel, MMD attempts to minimize the Maximum Mean Discrepancy (MMD) between domains.\n\n## Label Shift Robustness Models\n\n- Group DRO: here, we use Group DRO [76] with class labels as the grouping attribute.\n- Adversarial Label DRO: This method, proposed in [92], uses a distributionally robust objective to optimize for the worst-case weighting over label groupings. We note that this approach is computationally expensive, requiring sample-level gradients even following the authors\u2019 original implementation, and so was not practical for our datasets with very large n (ASSISTments, Public Health Insurance).\n\n## Comparison To Other Benchmarking Toolkits\n\nIn this section, we provide a brief comparison of TableShift to other relevant benchmarking toolkits. Our goal is to compare and contrast their relevant attributes with TableShift and to motivate the creation of a novel benchmark and API for TableShift.\n\nThere is no existing benchmark for domain shift in tabular data. However, in this section we compare to three main categories of relevant related toolkits:\n\n1. Domain Shift Benchmarks for Non-Tabular Data\n- WILDS: WILDS30 is perhaps the closest benchmark to TableShift, but only uses non-tabular data. WILDS demonstrates a lightweight, useful set of programming abstractions for benchmarking models and sharing results across a diverse set of datasets for domain shift. WILDS interfaces with image and text datasets, and includes a rich variety of datasets with real-world sensitive attributes, carefully selected domain shifts, and has wide adoption in the robustness community. WILDS includes a high-quality Python API, which has led to wide integration with researchers\u2019 open-source code and widespread adoption. However, WILDS is currently not compatible with tabular datasets and does not.", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "Domain Generalization Models", "md": "## Domain Generalization Models"}, {"type": "text", "value": "- Invariant Risk Minimization (IRM): IRM [6] uses a modified training objective to learn models which a feature representation such that the optimal linear classifier on top of that representation matches across domains.\n- MixUp: Inter-Domain MixUp [90, 89] uses combinations of data points from random pairs of domains and their labels during training.\n- Domain-Adversarial Neural Networks (DANN): DANN [1] uses adversarial training to achieve domain robustness, where a discriminator attempts to predict the domain of a training example in order to match feature distributions across domains.\n- Risk Extrapolation (REx): REx [52] attempts to reduce differences in risk across training domains, in order to reduce a model\u2019s sensitivity to distributional shifts.\n- CORAL: CORAL (CORrelation ALignment) [82] attempts to ensure that feature activations are similar across domains; this can be used as either a domain generalization method or a domain adaptation method.\n- MMD: Similar to CORAL using a different kernel, MMD attempts to minimize the Maximum Mean Discrepancy (MMD) between domains.", "md": "- Invariant Risk Minimization (IRM): IRM [6] uses a modified training objective to learn models which a feature representation such that the optimal linear classifier on top of that representation matches across domains.\n- MixUp: Inter-Domain MixUp [90, 89] uses combinations of data points from random pairs of domains and their labels during training.\n- Domain-Adversarial Neural Networks (DANN): DANN [1] uses adversarial training to achieve domain robustness, where a discriminator attempts to predict the domain of a training example in order to match feature distributions across domains.\n- Risk Extrapolation (REx): REx [52] attempts to reduce differences in risk across training domains, in order to reduce a model\u2019s sensitivity to distributional shifts.\n- CORAL: CORAL (CORrelation ALignment) [82] attempts to ensure that feature activations are similar across domains; this can be used as either a domain generalization method or a domain adaptation method.\n- MMD: Similar to CORAL using a different kernel, MMD attempts to minimize the Maximum Mean Discrepancy (MMD) between domains."}, {"type": "heading", "lvl": 2, "value": "Label Shift Robustness Models", "md": "## Label Shift Robustness Models"}, {"type": "text", "value": "- Group DRO: here, we use Group DRO [76] with class labels as the grouping attribute.\n- Adversarial Label DRO: This method, proposed in [92], uses a distributionally robust objective to optimize for the worst-case weighting over label groupings. We note that this approach is computationally expensive, requiring sample-level gradients even following the authors\u2019 original implementation, and so was not practical for our datasets with very large n (ASSISTments, Public Health Insurance).", "md": "- Group DRO: here, we use Group DRO [76] with class labels as the grouping attribute.\n- Adversarial Label DRO: This method, proposed in [92], uses a distributionally robust objective to optimize for the worst-case weighting over label groupings. We note that this approach is computationally expensive, requiring sample-level gradients even following the authors\u2019 original implementation, and so was not practical for our datasets with very large n (ASSISTments, Public Health Insurance)."}, {"type": "heading", "lvl": 2, "value": "Comparison To Other Benchmarking Toolkits", "md": "## Comparison To Other Benchmarking Toolkits"}, {"type": "text", "value": "In this section, we provide a brief comparison of TableShift to other relevant benchmarking toolkits. Our goal is to compare and contrast their relevant attributes with TableShift and to motivate the creation of a novel benchmark and API for TableShift.\n\nThere is no existing benchmark for domain shift in tabular data. However, in this section we compare to three main categories of relevant related toolkits:\n\n1. Domain Shift Benchmarks for Non-Tabular Data\n- WILDS: WILDS30 is perhaps the closest benchmark to TableShift, but only uses non-tabular data. WILDS demonstrates a lightweight, useful set of programming abstractions for benchmarking models and sharing results across a diverse set of datasets for domain shift. WILDS interfaces with image and text datasets, and includes a rich variety of datasets with real-world sensitive attributes, carefully selected domain shifts, and has wide adoption in the robustness community. WILDS includes a high-quality Python API, which has led to wide integration with researchers\u2019 open-source code and widespread adoption. However, WILDS is currently not compatible with tabular datasets and does not.", "md": "In this section, we provide a brief comparison of TableShift to other relevant benchmarking toolkits. Our goal is to compare and contrast their relevant attributes with TableShift and to motivate the creation of a novel benchmark and API for TableShift.\n\nThere is no existing benchmark for domain shift in tabular data. However, in this section we compare to three main categories of relevant related toolkits:\n\n1. Domain Shift Benchmarks for Non-Tabular Data\n- WILDS: WILDS30 is perhaps the closest benchmark to TableShift, but only uses non-tabular data. WILDS demonstrates a lightweight, useful set of programming abstractions for benchmarking models and sharing results across a diverse set of datasets for domain shift. WILDS interfaces with image and text datasets, and includes a rich variety of datasets with real-world sensitive attributes, carefully selected domain shifts, and has wide adoption in the robustness community. WILDS includes a high-quality Python API, which has led to wide integration with researchers\u2019 open-source code and widespread adoption. However, WILDS is currently not compatible with tabular datasets and does not."}]}, {"page": 44, "text": "include any tabular datasets in its benchmark suite. The needs for tabular datasets are different than\nthe datasets currently used in WILDS (i.e. non-Torch models must be supported by the benchmark;\nsubgroup and domain-shift information are handled differently for our use cases; data preprocessing\nis also different for tabular data as noted above).\nDomainBed: DomainBed31 is a benchmark that contains several reference implementations, includ-\ning some that have been adapted for use in TableShift. In addition to these model implementations,\nDomainBed serves as an interface to several existing datasets through a Python API. However,\nDomainBed is specifically adapted to image data. It only supports image datasets with a specific\nfolder structure (which would make extending to tabular datasets nontrivial) and includes many\nimage-specific augmentation components of its pipelines. It also uses ResNet50/ResNet18 networks\ndesigned specifically for image classification, and therefore does not currently support either deep\nlearning models suited to image data, nor (more importantly) the effective non-DL baselines described\nabove such as XGBoost and LightGBM.\nShift Happens: The \u201cshift happens\u201d benchmark32 is a community-built benchmark suite for image\nmodels. It specifically aims to feature datasets with domain shift, for tasks including image classifica-\ntion under domain shift, and out-of-distribution detection. The benchmark includes a Python API.\nThis benchmark does not support tabular datasets, and is much less widely used, perhaps due to the\ncommunity-driven effort (as opposed to benchmarks such as WILDS and DomainBed, which come\npackaged with preselected datasets and domain splits).\nShifts 2.0: Shifts ([57], recently upgraded to Shifts 2.0 [57]) is a collection of multimodal tasks with\ndomain shifts. The Shifts benchmark is a part of the Shifts Project, an international collaboration\nof academic and industrial researchers dedicated to studying distributional shift.33 Shifts 2.0, the\ncurrent version, includes fi ve tasks: tabular weather prediction, tabular marine cargo vessel power\nconsumption prediction, machine translation, self-driving car vehicle motion prediction, and seg-\nmentation of white matter Multiple Sclerosis lesions in 3D magnetic resonance brain images. While\nshifts does contain two tabular data tasks, its relatively small number of tasks makes it a less reliable\nbenchmark compared to the rich set of tabular datasets comprising TableShift. Shifts also does not\ninclude any tasks with real-world sensitive subgroups (such as age, race, or gender) which are of\nparticular interest in many tabular classification tasks. Additionally, the domains represented in the\ntabular tasks of Shifts do not cover many critical domains widely recognized as using tabular data\n(e.g. finance, medicine, etc.; see Section D.2).\nG.2    IID Benchmarks for Tabular Data\nBenchmark of [37]: The unnamed benchmark proposed in this work is intended to provide a\nconsistent benchmarking suite for tabular dataset classification tasks, and was motivated by some of\nthe same gaps described in this work. However, the datasets comprising the benchmark of [37] do\nnot meet our specifications, for several reasons. First, the datasets are limited to be of maximum size\n10k observations; this is too small for reliable and repeated benchmarking comparisons. Additionally,\nthe datasets are label-balanced; in contrast, we use the naturaly-occurring label distributions for\nall datasets (and we show that these label distributions are importantly related to shift gap). Most\ncritically, the benchmark datasets in [37] do not contain domain shifts; for most or all of the datasets,\nit is does not appear that a domain shift could be induced from splitting the existing data on an\nexisting feature.\nOpenML: OpenML has some overlap with the proposed functionality. However, OpenML both\nlacks functionality we seek to provide (subgroup robustness and domain shift utilities; a curated\nset of benchmarking datasets; lightweight and standardized control over common tabular prepro-\ncessing methods) and also provides extraneous functionality not needed for a lightweight tabular\nbenchmarking library (tools for OpenML-hosted model/pipeline/evaluation sharing and collaboration;\nAPI/utilities for model training) . Additionally, OpenML is not yet widely used in the tabular data\ncommunity, as demonstrated by the wide calls for effective tabular data benchmarking tools ([15],\n[37], [78]) and the lack of usage of OpenML in most robustness works, even recent works (e.g. [91]),\nwhich largely focus on canonical tabular datasets such as COMPAS and Adult.\n   31\n    See https://github.com/facebookresearch/DomainBed and [38].\n   32\n    https://shift-happens-benchmark.github.io/index.html\n   33\n    https://shifts.ai/\n                                                   44", "md": "include any tabular datasets in its benchmark suite. The needs for tabular datasets are different than\nthe datasets currently used in WILDS (i.e. non-Torch models must be supported by the benchmark;\nsubgroup and domain-shift information are handled differently for our use cases; data preprocessing\nis also different for tabular data as noted above).\n\nDomainBed: DomainBed$$^{31}$$ is a benchmark that contains several reference implementations, including some that have been adapted for use in TableShift. In addition to these model implementations, DomainBed serves as an interface to several existing datasets through a Python API. However, DomainBed is specifically adapted to image data. It only supports image datasets with a specific folder structure (which would make extending to tabular datasets nontrivial) and includes many image-specific augmentation components of its pipelines. It also uses ResNet50/ResNet18 networks designed specifically for image classification, and therefore does not currently support either deep learning models suited to image data, nor (more importantly) the effective non-DL baselines described above such as XGBoost and LightGBM.\n\nShift Happens: The \u201cshift happens\u201d benchmark$$^{32}$$ is a community-built benchmark suite for image models. It specifically aims to feature datasets with domain shift, for tasks including image classification under domain shift, and out-of-distribution detection. The benchmark includes a Python API. This benchmark does not support tabular datasets, and is much less widely used, perhaps due to the community-driven effort (as opposed to benchmarks such as WILDS and DomainBed, which come packaged with preselected datasets and domain splits).\n\nShifts 2.0: Shifts ([57], recently upgraded to Shifts 2.0 [57]) is a collection of multimodal tasks with domain shifts. The Shifts benchmark is a part of the Shifts Project, an international collaboration of academic and industrial researchers dedicated to studying distributional shift.$$^{33}$$ Shifts 2.0, the current version, includes five tasks: tabular weather prediction, tabular marine cargo vessel power consumption prediction, machine translation, self-driving car vehicle motion prediction, and segmentation of white matter Multiple Sclerosis lesions in 3D magnetic resonance brain images. While shifts does contain two tabular data tasks, its relatively small number of tasks makes it a less reliable benchmark compared to the rich set of tabular datasets comprising TableShift. Shifts also does not include any tasks with real-world sensitive subgroups (such as age, race, or gender) which are of particular interest in many tabular classification tasks. Additionally, the domains represented in the tabular tasks of Shifts do not cover many critical domains widely recognized as using tabular data (e.g. finance, medicine, etc.; see Section D.2).\n\nIID Benchmarks for Tabular Data\n\nBenchmark of [37]: The unnamed benchmark proposed in this work is intended to provide a consistent benchmarking suite for tabular dataset classification tasks, and was motivated by some of the same gaps described in this work. However, the datasets comprising the benchmark of [37] do not meet our specifications, for several reasons. First, the datasets are limited to be of maximum size 10k observations; this is too small for reliable and repeated benchmarking comparisons. Additionally, the datasets are label-balanced; in contrast, we use the naturaly-occurring label distributions for all datasets (and we show that these label distributions are importantly related to shift gap). Most critically, the benchmark datasets in [37] do not contain domain shifts; for most or all of the datasets, it is does not appear that a domain shift could be induced from splitting the existing data on an existing feature.\n\nOpenML: OpenML has some overlap with the proposed functionality. However, OpenML both lacks functionality we seek to provide (subgroup robustness and domain shift utilities; a curated set of benchmarking datasets; lightweight and standardized control over common tabular preprocessing methods) and also provides extraneous functionality not needed for a lightweight tabular benchmarking library (tools for OpenML-hosted model/pipeline/evaluation sharing and collaboration; API/utilities for model training). Additionally, OpenML is not yet widely used in the tabular data community, as demonstrated by the wide calls for effective tabular data benchmarking tools ([15], [37], [78]) and the lack of usage of OpenML in most robustness works, even recent works (e.g. [91]), which largely focus on canonical tabular datasets such as COMPAS and Adult.\n\n$$^{31}$$ See https://github.com/facebookresearch/DomainBed and [38].\n\n$$^{32}$$ https://shift-happens-benchmark.github.io/index.html\n\n$$^{33}$$ https://shifts.ai/", "images": [], "items": [{"type": "text", "value": "include any tabular datasets in its benchmark suite. The needs for tabular datasets are different than\nthe datasets currently used in WILDS (i.e. non-Torch models must be supported by the benchmark;\nsubgroup and domain-shift information are handled differently for our use cases; data preprocessing\nis also different for tabular data as noted above).\n\nDomainBed: DomainBed$$^{31}$$ is a benchmark that contains several reference implementations, including some that have been adapted for use in TableShift. In addition to these model implementations, DomainBed serves as an interface to several existing datasets through a Python API. However, DomainBed is specifically adapted to image data. It only supports image datasets with a specific folder structure (which would make extending to tabular datasets nontrivial) and includes many image-specific augmentation components of its pipelines. It also uses ResNet50/ResNet18 networks designed specifically for image classification, and therefore does not currently support either deep learning models suited to image data, nor (more importantly) the effective non-DL baselines described above such as XGBoost and LightGBM.\n\nShift Happens: The \u201cshift happens\u201d benchmark$$^{32}$$ is a community-built benchmark suite for image models. It specifically aims to feature datasets with domain shift, for tasks including image classification under domain shift, and out-of-distribution detection. The benchmark includes a Python API. This benchmark does not support tabular datasets, and is much less widely used, perhaps due to the community-driven effort (as opposed to benchmarks such as WILDS and DomainBed, which come packaged with preselected datasets and domain splits).\n\nShifts 2.0: Shifts ([57], recently upgraded to Shifts 2.0 [57]) is a collection of multimodal tasks with domain shifts. The Shifts benchmark is a part of the Shifts Project, an international collaboration of academic and industrial researchers dedicated to studying distributional shift.$$^{33}$$ Shifts 2.0, the current version, includes five tasks: tabular weather prediction, tabular marine cargo vessel power consumption prediction, machine translation, self-driving car vehicle motion prediction, and segmentation of white matter Multiple Sclerosis lesions in 3D magnetic resonance brain images. While shifts does contain two tabular data tasks, its relatively small number of tasks makes it a less reliable benchmark compared to the rich set of tabular datasets comprising TableShift. Shifts also does not include any tasks with real-world sensitive subgroups (such as age, race, or gender) which are of particular interest in many tabular classification tasks. Additionally, the domains represented in the tabular tasks of Shifts do not cover many critical domains widely recognized as using tabular data (e.g. finance, medicine, etc.; see Section D.2).\n\nIID Benchmarks for Tabular Data\n\nBenchmark of [37]: The unnamed benchmark proposed in this work is intended to provide a consistent benchmarking suite for tabular dataset classification tasks, and was motivated by some of the same gaps described in this work. However, the datasets comprising the benchmark of [37] do not meet our specifications, for several reasons. First, the datasets are limited to be of maximum size 10k observations; this is too small for reliable and repeated benchmarking comparisons. Additionally, the datasets are label-balanced; in contrast, we use the naturaly-occurring label distributions for all datasets (and we show that these label distributions are importantly related to shift gap). Most critically, the benchmark datasets in [37] do not contain domain shifts; for most or all of the datasets, it is does not appear that a domain shift could be induced from splitting the existing data on an existing feature.\n\nOpenML: OpenML has some overlap with the proposed functionality. However, OpenML both lacks functionality we seek to provide (subgroup robustness and domain shift utilities; a curated set of benchmarking datasets; lightweight and standardized control over common tabular preprocessing methods) and also provides extraneous functionality not needed for a lightweight tabular benchmarking library (tools for OpenML-hosted model/pipeline/evaluation sharing and collaboration; API/utilities for model training). Additionally, OpenML is not yet widely used in the tabular data community, as demonstrated by the wide calls for effective tabular data benchmarking tools ([15], [37], [78]) and the lack of usage of OpenML in most robustness works, even recent works (e.g. [91]), which largely focus on canonical tabular datasets such as COMPAS and Adult.\n\n$$^{31}$$ See https://github.com/facebookresearch/DomainBed and [38].\n\n$$^{32}$$ https://shift-happens-benchmark.github.io/index.html\n\n$$^{33}$$ https://shifts.ai/", "md": "include any tabular datasets in its benchmark suite. The needs for tabular datasets are different than\nthe datasets currently used in WILDS (i.e. non-Torch models must be supported by the benchmark;\nsubgroup and domain-shift information are handled differently for our use cases; data preprocessing\nis also different for tabular data as noted above).\n\nDomainBed: DomainBed$$^{31}$$ is a benchmark that contains several reference implementations, including some that have been adapted for use in TableShift. In addition to these model implementations, DomainBed serves as an interface to several existing datasets through a Python API. However, DomainBed is specifically adapted to image data. It only supports image datasets with a specific folder structure (which would make extending to tabular datasets nontrivial) and includes many image-specific augmentation components of its pipelines. It also uses ResNet50/ResNet18 networks designed specifically for image classification, and therefore does not currently support either deep learning models suited to image data, nor (more importantly) the effective non-DL baselines described above such as XGBoost and LightGBM.\n\nShift Happens: The \u201cshift happens\u201d benchmark$$^{32}$$ is a community-built benchmark suite for image models. It specifically aims to feature datasets with domain shift, for tasks including image classification under domain shift, and out-of-distribution detection. The benchmark includes a Python API. This benchmark does not support tabular datasets, and is much less widely used, perhaps due to the community-driven effort (as opposed to benchmarks such as WILDS and DomainBed, which come packaged with preselected datasets and domain splits).\n\nShifts 2.0: Shifts ([57], recently upgraded to Shifts 2.0 [57]) is a collection of multimodal tasks with domain shifts. The Shifts benchmark is a part of the Shifts Project, an international collaboration of academic and industrial researchers dedicated to studying distributional shift.$$^{33}$$ Shifts 2.0, the current version, includes five tasks: tabular weather prediction, tabular marine cargo vessel power consumption prediction, machine translation, self-driving car vehicle motion prediction, and segmentation of white matter Multiple Sclerosis lesions in 3D magnetic resonance brain images. While shifts does contain two tabular data tasks, its relatively small number of tasks makes it a less reliable benchmark compared to the rich set of tabular datasets comprising TableShift. Shifts also does not include any tasks with real-world sensitive subgroups (such as age, race, or gender) which are of particular interest in many tabular classification tasks. Additionally, the domains represented in the tabular tasks of Shifts do not cover many critical domains widely recognized as using tabular data (e.g. finance, medicine, etc.; see Section D.2).\n\nIID Benchmarks for Tabular Data\n\nBenchmark of [37]: The unnamed benchmark proposed in this work is intended to provide a consistent benchmarking suite for tabular dataset classification tasks, and was motivated by some of the same gaps described in this work. However, the datasets comprising the benchmark of [37] do not meet our specifications, for several reasons. First, the datasets are limited to be of maximum size 10k observations; this is too small for reliable and repeated benchmarking comparisons. Additionally, the datasets are label-balanced; in contrast, we use the naturaly-occurring label distributions for all datasets (and we show that these label distributions are importantly related to shift gap). Most critically, the benchmark datasets in [37] do not contain domain shifts; for most or all of the datasets, it is does not appear that a domain shift could be induced from splitting the existing data on an existing feature.\n\nOpenML: OpenML has some overlap with the proposed functionality. However, OpenML both lacks functionality we seek to provide (subgroup robustness and domain shift utilities; a curated set of benchmarking datasets; lightweight and standardized control over common tabular preprocessing methods) and also provides extraneous functionality not needed for a lightweight tabular benchmarking library (tools for OpenML-hosted model/pipeline/evaluation sharing and collaboration; API/utilities for model training). Additionally, OpenML is not yet widely used in the tabular data community, as demonstrated by the wide calls for effective tabular data benchmarking tools ([15], [37], [78]) and the lack of usage of OpenML in most robustness works, even recent works (e.g. [91]), which largely focus on canonical tabular datasets such as COMPAS and Adult.\n\n$$^{31}$$ See https://github.com/facebookresearch/DomainBed and [38].\n\n$$^{32}$$ https://shift-happens-benchmark.github.io/index.html\n\n$$^{33}$$ https://shifts.ai/"}]}, {"page": 45, "text": "            Table 18: Comparison of relevant benchmarks. DB: DomainBed. OML: OpenML. GOV22: [37].\n            SH: Shift Happens. HFDS: Hugging Face Datasets. TFDS: TensorFlow Datasets.\n                                                    DB       OML        GOV22         WILDS         SH      Shifts 2.0  HFDS   TFDS   TableShift\nOutput              Supports tabular data                      \u2713                                                 \u2713         \u2713      \u2713        \u2713\n                    input formats (e.g. .csv)\n                    Supports tabular output                                                                      \u2713         \u2713      \u2713        \u2713\n                    formats (e.g.\n                    pd.DataFrame)\n                    Support for                      \u2713                                   \u2713           \u2713                     \u2713      \u2713        \u2713\n                    large/out-of-core\n                    datasets\nPreprocessing Supports tabular                                                                                                             \u2713\n                    preprocessing:\n                    categorical encoding;\n                    missing value handling\n                    Provides shared utilities        \u2713                                   \u2713           \u2713                     \u2713      \u2713        \u2713\n                    for user-defined\n                    preprocessing per\n                    dataset\nMetadata            Feature-level metadata                                                                                                 \u2713\n                    Dataset-level metadata                                                                                 \u2713      \u2713        \u2713\nBenchmark           Includes domain shift            \u2713                                   \u2713           \u2713           \u2713       some              \u2713\nTasks               (non-IID) splits\n                    Meets criteria in \u00a73.1           \u2713                                   \u2713                                                 \u2713\n                    Large test sets (\u2265    10k)       \u2713                                               \u2713\n                    Includes                         \u2713         \u2713                         \u2713           \u2713           \u2713         \u2713      \u2713        \u2713\n                    label-imbalanced\n                    datasets\n                    Includes real-world                      some                        \u2713                               some   some       all\n                    sensitive attributes\n            DataPerf: DataPerf is \u201ca benchmark package for evaluating ML datasets and dataset working\n            algorithms\u201d [59]. Similar to WILDS and DomainBed, DataPerf covers many domains, not only\n            tabular data. DataPerf has a much broader set of goals relative to TableShift, and includes a collection\n            of tasks, metrics and rules that are intended to benchmark all stages of an ML pipeline, from raw data\n            to test set selection amd model selection. However, DataPerf does not offer domain shifts, and while\n            it is possible domain shifts could be integrated into DataPerf, it does not natively support the kind of\n            benchmarking that we intend to support with TableShift.\n            G.3     Other Data Hosting Platforms\n            Hugging Face Datasets (HFDS): HFDS is a generic dataset hosting utility provided by the company\n            Hugging Face. It serves as a large, open dataset repository; however, these datasets are not curated\n            for size, featurization, or quality. HFDS is a public platform where datasets can be contributed openly.\n            However, of the tabular datasets on HFDS, few if any meet the specifications described in \u00a73.1; in\n            particular, most are not domain shift datasets.\n            TensorFlow Datasets (TFDS): TFDS is similar in many ways to HFDS. It is a public, open\n            repository of datasets, and new datasets can be contributed via git. However, TFDS also has the same\n            shortcomings as HFDS; in particular, its open format leads to a collection of datasets mostly not\n            useful for tabular data benchmarking and almost no datasets with meaningful distribution shifts.\n            H      Training Details\n            Neural network-based models were trained on GPU, either NVIDIA RTX 2080 Ti GPUs with 11GB\n            of RAM, or NVIDIA Tesla M60 GPUs with 48 GB of RAM. We used a batch size of 4096 for training\n            all models, except where this was not possible due to memory limitations (see code for details).\n                                                                            45", "md": "|DB|OML|GOV22|WILDS|SH|Shifts 2.0|HFDS|TFDS|TableShift|\n|---|---|---|---|---|---|---|---|---|\n|Supports tabular data input formats (e.g. .csv)|\u2713| | | | |\u2713|\u2713|\u2713|\n|Supports tabular output formats (e.g. pd.DataFrame)| | | | |\u2713|\u2713|\u2713|\u2713|\n|Support for large/out-of-core datasets|\u2713| |\u2713| | |\u2713|\u2713|\u2713|\n|Supports tabular preprocessing: categorical encoding; missing value handling| | | | | | | |\u2713|\n|Provides shared utilities for user-defined preprocessing per dataset|\u2713| |\u2713| | |\u2713|\u2713|\u2713|\n|Feature-level metadata| | | | | | | |\u2713|\n|Dataset-level metadata| |\u2713| | | |\u2713|\u2713|\u2713|\n|Includes domain shift (non-IID) splits|\u2713|\u2713|\u2713|\u2713|\u2713|\u2713|\u2713|\u2713|\n|Meets criteria in \u00a73.1|\u2713|\u2713| | | | | |\u2713|\n|Large test sets (\u2265 10k)|\u2713| |\u2713| | | | | |\n|Includes label-imbalanced datasets|\u2713| |\u2713|\u2713|\u2713|\u2713|\u2713|\u2713|\n|Includes real-world sensitive attributes| |some|\u2713| |\u2713|some|some|all|\n\nDataPerf: DataPerf is \"a benchmark package for evaluating ML datasets and dataset working algorithms\" [59]. Similar to WILDS and DomainBed, DataPerf covers many domains, not only tabular data. DataPerf has a much broader set of goals relative to TableShift, and includes a collection of tasks, metrics and rules that are intended to benchmark all stages of an ML pipeline, from raw data to test set selection and model selection. However, DataPerf does not offer domain shifts, and while it is possible domain shifts could be integrated into DataPerf, it does not natively support the kind of benchmarking that we intend to support with TableShift.\n\nOther Data Hosting Platforms\n\n- Hugging Face Datasets (HFDS): HFDS is a generic dataset hosting utility provided by the company Hugging Face. It serves as a large, open dataset repository; however, these datasets are not curated for size, featurization, or quality. HFDS is a public platform where datasets can be contributed openly. However, of the tabular datasets on HFDS, few if any meet the specifications described in \u00a73.1; in particular, most are not domain shift datasets.\n- TensorFlow Datasets (TFDS): TFDS is similar in many ways to HFDS. It is a public, open repository of datasets, and new datasets can be contributed via git. However, TFDS also has the same shortcomings as HFDS; in particular, its open format leads to a collection of datasets mostly not useful for tabular data benchmarking and almost no datasets with meaningful distribution shifts.\n\nTraining Details\n\nNeural network-based models were trained on GPU, either NVIDIA RTX 2080 Ti GPUs with 11GB of RAM, or NVIDIA Tesla M60 GPUs with 48 GB of RAM. We used a batch size of 4096 for training all models, except where this was not possible due to memory limitations (see code for details).\n\n45", "images": [], "items": [{"type": "table", "rows": [["DB", "OML", "GOV22", "WILDS", "SH", "Shifts 2.0", "HFDS", "TFDS", "TableShift"], ["Supports tabular data input formats (e.g. .csv)", "\u2713", "", "", "", "", "\u2713", "\u2713", "\u2713"], ["Supports tabular output formats (e.g. pd.DataFrame)", "", "", "", "", "\u2713", "\u2713", "\u2713", "\u2713"], ["Support for large/out-of-core datasets", "\u2713", "", "\u2713", "", "", "\u2713", "\u2713", "\u2713"], ["Supports tabular preprocessing: categorical encoding; missing value handling", "", "", "", "", "", "", "", "\u2713"], ["Provides shared utilities for user-defined preprocessing per dataset", "\u2713", "", "\u2713", "", "", "\u2713", "\u2713", "\u2713"], ["Feature-level metadata", "", "", "", "", "", "", "", "\u2713"], ["Dataset-level metadata", "", "\u2713", "", "", "", "\u2713", "\u2713", "\u2713"], ["Includes domain shift (non-IID) splits", "\u2713", "\u2713", "\u2713", "\u2713", "\u2713", "\u2713", "\u2713", "\u2713"], ["Meets criteria in \u00a73.1", "\u2713", "\u2713", "", "", "", "", "", "\u2713"], ["Large test sets (\u2265 10k)", "\u2713", "", "\u2713", "", "", "", "", ""], ["Includes label-imbalanced datasets", "\u2713", "", "\u2713", "\u2713", "\u2713", "\u2713", "\u2713", "\u2713"], ["Includes real-world sensitive attributes", "", "some", "\u2713", "", "\u2713", "some", "some", "all"]], "md": "|DB|OML|GOV22|WILDS|SH|Shifts 2.0|HFDS|TFDS|TableShift|\n|---|---|---|---|---|---|---|---|---|\n|Supports tabular data input formats (e.g. .csv)|\u2713| | | | |\u2713|\u2713|\u2713|\n|Supports tabular output formats (e.g. pd.DataFrame)| | | | |\u2713|\u2713|\u2713|\u2713|\n|Support for large/out-of-core datasets|\u2713| |\u2713| | |\u2713|\u2713|\u2713|\n|Supports tabular preprocessing: categorical encoding; missing value handling| | | | | | | |\u2713|\n|Provides shared utilities for user-defined preprocessing per dataset|\u2713| |\u2713| | |\u2713|\u2713|\u2713|\n|Feature-level metadata| | | | | | | |\u2713|\n|Dataset-level metadata| |\u2713| | | |\u2713|\u2713|\u2713|\n|Includes domain shift (non-IID) splits|\u2713|\u2713|\u2713|\u2713|\u2713|\u2713|\u2713|\u2713|\n|Meets criteria in \u00a73.1|\u2713|\u2713| | | | | |\u2713|\n|Large test sets (\u2265 10k)|\u2713| |\u2713| | | | | |\n|Includes label-imbalanced datasets|\u2713| |\u2713|\u2713|\u2713|\u2713|\u2713|\u2713|\n|Includes real-world sensitive attributes| |some|\u2713| |\u2713|some|some|all|", "isPerfectTable": true, "csv": "\"DB\",\"OML\",\"GOV22\",\"WILDS\",\"SH\",\"Shifts 2.0\",\"HFDS\",\"TFDS\",\"TableShift\"\n\"Supports tabular data input formats (e.g. .csv)\",\"\u2713\",\"\",\"\",\"\",\"\",\"\u2713\",\"\u2713\",\"\u2713\"\n\"Supports tabular output formats (e.g. pd.DataFrame)\",\"\",\"\",\"\",\"\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\"\n\"Support for large/out-of-core datasets\",\"\u2713\",\"\",\"\u2713\",\"\",\"\",\"\u2713\",\"\u2713\",\"\u2713\"\n\"Supports tabular preprocessing: categorical encoding; missing value handling\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\u2713\"\n\"Provides shared utilities for user-defined preprocessing per dataset\",\"\u2713\",\"\",\"\u2713\",\"\",\"\",\"\u2713\",\"\u2713\",\"\u2713\"\n\"Feature-level metadata\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\u2713\"\n\"Dataset-level metadata\",\"\",\"\u2713\",\"\",\"\",\"\",\"\u2713\",\"\u2713\",\"\u2713\"\n\"Includes domain shift (non-IID) splits\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\"\n\"Meets criteria in \u00a73.1\",\"\u2713\",\"\u2713\",\"\",\"\",\"\",\"\",\"\",\"\u2713\"\n\"Large test sets (\u2265 10k)\",\"\u2713\",\"\",\"\u2713\",\"\",\"\",\"\",\"\",\"\"\n\"Includes label-imbalanced datasets\",\"\u2713\",\"\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\",\"\u2713\"\n\"Includes real-world sensitive attributes\",\"\",\"some\",\"\u2713\",\"\",\"\u2713\",\"some\",\"some\",\"all\""}, {"type": "text", "value": "DataPerf: DataPerf is \"a benchmark package for evaluating ML datasets and dataset working algorithms\" [59]. Similar to WILDS and DomainBed, DataPerf covers many domains, not only tabular data. DataPerf has a much broader set of goals relative to TableShift, and includes a collection of tasks, metrics and rules that are intended to benchmark all stages of an ML pipeline, from raw data to test set selection and model selection. However, DataPerf does not offer domain shifts, and while it is possible domain shifts could be integrated into DataPerf, it does not natively support the kind of benchmarking that we intend to support with TableShift.\n\nOther Data Hosting Platforms\n\n- Hugging Face Datasets (HFDS): HFDS is a generic dataset hosting utility provided by the company Hugging Face. It serves as a large, open dataset repository; however, these datasets are not curated for size, featurization, or quality. HFDS is a public platform where datasets can be contributed openly. However, of the tabular datasets on HFDS, few if any meet the specifications described in \u00a73.1; in particular, most are not domain shift datasets.\n- TensorFlow Datasets (TFDS): TFDS is similar in many ways to HFDS. It is a public, open repository of datasets, and new datasets can be contributed via git. However, TFDS also has the same shortcomings as HFDS; in particular, its open format leads to a collection of datasets mostly not useful for tabular data benchmarking and almost no datasets with meaningful distribution shifts.\n\nTraining Details\n\nNeural network-based models were trained on GPU, either NVIDIA RTX 2080 Ti GPUs with 11GB of RAM, or NVIDIA Tesla M60 GPUs with 48 GB of RAM. We used a batch size of 4096 for training all models, except where this was not possible due to memory limitations (see code for details).\n\n45", "md": "DataPerf: DataPerf is \"a benchmark package for evaluating ML datasets and dataset working algorithms\" [59]. Similar to WILDS and DomainBed, DataPerf covers many domains, not only tabular data. DataPerf has a much broader set of goals relative to TableShift, and includes a collection of tasks, metrics and rules that are intended to benchmark all stages of an ML pipeline, from raw data to test set selection and model selection. However, DataPerf does not offer domain shifts, and while it is possible domain shifts could be integrated into DataPerf, it does not natively support the kind of benchmarking that we intend to support with TableShift.\n\nOther Data Hosting Platforms\n\n- Hugging Face Datasets (HFDS): HFDS is a generic dataset hosting utility provided by the company Hugging Face. It serves as a large, open dataset repository; however, these datasets are not curated for size, featurization, or quality. HFDS is a public platform where datasets can be contributed openly. However, of the tabular datasets on HFDS, few if any meet the specifications described in \u00a73.1; in particular, most are not domain shift datasets.\n- TensorFlow Datasets (TFDS): TFDS is similar in many ways to HFDS. It is a public, open repository of datasets, and new datasets can be contributed via git. However, TFDS also has the same shortcomings as HFDS; in particular, its open format leads to a collection of datasets mostly not useful for tabular data benchmarking and almost no datasets with meaningful distribution shifts.\n\nTraining Details\n\nNeural network-based models were trained on GPU, either NVIDIA RTX 2080 Ti GPUs with 11GB of RAM, or NVIDIA Tesla M60 GPUs with 48 GB of RAM. We used a batch size of 4096 for training all models, except where this was not possible due to memory limitations (see code for details).\n\n45"}]}, {"page": 46, "text": "Where possible, gradient boosted tree models were trained using CPU (not GPU).\n I   Hyperparameter Grids\n The hyperparameter tuning grid for each model is shown in Table 19. We make the full hyperparameter\n tuning code available as part of the release of this work, at https://github.com/mlfoundations/\n tableshift.\nWe made an effort to ensure our hyperparameter grids always included at least the full grid described\n in the original work(s) cited for each learning method used in our study. For some methods, our grid\n is a superset of the hyperparameter grid in the original study. This is to ensure, where possible, that\nwe tune a similar range of certain parameters (i.e. learning rate) across all methods. For domain\n generalization methods, since we are not aware of any prior application to these methods to tabular\n data, we use the hyperparameter grids from [38].\n                                                   46", "md": "# Hyperparameter Grids\n\nWhere possible, gradient boosted tree models were trained using CPU (not GPU).\n\n## Hyperparameter Grids\n\nThe hyperparameter tuning grid for each model is shown in Table 19. We make the full hyperparameter tuning code available as part of the release of this work, at https://github.com/mlfoundations/tableshift.\n\nWe made an effort to ensure our hyperparameter grids always included at least the full grid described in the original work(s) cited for each learning method used in our study. For some methods, our grid is a superset of the hyperparameter grid in the original study. This is to ensure, where possible, that we tune a similar range of certain parameters (i.e. learning rate) across all methods. For domain generalization methods, since we are not aware of any prior application to these methods to tabular data, we use the hyperparameter grids from [38].\n\n**Table 19: Hyperparameter Grid**\n|Learning Method|Hyperparameter Grid|\n|---|---|\n|Method 1|$\\text{Grid definition for Method 1}$|\n|Method 2|$\\text{Grid definition for Method 2}$|\n|Method 3|$\\text{Grid definition for Method 3}$|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Hyperparameter Grids", "md": "# Hyperparameter Grids"}, {"type": "text", "value": "Where possible, gradient boosted tree models were trained using CPU (not GPU).", "md": "Where possible, gradient boosted tree models were trained using CPU (not GPU)."}, {"type": "heading", "lvl": 2, "value": "Hyperparameter Grids", "md": "## Hyperparameter Grids"}, {"type": "text", "value": "The hyperparameter tuning grid for each model is shown in Table 19. We make the full hyperparameter tuning code available as part of the release of this work, at https://github.com/mlfoundations/tableshift.\n\nWe made an effort to ensure our hyperparameter grids always included at least the full grid described in the original work(s) cited for each learning method used in our study. For some methods, our grid is a superset of the hyperparameter grid in the original study. This is to ensure, where possible, that we tune a similar range of certain parameters (i.e. learning rate) across all methods. For domain generalization methods, since we are not aware of any prior application to these methods to tabular data, we use the hyperparameter grids from [38].\n\n**Table 19: Hyperparameter Grid**", "md": "The hyperparameter tuning grid for each model is shown in Table 19. We make the full hyperparameter tuning code available as part of the release of this work, at https://github.com/mlfoundations/tableshift.\n\nWe made an effort to ensure our hyperparameter grids always included at least the full grid described in the original work(s) cited for each learning method used in our study. For some methods, our grid is a superset of the hyperparameter grid in the original study. This is to ensure, where possible, that we tune a similar range of certain parameters (i.e. learning rate) across all methods. For domain generalization methods, since we are not aware of any prior application to these methods to tabular data, we use the hyperparameter grids from [38].\n\n**Table 19: Hyperparameter Grid**"}, {"type": "table", "rows": [["Learning Method", "Hyperparameter Grid"], ["Method 1", "$\\text{Grid definition for Method 1}$"], ["Method 2", "$\\text{Grid definition for Method 2}$"], ["Method 3", "$\\text{Grid definition for Method 3}$"]], "md": "|Learning Method|Hyperparameter Grid|\n|---|---|\n|Method 1|$\\text{Grid definition for Method 1}$|\n|Method 2|$\\text{Grid definition for Method 2}$|\n|Method 3|$\\text{Grid definition for Method 3}$|", "isPerfectTable": true, "csv": "\"Learning Method\",\"Hyperparameter Grid\"\n\"Method 1\",\"$\\text{Grid definition for Method 1}$\"\n\"Method 2\",\"$\\text{Grid definition for Method 2}$\"\n\"Method 3\",\"$\\text{Grid definition for Method 3}$\""}]}, {"page": 47, "text": "Table 19: Hyperparameter grids used in all experiments. \u2663: all MLP parameters also tuned. Continued\nin Table 20.\n                    Model                  Hyperparameter                          Values\n                                                           Baseline Methods\n                                           Learning Rate                           LogUniform(1e\u22125, 1e\u22121)\n                                           Weight Decay                            LogUniform(1e\u22126, 1)\n                                           Num. Layers                             {1, 2, . . . , 8}\n                    \u2663   MLP                Hidden Units                            {64, 128, 256, 512, 1024}\n                                           Num Epochs                              QRandInt(5, 100, 5)\n                                           Dropout                                 Unif(0, 0.5)\n                                           Batch Size                              {4096}\n                                           Learning Rate                           LogUniform{1e \u2212          5, 1}\n                                           Max. Depth                              {3, . . . , 10}\n                                           Min Child Weight                        LogUniform{1e \u2212          8, 1e5}\n                    XGBoost                Row Subsample                           Uniform{0.5, 1.}\n                                           Column Subsample (Tree)                 Uniform{0.5, 1.}\n                                           Column Subsample (Level)                Uniform{0.5, 1.}\n                                           \u03b3                                       LogUniform{1e \u2212          8, 1e2}\n                                           \u03bb                                       LogUniform{1e \u2212          8, 1e2}\n                                           \u03b1                                       LogUniform{1e \u2212          8, 1e2}\n                                           Max. Bins                               {128, 256, 512}\n                                           Learning Rate                           LogUniform{1e \u2212          5, 1}\n                                           Min. Child Samples                      {1, 2, 4, 8, 16, 32, 64}\n                    LightGBM               Min. Child Weight                       LogUniform (1e \u2212         8, 1e5)\n                                           Row Subsample                           Uniform{0.5, 1.}\n                                           Max. Depth                              {None, 1, 2, . . . , 31}\n                                           Column Subsample (Tree)                 Uniform{0.5, 1.}\n                                           Column Subsample (Level)                Uniform{0.5, 1.}\n                                           \u03bb                                       LogUniform{1e \u2212          8, 1e2}\n                                           \u03b1                                       LogUniform{1e \u2212          8, 1e2}\n                                           Learning Rate                           LogUniform{1e \u2212          3, 1}\n                                           Depth                                   QRandInt{3, 10}\n                    CatBoost               Bagging Temp.                           LogUniform (1e \u2212         6, 1)\n                                           L2 Leaf Reg.                            LogUniform (1, 100)\n                                           Leaf Estimation Iterations              QRandInt{1, 10}\n                                                Domain Generalization Methods\n                                           LRG                                     LogUniform{1e \u2212          5, 1e \u2212  1}\n                                           WeightDecay      G                      LogUniform{1e \u2212          6, 1}\n                                           LRd                                     LogUniform{1e \u2212          5, 1e \u2212  1}\n                    DANN \u2663                 WeightDecayD                            LogUniform{1e \u2212          6, 1}\n                                           D steps per G step                      LogUniform{2, 23}\n                                           Grad Penalty                            LogUniform{1e \u2212          2, 1e1}\n                                           Loss \u03bb                                  LogUniform{1e \u2212          2, 1e2}\n                                           IRM \u03bb                                   LogUniform{1e \u2212          1, 1e5}\n                    IRM \u2663                  IRM Penalty Anneal Iters                LogUniform{1, 1e4}\n                    MixUp \u2663                MixUp \u03b1                                 Uniform{1e \u2212       1, 1e1}\n                                           VReX \u03bb                                  LogUniform{1e \u2212          1, 1e5}\n                    VReX \u2663                 VReX Penalty Anneal Iters               LogUniform{1, 1e4}\n                    CORAL \u2663                MMD \u03b3                                   LogUniform{1e \u2212          1, 1e1}\n                    MMD \u2663                  MMD \u03b3                                   Uniform{1e \u2212       1, 1e1}\n                                                                     47", "md": "|Model|Hyperparameter|Values|\n|---|---|---|\n|Baseline Methods|Learning Rate|$\\text{LogUniform}(1e^{-5}, 1e^{-1})$|\n| |Weight Decay|$\\text{LogUniform}(1e^{-6}, 1)$|\n| |Num. Layers|{1, 2, ..., 8}|\n|MLP|Hidden Units|{64, 128, 256, 512, 1024}|\n| |Num Epochs|$\\text{QRandInt}(5, 100, 5)$|\n| |Dropout|$\\text{Unif}(0, 0.5)$|\n| |Batch Size|{4096}|\n| |Learning Rate|$\\text{LogUniform}(1e^{-5}, 1)$|\n| |Max. Depth|{3, ..., 10}|\n| |Min Child Weight|$\\text{LogUniform}(1e^{-8}, 1e5)$|\n|XGBoost|Row Subsample|$\\text{Uniform}(0.5, 1.)$|\n| |Column Subsample (Tree)|$\\text{Uniform}(0.5, 1.)$|\n| |Column Subsample (Level)|$\\text{Uniform}(0.5, 1.)$|\n| |\u03b3|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |\u03bb|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |\u03b1|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |Max. Bins|{128, 256, 512}|\n| |Learning Rate|$\\text{LogUniform}(1e^{-5}, 1)$|\n| |Min. Child Samples|{1, 2, 4, 8, 16, 32, 64}|\n|LightGBM|Min. Child Weight|$\\text{LogUniform}(1e^{-8}, 1e5)$|\n| |Row Subsample|$\\text{Uniform}(0.5, 1.)$|\n| |Max. Depth|{None, 1, 2, ..., 31}|\n| |Column Subsample (Tree)|$\\text{Uniform}(0.5, 1.)$|\n| |Column Subsample (Level)|$\\text{Uniform}(0.5, 1.)$|\n| |\u03bb|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |\u03b1|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |Learning Rate|$\\text{LogUniform}(1e^{-3}, 1)$|\n| |Depth|$\\text{QRandInt}(3, 10)$|\n|CatBoost|Bagging Temp.|$\\text{LogUniform}(1e^{-6}, 1)$|\n| |L2 Leaf Reg.|$\\text{LogUniform}(1, 100)$|\n| |Leaf Estimation Iterations|$\\text{QRandInt}(1, 10)$|\n|Domain Generalization Methods|LRG|$\\text{LogUniform}(1e^{-5}, 1e^{-1})$|\n| |WeightDecay G|$\\text{LogUniform}(1e^{-6}, 1)$|\n| |LRd|$\\text{LogUniform}(1e^{-5}, 1e^{-1})$|\n|DANN|WeightDecayD|$\\text{LogUniform}(1e^{-6}, 1)$|\n| |D steps per G step|$\\text{LogUniform}(2, 23)$|\n| |Grad Penalty|$\\text{LogUniform}(1e^{-2}, 1e1)$|\n| |Loss \u03bb|$\\text{LogUniform}(1e^{-2}, 1e2)$|\n| |IRM \u03bb|$\\text{LogUniform}(1e^{-1}, 1e5)$|\n|IRM|IRM Penalty Anneal Iters|$\\text{LogUniform}(1, 1e4)$|\n|MixUp|MixUp \u03b1|$\\text{Uniform}(1e^{-1}, 1e1)$|\n| |VReX \u03bb|$\\text{LogUniform}(1e^{-1}, 1e5)$|\n|VReX|VReX Penalty Anneal Iters|$\\text{LogUniform}(1, 1e4)$|\n|CORAL|MMD \u03b3|$\\text{LogUniform}(1e^{-1}, 1e1)$|\n|MMD|MMD \u03b3|$\\text{Uniform}(1e^{-1}, 1e1)$|", "images": [], "items": [{"type": "table", "rows": [["Model", "Hyperparameter", "Values"], ["Baseline Methods", "Learning Rate", "$\\text{LogUniform}(1e^{-5}, 1e^{-1})$"], ["", "Weight Decay", "$\\text{LogUniform}(1e^{-6}, 1)$"], ["", "Num. Layers", "{1, 2, ..., 8}"], ["MLP", "Hidden Units", "{64, 128, 256, 512, 1024}"], ["", "Num Epochs", "$\\text{QRandInt}(5, 100, 5)$"], ["", "Dropout", "$\\text{Unif}(0, 0.5)$"], ["", "Batch Size", "{4096}"], ["", "Learning Rate", "$\\text{LogUniform}(1e^{-5}, 1)$"], ["", "Max. Depth", "{3, ..., 10}"], ["", "Min Child Weight", "$\\text{LogUniform}(1e^{-8}, 1e5)$"], ["XGBoost", "Row Subsample", "$\\text{Uniform}(0.5, 1.)$"], ["", "Column Subsample (Tree)", "$\\text{Uniform}(0.5, 1.)$"], ["", "Column Subsample (Level)", "$\\text{Uniform}(0.5, 1.)$"], ["", "\u03b3", "$\\text{LogUniform}(1e^{-8}, 1e2)$"], ["", "\u03bb", "$\\text{LogUniform}(1e^{-8}, 1e2)$"], ["", "\u03b1", "$\\text{LogUniform}(1e^{-8}, 1e2)$"], ["", "Max. Bins", "{128, 256, 512}"], ["", "Learning Rate", "$\\text{LogUniform}(1e^{-5}, 1)$"], ["", "Min. Child Samples", "{1, 2, 4, 8, 16, 32, 64}"], ["LightGBM", "Min. Child Weight", "$\\text{LogUniform}(1e^{-8}, 1e5)$"], ["", "Row Subsample", "$\\text{Uniform}(0.5, 1.)$"], ["", "Max. Depth", "{None, 1, 2, ..., 31}"], ["", "Column Subsample (Tree)", "$\\text{Uniform}(0.5, 1.)$"], ["", "Column Subsample (Level)", "$\\text{Uniform}(0.5, 1.)$"], ["", "\u03bb", "$\\text{LogUniform}(1e^{-8}, 1e2)$"], ["", "\u03b1", "$\\text{LogUniform}(1e^{-8}, 1e2)$"], ["", "Learning Rate", "$\\text{LogUniform}(1e^{-3}, 1)$"], ["", "Depth", "$\\text{QRandInt}(3, 10)$"], ["CatBoost", "Bagging Temp.", "$\\text{LogUniform}(1e^{-6}, 1)$"], ["", "L2 Leaf Reg.", "$\\text{LogUniform}(1, 100)$"], ["", "Leaf Estimation Iterations", "$\\text{QRandInt}(1, 10)$"], ["Domain Generalization Methods", "LRG", "$\\text{LogUniform}(1e^{-5}, 1e^{-1})$"], ["", "WeightDecay G", "$\\text{LogUniform}(1e^{-6}, 1)$"], ["", "LRd", "$\\text{LogUniform}(1e^{-5}, 1e^{-1})$"], ["DANN", "WeightDecayD", "$\\text{LogUniform}(1e^{-6}, 1)$"], ["", "D steps per G step", "$\\text{LogUniform}(2, 23)$"], ["", "Grad Penalty", "$\\text{LogUniform}(1e^{-2}, 1e1)$"], ["", "Loss \u03bb", "$\\text{LogUniform}(1e^{-2}, 1e2)$"], ["", "IRM \u03bb", "$\\text{LogUniform}(1e^{-1}, 1e5)$"], ["IRM", "IRM Penalty Anneal Iters", "$\\text{LogUniform}(1, 1e4)$"], ["MixUp", "MixUp \u03b1", "$\\text{Uniform}(1e^{-1}, 1e1)$"], ["", "VReX \u03bb", "$\\text{LogUniform}(1e^{-1}, 1e5)$"], ["VReX", "VReX Penalty Anneal Iters", "$\\text{LogUniform}(1, 1e4)$"], ["CORAL", "MMD \u03b3", "$\\text{LogUniform}(1e^{-1}, 1e1)$"], ["MMD", "MMD \u03b3", "$\\text{Uniform}(1e^{-1}, 1e1)$"]], "md": "|Model|Hyperparameter|Values|\n|---|---|---|\n|Baseline Methods|Learning Rate|$\\text{LogUniform}(1e^{-5}, 1e^{-1})$|\n| |Weight Decay|$\\text{LogUniform}(1e^{-6}, 1)$|\n| |Num. Layers|{1, 2, ..., 8}|\n|MLP|Hidden Units|{64, 128, 256, 512, 1024}|\n| |Num Epochs|$\\text{QRandInt}(5, 100, 5)$|\n| |Dropout|$\\text{Unif}(0, 0.5)$|\n| |Batch Size|{4096}|\n| |Learning Rate|$\\text{LogUniform}(1e^{-5}, 1)$|\n| |Max. Depth|{3, ..., 10}|\n| |Min Child Weight|$\\text{LogUniform}(1e^{-8}, 1e5)$|\n|XGBoost|Row Subsample|$\\text{Uniform}(0.5, 1.)$|\n| |Column Subsample (Tree)|$\\text{Uniform}(0.5, 1.)$|\n| |Column Subsample (Level)|$\\text{Uniform}(0.5, 1.)$|\n| |\u03b3|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |\u03bb|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |\u03b1|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |Max. Bins|{128, 256, 512}|\n| |Learning Rate|$\\text{LogUniform}(1e^{-5}, 1)$|\n| |Min. Child Samples|{1, 2, 4, 8, 16, 32, 64}|\n|LightGBM|Min. Child Weight|$\\text{LogUniform}(1e^{-8}, 1e5)$|\n| |Row Subsample|$\\text{Uniform}(0.5, 1.)$|\n| |Max. Depth|{None, 1, 2, ..., 31}|\n| |Column Subsample (Tree)|$\\text{Uniform}(0.5, 1.)$|\n| |Column Subsample (Level)|$\\text{Uniform}(0.5, 1.)$|\n| |\u03bb|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |\u03b1|$\\text{LogUniform}(1e^{-8}, 1e2)$|\n| |Learning Rate|$\\text{LogUniform}(1e^{-3}, 1)$|\n| |Depth|$\\text{QRandInt}(3, 10)$|\n|CatBoost|Bagging Temp.|$\\text{LogUniform}(1e^{-6}, 1)$|\n| |L2 Leaf Reg.|$\\text{LogUniform}(1, 100)$|\n| |Leaf Estimation Iterations|$\\text{QRandInt}(1, 10)$|\n|Domain Generalization Methods|LRG|$\\text{LogUniform}(1e^{-5}, 1e^{-1})$|\n| |WeightDecay G|$\\text{LogUniform}(1e^{-6}, 1)$|\n| |LRd|$\\text{LogUniform}(1e^{-5}, 1e^{-1})$|\n|DANN|WeightDecayD|$\\text{LogUniform}(1e^{-6}, 1)$|\n| |D steps per G step|$\\text{LogUniform}(2, 23)$|\n| |Grad Penalty|$\\text{LogUniform}(1e^{-2}, 1e1)$|\n| |Loss \u03bb|$\\text{LogUniform}(1e^{-2}, 1e2)$|\n| |IRM \u03bb|$\\text{LogUniform}(1e^{-1}, 1e5)$|\n|IRM|IRM Penalty Anneal Iters|$\\text{LogUniform}(1, 1e4)$|\n|MixUp|MixUp \u03b1|$\\text{Uniform}(1e^{-1}, 1e1)$|\n| |VReX \u03bb|$\\text{LogUniform}(1e^{-1}, 1e5)$|\n|VReX|VReX Penalty Anneal Iters|$\\text{LogUniform}(1, 1e4)$|\n|CORAL|MMD \u03b3|$\\text{LogUniform}(1e^{-1}, 1e1)$|\n|MMD|MMD \u03b3|$\\text{Uniform}(1e^{-1}, 1e1)$|", "isPerfectTable": true, "csv": "\"Model\",\"Hyperparameter\",\"Values\"\n\"Baseline Methods\",\"Learning Rate\",\"$\\text{LogUniform}(1e^{-5}, 1e^{-1})$\"\n\"\",\"Weight Decay\",\"$\\text{LogUniform}(1e^{-6}, 1)$\"\n\"\",\"Num. Layers\",\"{1, 2, ..., 8}\"\n\"MLP\",\"Hidden Units\",\"{64, 128, 256, 512, 1024}\"\n\"\",\"Num Epochs\",\"$\\text{QRandInt}(5, 100, 5)$\"\n\"\",\"Dropout\",\"$\\text{Unif}(0, 0.5)$\"\n\"\",\"Batch Size\",\"{4096}\"\n\"\",\"Learning Rate\",\"$\\text{LogUniform}(1e^{-5}, 1)$\"\n\"\",\"Max. Depth\",\"{3, ..., 10}\"\n\"\",\"Min Child Weight\",\"$\\text{LogUniform}(1e^{-8}, 1e5)$\"\n\"XGBoost\",\"Row Subsample\",\"$\\text{Uniform}(0.5, 1.)$\"\n\"\",\"Column Subsample (Tree)\",\"$\\text{Uniform}(0.5, 1.)$\"\n\"\",\"Column Subsample (Level)\",\"$\\text{Uniform}(0.5, 1.)$\"\n\"\",\"\u03b3\",\"$\\text{LogUniform}(1e^{-8}, 1e2)$\"\n\"\",\"\u03bb\",\"$\\text{LogUniform}(1e^{-8}, 1e2)$\"\n\"\",\"\u03b1\",\"$\\text{LogUniform}(1e^{-8}, 1e2)$\"\n\"\",\"Max. Bins\",\"{128, 256, 512}\"\n\"\",\"Learning Rate\",\"$\\text{LogUniform}(1e^{-5}, 1)$\"\n\"\",\"Min. Child Samples\",\"{1, 2, 4, 8, 16, 32, 64}\"\n\"LightGBM\",\"Min. Child Weight\",\"$\\text{LogUniform}(1e^{-8}, 1e5)$\"\n\"\",\"Row Subsample\",\"$\\text{Uniform}(0.5, 1.)$\"\n\"\",\"Max. Depth\",\"{None, 1, 2, ..., 31}\"\n\"\",\"Column Subsample (Tree)\",\"$\\text{Uniform}(0.5, 1.)$\"\n\"\",\"Column Subsample (Level)\",\"$\\text{Uniform}(0.5, 1.)$\"\n\"\",\"\u03bb\",\"$\\text{LogUniform}(1e^{-8}, 1e2)$\"\n\"\",\"\u03b1\",\"$\\text{LogUniform}(1e^{-8}, 1e2)$\"\n\"\",\"Learning Rate\",\"$\\text{LogUniform}(1e^{-3}, 1)$\"\n\"\",\"Depth\",\"$\\text{QRandInt}(3, 10)$\"\n\"CatBoost\",\"Bagging Temp.\",\"$\\text{LogUniform}(1e^{-6}, 1)$\"\n\"\",\"L2 Leaf Reg.\",\"$\\text{LogUniform}(1, 100)$\"\n\"\",\"Leaf Estimation Iterations\",\"$\\text{QRandInt}(1, 10)$\"\n\"Domain Generalization Methods\",\"LRG\",\"$\\text{LogUniform}(1e^{-5}, 1e^{-1})$\"\n\"\",\"WeightDecay G\",\"$\\text{LogUniform}(1e^{-6}, 1)$\"\n\"\",\"LRd\",\"$\\text{LogUniform}(1e^{-5}, 1e^{-1})$\"\n\"DANN\",\"WeightDecayD\",\"$\\text{LogUniform}(1e^{-6}, 1)$\"\n\"\",\"D steps per G step\",\"$\\text{LogUniform}(2, 23)$\"\n\"\",\"Grad Penalty\",\"$\\text{LogUniform}(1e^{-2}, 1e1)$\"\n\"\",\"Loss \u03bb\",\"$\\text{LogUniform}(1e^{-2}, 1e2)$\"\n\"\",\"IRM \u03bb\",\"$\\text{LogUniform}(1e^{-1}, 1e5)$\"\n\"IRM\",\"IRM Penalty Anneal Iters\",\"$\\text{LogUniform}(1, 1e4)$\"\n\"MixUp\",\"MixUp \u03b1\",\"$\\text{Uniform}(1e^{-1}, 1e1)$\"\n\"\",\"VReX \u03bb\",\"$\\text{LogUniform}(1e^{-1}, 1e5)$\"\n\"VReX\",\"VReX Penalty Anneal Iters\",\"$\\text{LogUniform}(1, 1e4)$\"\n\"CORAL\",\"MMD \u03b3\",\"$\\text{LogUniform}(1e^{-1}, 1e1)$\"\n\"MMD\",\"MMD \u03b3\",\"$\\text{Uniform}(1e^{-1}, 1e1)$\""}]}, {"page": 48, "text": "           Model                                  Hyperparameter                  Values\n                                                Tabular Neural Networks\n                                                  Num. Blocks                     {1, 2, 3, 4}\n                                                  d main                          RandInt(64, 1024)\n                                                  Hidden Factor                   RandInt(1, 4)\n           ResNet \u2663                               Dropout First                   Uniform(0, 0.5)\n                                                  Dropout Second                  Uniform(0, 0.5)\n                                                  Num. Blocks                     {1, 2, 3, 4}\n                                                  Residual Dropout                Uniform(0, 0.2)\n                                                  Attention Dropout               Uniform(0, 0.5)\n           FT-Transformer \u2663                       FFN Dropout                     Uniform(0, 0.5)\n                                                  FFN Factor                      Uniform(2/3, 8/3)\n                                                  FFN Factor                      {64, 128, 256, 512}\n                                                  Num. Blocks                     {1, 2, 3, 4}\n                                                  Learning Rate                   LogUniform(1e\u22125, 1e\u22121)\n           TabTransformer                         Weight Decay                    LogUniform(1e\u22126, 1)\n                                                  Num Epochs                      QRandInt(5, 100, 5)\n                                                  FFN Dropout                     Uniform(0, 0.5)\n                                                  Attention Dropout               Uniform(0, 0.5)\n                                                  Model Dimension                 32, 64, 128, 256\n                                                  Depth                           3, 4, 5, 6\n                                                  Num. Heads                      2, 4, 8\n                                                  Num. Epochs                     {1, 2, 3, 4, 5}\n                                                  Num. Layers                     2, 4, 8\n           NODE                                   Total Tree Count                1024, 2048\n                                                  Tree Depth                      6, 8\n                                                  Tree Output Dim.                2, 3\n                                                  FFN Factor                      {64, 128, 256, 512}\n                                                  Learning Rate                   LogUniform(1e\u22125, 1e\u22121)\n                                                  Weight Decay                    LogUniform(1e\u22126, 1)\n                                                  Num. Epochs                     {1, 2, 3, 4, 5}\n                                                  Depth                           4, 6\n                                                  Model Dimension                 4, 8, 12, 16, 32\n           SAINT                                  Learning Rate                   LogUniform(1e\u22125, 1e\u22121)\n                                                  Weight Decay                    LogUniform(1e\u22126, 1)\n                                                  FFN Dropout                     Uniform(0.1, 0.8)\n                                                  Heads                           4, 8\n                                                  Attention Type                  Row, Col, RowCol\n                                              Domain Robustness Methods\n           DRO \u2663                                  Uncertainty set size            LogUniform{1e \u2212        4, 1.}\n                                                  Geometry                        { CVaR, \u03c72}\n           Group DRO \u2663                            Group weights step size         LogUniform(1e\u22124, 1}\n                                            Label Shift Robustness Methods\n           Label Group DRO \u2663                      Group weights step size         LogUniform(1e\u22124, 1}\n                                                  Adv. Learning Rate \u03b7\u03c0           LogUniform{1e \u2212        4, 1e \u2212  1}\n           Adversarial Label DRO \u2663                Adv. radius r                   LogUniform{1e \u2212        5, 0.5}\n                                                  Clip max r                      LogUniform{1e \u2212        1, 10}\n                                                  \u03f5                               LogUniform{1e \u2212        4, 1e \u2212  1}\nTable 20: Hyperparameter grids used in all experiments. \u2663: all MLP parameters also tuned. Continued\nfrom Table 19.\n                                                               48", "md": "|Model|Hyperparameter|Values|\n|---|---|---|\n|Tabular Neural Networks|Num. Blocks|$\\{1, 2, 3, 4\\}$|\n| |d main|$RandInt(64, 1024)$|\n| |Hidden Factor|$RandInt(1, 4)$|\n|ResNet|Dropout First|$Uniform(0, 0.5)$|\n| |Dropout Second|$Uniform(0, 0.5)$|\n| |Num. Blocks|$\\{1, 2, 3, 4\\}$|\n| |Residual Dropout|$Uniform(0, 0.2)$|\n| |Attention Dropout|$Uniform(0, 0.5)$|\n|FT-Transformer|FFN Dropout|$Uniform(0, 0.5)$|\n| |FFN Factor|$Uniform(2/3, 8/3)$|\n| |FFN Factor|$\\{64, 128, 256, 512\\}$|\n| |Num. Blocks|$\\{1, 2, 3, 4\\}$|\n| |Learning Rate|$LogUniform(1e^{-5}, 1e^{-1})$|\n|TabTransformer|Weight Decay|$LogUniform(1e^{-6}, 1)$|\n| |Num Epochs|$QRandInt(5, 100, 5)$|\n| |FFN Dropout|$Uniform(0, 0.5)$|\n| |Attention Dropout|$Uniform(0, 0.5)$|\n| |Model Dimension|$32, 64, 128, 256$|\n| |Depth|$3, 4, 5, 6$|\n| |Num. Heads|$2, 4, 8$|\n| |Num. Epochs|$\\{1, 2, 3, 4, 5\\}$|\n| |Num. Layers|$2, 4, 8$|\n|NODE|Total Tree Count|$1024, 2048$|\n| |Tree Depth|$6, 8$|\n| |Tree Output Dim.|$2, 3$|\n| |FFN Factor|$\\{64, 128, 256, 512\\}$|\n| |Learning Rate|$LogUniform(1e^{-5}, 1e^{-1})$|\n| |Weight Decay|$LogUniform(1e^{-6}, 1)$|\n| |Num. Epochs|$\\{1, 2, 3, 4, 5\\}$|\n| |Depth|$4, 6$|\n| |Model Dimension|$4, 8, 12, 16, 32$|\n|SAINT|Learning Rate|$LogUniform(1e^{-5}, 1e^{-1})$|\n| |Weight Decay|$LogUniform(1e^{-6}, 1)$|\n| |FFN Dropout|$Uniform(0.1, 0.8)$|\n| |Heads|$4, 8$|\n| |Attention Type|$Row, Col, RowCol$|\n|DRO|Uncertainty set size|$LogUniform\\{1e^{-4}, 1\\}$|\n| |Geometry|$\\{CVaR, \\chi^2\\}$|\n|Group DRO|Group weights step size|$LogUniform(1e^{-4}, 1)$|\n|Label Group DRO|Group weights step size|$LogUniform(1e^{-4}, 1)$|\n| |Adv. Learning Rate \u03b7\u03c0|$LogUniform\\{1e^{-4}, 1e^{-1}\\}$|\n|Adversarial Label DRO|Adv. radius r|$LogUniform\\{1e^{-5}, 0.5\\}$|\n| |Clip max r|$LogUniform\\{1e^{-1}, 10\\}$|\n|$\\epsilon$|$LogUniform\\{1e^{-4}, 1e^{-1}\\}$| |", "images": [], "items": [{"type": "table", "rows": [["Model", "Hyperparameter", "Values"], ["Tabular Neural Networks", "Num. Blocks", "$\\{1, 2, 3, 4\\}$"], ["", "d main", "$RandInt(64, 1024)$"], ["", "Hidden Factor", "$RandInt(1, 4)$"], ["ResNet", "Dropout First", "$Uniform(0, 0.5)$"], ["", "Dropout Second", "$Uniform(0, 0.5)$"], ["", "Num. Blocks", "$\\{1, 2, 3, 4\\}$"], ["", "Residual Dropout", "$Uniform(0, 0.2)$"], ["", "Attention Dropout", "$Uniform(0, 0.5)$"], ["FT-Transformer", "FFN Dropout", "$Uniform(0, 0.5)$"], ["", "FFN Factor", "$Uniform(2/3, 8/3)$"], ["", "FFN Factor", "$\\{64, 128, 256, 512\\}$"], ["", "Num. Blocks", "$\\{1, 2, 3, 4\\}$"], ["", "Learning Rate", "$LogUniform(1e^{-5}, 1e^{-1})$"], ["TabTransformer", "Weight Decay", "$LogUniform(1e^{-6}, 1)$"], ["", "Num Epochs", "$QRandInt(5, 100, 5)$"], ["", "FFN Dropout", "$Uniform(0, 0.5)$"], ["", "Attention Dropout", "$Uniform(0, 0.5)$"], ["", "Model Dimension", "$32, 64, 128, 256$"], ["", "Depth", "$3, 4, 5, 6$"], ["", "Num. Heads", "$2, 4, 8$"], ["", "Num. Epochs", "$\\{1, 2, 3, 4, 5\\}$"], ["", "Num. Layers", "$2, 4, 8$"], ["NODE", "Total Tree Count", "$1024, 2048$"], ["", "Tree Depth", "$6, 8$"], ["", "Tree Output Dim.", "$2, 3$"], ["", "FFN Factor", "$\\{64, 128, 256, 512\\}$"], ["", "Learning Rate", "$LogUniform(1e^{-5}, 1e^{-1})$"], ["", "Weight Decay", "$LogUniform(1e^{-6}, 1)$"], ["", "Num. Epochs", "$\\{1, 2, 3, 4, 5\\}$"], ["", "Depth", "$4, 6$"], ["", "Model Dimension", "$4, 8, 12, 16, 32$"], ["SAINT", "Learning Rate", "$LogUniform(1e^{-5}, 1e^{-1})$"], ["", "Weight Decay", "$LogUniform(1e^{-6}, 1)$"], ["", "FFN Dropout", "$Uniform(0.1, 0.8)$"], ["", "Heads", "$4, 8$"], ["", "Attention Type", "$Row, Col, RowCol$"], ["DRO", "Uncertainty set size", "$LogUniform\\{1e^{-4}, 1\\}$"], ["", "Geometry", "$\\{CVaR, \\chi^2\\}$"], ["Group DRO", "Group weights step size", "$LogUniform(1e^{-4}, 1)$"], ["Label Group DRO", "Group weights step size", "$LogUniform(1e^{-4}, 1)$"], ["", "Adv. Learning Rate \u03b7\u03c0", "$LogUniform\\{1e^{-4}, 1e^{-1}\\}$"], ["Adversarial Label DRO", "Adv. radius r", "$LogUniform\\{1e^{-5}, 0.5\\}$"], ["", "Clip max r", "$LogUniform\\{1e^{-1}, 10\\}$"], ["$\\epsilon$", "$LogUniform\\{1e^{-4}, 1e^{-1}\\}$", ""]], "md": "|Model|Hyperparameter|Values|\n|---|---|---|\n|Tabular Neural Networks|Num. Blocks|$\\{1, 2, 3, 4\\}$|\n| |d main|$RandInt(64, 1024)$|\n| |Hidden Factor|$RandInt(1, 4)$|\n|ResNet|Dropout First|$Uniform(0, 0.5)$|\n| |Dropout Second|$Uniform(0, 0.5)$|\n| |Num. Blocks|$\\{1, 2, 3, 4\\}$|\n| |Residual Dropout|$Uniform(0, 0.2)$|\n| |Attention Dropout|$Uniform(0, 0.5)$|\n|FT-Transformer|FFN Dropout|$Uniform(0, 0.5)$|\n| |FFN Factor|$Uniform(2/3, 8/3)$|\n| |FFN Factor|$\\{64, 128, 256, 512\\}$|\n| |Num. Blocks|$\\{1, 2, 3, 4\\}$|\n| |Learning Rate|$LogUniform(1e^{-5}, 1e^{-1})$|\n|TabTransformer|Weight Decay|$LogUniform(1e^{-6}, 1)$|\n| |Num Epochs|$QRandInt(5, 100, 5)$|\n| |FFN Dropout|$Uniform(0, 0.5)$|\n| |Attention Dropout|$Uniform(0, 0.5)$|\n| |Model Dimension|$32, 64, 128, 256$|\n| |Depth|$3, 4, 5, 6$|\n| |Num. Heads|$2, 4, 8$|\n| |Num. Epochs|$\\{1, 2, 3, 4, 5\\}$|\n| |Num. Layers|$2, 4, 8$|\n|NODE|Total Tree Count|$1024, 2048$|\n| |Tree Depth|$6, 8$|\n| |Tree Output Dim.|$2, 3$|\n| |FFN Factor|$\\{64, 128, 256, 512\\}$|\n| |Learning Rate|$LogUniform(1e^{-5}, 1e^{-1})$|\n| |Weight Decay|$LogUniform(1e^{-6}, 1)$|\n| |Num. Epochs|$\\{1, 2, 3, 4, 5\\}$|\n| |Depth|$4, 6$|\n| |Model Dimension|$4, 8, 12, 16, 32$|\n|SAINT|Learning Rate|$LogUniform(1e^{-5}, 1e^{-1})$|\n| |Weight Decay|$LogUniform(1e^{-6}, 1)$|\n| |FFN Dropout|$Uniform(0.1, 0.8)$|\n| |Heads|$4, 8$|\n| |Attention Type|$Row, Col, RowCol$|\n|DRO|Uncertainty set size|$LogUniform\\{1e^{-4}, 1\\}$|\n| |Geometry|$\\{CVaR, \\chi^2\\}$|\n|Group DRO|Group weights step size|$LogUniform(1e^{-4}, 1)$|\n|Label Group DRO|Group weights step size|$LogUniform(1e^{-4}, 1)$|\n| |Adv. Learning Rate \u03b7\u03c0|$LogUniform\\{1e^{-4}, 1e^{-1}\\}$|\n|Adversarial Label DRO|Adv. radius r|$LogUniform\\{1e^{-5}, 0.5\\}$|\n| |Clip max r|$LogUniform\\{1e^{-1}, 10\\}$|\n|$\\epsilon$|$LogUniform\\{1e^{-4}, 1e^{-1}\\}$| |", "isPerfectTable": true, "csv": "\"Model\",\"Hyperparameter\",\"Values\"\n\"Tabular Neural Networks\",\"Num. Blocks\",\"$\\{1, 2, 3, 4\\}$\"\n\"\",\"d main\",\"$RandInt(64, 1024)$\"\n\"\",\"Hidden Factor\",\"$RandInt(1, 4)$\"\n\"ResNet\",\"Dropout First\",\"$Uniform(0, 0.5)$\"\n\"\",\"Dropout Second\",\"$Uniform(0, 0.5)$\"\n\"\",\"Num. Blocks\",\"$\\{1, 2, 3, 4\\}$\"\n\"\",\"Residual Dropout\",\"$Uniform(0, 0.2)$\"\n\"\",\"Attention Dropout\",\"$Uniform(0, 0.5)$\"\n\"FT-Transformer\",\"FFN Dropout\",\"$Uniform(0, 0.5)$\"\n\"\",\"FFN Factor\",\"$Uniform(2/3, 8/3)$\"\n\"\",\"FFN Factor\",\"$\\{64, 128, 256, 512\\}$\"\n\"\",\"Num. Blocks\",\"$\\{1, 2, 3, 4\\}$\"\n\"\",\"Learning Rate\",\"$LogUniform(1e^{-5}, 1e^{-1})$\"\n\"TabTransformer\",\"Weight Decay\",\"$LogUniform(1e^{-6}, 1)$\"\n\"\",\"Num Epochs\",\"$QRandInt(5, 100, 5)$\"\n\"\",\"FFN Dropout\",\"$Uniform(0, 0.5)$\"\n\"\",\"Attention Dropout\",\"$Uniform(0, 0.5)$\"\n\"\",\"Model Dimension\",\"$32, 64, 128, 256$\"\n\"\",\"Depth\",\"$3, 4, 5, 6$\"\n\"\",\"Num. Heads\",\"$2, 4, 8$\"\n\"\",\"Num. Epochs\",\"$\\{1, 2, 3, 4, 5\\}$\"\n\"\",\"Num. Layers\",\"$2, 4, 8$\"\n\"NODE\",\"Total Tree Count\",\"$1024, 2048$\"\n\"\",\"Tree Depth\",\"$6, 8$\"\n\"\",\"Tree Output Dim.\",\"$2, 3$\"\n\"\",\"FFN Factor\",\"$\\{64, 128, 256, 512\\}$\"\n\"\",\"Learning Rate\",\"$LogUniform(1e^{-5}, 1e^{-1})$\"\n\"\",\"Weight Decay\",\"$LogUniform(1e^{-6}, 1)$\"\n\"\",\"Num. Epochs\",\"$\\{1, 2, 3, 4, 5\\}$\"\n\"\",\"Depth\",\"$4, 6$\"\n\"\",\"Model Dimension\",\"$4, 8, 12, 16, 32$\"\n\"SAINT\",\"Learning Rate\",\"$LogUniform(1e^{-5}, 1e^{-1})$\"\n\"\",\"Weight Decay\",\"$LogUniform(1e^{-6}, 1)$\"\n\"\",\"FFN Dropout\",\"$Uniform(0.1, 0.8)$\"\n\"\",\"Heads\",\"$4, 8$\"\n\"\",\"Attention Type\",\"$Row, Col, RowCol$\"\n\"DRO\",\"Uncertainty set size\",\"$LogUniform\\{1e^{-4}, 1\\}$\"\n\"\",\"Geometry\",\"$\\{CVaR, \\chi^2\\}$\"\n\"Group DRO\",\"Group weights step size\",\"$LogUniform(1e^{-4}, 1)$\"\n\"Label Group DRO\",\"Group weights step size\",\"$LogUniform(1e^{-4}, 1)$\"\n\"\",\"Adv. Learning Rate \u03b7\u03c0\",\"$LogUniform\\{1e^{-4}, 1e^{-1}\\}$\"\n\"Adversarial Label DRO\",\"Adv. radius r\",\"$LogUniform\\{1e^{-5}, 0.5\\}$\"\n\"\",\"Clip max r\",\"$LogUniform\\{1e^{-1}, 10\\}$\"\n\"$\\epsilon$\",\"$LogUniform\\{1e^{-4}, 1e^{-1}\\}$\",\"\""}]}], "job_id": "4920dc86-cac2-4414-bfdb-370d01d06a12", "file_path": "./corpus/2312.07577.pdf"}