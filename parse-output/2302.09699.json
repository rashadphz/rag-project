{"pages": [{"page": 1, "text": "                      Private (Stochastic) Non-Convex Optimization Revisited:\n                             Second-Order Stationary Points and Excess Risks\n                     Arun Ganesh \u2217                Daogao Liu \u2020               Sewoong Oh \u2021               Abhradeep Thakurta \u00a7\n                                                                  February 21, 2023\narXiv:2302.09699v1  [cs.LG]  20 Feb 2023\n                                                                         Abstract\n                       We consider the problem of minimizing a non-convex objective while preserving the privacy\n                   of the examples in the training data. Building upon the previous variance-reduced algorithm\n                   SpiderBoost, we introduce a new framework that utilizes two diff                 erent kinds of gradient oracles.\n                   The fi  rst kind of oracles can estimate the gradient of one point, and the second kind of oracles,\n                   less precise and more cost-eff        ective, can estimate the gradient diff         erence between two points.\n                   SpiderBoost uses the fi      rst kind periodically, once every few steps, while our framework proposes\n                   using the fi  rst oracle whenever the total drift has become large and relies on the second oracle\n                   otherwise. This new framework ensures the gradient estimations remain accurate all the time,\n                   resulting in improved rates for fi       nding second-order stationary points.\n                       Moreover, we address a more challenging task of fi              nding the global minima of a non-convex\n                   objective using the exponential mechanism. Our fi                 ndings indicate that the regularized expo-\n                   nential mechanism can closely match previous empirical and population risk bounds, without\n                   requiring smoothness assumptions for algorithms with polynomial running time. Furthermore,\n                   by disregarding running time considerations, we show that the exponential mechanism can\n                   achieve a good population risk bound and provide a nearly matching lower bound.\n           1      Introduction\n           Differential privacy [DMNS06] is a standard privacy guarantee for training machine learning models.\n           Given a randomized algorithm A : P \u2217                 \u2192   R, where P is a data domain and R is a range of outputs,\n           we say A is (\u03b5, \u03b4)-differentially private (DP) for some \u03b5 \u2265                        0 and \u03b4 \u2208      [0, 1] if for any neighboring\n           datasets D, D\u2032 \u2208         P \u2217  that differ in at most one element and any R \u2286                       R, the distribution of the\n           outcome of the algorithm, e.g., pair of models trained on the respective datasets, are similar:\n                                                       Pr                         Pr\n                                                    x\u223cA(D) [x \u2208     R] \u2264    e\u03b5 x\u223cA(D\u2032) [x \u2208     R] + \u03b4.\n           Smaller \u03b5 and \u03b4 imply the distributions are closer; hence, an adversary accessing the trained model\n           cannot tell with high confidence whether an example x was in the training dateset. Given this\n           measure of privacy, we consider the problem of optimizing a non-convex loss while ensuring a\n           desired level of privacy. In particular, suppose we are given a dataset D = {z1, . . . , zn} drawn i.i.d.\n           from underlying distribution P. Each loss function f(\u00b7; z) : K \u2192                          R is G-Lipschitz over the convex\n           set K \u2282      Rd of diameter D. Let the population risk function be FP(x) := Ez\u223cP[f(x; z)] and the             1\n           empirical risk function be FD(x) := 1              n    z\u2208D f(x; z). We also denote FS(x) :=                 |S|    z\u2208S f(x; z) for\n           S \u2286 \u2217  D.\n                Google Research, arunganesh@google.com\n               \u2020\n                University of Washington, most of this work was done while interning at Google, dgliu@uw.edu\n               \u2021University of Washington and Google Research, sewoong@cs.washington.edu\n               \u00a7\n                Google Research, athakurta@google.com\n                                                                              1", "md": "# Private (Stochastic) Non-Convex Optimization Revisited\n\n# Private (Stochastic) Non-Convex Optimization Revisited: Second-Order Stationary Points and Excess Risks\n\nArun Ganesh \u2217, Daogao Liu \u2020, Sewoong Oh \u2021, Abhradeep Thakurta \u00a7\n\nFebruary 21, 2023\n\narXiv:2302.09699v1 [cs.LG] 20 Feb 2023\n\n## Abstract\n\nWe consider the problem of minimizing a non-convex objective while preserving the privacy\nof the examples in the training data. Building upon the previous variance-reduced algorithm\nSpiderBoost, we introduce a new framework that utilizes two different kinds of gradient oracles.\nThe first kind of oracles can estimate the gradient of one point, and the second kind of oracles,\nless precise and more cost-effective, can estimate the gradient difference between two points.\nSpiderBoost uses the first kind periodically, once every few steps, while our framework proposes\nusing the first oracle whenever the total drift has become large and relies on the second oracle\notherwise. This new framework ensures the gradient estimations remain accurate all the time,\nresulting in improved rates for finding second-order stationary points.\n\nMoreover, we address a more challenging task of finding the global minima of a non-convex\nobjective using the exponential mechanism. Our findings indicate that the regularized exponential\nmechanism can closely match previous empirical and population risk bounds, without\nrequiring smoothness assumptions for algorithms with polynomial running time. Furthermore,\nby disregarding running time considerations, we show that the exponential mechanism can\nachieve a good population risk bound and provide a nearly matching lower bound.\n\n## Introduction\n\nDifferential privacy [DMNS06] is a standard privacy guarantee for training machine learning models.\nGiven a randomized algorithm A : P* \u2192 R, where P is a data domain and R is a range of outputs,\nwe say A is (\u03b5, \u03b4)-differentially private (DP) for some \u03b5 \u2265 0 and \u03b4 \u2208 [0, 1] if for any neighboring\ndatasets D, D' \u2208 P* that differ in at most one element and any R \u2286 R, the distribution of the\noutcome of the algorithm, e.g., pair of models trained on the respective datasets, are similar:\n\n$$Pr\\left[x\\sim A(D) [x \\in R] \\leq e^{\\epsilon} x\\sim A(D')[x \\in R] + \\delta\\right].$$\n\nSmaller \u03b5 and \u03b4 imply the distributions are closer; hence, an adversary accessing the trained model\ncannot tell with high confidence whether an example x was in the training dataset. Given this\nmeasure of privacy, we consider the problem of optimizing a non-convex loss while ensuring a\ndesired level of privacy. In particular, suppose we are given a dataset D = {z1, . . . , zn} drawn i.i.d.\nfrom underlying distribution P. Each loss function f(\u00b7; z) : K \u2192 R is G-Lipschitz over the convex\nset K \u2282 Rd of diameter D. Let the population risk function be FP(x) := Ez\u223cP[f(x; z)] and the\nempirical risk function be FD(x) := 1/n \u03a3z\u2208D f(x; z). We also denote FS(x) := |S| \u03a3z\u2208S f(x; z) for\nS \u2286 D*.\n\nGoogle Research, arunganesh@google.com\n\nUniversity of Washington, most of this work was done while interning at Google, dgliu@uw.edu\n\nUniversity of Washington and Google Research, sewoong@cs.washington.edu\n\nGoogle Research, athakurta@google.com", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Private (Stochastic) Non-Convex Optimization Revisited", "md": "# Private (Stochastic) Non-Convex Optimization Revisited"}, {"type": "heading", "lvl": 1, "value": "Private (Stochastic) Non-Convex Optimization Revisited: Second-Order Stationary Points and Excess Risks", "md": "# Private (Stochastic) Non-Convex Optimization Revisited: Second-Order Stationary Points and Excess Risks"}, {"type": "text", "value": "Arun Ganesh \u2217, Daogao Liu \u2020, Sewoong Oh \u2021, Abhradeep Thakurta \u00a7\n\nFebruary 21, 2023\n\narXiv:2302.09699v1 [cs.LG] 20 Feb 2023", "md": "Arun Ganesh \u2217, Daogao Liu \u2020, Sewoong Oh \u2021, Abhradeep Thakurta \u00a7\n\nFebruary 21, 2023\n\narXiv:2302.09699v1 [cs.LG] 20 Feb 2023"}, {"type": "heading", "lvl": 2, "value": "Abstract", "md": "## Abstract"}, {"type": "text", "value": "We consider the problem of minimizing a non-convex objective while preserving the privacy\nof the examples in the training data. Building upon the previous variance-reduced algorithm\nSpiderBoost, we introduce a new framework that utilizes two different kinds of gradient oracles.\nThe first kind of oracles can estimate the gradient of one point, and the second kind of oracles,\nless precise and more cost-effective, can estimate the gradient difference between two points.\nSpiderBoost uses the first kind periodically, once every few steps, while our framework proposes\nusing the first oracle whenever the total drift has become large and relies on the second oracle\notherwise. This new framework ensures the gradient estimations remain accurate all the time,\nresulting in improved rates for finding second-order stationary points.\n\nMoreover, we address a more challenging task of finding the global minima of a non-convex\nobjective using the exponential mechanism. Our findings indicate that the regularized exponential\nmechanism can closely match previous empirical and population risk bounds, without\nrequiring smoothness assumptions for algorithms with polynomial running time. Furthermore,\nby disregarding running time considerations, we show that the exponential mechanism can\nachieve a good population risk bound and provide a nearly matching lower bound.", "md": "We consider the problem of minimizing a non-convex objective while preserving the privacy\nof the examples in the training data. Building upon the previous variance-reduced algorithm\nSpiderBoost, we introduce a new framework that utilizes two different kinds of gradient oracles.\nThe first kind of oracles can estimate the gradient of one point, and the second kind of oracles,\nless precise and more cost-effective, can estimate the gradient difference between two points.\nSpiderBoost uses the first kind periodically, once every few steps, while our framework proposes\nusing the first oracle whenever the total drift has become large and relies on the second oracle\notherwise. This new framework ensures the gradient estimations remain accurate all the time,\nresulting in improved rates for finding second-order stationary points.\n\nMoreover, we address a more challenging task of finding the global minima of a non-convex\nobjective using the exponential mechanism. Our findings indicate that the regularized exponential\nmechanism can closely match previous empirical and population risk bounds, without\nrequiring smoothness assumptions for algorithms with polynomial running time. Furthermore,\nby disregarding running time considerations, we show that the exponential mechanism can\nachieve a good population risk bound and provide a nearly matching lower bound."}, {"type": "heading", "lvl": 2, "value": "Introduction", "md": "## Introduction"}, {"type": "text", "value": "Differential privacy [DMNS06] is a standard privacy guarantee for training machine learning models.\nGiven a randomized algorithm A : P* \u2192 R, where P is a data domain and R is a range of outputs,\nwe say A is (\u03b5, \u03b4)-differentially private (DP) for some \u03b5 \u2265 0 and \u03b4 \u2208 [0, 1] if for any neighboring\ndatasets D, D' \u2208 P* that differ in at most one element and any R \u2286 R, the distribution of the\noutcome of the algorithm, e.g., pair of models trained on the respective datasets, are similar:\n\n$$Pr\\left[x\\sim A(D) [x \\in R] \\leq e^{\\epsilon} x\\sim A(D')[x \\in R] + \\delta\\right].$$\n\nSmaller \u03b5 and \u03b4 imply the distributions are closer; hence, an adversary accessing the trained model\ncannot tell with high confidence whether an example x was in the training dataset. Given this\nmeasure of privacy, we consider the problem of optimizing a non-convex loss while ensuring a\ndesired level of privacy. In particular, suppose we are given a dataset D = {z1, . . . , zn} drawn i.i.d.\nfrom underlying distribution P. Each loss function f(\u00b7; z) : K \u2192 R is G-Lipschitz over the convex\nset K \u2282 Rd of diameter D. Let the population risk function be FP(x) := Ez\u223cP[f(x; z)] and the\nempirical risk function be FD(x) := 1/n \u03a3z\u2208D f(x; z). We also denote FS(x) := |S| \u03a3z\u2208S f(x; z) for\nS \u2286 D*.\n\nGoogle Research, arunganesh@google.com\n\nUniversity of Washington, most of this work was done while interning at Google, dgliu@uw.edu\n\nUniversity of Washington and Google Research, sewoong@cs.washington.edu\n\nGoogle Research, athakurta@google.com", "md": "Differential privacy [DMNS06] is a standard privacy guarantee for training machine learning models.\nGiven a randomized algorithm A : P* \u2192 R, where P is a data domain and R is a range of outputs,\nwe say A is (\u03b5, \u03b4)-differentially private (DP) for some \u03b5 \u2265 0 and \u03b4 \u2208 [0, 1] if for any neighboring\ndatasets D, D' \u2208 P* that differ in at most one element and any R \u2286 R, the distribution of the\noutcome of the algorithm, e.g., pair of models trained on the respective datasets, are similar:\n\n$$Pr\\left[x\\sim A(D) [x \\in R] \\leq e^{\\epsilon} x\\sim A(D')[x \\in R] + \\delta\\right].$$\n\nSmaller \u03b5 and \u03b4 imply the distributions are closer; hence, an adversary accessing the trained model\ncannot tell with high confidence whether an example x was in the training dataset. Given this\nmeasure of privacy, we consider the problem of optimizing a non-convex loss while ensuring a\ndesired level of privacy. In particular, suppose we are given a dataset D = {z1, . . . , zn} drawn i.i.d.\nfrom underlying distribution P. Each loss function f(\u00b7; z) : K \u2192 R is G-Lipschitz over the convex\nset K \u2282 Rd of diameter D. Let the population risk function be FP(x) := Ez\u223cP[f(x; z)] and the\nempirical risk function be FD(x) := 1/n \u03a3z\u2208D f(x; z). We also denote FS(x) := |S| \u03a3z\u2208S f(x; z) for\nS \u2286 D*.\n\nGoogle Research, arunganesh@google.com\n\nUniversity of Washington, most of this work was done while interning at Google, dgliu@uw.edu\n\nUniversity of Washington and Google Research, sewoong@cs.washington.edu\n\nGoogle Research, athakurta@google.com"}]}, {"page": 2, "text": "                                                      \u03b1-SOSP                        Excess population risk\n                                          empirical            population           poly-time           exp-time\n                                                 1     4\n                          SOTA          min( d   4     7            N/A                   d    \u2660          N/A\n                                                 1     4                              \u03b52 log n\n                                                 2 , d 7 )\n                                               n     n\n                                                 1                     \u221a      37\n                                               d 3              1          d          d log log n       d         d\n                           Ours                  2              1         n            \u03b5 log(n)        n\u03b5 +       n\n                                               n 3            n 3 +\n                             LB                \u221a  d              \u221a 1      \u221a d         d         d       d         d\n                                                n                  n +     n         n\u03b5 +       n      n\u03b5 +       n\nTable 1: SOTA refers to the best previously known bounds on \u03b1 for \u03b1-SOSP by [WCX19] and on\nthe excess population risk by [WCX19]. We introduce algorithm 1 that finds an \u03b1-SOSP (columns\n2\u20133) with an improved rate.                  We show exponential mechanism can minimize the excess risk in\npolynomial time and exponential time, respectively (columns 4 and 5). \u2660                                    requires extra assumption\non bounded smoothness. The lower bounds for SOSP are from [ABG+22], and the lower bound on\nexcess population risk is from Theorem 4.11. We omit logarithmic factors in n and d.\n     Our focus is in minimizing non-convex risk functions, both empirical and population, which\nmay have multiple local minima. Since finding the global optimum of a non-convex function can\nbe challenging, an alternative goal in the field is to find stationary points: A first-order stationary\npoint is a point with a small gradient of the function, and a second-order stationary point is a first-\norder stationary point where additionally the function has a positive or nearly positive semi-definite\nHessian. As first order stationary points can be saddle points or even a local maximum, we focus\non the problem of finding a second order stationary point, i.e., a local minimum, privately. Existing\nworks in finding approximate SOSP privately only give guarantees for the empirical function FD. We\nimprove upon the state-of-the-art result for empirical risk minimization and give the first guarantee\nfor the population function FP. This requires standard assumptions on bounded Lipschitzness,\nsmoothness, and Hessian Lipschitzness, which we make precise in Section 2 and in Assumption 3.1.\n     Compared to finding a local minimum, finding a global minimum can be extremely chal-\nlenging.      Progress towards finding the global minima is measured in the excess empirical risk,\nE[FD(xpriv)] \u2212        minx\u2208K FD(x), and the excess population risk, E[FP(xpriv)] \u2212                                 minx\u2208K FP(x) for a\nprivate solution xpriv. We provide two approaches, in polynomial time and exponential time, that\nimprove upon the state-of-the-art guarantees as measured in the excess risks for the respective\nfamilies of computational complexity.\n1.1      Main results\nOur main contribution is a private non-convex optimization algorithm based on the variance-\nreduced SpiderBoost [WJZ+19]; Algorithm 1 achieves improved rates on the approximation error\nfor finding SOSP of the empirical and population risks privately. Table 1 summarizes our main\nresults.\nFinding second-order stationary points.                               Advances in private non-convex optimization have\nfocused on finding a first-order stationary point (FOSP), whose performance is measured in (i)\nthe norm of the empirical gradient at the solution x, i.e., \u2225\u2207FD(x)\u2225, and (ii) the norm of the\npopulation gradient, i.e., \u2225\u2207FP(x)\u2225. We survey the recent progress in Appendix C in detail.\nDefinition 1.1 (First-order stationary point). We say x \u2208                                Rd is a First-Order Stationary Point\n(FOSP) of g : Rd \u2192            R iff \u2207g(x) = 0. x is an \u03b1-FOSP of g, if \u2225\u2207g(x)\u22252 \u2264                             \u03b1.\n                                                                       2", "md": "$$\n\\begin{array}{cccccc}\n\\text{\u03b1-SOSP} & \\text{Excess population risk} \\\\\n\\text{empirical} & \\text{population} & \\text{poly-time} & \\text{exp-time} \\\\\n1 & 4 \\\\\n\\text{SOTA} & \\min(d, 4) & 7 & \\text{N/A} & d & \u2660 & \\text{N/A} \\\\\n1 & 4 & \\epsilon^2 \\log n \\\\\n2, d & 7 & \\\\\nn & n \\\\\n1 & \\sqrt{37} \\\\\nd^3 & 1 & d & d \\log \\log n & d & d \\\\\n\\text{Ours} & 2 & 1 & n & \\epsilon \\log(n) & n\\epsilon + n \\\\\nn^3 & n^3 + \\\\\n\\text{LB} & \\sqrt{d} & \\sqrt{1} & \\sqrt{d} & d & d & d \\\\\nn & n + & n & n\\epsilon + n & n & n\\epsilon + n \\\\\n\\end{array}\n$$\n\nTable 1: SOTA refers to the best previously known bounds on \u03b1 for \u03b1-SOSP by [WCX19] and on the excess population risk by [WCX19]. We introduce algorithm 1 that finds an \u03b1-SOSP (columns 2\u20133) with an improved rate. We show exponential mechanism can minimize the excess risk in polynomial time and exponential time, respectively (columns 4 and 5). \u2660 requires extra assumption on bounded smoothness. The lower bounds for SOSP are from [ABG+22], and the lower bound on excess population risk is from Theorem 4.11. We omit logarithmic factors in n and d.\n\nOur focus is in minimizing non-convex risk functions, both empirical and population, which may have multiple local minima. Since finding the global optimum of a non-convex function can be challenging, an alternative goal in the field is to find stationary points: A first-order stationary point is a point with a small gradient of the function, and a second-order stationary point is a first-order stationary point where additionally the function has a positive or nearly positive semi-definite Hessian. As first order stationary points can be saddle points or even a local maximum, we focus on the problem of finding a second order stationary point, i.e., a local minimum, privately. Existing works in finding approximate SOSP privately only give guarantees for the empirical function FD. We improve upon the state-of-the-art result for empirical risk minimization and give the first guarantee for the population function FP. This requires standard assumptions on bounded Lipschitzness, smoothness, and Hessian Lipschitzness, which we make precise in Section 2 and in Assumption 3.1.\n\nCompared to finding a local minimum, finding a global minimum can be extremely challenging. Progress towards finding the global minima is measured in the excess empirical risk, E[FD(x_{priv})] - \\min_{x \\in K} FD(x), and the excess population risk, E[FP(x_{priv})] - \\min_{x \\in K} FP(x) for a private solution x_{priv}. We provide two approaches, in polynomial time and exponential time, that improve upon the state-of-the-art guarantees as measured in the excess risks for the respective families of computational complexity.\n\n1.1 Main results\n\nOur main contribution is a private non-convex optimization algorithm based on the variance-reduced SpiderBoost [WJZ+19]; Algorithm 1 achieves improved rates on the approximation error for finding SOSP of the empirical and population risks privately. Table 1 summarizes our main results.\n\nFinding second-order stationary points. Advances in private non-convex optimization have focused on finding a first-order stationary point (FOSP), whose performance is measured in (i) the norm of the empirical gradient at the solution x, i.e., \\|\\nabla FD(x)\\|, and (ii) the norm of the population gradient, i.e., \\|\\nabla FP(x)\\|. We survey the recent progress in Appendix C in detail.\n\nDefinition 1.1 (First-order stationary point). We say x \\in \\mathbb{R}^d is a First-Order Stationary Point (FOSP) of g : \\mathbb{R}^d \\rightarrow \\mathbb{R} iff \\nabla g(x) = 0. x is an \u03b1-FOSP of g, if \\|\\nabla g(x)\\|^2 \\leq \\alpha^2.", "images": [{"name": "page-2-34.jpg", "height": 29, "width": 308, "x": 152, "y": 140}, {"name": "page-2-0.jpg", "height": 14, "width": 308, "x": 152, "y": 57}, {"name": "page-2-1.jpg", "height": 14, "width": 308, "x": 152, "y": 71}], "items": [{"type": "text", "value": "$$\n\\begin{array}{cccccc}\n\\text{\u03b1-SOSP} & \\text{Excess population risk} \\\\\n\\text{empirical} & \\text{population} & \\text{poly-time} & \\text{exp-time} \\\\\n1 & 4 \\\\\n\\text{SOTA} & \\min(d, 4) & 7 & \\text{N/A} & d & \u2660 & \\text{N/A} \\\\\n1 & 4 & \\epsilon^2 \\log n \\\\\n2, d & 7 & \\\\\nn & n \\\\\n1 & \\sqrt{37} \\\\\nd^3 & 1 & d & d \\log \\log n & d & d \\\\\n\\text{Ours} & 2 & 1 & n & \\epsilon \\log(n) & n\\epsilon + n \\\\\nn^3 & n^3 + \\\\\n\\text{LB} & \\sqrt{d} & \\sqrt{1} & \\sqrt{d} & d & d & d \\\\\nn & n + & n & n\\epsilon + n & n & n\\epsilon + n \\\\\n\\end{array}\n$$\n\nTable 1: SOTA refers to the best previously known bounds on \u03b1 for \u03b1-SOSP by [WCX19] and on the excess population risk by [WCX19]. We introduce algorithm 1 that finds an \u03b1-SOSP (columns 2\u20133) with an improved rate. We show exponential mechanism can minimize the excess risk in polynomial time and exponential time, respectively (columns 4 and 5). \u2660 requires extra assumption on bounded smoothness. The lower bounds for SOSP are from [ABG+22], and the lower bound on excess population risk is from Theorem 4.11. We omit logarithmic factors in n and d.\n\nOur focus is in minimizing non-convex risk functions, both empirical and population, which may have multiple local minima. Since finding the global optimum of a non-convex function can be challenging, an alternative goal in the field is to find stationary points: A first-order stationary point is a point with a small gradient of the function, and a second-order stationary point is a first-order stationary point where additionally the function has a positive or nearly positive semi-definite Hessian. As first order stationary points can be saddle points or even a local maximum, we focus on the problem of finding a second order stationary point, i.e., a local minimum, privately. Existing works in finding approximate SOSP privately only give guarantees for the empirical function FD. We improve upon the state-of-the-art result for empirical risk minimization and give the first guarantee for the population function FP. This requires standard assumptions on bounded Lipschitzness, smoothness, and Hessian Lipschitzness, which we make precise in Section 2 and in Assumption 3.1.\n\nCompared to finding a local minimum, finding a global minimum can be extremely challenging. Progress towards finding the global minima is measured in the excess empirical risk, E[FD(x_{priv})] - \\min_{x \\in K} FD(x), and the excess population risk, E[FP(x_{priv})] - \\min_{x \\in K} FP(x) for a private solution x_{priv}. We provide two approaches, in polynomial time and exponential time, that improve upon the state-of-the-art guarantees as measured in the excess risks for the respective families of computational complexity.\n\n1.1 Main results\n\nOur main contribution is a private non-convex optimization algorithm based on the variance-reduced SpiderBoost [WJZ+19]; Algorithm 1 achieves improved rates on the approximation error for finding SOSP of the empirical and population risks privately. Table 1 summarizes our main results.\n\nFinding second-order stationary points. Advances in private non-convex optimization have focused on finding a first-order stationary point (FOSP), whose performance is measured in (i) the norm of the empirical gradient at the solution x, i.e., \\|\\nabla FD(x)\\|, and (ii) the norm of the population gradient, i.e., \\|\\nabla FP(x)\\|. We survey the recent progress in Appendix C in detail.\n\nDefinition 1.1 (First-order stationary point). We say x \\in \\mathbb{R}^d is a First-Order Stationary Point (FOSP) of g : \\mathbb{R}^d \\rightarrow \\mathbb{R} iff \\nabla g(x) = 0. x is an \u03b1-FOSP of g, if \\|\\nabla g(x)\\|^2 \\leq \\alpha^2.", "md": "$$\n\\begin{array}{cccccc}\n\\text{\u03b1-SOSP} & \\text{Excess population risk} \\\\\n\\text{empirical} & \\text{population} & \\text{poly-time} & \\text{exp-time} \\\\\n1 & 4 \\\\\n\\text{SOTA} & \\min(d, 4) & 7 & \\text{N/A} & d & \u2660 & \\text{N/A} \\\\\n1 & 4 & \\epsilon^2 \\log n \\\\\n2, d & 7 & \\\\\nn & n \\\\\n1 & \\sqrt{37} \\\\\nd^3 & 1 & d & d \\log \\log n & d & d \\\\\n\\text{Ours} & 2 & 1 & n & \\epsilon \\log(n) & n\\epsilon + n \\\\\nn^3 & n^3 + \\\\\n\\text{LB} & \\sqrt{d} & \\sqrt{1} & \\sqrt{d} & d & d & d \\\\\nn & n + & n & n\\epsilon + n & n & n\\epsilon + n \\\\\n\\end{array}\n$$\n\nTable 1: SOTA refers to the best previously known bounds on \u03b1 for \u03b1-SOSP by [WCX19] and on the excess population risk by [WCX19]. We introduce algorithm 1 that finds an \u03b1-SOSP (columns 2\u20133) with an improved rate. We show exponential mechanism can minimize the excess risk in polynomial time and exponential time, respectively (columns 4 and 5). \u2660 requires extra assumption on bounded smoothness. The lower bounds for SOSP are from [ABG+22], and the lower bound on excess population risk is from Theorem 4.11. We omit logarithmic factors in n and d.\n\nOur focus is in minimizing non-convex risk functions, both empirical and population, which may have multiple local minima. Since finding the global optimum of a non-convex function can be challenging, an alternative goal in the field is to find stationary points: A first-order stationary point is a point with a small gradient of the function, and a second-order stationary point is a first-order stationary point where additionally the function has a positive or nearly positive semi-definite Hessian. As first order stationary points can be saddle points or even a local maximum, we focus on the problem of finding a second order stationary point, i.e., a local minimum, privately. Existing works in finding approximate SOSP privately only give guarantees for the empirical function FD. We improve upon the state-of-the-art result for empirical risk minimization and give the first guarantee for the population function FP. This requires standard assumptions on bounded Lipschitzness, smoothness, and Hessian Lipschitzness, which we make precise in Section 2 and in Assumption 3.1.\n\nCompared to finding a local minimum, finding a global minimum can be extremely challenging. Progress towards finding the global minima is measured in the excess empirical risk, E[FD(x_{priv})] - \\min_{x \\in K} FD(x), and the excess population risk, E[FP(x_{priv})] - \\min_{x \\in K} FP(x) for a private solution x_{priv}. We provide two approaches, in polynomial time and exponential time, that improve upon the state-of-the-art guarantees as measured in the excess risks for the respective families of computational complexity.\n\n1.1 Main results\n\nOur main contribution is a private non-convex optimization algorithm based on the variance-reduced SpiderBoost [WJZ+19]; Algorithm 1 achieves improved rates on the approximation error for finding SOSP of the empirical and population risks privately. Table 1 summarizes our main results.\n\nFinding second-order stationary points. Advances in private non-convex optimization have focused on finding a first-order stationary point (FOSP), whose performance is measured in (i) the norm of the empirical gradient at the solution x, i.e., \\|\\nabla FD(x)\\|, and (ii) the norm of the population gradient, i.e., \\|\\nabla FP(x)\\|. We survey the recent progress in Appendix C in detail.\n\nDefinition 1.1 (First-order stationary point). We say x \\in \\mathbb{R}^d is a First-Order Stationary Point (FOSP) of g : \\mathbb{R}^d \\rightarrow \\mathbb{R} iff \\nabla g(x) = 0. x is an \u03b1-FOSP of g, if \\|\\nabla g(x)\\|^2 \\leq \\alpha^2."}]}, {"page": 3, "text": "   Since FOSP can be a saddle point or a local maxima, finding a second-order stationary point\nis desired. Exact second-order stationary points can be extremely challenging to find [GHJY15].\nInstead, progress is commonly measured in terms of how well the solution approximates an SOSP.\nDefinition 1.2 (Second-order stationary point, [AAZB+17]). We say a point x \u2208           Rd is a Second-\nOrder Stationary Point (SOSP) of a twice differentiable function g : Rd \u2192          R iff \u2225\u2207g(x)\u22252 = 0\nand \u22072g(x) \u2ab0   0. We say x \u2208    Rd is an \u03b1-SOSP for \u03c1-Hessian Lipschitz function g, if \u2225\u2207g(x)\u22252 \u2264\n\u03b1    \u22072g(x) \u2ab0   \u2212\u221a  \u03c1\u03b1I .\n   On the empirical risk FD, the SOTA on privately finding \u03b1-SOSP is by [WCX19, WX20],\nwhich achieves \u03b1 = \u02dc           \u221a d/n)1/2, (d/n)4/7}). In Theorem 3.9, we show that the proposed\n                      O(min{(                         \u221a\nAlgorithm 1 achieves a rate bounded by \u03b1 = \u02dc      O((   d/n)2/3), which improves over the SOTA in\nall regime.1  There remains a factor (   \u221a d/n)\u22121/6 gap to a known lower bound of \u03b1 = \u2126(         \u221a d/n)\nthat holds even if privacy is not required and even if finding only an \u03b1-FOSP [ABG+22]. On the\npopulation risk FP, Algorithm 1 is the first private algorithm to guarantee finding an \u03b1-SOSP\nwith \u03b1 = \u02dc O(n\u22121/3 + (  \u221a d/n)3/7) in Theorem 3.12.      There is a gap to a known lower bound of\n\u03b1 = \u2126(1/\u221a   n+  \u221a d/n) that holds even if privacy is not required and even if finding only an \u03b1-FOSP\n[ABG+22].\nMinimizing excess risk.       We also provide sampling-based algorithms that aims to tackle the ul-\ntimate objective of finding a private solution xpriv \u2208 Rd that minimizes the excess empirical risk:\nE[FD(xpriv)]\u2212minx\u2208K FD(x), and the excess population risk, E[FP(xpriv)]\u2212minx\u2208K FP(x), where\nthe expectation is over the randomness on the solution xpriv. With a mild smoothness assumption,\n[WCX19] achieves in polynomial time a bound of O(d       log(1/\u03b4)/(\u03b52 log n)) for both excess empiri-\ncal and population risks. In Table 1 we omit excess empirical risk, as the bounds are the same. We\nintroduce a sampling-based algorithm from the exponential mechanism, which runs in polynomial\ntime and achieves excess empirical and population risks bounded by O(d           log(1/\u03b4)/(\u03b5 log(nd)))\nwith improved dependence on \u03b5 (Theorem 4.6). Moreover, we do not need the smoothness assump-\ntion required by [WCX19].\n   If we allow an exponential running time, [GTU22] demonstrated \u02dc        O(d/(\u03b5n)) upper bound for\nnon-convex excess empirical risks along with a nearly matching lower bound. It remained an open\nquestion to obtain a tight bound for the excess population risk. We close this gap by providing\na nearly matching upper and lower bounds of \u02dc      \u0398(d/(\u03b5n) +     d/n) for the excess population risk\n(Theorem 4.8).\n1.2   Our techniques\nStationary points.      We propose a simple framework based on SpiderBoost [WJZ+19] and its\nprivate version [ABG+22] that achieves the current best rate for finding the first order stationary\npoint privately. In SGD and its variants, we usually get an estimation \u2206t of the gradient \u2207f(xt).\nIn the stochastic variance-reduced algorithm SpiderBoost, it only queries the gradient O1(xt) \u2248\n\u2207f(xt) directly every q steps with some oracle O1, and for the other q \u2212      1 steps in each period, it\nqueries the difference between two steps, that is O2(xt, xt\u22121) \u2248    \u2207f(xt) \u2212  \u2207f(xt\u22121), and maintain\n\u2206t = \u2206t\u22121 +O2(xt, xt\u22121). One interpretation of the difference between these two kinds of oracles is\nthat, in many situations, one can treat O1 as more accurate and more costly (e.g., in computation\nor privacy budget), though our framework does not necessarily assume this.\n   As SpiderBoost queries O1 every q steps, the error on the estimation may accumulate and\n\u2225\u2206t \u2212\u2207f(xt)\u2225    can be large. Though on average, as shown in [ABG+22], these estimations can be\ngood enough to find a private first-order stationary point, such a large deviation makes it challenging\nto analyze the behavior near a saddle point and to provide a tight analysis of the population risk.\n  1We want \u03b1 = o(1) and hence can assume d \u2264 n2.\n                                                   3", "md": "Since FOSP can be a saddle point or a local maxima, finding a second-order stationary point is desired. Exact second-order stationary points can be extremely challenging to find [GHJY15]. Instead, progress is commonly measured in terms of how well the solution approximates an SOSP.\n\nDefinition 1.2 (Second-order stationary point, [AAZB+17]): We say a point \\( x \\in \\mathbb{R}^d \\) is a Second-Order Stationary Point (SOSP) of a twice differentiable function \\( g : \\mathbb{R}^d \\rightarrow \\mathbb{R} \\) if \\( \\|\\nabla g(x)\\|^2 = 0 \\) and \\( \\nabla^2 g(x) \\succeq 0 \\). We say \\( x \\in \\mathbb{R}^d \\) is an \\( \\alpha \\)-SOSP for \\( \\rho \\)-Hessian Lipschitz function \\( g \\), if \\( \\|\\nabla g(x)\\|^2 \\leq \\alpha \\nabla^2 g(x) \\succeq -\\sqrt{\\rho \\alpha} I \\).\n\nOn the empirical risk FD, the SOTA on privately finding \\( \\alpha \\)-SOSP is by [WCX19, WX20], which achieves \\( \\alpha = \\tilde{O}(\\sqrt{d/n})^{1/2}, (d/n)^{4/7}) \\). In Theorem 3.9, we show that the proposed Algorithm 1 achieves a rate bounded by \\( \\alpha = \\tilde{O}((\\sqrt{d/n})^{2/3}) \\), which improves over the SOTA in all regime.1 There remains a factor \\( (\\sqrt{d/n})^{-1/6} \\) gap to a known lower bound of \\( \\alpha = \\Omega(\\sqrt{d/n}) \\) that holds even if privacy is not required and even if finding only an \\( \\alpha \\)-FOSP [ABG+22]. On the population risk FP, Algorithm 1 is the first private algorithm to guarantee finding an \\( \\alpha \\)-SOSP with \\( \\alpha = \\tilde{O}(n^{-1/3} + (\\sqrt{d/n})^{3/7}) \\) in Theorem 3.12. There is a gap to a known lower bound of \\( \\alpha = \\Omega(1/\\sqrt{n} + \\sqrt{d/n}) \\) that holds even if privacy is not required and even if finding only an \\( \\alpha \\)-FOSP [ABG+22].\n\nMinimizing excess risk: We also provide sampling-based algorithms that aim to tackle the ultimate objective of finding a private solution \\( x_{\\text{priv}} \\in \\mathbb{R}^d \\) that minimizes the excess empirical risk: \\( E[FD(x_{\\text{priv}})] - \\min_{x \\in K} FD(x) \\), and the excess population risk, \\( E[FP(x_{\\text{priv}})] - \\min_{x \\in K} FP(x) \\), where the expectation is over the randomness on the solution \\( x_{\\text{priv}} \\). With a mild smoothness assumption, [WCX19] achieves in polynomial time a bound of \\( O(d \\log(1/\\delta)/(\u03b5^2 \\log n)) \\) for both excess empirical and population risks. In Table 1 we omit excess empirical risk, as the bounds are the same. We introduce a sampling-based algorithm from the exponential mechanism, which runs in polynomial time and achieves excess empirical and population risks bounded by \\( O(d \\log(1/\\delta)/(\u03b5 \\log(nd))) \\) with improved dependence on \\( \u03b5 \\) (Theorem 4.6). Moreover, we do not need the smoothness assumption required by [WCX19].\n\nIf we allow an exponential running time, [GTU22] demonstrated \\( \\tilde{O}(d/(\u03b5n)) \\) upper bound for non-convex excess empirical risks along with a nearly matching lower bound. It remained an open question to obtain a tight bound for the excess population risk. We close this gap by providing a nearly matching upper and lower bounds of \\( \\tilde{\\Theta}(d/(\u03b5n) + d/n) \\) for the excess population risk (Theorem 4.8).\n\n### Our techniques\n\nStationary points: We propose a simple framework based on SpiderBoost [WJZ+19] and its private version [ABG+22] that achieves the current best rate for finding the first order stationary point privately. In SGD and its variants, we usually get an estimation \\( \\Delta t \\) of the gradient \\( \\nabla f(x_t) \\). In the stochastic variance-reduced algorithm SpiderBoost, it only queries the gradient \\( O_1(x_t) \\approx \\nabla f(x_t) \\) directly every \\( q \\) steps with some oracle \\( O_1 \\), and for the other \\( q - 1 \\) steps in each period, it queries the difference between two steps, that is \\( O_2(x_t, x_{t-1}) \\approx \\nabla f(x_t) - \\nabla f(x_{t-1}) \\), and maintains \\( \\Delta t = \\Delta t - 1 + O_2(x_t, x_{t-1}) \\). One interpretation of the difference between these two kinds of oracles is that, in many situations, one can treat \\( O_1 \\) as more accurate and more costly (e.g., in computation or privacy budget), though our framework does not necessarily assume this.\n\nAs SpiderBoost queries \\( O_1 \\) every \\( q \\) steps, the error on the estimation may accumulate and \\( \\|\\Delta t - \\nabla f(x_t)\\| \\) can be large. Though on average, as shown in [ABG+22], these estimations can be good enough to find a private first-order stationary point, such a large deviation makes it challenging to analyze the behavior near a saddle point and to provide a tight analysis of the population risk.\n\n1We want \\( \\alpha = o(1) \\) and hence can assume \\( d \\leq n^2 \\).", "images": [], "items": [{"type": "text", "value": "Since FOSP can be a saddle point or a local maxima, finding a second-order stationary point is desired. Exact second-order stationary points can be extremely challenging to find [GHJY15]. Instead, progress is commonly measured in terms of how well the solution approximates an SOSP.\n\nDefinition 1.2 (Second-order stationary point, [AAZB+17]): We say a point \\( x \\in \\mathbb{R}^d \\) is a Second-Order Stationary Point (SOSP) of a twice differentiable function \\( g : \\mathbb{R}^d \\rightarrow \\mathbb{R} \\) if \\( \\|\\nabla g(x)\\|^2 = 0 \\) and \\( \\nabla^2 g(x) \\succeq 0 \\). We say \\( x \\in \\mathbb{R}^d \\) is an \\( \\alpha \\)-SOSP for \\( \\rho \\)-Hessian Lipschitz function \\( g \\), if \\( \\|\\nabla g(x)\\|^2 \\leq \\alpha \\nabla^2 g(x) \\succeq -\\sqrt{\\rho \\alpha} I \\).\n\nOn the empirical risk FD, the SOTA on privately finding \\( \\alpha \\)-SOSP is by [WCX19, WX20], which achieves \\( \\alpha = \\tilde{O}(\\sqrt{d/n})^{1/2}, (d/n)^{4/7}) \\). In Theorem 3.9, we show that the proposed Algorithm 1 achieves a rate bounded by \\( \\alpha = \\tilde{O}((\\sqrt{d/n})^{2/3}) \\), which improves over the SOTA in all regime.1 There remains a factor \\( (\\sqrt{d/n})^{-1/6} \\) gap to a known lower bound of \\( \\alpha = \\Omega(\\sqrt{d/n}) \\) that holds even if privacy is not required and even if finding only an \\( \\alpha \\)-FOSP [ABG+22]. On the population risk FP, Algorithm 1 is the first private algorithm to guarantee finding an \\( \\alpha \\)-SOSP with \\( \\alpha = \\tilde{O}(n^{-1/3} + (\\sqrt{d/n})^{3/7}) \\) in Theorem 3.12. There is a gap to a known lower bound of \\( \\alpha = \\Omega(1/\\sqrt{n} + \\sqrt{d/n}) \\) that holds even if privacy is not required and even if finding only an \\( \\alpha \\)-FOSP [ABG+22].\n\nMinimizing excess risk: We also provide sampling-based algorithms that aim to tackle the ultimate objective of finding a private solution \\( x_{\\text{priv}} \\in \\mathbb{R}^d \\) that minimizes the excess empirical risk: \\( E[FD(x_{\\text{priv}})] - \\min_{x \\in K} FD(x) \\), and the excess population risk, \\( E[FP(x_{\\text{priv}})] - \\min_{x \\in K} FP(x) \\), where the expectation is over the randomness on the solution \\( x_{\\text{priv}} \\). With a mild smoothness assumption, [WCX19] achieves in polynomial time a bound of \\( O(d \\log(1/\\delta)/(\u03b5^2 \\log n)) \\) for both excess empirical and population risks. In Table 1 we omit excess empirical risk, as the bounds are the same. We introduce a sampling-based algorithm from the exponential mechanism, which runs in polynomial time and achieves excess empirical and population risks bounded by \\( O(d \\log(1/\\delta)/(\u03b5 \\log(nd))) \\) with improved dependence on \\( \u03b5 \\) (Theorem 4.6). Moreover, we do not need the smoothness assumption required by [WCX19].\n\nIf we allow an exponential running time, [GTU22] demonstrated \\( \\tilde{O}(d/(\u03b5n)) \\) upper bound for non-convex excess empirical risks along with a nearly matching lower bound. It remained an open question to obtain a tight bound for the excess population risk. We close this gap by providing a nearly matching upper and lower bounds of \\( \\tilde{\\Theta}(d/(\u03b5n) + d/n) \\) for the excess population risk (Theorem 4.8).", "md": "Since FOSP can be a saddle point or a local maxima, finding a second-order stationary point is desired. Exact second-order stationary points can be extremely challenging to find [GHJY15]. Instead, progress is commonly measured in terms of how well the solution approximates an SOSP.\n\nDefinition 1.2 (Second-order stationary point, [AAZB+17]): We say a point \\( x \\in \\mathbb{R}^d \\) is a Second-Order Stationary Point (SOSP) of a twice differentiable function \\( g : \\mathbb{R}^d \\rightarrow \\mathbb{R} \\) if \\( \\|\\nabla g(x)\\|^2 = 0 \\) and \\( \\nabla^2 g(x) \\succeq 0 \\). We say \\( x \\in \\mathbb{R}^d \\) is an \\( \\alpha \\)-SOSP for \\( \\rho \\)-Hessian Lipschitz function \\( g \\), if \\( \\|\\nabla g(x)\\|^2 \\leq \\alpha \\nabla^2 g(x) \\succeq -\\sqrt{\\rho \\alpha} I \\).\n\nOn the empirical risk FD, the SOTA on privately finding \\( \\alpha \\)-SOSP is by [WCX19, WX20], which achieves \\( \\alpha = \\tilde{O}(\\sqrt{d/n})^{1/2}, (d/n)^{4/7}) \\). In Theorem 3.9, we show that the proposed Algorithm 1 achieves a rate bounded by \\( \\alpha = \\tilde{O}((\\sqrt{d/n})^{2/3}) \\), which improves over the SOTA in all regime.1 There remains a factor \\( (\\sqrt{d/n})^{-1/6} \\) gap to a known lower bound of \\( \\alpha = \\Omega(\\sqrt{d/n}) \\) that holds even if privacy is not required and even if finding only an \\( \\alpha \\)-FOSP [ABG+22]. On the population risk FP, Algorithm 1 is the first private algorithm to guarantee finding an \\( \\alpha \\)-SOSP with \\( \\alpha = \\tilde{O}(n^{-1/3} + (\\sqrt{d/n})^{3/7}) \\) in Theorem 3.12. There is a gap to a known lower bound of \\( \\alpha = \\Omega(1/\\sqrt{n} + \\sqrt{d/n}) \\) that holds even if privacy is not required and even if finding only an \\( \\alpha \\)-FOSP [ABG+22].\n\nMinimizing excess risk: We also provide sampling-based algorithms that aim to tackle the ultimate objective of finding a private solution \\( x_{\\text{priv}} \\in \\mathbb{R}^d \\) that minimizes the excess empirical risk: \\( E[FD(x_{\\text{priv}})] - \\min_{x \\in K} FD(x) \\), and the excess population risk, \\( E[FP(x_{\\text{priv}})] - \\min_{x \\in K} FP(x) \\), where the expectation is over the randomness on the solution \\( x_{\\text{priv}} \\). With a mild smoothness assumption, [WCX19] achieves in polynomial time a bound of \\( O(d \\log(1/\\delta)/(\u03b5^2 \\log n)) \\) for both excess empirical and population risks. In Table 1 we omit excess empirical risk, as the bounds are the same. We introduce a sampling-based algorithm from the exponential mechanism, which runs in polynomial time and achieves excess empirical and population risks bounded by \\( O(d \\log(1/\\delta)/(\u03b5 \\log(nd))) \\) with improved dependence on \\( \u03b5 \\) (Theorem 4.6). Moreover, we do not need the smoothness assumption required by [WCX19].\n\nIf we allow an exponential running time, [GTU22] demonstrated \\( \\tilde{O}(d/(\u03b5n)) \\) upper bound for non-convex excess empirical risks along with a nearly matching lower bound. It remained an open question to obtain a tight bound for the excess population risk. We close this gap by providing a nearly matching upper and lower bounds of \\( \\tilde{\\Theta}(d/(\u03b5n) + d/n) \\) for the excess population risk (Theorem 4.8)."}, {"type": "heading", "lvl": 3, "value": "Our techniques", "md": "### Our techniques"}, {"type": "text", "value": "Stationary points: We propose a simple framework based on SpiderBoost [WJZ+19] and its private version [ABG+22] that achieves the current best rate for finding the first order stationary point privately. In SGD and its variants, we usually get an estimation \\( \\Delta t \\) of the gradient \\( \\nabla f(x_t) \\). In the stochastic variance-reduced algorithm SpiderBoost, it only queries the gradient \\( O_1(x_t) \\approx \\nabla f(x_t) \\) directly every \\( q \\) steps with some oracle \\( O_1 \\), and for the other \\( q - 1 \\) steps in each period, it queries the difference between two steps, that is \\( O_2(x_t, x_{t-1}) \\approx \\nabla f(x_t) - \\nabla f(x_{t-1}) \\), and maintains \\( \\Delta t = \\Delta t - 1 + O_2(x_t, x_{t-1}) \\). One interpretation of the difference between these two kinds of oracles is that, in many situations, one can treat \\( O_1 \\) as more accurate and more costly (e.g., in computation or privacy budget), though our framework does not necessarily assume this.\n\nAs SpiderBoost queries \\( O_1 \\) every \\( q \\) steps, the error on the estimation may accumulate and \\( \\|\\Delta t - \\nabla f(x_t)\\| \\) can be large. Though on average, as shown in [ABG+22], these estimations can be good enough to find a private first-order stationary point, such a large deviation makes it challenging to analyze the behavior near a saddle point and to provide a tight analysis of the population risk.\n\n1We want \\( \\alpha = o(1) \\) and hence can assume \\( d \\leq n^2 \\).", "md": "Stationary points: We propose a simple framework based on SpiderBoost [WJZ+19] and its private version [ABG+22] that achieves the current best rate for finding the first order stationary point privately. In SGD and its variants, we usually get an estimation \\( \\Delta t \\) of the gradient \\( \\nabla f(x_t) \\). In the stochastic variance-reduced algorithm SpiderBoost, it only queries the gradient \\( O_1(x_t) \\approx \\nabla f(x_t) \\) directly every \\( q \\) steps with some oracle \\( O_1 \\), and for the other \\( q - 1 \\) steps in each period, it queries the difference between two steps, that is \\( O_2(x_t, x_{t-1}) \\approx \\nabla f(x_t) - \\nabla f(x_{t-1}) \\), and maintains \\( \\Delta t = \\Delta t - 1 + O_2(x_t, x_{t-1}) \\). One interpretation of the difference between these two kinds of oracles is that, in many situations, one can treat \\( O_1 \\) as more accurate and more costly (e.g., in computation or privacy budget), though our framework does not necessarily assume this.\n\nAs SpiderBoost queries \\( O_1 \\) every \\( q \\) steps, the error on the estimation may accumulate and \\( \\|\\Delta t - \\nabla f(x_t)\\| \\) can be large. Though on average, as shown in [ABG+22], these estimations can be good enough to find a private first-order stationary point, such a large deviation makes it challenging to analyze the behavior near a saddle point and to provide a tight analysis of the population risk.\n\n1We want \\( \\alpha = o(1) \\) and hence can assume \\( d \\leq n^2 \\)."}]}, {"page": 4, "text": "    In our framework, rather than using O1 once every q steps, we introduce a new technique of\nkeeping track of the total drift we make, i.e., driftt =  t i=\u03c4t \u2225xi \u2212xi\u22121\u222522, where \u03c4t is the last time\nstamp when we used O1. As we are considering smooth functions, the worst error to estimate\n\u2207f(xt) \u2212   \u2207f(xt\u22121) is proportional to \u2225xt \u2212   xt\u22121\u22252. When the driftt is small, we know the current\nestimation should still be good enough, and we do not need to get an expensive fresh estimation\nfrom O1. When driftt is large, the gradient estimation error may be large and we query O1 and get\n\u2206t = O1(xt). To control the total cost, we need an appropriate threshold to determine when the\ndrift is large. The smaller the threshold is, we can guarantee more accurate estimations but may\nneed to pay more cost for querying O1 more frequently.\n    We want to bound the total occurrences of the event that driftt is large, which leads to querying\nO1. A crucial observation is that, if driftt increases quickly, then the gradient norms are large\nand hence function values decrease quickly, which we know does not happen frequently under the\nstandard assumption that the function is bounded.\n    In our framework, we assume O1(x) is an unbiased estimation of \u2207f(x), and O1(x) \u2212\u2207f(x) is\nNorm-SubGaussian (Definition 2.2), and similarly O2(x, y) is an unbiased estimation of \u2207f(x) \u2212\n\u2207f(y) whose error is also Norm-SubGaussian. In the empirical case, we can simply add Gaussian\nnoises with appropriately chosen variances to the gradients of the empirical function \u2207FD for\nsimplicity, and one can choose a smaller batch size to reduce the computational complexity. In\nthe population case, we draw samples from the dataset without replacement to avoid dependence\nissues, and add the Gaussian noises to the sampled gradients. Hence we only need the gradient\noracle complexity to be linear in the number of samples for the population case.\nMinimizing excess risk.        Our polynomial time approach relies on the Log-Sobolev Inequality\n(LSI) and the classic Stroock perturbation lemma. The previous work of [MASN16] shows that\nif the density exp    \u2212  \u03b2FD(x) \u2212   r(x)  satisfies the LSI for some regularizer r, then sampling a\nmodel x from this density satisfies differential privacy with an appropriate (\u03b5, \u03b4).        If r is a \u00b5\nstrongly convex function, then the density proportional to exp(\u2212r) satisfies LSI with constant 1/\u00b5,\nand exp(\u2212\u03b2FD(x)\u2212r(x)) satisfies LSI with constant exp(maxx,y |FD(x)\u2212FD(y)|)/\u00b5 by the Stroock\nperturbation lemma. Our bound on the empirical risk follows from choosing the appropriate inverse\ntemperature \u03b2 and regularizer r to satisfy (\u03b5, \u03b4)-DP. The final bound on the population risk also\nfollows from LSI, which bounds the stability of the sample drawn from the respective distribution.\n    When running time is not concerned, we apply an exponential mechanism over a discretization of\nK to get the upper bound. The empirical risk bound follows from [BST14], and we use concentration\nof sums of bounded random variables to bound the maximum difference over the discretizations\nbetween the empirical and population risk. We show this is nearly tight by reductions from selection\nto non-convex Lipschitz optimization of [GTU22].\n1.3    Further related work\nIn the convex setting, it is feasible to achieve efficient algorithms with good risk guarantees.\nIn turn, differentially private empirical risk minimization (DP-ERM) [CM08, CMS11, CYS21,\nINS+19, KST12, BST14, TGTZ15, SCS13, SSTT21] and differentially private stochastic optimiza-\ntion [ALD21, BFTT19, BFGT20, FKT20, KLL21, AFKT21, KLZ22, GLL22, GTU22, CJJ+23,\nGLL+23] have been two of the most extensively studied problems in the DP literature.               Most\ncommon approaches are variants of DP-SGD [CMS11] or the exponential mechanism [MT07].\n    As for the non-convex optimization, due to the intrinsic challenges in minimizing general\nnon-convex functions, most of the previous works [WYX17, WJEG19, WX19, WCX19, ZCH+20,\nSSTT21, TC22, YZCL22, ABG+22, WB23, GW23] adopted the gradient norm as the accuracy\nmetric rather than risk.     Instead of minimizing the gradient norm discussed before, [BGM21]\ntried to minimize the stationarity gap of the population function privately, which is defined as\n                                                    4", "md": "# Math Equations and Text\n\nIn our framework, rather than using O1 once every q steps, we introduce a new technique of keeping track of the total drift we make, i.e., $$\\text{drift}_t = \\sum_{i=\\tau_t} \\|x_i - x_{i-1}\\|^2_2$$, where $\\tau_t$ is the last time stamp when we used O1. As we are considering smooth functions, the worst error to estimate $\\nabla f(x_t) - \\nabla f(x_{t-1})$ is proportional to $\\|x_t - x_{t-1}\\|^2$. When the driftt is small, we know the current estimation should still be good enough, and we do not need to get an expensive fresh estimation from O1. When driftt is large, the gradient estimation error may be large and we query O1 and get $\\Delta_t = O1(x_t)$. To control the total cost, we need an appropriate threshold to determine when the drift is large. The smaller the threshold is, we can guarantee more accurate estimations but may need to pay more cost for querying O1 more frequently.\n\nWe want to bound the total occurrences of the event that driftt is large, which leads to querying O1. A crucial observation is that, if driftt increases quickly, then the gradient norms are large and hence function values decrease quickly, which we know does not happen frequently under the standard assumption that the function is bounded.\n\nIn our framework, we assume O1(x) is an unbiased estimation of $\\nabla f(x)$, and $O1(x) - \\nabla f(x)$ is Norm-SubGaussian (Definition 2.2), and similarly O2(x, y) is an unbiased estimation of $\\nabla f(x) - \\nabla f(y)$ whose error is also Norm-SubGaussian. In the empirical case, we can simply add Gaussian noises with appropriately chosen variances to the gradients of the empirical function $\\nabla F_D$ for simplicity, and one can choose a smaller batch size to reduce the computational complexity. In the population case, we draw samples from the dataset without replacement to avoid dependence issues, and add the Gaussian noises to the sampled gradients. Hence we only need the gradient oracle complexity to be linear in the number of samples for the population case.\n\nMinimizing excess risk. Our polynomial time approach relies on the Log-Sobolev Inequality (LSI) and the classic Stroock perturbation lemma. The previous work of [MASN16] shows that if the density $\\exp(-\\beta F_D(x) - r(x))$ satisfies the LSI for some regularizer r, then sampling a model x from this density satisfies differential privacy with an appropriate ($\\epsilon, \\delta$). If r is a $\\mu$ strongly convex function, then the density proportional to $\\exp(-r)$ satisfies LSI with constant $1/\\mu$, and $\\exp(-\\beta F_D(x) - r(x))$ satisfies LSI with constant $\\exp(\\max_{x,y} |F_D(x) - F_D(y)|)/\\mu$ by the Stroock perturbation lemma. Our bound on the empirical risk follows from choosing the appropriate inverse temperature $\\beta$ and regularizer r to satisfy ($\\epsilon, \\delta$)-DP. The final bound on the population risk also follows from LSI, which bounds the stability of the sample drawn from the respective distribution.\n\nWhen running time is not concerned, we apply an exponential mechanism over a discretization of K to get the upper bound. The empirical risk bound follows from [BST14], and we use concentration of sums of bounded random variables to bound the maximum difference over the discretizations between the empirical and population risk. We show this is nearly tight by reductions from selection to non-convex Lipschitz optimization of [GTU22].\n\n### Further related work\n\nIn the convex setting, it is feasible to achieve efficient algorithms with good risk guarantees. In turn, differentially private empirical risk minimization (DP-ERM) [CM08, CMS11, CYS21, INS+19, KST12, BST14, TGTZ15, SCS13, SSTT21] and differentially private stochastic optimization [ALD21, BFTT19, BFGT20, FKT20, KLL21, AFKT21, KLZ22, GLL22, GTU22, CJJ+23, GLL+23] have been two of the most extensively studied problems in the DP literature. Most common approaches are variants of DP-SGD [CMS11] or the exponential mechanism [MT07].\n\nAs for the non-convex optimization, due to the intrinsic challenges in minimizing general non-convex functions, most of the previous works [WYX17, WJEG19, WX19, WCX19, ZCH+20, SSTT21, TC22, YZCL22, ABG+22, WB23, GW23] adopted the gradient norm as the accuracy metric rather than risk. Instead of minimizing the gradient norm discussed before, [BGM21] tried to minimize the stationarity gap of the population function privately, which is defined as 4.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Text", "md": "# Math Equations and Text"}, {"type": "text", "value": "In our framework, rather than using O1 once every q steps, we introduce a new technique of keeping track of the total drift we make, i.e., $$\\text{drift}_t = \\sum_{i=\\tau_t} \\|x_i - x_{i-1}\\|^2_2$$, where $\\tau_t$ is the last time stamp when we used O1. As we are considering smooth functions, the worst error to estimate $\\nabla f(x_t) - \\nabla f(x_{t-1})$ is proportional to $\\|x_t - x_{t-1}\\|^2$. When the driftt is small, we know the current estimation should still be good enough, and we do not need to get an expensive fresh estimation from O1. When driftt is large, the gradient estimation error may be large and we query O1 and get $\\Delta_t = O1(x_t)$. To control the total cost, we need an appropriate threshold to determine when the drift is large. The smaller the threshold is, we can guarantee more accurate estimations but may need to pay more cost for querying O1 more frequently.\n\nWe want to bound the total occurrences of the event that driftt is large, which leads to querying O1. A crucial observation is that, if driftt increases quickly, then the gradient norms are large and hence function values decrease quickly, which we know does not happen frequently under the standard assumption that the function is bounded.\n\nIn our framework, we assume O1(x) is an unbiased estimation of $\\nabla f(x)$, and $O1(x) - \\nabla f(x)$ is Norm-SubGaussian (Definition 2.2), and similarly O2(x, y) is an unbiased estimation of $\\nabla f(x) - \\nabla f(y)$ whose error is also Norm-SubGaussian. In the empirical case, we can simply add Gaussian noises with appropriately chosen variances to the gradients of the empirical function $\\nabla F_D$ for simplicity, and one can choose a smaller batch size to reduce the computational complexity. In the population case, we draw samples from the dataset without replacement to avoid dependence issues, and add the Gaussian noises to the sampled gradients. Hence we only need the gradient oracle complexity to be linear in the number of samples for the population case.\n\nMinimizing excess risk. Our polynomial time approach relies on the Log-Sobolev Inequality (LSI) and the classic Stroock perturbation lemma. The previous work of [MASN16] shows that if the density $\\exp(-\\beta F_D(x) - r(x))$ satisfies the LSI for some regularizer r, then sampling a model x from this density satisfies differential privacy with an appropriate ($\\epsilon, \\delta$). If r is a $\\mu$ strongly convex function, then the density proportional to $\\exp(-r)$ satisfies LSI with constant $1/\\mu$, and $\\exp(-\\beta F_D(x) - r(x))$ satisfies LSI with constant $\\exp(\\max_{x,y} |F_D(x) - F_D(y)|)/\\mu$ by the Stroock perturbation lemma. Our bound on the empirical risk follows from choosing the appropriate inverse temperature $\\beta$ and regularizer r to satisfy ($\\epsilon, \\delta$)-DP. The final bound on the population risk also follows from LSI, which bounds the stability of the sample drawn from the respective distribution.\n\nWhen running time is not concerned, we apply an exponential mechanism over a discretization of K to get the upper bound. The empirical risk bound follows from [BST14], and we use concentration of sums of bounded random variables to bound the maximum difference over the discretizations between the empirical and population risk. We show this is nearly tight by reductions from selection to non-convex Lipschitz optimization of [GTU22].", "md": "In our framework, rather than using O1 once every q steps, we introduce a new technique of keeping track of the total drift we make, i.e., $$\\text{drift}_t = \\sum_{i=\\tau_t} \\|x_i - x_{i-1}\\|^2_2$$, where $\\tau_t$ is the last time stamp when we used O1. As we are considering smooth functions, the worst error to estimate $\\nabla f(x_t) - \\nabla f(x_{t-1})$ is proportional to $\\|x_t - x_{t-1}\\|^2$. When the driftt is small, we know the current estimation should still be good enough, and we do not need to get an expensive fresh estimation from O1. When driftt is large, the gradient estimation error may be large and we query O1 and get $\\Delta_t = O1(x_t)$. To control the total cost, we need an appropriate threshold to determine when the drift is large. The smaller the threshold is, we can guarantee more accurate estimations but may need to pay more cost for querying O1 more frequently.\n\nWe want to bound the total occurrences of the event that driftt is large, which leads to querying O1. A crucial observation is that, if driftt increases quickly, then the gradient norms are large and hence function values decrease quickly, which we know does not happen frequently under the standard assumption that the function is bounded.\n\nIn our framework, we assume O1(x) is an unbiased estimation of $\\nabla f(x)$, and $O1(x) - \\nabla f(x)$ is Norm-SubGaussian (Definition 2.2), and similarly O2(x, y) is an unbiased estimation of $\\nabla f(x) - \\nabla f(y)$ whose error is also Norm-SubGaussian. In the empirical case, we can simply add Gaussian noises with appropriately chosen variances to the gradients of the empirical function $\\nabla F_D$ for simplicity, and one can choose a smaller batch size to reduce the computational complexity. In the population case, we draw samples from the dataset without replacement to avoid dependence issues, and add the Gaussian noises to the sampled gradients. Hence we only need the gradient oracle complexity to be linear in the number of samples for the population case.\n\nMinimizing excess risk. Our polynomial time approach relies on the Log-Sobolev Inequality (LSI) and the classic Stroock perturbation lemma. The previous work of [MASN16] shows that if the density $\\exp(-\\beta F_D(x) - r(x))$ satisfies the LSI for some regularizer r, then sampling a model x from this density satisfies differential privacy with an appropriate ($\\epsilon, \\delta$). If r is a $\\mu$ strongly convex function, then the density proportional to $\\exp(-r)$ satisfies LSI with constant $1/\\mu$, and $\\exp(-\\beta F_D(x) - r(x))$ satisfies LSI with constant $\\exp(\\max_{x,y} |F_D(x) - F_D(y)|)/\\mu$ by the Stroock perturbation lemma. Our bound on the empirical risk follows from choosing the appropriate inverse temperature $\\beta$ and regularizer r to satisfy ($\\epsilon, \\delta$)-DP. The final bound on the population risk also follows from LSI, which bounds the stability of the sample drawn from the respective distribution.\n\nWhen running time is not concerned, we apply an exponential mechanism over a discretization of K to get the upper bound. The empirical risk bound follows from [BST14], and we use concentration of sums of bounded random variables to bound the maximum difference over the discretizations between the empirical and population risk. We show this is nearly tight by reductions from selection to non-convex Lipschitz optimization of [GTU22]."}, {"type": "heading", "lvl": 3, "value": "Further related work", "md": "### Further related work"}, {"type": "text", "value": "In the convex setting, it is feasible to achieve efficient algorithms with good risk guarantees. In turn, differentially private empirical risk minimization (DP-ERM) [CM08, CMS11, CYS21, INS+19, KST12, BST14, TGTZ15, SCS13, SSTT21] and differentially private stochastic optimization [ALD21, BFTT19, BFGT20, FKT20, KLL21, AFKT21, KLZ22, GLL22, GTU22, CJJ+23, GLL+23] have been two of the most extensively studied problems in the DP literature. Most common approaches are variants of DP-SGD [CMS11] or the exponential mechanism [MT07].\n\nAs for the non-convex optimization, due to the intrinsic challenges in minimizing general non-convex functions, most of the previous works [WYX17, WJEG19, WX19, WCX19, ZCH+20, SSTT21, TC22, YZCL22, ABG+22, WB23, GW23] adopted the gradient norm as the accuracy metric rather than risk. Instead of minimizing the gradient norm discussed before, [BGM21] tried to minimize the stationarity gap of the population function privately, which is defined as 4.", "md": "In the convex setting, it is feasible to achieve efficient algorithms with good risk guarantees. In turn, differentially private empirical risk minimization (DP-ERM) [CM08, CMS11, CYS21, INS+19, KST12, BST14, TGTZ15, SCS13, SSTT21] and differentially private stochastic optimization [ALD21, BFTT19, BFGT20, FKT20, KLL21, AFKT21, KLZ22, GLL22, GTU22, CJJ+23, GLL+23] have been two of the most extensively studied problems in the DP literature. Most common approaches are variants of DP-SGD [CMS11] or the exponential mechanism [MT07].\n\nAs for the non-convex optimization, due to the intrinsic challenges in minimizing general non-convex functions, most of the previous works [WYX17, WJEG19, WX19, WCX19, ZCH+20, SSTT21, TC22, YZCL22, ABG+22, WB23, GW23] adopted the gradient norm as the accuracy metric rather than risk. Instead of minimizing the gradient norm discussed before, [BGM21] tried to minimize the stationarity gap of the population function privately, which is defined as 4."}]}, {"page": 5, "text": "Gap   FP(x) := maxy\u2208K\u27e8\u2207FP(x), x \u2212                   y\u27e9, which requires K to be a bounded domain. There are also\nsome different definitions of the second order stationary point. We refer the readers to [LRY+20]\nfor more details. Some more detailed comparisons on FOSP and SOSP in the DP literature can be\nfound in Appendix C.\n     The risk bound achieved by algorithms with polynomial running time is weak and requires\nn \u226b    d to be meaningful. Many previous works consider minimizing risks of non-convex functions\nunder stronger assumptions, such as, Polyak-Lojasiewicz condition [WYX17, ZMLX21], Generalized\nlinear model (GLM) [WCX19] and weakly convex functions [BGM21].\n     In the (non-private) classic stochastic optimization, there is a long line of influential works on\nfinding the first and second-order stationary points for non-convex functions, [AAZB+17, JGN+17,\nFLLZ18, XJY18, CO19].\n2      Preliminary\nThroughout the paper, if not stated explicitly, the norm \u2225                           \u00b7 \u2225  means the \u21132 norm.\nDefinition 2.1 (Lipschitz and Smoothness). Given a function f : K \u2192                                     R, we say f is G-Lipschitz,\nif for all x1, x2 \u2208      K, |f(x1) \u2212      f(x2)| \u2264      G\u2225x1 \u2212     x2\u2225, and we say a function f : K \u2192                   R is M-smooth,\nif for all x1, x2 \u2208      K, \u2225\u2207f(x1) \u2212          \u2207f(x2)\u2225      \u2264  M\u2225x1 \u2212       x2\u2225.\nDefinition 2.2 (SubGaussian, and Norm-SubGaussian). A random vector x \u2208                                             Rd is SubGaussian\n(SG(\u03b6)) if there exists a positive constant \u03b6 such that E e\u27e8v,x\u2212E x\u27e9                            \u2264  e\u2225v\u22252\u03b62/2, \u2200v \u2208\u2212  t2    Rd. x \u2208     Rd is\nnorm-SubGaussian (nSG(\u03b6)) if there exists \u03b6 such that Pr[\u2225x \u2212                                E x\u2225   \u2265   t] \u2264   2e   2\u03b62 , \u2200t \u2208   R.\nFact 2.3. For a Gaussian \u03b8 \u223c                 N(0, \u03c32Id), \u03b8 is SG(\u03c3) and nSG(\u03c3                   \u221a  d).\nLemma 2.4 (Hoeffding type inequality for norm-subGaussian, [JNG+19]). Let x1, \u00b7 \u00b7 \u00b7 , xk \u2208                                             Rd be\nrandom vectors, and for each i \u2208                [k], xi | Fi\u22121 is zero-mean nSG(\u03b6i) where Fi is the corresponding\nfi\n ltration. Then there exists an absolute constant c such that for any \u03b4 > 0, with probability at least\n1 \u2212  \u03c9, \u2225    k i=1 xi\u2225    \u2264  c \u00b7   k    i=1 \u03b62 i log(2d/\u03c9), which means  k              i=1 xi is nSG(          c log(d)  k    i=1 \u03b62 i ).\nDefinition 2.5 (Laplace distribution). We say X \u223c                                   Lap(b) if X has density f(X = x) =\n1\n2b exp(\u2212|x| b ).\nTheorem 2.6 (Matrix Bernstein inequality, [Tro15]). Consider a sequence {Xi}i\u2208m of independent,\nmean-zero, symmetric d \u00d7 d random matrices. If for each matrix Xi, we know \u2225Xi\u2225op \u2264   \u2212t2        , where \u03c32 = \u2225                    M, then\nfor all t \u2265    0, we have Pr          \u2225    i\u2208[m] Xi\u2225op \u2265       t   \u2264  d exp      2(\u03c32+Mt/3)                                i\u2208[m] E X2  i \u2225op.\nTheorem 2.7 (Basic composition, [DR+14]). If A1 is (\u03b51, \u03b41)-DP and A2 is (\u03b52, \u03b42)-DP, then their\ncombination is (\u03b51 + \u03b52, \u03b41 + \u03b42)-DP.\nTheorem 2.8 (Advanced composition, [KOV15]). For \u03b5 \u2264                                   0.9, an end-to-end guarantee of (\u03b5, \u03b4)-\ndifferential privacy is satisfi          ed if a database is accessed at most k times, where each time with a\n(\u03b5/(2     2k log(2/\u03b4)), \u03b4/(2k))-differentially private mechanism.\n     Due to space limit, some proofs are left in the Appendix.\n3      Convergence to Stationary points\nWe follow the assumptions of [WCX19], which also studies privately finding an \u03b1-SOSP.\n                                                                      5", "md": "Gap   $$FP(x) := \\max_{y \\in K} \\langle \\nabla FP(x), x - y \\rangle$$, which requires K to be a bounded domain. There are also\nsome different definitions of the second order stationary point. We refer the readers to [LRY+20]\nfor more details. Some more detailed comparisons on FOSP and SOSP in the DP literature can be\nfound in Appendix C.\n\nThe risk bound achieved by algorithms with polynomial running time is weak and requires\n$$n \\gg d$$ to be meaningful. Many previous works consider minimizing risks of non-convex functions\nunder stronger assumptions, such as, Polyak-Lojasiewicz condition [WYX17], [ZMLX21], Generalized\nlinear model (GLM) [WCX19] and weakly convex functions [BGM21].\n\nIn the (non-private) classic stochastic optimization, there is a long line of influential works on\nfinding the first and second-order stationary points for non-convex functions, [AAZB+17], [JGN+17],\n[FLLZ18], [XJY18], [CO19].\n\n## Preliminary\n\nThroughout the paper, if not stated explicitly, the norm $$\\| \\cdot \\|$$ means the \u21132 norm.\n\nDefinition 2.1 (Lipschitz and Smoothness). Given a function $$f : K \\to \\mathbb{R}$$, we say f is G-Lipschitz,\nif for all $$x_1, x_2 \\in K$$, $$|f(x_1) - f(x_2)| \\le G\\|x_1 - x_2\\|$$, and we say a function $$f : K \\to \\mathbb{R}$$ is M-smooth,\nif for all $$x_1, x_2 \\in K$$, $$\\|\\nabla f(x_1) - \\nabla f(x_2)\\| \\le M\\|x_1 - x_2\\|$$.\n\nDefinition 2.2 (SubGaussian, and Norm-SubGaussian). A random vector $$x \\in \\mathbb{R}^d$$ is SubGaussian\n(SG(\u03b6)) if there exists a positive constant \u03b6 such that $$E e^{\\langle v, x - E[x] \\rangle} \\le e^{\\|v\\|^2\u03b6^2/2}, \\forall v \\in \\mathbb{R}^d$$. x \\in \\mathbb{R}^d$$ is\nnorm-SubGaussian (nSG(\u03b6)) if there exists \u03b6 such that $$Pr[\\|x - E[x]\\| \\ge t] \\le 2e^{-2\u03b6^2}, \\forall t \\in \\mathbb{R}$$.\n\nFact 2.3. For a Gaussian $$\\theta \\sim N(0, \\sigma^2I_d)$$, $$\\theta$$ is SG(\u03c3) and nSG($$\\sigma \\sqrt{d}$$).\n\nLemma 2.4 (Hoeffding type inequality for norm-subGaussian, [JNG+19]). Let $$x_1, \\ldots, x_k \\in \\mathbb{R}^d$$ be\nrandom vectors, and for each $$i \\in [k]$$, $$x_i | F_{i-1}$$ is zero-mean nSG(\u03b6_i) where F_i is the corresponding\nfiltration. Then there exists an absolute constant c such that for any $$\\delta > 0$$, with probability at least\n$$1 - \\omega$$, $$\\| \\sum_{i=1}^k x_i \\| \\le c \\cdot \\sqrt{ \\sum_{i=1}^k \\zeta_i^2 \\log(2d/\\omega) }$$, which means $$\\sum_{i=1}^k x_i$$ is nSG($$c \\log(d) \\sqrt{ \\sum_{i=1}^k \\zeta_i^2 }$$).\n\nDefinition 2.5 (Laplace distribution). We say $$X \\sim Lap(b)$$ if X has density $$f(X = x) = \\frac{1}{2b} \\exp(-|x|/b)$$.\n\nTheorem 2.6 (Matrix Bernstein inequality, [Tro15]). Consider a sequence {Xi}i\u2208m of independent,\nmean-zero, symmetric d \u00d7 d random matrices. If for each matrix Xi, we know $$\\|X_i\\|_{op} \\le -t^2$$, where $$\\sigma^2 = \\|M$$, then\nfor all $$t \\ge 0$$, we have $$Pr\\left( \\| \\sum_{i=1}^m X_i \\|_{op} \\ge t \\right) \\le d \\exp\\left( 2(\\sigma^2 + Mt/3) \\sum_{i=1}^m E[X_i^2] \\|_{op} \\right)$$.\n\nTheorem 2.7 (Basic composition, [DR+14]). If A1 is (\u03b51, \u03b41)-DP and A2 is (\u03b52, \u03b42)-DP, then their\ncombination is $$(\\epsilon_1 + \\epsilon_2, \\delta_1 + \\delta_2)$$-DP.\n\nTheorem 2.8 (Advanced composition, [KOV15]). For $$\\epsilon \\le 0.9$$, an end-to-end guarantee of $$(\\epsilon, \\delta)$$-\ndifferential privacy is satisfied if a database is accessed at most k times, where each time with a\n$$(\\epsilon/(2^{k+1}), \\delta/(2k))$$-differentially private mechanism.\n\nDue to space limit, some proofs are left in the Appendix.\n\n## Convergence to Stationary points\n\nWe follow the assumptions of [WCX19], which also studies privately finding an \u03b1-SOSP.", "images": [], "items": [{"type": "text", "value": "Gap   $$FP(x) := \\max_{y \\in K} \\langle \\nabla FP(x), x - y \\rangle$$, which requires K to be a bounded domain. There are also\nsome different definitions of the second order stationary point. We refer the readers to [LRY+20]\nfor more details. Some more detailed comparisons on FOSP and SOSP in the DP literature can be\nfound in Appendix C.\n\nThe risk bound achieved by algorithms with polynomial running time is weak and requires\n$$n \\gg d$$ to be meaningful. Many previous works consider minimizing risks of non-convex functions\nunder stronger assumptions, such as, Polyak-Lojasiewicz condition [WYX17], [ZMLX21], Generalized\nlinear model (GLM) [WCX19] and weakly convex functions [BGM21].\n\nIn the (non-private) classic stochastic optimization, there is a long line of influential works on\nfinding the first and second-order stationary points for non-convex functions, [AAZB+17], [JGN+17],\n[FLLZ18], [XJY18], [CO19].", "md": "Gap   $$FP(x) := \\max_{y \\in K} \\langle \\nabla FP(x), x - y \\rangle$$, which requires K to be a bounded domain. There are also\nsome different definitions of the second order stationary point. We refer the readers to [LRY+20]\nfor more details. Some more detailed comparisons on FOSP and SOSP in the DP literature can be\nfound in Appendix C.\n\nThe risk bound achieved by algorithms with polynomial running time is weak and requires\n$$n \\gg d$$ to be meaningful. Many previous works consider minimizing risks of non-convex functions\nunder stronger assumptions, such as, Polyak-Lojasiewicz condition [WYX17], [ZMLX21], Generalized\nlinear model (GLM) [WCX19] and weakly convex functions [BGM21].\n\nIn the (non-private) classic stochastic optimization, there is a long line of influential works on\nfinding the first and second-order stationary points for non-convex functions, [AAZB+17], [JGN+17],\n[FLLZ18], [XJY18], [CO19]."}, {"type": "heading", "lvl": 2, "value": "Preliminary", "md": "## Preliminary"}, {"type": "text", "value": "Throughout the paper, if not stated explicitly, the norm $$\\| \\cdot \\|$$ means the \u21132 norm.\n\nDefinition 2.1 (Lipschitz and Smoothness). Given a function $$f : K \\to \\mathbb{R}$$, we say f is G-Lipschitz,\nif for all $$x_1, x_2 \\in K$$, $$|f(x_1) - f(x_2)| \\le G\\|x_1 - x_2\\|$$, and we say a function $$f : K \\to \\mathbb{R}$$ is M-smooth,\nif for all $$x_1, x_2 \\in K$$, $$\\|\\nabla f(x_1) - \\nabla f(x_2)\\| \\le M\\|x_1 - x_2\\|$$.\n\nDefinition 2.2 (SubGaussian, and Norm-SubGaussian). A random vector $$x \\in \\mathbb{R}^d$$ is SubGaussian\n(SG(\u03b6)) if there exists a positive constant \u03b6 such that $$E e^{\\langle v, x - E[x] \\rangle} \\le e^{\\|v\\|^2\u03b6^2/2}, \\forall v \\in \\mathbb{R}^d$$. x \\in \\mathbb{R}^d$$ is\nnorm-SubGaussian (nSG(\u03b6)) if there exists \u03b6 such that $$Pr[\\|x - E[x]\\| \\ge t] \\le 2e^{-2\u03b6^2}, \\forall t \\in \\mathbb{R}$$.\n\nFact 2.3. For a Gaussian $$\\theta \\sim N(0, \\sigma^2I_d)$$, $$\\theta$$ is SG(\u03c3) and nSG($$\\sigma \\sqrt{d}$$).\n\nLemma 2.4 (Hoeffding type inequality for norm-subGaussian, [JNG+19]). Let $$x_1, \\ldots, x_k \\in \\mathbb{R}^d$$ be\nrandom vectors, and for each $$i \\in [k]$$, $$x_i | F_{i-1}$$ is zero-mean nSG(\u03b6_i) where F_i is the corresponding\nfiltration. Then there exists an absolute constant c such that for any $$\\delta > 0$$, with probability at least\n$$1 - \\omega$$, $$\\| \\sum_{i=1}^k x_i \\| \\le c \\cdot \\sqrt{ \\sum_{i=1}^k \\zeta_i^2 \\log(2d/\\omega) }$$, which means $$\\sum_{i=1}^k x_i$$ is nSG($$c \\log(d) \\sqrt{ \\sum_{i=1}^k \\zeta_i^2 }$$).\n\nDefinition 2.5 (Laplace distribution). We say $$X \\sim Lap(b)$$ if X has density $$f(X = x) = \\frac{1}{2b} \\exp(-|x|/b)$$.\n\nTheorem 2.6 (Matrix Bernstein inequality, [Tro15]). Consider a sequence {Xi}i\u2208m of independent,\nmean-zero, symmetric d \u00d7 d random matrices. If for each matrix Xi, we know $$\\|X_i\\|_{op} \\le -t^2$$, where $$\\sigma^2 = \\|M$$, then\nfor all $$t \\ge 0$$, we have $$Pr\\left( \\| \\sum_{i=1}^m X_i \\|_{op} \\ge t \\right) \\le d \\exp\\left( 2(\\sigma^2 + Mt/3) \\sum_{i=1}^m E[X_i^2] \\|_{op} \\right)$$.\n\nTheorem 2.7 (Basic composition, [DR+14]). If A1 is (\u03b51, \u03b41)-DP and A2 is (\u03b52, \u03b42)-DP, then their\ncombination is $$(\\epsilon_1 + \\epsilon_2, \\delta_1 + \\delta_2)$$-DP.\n\nTheorem 2.8 (Advanced composition, [KOV15]). For $$\\epsilon \\le 0.9$$, an end-to-end guarantee of $$(\\epsilon, \\delta)$$-\ndifferential privacy is satisfied if a database is accessed at most k times, where each time with a\n$$(\\epsilon/(2^{k+1}), \\delta/(2k))$$-differentially private mechanism.\n\nDue to space limit, some proofs are left in the Appendix.", "md": "Throughout the paper, if not stated explicitly, the norm $$\\| \\cdot \\|$$ means the \u21132 norm.\n\nDefinition 2.1 (Lipschitz and Smoothness). Given a function $$f : K \\to \\mathbb{R}$$, we say f is G-Lipschitz,\nif for all $$x_1, x_2 \\in K$$, $$|f(x_1) - f(x_2)| \\le G\\|x_1 - x_2\\|$$, and we say a function $$f : K \\to \\mathbb{R}$$ is M-smooth,\nif for all $$x_1, x_2 \\in K$$, $$\\|\\nabla f(x_1) - \\nabla f(x_2)\\| \\le M\\|x_1 - x_2\\|$$.\n\nDefinition 2.2 (SubGaussian, and Norm-SubGaussian). A random vector $$x \\in \\mathbb{R}^d$$ is SubGaussian\n(SG(\u03b6)) if there exists a positive constant \u03b6 such that $$E e^{\\langle v, x - E[x] \\rangle} \\le e^{\\|v\\|^2\u03b6^2/2}, \\forall v \\in \\mathbb{R}^d$$. x \\in \\mathbb{R}^d$$ is\nnorm-SubGaussian (nSG(\u03b6)) if there exists \u03b6 such that $$Pr[\\|x - E[x]\\| \\ge t] \\le 2e^{-2\u03b6^2}, \\forall t \\in \\mathbb{R}$$.\n\nFact 2.3. For a Gaussian $$\\theta \\sim N(0, \\sigma^2I_d)$$, $$\\theta$$ is SG(\u03c3) and nSG($$\\sigma \\sqrt{d}$$).\n\nLemma 2.4 (Hoeffding type inequality for norm-subGaussian, [JNG+19]). Let $$x_1, \\ldots, x_k \\in \\mathbb{R}^d$$ be\nrandom vectors, and for each $$i \\in [k]$$, $$x_i | F_{i-1}$$ is zero-mean nSG(\u03b6_i) where F_i is the corresponding\nfiltration. Then there exists an absolute constant c such that for any $$\\delta > 0$$, with probability at least\n$$1 - \\omega$$, $$\\| \\sum_{i=1}^k x_i \\| \\le c \\cdot \\sqrt{ \\sum_{i=1}^k \\zeta_i^2 \\log(2d/\\omega) }$$, which means $$\\sum_{i=1}^k x_i$$ is nSG($$c \\log(d) \\sqrt{ \\sum_{i=1}^k \\zeta_i^2 }$$).\n\nDefinition 2.5 (Laplace distribution). We say $$X \\sim Lap(b)$$ if X has density $$f(X = x) = \\frac{1}{2b} \\exp(-|x|/b)$$.\n\nTheorem 2.6 (Matrix Bernstein inequality, [Tro15]). Consider a sequence {Xi}i\u2208m of independent,\nmean-zero, symmetric d \u00d7 d random matrices. If for each matrix Xi, we know $$\\|X_i\\|_{op} \\le -t^2$$, where $$\\sigma^2 = \\|M$$, then\nfor all $$t \\ge 0$$, we have $$Pr\\left( \\| \\sum_{i=1}^m X_i \\|_{op} \\ge t \\right) \\le d \\exp\\left( 2(\\sigma^2 + Mt/3) \\sum_{i=1}^m E[X_i^2] \\|_{op} \\right)$$.\n\nTheorem 2.7 (Basic composition, [DR+14]). If A1 is (\u03b51, \u03b41)-DP and A2 is (\u03b52, \u03b42)-DP, then their\ncombination is $$(\\epsilon_1 + \\epsilon_2, \\delta_1 + \\delta_2)$$-DP.\n\nTheorem 2.8 (Advanced composition, [KOV15]). For $$\\epsilon \\le 0.9$$, an end-to-end guarantee of $$(\\epsilon, \\delta)$$-\ndifferential privacy is satisfied if a database is accessed at most k times, where each time with a\n$$(\\epsilon/(2^{k+1}), \\delta/(2k))$$-differentially private mechanism.\n\nDue to space limit, some proofs are left in the Appendix."}, {"type": "heading", "lvl": 2, "value": "Convergence to Stationary points", "md": "## Convergence to Stationary points"}, {"type": "text", "value": "We follow the assumptions of [WCX19], which also studies privately finding an \u03b1-SOSP.", "md": "We follow the assumptions of [WCX19], which also studies privately finding an \u03b1-SOSP."}]}, {"page": 6, "text": "Assumption 3.1. Any function drawn from P is G-Lipschitz, \u03c1-Hessian Lipschitz, and M-smooth,\nalmost surely, and the risk is upper bounded by B.\n      As discussed before, we define two different kinds of gradient oracles, one for estimating the\ngradient at one point and the other for estimating the gradient difference at two points.\nDefinition 3.2 (SubGaussian gradient oracles). For a G-Lipschitz and M-smooth function F:\n(1) We say O1 is a fi           rst kind of \u03b61 norm-subGaussian Gradient oracle if given x \u2208                                  Rd, O(x) satisfi    es\nE O1(x) = \u2207F(x) and O1(x) \u2212                      \u2207F(x) is nSG(\u03b61).\n(2) We say O2 is a second kind of \u03b62 norm-subGaussian stochastic Gradient oracle if given x, y \u2208                                                Rd,\nO2(x, y) satisfi       es that E O2(x, y) = \u2207F(x)\u2212\u2207F(y) and O2(x, y)\u2212(\u2207F(x)\u2212\u2207F(y)) is nSG(\u03b62\u2225x\u2212\ny\u2225).  Note that we should assume M \u2265                       \u221a  \u03c1\u03b1 to make finding a second-order stationary point strictly\nmore challenging than finding a first-order stationary point. We use smin(\u00b7) to denote the smallest\neigenvalue of a matrix.\n3.1       Meta framework\nAlgorithm 1 Stochastic Spider\n  1: Input: Objective function F, Gradient Oracle O1, O2 with SubGaussian parameters \u03b61 and \u03b62,\n      parameters of objective function B, M, G, \u03c1, parameter \u03ba, failure probability \u03c9\n                                                                               M log( dMB\n  2: Set \u03b3 =           4C(\u03b62  2\u03ba + 4\u03b62    1) \u00b7 log(BMd/\u03c1\u03c9), \u0393 =                     \u221a \u03c1\u03b3\u03c1\u03b3\u03c9 )\n  3: Set \u03b7 = 1/M, t = 0, T = BM log4(dMB                     \u03c1\u03b3\u03c9 )/\u03b32\n  4: Set drift0 = \u03ba, frozen = 1, \u2207\u22121 = 0\n  5: while t \u2264         T do\n  6:      if \u2225\u2207t\u22121\u2225       \u2264   \u03b3 log3(BMd/\u03c1\u03c9)                frozent\u22121 \u2264        0 then\n  7:         frozent = \u0393, driftt = 0\n  8:         \u2207t = O1(xt) + gt, where gt \u223c                   N  (0, \u03b62d1Id)\n  9:      else if driftt\u22121 \u2265          \u03ba then\n 10:         \u2207t = O1(xt), driftt = 0, frozent = frozent\u22121 \u2212                          1\n 11:      else\n 12:         \u2206t = O2(xt, xt\u22121), \u2207t = \u2207t\u22121 + \u2206t, frozent = frozent\u22121 \u2212                                   1\n 13:      end if\n 14:      xt+1 = xt \u2212        \u03b7\u2207t, driftt = driftt\u22121 + \u03b72\u2225\u2207t\u22252               2, t = t + 1\n 15: end while\n 16: Return: {x1, \u00b7 \u00b7 \u00b7 , xT }\n      We demonstrate a framework based on the SpiderBoost in Algorithm 1. Our analysis of Algo-\nrithm 1 builds upon three key properties we prove in this section: (i) \u2207t is consistently close to the\ntrue gradient \u2207F(xt) with high probability; (ii) the algorithm can escape the saddle point with\nhigh probability, and (iii) a large drift implies significant decrease in the function value, allowing\nus to limit the number of queries to the more accurate but more expensive first kind of gradient\noracle O1.\nLemma 3.3. For any 0 \u2264                     t \u2264   T and letting \u03c4t \u2264            t be the largest integer such that drift\u03c4t is set to\nbe 0, with probability at least 1 \u2212                 \u03c9/T    , for some universal constant C > 0, we have\n                                                                   t\n                         \u2225\u2207t \u2212      \u2207F(xt)\u22252 \u2264           \u03b622 \u00b7 i=\u03c4t+1    \u2225xi6\u2212    xi\u22121\u22252 + 4\u03b62      1   \u00b7 C \u00b7 log(T     d/\u03c9).                    (1)", "md": "Assumption 3.1. Any function drawn from P is G-Lipschitz, \u03c1-Hessian Lipschitz, and M-smooth, almost surely, and the risk is upper bounded by B.\n\nAs discussed before, we define two different kinds of gradient oracles, one for estimating the gradient at one point and the other for estimating the gradient difference at two points.\n\nDefinition 3.2 (SubGaussian gradient oracles). For a G-Lipschitz and M-smooth function F:\n1. We say O1 is a first kind of \u03b61 norm-subGaussian Gradient oracle if given $$x \\in \\mathbb{R}^d$$, $$O(x)$$ satisfies\n$$\nE O1(x) = \\nabla F(x) \\text{ and } O1(x) - \\nabla F(x) \\text{ is nSG}(\\zeta_1).\n$$\n2. We say O2 is a second kind of \u03b62 norm-subGaussian stochastic Gradient oracle if given $$x, y \\in \\mathbb{R}^d$$,\n$$O2(x, y)$$ satisfies that $$E O2(x, y) = \\nabla F(x) - \\nabla F(y)$$ and $$O2(x, y) - (\\nabla F(x) - \\nabla F(y))$$ is nSG$$(\\zeta_2 \\|x - y\\|)$$. Note that we should assume $$M \\geq \\sqrt{\\rho \\alpha}$$ to make finding a second-order stationary point strictly more challenging than finding a first-order stationary point. We use $$s_{\\text{min}}(\\cdot)$$ to denote the smallest eigenvalue of a matrix.\n\n### Meta framework\n**Algorithm 1 Stochastic Spider**\n1. **Input:** Objective function F, Gradient Oracle O1, O2 with SubGaussian parameters $$\\zeta_1$$ and $$\\zeta_2$$, parameters of objective function B, M, G, $$\\rho$$, parameter $$\\kappa$$, failure probability $$\\omega$$\n2. Set $$\\gamma = 4C(\\zeta_2^2\\kappa + 4\\zeta_2^2) \\cdot \\log(BMd/\\rho\\omega)$$, $$\\Gamma = \\sqrt{\\rho\\gamma\\rho\\gamma\\omega}$$\n3. Set $$\\eta = 1/M$$, $$t = 0$$, $$T = BM \\cdot \\log^4(dMB/\\rho\\gamma\\omega)/\\gamma^2$$\n4. Set $$\\text{drift}_0 = \\kappa$$, $$\\text{frozen} = 1$$, $$\\nabla^{-1} = 0$$\n5. **while** $$t \\leq T$$ **do**\n- **if** $$\\| \\nabla_{t-1} \\| \\leq \\gamma \\log^3(BMd/\\rho\\omega)$$ **and** $$\\text{frozen}_{t-1} \\leq 0$$ **then**\n- $$\\text{frozen}_t = \\Gamma$$, $$\\text{drift}_t = 0$$\n- $$\\nabla_t = O1(x_t) + g_t$$, where $$g_t \\sim \\mathcal{N}(0, \\zeta_2 dI_d)$$\n- **else if** $$\\text{drift}_{t-1} \\geq \\kappa$$ **then**\n- $$\\nabla_t = O1(x_t)$$, $$\\text{drift}_t = 0$$, $$\\text{frozen} = \\text{frozen}_{t-1} - 1$$\n- **else**\n- $$\\Delta_t = O2(x_t, x_{t-1})$$, $$\\nabla_t = \\nabla_{t-1} + \\Delta_t$$, $$\\text{frozen} = \\text{frozen}_{t-1} - 1$$\n- $$x_{t+1} = x_t - \\eta \\nabla_t$$, $$\\text{drift}_t = \\text{drift}_{t-1} + \\eta^2 \\| \\nabla_t \\|_2^2$$, $$t = t + 1$$\n6. **end while**\n7. **Return:** $$\\{x_1, \\ldots, x_T\\}$$\n\nWe demonstrate a framework based on the SpiderBoost in Algorithm 1. Our analysis of Algorithm 1 builds upon three key properties we prove in this section: (i) $$\\nabla_t$$ is consistently close to the true gradient $$\\nabla F(x_t)$$ with high probability; (ii) the algorithm can escape the saddle point with high probability, and (iii) a large drift implies a significant decrease in the function value, allowing us to limit the number of queries to the more accurate but more expensive first kind of gradient oracle $$O1$$.\n\n**Lemma 3.3.** For any $$0 \\leq t \\leq T$$ and letting $$\\tau_t \\leq t$$ be the largest integer such that $$\\text{drift}_{\\tau_t}$$ is set to be 0, with probability at least $$1 - \\omega/T$$, for some universal constant $$C > 0$$, we have\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2 \\leq \\zeta_2^2 \\cdot \\sum_{i=\\tau_t+1}^t \\|x_i - x_{i-1}\\|_2^2 + 4\\zeta_2^2 \\cdot C \\cdot \\log(Td/\\omega). \\quad (1)\n$$", "images": [], "items": [{"type": "text", "value": "Assumption 3.1. Any function drawn from P is G-Lipschitz, \u03c1-Hessian Lipschitz, and M-smooth, almost surely, and the risk is upper bounded by B.\n\nAs discussed before, we define two different kinds of gradient oracles, one for estimating the gradient at one point and the other for estimating the gradient difference at two points.\n\nDefinition 3.2 (SubGaussian gradient oracles). For a G-Lipschitz and M-smooth function F:\n1. We say O1 is a first kind of \u03b61 norm-subGaussian Gradient oracle if given $$x \\in \\mathbb{R}^d$$, $$O(x)$$ satisfies\n$$\nE O1(x) = \\nabla F(x) \\text{ and } O1(x) - \\nabla F(x) \\text{ is nSG}(\\zeta_1).\n$$\n2. We say O2 is a second kind of \u03b62 norm-subGaussian stochastic Gradient oracle if given $$x, y \\in \\mathbb{R}^d$$,\n$$O2(x, y)$$ satisfies that $$E O2(x, y) = \\nabla F(x) - \\nabla F(y)$$ and $$O2(x, y) - (\\nabla F(x) - \\nabla F(y))$$ is nSG$$(\\zeta_2 \\|x - y\\|)$$. Note that we should assume $$M \\geq \\sqrt{\\rho \\alpha}$$ to make finding a second-order stationary point strictly more challenging than finding a first-order stationary point. We use $$s_{\\text{min}}(\\cdot)$$ to denote the smallest eigenvalue of a matrix.", "md": "Assumption 3.1. Any function drawn from P is G-Lipschitz, \u03c1-Hessian Lipschitz, and M-smooth, almost surely, and the risk is upper bounded by B.\n\nAs discussed before, we define two different kinds of gradient oracles, one for estimating the gradient at one point and the other for estimating the gradient difference at two points.\n\nDefinition 3.2 (SubGaussian gradient oracles). For a G-Lipschitz and M-smooth function F:\n1. We say O1 is a first kind of \u03b61 norm-subGaussian Gradient oracle if given $$x \\in \\mathbb{R}^d$$, $$O(x)$$ satisfies\n$$\nE O1(x) = \\nabla F(x) \\text{ and } O1(x) - \\nabla F(x) \\text{ is nSG}(\\zeta_1).\n$$\n2. We say O2 is a second kind of \u03b62 norm-subGaussian stochastic Gradient oracle if given $$x, y \\in \\mathbb{R}^d$$,\n$$O2(x, y)$$ satisfies that $$E O2(x, y) = \\nabla F(x) - \\nabla F(y)$$ and $$O2(x, y) - (\\nabla F(x) - \\nabla F(y))$$ is nSG$$(\\zeta_2 \\|x - y\\|)$$. Note that we should assume $$M \\geq \\sqrt{\\rho \\alpha}$$ to make finding a second-order stationary point strictly more challenging than finding a first-order stationary point. We use $$s_{\\text{min}}(\\cdot)$$ to denote the smallest eigenvalue of a matrix."}, {"type": "heading", "lvl": 3, "value": "Meta framework", "md": "### Meta framework"}, {"type": "text", "value": "**Algorithm 1 Stochastic Spider**\n1. **Input:** Objective function F, Gradient Oracle O1, O2 with SubGaussian parameters $$\\zeta_1$$ and $$\\zeta_2$$, parameters of objective function B, M, G, $$\\rho$$, parameter $$\\kappa$$, failure probability $$\\omega$$\n2. Set $$\\gamma = 4C(\\zeta_2^2\\kappa + 4\\zeta_2^2) \\cdot \\log(BMd/\\rho\\omega)$$, $$\\Gamma = \\sqrt{\\rho\\gamma\\rho\\gamma\\omega}$$\n3. Set $$\\eta = 1/M$$, $$t = 0$$, $$T = BM \\cdot \\log^4(dMB/\\rho\\gamma\\omega)/\\gamma^2$$\n4. Set $$\\text{drift}_0 = \\kappa$$, $$\\text{frozen} = 1$$, $$\\nabla^{-1} = 0$$\n5. **while** $$t \\leq T$$ **do**\n- **if** $$\\| \\nabla_{t-1} \\| \\leq \\gamma \\log^3(BMd/\\rho\\omega)$$ **and** $$\\text{frozen}_{t-1} \\leq 0$$ **then**\n- $$\\text{frozen}_t = \\Gamma$$, $$\\text{drift}_t = 0$$\n- $$\\nabla_t = O1(x_t) + g_t$$, where $$g_t \\sim \\mathcal{N}(0, \\zeta_2 dI_d)$$\n- **else if** $$\\text{drift}_{t-1} \\geq \\kappa$$ **then**\n- $$\\nabla_t = O1(x_t)$$, $$\\text{drift}_t = 0$$, $$\\text{frozen} = \\text{frozen}_{t-1} - 1$$\n- **else**\n- $$\\Delta_t = O2(x_t, x_{t-1})$$, $$\\nabla_t = \\nabla_{t-1} + \\Delta_t$$, $$\\text{frozen} = \\text{frozen}_{t-1} - 1$$\n- $$x_{t+1} = x_t - \\eta \\nabla_t$$, $$\\text{drift}_t = \\text{drift}_{t-1} + \\eta^2 \\| \\nabla_t \\|_2^2$$, $$t = t + 1$$\n6. **end while**\n7. **Return:** $$\\{x_1, \\ldots, x_T\\}$$\n\nWe demonstrate a framework based on the SpiderBoost in Algorithm 1. Our analysis of Algorithm 1 builds upon three key properties we prove in this section: (i) $$\\nabla_t$$ is consistently close to the true gradient $$\\nabla F(x_t)$$ with high probability; (ii) the algorithm can escape the saddle point with high probability, and (iii) a large drift implies a significant decrease in the function value, allowing us to limit the number of queries to the more accurate but more expensive first kind of gradient oracle $$O1$$.\n\n**Lemma 3.3.** For any $$0 \\leq t \\leq T$$ and letting $$\\tau_t \\leq t$$ be the largest integer such that $$\\text{drift}_{\\tau_t}$$ is set to be 0, with probability at least $$1 - \\omega/T$$, for some universal constant $$C > 0$$, we have\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2 \\leq \\zeta_2^2 \\cdot \\sum_{i=\\tau_t+1}^t \\|x_i - x_{i-1}\\|_2^2 + 4\\zeta_2^2 \\cdot C \\cdot \\log(Td/\\omega). \\quad (1)\n$$", "md": "**Algorithm 1 Stochastic Spider**\n1. **Input:** Objective function F, Gradient Oracle O1, O2 with SubGaussian parameters $$\\zeta_1$$ and $$\\zeta_2$$, parameters of objective function B, M, G, $$\\rho$$, parameter $$\\kappa$$, failure probability $$\\omega$$\n2. Set $$\\gamma = 4C(\\zeta_2^2\\kappa + 4\\zeta_2^2) \\cdot \\log(BMd/\\rho\\omega)$$, $$\\Gamma = \\sqrt{\\rho\\gamma\\rho\\gamma\\omega}$$\n3. Set $$\\eta = 1/M$$, $$t = 0$$, $$T = BM \\cdot \\log^4(dMB/\\rho\\gamma\\omega)/\\gamma^2$$\n4. Set $$\\text{drift}_0 = \\kappa$$, $$\\text{frozen} = 1$$, $$\\nabla^{-1} = 0$$\n5. **while** $$t \\leq T$$ **do**\n- **if** $$\\| \\nabla_{t-1} \\| \\leq \\gamma \\log^3(BMd/\\rho\\omega)$$ **and** $$\\text{frozen}_{t-1} \\leq 0$$ **then**\n- $$\\text{frozen}_t = \\Gamma$$, $$\\text{drift}_t = 0$$\n- $$\\nabla_t = O1(x_t) + g_t$$, where $$g_t \\sim \\mathcal{N}(0, \\zeta_2 dI_d)$$\n- **else if** $$\\text{drift}_{t-1} \\geq \\kappa$$ **then**\n- $$\\nabla_t = O1(x_t)$$, $$\\text{drift}_t = 0$$, $$\\text{frozen} = \\text{frozen}_{t-1} - 1$$\n- **else**\n- $$\\Delta_t = O2(x_t, x_{t-1})$$, $$\\nabla_t = \\nabla_{t-1} + \\Delta_t$$, $$\\text{frozen} = \\text{frozen}_{t-1} - 1$$\n- $$x_{t+1} = x_t - \\eta \\nabla_t$$, $$\\text{drift}_t = \\text{drift}_{t-1} + \\eta^2 \\| \\nabla_t \\|_2^2$$, $$t = t + 1$$\n6. **end while**\n7. **Return:** $$\\{x_1, \\ldots, x_T\\}$$\n\nWe demonstrate a framework based on the SpiderBoost in Algorithm 1. Our analysis of Algorithm 1 builds upon three key properties we prove in this section: (i) $$\\nabla_t$$ is consistently close to the true gradient $$\\nabla F(x_t)$$ with high probability; (ii) the algorithm can escape the saddle point with high probability, and (iii) a large drift implies a significant decrease in the function value, allowing us to limit the number of queries to the more accurate but more expensive first kind of gradient oracle $$O1$$.\n\n**Lemma 3.3.** For any $$0 \\leq t \\leq T$$ and letting $$\\tau_t \\leq t$$ be the largest integer such that $$\\text{drift}_{\\tau_t}$$ is set to be 0, with probability at least $$1 - \\omega/T$$, for some universal constant $$C > 0$$, we have\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2 \\leq \\zeta_2^2 \\cdot \\sum_{i=\\tau_t+1}^t \\|x_i - x_{i-1}\\|_2^2 + 4\\zeta_2^2 \\cdot C \\cdot \\log(Td/\\omega). \\quad (1)\n$$"}]}, {"page": 7, "text": "Hence with probability at least 1 \u2212                      \u03c9, we know for each t \u2264                  T , \u2225\u2207t \u2212       \u2207F(xt)\u22252 \u2264           \u03b32/16, where\n\u03b32 := 16C(\u03b62       2\u03ba + 4\u03b62    1) \u00b7 log(T    d/\u03c9) and \u03ba is a parameter we can choose in the algorithm.\n      As shown in Lemma 3.3, the error on the gradient estimation for each step is bounded with\nhigh probability. Then we can show the algorithm can escape the saddle point efficiently based on\nprevious results.\nLemma 3.4 (Essentially from [WCX19]). Under Assumption 3.1, run SGD iterations xt+1 =\nxt \u2212     \u03b7\u2207t, with step size \u03b7 = 1/M. Suppose x0 is a stationary point satisfying \u2225\u2207F(x0)\u2225                                                          \u2264    \u03b1\nand smin(\u22072F(x0)) \u2264   \u03b32             \u2212\u221a\u03c1\u03b1, \u03b1 = \u03b3 log3(dBM/\u03c1\u03c9). If \u22070 = \u2207F(x0) + \u03b61 + \u03b62 where \u2225\u03b61\u2225                                                  \u2264   \u03b3,\n\u03b62 \u223c    N   (0,  d log(d/\u03c9)Id), and \u2225\u2207t\u2212\u2207F(xt)\u2225                    \u2264   \u03b3 for all t \u2208      [\u0393], with probability at least 1\u2212\u03c9\u00b7log(1/\u03c9),\none has\n                                               F(x\u0393) \u2212       F(x0) \u2264        \u2212\u2126             \u03b33/2            ,\n                  M log( dMB                                                       \u221a\u03c1 log3(dMB   \u03c1\u03b3\u03c9 )\n                           \u03c1\u03b3\u03c9 )\nwhere \u0393 =              \u221a  \u03c1\u03b3      .\n      We discuss this lemma in the Appendix A.2 in more details. The next lemma is standard,\nshowing how large the function values can decrease in each step.\nLemma 3.5. By setting \u03b7 = 1/M, we have\n                                    F(xt+1) \u2264        F(xt) + \u03b7\u2225\u2207t\u2225           \u00b7 \u2225\u2207F(xt) \u2212         \u2207t\u2225   \u2212   \u03b7\nMoreover, with probability at least 1 \u2212                      \u03c9, for each t \u2264          T such that \u2225\u2207F(xt)\u2225 2\u2225\u2207t\u22252.        \u2265   \u03b3, we have\n                                             F(xt+1) \u2212        F(xt) \u2264      \u2212\u03b7\u2225\u2207t\u22252/6 \u2264            \u2212\u03b7\u03b32/6.\n      With the algorithm designed to control the drift term, the guarantee for Stochastic Spider to\nfind the second order stationary point is stated below:\nLemma 3.6. Suppose O1 and O2 are \u03b61 and \u03b62 norm-subGaussian respectively. If one sets \u03b3 =\nO(1)     (\u03b62  2\u03ba + 4\u03b62    1) \u00b7 log(T     d/\u03c9), with probability at least 1 \u2212                   \u03c9, at least one point in the output set\n{x1, \u00b7 \u00b7 \u00b7 , xT } of Algorithm 1 is \u03b1-SOSP, where\n                  \u03b1 = \u03b3 log3(BMd/\u03c1\u03c9\u03b3) =                       (\u03b622\u03ba + 4\u03b62    1) \u00b7 log(   \u03b62 d/\u03c9        ) \u00b7 log3(   \u03c1\u03c9(\u03b62BMd\n                                                                                          2\u03ba + \u03b62   1                     2\u03ba + \u03b62   1)).\n      As mentioned before, we can bound the number of occurrences where the drift gets large and\nhence bound the total time we query the oracle of the first kind.\nLemma 3.7. Under the event that \u2225\u2207t \u2212                                  \u2207F(xt)\u2225         \u2264    \u03b3/4 for all t \u2208           [T  ] and our parameter\nsettings, letting K = {t \u2208               [T  ] : driftt \u2265     \u03ba} be the set of iterations where the drift is large, we know\n|K| \u2264     O   B\u03b7\u03ba + T      \u03b32\u03b72/\u03ba) = O(B\u03b7 log4(dMB            \u03c1\u03b3\u03c9 )/\u03ba      .\n3.2       Convergence to the SOSP of the empirical risk\nWe use Stochastic Spider to improve the convergence to \u03b1-SOSP of the empirical risk, and aim at\ngetting \u03b1 = \u02dc       O(d1/3    /n2/3    ). We let FD be the objective function F and use the gradient oracles\n                         O1(x) := \u2207FD(x) + g1, and                        O2(x, y) := \u2207FD(x) \u2212               \u2207FD(y) + g2,                              (2)\n                                                                             7", "md": "Hence with probability at least 1 - $$\\omega$$, we know for each $$t \\leq T$$, $$\\|\\nabla_t - \\nabla F(x_t)\\|^2 \\leq \\gamma^2/16$$, where\n\n$$\\gamma^2 := 16C(\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(Td/\\omega)$$ and $$\\kappa$$ is a parameter we can choose in the algorithm.\n\nAs shown in Lemma 3.3, the error on the gradient estimation for each step is bounded with high probability. Then we can show the algorithm can escape the saddle point efficiently based on previous results.\n\nLemma 3.4 (Essentially from [WCX19]). Under Assumption 3.1, run SGD iterations $$x_{t+1} = x_t - \\eta\\nabla_t$$, with step size $$\\eta = 1/M$$. Suppose $$x_0$$ is a stationary point satisfying $$\\|\\nabla F(x_0)\\| \\leq \\alpha$$ and $$s_{\\min}(\\nabla^2 F(x_0)) \\leq \\gamma^2 - \\sqrt{\\rho\\alpha}$$, $$\\alpha = \\gamma \\log^3(dBM/\\rho\\omega)$$. If $$\\nabla_0 = \\nabla F(x_0) + \\zeta_1 + \\zeta_2$$ where $$\\|\\zeta_1\\| \\leq \\gamma$$, $$\\zeta_2 \\sim N(0, d \\log(d/\\omega)I_d)$$, and $$\\|\\nabla_t - \\nabla F(x_t)\\| \\leq \\gamma$$ for all $$t \\in [\\Gamma]$$, with probability at least $$1-\\omega \\cdot \\log(1/\\omega)$$, one has\n\n$$F(x_{\\Gamma}) - F(x_0) \\leq -\\Omega \\frac{\\gamma^{3/2}}{M \\log(dMB/\\rho\\gamma\\omega)\\sqrt{\\rho\\log^3(dMB/\\rho\\gamma)}}$$\n\nwhere $$\\Gamma = \\sqrt{\\rho\\gamma}$$. We discuss this lemma in the Appendix A.2 in more details. The next lemma is standard, showing how large the function values can decrease in each step.\n\nLemma 3.5. By setting $$\\eta = 1/M$$, we have\n\n$$F(x_{t+1}) \\leq F(x_t) + \\eta\\|\\nabla_t\\| \\cdot \\|\\nabla F(x_t) - \\nabla_t\\| - \\eta$$\n\nMoreover, with probability at least 1 - $$\\omega$$, for each $$t \\leq T$$ such that $$\\|\\nabla F(x_t)\\|^2\\|\\nabla_t\\|^2 \\geq \\gamma$$, we have\n\n$$F(x_{t+1}) - F(x_t) \\leq -\\eta\\|\\nabla_t\\|^2/6 \\leq -\\eta\\gamma^2/6$$.\n\nWith the algorithm designed to control the drift term, the guarantee for Stochastic Spider to find the second-order stationary point is stated below:\n\nLemma 3.6. Suppose $$O_1$$ and $$O_2$$ are $$\\zeta_1$$ and $$\\zeta_2$$ norm-subGaussian respectively. If one sets $$\\gamma = O(1)(\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(Td/\\omega)$$, with probability at least 1 - $$\\omega$$, at least one point in the output set {$$x_1, \\ldots, x_T$$} of Algorithm 1 is $$\\alpha$$-SOSP, where\n\n$$\\alpha = \\gamma \\log^3(BMd/\\rho\\omega\\gamma) = (\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(\\zeta_2d/\\omega) \\cdot \\log^3(\\rho\\omega(\\zeta_2BMd^2\\kappa + \\zeta_2^1))$$.\n\nAs mentioned before, we can bound the number of occurrences where the drift gets large and hence bound the total time we query the oracle of the first kind.\n\nLemma 3.7. Under the event that $$\\|\\nabla_t - \\nabla F(x_t)\\| \\leq \\gamma/4$$ for all $$t \\in [T]$$ and our parameter settings, letting $$K = \\{t \\in [T] : \\text{drift}_t \\geq \\kappa\\}$$ be the set of iterations where the drift is large, we know $$|K| \\leq O(B\\eta\\kappa + T\\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB\\rho\\gamma\\omega)/\\kappa)$$.\n\n3.2 Convergence to the SOSP of the empirical risk\n\nWe use Stochastic Spider to improve the convergence to $$\\alpha$$-SOSP of the empirical risk, and aim at getting $$\\alpha = \\tilde{O}(d^{1/3}/n^{2/3})$$. We let $$F_D$$ be the objective function $$F$$ and use the gradient oracles\n\n$$O_1(x) := \\nabla F_D(x) + g_1$$, and $$O_2(x, y) := \\nabla F_D(x) - \\nabla F_D(y) + g_2$$", "images": [], "items": [{"type": "text", "value": "Hence with probability at least 1 - $$\\omega$$, we know for each $$t \\leq T$$, $$\\|\\nabla_t - \\nabla F(x_t)\\|^2 \\leq \\gamma^2/16$$, where\n\n$$\\gamma^2 := 16C(\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(Td/\\omega)$$ and $$\\kappa$$ is a parameter we can choose in the algorithm.\n\nAs shown in Lemma 3.3, the error on the gradient estimation for each step is bounded with high probability. Then we can show the algorithm can escape the saddle point efficiently based on previous results.\n\nLemma 3.4 (Essentially from [WCX19]). Under Assumption 3.1, run SGD iterations $$x_{t+1} = x_t - \\eta\\nabla_t$$, with step size $$\\eta = 1/M$$. Suppose $$x_0$$ is a stationary point satisfying $$\\|\\nabla F(x_0)\\| \\leq \\alpha$$ and $$s_{\\min}(\\nabla^2 F(x_0)) \\leq \\gamma^2 - \\sqrt{\\rho\\alpha}$$, $$\\alpha = \\gamma \\log^3(dBM/\\rho\\omega)$$. If $$\\nabla_0 = \\nabla F(x_0) + \\zeta_1 + \\zeta_2$$ where $$\\|\\zeta_1\\| \\leq \\gamma$$, $$\\zeta_2 \\sim N(0, d \\log(d/\\omega)I_d)$$, and $$\\|\\nabla_t - \\nabla F(x_t)\\| \\leq \\gamma$$ for all $$t \\in [\\Gamma]$$, with probability at least $$1-\\omega \\cdot \\log(1/\\omega)$$, one has\n\n$$F(x_{\\Gamma}) - F(x_0) \\leq -\\Omega \\frac{\\gamma^{3/2}}{M \\log(dMB/\\rho\\gamma\\omega)\\sqrt{\\rho\\log^3(dMB/\\rho\\gamma)}}$$\n\nwhere $$\\Gamma = \\sqrt{\\rho\\gamma}$$. We discuss this lemma in the Appendix A.2 in more details. The next lemma is standard, showing how large the function values can decrease in each step.\n\nLemma 3.5. By setting $$\\eta = 1/M$$, we have\n\n$$F(x_{t+1}) \\leq F(x_t) + \\eta\\|\\nabla_t\\| \\cdot \\|\\nabla F(x_t) - \\nabla_t\\| - \\eta$$\n\nMoreover, with probability at least 1 - $$\\omega$$, for each $$t \\leq T$$ such that $$\\|\\nabla F(x_t)\\|^2\\|\\nabla_t\\|^2 \\geq \\gamma$$, we have\n\n$$F(x_{t+1}) - F(x_t) \\leq -\\eta\\|\\nabla_t\\|^2/6 \\leq -\\eta\\gamma^2/6$$.\n\nWith the algorithm designed to control the drift term, the guarantee for Stochastic Spider to find the second-order stationary point is stated below:\n\nLemma 3.6. Suppose $$O_1$$ and $$O_2$$ are $$\\zeta_1$$ and $$\\zeta_2$$ norm-subGaussian respectively. If one sets $$\\gamma = O(1)(\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(Td/\\omega)$$, with probability at least 1 - $$\\omega$$, at least one point in the output set {$$x_1, \\ldots, x_T$$} of Algorithm 1 is $$\\alpha$$-SOSP, where\n\n$$\\alpha = \\gamma \\log^3(BMd/\\rho\\omega\\gamma) = (\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(\\zeta_2d/\\omega) \\cdot \\log^3(\\rho\\omega(\\zeta_2BMd^2\\kappa + \\zeta_2^1))$$.\n\nAs mentioned before, we can bound the number of occurrences where the drift gets large and hence bound the total time we query the oracle of the first kind.\n\nLemma 3.7. Under the event that $$\\|\\nabla_t - \\nabla F(x_t)\\| \\leq \\gamma/4$$ for all $$t \\in [T]$$ and our parameter settings, letting $$K = \\{t \\in [T] : \\text{drift}_t \\geq \\kappa\\}$$ be the set of iterations where the drift is large, we know $$|K| \\leq O(B\\eta\\kappa + T\\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB\\rho\\gamma\\omega)/\\kappa)$$.\n\n3.2 Convergence to the SOSP of the empirical risk\n\nWe use Stochastic Spider to improve the convergence to $$\\alpha$$-SOSP of the empirical risk, and aim at getting $$\\alpha = \\tilde{O}(d^{1/3}/n^{2/3})$$. We let $$F_D$$ be the objective function $$F$$ and use the gradient oracles\n\n$$O_1(x) := \\nabla F_D(x) + g_1$$, and $$O_2(x, y) := \\nabla F_D(x) - \\nabla F_D(y) + g_2$$", "md": "Hence with probability at least 1 - $$\\omega$$, we know for each $$t \\leq T$$, $$\\|\\nabla_t - \\nabla F(x_t)\\|^2 \\leq \\gamma^2/16$$, where\n\n$$\\gamma^2 := 16C(\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(Td/\\omega)$$ and $$\\kappa$$ is a parameter we can choose in the algorithm.\n\nAs shown in Lemma 3.3, the error on the gradient estimation for each step is bounded with high probability. Then we can show the algorithm can escape the saddle point efficiently based on previous results.\n\nLemma 3.4 (Essentially from [WCX19]). Under Assumption 3.1, run SGD iterations $$x_{t+1} = x_t - \\eta\\nabla_t$$, with step size $$\\eta = 1/M$$. Suppose $$x_0$$ is a stationary point satisfying $$\\|\\nabla F(x_0)\\| \\leq \\alpha$$ and $$s_{\\min}(\\nabla^2 F(x_0)) \\leq \\gamma^2 - \\sqrt{\\rho\\alpha}$$, $$\\alpha = \\gamma \\log^3(dBM/\\rho\\omega)$$. If $$\\nabla_0 = \\nabla F(x_0) + \\zeta_1 + \\zeta_2$$ where $$\\|\\zeta_1\\| \\leq \\gamma$$, $$\\zeta_2 \\sim N(0, d \\log(d/\\omega)I_d)$$, and $$\\|\\nabla_t - \\nabla F(x_t)\\| \\leq \\gamma$$ for all $$t \\in [\\Gamma]$$, with probability at least $$1-\\omega \\cdot \\log(1/\\omega)$$, one has\n\n$$F(x_{\\Gamma}) - F(x_0) \\leq -\\Omega \\frac{\\gamma^{3/2}}{M \\log(dMB/\\rho\\gamma\\omega)\\sqrt{\\rho\\log^3(dMB/\\rho\\gamma)}}$$\n\nwhere $$\\Gamma = \\sqrt{\\rho\\gamma}$$. We discuss this lemma in the Appendix A.2 in more details. The next lemma is standard, showing how large the function values can decrease in each step.\n\nLemma 3.5. By setting $$\\eta = 1/M$$, we have\n\n$$F(x_{t+1}) \\leq F(x_t) + \\eta\\|\\nabla_t\\| \\cdot \\|\\nabla F(x_t) - \\nabla_t\\| - \\eta$$\n\nMoreover, with probability at least 1 - $$\\omega$$, for each $$t \\leq T$$ such that $$\\|\\nabla F(x_t)\\|^2\\|\\nabla_t\\|^2 \\geq \\gamma$$, we have\n\n$$F(x_{t+1}) - F(x_t) \\leq -\\eta\\|\\nabla_t\\|^2/6 \\leq -\\eta\\gamma^2/6$$.\n\nWith the algorithm designed to control the drift term, the guarantee for Stochastic Spider to find the second-order stationary point is stated below:\n\nLemma 3.6. Suppose $$O_1$$ and $$O_2$$ are $$\\zeta_1$$ and $$\\zeta_2$$ norm-subGaussian respectively. If one sets $$\\gamma = O(1)(\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(Td/\\omega)$$, with probability at least 1 - $$\\omega$$, at least one point in the output set {$$x_1, \\ldots, x_T$$} of Algorithm 1 is $$\\alpha$$-SOSP, where\n\n$$\\alpha = \\gamma \\log^3(BMd/\\rho\\omega\\gamma) = (\\zeta_2^2\\kappa + 4\\zeta_2^1) \\cdot \\log(\\zeta_2d/\\omega) \\cdot \\log^3(\\rho\\omega(\\zeta_2BMd^2\\kappa + \\zeta_2^1))$$.\n\nAs mentioned before, we can bound the number of occurrences where the drift gets large and hence bound the total time we query the oracle of the first kind.\n\nLemma 3.7. Under the event that $$\\|\\nabla_t - \\nabla F(x_t)\\| \\leq \\gamma/4$$ for all $$t \\in [T]$$ and our parameter settings, letting $$K = \\{t \\in [T] : \\text{drift}_t \\geq \\kappa\\}$$ be the set of iterations where the drift is large, we know $$|K| \\leq O(B\\eta\\kappa + T\\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB\\rho\\gamma\\omega)/\\kappa)$$.\n\n3.2 Convergence to the SOSP of the empirical risk\n\nWe use Stochastic Spider to improve the convergence to $$\\alpha$$-SOSP of the empirical risk, and aim at getting $$\\alpha = \\tilde{O}(d^{1/3}/n^{2/3})$$. We let $$F_D$$ be the objective function $$F$$ and use the gradient oracles\n\n$$O_1(x) := \\nabla F_D(x) + g_1$$, and $$O_2(x, y) := \\nabla F_D(x) - \\nabla F_D(y) + g_2$$"}]}, {"page": 8, "text": "Algorithm 2 AboveThreshold\n  1: Input: A set of points {xi}T                i=1, dataset S, parameters of objective function B, M, G, \u03c1, objective\n      error \u03b1\n  2: Set     T1 = \u03b1 + Lap(4G        n\u03b5 ) + 16 log(2T/\u03c9)G        , T2 = \u2212\u221a       \u03c1\u03b1 + Lap(4M\n                                                     n\u03b5                                          n\u03b5 ) \u2212     16 log(2T/\u03c9)M\n                                                                                                                   n\u03b5\n  3: for i = 1, \u00b7 \u00b7 \u00b7 , T do                                 smin(\u22072FS(xi)) + Lap(8M\n  4:      if \u2225\u2207FS(xi)\u2225          + Lap(8G    n\u03b5 ) \u2264   T1                                             n\u03b5 ) \u2265    T2 then\n  5:          Output: xi\n  6:          Halt\n  7:      end if\n  8: end for\nwhere g1 \u223c         N  (0, \u03c32 1Id) and g2 \u223c          N  (0, \u03c32 2Id) ensures privacy.\n      Before stating the formal results, note that by Lemma 3.6, the framework can only guarantee the\nexistence of an \u03b1-SOSP in the outputted set. In order to find the SOSP privately from the set, we\nadopt the well-known AboveThreshold algorithm, whose pseudo-code can be found in Algorithm 2.\nAlgorithm 2 is a slight modification of the AboveThreshold algorithm [DR+14], and we get the\nfollowing guarantee immediately.\nLemma 3.8. Algorithm 2 is (\u03b5, 0)-DP. Given the point set {x1, \u00b7 \u00b7 \u00b7 , xT } and S of size n as the\ninput,\n      \u2022 if it outputs any point xi, then with probability at least 1 \u2212                                 \u03c9, we know\n                 \u2225\u2207FS(xi)\u2225        \u2264   \u03b1 + 32 log(2T/\u03c9)G, and smin(\u22072FS(xi)) \u2265                                \u2212\u221a\u03c1\u03b1 \u2212         32 log(2T/\u03c9)M\n                                                       n\u03b5                                                                             n\u03b5\n      \u2022 if there exists a \u03b1-SOSP point x \u2208                      {xi}i\u2208[T], then with probability at least 1 \u2212                       \u03c9, Algorithm 2\n         will output one point.\n      Combining Algorithm 1 and Algorithm 2, we can find the SOSP we want, which is stated\nformally below:\nTheorem 3.9 (Empirical). Using full batch in Algorithm 1, and setting \u03ba = G4/3B1/3                                                 ( \u221a  d log(1/\u03b4)  )2/3,\n                                                                                                                          M5/3             n\u03b5\n                B\u03b7 log2(1/\u03b4)/\u03ba log2(ndMB/\u03c9)           , \u03c32 = M\u221a        log2(1/\u03b4)BM/\u03b12      1 log5(ndMB/\u03c9)       , Algorithm 1 is (\u03b5, \u03b4)-DP,\n\u03c31 = G\u221a                       n\u03b5                                                       n\u03b5\nand with probability at least 1 \u2212                  \u03c9, at least one point in the output set {xi}i\u2208[T] is \u03b11-SOSP of FD\nwith\n                                                  \uf8eb        dBGM log2(1/\u03b4)              2/3 \u00b7 log6 nBMd           \uf8f6\n                                      \u03b11 = O      \uf8ed                 n\u03b5                                   \u03c1\u03c9      \uf8f8   .\n      Moreover, if we run Algorithm 2 with inputs {xi}i\u2208[T], D, B, M, G, \u03c1, \u03b11, with probability at least\n1 \u2212    \u03c9, we can get an \u03b12-SOSP of FD with\n                                \u03b12 = O         \u03b11 + G log(n/G\u03c9)              + M log(ndBGM/\u03c1\u03c9)                   \u221a  \u03b11     .\n3.3       Convergence to the SOSP of the population risk       n\u03b5                           n\u03b5\u221a\u03c1\nThis subsection aims at getting an \u03b1-SOSP for FP (the population function). Differing from the\nstochastic oracles used for empirical function FD, we do not use full batch in the oracle. As an\n                                                                             8", "md": "Algorithm 2 **AboveThreshold**\n1: Input: A set of points {xi}^T_{i=1}, dataset S, parameters of objective function B, M, G, \u03c1, objective error \u03b1\n2: Set T1 = \u03b1 + Lap(4Gn\u03b5) + 16 log(2T/\u03c9)G, T2 = -\u221a(\u03c1\u03b1 + Lap(4Mn\u03b5) - 16 log(2T/\u03c9)Mn\u03b5)\n3: for i = 1, ..., T do\n4: if ||\u2207FS(xi)|| + Lap(8Gn\u03b5) \u2264 T1n\u03b5) \u2265 T2 then\n5: Output: xi\n6: Halt\n7: end if\n8: end for\n\nwhere g1 ~ N(0, \u03c3^2_1Id) and g2 ~ N(0, \u03c3^2_2Id) ensures privacy.\nBefore stating the formal results, note that by Lemma 3.6, the framework can only guarantee the existence of an \u03b1-SOSP in the outputted set. In order to find the SOSP privately from the set, we adopt the well-known AboveThreshold algorithm, whose pseudo-code can be found in Algorithm 2. Algorithm 2 is a slight modification of the AboveThreshold algorithm [DR+14], and we get the following guarantee immediately.\n\n**Lemma 3.8.** Algorithm 2 is (\u03b5, 0)-DP. Given the point set {x1, ..., xT} and S of size n as the input,\n- if it outputs any point xi, then with probability at least 1 - \u03c9, we know ||\u2207FS(xi)|| \u2264 \u03b1 + 32 log(2T/\u03c9)G, and smin(\u2207^2FS(xi)) \u2265 -\u221a(\u03c1\u03b1 - 32 log(2T/\u03c9)Mn\u03b5)\n- if there exists an \u03b1-SOSP point x \u2208 {xi}^T_i=1, then with probability at least 1 - \u03c9, Algorithm 2 will output one point.\n\nCombining Algorithm 1 and Algorithm 2, we can find the SOSP we want, which is stated formally below:\n\n**Theorem 3.9 (Empirical).** Using full batch in Algorithm 1, and setting \u03ba = G^(4/3)B^(1/3) / (\u221ad log(1/\u03b4))^(2/3), M^(5/3) / n\u03b5, B\u03b7 log^2(1/\u03b4) / \u03ba log^2(ndMB/\u03c9), \u03c3^2 = M\u221a(log^2(1/\u03b4)BM/\u03b1^2) log^5(ndMB/\u03c9), Algorithm 1 is (\u03b5, \u03b4)-DP, \u03c31 = G\u221a(n\u03b5) / n\u03b5, and with probability at least 1 - \u03c9, at least one point in the output set {xi}^T_i=1 is \u03b11-SOSP of FD with\n\u03b11 = O(dBGM log^2(1/\u03b4)^(2/3) \u00b7 log^6(nBMd) / (n\u03b5\u03c1\u03c9)).\nMoreover, if we run Algorithm 2 with inputs {xi}^T_i=1, D, B, M, G, \u03c1, \u03b11, with probability at least 1 - \u03c9, we can get an \u03b12-SOSP of FD with\n\u03b12 = O(\u03b11 + G log(n/G\u03c9) + M log(ndBGM/\u03c1\u03c9) \u221a(\u03b11)).\n\n**3.3 Convergence to the SOSP of the population risk**\nThis subsection aims at getting an \u03b1-SOSP for FP (the population function). Differing from the stochastic oracles used for empirical function FD, we do not use full batch in the oracle. As an", "images": [], "items": [{"type": "text", "value": "Algorithm 2 **AboveThreshold**\n1: Input: A set of points {xi}^T_{i=1}, dataset S, parameters of objective function B, M, G, \u03c1, objective error \u03b1\n2: Set T1 = \u03b1 + Lap(4Gn\u03b5) + 16 log(2T/\u03c9)G, T2 = -\u221a(\u03c1\u03b1 + Lap(4Mn\u03b5) - 16 log(2T/\u03c9)Mn\u03b5)\n3: for i = 1, ..., T do\n4: if ||\u2207FS(xi)|| + Lap(8Gn\u03b5) \u2264 T1n\u03b5) \u2265 T2 then\n5: Output: xi\n6: Halt\n7: end if\n8: end for\n\nwhere g1 ~ N(0, \u03c3^2_1Id) and g2 ~ N(0, \u03c3^2_2Id) ensures privacy.\nBefore stating the formal results, note that by Lemma 3.6, the framework can only guarantee the existence of an \u03b1-SOSP in the outputted set. In order to find the SOSP privately from the set, we adopt the well-known AboveThreshold algorithm, whose pseudo-code can be found in Algorithm 2. Algorithm 2 is a slight modification of the AboveThreshold algorithm [DR+14], and we get the following guarantee immediately.\n\n**Lemma 3.8.** Algorithm 2 is (\u03b5, 0)-DP. Given the point set {x1, ..., xT} and S of size n as the input,\n- if it outputs any point xi, then with probability at least 1 - \u03c9, we know ||\u2207FS(xi)|| \u2264 \u03b1 + 32 log(2T/\u03c9)G, and smin(\u2207^2FS(xi)) \u2265 -\u221a(\u03c1\u03b1 - 32 log(2T/\u03c9)Mn\u03b5)\n- if there exists an \u03b1-SOSP point x \u2208 {xi}^T_i=1, then with probability at least 1 - \u03c9, Algorithm 2 will output one point.\n\nCombining Algorithm 1 and Algorithm 2, we can find the SOSP we want, which is stated formally below:\n\n**Theorem 3.9 (Empirical).** Using full batch in Algorithm 1, and setting \u03ba = G^(4/3)B^(1/3) / (\u221ad log(1/\u03b4))^(2/3), M^(5/3) / n\u03b5, B\u03b7 log^2(1/\u03b4) / \u03ba log^2(ndMB/\u03c9), \u03c3^2 = M\u221a(log^2(1/\u03b4)BM/\u03b1^2) log^5(ndMB/\u03c9), Algorithm 1 is (\u03b5, \u03b4)-DP, \u03c31 = G\u221a(n\u03b5) / n\u03b5, and with probability at least 1 - \u03c9, at least one point in the output set {xi}^T_i=1 is \u03b11-SOSP of FD with\n\u03b11 = O(dBGM log^2(1/\u03b4)^(2/3) \u00b7 log^6(nBMd) / (n\u03b5\u03c1\u03c9)).\nMoreover, if we run Algorithm 2 with inputs {xi}^T_i=1, D, B, M, G, \u03c1, \u03b11, with probability at least 1 - \u03c9, we can get an \u03b12-SOSP of FD with\n\u03b12 = O(\u03b11 + G log(n/G\u03c9) + M log(ndBGM/\u03c1\u03c9) \u221a(\u03b11)).\n\n**3.3 Convergence to the SOSP of the population risk**\nThis subsection aims at getting an \u03b1-SOSP for FP (the population function). Differing from the stochastic oracles used for empirical function FD, we do not use full batch in the oracle. As an", "md": "Algorithm 2 **AboveThreshold**\n1: Input: A set of points {xi}^T_{i=1}, dataset S, parameters of objective function B, M, G, \u03c1, objective error \u03b1\n2: Set T1 = \u03b1 + Lap(4Gn\u03b5) + 16 log(2T/\u03c9)G, T2 = -\u221a(\u03c1\u03b1 + Lap(4Mn\u03b5) - 16 log(2T/\u03c9)Mn\u03b5)\n3: for i = 1, ..., T do\n4: if ||\u2207FS(xi)|| + Lap(8Gn\u03b5) \u2264 T1n\u03b5) \u2265 T2 then\n5: Output: xi\n6: Halt\n7: end if\n8: end for\n\nwhere g1 ~ N(0, \u03c3^2_1Id) and g2 ~ N(0, \u03c3^2_2Id) ensures privacy.\nBefore stating the formal results, note that by Lemma 3.6, the framework can only guarantee the existence of an \u03b1-SOSP in the outputted set. In order to find the SOSP privately from the set, we adopt the well-known AboveThreshold algorithm, whose pseudo-code can be found in Algorithm 2. Algorithm 2 is a slight modification of the AboveThreshold algorithm [DR+14], and we get the following guarantee immediately.\n\n**Lemma 3.8.** Algorithm 2 is (\u03b5, 0)-DP. Given the point set {x1, ..., xT} and S of size n as the input,\n- if it outputs any point xi, then with probability at least 1 - \u03c9, we know ||\u2207FS(xi)|| \u2264 \u03b1 + 32 log(2T/\u03c9)G, and smin(\u2207^2FS(xi)) \u2265 -\u221a(\u03c1\u03b1 - 32 log(2T/\u03c9)Mn\u03b5)\n- if there exists an \u03b1-SOSP point x \u2208 {xi}^T_i=1, then with probability at least 1 - \u03c9, Algorithm 2 will output one point.\n\nCombining Algorithm 1 and Algorithm 2, we can find the SOSP we want, which is stated formally below:\n\n**Theorem 3.9 (Empirical).** Using full batch in Algorithm 1, and setting \u03ba = G^(4/3)B^(1/3) / (\u221ad log(1/\u03b4))^(2/3), M^(5/3) / n\u03b5, B\u03b7 log^2(1/\u03b4) / \u03ba log^2(ndMB/\u03c9), \u03c3^2 = M\u221a(log^2(1/\u03b4)BM/\u03b1^2) log^5(ndMB/\u03c9), Algorithm 1 is (\u03b5, \u03b4)-DP, \u03c31 = G\u221a(n\u03b5) / n\u03b5, and with probability at least 1 - \u03c9, at least one point in the output set {xi}^T_i=1 is \u03b11-SOSP of FD with\n\u03b11 = O(dBGM log^2(1/\u03b4)^(2/3) \u00b7 log^6(nBMd) / (n\u03b5\u03c1\u03c9)).\nMoreover, if we run Algorithm 2 with inputs {xi}^T_i=1, D, B, M, G, \u03c1, \u03b11, with probability at least 1 - \u03c9, we can get an \u03b12-SOSP of FD with\n\u03b12 = O(\u03b11 + G log(n/G\u03c9) + M log(ndBGM/\u03c1\u03c9) \u221a(\u03b11)).\n\n**3.3 Convergence to the SOSP of the population risk**\nThis subsection aims at getting an \u03b1-SOSP for FP (the population function). Differing from the stochastic oracles used for empirical function FD, we do not use full batch in the oracle. As an"}]}, {"page": 9, "text": "alternative, we draw fresh samples from D without replacement with a smaller batch size:\n             O1(x) := 1     b1  z\u2208S1   \u2207f(x; z) + g1, and O2(x, y) := 1                  b2   z\u2208S2  (\u2207f(x; z) \u2212        \u2207f(y; z)) + g2,                 (3)\nwhere S1 and S2 are sets of size of b1 and b2 respectively drawn from D without replacement,\ng1 \u223c    N   (0, \u03c32 1Id) and g2 \u223c         N   (0, \u03c32 2\u2225x \u2212     y\u222522 \u00b7 Id). These gradient oracles satisfy the following.\nClaim 3.10. The gradient oracles O1 and O2 constructed in Equation (3) are a fi                                                           rst kind of\nO(L\u221a   \u221a log d  +  \u221a  d\u03c31) norm-subGaussian gradient oracle and second kind of O(M\u221a                                       \u221a  log d +   \u221a d\u03c32) norm-\n          b1                                                                                                                 b2\nsubGaussian gradient oracle respectively.\nProof. For the oracle O1, we know for each z \u2208                                  S1, Ez\u223cP[\u2207f(x, z)] = \u2207FP(x) and \u2207f(x, z) \u2212\n\u2207FP(x) is nSG(L) due to the Lipschitzness assumption. The statement follows from Fact 2.3 and\nLemma 2.4. As for the O2, the statement follows similarly with the smoothness assumption.\n      Recall that in the empirical case, we use Algorithm 2 to choose the SOSP for FD. But in the\npopulation case, we need to find SOSP for FP, and what we have are samples from P. We need\nthe following technical results to help us find the SOSP from the set, which follows from Hoeffding\ninequality for norm-subGaussians (Lemma 2.4) and Matrix Bernstein inequality (Theorem 2.6).\nLemma 3.11. Fix a point x \u2208                       Rd. Given a set S of m samples drawn i.i.d. from the distribution\nP, then we know with probability at least 1 \u2212       G log(d/\u03c9)          \u03c9, we have                                           M log(d/\u03c9)\n         \u2225\u2207FS(x) \u2212         \u2207FP(x)\u22252 \u2264           O         \u221a  m               \u2225\u22072FS(x) \u2212          \u22072FP(x)\u2225op \u2264            O          \u221a  m          .\n      We can bound the population bound similar to the empirical bound with these tools.\nTheorem 3.12 (Population). Divide the dataset D into two disjoint datasets D1 and D2 of size\n\u2308n/2\u2309      and \u230an/2\u230b        respectively. Setting b1 = n\u03ba            B\u03b7  , b2 = n\u03b12   1                 log(1/\u03b4)  , \u03c32 = M\u221a        log(1/\u03b4)   and \u03ba =\n                                                                                   BM , \u03c31 = G\u221ab1\u03b5                                 b2\u03b5\nmax(G4/3B1/3 log1/3 d          n\u22121/3, (GB2/3                \u221a  d log(1/\u03b4)  )4/7  ) in Equation (3) and using them as gradient\n                M5/3                        M5/3 )6/7(           n\u03b5\noracles, Algorithm 1 with D1 is (\u03b5, \u03b4)-DP, and with probability at least 1 \u2212                                           \u03c9, at least one point in\nthe output is \u03b11-SOSP of FP with\n         \u03b11 = O         (BGM \u00b7 log d)1/3              1                                       d log(1/\u03b4)     )3/7    log3(nBMd/\u03c1\u03c9)                .\n                                                   n1/3 + (G1/7B3/7M3/7)(                         n\u03b5\n      Moreover, if we run Algorithm 2 with inputs {xi}i\u2208[T], D2, B, M, G, \u03c1, \u03b11, with probability at\nleast 1 \u2212      \u03c9, Algorithm 2 can output an \u03b12-SOSP of FP with               \u221a                                         \u221a\n                     \u03b12 = O         \u03b11 + M log(ndBGM/\u03c1\u03c9)                        \u03b11 + G(log(n/G\u03c9)               + log(d/\u03c9)       )    .\n                                               \u221a  \u03c1 min(n\u03b5, n1/2)                                  n\u03b5                     n\n4       Bounding the excess risk\nIn this section, we consider the risk bounds.\n                                                                             9", "md": "```markdown\nalternative, we draw fresh samples from D without replacement with a smaller batch size:\n$$\nO_1(x) := 1 \\quad b_1 \\quad z \\in S_1 \\quad \\nabla f(x; z) + g_1, \\quad \\text{and} \\quad O_2(x, y) := 1 \\quad b_2 \\quad z \\in S_2 \\quad (\\nabla f(x; z) - \\nabla f(y; z)) + g_2, \\quad (3)\n$$\nwhere S_1 and S_2 are sets of size of b_1 and b_2 respectively drawn from D without replacement,\ng_1 \\sim \\mathcal{N}(0, \\sigma_1^2 \\text{Id}) \\quad \\text{and} \\quad g_2 \\sim \\mathcal{N}(0, \\sigma_2^2 \\|x - y\\|_2^2 \\cdot \\text{Id}). These gradient oracles satisfy the following.\n\nClaim 3.10. The gradient oracles O_1 and O_2 constructed in Equation (3) are a first kind of\n$$\nO(L\\sqrt{\\log d} + \\sqrt{d\\sigma_1}) \\quad \\text{norm-subGaussian gradient oracle and second kind of} \\quad O(M\\sqrt{\\log d} + \\sqrt{d\\sigma_2}) \\quad \\text{norm-} b_1 \\quad \\text{subGaussian gradient oracle respectively.}\n$$\n\nProof. For the oracle O_1, we know for each z \\in S_1, \\mathbb{E}_{z \\sim P}[\\nabla f(x, z)] = \\nabla F_P(x) \\quad \\text{and} \\quad \\nabla f(x, z) - \\nabla F_P(x) \\quad \\text{is nSG(L) due to the Lipschitzness assumption. The statement follows from Fact 2.3 and Lemma 2.4. As for the O_2, the statement follows similarly with the smoothness assumption.}\n\nRecall that in the empirical case, we use Algorithm 2 to choose the SOSP for FD. But in the population case, we need to find SOSP for F_P, and what we have are samples from P. We need the following technical results to help us find the SOSP from the set, which follows from Hoeffding inequality for norm-subGaussians (Lemma 2.4) and Matrix Bernstein inequality (Theorem 2.6).\n\nLemma 3.11. Fix a point x \\in \\mathbb{R}^d. Given a set S of m samples drawn i.i.d. from the distribution P, then we know with probability at least 1 - G \\log(d/\\omega) \\omega, we have\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O(\\sqrt{m}) \\quad \\text{and} \\quad \\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq O(\\sqrt{m}).\n$$\nWe can bound the population bound similar to the empirical bound with these tools.\n\nTheorem 3.12 (Population). Divide the dataset D into two disjoint datasets D_1 and D_2 of size\n$$\n\\lceil n/2 \\rceil \\quad \\text{and} \\quad \\lfloor n/2 \\rfloor \\quad \\text{respectively. Setting} \\quad b_1 = n\\kappa \\quad B\\eta, \\quad b_2 = n\\alpha^2 \\quad \\log(1/\\delta), \\quad \\sigma_2 = M\\sqrt{\\log(1/\\delta)} \\quad \\text{and} \\quad \\kappa = \\frac{BM}{G\\sqrt{b_1}\\epsilon}, \\quad \\sigma_1 = \\frac{G\\sqrt{b_1}\\epsilon}{b_2\\epsilon}\n$$\n$$\n\\max(G^{4/3}B^{1/3} \\log^{1/3} d \\cdot n^{-1/3}, (GB^{2/3} \\sqrt{d} \\log(1/\\delta))^{4/7}) \\quad \\text{in Equation (3) and using them as gradient} \\quad M^{5/3} \\quad \\text{oracles, Algorithm 1 with D_1 is} \\quad (\\epsilon, \\delta)-\\text{DP, and with probability at least} \\quad 1 - \\omega, \\quad \\text{at least one point in the output is} \\quad \\alpha_1\\text{-SOSP of F_P with}\n$$\n$$\n\\alpha_1 = O(BGM \\cdot \\log d)^{1/3} \\cdot \\frac{1}{d \\log(1/\\delta)})^{3/7} \\cdot \\log^3(nBMd/\\rho\\omega).\n$$\n$$\nn^{1/3} + (G^{1/7}B^{3/7}M^{3/7}) \\cdot (n\\epsilon)\n$$\nMoreover, if we run Algorithm 2 with inputs \\{x_i\\}_{i \\in [T]}, D_2, B, M, G, \\rho, \\alpha_1, \\quad \\text{with probability at least} \\quad 1 - \\omega, \\quad \\text{Algorithm 2 can output an} \\quad \\alpha_2\\text{-SOSP of F_P with}\n$$\n\\alpha_2 = O(\\alpha_1 + M \\log(ndBGM/\\rho\\omega) \\quad \\alpha_1 + G(\\log(n/G\\omega) + \\log(d/\\omega))).\n$$\n$$\n\\sqrt{\\rho} \\min(n\\epsilon, n^{1/2}) \\quad n\\epsilon \\quad n\n$$\n\n4 Bounding the excess risk\nIn this section, we consider the risk bounds.\n```\n```", "images": [], "items": [{"type": "text", "value": "```markdown\nalternative, we draw fresh samples from D without replacement with a smaller batch size:\n$$\nO_1(x) := 1 \\quad b_1 \\quad z \\in S_1 \\quad \\nabla f(x; z) + g_1, \\quad \\text{and} \\quad O_2(x, y) := 1 \\quad b_2 \\quad z \\in S_2 \\quad (\\nabla f(x; z) - \\nabla f(y; z)) + g_2, \\quad (3)\n$$\nwhere S_1 and S_2 are sets of size of b_1 and b_2 respectively drawn from D without replacement,\ng_1 \\sim \\mathcal{N}(0, \\sigma_1^2 \\text{Id}) \\quad \\text{and} \\quad g_2 \\sim \\mathcal{N}(0, \\sigma_2^2 \\|x - y\\|_2^2 \\cdot \\text{Id}). These gradient oracles satisfy the following.\n\nClaim 3.10. The gradient oracles O_1 and O_2 constructed in Equation (3) are a first kind of\n$$\nO(L\\sqrt{\\log d} + \\sqrt{d\\sigma_1}) \\quad \\text{norm-subGaussian gradient oracle and second kind of} \\quad O(M\\sqrt{\\log d} + \\sqrt{d\\sigma_2}) \\quad \\text{norm-} b_1 \\quad \\text{subGaussian gradient oracle respectively.}\n$$\n\nProof. For the oracle O_1, we know for each z \\in S_1, \\mathbb{E}_{z \\sim P}[\\nabla f(x, z)] = \\nabla F_P(x) \\quad \\text{and} \\quad \\nabla f(x, z) - \\nabla F_P(x) \\quad \\text{is nSG(L) due to the Lipschitzness assumption. The statement follows from Fact 2.3 and Lemma 2.4. As for the O_2, the statement follows similarly with the smoothness assumption.}\n\nRecall that in the empirical case, we use Algorithm 2 to choose the SOSP for FD. But in the population case, we need to find SOSP for F_P, and what we have are samples from P. We need the following technical results to help us find the SOSP from the set, which follows from Hoeffding inequality for norm-subGaussians (Lemma 2.4) and Matrix Bernstein inequality (Theorem 2.6).\n\nLemma 3.11. Fix a point x \\in \\mathbb{R}^d. Given a set S of m samples drawn i.i.d. from the distribution P, then we know with probability at least 1 - G \\log(d/\\omega) \\omega, we have\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O(\\sqrt{m}) \\quad \\text{and} \\quad \\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq O(\\sqrt{m}).\n$$\nWe can bound the population bound similar to the empirical bound with these tools.\n\nTheorem 3.12 (Population). Divide the dataset D into two disjoint datasets D_1 and D_2 of size\n$$\n\\lceil n/2 \\rceil \\quad \\text{and} \\quad \\lfloor n/2 \\rfloor \\quad \\text{respectively. Setting} \\quad b_1 = n\\kappa \\quad B\\eta, \\quad b_2 = n\\alpha^2 \\quad \\log(1/\\delta), \\quad \\sigma_2 = M\\sqrt{\\log(1/\\delta)} \\quad \\text{and} \\quad \\kappa = \\frac{BM}{G\\sqrt{b_1}\\epsilon}, \\quad \\sigma_1 = \\frac{G\\sqrt{b_1}\\epsilon}{b_2\\epsilon}\n$$\n$$\n\\max(G^{4/3}B^{1/3} \\log^{1/3} d \\cdot n^{-1/3}, (GB^{2/3} \\sqrt{d} \\log(1/\\delta))^{4/7}) \\quad \\text{in Equation (3) and using them as gradient} \\quad M^{5/3} \\quad \\text{oracles, Algorithm 1 with D_1 is} \\quad (\\epsilon, \\delta)-\\text{DP, and with probability at least} \\quad 1 - \\omega, \\quad \\text{at least one point in the output is} \\quad \\alpha_1\\text{-SOSP of F_P with}\n$$\n$$\n\\alpha_1 = O(BGM \\cdot \\log d)^{1/3} \\cdot \\frac{1}{d \\log(1/\\delta)})^{3/7} \\cdot \\log^3(nBMd/\\rho\\omega).\n$$\n$$\nn^{1/3} + (G^{1/7}B^{3/7}M^{3/7}) \\cdot (n\\epsilon)\n$$\nMoreover, if we run Algorithm 2 with inputs \\{x_i\\}_{i \\in [T]}, D_2, B, M, G, \\rho, \\alpha_1, \\quad \\text{with probability at least} \\quad 1 - \\omega, \\quad \\text{Algorithm 2 can output an} \\quad \\alpha_2\\text{-SOSP of F_P with}\n$$\n\\alpha_2 = O(\\alpha_1 + M \\log(ndBGM/\\rho\\omega) \\quad \\alpha_1 + G(\\log(n/G\\omega) + \\log(d/\\omega))).\n$$\n$$\n\\sqrt{\\rho} \\min(n\\epsilon, n^{1/2}) \\quad n\\epsilon \\quad n\n$$\n\n4 Bounding the excess risk\nIn this section, we consider the risk bounds.\n```\n```", "md": "```markdown\nalternative, we draw fresh samples from D without replacement with a smaller batch size:\n$$\nO_1(x) := 1 \\quad b_1 \\quad z \\in S_1 \\quad \\nabla f(x; z) + g_1, \\quad \\text{and} \\quad O_2(x, y) := 1 \\quad b_2 \\quad z \\in S_2 \\quad (\\nabla f(x; z) - \\nabla f(y; z)) + g_2, \\quad (3)\n$$\nwhere S_1 and S_2 are sets of size of b_1 and b_2 respectively drawn from D without replacement,\ng_1 \\sim \\mathcal{N}(0, \\sigma_1^2 \\text{Id}) \\quad \\text{and} \\quad g_2 \\sim \\mathcal{N}(0, \\sigma_2^2 \\|x - y\\|_2^2 \\cdot \\text{Id}). These gradient oracles satisfy the following.\n\nClaim 3.10. The gradient oracles O_1 and O_2 constructed in Equation (3) are a first kind of\n$$\nO(L\\sqrt{\\log d} + \\sqrt{d\\sigma_1}) \\quad \\text{norm-subGaussian gradient oracle and second kind of} \\quad O(M\\sqrt{\\log d} + \\sqrt{d\\sigma_2}) \\quad \\text{norm-} b_1 \\quad \\text{subGaussian gradient oracle respectively.}\n$$\n\nProof. For the oracle O_1, we know for each z \\in S_1, \\mathbb{E}_{z \\sim P}[\\nabla f(x, z)] = \\nabla F_P(x) \\quad \\text{and} \\quad \\nabla f(x, z) - \\nabla F_P(x) \\quad \\text{is nSG(L) due to the Lipschitzness assumption. The statement follows from Fact 2.3 and Lemma 2.4. As for the O_2, the statement follows similarly with the smoothness assumption.}\n\nRecall that in the empirical case, we use Algorithm 2 to choose the SOSP for FD. But in the population case, we need to find SOSP for F_P, and what we have are samples from P. We need the following technical results to help us find the SOSP from the set, which follows from Hoeffding inequality for norm-subGaussians (Lemma 2.4) and Matrix Bernstein inequality (Theorem 2.6).\n\nLemma 3.11. Fix a point x \\in \\mathbb{R}^d. Given a set S of m samples drawn i.i.d. from the distribution P, then we know with probability at least 1 - G \\log(d/\\omega) \\omega, we have\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O(\\sqrt{m}) \\quad \\text{and} \\quad \\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq O(\\sqrt{m}).\n$$\nWe can bound the population bound similar to the empirical bound with these tools.\n\nTheorem 3.12 (Population). Divide the dataset D into two disjoint datasets D_1 and D_2 of size\n$$\n\\lceil n/2 \\rceil \\quad \\text{and} \\quad \\lfloor n/2 \\rfloor \\quad \\text{respectively. Setting} \\quad b_1 = n\\kappa \\quad B\\eta, \\quad b_2 = n\\alpha^2 \\quad \\log(1/\\delta), \\quad \\sigma_2 = M\\sqrt{\\log(1/\\delta)} \\quad \\text{and} \\quad \\kappa = \\frac{BM}{G\\sqrt{b_1}\\epsilon}, \\quad \\sigma_1 = \\frac{G\\sqrt{b_1}\\epsilon}{b_2\\epsilon}\n$$\n$$\n\\max(G^{4/3}B^{1/3} \\log^{1/3} d \\cdot n^{-1/3}, (GB^{2/3} \\sqrt{d} \\log(1/\\delta))^{4/7}) \\quad \\text{in Equation (3) and using them as gradient} \\quad M^{5/3} \\quad \\text{oracles, Algorithm 1 with D_1 is} \\quad (\\epsilon, \\delta)-\\text{DP, and with probability at least} \\quad 1 - \\omega, \\quad \\text{at least one point in the output is} \\quad \\alpha_1\\text{-SOSP of F_P with}\n$$\n$$\n\\alpha_1 = O(BGM \\cdot \\log d)^{1/3} \\cdot \\frac{1}{d \\log(1/\\delta)})^{3/7} \\cdot \\log^3(nBMd/\\rho\\omega).\n$$\n$$\nn^{1/3} + (G^{1/7}B^{3/7}M^{3/7}) \\cdot (n\\epsilon)\n$$\nMoreover, if we run Algorithm 2 with inputs \\{x_i\\}_{i \\in [T]}, D_2, B, M, G, \\rho, \\alpha_1, \\quad \\text{with probability at least} \\quad 1 - \\omega, \\quad \\text{Algorithm 2 can output an} \\quad \\alpha_2\\text{-SOSP of F_P with}\n$$\n\\alpha_2 = O(\\alpha_1 + M \\log(ndBGM/\\rho\\omega) \\quad \\alpha_1 + G(\\log(n/G\\omega) + \\log(d/\\omega))).\n$$\n$$\n\\sqrt{\\rho} \\min(n\\epsilon, n^{1/2}) \\quad n\\epsilon \\quad n\n$$\n\n4 Bounding the excess risk\nIn this section, we consider the risk bounds.\n```\n```"}]}, {"page": 10, "text": "4.1     Polynomial time approach\nIf we want the algorithm to be efficient and implementable in polynomial time, to our knowledge\nthe only known bound is O(d log(1/\u03b4)   \u03b52 log n ) in [WCX19] for smooth functions. [WCX19] used Gradient\nLangevin Dynamics, a popular variant of SGD to solve this problem, and prove the privacy by\nadvanced composition.            We generalize the exponential mechanism to the non-convex case and\nimplement it without smoothness assumption.\n    First recall the Log-Sobolev inequality: We say a probability distribution \u03c0 satisfies LSI with\nconstant CLSI if for all f : Rd \u2192          R, E\u03c0[f 2 log f 2] \u2212     E\u03c0[f 2] log E\u03c0[f 2] \u2264    2CLSI E\u03c0 \u2225\u2207f\u22252      2.\n    A well-known result ([OV00]) says if f is \u00b5-strongly convex, then the distribution proptional to\nexp(\u2212f) satisfies LSI with constant 1/\u00b5. Recall the results from previous results [MASN16] about\nLSI and DP:\nTheorem 4.1 ([MASN16]). Sampling from\u221aexp(\u2212\u03b2F(x; D) \u2212                               r(x)) for some public regularizer r\nis (\u03b5, \u03b4)-DP, where \u03b5 \u2264        2G\u03b2n    CLSI     1 + 2 log(1/\u03b4), and CLSI is the worst LSI constant.\n    We can apply the classic perturbation lemma to get the new LSI constant in the non-convex\ncase. Suppose we add a regularizer \u00b5            2\u2225x\u22252, and try to sample from exp(\u2212\u03b2(F(x; D) + \u00b52 \u2225x\u22252)).\nLemma 4.2 (Stroock perturbation). Suppose \u03c0 satisfi                       es LSI with constant CLSI(\u03c0). If 0 < c \u2264\nd\u03c0\u2032\nd\u03c0 \u2264    C, then CLSI(\u03c0\u2032) \u2264        Cc CLSI(\u03c0).\n    Lemma 4.3 is a more general version of Theorem 3.4 in [GTU22] and can be used to bound the\nempirical risk.\nLemma 4.3. Let \u03c0(x) \u221d             exp(\u2212\u03b2(FD(x) + \u00b5        2 \u2225x\u222522)). Then for \u03b2GD > d, we know\n                       E                       2) \u2212   min                         2) \u2264   d\n                      x\u223c\u03c0(FD(x) + \u00b5     2\u2225x\u22252        x\u2217\u2208K(FD(x\u2217) + \u00b5      2\u2225x\u2217\u22252         \u03b2 log(\u03b2GD/d)\n    We now turn to bound the generalization error, and use the notion of uniform stability:\nLemma 4.4 (Stability and Generalization [BE02]). Given a dataset D = {si}i\u2208[n] drawn i.i.d.\nfrom some underlying distribution P, and given any algorithm A, suppose we randomly replace\na sample s in D by an independent fresh one s\u2032 from P and get the neighoring dataset D\u2032, then\nE D,A[FP(A(D)) \u2212        FD(A(D))] = ED,s\u2032,A[f(A(D); s\u2032)) \u2212               f(A(D\u2032); s\u2032))], where A(D) is the output of\nA with input D.\n    As each function f(; s\u2032) is G-Lipschitz, it suffices to bound the W2 distance of A(D) and A(D\u2032).\nIf A is sampling from the exponential mechanism, letting \u03c0D \u221d                             exp(\u2212\u03b2(FD(x) + \u00b52\u2225x\u22252)) and\n\u03c0D\u2032 \u221d    exp(\u2212\u03b2(FD\u2032(x) + \u00b52\u2225x\u22252)), it suffices to bound the W2 distance between \u03c0D and \u03c0D\u2032. The\nfollowing lemma can bound the generalization risk of the exponential mechanism under LSI:\nLemma 4.5 (Generalization error bound).ELet \u03c0D \u221d                        exp(\u2212\u03b2(FD(x) + \u00b5    ). 2 \u2225x\u22252 2)). Then we have\n                                    D,x\u223c\u03c0D[FP(x) \u2212       FD(x)] \u2264     O(G2 exp(\u03b2GD)\n                                                                                 n\u00b5\n    We get the following results:\nTheorem 4.6 (Risk bound). We are given \u03b5, \u03b4 \u2208                    (0, 1/2). Sampling from exp(\u2212\u03b2(FD(x)+ \u00b5                2\u2225x\u22252  2))\n                   \u03b5 log(nd)              d\nwith \u03b2 = O(     GD\u221alog(1/\u03b4))), \u00b5 =       D2\u03b2 is (\u03b5, \u03b4)-DP. The empirical risk and population risk are bounded\nby O(GD d\u00b7log log(n)\u221a      log(1/\u03b4)).\n                   \u03b5 log(nd)\n                                                               10", "md": "#### 4.1 Polynomial time approach\n\nIf we want the algorithm to be efficient and implementable in polynomial time, to our knowledge the only known bound is $$O(d \\log(1/\\delta) \\frac{\\epsilon^2 \\log n}{})$$ in [WCX19] for smooth functions. [WCX19] used Gradient Langevin Dynamics, a popular variant of SGD to solve this problem, and prove the privacy by advanced composition. We generalize the exponential mechanism to the non-convex case and implement it without smoothness assumption.\n\nFirst recall the Log-Sobolev inequality: We say a probability distribution \u03c0 satisfies LSI with constant CLSI if for all $$f : \\mathbb{R}^d \\rightarrow \\mathbb{R}$$, $$E_{\\pi}[f^2 \\log f^2] - E_{\\pi}[f^2] \\log E_{\\pi}[f^2] \\leq 2CLSI E_{\\pi} \\|\\nabla f\\|^2_2$$.\n\nA well-known result ([OV00]) says if f is \u00b5-strongly convex, then the distribution proportional to $$\\exp(-f)$$ satisfies LSI with constant $$\\frac{1}{\\mu}$$. Recall the results from previous results [MASN16] about LSI and DP:\n\nTheorem 4.1 ([MASN16]). Sampling from $$\\sqrt{\\exp(-\\beta F(x; D) - r(x))$$ for some public regularizer r is ($\\epsilon, \\delta$)-DP, where $$\\epsilon \\leq 2G\\beta n CLSI (1 + 2 \\log(1/\\delta))$$, and CLSI is the worst LSI constant.\n\nWe can apply the classic perturbation lemma to get the new LSI constant in the non-convex case. Suppose we add a regularizer $$\\mu \\frac{2}{\\|x\\|^2}$$, and try to sample from $$\\exp(-\\beta(F(x; D) + \\mu^2 \\|x\\|^2))$$.\n\nLemma 4.2 (Stroock perturbation). Suppose \u03c0 satisfies LSI with constant CLSI(\u03c0). If $$0 < c \\leq \\frac{d\\pi'}{d\\pi} \\leq C$$, then $$CLSI(\\pi') \\leq Cc CLSI(\\pi)$$.\n\nLemma 4.3 is a more general version of Theorem 3.4 in [GTU22] and can be used to bound the empirical risk.\n\nLemma 4.3. Let $$\\pi(x) \\propto \\exp(-\\beta(F_D(x) + \\mu^2 \\|x\\|^2_2))$$. Then for $$\\beta GD > d$$, we know $$E\\left(\\|f(A(D)) - \\min f(A(D))\\|^2\\right) \\leq d \\left(\\min_{x \\in K} (F_D(x) + \\mu^2 \\|x\\|^2)\\right) \\beta \\log(\\beta GD/d)$$.\n\nWe now turn to bound the generalization error, and use the notion of uniform stability:\n\nLemma 4.4 (Stability and Generalization [BE02]). Given a dataset $$D = \\{s_i\\}_{i \\in [n]}$$ drawn i.i.d. from some underlying distribution P, and given any algorithm A, suppose we randomly replace a sample s in D by an independent fresh one s' from P and get the neighboring dataset D', then $$E_{D,A}[F_P(A(D)) - F_D(A(D))] = E_{D,s'}[f(A(D); s')) - f(A(D'); s'))]$$, where A(D) is the output of A with input D.\n\nAs each function $$f(; s')$$ is G-Lipschitz, it suffices to bound the W2 distance of A(D) and A(D'). If A is sampling from the exponential mechanism, letting $$\\pi_D \\propto \\exp(-\\beta(F_D(x) + \\mu^2\\|x\\|^2))$$ and $$\\pi_{D'} \\propto \\exp(-\\beta(F_{D'}(x) + \\mu^2\\|x\\|^2))$$, it suffices to bound the W2 distance between $$\\pi_D$$ and $$\\pi_{D'}$$. The following lemma can bound the generalization risk of the exponential mechanism under LSI:\n\nLemma 4.5 (Generalization error bound). Let $$\\pi_D \\propto \\exp(-\\beta(F_D(x) + \\mu^2 \\|x\\|^2_2))$$. Then we have $$E_{D,x \\sim \\pi_D}[F_P(x) - F_D(x)] \\leq O(G^2 \\exp(\\beta GD) n\\mu$$.\n\nWe get the following results:\n\nTheorem 4.6 (Risk bound). We are given $$\\epsilon, \\delta \\in (0, 1/2)$$. Sampling from $$\\exp(-\\beta(F_D(x)+ \\mu 2\\|x\\|^2_2))$$ with $$\\beta = O(GD\\sqrt{\\log(1/\\delta)})$$, $$\\mu = D^2\\beta$$ is ($\\epsilon, \\delta$)-DP. The empirical risk and population risk are bounded by $$O(GD d \\cdot \\log \\log(n) \\sqrt{\\log(1/\\delta)})$$.\n\n10", "images": [], "items": [{"type": "heading", "lvl": 4, "value": "4.1 Polynomial time approach", "md": "#### 4.1 Polynomial time approach"}, {"type": "text", "value": "If we want the algorithm to be efficient and implementable in polynomial time, to our knowledge the only known bound is $$O(d \\log(1/\\delta) \\frac{\\epsilon^2 \\log n}{})$$ in [WCX19] for smooth functions. [WCX19] used Gradient Langevin Dynamics, a popular variant of SGD to solve this problem, and prove the privacy by advanced composition. We generalize the exponential mechanism to the non-convex case and implement it without smoothness assumption.\n\nFirst recall the Log-Sobolev inequality: We say a probability distribution \u03c0 satisfies LSI with constant CLSI if for all $$f : \\mathbb{R}^d \\rightarrow \\mathbb{R}$$, $$E_{\\pi}[f^2 \\log f^2] - E_{\\pi}[f^2] \\log E_{\\pi}[f^2] \\leq 2CLSI E_{\\pi} \\|\\nabla f\\|^2_2$$.\n\nA well-known result ([OV00]) says if f is \u00b5-strongly convex, then the distribution proportional to $$\\exp(-f)$$ satisfies LSI with constant $$\\frac{1}{\\mu}$$. Recall the results from previous results [MASN16] about LSI and DP:\n\nTheorem 4.1 ([MASN16]). Sampling from $$\\sqrt{\\exp(-\\beta F(x; D) - r(x))$$ for some public regularizer r is ($\\epsilon, \\delta$)-DP, where $$\\epsilon \\leq 2G\\beta n CLSI (1 + 2 \\log(1/\\delta))$$, and CLSI is the worst LSI constant.\n\nWe can apply the classic perturbation lemma to get the new LSI constant in the non-convex case. Suppose we add a regularizer $$\\mu \\frac{2}{\\|x\\|^2}$$, and try to sample from $$\\exp(-\\beta(F(x; D) + \\mu^2 \\|x\\|^2))$$.\n\nLemma 4.2 (Stroock perturbation). Suppose \u03c0 satisfies LSI with constant CLSI(\u03c0). If $$0 < c \\leq \\frac{d\\pi'}{d\\pi} \\leq C$$, then $$CLSI(\\pi') \\leq Cc CLSI(\\pi)$$.\n\nLemma 4.3 is a more general version of Theorem 3.4 in [GTU22] and can be used to bound the empirical risk.\n\nLemma 4.3. Let $$\\pi(x) \\propto \\exp(-\\beta(F_D(x) + \\mu^2 \\|x\\|^2_2))$$. Then for $$\\beta GD > d$$, we know $$E\\left(\\|f(A(D)) - \\min f(A(D))\\|^2\\right) \\leq d \\left(\\min_{x \\in K} (F_D(x) + \\mu^2 \\|x\\|^2)\\right) \\beta \\log(\\beta GD/d)$$.\n\nWe now turn to bound the generalization error, and use the notion of uniform stability:\n\nLemma 4.4 (Stability and Generalization [BE02]). Given a dataset $$D = \\{s_i\\}_{i \\in [n]}$$ drawn i.i.d. from some underlying distribution P, and given any algorithm A, suppose we randomly replace a sample s in D by an independent fresh one s' from P and get the neighboring dataset D', then $$E_{D,A}[F_P(A(D)) - F_D(A(D))] = E_{D,s'}[f(A(D); s')) - f(A(D'); s'))]$$, where A(D) is the output of A with input D.\n\nAs each function $$f(; s')$$ is G-Lipschitz, it suffices to bound the W2 distance of A(D) and A(D'). If A is sampling from the exponential mechanism, letting $$\\pi_D \\propto \\exp(-\\beta(F_D(x) + \\mu^2\\|x\\|^2))$$ and $$\\pi_{D'} \\propto \\exp(-\\beta(F_{D'}(x) + \\mu^2\\|x\\|^2))$$, it suffices to bound the W2 distance between $$\\pi_D$$ and $$\\pi_{D'}$$. The following lemma can bound the generalization risk of the exponential mechanism under LSI:\n\nLemma 4.5 (Generalization error bound). Let $$\\pi_D \\propto \\exp(-\\beta(F_D(x) + \\mu^2 \\|x\\|^2_2))$$. Then we have $$E_{D,x \\sim \\pi_D}[F_P(x) - F_D(x)] \\leq O(G^2 \\exp(\\beta GD) n\\mu$$.\n\nWe get the following results:\n\nTheorem 4.6 (Risk bound). We are given $$\\epsilon, \\delta \\in (0, 1/2)$$. Sampling from $$\\exp(-\\beta(F_D(x)+ \\mu 2\\|x\\|^2_2))$$ with $$\\beta = O(GD\\sqrt{\\log(1/\\delta)})$$, $$\\mu = D^2\\beta$$ is ($\\epsilon, \\delta$)-DP. The empirical risk and population risk are bounded by $$O(GD d \\cdot \\log \\log(n) \\sqrt{\\log(1/\\delta)})$$.\n\n10", "md": "If we want the algorithm to be efficient and implementable in polynomial time, to our knowledge the only known bound is $$O(d \\log(1/\\delta) \\frac{\\epsilon^2 \\log n}{})$$ in [WCX19] for smooth functions. [WCX19] used Gradient Langevin Dynamics, a popular variant of SGD to solve this problem, and prove the privacy by advanced composition. We generalize the exponential mechanism to the non-convex case and implement it without smoothness assumption.\n\nFirst recall the Log-Sobolev inequality: We say a probability distribution \u03c0 satisfies LSI with constant CLSI if for all $$f : \\mathbb{R}^d \\rightarrow \\mathbb{R}$$, $$E_{\\pi}[f^2 \\log f^2] - E_{\\pi}[f^2] \\log E_{\\pi}[f^2] \\leq 2CLSI E_{\\pi} \\|\\nabla f\\|^2_2$$.\n\nA well-known result ([OV00]) says if f is \u00b5-strongly convex, then the distribution proportional to $$\\exp(-f)$$ satisfies LSI with constant $$\\frac{1}{\\mu}$$. Recall the results from previous results [MASN16] about LSI and DP:\n\nTheorem 4.1 ([MASN16]). Sampling from $$\\sqrt{\\exp(-\\beta F(x; D) - r(x))$$ for some public regularizer r is ($\\epsilon, \\delta$)-DP, where $$\\epsilon \\leq 2G\\beta n CLSI (1 + 2 \\log(1/\\delta))$$, and CLSI is the worst LSI constant.\n\nWe can apply the classic perturbation lemma to get the new LSI constant in the non-convex case. Suppose we add a regularizer $$\\mu \\frac{2}{\\|x\\|^2}$$, and try to sample from $$\\exp(-\\beta(F(x; D) + \\mu^2 \\|x\\|^2))$$.\n\nLemma 4.2 (Stroock perturbation). Suppose \u03c0 satisfies LSI with constant CLSI(\u03c0). If $$0 < c \\leq \\frac{d\\pi'}{d\\pi} \\leq C$$, then $$CLSI(\\pi') \\leq Cc CLSI(\\pi)$$.\n\nLemma 4.3 is a more general version of Theorem 3.4 in [GTU22] and can be used to bound the empirical risk.\n\nLemma 4.3. Let $$\\pi(x) \\propto \\exp(-\\beta(F_D(x) + \\mu^2 \\|x\\|^2_2))$$. Then for $$\\beta GD > d$$, we know $$E\\left(\\|f(A(D)) - \\min f(A(D))\\|^2\\right) \\leq d \\left(\\min_{x \\in K} (F_D(x) + \\mu^2 \\|x\\|^2)\\right) \\beta \\log(\\beta GD/d)$$.\n\nWe now turn to bound the generalization error, and use the notion of uniform stability:\n\nLemma 4.4 (Stability and Generalization [BE02]). Given a dataset $$D = \\{s_i\\}_{i \\in [n]}$$ drawn i.i.d. from some underlying distribution P, and given any algorithm A, suppose we randomly replace a sample s in D by an independent fresh one s' from P and get the neighboring dataset D', then $$E_{D,A}[F_P(A(D)) - F_D(A(D))] = E_{D,s'}[f(A(D); s')) - f(A(D'); s'))]$$, where A(D) is the output of A with input D.\n\nAs each function $$f(; s')$$ is G-Lipschitz, it suffices to bound the W2 distance of A(D) and A(D'). If A is sampling from the exponential mechanism, letting $$\\pi_D \\propto \\exp(-\\beta(F_D(x) + \\mu^2\\|x\\|^2))$$ and $$\\pi_{D'} \\propto \\exp(-\\beta(F_{D'}(x) + \\mu^2\\|x\\|^2))$$, it suffices to bound the W2 distance between $$\\pi_D$$ and $$\\pi_{D'}$$. The following lemma can bound the generalization risk of the exponential mechanism under LSI:\n\nLemma 4.5 (Generalization error bound). Let $$\\pi_D \\propto \\exp(-\\beta(F_D(x) + \\mu^2 \\|x\\|^2_2))$$. Then we have $$E_{D,x \\sim \\pi_D}[F_P(x) - F_D(x)] \\leq O(G^2 \\exp(\\beta GD) n\\mu$$.\n\nWe get the following results:\n\nTheorem 4.6 (Risk bound). We are given $$\\epsilon, \\delta \\in (0, 1/2)$$. Sampling from $$\\exp(-\\beta(F_D(x)+ \\mu 2\\|x\\|^2_2))$$ with $$\\beta = O(GD\\sqrt{\\log(1/\\delta)})$$, $$\\mu = D^2\\beta$$ is ($\\epsilon, \\delta$)-DP. The empirical risk and population risk are bounded by $$O(GD d \\cdot \\log \\log(n) \\sqrt{\\log(1/\\delta)})$$.\n\n10"}]}, {"page": 11, "text": "4.1.1       Implementation\nThere are multiple existing algorithms that can sample efficiently from density with LSI, under\nmild assumptions. For example, when the functions are smooth or weakly smooth, one can turn\nto the Langevin Monte Carlo [CEL+22], and [LC22].                                The algorithm in [WCX19] also requires\nmild smoothness assumptions. We discuss the implementation of non-smooth functions in bit more\ndetails, which is more challenging.\n     We can adopt the rejection sampler in [GLL22], which is based on the alternating sampling\nalgorithm in [LST21]. Both [LST21] and [GLL22] are written in the language of log-concave and\nstrongly log-concave densities, but their results hold as long as LSI holds. By combining them\ntogether, we can get the following risk bounds. The details of the implementation can be found in\nAppendix B.3.\nTheorem 4.7 (Implementation, risk bound). For \u03b5, \u03b4 \u2208                               (0, 1/2), there is an (\u03b5, 2\u03b4)-DP effi             cient\nsampler that can achieve the empirical and population risks O(GD d\u00b7log log(n)\u221a                                   log(1/\u03b4) ). Moreover,\n                                                                                                         \u03b5 log(nd)\nin expectation, the sampler takes \u02dc             O    n\u03b53 log3(d)       log(1/\u03b4)/(GD)           function values query and some\nGaussian random variables restricted to the convex set K in total.\n4.2      Exponential time approach\nIn [GTU22], it is shown that sampling from exp(\u2212                         \u03b5n\n                                                                         GDFD(x)) is \u03b5-DP, and a nearly tight empirical\nrisk bound of \u02dc     O(DGdn\u03b5 ) is achieved for convex functions. It is open what is the bound we can get for\nnon-convex DP-SO.\n4.2.1       Upper Bound\nGiven exponential time we can use a discrete exponential mechanism as considered in [BST14]. We\nrecap the argument and extend it to DP-SO. The proof is based on a simple packing argument,\nand can be found in Appendix B.4.\nTheorem 4.8. There exists an \u03b5-DP differentially private algorithm that achieves a population\nrisk of O      GD      d log(\u03b5n/d)/(\u03b5n) +             d log(\u03b5n/d)/(\u221an)             .\n4.2.2       Lower Bound\nResults in [GTU22] imply that the first term of \u02dc                  O(GDd/\u03b5n) is tight, even if we relax to approximate\nDP with \u03b4 > 0. A reduction from private selection problem shows the \u02dc                                    O(   d/n) generalization\nterm is also nearly-tight (Theorem 4.11). In the selection problem, we have k coins, each with an\nunknown probability pi. Each coin is flipped n times such that {xi,j}j\u2208[n], each xi,j i.i.d. sampled\nfrom Bern(pi), and we want to choose a coin i with the smallest pi. The risk of choosing i is\npi \u2212   mini\u2217   pi\u2217.\nTheorem 4.9. Any algorithm for the selection problem has excess population risk \u02dc                                      \u2126(   log k\n                                                                                                                                n ).\n     This follows from a folklore result on the selection problem (see e.g. [BU17]). We can combine\nthis with the following reduction from selection to non-convex optimization:\nTheorem 4.10 (Restatement of results in [GTU22]). If any (\u03b5, \u03b4)-DP algorithm for selection\nhas risk R(k), then any (\u03b5, \u03b4)-DP algorithm for minimizing 1-Lipschitz losses over Bd(0, 1) (the\nd-dimensional unit ball) has risk R(2\u0398(d)).\n     From this and the aforementioned lower bounds in empirical non-convex optimization we get\nthe following:\n                                                                     11", "md": "#### 4.1.1 Implementation\n\nThere are multiple existing algorithms that can sample efficiently from density with LSI, under mild assumptions. For example, when the functions are smooth or weakly smooth, one can turn to the Langevin Monte Carlo $$[CEL+22]$$, and $$[LC22]$$. The algorithm in $$[WCX19]$$ also requires mild smoothness assumptions. We discuss the implementation of non-smooth functions in bit more details, which is more challenging.\n\nWe can adopt the rejection sampler in $$[GLL22]$$, which is based on the alternating sampling algorithm in $$[LST21]$$. Both $$[LST21]$$ and $$[GLL22]$$ are written in the language of log-concave and strongly log-concave densities, but their results hold as long as LSI holds. By combining them together, we can get the following risk bounds. The details of the implementation can be found in Appendix B.3.\n\nTheorem 4.7 (Implementation, risk bound). For $$\u03b5, \u03b4 \u2208 (0, 1/2)$$, there is an $$(\u03b5, 2\u03b4)$$-DP efficient sampler that can achieve the empirical and population risks $$O(GD d\u00b7log log(n)\u221a log(1/\u03b4))$$. Moreover, in expectation, the sampler takes $$\\tilde{O} \\, n\u03b5^3 log^3(d) log(1/\u03b4)/(GD)$$ function values query and some Gaussian random variables restricted to the convex set K in total.\n\n#### 4.2 Exponential time approach\n\nIn $$[GTU22]$$, it is shown that sampling from $$exp(-\u03b5n GDFD(x))$$ is \u03b5-DP, and a nearly tight empirical risk bound of $$\\tilde{O}(DGdn\u03b5)$$ is achieved for convex functions. It is open what is the bound we can get for non-convex DP-SO.\n\n#### 4.2.1 Upper Bound\n\nGiven exponential time we can use a discrete exponential mechanism as considered in $$[BST14]$$. We recap the argument and extend it to DP-SO. The proof is based on a simple packing argument, and can be found in Appendix B.4.\n\nTheorem 4.8. There exists an \u03b5-DP differentially private algorithm that achieves a population risk of $$O(GD d log(\u03b5n/d)/(\u03b5n) + d log(\u03b5n/d)/(\u221an))$$.\n\n#### 4.2.2 Lower Bound\n\nResults in $$[GTU22]$$ imply that the first term of $$\\tilde{O}(GDd/\u03b5n)$$ is tight, even if we relax to approximate DP with $$\u03b4 > 0$$. A reduction from private selection problem shows the $$\\tilde{O}(d/n)$$ generalization term is also nearly-tight (Theorem 4.11). In the selection problem, we have $$k$$ coins, each with an unknown probability $$p_i$$. Each coin is flipped $$n$$ times such that $$\\{x_{i,j}\\}_{j\u2208[n]}$$, each $$x_{i,j}$$ i.i.d. sampled from Bern($$p_i$$), and we want to choose a coin $$i$$ with the smallest $$p_i$$. The risk of choosing $$i$$ is $$p_i - \\min_{i^*} p_{i^*}$$.\n\nTheorem 4.9. Any algorithm for the selection problem has excess population risk $$\\tilde{\u2126}(log k/n)$$. This follows from a folklore result on the selection problem (see e.g. $$[BU17]$$). We can combine this with the following reduction from selection to non-convex optimization:\n\nTheorem 4.10 (Restatement of results in [GTU22]). If any $$(\u03b5, \u03b4)$$-DP algorithm for selection has risk $$R(k)$$, then any $$(\u03b5, \u03b4)$$-DP algorithm for minimizing 1-Lipschitz losses over $$B_d(0, 1)$$ (the d-dimensional unit ball) has risk $$R(2\u0398(d))$$. From this and the aforementioned lower bounds in empirical non-convex optimization we get the following:\n\n11", "images": [], "items": [{"type": "heading", "lvl": 4, "value": "4.1.1 Implementation", "md": "#### 4.1.1 Implementation"}, {"type": "text", "value": "There are multiple existing algorithms that can sample efficiently from density with LSI, under mild assumptions. For example, when the functions are smooth or weakly smooth, one can turn to the Langevin Monte Carlo $$[CEL+22]$$, and $$[LC22]$$. The algorithm in $$[WCX19]$$ also requires mild smoothness assumptions. We discuss the implementation of non-smooth functions in bit more details, which is more challenging.\n\nWe can adopt the rejection sampler in $$[GLL22]$$, which is based on the alternating sampling algorithm in $$[LST21]$$. Both $$[LST21]$$ and $$[GLL22]$$ are written in the language of log-concave and strongly log-concave densities, but their results hold as long as LSI holds. By combining them together, we can get the following risk bounds. The details of the implementation can be found in Appendix B.3.\n\nTheorem 4.7 (Implementation, risk bound). For $$\u03b5, \u03b4 \u2208 (0, 1/2)$$, there is an $$(\u03b5, 2\u03b4)$$-DP efficient sampler that can achieve the empirical and population risks $$O(GD d\u00b7log log(n)\u221a log(1/\u03b4))$$. Moreover, in expectation, the sampler takes $$\\tilde{O} \\, n\u03b5^3 log^3(d) log(1/\u03b4)/(GD)$$ function values query and some Gaussian random variables restricted to the convex set K in total.", "md": "There are multiple existing algorithms that can sample efficiently from density with LSI, under mild assumptions. For example, when the functions are smooth or weakly smooth, one can turn to the Langevin Monte Carlo $$[CEL+22]$$, and $$[LC22]$$. The algorithm in $$[WCX19]$$ also requires mild smoothness assumptions. We discuss the implementation of non-smooth functions in bit more details, which is more challenging.\n\nWe can adopt the rejection sampler in $$[GLL22]$$, which is based on the alternating sampling algorithm in $$[LST21]$$. Both $$[LST21]$$ and $$[GLL22]$$ are written in the language of log-concave and strongly log-concave densities, but their results hold as long as LSI holds. By combining them together, we can get the following risk bounds. The details of the implementation can be found in Appendix B.3.\n\nTheorem 4.7 (Implementation, risk bound). For $$\u03b5, \u03b4 \u2208 (0, 1/2)$$, there is an $$(\u03b5, 2\u03b4)$$-DP efficient sampler that can achieve the empirical and population risks $$O(GD d\u00b7log log(n)\u221a log(1/\u03b4))$$. Moreover, in expectation, the sampler takes $$\\tilde{O} \\, n\u03b5^3 log^3(d) log(1/\u03b4)/(GD)$$ function values query and some Gaussian random variables restricted to the convex set K in total."}, {"type": "heading", "lvl": 4, "value": "4.2 Exponential time approach", "md": "#### 4.2 Exponential time approach"}, {"type": "text", "value": "In $$[GTU22]$$, it is shown that sampling from $$exp(-\u03b5n GDFD(x))$$ is \u03b5-DP, and a nearly tight empirical risk bound of $$\\tilde{O}(DGdn\u03b5)$$ is achieved for convex functions. It is open what is the bound we can get for non-convex DP-SO.", "md": "In $$[GTU22]$$, it is shown that sampling from $$exp(-\u03b5n GDFD(x))$$ is \u03b5-DP, and a nearly tight empirical risk bound of $$\\tilde{O}(DGdn\u03b5)$$ is achieved for convex functions. It is open what is the bound we can get for non-convex DP-SO."}, {"type": "heading", "lvl": 4, "value": "4.2.1 Upper Bound", "md": "#### 4.2.1 Upper Bound"}, {"type": "text", "value": "Given exponential time we can use a discrete exponential mechanism as considered in $$[BST14]$$. We recap the argument and extend it to DP-SO. The proof is based on a simple packing argument, and can be found in Appendix B.4.\n\nTheorem 4.8. There exists an \u03b5-DP differentially private algorithm that achieves a population risk of $$O(GD d log(\u03b5n/d)/(\u03b5n) + d log(\u03b5n/d)/(\u221an))$$.", "md": "Given exponential time we can use a discrete exponential mechanism as considered in $$[BST14]$$. We recap the argument and extend it to DP-SO. The proof is based on a simple packing argument, and can be found in Appendix B.4.\n\nTheorem 4.8. There exists an \u03b5-DP differentially private algorithm that achieves a population risk of $$O(GD d log(\u03b5n/d)/(\u03b5n) + d log(\u03b5n/d)/(\u221an))$$."}, {"type": "heading", "lvl": 4, "value": "4.2.2 Lower Bound", "md": "#### 4.2.2 Lower Bound"}, {"type": "text", "value": "Results in $$[GTU22]$$ imply that the first term of $$\\tilde{O}(GDd/\u03b5n)$$ is tight, even if we relax to approximate DP with $$\u03b4 > 0$$. A reduction from private selection problem shows the $$\\tilde{O}(d/n)$$ generalization term is also nearly-tight (Theorem 4.11). In the selection problem, we have $$k$$ coins, each with an unknown probability $$p_i$$. Each coin is flipped $$n$$ times such that $$\\{x_{i,j}\\}_{j\u2208[n]}$$, each $$x_{i,j}$$ i.i.d. sampled from Bern($$p_i$$), and we want to choose a coin $$i$$ with the smallest $$p_i$$. The risk of choosing $$i$$ is $$p_i - \\min_{i^*} p_{i^*}$$.\n\nTheorem 4.9. Any algorithm for the selection problem has excess population risk $$\\tilde{\u2126}(log k/n)$$. This follows from a folklore result on the selection problem (see e.g. $$[BU17]$$). We can combine this with the following reduction from selection to non-convex optimization:\n\nTheorem 4.10 (Restatement of results in [GTU22]). If any $$(\u03b5, \u03b4)$$-DP algorithm for selection has risk $$R(k)$$, then any $$(\u03b5, \u03b4)$$-DP algorithm for minimizing 1-Lipschitz losses over $$B_d(0, 1)$$ (the d-dimensional unit ball) has risk $$R(2\u0398(d))$$. From this and the aforementioned lower bounds in empirical non-convex optimization we get the following:\n\n11", "md": "Results in $$[GTU22]$$ imply that the first term of $$\\tilde{O}(GDd/\u03b5n)$$ is tight, even if we relax to approximate DP with $$\u03b4 > 0$$. A reduction from private selection problem shows the $$\\tilde{O}(d/n)$$ generalization term is also nearly-tight (Theorem 4.11). In the selection problem, we have $$k$$ coins, each with an unknown probability $$p_i$$. Each coin is flipped $$n$$ times such that $$\\{x_{i,j}\\}_{j\u2208[n]}$$, each $$x_{i,j}$$ i.i.d. sampled from Bern($$p_i$$), and we want to choose a coin $$i$$ with the smallest $$p_i$$. The risk of choosing $$i$$ is $$p_i - \\min_{i^*} p_{i^*}$$.\n\nTheorem 4.9. Any algorithm for the selection problem has excess population risk $$\\tilde{\u2126}(log k/n)$$. This follows from a folklore result on the selection problem (see e.g. $$[BU17]$$). We can combine this with the following reduction from selection to non-convex optimization:\n\nTheorem 4.10 (Restatement of results in [GTU22]). If any $$(\u03b5, \u03b4)$$-DP algorithm for selection has risk $$R(k)$$, then any $$(\u03b5, \u03b4)$$-DP algorithm for minimizing 1-Lipschitz losses over $$B_d(0, 1)$$ (the d-dimensional unit ball) has risk $$R(2\u0398(d))$$. From this and the aforementioned lower bounds in empirical non-convex optimization we get the following:\n\n11"}]}, {"page": 12, "text": "Theorem 4.11. For \u03b5 \u2264         1, \u03b4 \u2208  [2\u2212\u2126(n), 1/n1+\u2126(1)], any (\u03b5, \u03b4)-DP algorithm for minimizing 1-\nLipschitz losses over Bd(0, 1) has excess population risk max{\u2126(d log(1/\u03b4)/(\u03b5n)), \u02dc      \u2126(  d/n)}.\n5     Conclusion\nWe present a novel framework that can improve upon the state-of-the-art rates for locating second-\norder stationary points for both empirical and population risks. We also examine the utilization\nof the exponential mechanism to attain favorable excess risk bounds for both a polynomial time\nsampling approach and an exponential time sampling approach. Despite the progress made, several\ninteresting questions remain. There is still a gap between the upper and lower bounds for find-      \u221a\ning stationary points. As noted in [ABG+22], it is quite challenging to beat the current (           nd)2/3\nempirical upper bound, and overcoming this challenge may require the development of new tech-\nniques. A potential avenue for improving the population rate for SOSP could be combining our\ndrift-controlled framework with the tree-based private SpiderBoost algorithm in [ABG+22]. Addi-\ntionally, it is worth exploring if it is possible to achieve better excess risk bounds within polynomial\ntime, and what the optimal risk bound could be.\n6     Acknowledgement\nDG would like to thank Ruoqi Shen and Kevin Tian for several discussions.\n                                                     12", "md": "# Document\n\n## Theorem 4.11\n\nFor \\( \\epsilon \\leq 1 \\), \\( \\delta \\in [2^{-\\Omega(n)}, \\frac{1}{n^{1+\\Omega(1)}}] \\), any (\\( \\epsilon, \\delta \\))-DP algorithm for minimizing 1-Lipschitz losses over \\( B_d(0, 1) \\) has excess population risk \\( \\max\\{\\Omega(d \\log(1/\\delta)/(\\epsilon n)), \\tilde{\\Omega}(d/n)\\} \\).\n\n## Conclusion\n\nWe present a novel framework that can improve upon the state-of-the-art rates for locating second-order stationary points for both empirical and population risks. We also examine the utilization of the exponential mechanism to attain favorable excess risk bounds for both a polynomial time sampling approach and an exponential time sampling approach. Despite the progress made, several interesting questions remain. There is still a gap between the upper and lower bounds for finding stationary points. As noted in [ABG+22], it is quite challenging to beat the current \\( (nd)^{2/3} \\) empirical upper bound, and overcoming this challenge may require the development of new techniques. A potential avenue for improving the population rate for SOSP could be combining our drift-controlled framework with the tree-based private SpiderBoost algorithm in [ABG+22]. Additionally, it is worth exploring if it is possible to achieve better excess risk bounds within polynomial time, and what the optimal risk bound could be.\n\n## Acknowledgement\n\nDG would like to thank Ruoqi Shen and Kevin Tian for several discussions.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 2, "value": "Theorem 4.11", "md": "## Theorem 4.11"}, {"type": "text", "value": "For \\( \\epsilon \\leq 1 \\), \\( \\delta \\in [2^{-\\Omega(n)}, \\frac{1}{n^{1+\\Omega(1)}}] \\), any (\\( \\epsilon, \\delta \\))-DP algorithm for minimizing 1-Lipschitz losses over \\( B_d(0, 1) \\) has excess population risk \\( \\max\\{\\Omega(d \\log(1/\\delta)/(\\epsilon n)), \\tilde{\\Omega}(d/n)\\} \\).", "md": "For \\( \\epsilon \\leq 1 \\), \\( \\delta \\in [2^{-\\Omega(n)}, \\frac{1}{n^{1+\\Omega(1)}}] \\), any (\\( \\epsilon, \\delta \\))-DP algorithm for minimizing 1-Lipschitz losses over \\( B_d(0, 1) \\) has excess population risk \\( \\max\\{\\Omega(d \\log(1/\\delta)/(\\epsilon n)), \\tilde{\\Omega}(d/n)\\} \\)."}, {"type": "heading", "lvl": 2, "value": "Conclusion", "md": "## Conclusion"}, {"type": "text", "value": "We present a novel framework that can improve upon the state-of-the-art rates for locating second-order stationary points for both empirical and population risks. We also examine the utilization of the exponential mechanism to attain favorable excess risk bounds for both a polynomial time sampling approach and an exponential time sampling approach. Despite the progress made, several interesting questions remain. There is still a gap between the upper and lower bounds for finding stationary points. As noted in [ABG+22], it is quite challenging to beat the current \\( (nd)^{2/3} \\) empirical upper bound, and overcoming this challenge may require the development of new techniques. A potential avenue for improving the population rate for SOSP could be combining our drift-controlled framework with the tree-based private SpiderBoost algorithm in [ABG+22]. Additionally, it is worth exploring if it is possible to achieve better excess risk bounds within polynomial time, and what the optimal risk bound could be.", "md": "We present a novel framework that can improve upon the state-of-the-art rates for locating second-order stationary points for both empirical and population risks. We also examine the utilization of the exponential mechanism to attain favorable excess risk bounds for both a polynomial time sampling approach and an exponential time sampling approach. Despite the progress made, several interesting questions remain. There is still a gap between the upper and lower bounds for finding stationary points. As noted in [ABG+22], it is quite challenging to beat the current \\( (nd)^{2/3} \\) empirical upper bound, and overcoming this challenge may require the development of new techniques. A potential avenue for improving the population rate for SOSP could be combining our drift-controlled framework with the tree-based private SpiderBoost algorithm in [ABG+22]. Additionally, it is worth exploring if it is possible to achieve better excess risk bounds within polynomial time, and what the optimal risk bound could be."}, {"type": "heading", "lvl": 2, "value": "Acknowledgement", "md": "## Acknowledgement"}, {"type": "text", "value": "DG would like to thank Ruoqi Shen and Kevin Tian for several discussions.", "md": "DG would like to thank Ruoqi Shen and Kevin Tian for several discussions."}]}, {"page": 13, "text": "References\n[AAZB+17] Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma. Find-\n             ing approximate local minima faster than gradient descent. In Proceedings of the 49th\n             Annual ACM SIGACT Symposium on Theory of Computing, pages 1195\u20131199, 2017.\n [ABG+22] Raman Arora, Raef Bassily, Tom\u00b4       as Gonz\u00b4alez, Crist\u00b4\n                                                                   obal Guzm\u00b4  an, Michael Menart, and\n             Enayat Ullah. Faster rates of convergence to stationary points in differentially private\n             optimization. arXiv preprint arXiv:2206.00846, 2022.\n [AFKT21] Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex\n             optimization: Optimal rates in l1 geometry. In International Conference on Machine\n             Learning, pages 393\u2013403. PMLR, 2021.\n   [ALD21] Hilal Asi, Daniel Asher Nathan Levy, and John Duchi. Adapting to function difficulty\n             and growth conditions in private optimization. In Advances in Neural Information\n             Processing Systems, 2021.\n     [BE02] Olivier Bousquet and Andr\u00b4     e Elisseeff. Stability and generalization. The Journal of\n             Machine Learning Research, 2:499\u2013526, 2002.\n [BFGT20] Raef Bassily, Vitaly Feldman, Crist\u00b4         obal Guzm\u00b4  an, and Kunal Talwar.         Stabil-\n             ity of stochastic gradient descent on nonsmooth convex losses.             arXiv preprint\n             arXiv:2006.06914, 2020.\n [BFTT19] Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Thakurta.                    Private\n             stochastic convex optimization with optimal rates. In Advances in Neural Information\n             Processing Systems, pages 11279\u201311288, 2019.\n  [BGM21] Raef Bassily, Crist\u00b4   obal Guzm\u00b4 an, and Michael Menart. Differentially private stochastic\n             optimization: New results in convex and non-convex settings.          Advances in Neural\n             Information Processing Systems, 34:9317\u20139329, 2021.\n   [BST14] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk mini-\n             mization: Efficient algorithms and tight error bounds. In Proc. of the 2014 IEEE 55th\n             Annual Symp. on Foundations of Computer Science (FOCS), pages 464\u2013473, 2014.\n     [BU17] Mitali Bafna and Jonathan Ullman.          The price of selection in differential privacy.\n             In Satyen Kale and Ohad Shamir, editors, Proceedings of the 2017 Conference on\n             Learning Theory, volume 65 of Proceedings of Machine Learning Research, pages 151\u2013\n             168. PMLR, 07\u201310 Jul 2017.\n [CCSW22] Yongxin Chen, Sinho Chewi, Adil Salim, and Andre Wibisono. Improved analysis for a\n             proximal algorithm for sampling. In Conference on Learning Theory, pages 2984\u20133014.\n             PMLR, 2022.\n  [CEL+22] Sinho Chewi, Murat A Erdogdu, Mufan Li, Ruoqi Shen, and Shunshi Zhang. Analysis\n             of langevin monte carlo from poincare to log-sobolev.         In Conference on Learning\n             Theory, pages 1\u20132. PMLR, 2022.\n  [CJJ+23] Yair Carmon, Arun Jambulapati, Yujia Jin, Yin Tat Lee, Daogao Liu, Aaron Sidford,\n             and Kevin Tian. Resqueing parallel and private stochastic convex optimization. arXiv\n             preprint arXiv:2301.00457, 2023.\n                                                   13", "md": "# References\n\n## References\n\n- [AAZB+17] Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma. Finding approximate local minima faster than gradient descent. In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, pages 1195\u20131199, 2017.\n- [ABG+22] Raman Arora, Raef Bassily, Tom\u00e1s Gonz\u00e1lez, Crist\u00f3bal Guzm\u00e1n, Michael Menart, and Enayat Ullah. Faster rates of convergence to stationary points in differentially private optimization. arXiv preprint arXiv:2206.00846, 2022.\n- [AFKT21] Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021.\n- [ALD21] Hilal Asi, Daniel Asher Nathan Levy, and John Duchi. Adapting to function difficulty and growth conditions in private optimization. In Advances in Neural Information Processing Systems, 2021.\n- [BE02] Olivier Bousquet and Andr\u00e9 Elisseeff. Stability and generalization. The Journal of Machine Learning Research, 2:499\u2013526, 2002.\n- [BFGT20] Raef Bassily, Vitaly Feldman, Crist\u00f3bal Guzm\u00e1n, and Kunal Talwar. Stability of stochastic gradient descent on nonsmooth convex losses. arXiv preprint arXiv:2006.06914, 2020.\n- [BFTT19] Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Thakurta. Private stochastic convex optimization with optimal rates. In Advances in Neural Information Processing Systems, pages 11279\u201311288, 2019.\n- [BGM21] Raef Bassily, Crist\u00f3bal Guzm\u00e1n, and Michael Menart. Differentially private stochastic optimization: New results in convex and non-convex settings. Advances in Neural Information Processing Systems, 34:9317\u20139329, 2021.\n- [BST14] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In Proc. of the 2014 IEEE 55th Annual Symp. on Foundations of Computer Science (FOCS), pages 464\u2013473, 2014.\n- [BU17] Mitali Bafna and Jonathan Ullman. The price of selection in differential privacy. In Satyen Kale and Ohad Shamir, editors, Proceedings of the 2017 Conference on Learning Theory, volume 65 of Proceedings of Machine Learning Research, pages 151\u2013168. PMLR, 07\u201310 Jul 2017.\n- [CCSW22] Yongxin Chen, Sinho Chewi, Adil Salim, and Andre Wibisono. Improved analysis for a proximal algorithm for sampling. In Conference on Learning Theory, pages 2984\u20133014. PMLR, 2022.\n- [CEL+22] Sinho Chewi, Murat A Erdogdu, Mufan Li, Ruoqi Shen, and Shunshi Zhang. Analysis of langevin monte carlo from poincare to log-sobolev. In Conference on Learning Theory, pages 1\u20132. PMLR, 2022.\n- [CJJ+23] Yair Carmon, Arun Jambulapati, Yujia Jin, Yin Tat Lee, Daogao Liu, Aaron Sidford, and Kevin Tian. Resqueing parallel and private stochastic convex optimization. arXiv preprint arXiv:2301.00457, 2023.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 2, "value": "References", "md": "## References"}, {"type": "text", "value": "- [AAZB+17] Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma. Finding approximate local minima faster than gradient descent. In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, pages 1195\u20131199, 2017.\n- [ABG+22] Raman Arora, Raef Bassily, Tom\u00e1s Gonz\u00e1lez, Crist\u00f3bal Guzm\u00e1n, Michael Menart, and Enayat Ullah. Faster rates of convergence to stationary points in differentially private optimization. arXiv preprint arXiv:2206.00846, 2022.\n- [AFKT21] Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021.\n- [ALD21] Hilal Asi, Daniel Asher Nathan Levy, and John Duchi. Adapting to function difficulty and growth conditions in private optimization. In Advances in Neural Information Processing Systems, 2021.\n- [BE02] Olivier Bousquet and Andr\u00e9 Elisseeff. Stability and generalization. The Journal of Machine Learning Research, 2:499\u2013526, 2002.\n- [BFGT20] Raef Bassily, Vitaly Feldman, Crist\u00f3bal Guzm\u00e1n, and Kunal Talwar. Stability of stochastic gradient descent on nonsmooth convex losses. arXiv preprint arXiv:2006.06914, 2020.\n- [BFTT19] Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Thakurta. Private stochastic convex optimization with optimal rates. In Advances in Neural Information Processing Systems, pages 11279\u201311288, 2019.\n- [BGM21] Raef Bassily, Crist\u00f3bal Guzm\u00e1n, and Michael Menart. Differentially private stochastic optimization: New results in convex and non-convex settings. Advances in Neural Information Processing Systems, 34:9317\u20139329, 2021.\n- [BST14] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In Proc. of the 2014 IEEE 55th Annual Symp. on Foundations of Computer Science (FOCS), pages 464\u2013473, 2014.\n- [BU17] Mitali Bafna and Jonathan Ullman. The price of selection in differential privacy. In Satyen Kale and Ohad Shamir, editors, Proceedings of the 2017 Conference on Learning Theory, volume 65 of Proceedings of Machine Learning Research, pages 151\u2013168. PMLR, 07\u201310 Jul 2017.\n- [CCSW22] Yongxin Chen, Sinho Chewi, Adil Salim, and Andre Wibisono. Improved analysis for a proximal algorithm for sampling. In Conference on Learning Theory, pages 2984\u20133014. PMLR, 2022.\n- [CEL+22] Sinho Chewi, Murat A Erdogdu, Mufan Li, Ruoqi Shen, and Shunshi Zhang. Analysis of langevin monte carlo from poincare to log-sobolev. In Conference on Learning Theory, pages 1\u20132. PMLR, 2022.\n- [CJJ+23] Yair Carmon, Arun Jambulapati, Yujia Jin, Yin Tat Lee, Daogao Liu, Aaron Sidford, and Kevin Tian. Resqueing parallel and private stochastic convex optimization. arXiv preprint arXiv:2301.00457, 2023.", "md": "- [AAZB+17] Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma. Finding approximate local minima faster than gradient descent. In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, pages 1195\u20131199, 2017.\n- [ABG+22] Raman Arora, Raef Bassily, Tom\u00e1s Gonz\u00e1lez, Crist\u00f3bal Guzm\u00e1n, Michael Menart, and Enayat Ullah. Faster rates of convergence to stationary points in differentially private optimization. arXiv preprint arXiv:2206.00846, 2022.\n- [AFKT21] Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021.\n- [ALD21] Hilal Asi, Daniel Asher Nathan Levy, and John Duchi. Adapting to function difficulty and growth conditions in private optimization. In Advances in Neural Information Processing Systems, 2021.\n- [BE02] Olivier Bousquet and Andr\u00e9 Elisseeff. Stability and generalization. The Journal of Machine Learning Research, 2:499\u2013526, 2002.\n- [BFGT20] Raef Bassily, Vitaly Feldman, Crist\u00f3bal Guzm\u00e1n, and Kunal Talwar. Stability of stochastic gradient descent on nonsmooth convex losses. arXiv preprint arXiv:2006.06914, 2020.\n- [BFTT19] Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Thakurta. Private stochastic convex optimization with optimal rates. In Advances in Neural Information Processing Systems, pages 11279\u201311288, 2019.\n- [BGM21] Raef Bassily, Crist\u00f3bal Guzm\u00e1n, and Michael Menart. Differentially private stochastic optimization: New results in convex and non-convex settings. Advances in Neural Information Processing Systems, 34:9317\u20139329, 2021.\n- [BST14] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In Proc. of the 2014 IEEE 55th Annual Symp. on Foundations of Computer Science (FOCS), pages 464\u2013473, 2014.\n- [BU17] Mitali Bafna and Jonathan Ullman. The price of selection in differential privacy. In Satyen Kale and Ohad Shamir, editors, Proceedings of the 2017 Conference on Learning Theory, volume 65 of Proceedings of Machine Learning Research, pages 151\u2013168. PMLR, 07\u201310 Jul 2017.\n- [CCSW22] Yongxin Chen, Sinho Chewi, Adil Salim, and Andre Wibisono. Improved analysis for a proximal algorithm for sampling. In Conference on Learning Theory, pages 2984\u20133014. PMLR, 2022.\n- [CEL+22] Sinho Chewi, Murat A Erdogdu, Mufan Li, Ruoqi Shen, and Shunshi Zhang. Analysis of langevin monte carlo from poincare to log-sobolev. In Conference on Learning Theory, pages 1\u20132. PMLR, 2022.\n- [CJJ+23] Yair Carmon, Arun Jambulapati, Yujia Jin, Yin Tat Lee, Daogao Liu, Aaron Sidford, and Kevin Tian. Resqueing parallel and private stochastic convex optimization. arXiv preprint arXiv:2301.00457, 2023."}]}, {"page": 14, "text": "   [CM08] Kamalika Chaudhuri and Claire Monteleoni.         Privacy-preserving logistic regression.\n            Advances in neural information processing systems, 21, 2008.\n  [CMS11] Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate. Differentially private\n            empirical risk minimization. Journal of Machine Learning Research, 12(Mar):1069\u2013\n            1109, 2011.\n    [CO19] Ashok Cutkosky and Francesco Orabona.          Momentum-based variance reduction in\n            non-convex sgd. Advances in neural information processing systems, 32, 2019.\n  [CYS21] Rishav Chourasia, Jiayuan Ye, and Reza Shokri.          Differential privacy dynamics of\n            langevin diffusion and noisy gradient descent.    In Advances in Neural Information\n            Processing Systems, 2021.\n[DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise\n            to sensitivity in private data analysis.   In Proc. of the Third Conf. on Theory of\n            Cryptography (TCC), pages 265\u2013284, 2006.\n  [DR+14] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy.\n            Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014.\n  [FKT20] Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimiza-\n            tion: Optimal rates in linear time. In Proc. of the Fifty-Second ACM Symp. on Theory\n            of Computing (STOC\u201920), 2020.\n [FLLZ18] Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. Spider: Near-optimal\n            non-convex optimization via stochastic path-integrated differential estimator.      Ad-\n            vances in Neural Information Processing Systems, 31, 2018.\n [GHJY15] Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points\u2014online\n            stochastic gradient for tensor decomposition. In Conference on learning theory, pages\n            797\u2013842. PMLR, 2015.\n  [GLL22] Sivakanth Gopi, Yin Tat Lee, and Daogao Liu. Private convex optimization via ex-\n            ponential mechanism. In Conference on Learning Theory, pages 1948\u20131989. PMLR,\n            2022.\n [GLL+23] Sivakanth Gopi, Yin Tat Lee, Daogao Liu, Ruoqi Shen, and Kevin Tian.              Private\n            convex optimization in general norms. In Proceedings of the 2023 Annual ACM-SIAM\n            Symposium on Discrete Algorithms (SODA), pages 5068\u20135089. SIAM, 2023.\n  [GTU22] Arun Ganesh, Abhradeep Thakurta, and Jalaj Upadhyay.             Langevin diffusion: An\n            almost universal algorithm for private euclidean (convex) optimization. arXiv preprint\n            arXiv:2204.01585, 2022.\n   [GW23] Changyu Gao and Stephen J Wright. Differentially private optimization for smooth\n            nonconvex erm. arXiv preprint arXiv:2302.04972, 2023.\n  [INS+19] Roger Iyengar, Joseph P Near, Dawn Song, Om Thakkar, Abhradeep Thakurta, and\n            Lun Wang. Towards practical differentially private convex optimization. In 2019 IEEE\n            Symposium on Security and Privacy (SP), 2019.\n [JGN+17] Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M Kakade, and Michael I Jordan. How\n            to escape saddle points efficiently. In International conference on machine learning,\n            pages 1724\u20131732. PMLR, 2017.\n                                                14", "md": "# References\n\n## List of References\n\n|Reference|Authors|Title|Publication|\n|---|---|---|---|\n|CM08|Kamalika Chaudhuri and Claire Monteleoni|Privacy-preserving logistic regression|Advances in neural information processing systems, 21, 2008|\n|CMS11|Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate|Differentially private empirical risk minimization|Journal of Machine Learning Research, 12(Mar):1069\u20131109, 2011|\n|CO19|Ashok Cutkosky and Francesco Orabona|Momentum-based variance reduction in non-convex sgd|Advances in neural information processing systems, 32, 2019|\n|CYS21|Rishav Chourasia, Jiayuan Ye, and Reza Shokri|Differential privacy dynamics of langevin diffusion and noisy gradient descent|In Advances in Neural Information Processing Systems, 2021|\n|DMNS06|Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith|Calibrating noise to sensitivity in private data analysis|In Proc. of the Third Conf. on Theory of Cryptography (TCC), pages 265\u2013284, 2006|\n|DR+14|Cynthia Dwork, Aaron Roth, et al.|The algorithmic foundations of differential privacy|Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014|\n|FKT20|Vitaly Feldman, Tomer Koren, and Kunal Talwar|Private stochastic convex optimization: Optimal rates in linear time|In Proc. of the Fifty-Second ACM Symp. on Theory of Computing (STOC\u201920), 2020|\n|FLLZ18|Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang|Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator|Advances in Neural Information Processing Systems, 31, 2018|\n|GHJY15|Rong Ge, Furong Huang, Chi Jin, and Yang Yuan|Escaping from saddle points\u2014online stochastic gradient for tensor decomposition|In Conference on learning theory, pages 797\u2013842. PMLR, 2015|\n|GLL22|Sivakanth Gopi, Yin Tat Lee, and Daogao Liu|Private convex optimization via exponential mechanism|In Conference on Learning Theory, pages 1948\u20131989. PMLR, 2022|\n|GLL+23|Sivakanth Gopi, Yin Tat Lee, Daogao Liu, Ruoqi Shen, and Kevin Tian|Private convex optimization in general norms|In Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 5068\u20135089. SIAM, 2023|\n|GTU22|Arun Ganesh, Abhradeep Thakurta, and Jalaj Upadhyay|Langevin diffusion: An almost universal algorithm for private euclidean (convex) optimization|arXiv preprint arXiv:2204.01585, 2022|\n|GW23|Changyu Gao and Stephen J Wright|Differentially private optimization for smooth nonconvex erm|arXiv preprint arXiv:2302.04972, 2023|\n|INS+19|Roger Iyengar, Joseph P Near, Dawn Song, Om Thakkar, Abhradeep Thakurta, and Lun Wang|Towards practical differentially private convex optimization|In 2019 IEEE Symposium on Security and Privacy (SP), 2019|\n|JGN+17|Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M Kakade, and Michael I Jordan|How to escape saddle points efficiently|In International conference on machine learning, pages 1724\u20131732. PMLR, 2017|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 2, "value": "List of References", "md": "## List of References"}, {"type": "table", "rows": [["Reference", "Authors", "Title", "Publication"], ["CM08", "Kamalika Chaudhuri and Claire Monteleoni", "Privacy-preserving logistic regression", "Advances in neural information processing systems, 21, 2008"], ["CMS11", "Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate", "Differentially private empirical risk minimization", "Journal of Machine Learning Research, 12(Mar):1069\u20131109, 2011"], ["CO19", "Ashok Cutkosky and Francesco Orabona", "Momentum-based variance reduction in non-convex sgd", "Advances in neural information processing systems, 32, 2019"], ["CYS21", "Rishav Chourasia, Jiayuan Ye, and Reza Shokri", "Differential privacy dynamics of langevin diffusion and noisy gradient descent", "In Advances in Neural Information Processing Systems, 2021"], ["DMNS06", "Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith", "Calibrating noise to sensitivity in private data analysis", "In Proc. of the Third Conf. on Theory of Cryptography (TCC), pages 265\u2013284, 2006"], ["DR+14", "Cynthia Dwork, Aaron Roth, et al.", "The algorithmic foundations of differential privacy", "Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014"], ["FKT20", "Vitaly Feldman, Tomer Koren, and Kunal Talwar", "Private stochastic convex optimization: Optimal rates in linear time", "In Proc. of the Fifty-Second ACM Symp. on Theory of Computing (STOC\u201920), 2020"], ["FLLZ18", "Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang", "Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator", "Advances in Neural Information Processing Systems, 31, 2018"], ["GHJY15", "Rong Ge, Furong Huang, Chi Jin, and Yang Yuan", "Escaping from saddle points\u2014online stochastic gradient for tensor decomposition", "In Conference on learning theory, pages 797\u2013842. PMLR, 2015"], ["GLL22", "Sivakanth Gopi, Yin Tat Lee, and Daogao Liu", "Private convex optimization via exponential mechanism", "In Conference on Learning Theory, pages 1948\u20131989. PMLR, 2022"], ["GLL+23", "Sivakanth Gopi, Yin Tat Lee, Daogao Liu, Ruoqi Shen, and Kevin Tian", "Private convex optimization in general norms", "In Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 5068\u20135089. SIAM, 2023"], ["GTU22", "Arun Ganesh, Abhradeep Thakurta, and Jalaj Upadhyay", "Langevin diffusion: An almost universal algorithm for private euclidean (convex) optimization", "arXiv preprint arXiv:2204.01585, 2022"], ["GW23", "Changyu Gao and Stephen J Wright", "Differentially private optimization for smooth nonconvex erm", "arXiv preprint arXiv:2302.04972, 2023"], ["INS+19", "Roger Iyengar, Joseph P Near, Dawn Song, Om Thakkar, Abhradeep Thakurta, and Lun Wang", "Towards practical differentially private convex optimization", "In 2019 IEEE Symposium on Security and Privacy (SP), 2019"], ["JGN+17", "Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M Kakade, and Michael I Jordan", "How to escape saddle points efficiently", "In International conference on machine learning, pages 1724\u20131732. PMLR, 2017"]], "md": "|Reference|Authors|Title|Publication|\n|---|---|---|---|\n|CM08|Kamalika Chaudhuri and Claire Monteleoni|Privacy-preserving logistic regression|Advances in neural information processing systems, 21, 2008|\n|CMS11|Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate|Differentially private empirical risk minimization|Journal of Machine Learning Research, 12(Mar):1069\u20131109, 2011|\n|CO19|Ashok Cutkosky and Francesco Orabona|Momentum-based variance reduction in non-convex sgd|Advances in neural information processing systems, 32, 2019|\n|CYS21|Rishav Chourasia, Jiayuan Ye, and Reza Shokri|Differential privacy dynamics of langevin diffusion and noisy gradient descent|In Advances in Neural Information Processing Systems, 2021|\n|DMNS06|Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith|Calibrating noise to sensitivity in private data analysis|In Proc. of the Third Conf. on Theory of Cryptography (TCC), pages 265\u2013284, 2006|\n|DR+14|Cynthia Dwork, Aaron Roth, et al.|The algorithmic foundations of differential privacy|Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014|\n|FKT20|Vitaly Feldman, Tomer Koren, and Kunal Talwar|Private stochastic convex optimization: Optimal rates in linear time|In Proc. of the Fifty-Second ACM Symp. on Theory of Computing (STOC\u201920), 2020|\n|FLLZ18|Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang|Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator|Advances in Neural Information Processing Systems, 31, 2018|\n|GHJY15|Rong Ge, Furong Huang, Chi Jin, and Yang Yuan|Escaping from saddle points\u2014online stochastic gradient for tensor decomposition|In Conference on learning theory, pages 797\u2013842. PMLR, 2015|\n|GLL22|Sivakanth Gopi, Yin Tat Lee, and Daogao Liu|Private convex optimization via exponential mechanism|In Conference on Learning Theory, pages 1948\u20131989. PMLR, 2022|\n|GLL+23|Sivakanth Gopi, Yin Tat Lee, Daogao Liu, Ruoqi Shen, and Kevin Tian|Private convex optimization in general norms|In Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 5068\u20135089. SIAM, 2023|\n|GTU22|Arun Ganesh, Abhradeep Thakurta, and Jalaj Upadhyay|Langevin diffusion: An almost universal algorithm for private euclidean (convex) optimization|arXiv preprint arXiv:2204.01585, 2022|\n|GW23|Changyu Gao and Stephen J Wright|Differentially private optimization for smooth nonconvex erm|arXiv preprint arXiv:2302.04972, 2023|\n|INS+19|Roger Iyengar, Joseph P Near, Dawn Song, Om Thakkar, Abhradeep Thakurta, and Lun Wang|Towards practical differentially private convex optimization|In 2019 IEEE Symposium on Security and Privacy (SP), 2019|\n|JGN+17|Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M Kakade, and Michael I Jordan|How to escape saddle points efficiently|In International conference on machine learning, pages 1724\u20131732. PMLR, 2017|", "isPerfectTable": true, "csv": "\"Reference\",\"Authors\",\"Title\",\"Publication\"\n\"CM08\",\"Kamalika Chaudhuri and Claire Monteleoni\",\"Privacy-preserving logistic regression\",\"Advances in neural information processing systems, 21, 2008\"\n\"CMS11\",\"Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate\",\"Differentially private empirical risk minimization\",\"Journal of Machine Learning Research, 12(Mar):1069\u20131109, 2011\"\n\"CO19\",\"Ashok Cutkosky and Francesco Orabona\",\"Momentum-based variance reduction in non-convex sgd\",\"Advances in neural information processing systems, 32, 2019\"\n\"CYS21\",\"Rishav Chourasia, Jiayuan Ye, and Reza Shokri\",\"Differential privacy dynamics of langevin diffusion and noisy gradient descent\",\"In Advances in Neural Information Processing Systems, 2021\"\n\"DMNS06\",\"Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith\",\"Calibrating noise to sensitivity in private data analysis\",\"In Proc. of the Third Conf. on Theory of Cryptography (TCC), pages 265\u2013284, 2006\"\n\"DR+14\",\"Cynthia Dwork, Aaron Roth, et al.\",\"The algorithmic foundations of differential privacy\",\"Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014\"\n\"FKT20\",\"Vitaly Feldman, Tomer Koren, and Kunal Talwar\",\"Private stochastic convex optimization: Optimal rates in linear time\",\"In Proc. of the Fifty-Second ACM Symp. on Theory of Computing (STOC\u201920), 2020\"\n\"FLLZ18\",\"Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang\",\"Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator\",\"Advances in Neural Information Processing Systems, 31, 2018\"\n\"GHJY15\",\"Rong Ge, Furong Huang, Chi Jin, and Yang Yuan\",\"Escaping from saddle points\u2014online stochastic gradient for tensor decomposition\",\"In Conference on learning theory, pages 797\u2013842. PMLR, 2015\"\n\"GLL22\",\"Sivakanth Gopi, Yin Tat Lee, and Daogao Liu\",\"Private convex optimization via exponential mechanism\",\"In Conference on Learning Theory, pages 1948\u20131989. PMLR, 2022\"\n\"GLL+23\",\"Sivakanth Gopi, Yin Tat Lee, Daogao Liu, Ruoqi Shen, and Kevin Tian\",\"Private convex optimization in general norms\",\"In Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 5068\u20135089. SIAM, 2023\"\n\"GTU22\",\"Arun Ganesh, Abhradeep Thakurta, and Jalaj Upadhyay\",\"Langevin diffusion: An almost universal algorithm for private euclidean (convex) optimization\",\"arXiv preprint arXiv:2204.01585, 2022\"\n\"GW23\",\"Changyu Gao and Stephen J Wright\",\"Differentially private optimization for smooth nonconvex erm\",\"arXiv preprint arXiv:2302.04972, 2023\"\n\"INS+19\",\"Roger Iyengar, Joseph P Near, Dawn Song, Om Thakkar, Abhradeep Thakurta, and Lun Wang\",\"Towards practical differentially private convex optimization\",\"In 2019 IEEE Symposium on Security and Privacy (SP), 2019\"\n\"JGN+17\",\"Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M Kakade, and Michael I Jordan\",\"How to escape saddle points efficiently\",\"In International conference on machine learning, pages 1724\u20131732. PMLR, 2017\""}]}, {"page": 15, "text": " [JNG+19] Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. A\n            short note on concentration inequalities for random vectors with subgaussian norm.\n            arXiv preprint arXiv:1902.03736, 2019.\n  [KLL21] Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. Private non-smooth erm and sco\n            in subquadratic steps. Advances in Neural Information Processing Systems, 34, 2021.\n  [KLZ22] Gautam Kamath, Xingtu Liu, and Huanyu Zhang. Improved rates for differentially\n            private stochastic convex optimization with heavy-tailed data. In International Con-\n            ference on Machine Learning, pages 10633\u201310660. PMLR, 2022.\n  [KOV15] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for\n            differential privacy. In Francis Bach and David Blei, editors, Proceedings of the 32nd\n            International Conference on Machine Learning, volume 37 of Proceedings of Machine\n            Learning Research, pages 1376\u20131385, Lille, France, 07\u201309 Jul 2015. PMLR.\n  [KST12] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk\n            minimization and high-dimensional regression.    In Conference on Learning Theory,\n            pages 25\u20131, 2012.\n    [LC22] Jiaming Liang and Yongxin Chen. A proximal algorithm for sampling from non-smooth\n            potentials. In 2022 Winter Simulation Conference (WSC), pages 3229\u20133240. IEEE,\n            2022.\n [LRY+20] Songtao Lu, Meisam Razaviyayn, Bo Yang, Kejun Huang, and Mingyi Hong. Finding\n            second-order stationary points efficiently in smooth nonconvex linearly constrained\n            optimization problems. Advances in Neural Information Processing Systems, 33:2811\u2013\n            2822, 2020.\n  [LST21] Yin Tat Lee, Ruoqi Shen, and Kevin Tian.          Structured logconcave sampling with\n            a restricted gaussian oracle.  In Conference on Learning Theory, pages 2993\u20133050.\n            PMLR, 2021.\n[MASN16] Kentaro Minami, HItomi Arai, Issei Sato, and Hiroshi Nakagawa. Differential privacy\n            without sensitivity. Advances in Neural Information Processing Systems, 29, 2016.\n   [MT07] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In 48th\n            Annual IEEE Symposium on Foundations of Computer Science (FOCS\u201907), pages 94\u2013\n            103. IEEE, 2007.\n   [OV00] Felix Otto and C\u00b4  edric Villani. Generalization of an inequality by talagrand and links\n            with the logarithmic sobolev inequality. Journal of Functional Analysis, 173(2):361\u2013\n            400, 2000.\n   [SCS13] Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. Stochastic gradient descent\n            with differentially private updates. In 2013 IEEE Global Conference on Signal and\n            Information Processing, pages 245\u2013248. IEEE, 2013.\n [SSTT21] Shuang Song, Thomas Steinke, Om Thakkar, and Abhradeep Thakurta. Evading the\n            curse of dimensionality in unconstrained private glms. In International Conference on\n            Artifi\n                 cial Intelligence and Statistics, pages 2638\u20132646. PMLR, 2021.\n   [TC22] Hoang Tran and Ashok Cutkosky. Momentum aggregation for private non-convex erm.\n            In Advances in Neural Information Processing Systems, 2022.\n                                               15", "md": "- [JNG+19] Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. A short note on concentration inequalities for random vectors with subgaussian norm. arXiv preprint arXiv:1902.03736, 2019.\n- [KLL21] Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. Private non-smooth erm and sco in subquadratic steps. Advances in Neural Information Processing Systems, 34, 2021.\n- [KLZ22] Gautam Kamath, Xingtu Liu, and Huanyu Zhang. Improved rates for differentially private stochastic convex optimization with heavy-tailed data. In International Conference on Machine Learning, pages 10633\u201310660. PMLR, 2022.\n- [KOV15] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy. In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 1376\u20131385, Lille, France, 07\u201309 Jul 2015. PMLR.\n- [KST12] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In Conference on Learning Theory, pages 25\u20131, 2012.\n- [LC22] Jiaming Liang and Yongxin Chen. A proximal algorithm for sampling from non-smooth potentials. In 2022 Winter Simulation Conference (WSC), pages 3229\u20133240. IEEE, 2022.\n- [LRY+20] Songtao Lu, Meisam Razaviyayn, Bo Yang, Kejun Huang, and Mingyi Hong. Finding second-order stationary points efficiently in smooth nonconvex linearly constrained optimization problems. Advances in Neural Information Processing Systems, 33:2811\u20132822, 2020.\n- [LST21] Yin Tat Lee, Ruoqi Shen, and Kevin Tian. Structured logconcave sampling with a restricted gaussian oracle. In Conference on Learning Theory, pages 2993\u20133050. PMLR, 2021.\n- [MASN16] Kentaro Minami, HItomi Arai, Issei Sato, and Hiroshi Nakagawa. Differential privacy without sensitivity. Advances in Neural Information Processing Systems, 29, 2016.\n- [MT07] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS\u201907), pages 94\u2013103. IEEE, 2007.\n- [OV00] Felix Otto and C\u00b4 edric Villani. Generalization of an inequality by talagrand and links with the logarithmic sobolev inequality. Journal of Functional Analysis, 173(2):361\u2013400, 2000.\n- [SCS13] Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. Stochastic gradient descent with differentially private updates. In 2013 IEEE Global Conference on Signal and Information Processing, pages 245\u2013248. IEEE, 2013.\n- [SSTT21] Shuang Song, Thomas Steinke, Om Thakkar, and Abhradeep Thakurta. Evading the curse of dimensionality in unconstrained private glms. In International Conference on Artificial Intelligence and Statistics, pages 2638\u20132646. PMLR, 2021.\n- [TC22] Hoang Tran and Ashok Cutkosky. Momentum aggregation for private non-convex erm. In Advances in Neural Information Processing Systems, 2022.", "images": [], "items": [{"type": "text", "value": "- [JNG+19] Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. A short note on concentration inequalities for random vectors with subgaussian norm. arXiv preprint arXiv:1902.03736, 2019.\n- [KLL21] Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. Private non-smooth erm and sco in subquadratic steps. Advances in Neural Information Processing Systems, 34, 2021.\n- [KLZ22] Gautam Kamath, Xingtu Liu, and Huanyu Zhang. Improved rates for differentially private stochastic convex optimization with heavy-tailed data. In International Conference on Machine Learning, pages 10633\u201310660. PMLR, 2022.\n- [KOV15] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy. In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 1376\u20131385, Lille, France, 07\u201309 Jul 2015. PMLR.\n- [KST12] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In Conference on Learning Theory, pages 25\u20131, 2012.\n- [LC22] Jiaming Liang and Yongxin Chen. A proximal algorithm for sampling from non-smooth potentials. In 2022 Winter Simulation Conference (WSC), pages 3229\u20133240. IEEE, 2022.\n- [LRY+20] Songtao Lu, Meisam Razaviyayn, Bo Yang, Kejun Huang, and Mingyi Hong. Finding second-order stationary points efficiently in smooth nonconvex linearly constrained optimization problems. Advances in Neural Information Processing Systems, 33:2811\u20132822, 2020.\n- [LST21] Yin Tat Lee, Ruoqi Shen, and Kevin Tian. Structured logconcave sampling with a restricted gaussian oracle. In Conference on Learning Theory, pages 2993\u20133050. PMLR, 2021.\n- [MASN16] Kentaro Minami, HItomi Arai, Issei Sato, and Hiroshi Nakagawa. Differential privacy without sensitivity. Advances in Neural Information Processing Systems, 29, 2016.\n- [MT07] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS\u201907), pages 94\u2013103. IEEE, 2007.\n- [OV00] Felix Otto and C\u00b4 edric Villani. Generalization of an inequality by talagrand and links with the logarithmic sobolev inequality. Journal of Functional Analysis, 173(2):361\u2013400, 2000.\n- [SCS13] Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. Stochastic gradient descent with differentially private updates. In 2013 IEEE Global Conference on Signal and Information Processing, pages 245\u2013248. IEEE, 2013.\n- [SSTT21] Shuang Song, Thomas Steinke, Om Thakkar, and Abhradeep Thakurta. Evading the curse of dimensionality in unconstrained private glms. In International Conference on Artificial Intelligence and Statistics, pages 2638\u20132646. PMLR, 2021.\n- [TC22] Hoang Tran and Ashok Cutkosky. Momentum aggregation for private non-convex erm. In Advances in Neural Information Processing Systems, 2022.", "md": "- [JNG+19] Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. A short note on concentration inequalities for random vectors with subgaussian norm. arXiv preprint arXiv:1902.03736, 2019.\n- [KLL21] Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. Private non-smooth erm and sco in subquadratic steps. Advances in Neural Information Processing Systems, 34, 2021.\n- [KLZ22] Gautam Kamath, Xingtu Liu, and Huanyu Zhang. Improved rates for differentially private stochastic convex optimization with heavy-tailed data. In International Conference on Machine Learning, pages 10633\u201310660. PMLR, 2022.\n- [KOV15] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy. In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 1376\u20131385, Lille, France, 07\u201309 Jul 2015. PMLR.\n- [KST12] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In Conference on Learning Theory, pages 25\u20131, 2012.\n- [LC22] Jiaming Liang and Yongxin Chen. A proximal algorithm for sampling from non-smooth potentials. In 2022 Winter Simulation Conference (WSC), pages 3229\u20133240. IEEE, 2022.\n- [LRY+20] Songtao Lu, Meisam Razaviyayn, Bo Yang, Kejun Huang, and Mingyi Hong. Finding second-order stationary points efficiently in smooth nonconvex linearly constrained optimization problems. Advances in Neural Information Processing Systems, 33:2811\u20132822, 2020.\n- [LST21] Yin Tat Lee, Ruoqi Shen, and Kevin Tian. Structured logconcave sampling with a restricted gaussian oracle. In Conference on Learning Theory, pages 2993\u20133050. PMLR, 2021.\n- [MASN16] Kentaro Minami, HItomi Arai, Issei Sato, and Hiroshi Nakagawa. Differential privacy without sensitivity. Advances in Neural Information Processing Systems, 29, 2016.\n- [MT07] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS\u201907), pages 94\u2013103. IEEE, 2007.\n- [OV00] Felix Otto and C\u00b4 edric Villani. Generalization of an inequality by talagrand and links with the logarithmic sobolev inequality. Journal of Functional Analysis, 173(2):361\u2013400, 2000.\n- [SCS13] Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. Stochastic gradient descent with differentially private updates. In 2013 IEEE Global Conference on Signal and Information Processing, pages 245\u2013248. IEEE, 2013.\n- [SSTT21] Shuang Song, Thomas Steinke, Om Thakkar, and Abhradeep Thakurta. Evading the curse of dimensionality in unconstrained private glms. In International Conference on Artificial Intelligence and Statistics, pages 2638\u20132646. PMLR, 2021.\n- [TC22] Hoang Tran and Ashok Cutkosky. Momentum aggregation for private non-convex erm. In Advances in Neural Information Processing Systems, 2022."}]}, {"page": 16, "text": "[TGTZ15] Kunal Talwar, Abhradeep Guha Thakurta, and Li Zhang.                           Nearly optimal private\n              lasso. Advances in Neural Information Processing Systems, 28, 2015.\n    [Tro15] Joel A Tropp. An introduction to matrix concentration inequalities. Foundations and\n              Trends\u00ae in Machine Learning, 8(1-2):1\u2013230, 2015.\n   [WB23] Yongqiang Wang and Tamer Ba\u00b8              sar. Decentralized nonconvex optimization with guar-\n              anteed privacy and accuracy. Automatica, 150:110858, 2023.\n [WCX19] Di Wang, Changyou Chen, and Jinhui Xu. Differentially private empirical risk min-\n              imization with non-convex loss functions. In International Conference on Machine\n              Learning, pages 6526\u20136535. PMLR, 2019.\n[WJEG19] Lingxiao Wang, Bargav Jayaraman, David Evans, and Quanquan Gu. Efficient privacy-\n              preserving stochastic nonconvex optimization. arXiv preprint arXiv:1910.13659, 2019.\n[WJZ+19] Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, and Vahid Tarokh. Spiderboost and\n              momentum: Faster variance reduction algorithms. Advances in Neural Information\n              Processing Systems, 32, 2019.\n   [WX19] Di Wang and Jinhui Xu. Differentially private empirical risk minimization with smooth\n              non-convex loss functions: A non-stationary view. In Proceedings of the AAAI Con-\n              ference on Artifi  cial Intelligence, volume 33, pages 1182\u20131189, 2019.\n   [WX20] Di Wang and Jinhui Xu. Escaping saddle points of empirical risk privately and scalably\n              via dp-trust region method. In Joint European Conference on Machine Learning and\n              Knowledge Discovery in Databases, pages 90\u2013106. Springer, 2020.\n [WYX17] Di Wang, Minwei Ye, and Jinhui Xu. Differentially private empirical risk minimiza-\n              tion revisited: Faster and more general. Advances in Neural Information Processing\n              Systems, 30, 2017.\n  [XJY18] Yi Xu, Rong Jin, and Tianbao Yang. First-order stochastic algorithms for escaping\n              from saddle points in almost linear time. Advances in neural information processing\n              systems, 31, 2018.\n [YZCL22] Xiaodong Yang, Huishuai Zhang, Wei Chen, and Tie-Yan Liu. Normalized/clipped sgd\n              with perturbation for differentially private non-convex optimization. arXiv preprint\n              arXiv:2206.13033, 2022.\n [ZCH+20] Yingxue Zhou, Xiangyi Chen, Mingyi Hong, Zhiwei Steven Wu, and Arindam Baner-\n              jee.  Private stochastic non-convex optimization: Adaptive algorithms and tighter\n              generalization bounds. arXiv preprint arXiv:2006.13501, 2020.\n[ZMLX21] Qiuchen Zhang, Jing Ma, Jian Lou, and Li Xiong.                       Private stochastic non-convex\n              optimization with improved utility rates. In Proceedings of the Thirtieth International\n              Joint Conference on Artifi     cial Intelligence, 2021.\n                                                        16", "md": "# References\n\n## List of References\n\n- [TGTZ15] Kunal Talwar, Abhradeep Guha Thakurta, and Li Zhang. Nearly optimal private lasso. Advances in Neural Information Processing Systems, 28, 2015.\n- [Tro15] Joel A Tropp. An introduction to matrix concentration inequalities. Foundations and Trends\u00ae in Machine Learning, 8(1-2):1\u2013230, 2015.\n- [WB23] Yongqiang Wang and Tamer Ba\u00b8 sar. Decentralized nonconvex optimization with guaranteed privacy and accuracy. Automatica, 150:110858, 2023.\n- [WCX19] Di Wang, Changyou Chen, and Jinhui Xu. Differentially private empirical risk minimization with non-convex loss functions. In International Conference on Machine Learning, pages 6526\u20136535. PMLR, 2019.\n- [WJEG19] Lingxiao Wang, Bargav Jayaraman, David Evans, and Quanquan Gu. Efficient privacy-preserving stochastic nonconvex optimization. arXiv preprint arXiv:1910.13659, 2019.\n- [WJZ+19] Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, and Vahid Tarokh. Spiderboost and momentum: Faster variance reduction algorithms. Advances in Neural Information Processing Systems, 32, 2019.\n- [WX19] Di Wang and Jinhui Xu. Differentially private empirical risk minimization with smooth non-convex loss functions: A non-stationary view. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 1182\u20131189, 2019.\n- [WX20] Di Wang and Jinhui Xu. Escaping saddle points of empirical risk privately and scalably via dp-trust region method. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 90\u2013106. Springer, 2020.\n- [WYX17] Di Wang, Minwei Ye, and Jinhui Xu. Differentially private empirical risk minimization revisited: Faster and more general. Advances in Neural Information Processing Systems, 30, 2017.\n- [XJY18] Yi Xu, Rong Jin, and Tianbao Yang. First-order stochastic algorithms for escaping from saddle points in almost linear time. Advances in neural information processing systems, 31, 2018.\n- [YZCL22] Xiaodong Yang, Huishuai Zhang, Wei Chen, and Tie-Yan Liu. Normalized/clipped sgd with perturbation for differentially private non-convex optimization. arXiv preprint arXiv:2206.13033, 2022.\n- [ZCH+20] Yingxue Zhou, Xiangyi Chen, Mingyi Hong, Zhiwei Steven Wu, and Arindam Banerjee. Private stochastic non-convex optimization: Adaptive algorithms and tighter generalization bounds. arXiv preprint arXiv:2006.13501, 2020.\n- [ZMLX21] Qiuchen Zhang, Jing Ma, Jian Lou, and Li Xiong. Private stochastic non-convex optimization with improved utility rates. In Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, 2021.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 2, "value": "List of References", "md": "## List of References"}, {"type": "text", "value": "- [TGTZ15] Kunal Talwar, Abhradeep Guha Thakurta, and Li Zhang. Nearly optimal private lasso. Advances in Neural Information Processing Systems, 28, 2015.\n- [Tro15] Joel A Tropp. An introduction to matrix concentration inequalities. Foundations and Trends\u00ae in Machine Learning, 8(1-2):1\u2013230, 2015.\n- [WB23] Yongqiang Wang and Tamer Ba\u00b8 sar. Decentralized nonconvex optimization with guaranteed privacy and accuracy. Automatica, 150:110858, 2023.\n- [WCX19] Di Wang, Changyou Chen, and Jinhui Xu. Differentially private empirical risk minimization with non-convex loss functions. In International Conference on Machine Learning, pages 6526\u20136535. PMLR, 2019.\n- [WJEG19] Lingxiao Wang, Bargav Jayaraman, David Evans, and Quanquan Gu. Efficient privacy-preserving stochastic nonconvex optimization. arXiv preprint arXiv:1910.13659, 2019.\n- [WJZ+19] Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, and Vahid Tarokh. Spiderboost and momentum: Faster variance reduction algorithms. Advances in Neural Information Processing Systems, 32, 2019.\n- [WX19] Di Wang and Jinhui Xu. Differentially private empirical risk minimization with smooth non-convex loss functions: A non-stationary view. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 1182\u20131189, 2019.\n- [WX20] Di Wang and Jinhui Xu. Escaping saddle points of empirical risk privately and scalably via dp-trust region method. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 90\u2013106. Springer, 2020.\n- [WYX17] Di Wang, Minwei Ye, and Jinhui Xu. Differentially private empirical risk minimization revisited: Faster and more general. Advances in Neural Information Processing Systems, 30, 2017.\n- [XJY18] Yi Xu, Rong Jin, and Tianbao Yang. First-order stochastic algorithms for escaping from saddle points in almost linear time. Advances in neural information processing systems, 31, 2018.\n- [YZCL22] Xiaodong Yang, Huishuai Zhang, Wei Chen, and Tie-Yan Liu. Normalized/clipped sgd with perturbation for differentially private non-convex optimization. arXiv preprint arXiv:2206.13033, 2022.\n- [ZCH+20] Yingxue Zhou, Xiangyi Chen, Mingyi Hong, Zhiwei Steven Wu, and Arindam Banerjee. Private stochastic non-convex optimization: Adaptive algorithms and tighter generalization bounds. arXiv preprint arXiv:2006.13501, 2020.\n- [ZMLX21] Qiuchen Zhang, Jing Ma, Jian Lou, and Li Xiong. Private stochastic non-convex optimization with improved utility rates. In Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, 2021.", "md": "- [TGTZ15] Kunal Talwar, Abhradeep Guha Thakurta, and Li Zhang. Nearly optimal private lasso. Advances in Neural Information Processing Systems, 28, 2015.\n- [Tro15] Joel A Tropp. An introduction to matrix concentration inequalities. Foundations and Trends\u00ae in Machine Learning, 8(1-2):1\u2013230, 2015.\n- [WB23] Yongqiang Wang and Tamer Ba\u00b8 sar. Decentralized nonconvex optimization with guaranteed privacy and accuracy. Automatica, 150:110858, 2023.\n- [WCX19] Di Wang, Changyou Chen, and Jinhui Xu. Differentially private empirical risk minimization with non-convex loss functions. In International Conference on Machine Learning, pages 6526\u20136535. PMLR, 2019.\n- [WJEG19] Lingxiao Wang, Bargav Jayaraman, David Evans, and Quanquan Gu. Efficient privacy-preserving stochastic nonconvex optimization. arXiv preprint arXiv:1910.13659, 2019.\n- [WJZ+19] Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, and Vahid Tarokh. Spiderboost and momentum: Faster variance reduction algorithms. Advances in Neural Information Processing Systems, 32, 2019.\n- [WX19] Di Wang and Jinhui Xu. Differentially private empirical risk minimization with smooth non-convex loss functions: A non-stationary view. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 1182\u20131189, 2019.\n- [WX20] Di Wang and Jinhui Xu. Escaping saddle points of empirical risk privately and scalably via dp-trust region method. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 90\u2013106. Springer, 2020.\n- [WYX17] Di Wang, Minwei Ye, and Jinhui Xu. Differentially private empirical risk minimization revisited: Faster and more general. Advances in Neural Information Processing Systems, 30, 2017.\n- [XJY18] Yi Xu, Rong Jin, and Tianbao Yang. First-order stochastic algorithms for escaping from saddle points in almost linear time. Advances in neural information processing systems, 31, 2018.\n- [YZCL22] Xiaodong Yang, Huishuai Zhang, Wei Chen, and Tie-Yan Liu. Normalized/clipped sgd with perturbation for differentially private non-convex optimization. arXiv preprint arXiv:2206.13033, 2022.\n- [ZCH+20] Yingxue Zhou, Xiangyi Chen, Mingyi Hong, Zhiwei Steven Wu, and Arindam Banerjee. Private stochastic non-convex optimization: Adaptive algorithms and tighter generalization bounds. arXiv preprint arXiv:2006.13501, 2020.\n- [ZMLX21] Qiuchen Zhang, Jing Ma, Jian Lou, and Li Xiong. Private stochastic non-convex optimization with improved utility rates. In Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, 2021."}]}, {"page": 17, "text": "A         Omitted Proof of Section 3\nA.1         Proof of Lemma 3.3\nLemma 3.3. For any 0 \u2264                      t \u2264   T and letting \u03c4t \u2264            t be the largest integer such that drift\u03c4t is set to\nbe 0, with probability at least 1 \u2212                  \u03c9/T    , for some universal constant C > 0, we have\n                                                                    t\n                          \u2225\u2207t \u2212     \u2207F(xt)\u22252 \u2264            \u03b622 \u00b7 i=\u03c4t+1    \u2225xi \u2212    xi\u22121\u22252 + 4\u03b62      1   \u00b7 C \u00b7 log(T     d/\u03c9).                         (1)\nHence with probability at least 1 \u2212                      \u03c9, we know for each t \u2264                  T , \u2225\u2207t \u2212       \u2207F(xt)\u22252 \u2264           \u03b32/16, where\n\u03b32 := 16C(\u03b62       2\u03ba + 4\u03b62    1) \u00b7 log(T    d/\u03c9) and \u03ba is a parameter we can choose in the algorithm.\nProof. If drift\u03c4       t = 0 happens, we use the first kind oracle to query the gradient, and hence \u2207\u03c4t \u2212\n\u2207F(x\u03c4t) is zero-mean and nSG(2\u03b61).                              If t = \u03c4t, Equation (1) holds by the property of norm-\nsubGaussian.\n      For each \u03c4t + 1 \u2264            i \u2264   t, conditional on \u2207i\u22121, we know \u2206i \u2212                          (\u2207F(xi) \u2212        F(xi\u22121)) is zero-mean\nand nSG(\u03b62\u2225xi \u2212             xi\u22121\u2225). Note that                                    t\n                        \u2207t \u2212    \u2207F(xt) = \u2207\u03c4t \u2212             \u2207F(x\u03c4t) +         i=\u03c4t+1   [\u2206i \u2212    (\u2207F(xi) \u2212         \u2207F(xi\u22121))].\nEquation (1) follows from Lemma 2.4.\n      We know driftt\u22121 =  t               i=\u03c4t+1 \u2225xi \u2212       xi\u22121\u22252 \u2264       \u03ba almost surely by the design of the algorithm. By\nunion bound, we know with probability at least 1 \u2212                                 \u03c9, for each t \u2208         [T  ],\n                                   \u2225\u2207t \u2212      \u2207F(xt)\u22252 \u2264          C(\u03b62  2\u03ba + 4\u03b62   1) \u00b7 log(T     d/\u03c9) = \u03b32/16.\nA.2         Discussion of Lemma 3.4\nLemma 3.4 (Essentially from [WCX19]). Under Assumption 3.1, run SGD iterations xt+1 =\nxt \u2212     \u03b7\u2207t, with step size \u03b7 = 1/M. Suppose x0 is a stationary point satisfying \u2225\u2207F(x0)\u2225                                                          \u2264    \u03b1\nand smin(\u22072F(x0)) \u2264   \u03b32             \u2212\u221a\u03c1\u03b1, \u03b1 = \u03b3 log3(dBM/\u03c1\u03c9). If \u22070 = \u2207F(x0) + \u03b61 + \u03b62 where \u2225\u03b61\u2225                                                  \u2264   \u03b3,\n\u03b62 \u223c    N   (0,  d log(d/\u03c9)Id), and \u2225\u2207t\u2212\u2207F(xt)\u2225                    \u2264   \u03b3 for all t \u2208      [\u0393], with probability at least 1\u2212\u03c9\u00b7log(1/\u03c9),\none has\n                                               F(x\u0393) \u2212       F(x0) \u2264        \u2212\u2126             \u03b33/2            ,\n                  M log( dMB                                                       \u221a\u03c1 log3(dMB   \u03c1\u03b3\u03c9 )\n                           \u03c1\u03b3\u03c9 )\nwhere \u0393 =              \u221a  \u03c1\u03b3      .\n      We briefly recap the proof of Lemma 3.4 in [WCX19]. One observation between the decreased\nfunction value, and the distance solutions moved is stated below:\nLemma A.1 (Lemma 11, [WCX19]). For each t \u2208                                       [\u0393], we know\n                         \u2225xt+1 \u2212      x0\u22252 2 \u2264    8\u03b7(\u0393(F(x0) \u2212          F(x\u0393)) + 50\u03b72\u0393           i\u2208[\u0393]  \u2225\u2207i \u2212      \u2207F(xt)\u22252     2.\n                                                                            17", "md": "# Proof of Section 3\n\n## Proof of Lemma 3.3\n\nLemma 3.3. For any \\(0 \\leq t \\leq T\\) and letting \\(\\tau_t \\leq t\\) be the largest integer such that drift\\(\\tau_t\\) is set to be 0, with probability at least \\(1 - \\frac{\\omega}{T}\\), for some universal constant \\(C > 0\\), we have\n\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2^2 \\leq \\zeta_{22} \\cdot \\sum_{i=\\tau_t+1}^{t} \\|x_i - x_{i-1}\\|_2^2 + 4\\zeta_1^2 \\cdot C \\cdot \\log\\left(\\frac{Td}{\\omega}\\right). \\quad (1)\n$$\nHence with probability at least \\(1 - \\omega\\), we know for each \\(t \\leq T\\), \\(\\| \\nabla_t - \\nabla F(x_t) \\|_2 \\leq \\frac{\\gamma^2}{16}\\), where\n\n$$\n\\gamma^2 := 16C(\\zeta_2^2\\kappa + 4\\zeta_1^2) \\cdot \\log\\left(\\frac{Td}{\\omega}\\right)\n$$\nand \\(\\kappa\\) is a parameter we can choose in the algorithm.\n\nProof. If drift\\(\\tau_t = 0\\) happens, we use the first kind oracle to query the gradient, and hence \\(\\nabla_{\\tau_t} - \\nabla F(x_{\\tau_t})\\) is zero-mean and nSG(2\\(\\zeta_1\\)). If \\(t = \\tau_t\\), Equation (1) holds by the property of norm-subGaussian.\n\nFor each \\(\\tau_t + 1 \\leq i \\leq t\\), conditional on \\(\\nabla_{i-1}\\), we know \\(\\Delta_i - (\\nabla F(x_i) - \\nabla F(x_{i-1}))\\) is zero-mean and nSG(\\(\\zeta_2\\|x_i - x_{i-1}\\|\\)). Note that\n\n$$\n\\nabla_t - \\nabla F(x_t) = \\nabla_{\\tau_t} - \\nabla F(x_{\\tau_t}) + \\sum_{i=\\tau_t+1}^{t} [\\Delta_i - (\\nabla F(x_i) - \\nabla F(x_{i-1}))].\n$$\nEquation (1) follows from Lemma 2.4.\n\nWe know drift\\(t-1 = \\sum_{i=\\tau_t+1}^{t} \\|x_i - x_{i-1}\\|_2^2 \\leq \\kappa\\) almost surely by the design of the algorithm. By union bound, we know with probability at least \\(1 - \\omega\\), for each \\(t \\in [T]\\),\n\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2^2 \\leq C(\\zeta_2^2\\kappa + 4\\zeta_1^2) \\cdot \\log\\left(\\frac{Td}{\\omega}\\right) = \\frac{\\gamma^2}{16}.\n$$\n## Discussion of Lemma 3.4\n\nLemma 3.4 (Essentially from [WCX19]). Under Assumption 3.1, run SGD iterations \\(x_{t+1} = x_t - \\eta\\nabla_t\\), with step size \\(\\eta = \\frac{1}{M}\\). Suppose \\(x_0\\) is a stationary point satisfying \\(\\| \\nabla F(x_0) \\| \\leq \\alpha\\) and \\(s_{\\min}(\\nabla^2 F(x_0)) \\leq \\gamma^2 - \\sqrt{\\rho\\alpha}\\), \\(\\alpha = \\gamma \\log^3(dBM/\\rho\\omega)\\). If \\(\\nabla_0 = \\nabla F(x_0) + \\zeta_1 + \\zeta_2\\) where \\(\\| \\zeta_1 \\| \\leq \\gamma\\), \\(\\zeta_2 \\sim \\mathcal{N}(0, d\\log(d/\\omega)I_d)\\), and \\(\\| \\nabla_t - \\nabla F(x_t) \\| \\leq \\gamma\\) for all \\(t \\in [\\Gamma]\\), with probability at least \\(1-\\omega \\cdot \\log(1/\\omega)\\), one has\n\n$$\nF(x_{\\Gamma}) - F(x_0) \\leq -\\Omega \\left( \\frac{\\gamma^{3/2}}{M \\log\\left(\\frac{dMB}{\\rho\\gamma\\omega}\\right)\\sqrt{\\rho\\log^3(dMB/\\rho\\gamma\\omega)}} \\right),\n$$\nwhere \\(\\Gamma = \\sqrt{\\rho\\gamma}\\).\n\nWe briefly recap the proof of Lemma 3.4 in [WCX19]. One observation between the decreased function value, and the distance solutions moved is stated below:\n\nLemma A.1 (Lemma 11, [WCX19]). For each \\(t \\in [\\Gamma]\\), we know\n\n$$\n\\|x_{t+1} - x_0\\|_2^2 \\leq 8\\eta(\\Gamma(F(x_0) - F(x_{\\Gamma})) + 50\\eta^2\\Gamma \\sum_{i \\in [\\Gamma]} \\| \\nabla_i - \\nabla F(x_t) \\|_2^2).\n$$", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Proof of Section 3", "md": "# Proof of Section 3"}, {"type": "heading", "lvl": 2, "value": "Proof of Lemma 3.3", "md": "## Proof of Lemma 3.3"}, {"type": "text", "value": "Lemma 3.3. For any \\(0 \\leq t \\leq T\\) and letting \\(\\tau_t \\leq t\\) be the largest integer such that drift\\(\\tau_t\\) is set to be 0, with probability at least \\(1 - \\frac{\\omega}{T}\\), for some universal constant \\(C > 0\\), we have\n\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2^2 \\leq \\zeta_{22} \\cdot \\sum_{i=\\tau_t+1}^{t} \\|x_i - x_{i-1}\\|_2^2 + 4\\zeta_1^2 \\cdot C \\cdot \\log\\left(\\frac{Td}{\\omega}\\right). \\quad (1)\n$$\nHence with probability at least \\(1 - \\omega\\), we know for each \\(t \\leq T\\), \\(\\| \\nabla_t - \\nabla F(x_t) \\|_2 \\leq \\frac{\\gamma^2}{16}\\), where\n\n$$\n\\gamma^2 := 16C(\\zeta_2^2\\kappa + 4\\zeta_1^2) \\cdot \\log\\left(\\frac{Td}{\\omega}\\right)\n$$\nand \\(\\kappa\\) is a parameter we can choose in the algorithm.\n\nProof. If drift\\(\\tau_t = 0\\) happens, we use the first kind oracle to query the gradient, and hence \\(\\nabla_{\\tau_t} - \\nabla F(x_{\\tau_t})\\) is zero-mean and nSG(2\\(\\zeta_1\\)). If \\(t = \\tau_t\\), Equation (1) holds by the property of norm-subGaussian.\n\nFor each \\(\\tau_t + 1 \\leq i \\leq t\\), conditional on \\(\\nabla_{i-1}\\), we know \\(\\Delta_i - (\\nabla F(x_i) - \\nabla F(x_{i-1}))\\) is zero-mean and nSG(\\(\\zeta_2\\|x_i - x_{i-1}\\|\\)). Note that\n\n$$\n\\nabla_t - \\nabla F(x_t) = \\nabla_{\\tau_t} - \\nabla F(x_{\\tau_t}) + \\sum_{i=\\tau_t+1}^{t} [\\Delta_i - (\\nabla F(x_i) - \\nabla F(x_{i-1}))].\n$$\nEquation (1) follows from Lemma 2.4.\n\nWe know drift\\(t-1 = \\sum_{i=\\tau_t+1}^{t} \\|x_i - x_{i-1}\\|_2^2 \\leq \\kappa\\) almost surely by the design of the algorithm. By union bound, we know with probability at least \\(1 - \\omega\\), for each \\(t \\in [T]\\),\n\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2^2 \\leq C(\\zeta_2^2\\kappa + 4\\zeta_1^2) \\cdot \\log\\left(\\frac{Td}{\\omega}\\right) = \\frac{\\gamma^2}{16}.\n$$", "md": "Lemma 3.3. For any \\(0 \\leq t \\leq T\\) and letting \\(\\tau_t \\leq t\\) be the largest integer such that drift\\(\\tau_t\\) is set to be 0, with probability at least \\(1 - \\frac{\\omega}{T}\\), for some universal constant \\(C > 0\\), we have\n\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2^2 \\leq \\zeta_{22} \\cdot \\sum_{i=\\tau_t+1}^{t} \\|x_i - x_{i-1}\\|_2^2 + 4\\zeta_1^2 \\cdot C \\cdot \\log\\left(\\frac{Td}{\\omega}\\right). \\quad (1)\n$$\nHence with probability at least \\(1 - \\omega\\), we know for each \\(t \\leq T\\), \\(\\| \\nabla_t - \\nabla F(x_t) \\|_2 \\leq \\frac{\\gamma^2}{16}\\), where\n\n$$\n\\gamma^2 := 16C(\\zeta_2^2\\kappa + 4\\zeta_1^2) \\cdot \\log\\left(\\frac{Td}{\\omega}\\right)\n$$\nand \\(\\kappa\\) is a parameter we can choose in the algorithm.\n\nProof. If drift\\(\\tau_t = 0\\) happens, we use the first kind oracle to query the gradient, and hence \\(\\nabla_{\\tau_t} - \\nabla F(x_{\\tau_t})\\) is zero-mean and nSG(2\\(\\zeta_1\\)). If \\(t = \\tau_t\\), Equation (1) holds by the property of norm-subGaussian.\n\nFor each \\(\\tau_t + 1 \\leq i \\leq t\\), conditional on \\(\\nabla_{i-1}\\), we know \\(\\Delta_i - (\\nabla F(x_i) - \\nabla F(x_{i-1}))\\) is zero-mean and nSG(\\(\\zeta_2\\|x_i - x_{i-1}\\|\\)). Note that\n\n$$\n\\nabla_t - \\nabla F(x_t) = \\nabla_{\\tau_t} - \\nabla F(x_{\\tau_t}) + \\sum_{i=\\tau_t+1}^{t} [\\Delta_i - (\\nabla F(x_i) - \\nabla F(x_{i-1}))].\n$$\nEquation (1) follows from Lemma 2.4.\n\nWe know drift\\(t-1 = \\sum_{i=\\tau_t+1}^{t} \\|x_i - x_{i-1}\\|_2^2 \\leq \\kappa\\) almost surely by the design of the algorithm. By union bound, we know with probability at least \\(1 - \\omega\\), for each \\(t \\in [T]\\),\n\n$$\n\\| \\nabla_t - \\nabla F(x_t) \\|_2^2 \\leq C(\\zeta_2^2\\kappa + 4\\zeta_1^2) \\cdot \\log\\left(\\frac{Td}{\\omega}\\right) = \\frac{\\gamma^2}{16}.\n$$"}, {"type": "heading", "lvl": 2, "value": "Discussion of Lemma 3.4", "md": "## Discussion of Lemma 3.4"}, {"type": "text", "value": "Lemma 3.4 (Essentially from [WCX19]). Under Assumption 3.1, run SGD iterations \\(x_{t+1} = x_t - \\eta\\nabla_t\\), with step size \\(\\eta = \\frac{1}{M}\\). Suppose \\(x_0\\) is a stationary point satisfying \\(\\| \\nabla F(x_0) \\| \\leq \\alpha\\) and \\(s_{\\min}(\\nabla^2 F(x_0)) \\leq \\gamma^2 - \\sqrt{\\rho\\alpha}\\), \\(\\alpha = \\gamma \\log^3(dBM/\\rho\\omega)\\). If \\(\\nabla_0 = \\nabla F(x_0) + \\zeta_1 + \\zeta_2\\) where \\(\\| \\zeta_1 \\| \\leq \\gamma\\), \\(\\zeta_2 \\sim \\mathcal{N}(0, d\\log(d/\\omega)I_d)\\), and \\(\\| \\nabla_t - \\nabla F(x_t) \\| \\leq \\gamma\\) for all \\(t \\in [\\Gamma]\\), with probability at least \\(1-\\omega \\cdot \\log(1/\\omega)\\), one has\n\n$$\nF(x_{\\Gamma}) - F(x_0) \\leq -\\Omega \\left( \\frac{\\gamma^{3/2}}{M \\log\\left(\\frac{dMB}{\\rho\\gamma\\omega}\\right)\\sqrt{\\rho\\log^3(dMB/\\rho\\gamma\\omega)}} \\right),\n$$\nwhere \\(\\Gamma = \\sqrt{\\rho\\gamma}\\).\n\nWe briefly recap the proof of Lemma 3.4 in [WCX19]. One observation between the decreased function value, and the distance solutions moved is stated below:\n\nLemma A.1 (Lemma 11, [WCX19]). For each \\(t \\in [\\Gamma]\\), we know\n\n$$\n\\|x_{t+1} - x_0\\|_2^2 \\leq 8\\eta(\\Gamma(F(x_0) - F(x_{\\Gamma})) + 50\\eta^2\\Gamma \\sum_{i \\in [\\Gamma]} \\| \\nabla_i - \\nabla F(x_t) \\|_2^2).\n$$", "md": "Lemma 3.4 (Essentially from [WCX19]). Under Assumption 3.1, run SGD iterations \\(x_{t+1} = x_t - \\eta\\nabla_t\\), with step size \\(\\eta = \\frac{1}{M}\\). Suppose \\(x_0\\) is a stationary point satisfying \\(\\| \\nabla F(x_0) \\| \\leq \\alpha\\) and \\(s_{\\min}(\\nabla^2 F(x_0)) \\leq \\gamma^2 - \\sqrt{\\rho\\alpha}\\), \\(\\alpha = \\gamma \\log^3(dBM/\\rho\\omega)\\). If \\(\\nabla_0 = \\nabla F(x_0) + \\zeta_1 + \\zeta_2\\) where \\(\\| \\zeta_1 \\| \\leq \\gamma\\), \\(\\zeta_2 \\sim \\mathcal{N}(0, d\\log(d/\\omega)I_d)\\), and \\(\\| \\nabla_t - \\nabla F(x_t) \\| \\leq \\gamma\\) for all \\(t \\in [\\Gamma]\\), with probability at least \\(1-\\omega \\cdot \\log(1/\\omega)\\), one has\n\n$$\nF(x_{\\Gamma}) - F(x_0) \\leq -\\Omega \\left( \\frac{\\gamma^{3/2}}{M \\log\\left(\\frac{dMB}{\\rho\\gamma\\omega}\\right)\\sqrt{\\rho\\log^3(dMB/\\rho\\gamma\\omega)}} \\right),\n$$\nwhere \\(\\Gamma = \\sqrt{\\rho\\gamma}\\).\n\nWe briefly recap the proof of Lemma 3.4 in [WCX19]. One observation between the decreased function value, and the distance solutions moved is stated below:\n\nLemma A.1 (Lemma 11, [WCX19]). For each \\(t \\in [\\Gamma]\\), we know\n\n$$\n\\|x_{t+1} - x_0\\|_2^2 \\leq 8\\eta(\\Gamma(F(x_0) - F(x_{\\Gamma})) + 50\\eta^2\\Gamma \\sum_{i \\in [\\Gamma]} \\| \\nabla_i - \\nabla F(x_t) \\|_2^2).\n$$"}]}, {"page": 18, "text": "     The difference between our algorithm and the DP-GD in [WCX19] is the noise on the gradient.\nNote that with high probability,             i\u2208[\u0393] \u2225\u2207i \u2212  \u2207F(xt)\u22252   2 in our algorithm is controlled and small,\nand hence does not change the other proofs in [WCX19]. Hence if F(x0) \u2212                       F(x\u0393) is small, i.e., the\nfunction value does not decrease significantly, we know xt is close to x0.\n     Let Bx(r) be the unit ball of radius r around point x. Denote the (x)\u0393 the point x\u0393 after\nrunning SGD mentioned in Lemma 3.4 for \u0393 steps beginning at x. With this observation, denote\nB\u03b3  (x0) := {x | x \u2208    Bx0(\u03b7\u03b1), Pr[F((x)\u0393) \u2212        F(x) \u2265   \u2212\u03a6] \u2265    \u03c9}. [WCX19] demonstrates the following\nlemma:\nLemma A.2. If \u2225\u2207F(x0)\u2225             \u2264  \u03b1 and smin(\u22072F(x0)) \u2264           \u2212\u221a\u03c1\u03b3, then the width of B\u03b3(x0) along the\n                                                                       \u03c9\u03b7\u03b3       2\u03c0\nalong the minimum eigenvector of \u22072F(x0) is at most                  log(1/\u03c9)     d .\n     The intuition is that if two different points x1, x2 \u2208             Bx0(\u03b7\u03b1), and x1 \u2212       x2 is large along the\nminimum eigenvector, then with high probability, the distance between \u2225(x1)\u0393 \u2212                           (x2)\u0393\u2225   will be\nlarge, and either \u2225(x1)\u0393 \u2212         x1\u2225   or \u2225(x2)\u0393 \u2212    x2\u2225   is large, and hence either F(x1) \u2212           F((x1)\u0393) or\nF(x2) \u2212    F((x2)\u0393) is large. The Lemma 3.4 follows from Lemma A.2 by using the Gaussian \u03b62 to\nkick off the point.\nA.3      Proof of Lemma 3.5\nLemma 3.5. By setting \u03b7 = 1/M, we have\n                            F(xt+1) \u2264     F(xt) + \u03b7\u2225\u2207t\u2225     \u00b7 \u2225\u2207F(xt) \u2212     \u2207t\u2225  \u2212   \u03b7\n                                                                                     2\u2225\u2207t\u22252.\nMoreover, with probability at least 1 \u2212         \u03c9, for each t \u2264     T such that \u2225\u2207F(xt)\u2225        \u2265  \u03b3, we have\n                                   F(xt+1) \u2212     F(xt) \u2264   \u2212\u03b7\u2225\u2207t\u22252/6 \u2264       \u2212\u03b7\u03b32/6.\nProof. By the assumption on smoothness, we know\n                          F(xt+1) \u2264F(xt) + \u27e8\u2207F(xt), xt+1 \u2212            xt\u27e9 + M2 \u2225xt+1 \u2212     xt\u22252\n                                     =F(xt) \u2212     \u03b7/2\u2225\u2207t\u22252 \u2212     \u27e8\u2207F(xt) \u2212     \u2207t, \u03b7\u2207t\u27e9\n                                     \u2264F(xt) + \u03b7\u2225\u2207F(xt) \u2212         \u2207t\u2225   \u00b7 \u2225\u2207t\u2225  \u2212  \u03b7\n                                                                                  2\u2225\u2207t\u22252.\n     By Lemma 3.3, with probability at least 1\u2212\u03c9, for each t \u2208                [T] we have \u2225\u2207F(xt) \u2212\u2207t\u22252 \u2264            \u03b3/4.\nHence we know if \u2207F(xt) \u2265           \u03b3, we have\n                                   F(xt+1) \u2212     F(xt) \u2264   \u2212\u03b7\u2225\u2207t\u22252/6 \u2264       \u2212\u03b7\u03b32/6.\nA.4      Proof of Lemma 3.6\nLemma 3.6. Suppose O1 and O2 are \u03b61 and \u03b62 norm-subGaussian respectively. If one sets \u03b3 =\nO(1)     (\u03b62\n           2\u03ba + 4\u03b62  1) \u00b7 log(Td/\u03c9), with probability at least 1 \u2212         \u03c9, at least one point in the output set\n{x1, \u00b7 \u00b7 \u00b7 , xT } of Algorithm 1 is \u03b1-SOSP, where\n              \u03b1 = \u03b3 log3(BMd/\u03c1\u03c9\u03b3) =              (\u03b62                     d/\u03c9     ) \u00b7 log3(     BMd\n                                                   2\u03ba + 4\u03b62 1) \u00b7 log( \u03b62                  \u03c1\u03c9(\u03b62\n                                                                       2\u03ba + \u03b62 1                2\u03ba + \u03b62 1)).\n                                                            18", "md": "The difference between our algorithm and the DP-GD in [WCX19] is the noise on the gradient.\nNote that with high probability, $$\\forall i\\in[\\Gamma] \\|\\nabla_i - \\nabla F(x_t)\\|^2_2$$ in our algorithm is controlled and small,\nand hence does not change the other proofs in [WCX19]. Hence if $$F(x_0) - F(x_{\\Gamma})$$ is small, i.e., the\nfunction value does not decrease significantly, we know $$x_t$$ is close to $$x_0$$.\n\nLet $$B_x(r)$$ be the unit ball of radius $$r$$ around point $$x$$. Denote $$x_{\\Gamma}$$ the point $$x_{\\Gamma}$$ after\nrunning SGD mentioned in Lemma 3.4 for $$\\Gamma$$ steps beginning at $$x$$. With this observation, denote\n$$B_{\\gamma}(x_0) := \\{x | x \\in B_{x_0}(\\eta\\alpha), Pr[F((x)_{\\Gamma}) - F(x) \\geq -\\Phi] \\geq \\omega\\}$$. [WCX19] demonstrates the following\nlemma:\n\nLemma A.2. If $$\\|\\nabla F(x_0)\\| \\leq \\alpha$$ and $$s_{\\min}(\\nabla^2F(x_0)) \\leq -\\sqrt{\\rho\\gamma}$$, then the width of $$B_{\\gamma}(x_0)$$ along the\nminimum eigenvector of $$\\nabla^2F(x_0)$$ is at most $$\\frac{\\log(1/\\omega)}{\\omega\\eta\\gamma\\sqrt{2\\pi}}$$.\n\nThe intuition is that if two different points $$x_1, x_2 \\in B_{x_0}(\\eta\\alpha)$$, and $$x_1 - x_2$$ is large along the\nminimum eigenvector, then with high probability, the distance between $$\\|(x_1)_{\\Gamma} - (x_2)_{\\Gamma}\\|$$ will be\nlarge, and either $$\\|(x_1)_{\\Gamma} - x_1\\|$$ or $$\\|(x_2)_{\\Gamma} - x_2\\|$$ is large, and hence either $$F(x_1) - F((x_1)_{\\Gamma})$$ or\n$$F(x_2) - F((x_2)_{\\Gamma})$$ is large. The Lemma 3.4 follows from Lemma A.2 by using the Gaussian $$\\zeta^2$$ to\nkick off the point.\n\nProof of Lemma 3.5\n\nLemma 3.5. By setting $$\\eta = 1/M$$, we have\n\n$$\nF(x_{t+1}) \\leq F(x_t) + \\eta\\|\\nabla_t\\| \\cdot \\|\\nabla F(x_t) - \\nabla_t\\| - \\frac{\\eta}{2}\\|\\nabla_t\\|^2.\n$$\n\nMoreover, with probability at least $$1 - \\omega$$, for each $$t \\leq T$$ such that $$\\|\\nabla F(x_t)\\| \\geq \\gamma$$, we have\n\n$$\nF(x_{t+1}) - F(x_t) \\leq -\\frac{\\eta\\|\\nabla_t\\|^2}{6} \\leq -\\frac{\\eta\\gamma^2}{6}.\n$$\n\nProof. By the assumption on smoothness, we know\n\n$$\n\\begin{align*}\nF(x_{t+1}) &\\leq F(x_t) + \\langle\\nabla F(x_t), x_{t+1} - x_t\\rangle + M^2 \\|x_{t+1} - x_t\\|^2 \\\\\n&= F(x_t) - \\frac{\\eta}{2}\\|\\nabla_t\\|^2 - \\langle\\nabla F(x_t) - \\nabla_t, \\eta\\nabla_t\\rangle \\\\\n&\\leq F(x_t) + \\eta\\|\\nabla F(x_t) - \\nabla_t\\| \\cdot \\|\\nabla_t\\| - \\frac{\\eta}{2}\\|\\nabla_t\\|^2.\n\\end{align*}\n$$\n\nBy Lemma 3.3, with probability at least $$1-\\omega$$, for each $$t \\in [T]$$ we have $$\\|\\nabla F(x_t) - \\nabla_t\\|^2 \\leq \\gamma/4$$.\nHence we know if $$\\nabla F(x_t) \\geq \\gamma$$, we have\n\n$$\nF(x_{t+1}) - F(x_t) \\leq -\\frac{\\eta\\|\\nabla_t\\|^2}{6} \\leq -\\frac{\\eta\\gamma^2}{6}.\n$$\n\nProof of Lemma 3.6\n\nLemma 3.6. Suppose $$O_1$$ and $$O_2$$ are $$\\zeta_1$$ and $$\\zeta_2$$ norm-subGaussian respectively. If one sets $$\\gamma =\nO(1)(\\zeta_2^2\\kappa + 4\\zeta_2^2\\kappa) \\cdot \\log(Td/\\omega)$$, with probability at least $$1 - \\omega$$, at least one point in the output set\n{$$x_1, \\ldots, x_T$$} of Algorithm 1 is $$\\alpha$$-SOSP, where\n\n$$\n\\alpha = \\gamma \\log^3(BMd/\\rho\\omega\\gamma) = \\left(\\frac{\\zeta_2^2d}{\\omega}\\right) \\cdot \\log^3\\left(BMd\\left(\\zeta_2^2\\rho\\omega(\\zeta_2^2\\kappa + \\zeta_2^2\\kappa)\\right)\\right).\n$$", "images": [], "items": [{"type": "text", "value": "The difference between our algorithm and the DP-GD in [WCX19] is the noise on the gradient.\nNote that with high probability, $$\\forall i\\in[\\Gamma] \\|\\nabla_i - \\nabla F(x_t)\\|^2_2$$ in our algorithm is controlled and small,\nand hence does not change the other proofs in [WCX19]. Hence if $$F(x_0) - F(x_{\\Gamma})$$ is small, i.e., the\nfunction value does not decrease significantly, we know $$x_t$$ is close to $$x_0$$.\n\nLet $$B_x(r)$$ be the unit ball of radius $$r$$ around point $$x$$. Denote $$x_{\\Gamma}$$ the point $$x_{\\Gamma}$$ after\nrunning SGD mentioned in Lemma 3.4 for $$\\Gamma$$ steps beginning at $$x$$. With this observation, denote\n$$B_{\\gamma}(x_0) := \\{x | x \\in B_{x_0}(\\eta\\alpha), Pr[F((x)_{\\Gamma}) - F(x) \\geq -\\Phi] \\geq \\omega\\}$$. [WCX19] demonstrates the following\nlemma:\n\nLemma A.2. If $$\\|\\nabla F(x_0)\\| \\leq \\alpha$$ and $$s_{\\min}(\\nabla^2F(x_0)) \\leq -\\sqrt{\\rho\\gamma}$$, then the width of $$B_{\\gamma}(x_0)$$ along the\nminimum eigenvector of $$\\nabla^2F(x_0)$$ is at most $$\\frac{\\log(1/\\omega)}{\\omega\\eta\\gamma\\sqrt{2\\pi}}$$.\n\nThe intuition is that if two different points $$x_1, x_2 \\in B_{x_0}(\\eta\\alpha)$$, and $$x_1 - x_2$$ is large along the\nminimum eigenvector, then with high probability, the distance between $$\\|(x_1)_{\\Gamma} - (x_2)_{\\Gamma}\\|$$ will be\nlarge, and either $$\\|(x_1)_{\\Gamma} - x_1\\|$$ or $$\\|(x_2)_{\\Gamma} - x_2\\|$$ is large, and hence either $$F(x_1) - F((x_1)_{\\Gamma})$$ or\n$$F(x_2) - F((x_2)_{\\Gamma})$$ is large. The Lemma 3.4 follows from Lemma A.2 by using the Gaussian $$\\zeta^2$$ to\nkick off the point.\n\nProof of Lemma 3.5\n\nLemma 3.5. By setting $$\\eta = 1/M$$, we have\n\n$$\nF(x_{t+1}) \\leq F(x_t) + \\eta\\|\\nabla_t\\| \\cdot \\|\\nabla F(x_t) - \\nabla_t\\| - \\frac{\\eta}{2}\\|\\nabla_t\\|^2.\n$$\n\nMoreover, with probability at least $$1 - \\omega$$, for each $$t \\leq T$$ such that $$\\|\\nabla F(x_t)\\| \\geq \\gamma$$, we have\n\n$$\nF(x_{t+1}) - F(x_t) \\leq -\\frac{\\eta\\|\\nabla_t\\|^2}{6} \\leq -\\frac{\\eta\\gamma^2}{6}.\n$$\n\nProof. By the assumption on smoothness, we know\n\n$$\n\\begin{align*}\nF(x_{t+1}) &\\leq F(x_t) + \\langle\\nabla F(x_t), x_{t+1} - x_t\\rangle + M^2 \\|x_{t+1} - x_t\\|^2 \\\\\n&= F(x_t) - \\frac{\\eta}{2}\\|\\nabla_t\\|^2 - \\langle\\nabla F(x_t) - \\nabla_t, \\eta\\nabla_t\\rangle \\\\\n&\\leq F(x_t) + \\eta\\|\\nabla F(x_t) - \\nabla_t\\| \\cdot \\|\\nabla_t\\| - \\frac{\\eta}{2}\\|\\nabla_t\\|^2.\n\\end{align*}\n$$\n\nBy Lemma 3.3, with probability at least $$1-\\omega$$, for each $$t \\in [T]$$ we have $$\\|\\nabla F(x_t) - \\nabla_t\\|^2 \\leq \\gamma/4$$.\nHence we know if $$\\nabla F(x_t) \\geq \\gamma$$, we have\n\n$$\nF(x_{t+1}) - F(x_t) \\leq -\\frac{\\eta\\|\\nabla_t\\|^2}{6} \\leq -\\frac{\\eta\\gamma^2}{6}.\n$$\n\nProof of Lemma 3.6\n\nLemma 3.6. Suppose $$O_1$$ and $$O_2$$ are $$\\zeta_1$$ and $$\\zeta_2$$ norm-subGaussian respectively. If one sets $$\\gamma =\nO(1)(\\zeta_2^2\\kappa + 4\\zeta_2^2\\kappa) \\cdot \\log(Td/\\omega)$$, with probability at least $$1 - \\omega$$, at least one point in the output set\n{$$x_1, \\ldots, x_T$$} of Algorithm 1 is $$\\alpha$$-SOSP, where\n\n$$\n\\alpha = \\gamma \\log^3(BMd/\\rho\\omega\\gamma) = \\left(\\frac{\\zeta_2^2d}{\\omega}\\right) \\cdot \\log^3\\left(BMd\\left(\\zeta_2^2\\rho\\omega(\\zeta_2^2\\kappa + \\zeta_2^2\\kappa)\\right)\\right).\n$$", "md": "The difference between our algorithm and the DP-GD in [WCX19] is the noise on the gradient.\nNote that with high probability, $$\\forall i\\in[\\Gamma] \\|\\nabla_i - \\nabla F(x_t)\\|^2_2$$ in our algorithm is controlled and small,\nand hence does not change the other proofs in [WCX19]. Hence if $$F(x_0) - F(x_{\\Gamma})$$ is small, i.e., the\nfunction value does not decrease significantly, we know $$x_t$$ is close to $$x_0$$.\n\nLet $$B_x(r)$$ be the unit ball of radius $$r$$ around point $$x$$. Denote $$x_{\\Gamma}$$ the point $$x_{\\Gamma}$$ after\nrunning SGD mentioned in Lemma 3.4 for $$\\Gamma$$ steps beginning at $$x$$. With this observation, denote\n$$B_{\\gamma}(x_0) := \\{x | x \\in B_{x_0}(\\eta\\alpha), Pr[F((x)_{\\Gamma}) - F(x) \\geq -\\Phi] \\geq \\omega\\}$$. [WCX19] demonstrates the following\nlemma:\n\nLemma A.2. If $$\\|\\nabla F(x_0)\\| \\leq \\alpha$$ and $$s_{\\min}(\\nabla^2F(x_0)) \\leq -\\sqrt{\\rho\\gamma}$$, then the width of $$B_{\\gamma}(x_0)$$ along the\nminimum eigenvector of $$\\nabla^2F(x_0)$$ is at most $$\\frac{\\log(1/\\omega)}{\\omega\\eta\\gamma\\sqrt{2\\pi}}$$.\n\nThe intuition is that if two different points $$x_1, x_2 \\in B_{x_0}(\\eta\\alpha)$$, and $$x_1 - x_2$$ is large along the\nminimum eigenvector, then with high probability, the distance between $$\\|(x_1)_{\\Gamma} - (x_2)_{\\Gamma}\\|$$ will be\nlarge, and either $$\\|(x_1)_{\\Gamma} - x_1\\|$$ or $$\\|(x_2)_{\\Gamma} - x_2\\|$$ is large, and hence either $$F(x_1) - F((x_1)_{\\Gamma})$$ or\n$$F(x_2) - F((x_2)_{\\Gamma})$$ is large. The Lemma 3.4 follows from Lemma A.2 by using the Gaussian $$\\zeta^2$$ to\nkick off the point.\n\nProof of Lemma 3.5\n\nLemma 3.5. By setting $$\\eta = 1/M$$, we have\n\n$$\nF(x_{t+1}) \\leq F(x_t) + \\eta\\|\\nabla_t\\| \\cdot \\|\\nabla F(x_t) - \\nabla_t\\| - \\frac{\\eta}{2}\\|\\nabla_t\\|^2.\n$$\n\nMoreover, with probability at least $$1 - \\omega$$, for each $$t \\leq T$$ such that $$\\|\\nabla F(x_t)\\| \\geq \\gamma$$, we have\n\n$$\nF(x_{t+1}) - F(x_t) \\leq -\\frac{\\eta\\|\\nabla_t\\|^2}{6} \\leq -\\frac{\\eta\\gamma^2}{6}.\n$$\n\nProof. By the assumption on smoothness, we know\n\n$$\n\\begin{align*}\nF(x_{t+1}) &\\leq F(x_t) + \\langle\\nabla F(x_t), x_{t+1} - x_t\\rangle + M^2 \\|x_{t+1} - x_t\\|^2 \\\\\n&= F(x_t) - \\frac{\\eta}{2}\\|\\nabla_t\\|^2 - \\langle\\nabla F(x_t) - \\nabla_t, \\eta\\nabla_t\\rangle \\\\\n&\\leq F(x_t) + \\eta\\|\\nabla F(x_t) - \\nabla_t\\| \\cdot \\|\\nabla_t\\| - \\frac{\\eta}{2}\\|\\nabla_t\\|^2.\n\\end{align*}\n$$\n\nBy Lemma 3.3, with probability at least $$1-\\omega$$, for each $$t \\in [T]$$ we have $$\\|\\nabla F(x_t) - \\nabla_t\\|^2 \\leq \\gamma/4$$.\nHence we know if $$\\nabla F(x_t) \\geq \\gamma$$, we have\n\n$$\nF(x_{t+1}) - F(x_t) \\leq -\\frac{\\eta\\|\\nabla_t\\|^2}{6} \\leq -\\frac{\\eta\\gamma^2}{6}.\n$$\n\nProof of Lemma 3.6\n\nLemma 3.6. Suppose $$O_1$$ and $$O_2$$ are $$\\zeta_1$$ and $$\\zeta_2$$ norm-subGaussian respectively. If one sets $$\\gamma =\nO(1)(\\zeta_2^2\\kappa + 4\\zeta_2^2\\kappa) \\cdot \\log(Td/\\omega)$$, with probability at least $$1 - \\omega$$, at least one point in the output set\n{$$x_1, \\ldots, x_T$$} of Algorithm 1 is $$\\alpha$$-SOSP, where\n\n$$\n\\alpha = \\gamma \\log^3(BMd/\\rho\\omega\\gamma) = \\left(\\frac{\\zeta_2^2d}{\\omega}\\right) \\cdot \\log^3\\left(BMd\\left(\\zeta_2^2\\rho\\omega(\\zeta_2^2\\kappa + \\zeta_2^2\\kappa)\\right)\\right).\n$$"}]}, {"page": 19, "text": "Proof. By Lemma 3.5, we know if the gradient \u2225\u2207F(xt)\u2225                                          \u2265    \u03b3, then with high probability that\nF(xt+1) \u2212         F(xt) \u2264        \u2212\u03b7\u03b32/6. By Lemma 3.4, if xt is a saddle point (with small gradient norm\nbut the Hessian has a small eigenvalue), then with high probability that F(x\u0393+t) \u2212                                                           F(xt) \u2264\n              \u03b33/2                                                                            \u03b32\n\u2212\u2126(     \u221a\u03c1 log3( dMB                                                                  M log4( dMB          on average for each step.\n                   \u03c1\u03b3\u03c9 )), and the function values decrease \u2126                                    \u03c1\u03b3\u03c9 )\n      Recall the assumption that the risk is upper bounded by B, by our setting T = \u2126                                              BM\u03b32 log4(dMB   \u03c1\u03b3\u03c9 )    ,\nthe statement is proved.\nA.5         Proof of Lemma 3.7\nLemma 3.7. Under the event that \u2225\u2207t \u2212                                  \u2207F(xt)\u2225         \u2264    \u03b3/4 for all t \u2208           [T  ] and our parameter\nsettings, letting K = {t \u2208               [T  ] : driftt \u2265     \u03ba} be the set of iterations where the drift is large, we know\n|K| \u2264     O   B\u03b7\u03ba + T      \u03b32\u03b72/\u03ba) = O(B\u03b7 log4(dMB            \u03c1\u03b3\u03c9 )/\u03ba      .\nProof. By Lemma 3.5, if \u2225F(xt)\u2225                        \u2265    \u03b3, we know F(xt+1) \u2212                 F(xt) \u2264       \u2212\u03b7\u2225\u2207t\u22252/6, and F(xt+1) \u2212\nF(xt) \u2264       \u03b7\u03b32 otherwise. Index the items in K = {t1, t2, \u00b7 \u00b7 \u00b7 , t|K|} such that ti < ti+1. We know\n                   F(xt   i+1) \u2212    F(xti) \u2264       \u2212   1\n                                                      6\u03b7  driftti+1 + (ti+1 \u2212          ti)\u03b32\u03b7 \u2264      \u2212   1\n                                                                                                        6\u03b7  \u03ba + (ti+1 \u2212       ti)\u03b32\u03b7.\n      Recall by the assumption that maxy F(y) \u2212                                minx F(x) \u2264           B.     And hence \u2212B \u2264                 F(xt|L|) \u2212\nF(xt    1) \u2264   \u2212|K|6\u03b7 \u03ba + T     \u03b32\u03b7, and we know\nA.6         Proof of Theorem 3.9      |K| \u2264     O   B\u03b7 \u03ba + T     \u03b32\u03b72/\u03ba) = O(B\u03b7 log4(dMB              \u03c1\u03b3\u03c9 )/\u03ba       .\nTheorem 3.9 (Empirical). Using full batch in Algorithm 1, and setting \u03ba = G4/3B1/3                                                 ( \u221a  d log(1/\u03b4)  )2/3  ,\n                                                                                                                          M5/3             n\u03b5\n\u03c31 = G\u221a         B\u03b7 log2(1/\u03b4)/\u03ba log2(ndMB/\u03c9)           , \u03c32 = M\u221a        log2(1/\u03b4)BM/\u03b12      1 log5(ndMB/\u03c9)       , Algorithm 1 is (\u03b5, \u03b4)-DP,\n                              n\u03b5                                                       n\u03b5\nand with probability at least 1 \u2212                  \u03c9, at least one point in the output set {xi}i\u2208[T] is \u03b11-SOSP of FD\nwith\n                                                  \uf8eb        dBGM log2(1/\u03b4)              2/3 \u00b7 log6 nBMd\uf8f8          \uf8f6   .\n                                      \u03b11 = O      \uf8ed                 n\u03b5                                   \u03c1\u03c9\n      Moreover, if we run Algorithm 2 with inputs {xi}i\u2208[T], D, B, M, G, \u03c1, \u03b11, with probability at least\n1 \u2212    \u03c9, we can get an \u03b12-SOSP of FD with\n                                \u03b12 = O         \u03b11 + G log(n/G\u03c9)              + M log(ndBGM/\u03c1\u03c9)                   \u221a  \u03b11     .\n                                                               n\u03b5                           n\u03b5\u221a\u03c1\nProof. The privacy guarantee can be proved by composition theorems (Theorem 2.7 and Theo-\nrem 2.8) and Lemma 3.7.\n      As for the utility, we know the O1 and O2 constructed in Equation (2) are first kind of \u03c31                                                      \u221a  d\nand second kind of \u03c32             \u221a  d norm-subGaussian gradient oracle by Fact 2.3. Hence by Lemma 3.6, the\nutility \u03b11 satisfies that\n       \u03b11 =O(\u03c31       \u221a  d + \u03c32    \u221a  d\u03ba) \u00b7 log3(BMd/\u03c1\u03c9)\n           =O     L       dB\u03b7 log2(1/\u03b4)/\u03ba            +   M log3(ndMB/\u03c9)                  log2(1/\u03b4)BM          \u221a  d\u03ba     \u00b7 log5(nBMd/\u03c1\u03c9).\n                                  n\u03b5                                           n\u03b5\u03b11\n                                                                            19", "md": "# Math Equations\n\nProof. By Lemma 3.5, we know if the gradient $$\\| \\nabla F(x_t) \\| \\geq \\gamma$$, then with high probability that\n$$F(x_{t+1}) - F(x_t) \\leq -\\eta \\gamma^2/6$$. By Lemma 3.4, if $$x_t$$ is a saddle point (with small gradient norm\nbut the Hessian has a small eigenvalue), then with high probability that $$F(x_{\\Gamma+t}) - F(x_t) \\leq \\gamma^{3/2} - \\gamma^2 - \\Omega(\\sqrt{\\rho \\log^3(dMB) M \\log^4(dMB) \\rho \\gamma \\omega})$$, and the function values decrease $$\\Omega(\\rho \\gamma \\omega)$$. Recall the assumption that the risk is upper bounded by B, by our setting $$T = \\Omega(BM\\gamma^2 \\log^4(dMB \\rho \\gamma \\omega))$$, the statement is proved.\n\nA.5 Proof of Lemma 3.7\n\nLemma 3.7. Under the event that $$\\| \\nabla_t - \\nabla F(x_t) \\| \\leq \\gamma/4$$ for all $$t \\in [T]$$ and our parameter settings, letting $$K = \\{t \\in [T] : \\text{drift}_t \\geq \\kappa\\}$$ be the set of iterations where the drift is large, we know\n$$|K| \\leq O(B\\eta\\kappa + T \\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB \\rho \\gamma \\omega)/\\kappa)$$.\n\nProof. By Lemma 3.5, if $$\\| F(x_t) \\| \\geq \\gamma$$, we know $$F(x_{t+1}) - F(x_t) \\leq -\\eta \\| \\nabla_t \\| ^2/6$$, and $$F(x_{t+1}) - F(x_t) \\leq \\eta \\gamma^2$$ otherwise. Index the items in $$K = \\{t_1, t_2, \\ldots, t|K|\\}$$ such that $$t_i < t_{i+1}$$. We know\n$$F(x_{t_{i+1}}) - F(x_{t_i}) \\leq -\\frac{1}{6\\eta} \\text{drift}_{t_{i+1}} + (t_{i+1} - t_i) \\gamma^2\\eta \\leq -\\frac{1}{6\\eta} \\kappa + (t_{i+1} - t_i) \\gamma^2\\eta$$. Recall by the assumption that $$\\max_y F(y) - \\min_x F(x) \\leq B$$. And hence $$-B \\leq F(x_{t|K|}) - F(x_{t_1}) \\leq -|K|6\\eta \\kappa + T \\gamma^2\\eta$$, and we know\n\nA.6 Proof of Theorem 3.9 $$|K| \\leq O(B\\eta \\kappa + T \\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB \\rho \\gamma \\omega)/\\kappa)$$.\n\nTheorem 3.9 (Empirical). Using full batch in Algorithm 1, and setting $$\\kappa = G^{4/3}B^{1/3} (\\sqrt{d \\log(1/\\delta)})^{2/3} / M^{5/3} n\\epsilon$$,\n$$\\sigma_1 = G\\sqrt{B\\eta \\log^2(1/\\delta)/\\kappa \\log^2(ndMB/\\omega)}$$, $$\\sigma_2 = M\\sqrt{\\log^2(1/\\delta)BM/\\alpha^2} \\log^5(ndMB/\\omega)$$, Algorithm 1 is $$(\\epsilon, \\delta)$$-DP,\nand with probability at least $$1 - \\omega$$, at least one point in the output set $$\\{x_i\\}_{i\\in[T]}$$ is $$\\alpha_1$$-SOSP of FD with\n$$\\alpha_1 = O\\left(\\frac{dBGM \\log^2(1/\\delta)^{2/3} \\cdot \\log^6 nBMd}{n\\epsilon \\rho \\omega}\\right)$$.\n\nMoreover, if we run Algorithm 2 with inputs $$\\{x_i\\}_{i\\in[T]}$$, D, B, M, G, $$\\rho$$, $$\\alpha_1$$, with probability at least\n$$1 - \\omega$$, we can get an $$\\alpha_2$$-SOSP of FD with\n$$\\alpha_2 = O\\left(\\alpha_1 + G \\log(n/G\\omega) + M \\log(ndBGM/\\rho\\omega) \\sqrt{\\alpha_1}\\right)$$.\n\nProof. The privacy guarantee can be proved by composition theorems (Theorem 2.7 and Theorem 2.8) and Lemma 3.7. As for the utility, we know the $$O_1$$ and $$O_2$$ constructed in Equation (2) are first kind of $$\\sigma_1 \\sqrt{d}$$ and second kind of $$\\sigma_2 \\sqrt{d}$$ norm-subGaussian gradient oracle by Fact 2.3. Hence by Lemma 3.6, the utility $$\\alpha_1$$ satisfies that\n$$\\alpha_1 = O(\\sigma_1 \\sqrt{d} + \\sigma_2 \\sqrt{d\\kappa}) \\cdot \\log^3(BMd/\\rho\\omega)$$\n$$= O\\left(\\frac{dB\\eta \\log^2(1/\\delta)/\\kappa + M \\log^3(ndMB/\\omega) \\log^2(1/\\delta)BM \\sqrt{d\\kappa}}{n\\epsilon}\\right)$$.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations", "md": "# Math Equations"}, {"type": "text", "value": "Proof. By Lemma 3.5, we know if the gradient $$\\| \\nabla F(x_t) \\| \\geq \\gamma$$, then with high probability that\n$$F(x_{t+1}) - F(x_t) \\leq -\\eta \\gamma^2/6$$. By Lemma 3.4, if $$x_t$$ is a saddle point (with small gradient norm\nbut the Hessian has a small eigenvalue), then with high probability that $$F(x_{\\Gamma+t}) - F(x_t) \\leq \\gamma^{3/2} - \\gamma^2 - \\Omega(\\sqrt{\\rho \\log^3(dMB) M \\log^4(dMB) \\rho \\gamma \\omega})$$, and the function values decrease $$\\Omega(\\rho \\gamma \\omega)$$. Recall the assumption that the risk is upper bounded by B, by our setting $$T = \\Omega(BM\\gamma^2 \\log^4(dMB \\rho \\gamma \\omega))$$, the statement is proved.\n\nA.5 Proof of Lemma 3.7\n\nLemma 3.7. Under the event that $$\\| \\nabla_t - \\nabla F(x_t) \\| \\leq \\gamma/4$$ for all $$t \\in [T]$$ and our parameter settings, letting $$K = \\{t \\in [T] : \\text{drift}_t \\geq \\kappa\\}$$ be the set of iterations where the drift is large, we know\n$$|K| \\leq O(B\\eta\\kappa + T \\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB \\rho \\gamma \\omega)/\\kappa)$$.\n\nProof. By Lemma 3.5, if $$\\| F(x_t) \\| \\geq \\gamma$$, we know $$F(x_{t+1}) - F(x_t) \\leq -\\eta \\| \\nabla_t \\| ^2/6$$, and $$F(x_{t+1}) - F(x_t) \\leq \\eta \\gamma^2$$ otherwise. Index the items in $$K = \\{t_1, t_2, \\ldots, t|K|\\}$$ such that $$t_i < t_{i+1}$$. We know\n$$F(x_{t_{i+1}}) - F(x_{t_i}) \\leq -\\frac{1}{6\\eta} \\text{drift}_{t_{i+1}} + (t_{i+1} - t_i) \\gamma^2\\eta \\leq -\\frac{1}{6\\eta} \\kappa + (t_{i+1} - t_i) \\gamma^2\\eta$$. Recall by the assumption that $$\\max_y F(y) - \\min_x F(x) \\leq B$$. And hence $$-B \\leq F(x_{t|K|}) - F(x_{t_1}) \\leq -|K|6\\eta \\kappa + T \\gamma^2\\eta$$, and we know\n\nA.6 Proof of Theorem 3.9 $$|K| \\leq O(B\\eta \\kappa + T \\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB \\rho \\gamma \\omega)/\\kappa)$$.\n\nTheorem 3.9 (Empirical). Using full batch in Algorithm 1, and setting $$\\kappa = G^{4/3}B^{1/3} (\\sqrt{d \\log(1/\\delta)})^{2/3} / M^{5/3} n\\epsilon$$,\n$$\\sigma_1 = G\\sqrt{B\\eta \\log^2(1/\\delta)/\\kappa \\log^2(ndMB/\\omega)}$$, $$\\sigma_2 = M\\sqrt{\\log^2(1/\\delta)BM/\\alpha^2} \\log^5(ndMB/\\omega)$$, Algorithm 1 is $$(\\epsilon, \\delta)$$-DP,\nand with probability at least $$1 - \\omega$$, at least one point in the output set $$\\{x_i\\}_{i\\in[T]}$$ is $$\\alpha_1$$-SOSP of FD with\n$$\\alpha_1 = O\\left(\\frac{dBGM \\log^2(1/\\delta)^{2/3} \\cdot \\log^6 nBMd}{n\\epsilon \\rho \\omega}\\right)$$.\n\nMoreover, if we run Algorithm 2 with inputs $$\\{x_i\\}_{i\\in[T]}$$, D, B, M, G, $$\\rho$$, $$\\alpha_1$$, with probability at least\n$$1 - \\omega$$, we can get an $$\\alpha_2$$-SOSP of FD with\n$$\\alpha_2 = O\\left(\\alpha_1 + G \\log(n/G\\omega) + M \\log(ndBGM/\\rho\\omega) \\sqrt{\\alpha_1}\\right)$$.\n\nProof. The privacy guarantee can be proved by composition theorems (Theorem 2.7 and Theorem 2.8) and Lemma 3.7. As for the utility, we know the $$O_1$$ and $$O_2$$ constructed in Equation (2) are first kind of $$\\sigma_1 \\sqrt{d}$$ and second kind of $$\\sigma_2 \\sqrt{d}$$ norm-subGaussian gradient oracle by Fact 2.3. Hence by Lemma 3.6, the utility $$\\alpha_1$$ satisfies that\n$$\\alpha_1 = O(\\sigma_1 \\sqrt{d} + \\sigma_2 \\sqrt{d\\kappa}) \\cdot \\log^3(BMd/\\rho\\omega)$$\n$$= O\\left(\\frac{dB\\eta \\log^2(1/\\delta)/\\kappa + M \\log^3(ndMB/\\omega) \\log^2(1/\\delta)BM \\sqrt{d\\kappa}}{n\\epsilon}\\right)$$.", "md": "Proof. By Lemma 3.5, we know if the gradient $$\\| \\nabla F(x_t) \\| \\geq \\gamma$$, then with high probability that\n$$F(x_{t+1}) - F(x_t) \\leq -\\eta \\gamma^2/6$$. By Lemma 3.4, if $$x_t$$ is a saddle point (with small gradient norm\nbut the Hessian has a small eigenvalue), then with high probability that $$F(x_{\\Gamma+t}) - F(x_t) \\leq \\gamma^{3/2} - \\gamma^2 - \\Omega(\\sqrt{\\rho \\log^3(dMB) M \\log^4(dMB) \\rho \\gamma \\omega})$$, and the function values decrease $$\\Omega(\\rho \\gamma \\omega)$$. Recall the assumption that the risk is upper bounded by B, by our setting $$T = \\Omega(BM\\gamma^2 \\log^4(dMB \\rho \\gamma \\omega))$$, the statement is proved.\n\nA.5 Proof of Lemma 3.7\n\nLemma 3.7. Under the event that $$\\| \\nabla_t - \\nabla F(x_t) \\| \\leq \\gamma/4$$ for all $$t \\in [T]$$ and our parameter settings, letting $$K = \\{t \\in [T] : \\text{drift}_t \\geq \\kappa\\}$$ be the set of iterations where the drift is large, we know\n$$|K| \\leq O(B\\eta\\kappa + T \\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB \\rho \\gamma \\omega)/\\kappa)$$.\n\nProof. By Lemma 3.5, if $$\\| F(x_t) \\| \\geq \\gamma$$, we know $$F(x_{t+1}) - F(x_t) \\leq -\\eta \\| \\nabla_t \\| ^2/6$$, and $$F(x_{t+1}) - F(x_t) \\leq \\eta \\gamma^2$$ otherwise. Index the items in $$K = \\{t_1, t_2, \\ldots, t|K|\\}$$ such that $$t_i < t_{i+1}$$. We know\n$$F(x_{t_{i+1}}) - F(x_{t_i}) \\leq -\\frac{1}{6\\eta} \\text{drift}_{t_{i+1}} + (t_{i+1} - t_i) \\gamma^2\\eta \\leq -\\frac{1}{6\\eta} \\kappa + (t_{i+1} - t_i) \\gamma^2\\eta$$. Recall by the assumption that $$\\max_y F(y) - \\min_x F(x) \\leq B$$. And hence $$-B \\leq F(x_{t|K|}) - F(x_{t_1}) \\leq -|K|6\\eta \\kappa + T \\gamma^2\\eta$$, and we know\n\nA.6 Proof of Theorem 3.9 $$|K| \\leq O(B\\eta \\kappa + T \\gamma^2\\eta^2/\\kappa) = O(B\\eta \\log^4(dMB \\rho \\gamma \\omega)/\\kappa)$$.\n\nTheorem 3.9 (Empirical). Using full batch in Algorithm 1, and setting $$\\kappa = G^{4/3}B^{1/3} (\\sqrt{d \\log(1/\\delta)})^{2/3} / M^{5/3} n\\epsilon$$,\n$$\\sigma_1 = G\\sqrt{B\\eta \\log^2(1/\\delta)/\\kappa \\log^2(ndMB/\\omega)}$$, $$\\sigma_2 = M\\sqrt{\\log^2(1/\\delta)BM/\\alpha^2} \\log^5(ndMB/\\omega)$$, Algorithm 1 is $$(\\epsilon, \\delta)$$-DP,\nand with probability at least $$1 - \\omega$$, at least one point in the output set $$\\{x_i\\}_{i\\in[T]}$$ is $$\\alpha_1$$-SOSP of FD with\n$$\\alpha_1 = O\\left(\\frac{dBGM \\log^2(1/\\delta)^{2/3} \\cdot \\log^6 nBMd}{n\\epsilon \\rho \\omega}\\right)$$.\n\nMoreover, if we run Algorithm 2 with inputs $$\\{x_i\\}_{i\\in[T]}$$, D, B, M, G, $$\\rho$$, $$\\alpha_1$$, with probability at least\n$$1 - \\omega$$, we can get an $$\\alpha_2$$-SOSP of FD with\n$$\\alpha_2 = O\\left(\\alpha_1 + G \\log(n/G\\omega) + M \\log(ndBGM/\\rho\\omega) \\sqrt{\\alpha_1}\\right)$$.\n\nProof. The privacy guarantee can be proved by composition theorems (Theorem 2.7 and Theorem 2.8) and Lemma 3.7. As for the utility, we know the $$O_1$$ and $$O_2$$ constructed in Equation (2) are first kind of $$\\sigma_1 \\sqrt{d}$$ and second kind of $$\\sigma_2 \\sqrt{d}$$ norm-subGaussian gradient oracle by Fact 2.3. Hence by Lemma 3.6, the utility $$\\alpha_1$$ satisfies that\n$$\\alpha_1 = O(\\sigma_1 \\sqrt{d} + \\sigma_2 \\sqrt{d\\kappa}) \\cdot \\log^3(BMd/\\rho\\omega)$$\n$$= O\\left(\\frac{dB\\eta \\log^2(1/\\delta)/\\kappa + M \\log^3(ndMB/\\omega) \\log^2(1/\\delta)BM \\sqrt{d\\kappa}}{n\\epsilon}\\right)$$."}]}, {"page": 20, "text": "Choosing the best \u03ba demonstrates the bound on \u03b11. The bound for \u03b12 follows from the value of \u03b11\nand Lemma 3.8. Combining the two items in Lemma 3.8, we know with probability at least 1 \u2212                                                             \u03c9,\nthe output point x of Algorithm 2 satisfies that\n           \u2225\u2207FD(x)\u2225         \u2264   \u03b11 + 32 log(2T/\u03c9)G              , and smin(\u22072FD(x)) \u2265                  \u2212\u221a    \u03c1\u03b11 \u2212     32 log(2T/\u03c9)M            .\n                                                  n\u03b5                                                                             n\u03b5\nHence we know x is an \u03b12-SOSP for \u03b12 stated in the statement.\nA.7         Proof of Lemma 3.11\nLemma 3.11. Fix a point x \u2208                       Rd. Given a set S of m samples drawn i.i.d. from the distribution\nP, then we know with probability at least 1 \u2212       G log(d/\u03c9)          \u03c9, we have                                           M log(d/\u03c9)\n         \u2225\u2207FS(x) \u2212         \u2207FP(x)\u22252 \u2264           O         \u221a  m               \u2225\u22072FS(x) \u2212          \u22072FP(x)\u2225op \u2264            O          \u221a  m          .\nProof. As for any s \u2208              S, \u2207f(x; s) \u2212          \u2207FP(x) is zero-mean nSG(G). Then the Hoeffding inequality\nfor norm-subGuassians (Lemma 2.4) demonstrates with probability at least 1 \u2212                                                         \u03c9/2, we have\n                                           G log(d/\u03c9)\n\u2225\u2207FS(x) \u2212          \u2207FP(x)\u22252 \u2264          O         \u221a m        .\n      As for the other term, we know for any s \u2208                             S, E[\u22072f(x; s) \u2212          \u22072FP(x)] = 0, and \u2225\u22072f(x; s) \u2212\n\u22072FP(x)\u2225op \u2264            2M almost surely. Hence applying Matrix Bernstein inequality (Theorem 2.6) with\n\u03c32 = 4M2m, t = O                  \u221amM log(d/\u03c9)              , we know with probability at least 1 \u2212                            \u03c9/2, \u2225\u22072FS(x) \u2212\n\u22072FP(x)\u2225op \u2264            t/m.\n      Applying the Union bound completes the proof.\nA.8         Proof of Theorem 3.12\nTheorem 3.12 (Population). Divide the dataset D into two disjoint datasets D1 and D2 of size\n\u2308n/2\u2309      and \u230an/2\u230b        respectively. Setting b1 = n\u03ba            B\u03b7  , b2 = n\u03b12   1                 log(1/\u03b4)  , \u03c32 = M\u221a        log(1/\u03b4)   and \u03ba =\n                                                                                   BM , \u03c31 = G\u221ab1\u03b5                                 b2\u03b5\nmax(G4/3B1/3 log1/3 d          n\u22121/3, (GB2/3                \u221a  d log(1/\u03b4)  )4/7  ) in Equation (3) and using them as gradient\n                M5/3                        M5/3 )6/7(           n\u03b5\noracles, Algorithm 1 with D1 is (\u03b5, \u03b4)-DP, and with probability at least 1 \u2212                                           \u03c9, at least one point in\nthe output is \u03b11-SOSP of FP with\n         \u03b11 = O         (BGM \u00b7 log d)1/3              1                                       d log(1/\u03b4)     )3/7    log3(nBMd/\u03c1\u03c9)                .\n                                                   n1/3 + (G1/7B3/7M3/7)(                         n\u03b5\n      Moreover, if we run Algorithm 2 with inputs {xi}i\u2208[T], D2, B, M, G, \u03c1, \u03b11, with probability at\nleast 1 \u2212      \u03c9, Algorithm 2 can output an \u03b12-SOSP of FP with\n                     \u03b12 = O         \u03b11 + M log(ndBGM/\u03c1\u03c9)                     \u221a  \u03b11 + G(log(n/G\u03c9)                       \u221a\n                                               \u221a  \u03c1 min(n\u03b5, n1/2)                                  n\u03b5          + log(d/\u03c9) n     )    .\nProof. We should have all samples to be fresh to avoid dependency, and hence we need\n                                                            b1 \u00b7 |K| + b2 \u00b7 T \u2264          n/2,\nwhich is satisfied by the parameter settings and Lemma 3.7. As we never reuse a sample, the\nprivacy guarantee follows directly from the Gaussian Mechanism [DR+14]. By lemma 3.6, we have\n                           \u03b11\n                log3(nBMd/\u03c1\u03c9)\n             =O(\u03c31      \u221a  d + G\u221a    \u221a log d    + \u03c32   \u221a  d\u03ba + M\u221a       \u221a \u03ba log d   )\u00b7\n                                        b1                                 b2\n                                d log(1/\u03b4)                      log(1/\u03b4)      \u221a                B\u03b7 log d                   \u221a  BM log d\n             =O(GB\u03b7            n\u03b5\u03ba              + BM2        n\u03b5\u03b12  1        20   d\u03ba + G\u221a       \u221a  n\u03ba         + M\u221a       \u03ba     \u221a  n\u03b11        ).", "md": "# Math Equations\n\nChoosing the best $$\\kappa$$ demonstrates the bound on $$\\alpha_1$$. The bound for $$\\alpha_2$$ follows from the value of $$\\alpha_1$$ and Lemma 3.8. Combining the two items in Lemma 3.8, we know with probability at least 1 - $$\\omega$$, the output point x of Algorithm 2 satisfies that\n\n$$\n\\| \\nabla F_D(x) \\| \\leq \\alpha_1 + 32 \\log(2T/\\omega)G, \\quad \\text{and} \\quad s_{\\min}(\\nabla^2 F_D(x)) \\geq -\\sqrt{\\frac{\\rho \\alpha_1 - 32 \\log(2T/\\omega)M}{n\\epsilon}}.\n$$\n\nHence we know x is an $$\\alpha_2$$-SOSP for $$\\alpha_2$$ stated in the statement.\n\n### Proof of Lemma 3.11\n\nLemma 3.11. Fix a point x $$\\in \\mathbb{R}^d$$. Given a set S of m samples drawn i.i.d. from the distribution P, then we know with probability at least 1 - $$G \\log(d/\\omega)$$, we have\n\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O\\left( \\sqrt{m} \\right), \\quad \\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq O\\left( \\sqrt{m} \\right).\n$$\n\nProof. As for any $$s \\in S$$, $$\\nabla f(x; s) - \\nabla F_P(x)$$ is zero-mean nSG(G). Then the Hoeffding inequality for norm-subGaussians (Lemma 2.4) demonstrates with probability at least 1 - $$\\omega/2$$, we have\n\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O\\left( \\sqrt{m} \\right).\n$$\n\nAs for the other term, we know for any $$s \\in S$$, $$E[\\nabla^2 f(x; s) - \\nabla^2 F_P(x)] = 0$$, and $$\\| \\nabla^2 f(x; s) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq 2M$$ almost surely. Hence applying Matrix Bernstein inequality (Theorem 2.6) with $$\\sigma^2 = 4M^2m$$, $$t = O\\left( \\sqrt{m}M \\log(d/\\omega) \\right)$$, we know with probability at least 1 - $$\\omega/2$$, $$\\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq t/m$$. Applying the Union bound completes the proof.\n\n### Proof of Theorem 3.12\n\nTheorem 3.12 (Population). Divide the dataset D into two disjoint datasets D1 and D2 of size $$\\lceil n/2 \\rceil$$ and $$\\lfloor n/2 \\rfloor$$ respectively. Setting $$b_1 = n\\kappa B\\eta$$, $$b_2 = n\\alpha_2 \\left( 1 + \\log(1/\\delta) \\right)$$, $$\\sigma_2 = M\\sqrt{\\log(1/\\delta)}$$ and $$\\kappa = \\frac{BM}{G\\sqrt{b_1\\epsilon}}$$, $$\\sigma_1 = \\frac{G}{\\sqrt{b_1\\epsilon}}$$ max$$\\left( G^{4/3}B^{1/3} \\log^{1/3} d \\cdot n^{-1/3}, \\left( G^{B^{2/3}} \\sqrt{d \\log(1/\\delta)} \\right)^{4/7} \\right)$$ in Equation (3) and using them as gradient oracles, Algorithm 1 with D1 is $$(\\epsilon, \\delta)$$-DP, and with probability at least 1 - $$\\omega$$, at least one point in the output is $$\\alpha_1$$-SOSP of F_P with\n\n$$\n\\alpha_1 = O\\left( (BGM \\cdot \\log d)^{1/3} \\cdot \\frac{1}{n^{1/3} + \\left( G^{1/7}B^{3/7}M^{3/7} \\right) \\cdot n\\epsilon} \\right).\n$$\n\nMoreover, if we run Algorithm 2 with inputs $$\\{x_i\\}_{i \\in [T]}$$, D2, B, M, G, $$\\rho$$, $$\\alpha_1$$, with probability at least 1 - $$\\omega$$, Algorithm 2 can output an $$\\alpha_2$$-SOSP of F_P with\n\n$$\n\\alpha_2 = O\\left( \\alpha_1 + M \\log(ndBGM/\\rho\\omega) \\sqrt{\\alpha_1 + G\\left( \\log(n/G\\omega) \\sqrt{\\rho \\min(n\\epsilon, n^{1/2})} + \\log(d/\\omega) n \\right)} \\right).\n$$\n\nProof. We should have all samples to be fresh to avoid dependency, and hence we need\n\n$$\nb_1 \\cdot |K| + b_2 \\cdot T \\leq n/2,\n$$\n\nwhich is satisfied by the parameter settings and Lemma 3.7. As we never reuse a sample, the privacy guarantee follows directly from the Gaussian Mechanism [DR+14]. By lemma 3.6, we have\n\n$$\n\\frac{\\alpha_1}{\\log^3(nBMd/\\rho\\omega)} = O\\left( \\sigma_1 \\sqrt{d} + G\\sqrt{\\log d} + \\sigma_2 \\sqrt{d\\kappa} + M\\sqrt{\\kappa \\log d} \\right).\n$$\n\n$$\n= O\\left( GB\\eta n\\epsilon\\kappa + BM^2 n\\epsilon\\alpha_2 \\left( 1 + 20 \\right) d\\kappa + G\\sqrt{n\\kappa} + M\\sqrt{\\kappa \\sqrt{n\\alpha_1}} \\right).\n$$", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations", "md": "# Math Equations"}, {"type": "text", "value": "Choosing the best $$\\kappa$$ demonstrates the bound on $$\\alpha_1$$. The bound for $$\\alpha_2$$ follows from the value of $$\\alpha_1$$ and Lemma 3.8. Combining the two items in Lemma 3.8, we know with probability at least 1 - $$\\omega$$, the output point x of Algorithm 2 satisfies that\n\n$$\n\\| \\nabla F_D(x) \\| \\leq \\alpha_1 + 32 \\log(2T/\\omega)G, \\quad \\text{and} \\quad s_{\\min}(\\nabla^2 F_D(x)) \\geq -\\sqrt{\\frac{\\rho \\alpha_1 - 32 \\log(2T/\\omega)M}{n\\epsilon}}.\n$$\n\nHence we know x is an $$\\alpha_2$$-SOSP for $$\\alpha_2$$ stated in the statement.", "md": "Choosing the best $$\\kappa$$ demonstrates the bound on $$\\alpha_1$$. The bound for $$\\alpha_2$$ follows from the value of $$\\alpha_1$$ and Lemma 3.8. Combining the two items in Lemma 3.8, we know with probability at least 1 - $$\\omega$$, the output point x of Algorithm 2 satisfies that\n\n$$\n\\| \\nabla F_D(x) \\| \\leq \\alpha_1 + 32 \\log(2T/\\omega)G, \\quad \\text{and} \\quad s_{\\min}(\\nabla^2 F_D(x)) \\geq -\\sqrt{\\frac{\\rho \\alpha_1 - 32 \\log(2T/\\omega)M}{n\\epsilon}}.\n$$\n\nHence we know x is an $$\\alpha_2$$-SOSP for $$\\alpha_2$$ stated in the statement."}, {"type": "heading", "lvl": 3, "value": "Proof of Lemma 3.11", "md": "### Proof of Lemma 3.11"}, {"type": "text", "value": "Lemma 3.11. Fix a point x $$\\in \\mathbb{R}^d$$. Given a set S of m samples drawn i.i.d. from the distribution P, then we know with probability at least 1 - $$G \\log(d/\\omega)$$, we have\n\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O\\left( \\sqrt{m} \\right), \\quad \\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq O\\left( \\sqrt{m} \\right).\n$$\n\nProof. As for any $$s \\in S$$, $$\\nabla f(x; s) - \\nabla F_P(x)$$ is zero-mean nSG(G). Then the Hoeffding inequality for norm-subGaussians (Lemma 2.4) demonstrates with probability at least 1 - $$\\omega/2$$, we have\n\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O\\left( \\sqrt{m} \\right).\n$$\n\nAs for the other term, we know for any $$s \\in S$$, $$E[\\nabla^2 f(x; s) - \\nabla^2 F_P(x)] = 0$$, and $$\\| \\nabla^2 f(x; s) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq 2M$$ almost surely. Hence applying Matrix Bernstein inequality (Theorem 2.6) with $$\\sigma^2 = 4M^2m$$, $$t = O\\left( \\sqrt{m}M \\log(d/\\omega) \\right)$$, we know with probability at least 1 - $$\\omega/2$$, $$\\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq t/m$$. Applying the Union bound completes the proof.", "md": "Lemma 3.11. Fix a point x $$\\in \\mathbb{R}^d$$. Given a set S of m samples drawn i.i.d. from the distribution P, then we know with probability at least 1 - $$G \\log(d/\\omega)$$, we have\n\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O\\left( \\sqrt{m} \\right), \\quad \\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq O\\left( \\sqrt{m} \\right).\n$$\n\nProof. As for any $$s \\in S$$, $$\\nabla f(x; s) - \\nabla F_P(x)$$ is zero-mean nSG(G). Then the Hoeffding inequality for norm-subGaussians (Lemma 2.4) demonstrates with probability at least 1 - $$\\omega/2$$, we have\n\n$$\n\\| \\nabla F_S(x) - \\nabla F_P(x) \\|_2 \\leq O\\left( \\sqrt{m} \\right).\n$$\n\nAs for the other term, we know for any $$s \\in S$$, $$E[\\nabla^2 f(x; s) - \\nabla^2 F_P(x)] = 0$$, and $$\\| \\nabla^2 f(x; s) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq 2M$$ almost surely. Hence applying Matrix Bernstein inequality (Theorem 2.6) with $$\\sigma^2 = 4M^2m$$, $$t = O\\left( \\sqrt{m}M \\log(d/\\omega) \\right)$$, we know with probability at least 1 - $$\\omega/2$$, $$\\| \\nabla^2 F_S(x) - \\nabla^2 F_P(x) \\|_{\\text{op}} \\leq t/m$$. Applying the Union bound completes the proof."}, {"type": "heading", "lvl": 3, "value": "Proof of Theorem 3.12", "md": "### Proof of Theorem 3.12"}, {"type": "text", "value": "Theorem 3.12 (Population). Divide the dataset D into two disjoint datasets D1 and D2 of size $$\\lceil n/2 \\rceil$$ and $$\\lfloor n/2 \\rfloor$$ respectively. Setting $$b_1 = n\\kappa B\\eta$$, $$b_2 = n\\alpha_2 \\left( 1 + \\log(1/\\delta) \\right)$$, $$\\sigma_2 = M\\sqrt{\\log(1/\\delta)}$$ and $$\\kappa = \\frac{BM}{G\\sqrt{b_1\\epsilon}}$$, $$\\sigma_1 = \\frac{G}{\\sqrt{b_1\\epsilon}}$$ max$$\\left( G^{4/3}B^{1/3} \\log^{1/3} d \\cdot n^{-1/3}, \\left( G^{B^{2/3}} \\sqrt{d \\log(1/\\delta)} \\right)^{4/7} \\right)$$ in Equation (3) and using them as gradient oracles, Algorithm 1 with D1 is $$(\\epsilon, \\delta)$$-DP, and with probability at least 1 - $$\\omega$$, at least one point in the output is $$\\alpha_1$$-SOSP of F_P with\n\n$$\n\\alpha_1 = O\\left( (BGM \\cdot \\log d)^{1/3} \\cdot \\frac{1}{n^{1/3} + \\left( G^{1/7}B^{3/7}M^{3/7} \\right) \\cdot n\\epsilon} \\right).\n$$\n\nMoreover, if we run Algorithm 2 with inputs $$\\{x_i\\}_{i \\in [T]}$$, D2, B, M, G, $$\\rho$$, $$\\alpha_1$$, with probability at least 1 - $$\\omega$$, Algorithm 2 can output an $$\\alpha_2$$-SOSP of F_P with\n\n$$\n\\alpha_2 = O\\left( \\alpha_1 + M \\log(ndBGM/\\rho\\omega) \\sqrt{\\alpha_1 + G\\left( \\log(n/G\\omega) \\sqrt{\\rho \\min(n\\epsilon, n^{1/2})} + \\log(d/\\omega) n \\right)} \\right).\n$$\n\nProof. We should have all samples to be fresh to avoid dependency, and hence we need\n\n$$\nb_1 \\cdot |K| + b_2 \\cdot T \\leq n/2,\n$$\n\nwhich is satisfied by the parameter settings and Lemma 3.7. As we never reuse a sample, the privacy guarantee follows directly from the Gaussian Mechanism [DR+14]. By lemma 3.6, we have\n\n$$\n\\frac{\\alpha_1}{\\log^3(nBMd/\\rho\\omega)} = O\\left( \\sigma_1 \\sqrt{d} + G\\sqrt{\\log d} + \\sigma_2 \\sqrt{d\\kappa} + M\\sqrt{\\kappa \\log d} \\right).\n$$\n\n$$\n= O\\left( GB\\eta n\\epsilon\\kappa + BM^2 n\\epsilon\\alpha_2 \\left( 1 + 20 \\right) d\\kappa + G\\sqrt{n\\kappa} + M\\sqrt{\\kappa \\sqrt{n\\alpha_1}} \\right).\n$$", "md": "Theorem 3.12 (Population). Divide the dataset D into two disjoint datasets D1 and D2 of size $$\\lceil n/2 \\rceil$$ and $$\\lfloor n/2 \\rfloor$$ respectively. Setting $$b_1 = n\\kappa B\\eta$$, $$b_2 = n\\alpha_2 \\left( 1 + \\log(1/\\delta) \\right)$$, $$\\sigma_2 = M\\sqrt{\\log(1/\\delta)}$$ and $$\\kappa = \\frac{BM}{G\\sqrt{b_1\\epsilon}}$$, $$\\sigma_1 = \\frac{G}{\\sqrt{b_1\\epsilon}}$$ max$$\\left( G^{4/3}B^{1/3} \\log^{1/3} d \\cdot n^{-1/3}, \\left( G^{B^{2/3}} \\sqrt{d \\log(1/\\delta)} \\right)^{4/7} \\right)$$ in Equation (3) and using them as gradient oracles, Algorithm 1 with D1 is $$(\\epsilon, \\delta)$$-DP, and with probability at least 1 - $$\\omega$$, at least one point in the output is $$\\alpha_1$$-SOSP of F_P with\n\n$$\n\\alpha_1 = O\\left( (BGM \\cdot \\log d)^{1/3} \\cdot \\frac{1}{n^{1/3} + \\left( G^{1/7}B^{3/7}M^{3/7} \\right) \\cdot n\\epsilon} \\right).\n$$\n\nMoreover, if we run Algorithm 2 with inputs $$\\{x_i\\}_{i \\in [T]}$$, D2, B, M, G, $$\\rho$$, $$\\alpha_1$$, with probability at least 1 - $$\\omega$$, Algorithm 2 can output an $$\\alpha_2$$-SOSP of F_P with\n\n$$\n\\alpha_2 = O\\left( \\alpha_1 + M \\log(ndBGM/\\rho\\omega) \\sqrt{\\alpha_1 + G\\left( \\log(n/G\\omega) \\sqrt{\\rho \\min(n\\epsilon, n^{1/2})} + \\log(d/\\omega) n \\right)} \\right).\n$$\n\nProof. We should have all samples to be fresh to avoid dependency, and hence we need\n\n$$\nb_1 \\cdot |K| + b_2 \\cdot T \\leq n/2,\n$$\n\nwhich is satisfied by the parameter settings and Lemma 3.7. As we never reuse a sample, the privacy guarantee follows directly from the Gaussian Mechanism [DR+14]. By lemma 3.6, we have\n\n$$\n\\frac{\\alpha_1}{\\log^3(nBMd/\\rho\\omega)} = O\\left( \\sigma_1 \\sqrt{d} + G\\sqrt{\\log d} + \\sigma_2 \\sqrt{d\\kappa} + M\\sqrt{\\kappa \\log d} \\right).\n$$\n\n$$\n= O\\left( GB\\eta n\\epsilon\\kappa + BM^2 n\\epsilon\\alpha_2 \\left( 1 + 20 \\right) d\\kappa + G\\sqrt{n\\kappa} + M\\sqrt{\\kappa \\sqrt{n\\alpha_1}} \\right).\n$$"}]}, {"page": 21, "text": "      Setting \u03ba = max(G4/3B1/3 log1/3 d                 (n)\u22121/3, (GB2/3                \u221a  d log(1/\u03b4)   )4/7), we get\n                                         M5/3                           M5/3 )6/7(           n\u03b5\n          \u03b11 = O         (BGM log d)1/3              1                                       d log(1/\u03b4)     )3/7    log3(nBMd/\u03c1\u03c9)                .\n                                                  n1/3 + (G1/7B3/7M3/7)(                         n\u03b5\n      Then we use the other half fresh samples D2 to find the point in the set by Algorithm 2. By\nLemma 3.8 and Lemma 3.11, we know with probability at least 1 \u2212                                                   \u03c9, for some large enough\nconstant C > 0, the output point x of Algorithm 2 satisfies that\n                                                                                                      \u221a\n                                    \u2225\u2207FP(x)\u22252 \u2264\u03b11 + G(32 log(2T/\u03c9)            n\u03b5           + C log(dn/\u03c9) n       \u221a ),\n                             smin(\u22072FP(x)) \u2265              \u2212  \u221a\u03c1\u03b11 \u2212        M(32 log(2T/\u03c9)             + C log(dn/\u03c9))\n                                                                                        n\u03b5                          n\nHence we know x is an \u03b12-SOSP for \u03b12 stated in the statement. The privacy guarantee follows\nfrom Basic composition and Lemma 3.8.\nB        Omitted proof of Section 4\nB.1        Proof of Lemma 4.5\nLemma 4.5 (Generalization error bound). Let \u03c0D \u221d                                      exp(\u2212\u03b2(FD(x) + \u00b5            2 \u2225x\u22252 2)). Then we have\n                                               E                                                              ).\n                                           D,x\u223c\u03c0D[FP(x) \u2212           FD(x)] \u2264        O(G2 exp(\u03b2GD)n\u00b5\nProof. We know how to bound the KL divergence by LSI:\n                                                KL(\u03c0D, \u03c0D\u2032) :=               log d\u03c0D\n                                                                                   d\u03c0D\u2032 d\u03c0D\n                                                                      \u2264CLSI       E   \u2207    log d\u03c0D        2\n                                                                            2    \u03c0D              d\u03c0D\u2032     2\n                                                                      \u22642CLSIG2\u03b22/n2.\nLSI can lead to Talagrand transportation inequality [Theorem 1 in [OV00]], i.e.,\n                                      W2(\u03c0D, \u03c0D\u2032) \u2272               CLSI \u00b7 KL(\u03c0D, \u03c0D\u2032) = CLSIG\u03b2/n.\n      The generalization error is bounded by O(CLSIG2\u03b2/n). Using Holley-Stroock perturbation, we\nknow CLSI(\u03c0D) \u2264                exp(\u03b2GD)      and hence the W2 distance between \u03c0D and \u03c0D\u2032 can be bounded by\n                                   \u03b2\u00b5\nO(G exp(\u03b2GD)         ). The statement follows the Lipschitzness constant and Lemma 4.4.\n           n\u00b5\nB.2        Proof of Theorem 4.6\nTheorem 4.6 (Risk bound). We are given \u03b5, \u03b4 \u2208                                 (0, 1/2). Sampling from exp(\u2212\u03b2(FD(x)+ \u00b5                          2 \u2225x\u22252  2))\n                        \u03b5 log(nd)                  d\nwith \u03b2 = O(         GD\u221alog(1/\u03b4))), \u00b5 =           D2\u03b2 is (\u03b5, \u03b4)-DP. The empirical risk and population risk are bounded\nby O(GD         d\u00b7log log(n)\u221alog(1/\u03b4)).\n                        \u03b5 log(nd)\nProof. Denote \u03c0(x) \u221d                exp(\u2212\u03b2(FD(x)+ \u00b5                   2)). By Lemma 4.2, we know CLSI(\u03c0) \u2264                            1\nPlugging in the parameters and applying Theorem 4.1, we get   2 \u2225x\u22252                                                                 \u03b2\u00b5 \u00b7exp(\u03b2GD).\n                      2G\u03b2      \u00b7    exp(\u03b2GD)             3 log(1/\u03b4) = O(1)GD\u03b2          \u221a         exp(\u03b2GD) log(1/\u03b4) \u2264                1\n                         n                \u03b2\u00b5                                         n    d\n                                                                            21", "md": "Setting $$\\kappa = \\max\\left(\\frac{G}{3}B^{1/3}\\log^{1/3}d(n)^{-1/3}, \\left(\\frac{GB^{2/3}\\sqrt{d}\\log(1/\\delta)}\\right)^{4/7}\\right)$$, we get\n\n$$\\alpha_1 = O\\left(\\frac{BGM\\log d}{3}1 + \\frac{\\log(1/\\delta)}{3}\\right)\\log^3(nBMd/\\rho\\omega)$$\n\n$$n^{1/3} + \\left(\\frac{G^{1/7}B^{3/7}M^{3/7}}{n\\epsilon}\\right)\\left(n\\epsilon\\right)$$\n\nThen we use the other half fresh samples D2 to find the point in the set by Algorithm 2. By Lemma 3.8 and Lemma 3.11, we know with probability at least 1 - $\\omega$, for some large enough constant C > 0, the output point x of Algorithm 2 satisfies that\n\n$$\\|\\nabla FP(x)\\|_2 \\leq \\alpha_1 + G\\left(\\frac{32\\log(2T/\\omega)}{n\\epsilon} + C\\log(dn/\\omega)\\sqrt{n}\\right)$$\n\n$$s_{\\min}(\\nabla^2FP(x)) \\geq -\\sqrt{\\rho}\\alpha_1 - M\\left(\\frac{32\\log(2T/\\omega)}{n\\epsilon} + C\\log(dn/\\omega)\\right)\\sqrt{n}$$\n\nHence we know x is an $\\alpha_2$-SOSP for $\\alpha_2$ stated in the statement. The privacy guarantee follows from Basic composition and Lemma 3.8.\n\nB Omitted proof of Section 4\n\nB.1 Proof of Lemma 4.5\n\nLemma 4.5 (Generalization error bound). Let $$\\pi_D \\propto \\exp\\left(-\\beta(F_D(x) + \\mu 2\\|x\\|_2^2)\\right)$$. Then we have\n\n$$E_{D,x\\sim\\pi_D}[FP(x) - FD(x)] \\leq O(G^2\\exp(\\beta GD)n\\mu)$$\n\nProof. We know how to bound the KL divergence by LSI:\n\n$$KL(\\pi_D, \\pi_{D'}) := \\log\\frac{d\\pi_D}{d\\pi_{D'}} \\leq CLSI E_{\\pi_D} \\left(\\nabla\\log\\frac{d\\pi_D}{d\\pi_{D'}}\\right)^2 \\leq 2CLSIG^2\\beta^2/n^2$$\n\nLSI can lead to Talagrand transportation inequality [Theorem 1 in [OV00]], i.e.,\n\n$$W_2(\\pi_D, \\pi_{D'}) \\lesssim CLSI \\cdot KL(\\pi_D, \\pi_{D'}) = CLSIG\\beta/n$$\n\nThe generalization error is bounded by $$O(CLSIG^2\\beta/n)$$. Using Holley-Stroock perturbation, we know $$CLSI(\\pi_D) \\leq \\exp(\\beta GD)$$ and hence the $$W_2$$ distance between $$\\pi_D$$ and $$\\pi_{D'}$$ can be bounded by\n\n$$O(G\\exp(\\beta GD))$$. The statement follows the Lipschitzness constant and Lemma 4.4.\n\nB.2 Proof of Theorem 4.6\n\nTheorem 4.6 (Risk bound). We are given $$\\epsilon, \\delta \\in (0, 1/2)$$. Sampling from $$\\exp(-\\beta(F_D(x)+ \\mu 2\\|x\\|_2^2))$$\n\nwith $$\\beta = O(GD\\sqrt{\\log(1/\\delta)})$$, $$\\mu = D2\\beta$$ is $$(\\epsilon, \\delta)$$-DP. The empirical risk and population risk are bounded by $$O(GD\\frac{d\\cdot\\log\\log(n)\\sqrt{\\log(1/\\delta)}}{\\epsilon\\log(nd)})$$.\n\nProof. Denote $$\\pi(x) \\propto \\exp(-\\beta(F_D(x)+ \\mu 2))$$. By Lemma 4.2, we know $$CLSI(\\pi) \\leq 1$$\n\nPlugging in the parameters and applying Theorem 4.1, we get $$\\frac{2G\\beta}{n}\\cdot\\exp(\\beta GD)\\frac{3\\log(1/\\delta)}{\\beta\\mu} = O(1)GD\\beta\\sqrt{\\exp(\\beta GD)\\log(1/\\delta)} \\leq 1$$", "images": [], "items": [{"type": "text", "value": "Setting $$\\kappa = \\max\\left(\\frac{G}{3}B^{1/3}\\log^{1/3}d(n)^{-1/3}, \\left(\\frac{GB^{2/3}\\sqrt{d}\\log(1/\\delta)}\\right)^{4/7}\\right)$$, we get\n\n$$\\alpha_1 = O\\left(\\frac{BGM\\log d}{3}1 + \\frac{\\log(1/\\delta)}{3}\\right)\\log^3(nBMd/\\rho\\omega)$$\n\n$$n^{1/3} + \\left(\\frac{G^{1/7}B^{3/7}M^{3/7}}{n\\epsilon}\\right)\\left(n\\epsilon\\right)$$\n\nThen we use the other half fresh samples D2 to find the point in the set by Algorithm 2. By Lemma 3.8 and Lemma 3.11, we know with probability at least 1 - $\\omega$, for some large enough constant C > 0, the output point x of Algorithm 2 satisfies that\n\n$$\\|\\nabla FP(x)\\|_2 \\leq \\alpha_1 + G\\left(\\frac{32\\log(2T/\\omega)}{n\\epsilon} + C\\log(dn/\\omega)\\sqrt{n}\\right)$$\n\n$$s_{\\min}(\\nabla^2FP(x)) \\geq -\\sqrt{\\rho}\\alpha_1 - M\\left(\\frac{32\\log(2T/\\omega)}{n\\epsilon} + C\\log(dn/\\omega)\\right)\\sqrt{n}$$\n\nHence we know x is an $\\alpha_2$-SOSP for $\\alpha_2$ stated in the statement. The privacy guarantee follows from Basic composition and Lemma 3.8.\n\nB Omitted proof of Section 4\n\nB.1 Proof of Lemma 4.5\n\nLemma 4.5 (Generalization error bound). Let $$\\pi_D \\propto \\exp\\left(-\\beta(F_D(x) + \\mu 2\\|x\\|_2^2)\\right)$$. Then we have\n\n$$E_{D,x\\sim\\pi_D}[FP(x) - FD(x)] \\leq O(G^2\\exp(\\beta GD)n\\mu)$$\n\nProof. We know how to bound the KL divergence by LSI:\n\n$$KL(\\pi_D, \\pi_{D'}) := \\log\\frac{d\\pi_D}{d\\pi_{D'}} \\leq CLSI E_{\\pi_D} \\left(\\nabla\\log\\frac{d\\pi_D}{d\\pi_{D'}}\\right)^2 \\leq 2CLSIG^2\\beta^2/n^2$$\n\nLSI can lead to Talagrand transportation inequality [Theorem 1 in [OV00]], i.e.,\n\n$$W_2(\\pi_D, \\pi_{D'}) \\lesssim CLSI \\cdot KL(\\pi_D, \\pi_{D'}) = CLSIG\\beta/n$$\n\nThe generalization error is bounded by $$O(CLSIG^2\\beta/n)$$. Using Holley-Stroock perturbation, we know $$CLSI(\\pi_D) \\leq \\exp(\\beta GD)$$ and hence the $$W_2$$ distance between $$\\pi_D$$ and $$\\pi_{D'}$$ can be bounded by\n\n$$O(G\\exp(\\beta GD))$$. The statement follows the Lipschitzness constant and Lemma 4.4.\n\nB.2 Proof of Theorem 4.6\n\nTheorem 4.6 (Risk bound). We are given $$\\epsilon, \\delta \\in (0, 1/2)$$. Sampling from $$\\exp(-\\beta(F_D(x)+ \\mu 2\\|x\\|_2^2))$$\n\nwith $$\\beta = O(GD\\sqrt{\\log(1/\\delta)})$$, $$\\mu = D2\\beta$$ is $$(\\epsilon, \\delta)$$-DP. The empirical risk and population risk are bounded by $$O(GD\\frac{d\\cdot\\log\\log(n)\\sqrt{\\log(1/\\delta)}}{\\epsilon\\log(nd)})$$.\n\nProof. Denote $$\\pi(x) \\propto \\exp(-\\beta(F_D(x)+ \\mu 2))$$. By Lemma 4.2, we know $$CLSI(\\pi) \\leq 1$$\n\nPlugging in the parameters and applying Theorem 4.1, we get $$\\frac{2G\\beta}{n}\\cdot\\exp(\\beta GD)\\frac{3\\log(1/\\delta)}{\\beta\\mu} = O(1)GD\\beta\\sqrt{\\exp(\\beta GD)\\log(1/\\delta)} \\leq 1$$", "md": "Setting $$\\kappa = \\max\\left(\\frac{G}{3}B^{1/3}\\log^{1/3}d(n)^{-1/3}, \\left(\\frac{GB^{2/3}\\sqrt{d}\\log(1/\\delta)}\\right)^{4/7}\\right)$$, we get\n\n$$\\alpha_1 = O\\left(\\frac{BGM\\log d}{3}1 + \\frac{\\log(1/\\delta)}{3}\\right)\\log^3(nBMd/\\rho\\omega)$$\n\n$$n^{1/3} + \\left(\\frac{G^{1/7}B^{3/7}M^{3/7}}{n\\epsilon}\\right)\\left(n\\epsilon\\right)$$\n\nThen we use the other half fresh samples D2 to find the point in the set by Algorithm 2. By Lemma 3.8 and Lemma 3.11, we know with probability at least 1 - $\\omega$, for some large enough constant C > 0, the output point x of Algorithm 2 satisfies that\n\n$$\\|\\nabla FP(x)\\|_2 \\leq \\alpha_1 + G\\left(\\frac{32\\log(2T/\\omega)}{n\\epsilon} + C\\log(dn/\\omega)\\sqrt{n}\\right)$$\n\n$$s_{\\min}(\\nabla^2FP(x)) \\geq -\\sqrt{\\rho}\\alpha_1 - M\\left(\\frac{32\\log(2T/\\omega)}{n\\epsilon} + C\\log(dn/\\omega)\\right)\\sqrt{n}$$\n\nHence we know x is an $\\alpha_2$-SOSP for $\\alpha_2$ stated in the statement. The privacy guarantee follows from Basic composition and Lemma 3.8.\n\nB Omitted proof of Section 4\n\nB.1 Proof of Lemma 4.5\n\nLemma 4.5 (Generalization error bound). Let $$\\pi_D \\propto \\exp\\left(-\\beta(F_D(x) + \\mu 2\\|x\\|_2^2)\\right)$$. Then we have\n\n$$E_{D,x\\sim\\pi_D}[FP(x) - FD(x)] \\leq O(G^2\\exp(\\beta GD)n\\mu)$$\n\nProof. We know how to bound the KL divergence by LSI:\n\n$$KL(\\pi_D, \\pi_{D'}) := \\log\\frac{d\\pi_D}{d\\pi_{D'}} \\leq CLSI E_{\\pi_D} \\left(\\nabla\\log\\frac{d\\pi_D}{d\\pi_{D'}}\\right)^2 \\leq 2CLSIG^2\\beta^2/n^2$$\n\nLSI can lead to Talagrand transportation inequality [Theorem 1 in [OV00]], i.e.,\n\n$$W_2(\\pi_D, \\pi_{D'}) \\lesssim CLSI \\cdot KL(\\pi_D, \\pi_{D'}) = CLSIG\\beta/n$$\n\nThe generalization error is bounded by $$O(CLSIG^2\\beta/n)$$. Using Holley-Stroock perturbation, we know $$CLSI(\\pi_D) \\leq \\exp(\\beta GD)$$ and hence the $$W_2$$ distance between $$\\pi_D$$ and $$\\pi_{D'}$$ can be bounded by\n\n$$O(G\\exp(\\beta GD))$$. The statement follows the Lipschitzness constant and Lemma 4.4.\n\nB.2 Proof of Theorem 4.6\n\nTheorem 4.6 (Risk bound). We are given $$\\epsilon, \\delta \\in (0, 1/2)$$. Sampling from $$\\exp(-\\beta(F_D(x)+ \\mu 2\\|x\\|_2^2))$$\n\nwith $$\\beta = O(GD\\sqrt{\\log(1/\\delta)})$$, $$\\mu = D2\\beta$$ is $$(\\epsilon, \\delta)$$-DP. The empirical risk and population risk are bounded by $$O(GD\\frac{d\\cdot\\log\\log(n)\\sqrt{\\log(1/\\delta)}}{\\epsilon\\log(nd)})$$.\n\nProof. Denote $$\\pi(x) \\propto \\exp(-\\beta(F_D(x)+ \\mu 2))$$. By Lemma 4.2, we know $$CLSI(\\pi) \\leq 1$$\n\nPlugging in the parameters and applying Theorem 4.1, we get $$\\frac{2G\\beta}{n}\\cdot\\exp(\\beta GD)\\frac{3\\log(1/\\delta)}{\\beta\\mu} = O(1)GD\\beta\\sqrt{\\exp(\\beta GD)\\log(1/\\delta)} \\leq 1$$"}]}, {"page": 22, "text": "and hence prove the privacy guarantee.\n      As for the empirical risk bound, by Lemma 4.3, we know\n                            E                           2) \u2212    min                               2) \u2272    d log(\u03b2GD/d)          ,\nand we know                x\u223c\u03c0(FD(x) + \u00b5        2 \u2225x\u22252         x\u2217\u2208K(FD(x\u2217) + \u00b5          2 \u2225x\u2217\u22252                     \u03b2\n                                        E                                                                 + \u00b5D2.\n                                      x\u223c\u03c0 FD(x) \u2212          min\n                                                           x\u2217\u2208K FD(x\u2217) \u2272           d log(\u03b2GD/d)\n                                                                                            \u03b2\nReplacing the value of \u03b2 achieves the empirical risk bound.\n      As for the population risk, we have\n                   E\n                  x\u223c\u03c0 FP(x) \u2212         min\n                                      y\u2217\u2208K FP(y\u2217)\n              = E x\u223c\u03c0[FP(x) \u2212         FD(x)] + E[FD(x) \u2212               min\n                                                                       x\u2217\u2208K FD(x\u2217)] + E[ min      x\u2217\u2208D FD(x\u2217) \u2212           min\n              \u2264    E                                                                                                      y\u2217\u2208K FP(y\u2217)]\n                  x\u223c\u03c0[FP(x) \u2212         FD(x)] + E[FD(x) \u2212               min\n                                                                       x\u2217\u2208K FD(x\u2217)].\nWe can bound Ex\u223c\u03c0[FP(x) \u2212                         FD(x)] \u2264         O(G2 exp(\u03b2GD)) \u2264              O(      GD\u03b5 log(n)\n                                                                              n\u00b5                     n1\u2212c   d\u221alog(1/\u03b4)) by Lemma 4.5 for\nan arbitrarily small constant c > 0.                          Hence the empirical risk is dominated term compared to\nE  x\u223c\u03c0[FP(x) \u2212         FD(x)], and we complete the proof.\nB.3        Implementation\nWe rewrite them below: Let                    F(x) := F(x) + r(x) where r(x) is some regularizer, and F = Ei\u2208I fi\nis the expectation of a family of G-Lipschitz functions.\nAlgorithm 3 AlternateSample, [LST21]\n  1: Input: Function              F, initial point x0 \u223c             \u03c00, step size \u03b7\n  2: for t \u2208      [T  ] do\n  3:      yt \u2190     xt\u22121 + \u221a      \u03b7\u03b6 where \u03b6 \u223c          N  (0, Id)\n  4:      Sample xt \u2190           exp(\u2212    F(x) \u2212        1              2)\n  5: end for                                          2\u03b7 \u2225x \u2212    yt\u22252\n  6: Output: xT\nTheorem B.1 (Guarantee of Algorithm 3, [CCSW22]). Let K \u2282                                                 Rd be a convex set of diameter\nD, and       F : K \u2192       R, and \u03c0 \u221d         exp(\u2212     F  ) satisfi  es LSI with constant CLSI. Then set \u03b7 \u2265                           0, we have\n                                                                               Rq(\u03c00, \u03c0)\n                                                       Rq(\u03c0t, \u03c0) \u2264        (1 + \u03b7/CLSI)2t/q ,\nwhere Rq(\u03c0\u2032, \u03c0) is the q-th order of Renyi divergence between \u03c0\u2032 and \u03c0.\n      To get a sample from exp(\u2212                   F  (x) \u2212      1               2), we use the rejection sampler from [GLL22],\nwhose guarantee is stated below:                                2\u03b7 \u2225x \u2212     yt\u22252\nLemma B.2 (Rejection Sampler, [GLL22]). If the step size \u03b7 \u2272                                          G\u22122 log\u22121(1/\u03b4inner) and the inner\naccuracy \u03b4inner \u2208            (0, 1/2), there is an algorithm that can return a random point x that has \u03b4inner\ntotal variation distance to the distribution proportional to exp(\u2212                                   F(x) \u2212       1             2). Moreover, the\nalgorithm accesses O(1) different fi function values and O(1) samples from the density proportional              2\u03b7 \u2225x \u2212    y\u22252\nto exp(\u2212r(x) \u2212             1             2).\n                          2\u03b7 \u2225x \u2212    y\u22252                                    22", "md": "# Math Equations and Text\n\n## Math Equations and Text\n\nand hence prove the privacy guarantee.\n\nAs for the empirical risk bound, by Lemma 4.3, we know\n\n$$\nE\\left[2\\right] - \\min\\left[2\\right] \\lesssim d \\log\\left(\\beta GD/d\\right),\n$$\nand we know\n\n$$\nx \\sim \\pi\\left(FD(x) + \\mu\\right)^2 \\left\\|x\\right\\|^2 x^* \\in K\\left(FD(x^*) + \\mu\\right)^2 \\left\\|x^*\\right\\|^2 \\beta\n$$\n$$\nE\\left[\\right] + \\mu D^2.\n$$\nReplacing the value of \u03b2 achieves the empirical risk bound.\n\nAs for the population risk, we have\n\n$$\nE\\left[x \\sim \\pi FP(x) - \\min y^* \\in K FP(y^*)\\right] = E\\left[x \\sim \\pi\\left[FP(x) - FD(x)\\right] + E\\left[FD(x) - \\min x^* \\in K FD(x^*)\\right] + E\\left[\\min x^* \\in D FD(x^*) - \\min y^* \\in K FP(y^*)\\right]\\right]\n$$\n$$\n\\leq E\\left[x \\sim \\pi\\left[FP(x) - FD(x)\\right] + E\\left[FD(x) - \\min x^* \\in K FD(x^*)\\right]\\right].\n$$\nWe can bound E[x \u223c \u03c0[FP(x) \u2212 FD(x)] \u2264 O(G^2 exp(\u03b2GD)) \u2264 O(GD\u03b5 log(n)/n\u00b5 n^{1-c} d\u221alog(1/\u03b4)) by Lemma 4.5 for an arbitrarily small constant c > 0. Hence the empirical risk is dominated term compared to E[x \u223c \u03c0[FP(x) \u2212 FD(x)], and we complete the proof.\n\n### Implementation\n\nWe rewrite them below: Let F(x) := F(x) + r(x) where r(x) is some regularizer, and F = Ei\u2208I fi is the expectation of a family of G-Lipschitz functions.\n\nAlgorithm 3 AlternateSample, [LST21]\n\n1. Input: Function F, initial point x0 \u223c \u03c00, step size \u03b7\n2. for t \u2208 [T] do\n3. yt \u2190 xt-1 + \u221a\u03b7\u03b6 where \u03b6 \u223c N(0, Id)\n4. Sample xt \u2190 exp(-F(x) - 1/2)\n5. end for\n6. Output: xT\n\nTheorem B.1 (Guarantee of Algorithm 3, [CCSW22]). Let K \u2282 Rd be a convex set of diameter D, and F : K \u2192 R, and \u03c0 \u221d exp(-F) satisfies LSI with constant CLSI. Then set \u03b7 \u2265 0, we have Rq(\u03c00, \u03c0)\n\n$$\nRq(\u03c0t, \u03c0) \u2264 (1 + \u03b7/CLSI)^{2t/q},\n$$\nwhere Rq(\u03c0', \u03c0) is the q-th order of Renyi divergence between \u03c0' and \u03c0.\n\nTo get a sample from exp(-F(x) - 1/2), we use the rejection sampler from [GLL22], whose guarantee is stated below:\n\nLemma B.2 (Rejection Sampler, [GLL22]). If the step size \u03b7 \u2272 G^-2 log^-1(1/\u03b4inner) and the inner accuracy \u03b4inner \u2208 (0, 1/2), there is an algorithm that can return a random point x that has \u03b4inner total variation distance to the distribution proportional to exp(-F(x) - 1/2). Moreover, the algorithm accesses O(1) different fi function values and O(1) samples from the density proportional to exp(-r(x) - 1/2).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Text", "md": "# Math Equations and Text"}, {"type": "heading", "lvl": 2, "value": "Math Equations and Text", "md": "## Math Equations and Text"}, {"type": "text", "value": "and hence prove the privacy guarantee.\n\nAs for the empirical risk bound, by Lemma 4.3, we know\n\n$$\nE\\left[2\\right] - \\min\\left[2\\right] \\lesssim d \\log\\left(\\beta GD/d\\right),\n$$\nand we know\n\n$$\nx \\sim \\pi\\left(FD(x) + \\mu\\right)^2 \\left\\|x\\right\\|^2 x^* \\in K\\left(FD(x^*) + \\mu\\right)^2 \\left\\|x^*\\right\\|^2 \\beta\n$$\n$$\nE\\left[\\right] + \\mu D^2.\n$$\nReplacing the value of \u03b2 achieves the empirical risk bound.\n\nAs for the population risk, we have\n\n$$\nE\\left[x \\sim \\pi FP(x) - \\min y^* \\in K FP(y^*)\\right] = E\\left[x \\sim \\pi\\left[FP(x) - FD(x)\\right] + E\\left[FD(x) - \\min x^* \\in K FD(x^*)\\right] + E\\left[\\min x^* \\in D FD(x^*) - \\min y^* \\in K FP(y^*)\\right]\\right]\n$$\n$$\n\\leq E\\left[x \\sim \\pi\\left[FP(x) - FD(x)\\right] + E\\left[FD(x) - \\min x^* \\in K FD(x^*)\\right]\\right].\n$$\nWe can bound E[x \u223c \u03c0[FP(x) \u2212 FD(x)] \u2264 O(G^2 exp(\u03b2GD)) \u2264 O(GD\u03b5 log(n)/n\u00b5 n^{1-c} d\u221alog(1/\u03b4)) by Lemma 4.5 for an arbitrarily small constant c > 0. Hence the empirical risk is dominated term compared to E[x \u223c \u03c0[FP(x) \u2212 FD(x)], and we complete the proof.", "md": "and hence prove the privacy guarantee.\n\nAs for the empirical risk bound, by Lemma 4.3, we know\n\n$$\nE\\left[2\\right] - \\min\\left[2\\right] \\lesssim d \\log\\left(\\beta GD/d\\right),\n$$\nand we know\n\n$$\nx \\sim \\pi\\left(FD(x) + \\mu\\right)^2 \\left\\|x\\right\\|^2 x^* \\in K\\left(FD(x^*) + \\mu\\right)^2 \\left\\|x^*\\right\\|^2 \\beta\n$$\n$$\nE\\left[\\right] + \\mu D^2.\n$$\nReplacing the value of \u03b2 achieves the empirical risk bound.\n\nAs for the population risk, we have\n\n$$\nE\\left[x \\sim \\pi FP(x) - \\min y^* \\in K FP(y^*)\\right] = E\\left[x \\sim \\pi\\left[FP(x) - FD(x)\\right] + E\\left[FD(x) - \\min x^* \\in K FD(x^*)\\right] + E\\left[\\min x^* \\in D FD(x^*) - \\min y^* \\in K FP(y^*)\\right]\\right]\n$$\n$$\n\\leq E\\left[x \\sim \\pi\\left[FP(x) - FD(x)\\right] + E\\left[FD(x) - \\min x^* \\in K FD(x^*)\\right]\\right].\n$$\nWe can bound E[x \u223c \u03c0[FP(x) \u2212 FD(x)] \u2264 O(G^2 exp(\u03b2GD)) \u2264 O(GD\u03b5 log(n)/n\u00b5 n^{1-c} d\u221alog(1/\u03b4)) by Lemma 4.5 for an arbitrarily small constant c > 0. Hence the empirical risk is dominated term compared to E[x \u223c \u03c0[FP(x) \u2212 FD(x)], and we complete the proof."}, {"type": "heading", "lvl": 3, "value": "Implementation", "md": "### Implementation"}, {"type": "text", "value": "We rewrite them below: Let F(x) := F(x) + r(x) where r(x) is some regularizer, and F = Ei\u2208I fi is the expectation of a family of G-Lipschitz functions.\n\nAlgorithm 3 AlternateSample, [LST21]\n\n1. Input: Function F, initial point x0 \u223c \u03c00, step size \u03b7\n2. for t \u2208 [T] do\n3. yt \u2190 xt-1 + \u221a\u03b7\u03b6 where \u03b6 \u223c N(0, Id)\n4. Sample xt \u2190 exp(-F(x) - 1/2)\n5. end for\n6. Output: xT\n\nTheorem B.1 (Guarantee of Algorithm 3, [CCSW22]). Let K \u2282 Rd be a convex set of diameter D, and F : K \u2192 R, and \u03c0 \u221d exp(-F) satisfies LSI with constant CLSI. Then set \u03b7 \u2265 0, we have Rq(\u03c00, \u03c0)\n\n$$\nRq(\u03c0t, \u03c0) \u2264 (1 + \u03b7/CLSI)^{2t/q},\n$$\nwhere Rq(\u03c0', \u03c0) is the q-th order of Renyi divergence between \u03c0' and \u03c0.\n\nTo get a sample from exp(-F(x) - 1/2), we use the rejection sampler from [GLL22], whose guarantee is stated below:\n\nLemma B.2 (Rejection Sampler, [GLL22]). If the step size \u03b7 \u2272 G^-2 log^-1(1/\u03b4inner) and the inner accuracy \u03b4inner \u2208 (0, 1/2), there is an algorithm that can return a random point x that has \u03b4inner total variation distance to the distribution proportional to exp(-F(x) - 1/2). Moreover, the algorithm accesses O(1) different fi function values and O(1) samples from the density proportional to exp(-r(x) - 1/2).", "md": "We rewrite them below: Let F(x) := F(x) + r(x) where r(x) is some regularizer, and F = Ei\u2208I fi is the expectation of a family of G-Lipschitz functions.\n\nAlgorithm 3 AlternateSample, [LST21]\n\n1. Input: Function F, initial point x0 \u223c \u03c00, step size \u03b7\n2. for t \u2208 [T] do\n3. yt \u2190 xt-1 + \u221a\u03b7\u03b6 where \u03b6 \u223c N(0, Id)\n4. Sample xt \u2190 exp(-F(x) - 1/2)\n5. end for\n6. Output: xT\n\nTheorem B.1 (Guarantee of Algorithm 3, [CCSW22]). Let K \u2282 Rd be a convex set of diameter D, and F : K \u2192 R, and \u03c0 \u221d exp(-F) satisfies LSI with constant CLSI. Then set \u03b7 \u2265 0, we have Rq(\u03c00, \u03c0)\n\n$$\nRq(\u03c0t, \u03c0) \u2264 (1 + \u03b7/CLSI)^{2t/q},\n$$\nwhere Rq(\u03c0', \u03c0) is the q-th order of Renyi divergence between \u03c0' and \u03c0.\n\nTo get a sample from exp(-F(x) - 1/2), we use the rejection sampler from [GLL22], whose guarantee is stated below:\n\nLemma B.2 (Rejection Sampler, [GLL22]). If the step size \u03b7 \u2272 G^-2 log^-1(1/\u03b4inner) and the inner accuracy \u03b4inner \u2208 (0, 1/2), there is an algorithm that can return a random point x that has \u03b4inner total variation distance to the distribution proportional to exp(-F(x) - 1/2). Moreover, the algorithm accesses O(1) different fi function values and O(1) samples from the density proportional to exp(-r(x) - 1/2)."}]}, {"page": 23, "text": "      Combining Theorem 4.6, Theorem B.1 and Lemma B.2, we can get the following implementation\nof the exponential mechanism for non-smooth functions.\nTheorem 4.7 (Implementation, risk bound). For \u03b5, \u03b4 \u2208                                          (0, 1/2), there is an (\u03b5, 2\u03b4)-DP effi                    cient\nsampler that can achieve the empirical and population risks O(GD                                               d\u00b7log log(n)\u221alog(1/\u03b4)). Moreover,\n                                                                                                                       \u03b5 log(nd)\nin expectation, the sampler takes \u02dc                   O    n\u03b53 log3(d)          log(1/\u03b4)/(GD)               function values query and some\nGaussian random variables restricted to the convex set K in total.\nProof. By Theorem 4.6, it suffices to get a good sample from \u03c0 with density proportional to\nexp(\u2212\u03b2(FD(x) + \u00b5            2 \u2225x\u22252  2)) where \u03b2 = O(                \u03b5 log(nd)                 D2\u03b2d  . Set q = 1, which gives that Rq(\u00b7, \u00b7)\n                                                                GD\u221alog(1/\u03b4))        ), \u00b5 =\nis the KL-divergence. Suppose we let x0 is drawn from density proportional to exp(\u2212\u03b2                                                    2 \u00b5\u2225x\u22252   2), then\nthe KL divergence between \u03c00 and \u03c0 is bounded by exp(q\u03b2GD).\n      Now let \u03c0(i)    T    be the distribution we get over x                     T from Algorithm 3 if we use an exact sampler\nfor i iterations, then the sampler of Lemma B.2 for the remaining T \u2212                                              i iterations. The output of\nAlgorithm 3 that we actually get is \u03c0(0)                      T . Note that CLSI \u2264                  D2n, and \u03b7 \u2272             \u03b2\u22122G\u22122 log\u22121(2T/\u03b4).\nSetting                   T = O       CLSI \u03b7     log(exp(q\u03b2GD)/\u03b42)                  = \u02dc O      n\u03b53 log3(d)   GD     log(1/\u03b4)\nwe get \u03b4inner = \u03b4/2T in Lemma B.2 and that R1(\u03c0(T)                                 T , \u03c0) \u2264       \u03b42/8. This implies the total variation\ndistance between \u03c0(T)          T      and \u03c0 is at most \u03b4/2 by Pinsker\u2019s inequality. Furthermore, by the post-\nprocessing inequality, the total variation distance between \u03c0(i)                                      and \u03c0(i+1)       is at most \u03b4/2T for all i.\n                                                                                                 T             T\nThen by triangle inequality the total variation distance between \u03c0(0)                                      T    and \u03c0 is at most \u03b4.\nB.4        Proof of Theorem 4.8\nTheorem 4.8. There exists an \u03b5-DP differentially private algorithm that achieves a population\nrisk of O        GD       d log(\u03b5n/d)/(\u03b5n) +                 d log(\u03b5n/d)/(\u221an)                .\nProof. We pick a maximal packing P of O((D/r)d) points, such that every point in K is distance at\nmost r from some point in P                   . By G-Lipschitzness, the risk of any point in P for the DP-ERM/SCO\nproblems over K are at most Gr plus the risk of the same point for DP-ERM/SCO over P                          GD                                     . The\nexponential mechanism over P gives a DP-ERM risk bound of O                                                     \u03b5n log |P     |  . Next, note that\nthe empirical loss of each point in P is the average of n random variables in [0, GD] wlog. So,\nthe expected maximum difference between the empirical and population loss of any point in P is\nO      GD\u221a  \u221a log |P |   . Putting it all together we get a DP-SCO expected risk bound of:\n               n\n                                                                   d log(D/r)             d log(D/r)\n                                         O     Gr + GD                   \u03b5n          +           \u221a  n                .\n      This is approximately minimized by setting r = Dd/\u03b5n. This gives a bound of:\n                                                             d log(\u03b5n/d)             d log(\u03b5n/d)\n                                             O     GD               \u03b5n          +            \u221a  n                .\n                                                                             23", "md": "# Math Equations\n\nCombining Theorem 4.6, Theorem B.1 and Lemma B.2, we can get the following implementation\nof the exponential mechanism for non-smooth functions.\n\nTheorem 4.7 (Implementation, risk bound). For $$\\epsilon, \\delta \\in (0, 1/2)$$, there is an $$(\\epsilon, 2\\delta)$$-DP efficient\nsampler that can achieve the empirical and population risks $$O(GDd \\cdot \\log \\log(n) \\sqrt{\\log(1/\\delta)})$$. Moreover,\nin expectation, the sampler takes $$\\tilde{O}\\left(\\frac{n\\epsilon^3 \\log^3(d) \\log(1/\\delta)}{GD}\\right)$$ function values query and some\nGaussian random variables restricted to the convex set K in total.\n\nProof. By Theorem 4.6, it suffices to get a good sample from $$\\pi$$ with density proportional to\n$$\\exp\\left(-\\beta(FD(x) + \\frac{\\mu}{2} \\|x\\|_2^2)\\right)$$ where $$\\beta = O\\left(\\frac{\\epsilon \\log(nd)}{D^2\\beta d}\\right)$$. Set $$q = 1$$, which gives that $$R_q(\\cdot, \\cdot)$$\nis the KL-divergence. Suppose we let $$x_0$$ is drawn from density proportional to $$\\exp\\left(-\\beta \\frac{\\mu}{2} \\|x\\|_2^2\\right)$$, then\nthe KL divergence between $$\\pi_0$$ and $$\\pi$$ is bounded by $$\\exp(q\\beta GD)$$.\n\nNow let $$\\pi(i)^T$$ be the distribution we get over $$x^T$$ from Algorithm 3 if we use an exact sampler\nfor $$i$$ iterations, then the sampler of Lemma B.2 for the remaining $$T-i$$ iterations. The output of\nAlgorithm 3 that we actually get is $$\\pi(0)^T$$. Note that $$CLSI \\leq D^2n$$, and $$\\eta \\lesssim \\beta^{-2}G^{-2} \\log^{-1}(2T/\\delta)$$.\nSetting $$T = O(CLSI \\eta \\log(\\exp(q\\beta GD)/\\delta^2)) = \\tilde{O}\\left(\\frac{n\\epsilon^3 \\log^3(d)}{GD \\log(1/\\delta)}\\right)$$\nwe get $$\\delta_{\\text{inner}} = \\delta/2T$$ in Lemma B.2 and that $$R_1(\\pi(T)^T, \\pi) \\leq \\delta^2/8$$. This implies the total variation\ndistance between $$\\pi(T)^T$$ and $$\\pi$$ is at most $$\\delta/2$$ by Pinsker\u2019s inequality. Furthermore, by the post-processing inequality, the total variation distance between $$\\pi(i)^T$$\nand $$\\pi(i+1)^T$$ is at most $$\\delta/2T$$ for all $$i$$. Then by triangle inequality the total variation distance between $$\\pi(0)^T$$ and $$\\pi$$ is at most $$\\delta$$.\n\nProof of Theorem 4.8\n\nTheorem 4.8. There exists an $$\\epsilon$$-DP differentially private algorithm that achieves a population\nrisk of $$O\\left(\\frac{GDd \\log(\\epsilon n/d)}{\\epsilon n} + \\frac{d \\log(\\epsilon n/d)}{\\sqrt{n}}\\right)$$.\n\nProof. We pick a maximal packing $$P$$ of $$O((D/r)d)$$ points, such that every point in $$K$$ is distance at\nmost $$r$$ from some point in $$P$$. By $$G$$-Lipschitzness, the risk of any point in $$P$$ for the DP-ERM/SCO\nproblems over $$K$$ are at most $$Gr$$ plus the risk of the same point for DP-ERM/SCO over $$PGD$$. The\nexponential mechanism over $$P$$ gives a DP-ERM risk bound of $$O(\\epsilon n \\log |P|)$$. Next, note that\nthe empirical loss of each point in $$P$$ is the average of $$n$$ random variables in $$[0, GD]$$ wlog. So,\nthe expected maximum difference between the empirical and population loss of any point in $$P$$ is\n$$O(GD \\sqrt{\\log |P|})$$. Putting it all together we get a DP-SCO expected risk bound of:\n$$O(Gr + GD \\epsilon n + d \\log(D/r) + d \\log(D/r) \\sqrt{n})$$.\n\nThis is approximately minimized by setting $$r = Dd/\\epsilon n$$. This gives a bound of:\n$$O(GD \\epsilon n + d \\log(\\epsilon n/d) + d \\log(\\epsilon n/d) \\sqrt{n})$$.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations", "md": "# Math Equations"}, {"type": "text", "value": "Combining Theorem 4.6, Theorem B.1 and Lemma B.2, we can get the following implementation\nof the exponential mechanism for non-smooth functions.\n\nTheorem 4.7 (Implementation, risk bound). For $$\\epsilon, \\delta \\in (0, 1/2)$$, there is an $$(\\epsilon, 2\\delta)$$-DP efficient\nsampler that can achieve the empirical and population risks $$O(GDd \\cdot \\log \\log(n) \\sqrt{\\log(1/\\delta)})$$. Moreover,\nin expectation, the sampler takes $$\\tilde{O}\\left(\\frac{n\\epsilon^3 \\log^3(d) \\log(1/\\delta)}{GD}\\right)$$ function values query and some\nGaussian random variables restricted to the convex set K in total.\n\nProof. By Theorem 4.6, it suffices to get a good sample from $$\\pi$$ with density proportional to\n$$\\exp\\left(-\\beta(FD(x) + \\frac{\\mu}{2} \\|x\\|_2^2)\\right)$$ where $$\\beta = O\\left(\\frac{\\epsilon \\log(nd)}{D^2\\beta d}\\right)$$. Set $$q = 1$$, which gives that $$R_q(\\cdot, \\cdot)$$\nis the KL-divergence. Suppose we let $$x_0$$ is drawn from density proportional to $$\\exp\\left(-\\beta \\frac{\\mu}{2} \\|x\\|_2^2\\right)$$, then\nthe KL divergence between $$\\pi_0$$ and $$\\pi$$ is bounded by $$\\exp(q\\beta GD)$$.\n\nNow let $$\\pi(i)^T$$ be the distribution we get over $$x^T$$ from Algorithm 3 if we use an exact sampler\nfor $$i$$ iterations, then the sampler of Lemma B.2 for the remaining $$T-i$$ iterations. The output of\nAlgorithm 3 that we actually get is $$\\pi(0)^T$$. Note that $$CLSI \\leq D^2n$$, and $$\\eta \\lesssim \\beta^{-2}G^{-2} \\log^{-1}(2T/\\delta)$$.\nSetting $$T = O(CLSI \\eta \\log(\\exp(q\\beta GD)/\\delta^2)) = \\tilde{O}\\left(\\frac{n\\epsilon^3 \\log^3(d)}{GD \\log(1/\\delta)}\\right)$$\nwe get $$\\delta_{\\text{inner}} = \\delta/2T$$ in Lemma B.2 and that $$R_1(\\pi(T)^T, \\pi) \\leq \\delta^2/8$$. This implies the total variation\ndistance between $$\\pi(T)^T$$ and $$\\pi$$ is at most $$\\delta/2$$ by Pinsker\u2019s inequality. Furthermore, by the post-processing inequality, the total variation distance between $$\\pi(i)^T$$\nand $$\\pi(i+1)^T$$ is at most $$\\delta/2T$$ for all $$i$$. Then by triangle inequality the total variation distance between $$\\pi(0)^T$$ and $$\\pi$$ is at most $$\\delta$$.\n\nProof of Theorem 4.8\n\nTheorem 4.8. There exists an $$\\epsilon$$-DP differentially private algorithm that achieves a population\nrisk of $$O\\left(\\frac{GDd \\log(\\epsilon n/d)}{\\epsilon n} + \\frac{d \\log(\\epsilon n/d)}{\\sqrt{n}}\\right)$$.\n\nProof. We pick a maximal packing $$P$$ of $$O((D/r)d)$$ points, such that every point in $$K$$ is distance at\nmost $$r$$ from some point in $$P$$. By $$G$$-Lipschitzness, the risk of any point in $$P$$ for the DP-ERM/SCO\nproblems over $$K$$ are at most $$Gr$$ plus the risk of the same point for DP-ERM/SCO over $$PGD$$. The\nexponential mechanism over $$P$$ gives a DP-ERM risk bound of $$O(\\epsilon n \\log |P|)$$. Next, note that\nthe empirical loss of each point in $$P$$ is the average of $$n$$ random variables in $$[0, GD]$$ wlog. So,\nthe expected maximum difference between the empirical and population loss of any point in $$P$$ is\n$$O(GD \\sqrt{\\log |P|})$$. Putting it all together we get a DP-SCO expected risk bound of:\n$$O(Gr + GD \\epsilon n + d \\log(D/r) + d \\log(D/r) \\sqrt{n})$$.\n\nThis is approximately minimized by setting $$r = Dd/\\epsilon n$$. This gives a bound of:\n$$O(GD \\epsilon n + d \\log(\\epsilon n/d) + d \\log(\\epsilon n/d) \\sqrt{n})$$.", "md": "Combining Theorem 4.6, Theorem B.1 and Lemma B.2, we can get the following implementation\nof the exponential mechanism for non-smooth functions.\n\nTheorem 4.7 (Implementation, risk bound). For $$\\epsilon, \\delta \\in (0, 1/2)$$, there is an $$(\\epsilon, 2\\delta)$$-DP efficient\nsampler that can achieve the empirical and population risks $$O(GDd \\cdot \\log \\log(n) \\sqrt{\\log(1/\\delta)})$$. Moreover,\nin expectation, the sampler takes $$\\tilde{O}\\left(\\frac{n\\epsilon^3 \\log^3(d) \\log(1/\\delta)}{GD}\\right)$$ function values query and some\nGaussian random variables restricted to the convex set K in total.\n\nProof. By Theorem 4.6, it suffices to get a good sample from $$\\pi$$ with density proportional to\n$$\\exp\\left(-\\beta(FD(x) + \\frac{\\mu}{2} \\|x\\|_2^2)\\right)$$ where $$\\beta = O\\left(\\frac{\\epsilon \\log(nd)}{D^2\\beta d}\\right)$$. Set $$q = 1$$, which gives that $$R_q(\\cdot, \\cdot)$$\nis the KL-divergence. Suppose we let $$x_0$$ is drawn from density proportional to $$\\exp\\left(-\\beta \\frac{\\mu}{2} \\|x\\|_2^2\\right)$$, then\nthe KL divergence between $$\\pi_0$$ and $$\\pi$$ is bounded by $$\\exp(q\\beta GD)$$.\n\nNow let $$\\pi(i)^T$$ be the distribution we get over $$x^T$$ from Algorithm 3 if we use an exact sampler\nfor $$i$$ iterations, then the sampler of Lemma B.2 for the remaining $$T-i$$ iterations. The output of\nAlgorithm 3 that we actually get is $$\\pi(0)^T$$. Note that $$CLSI \\leq D^2n$$, and $$\\eta \\lesssim \\beta^{-2}G^{-2} \\log^{-1}(2T/\\delta)$$.\nSetting $$T = O(CLSI \\eta \\log(\\exp(q\\beta GD)/\\delta^2)) = \\tilde{O}\\left(\\frac{n\\epsilon^3 \\log^3(d)}{GD \\log(1/\\delta)}\\right)$$\nwe get $$\\delta_{\\text{inner}} = \\delta/2T$$ in Lemma B.2 and that $$R_1(\\pi(T)^T, \\pi) \\leq \\delta^2/8$$. This implies the total variation\ndistance between $$\\pi(T)^T$$ and $$\\pi$$ is at most $$\\delta/2$$ by Pinsker\u2019s inequality. Furthermore, by the post-processing inequality, the total variation distance between $$\\pi(i)^T$$\nand $$\\pi(i+1)^T$$ is at most $$\\delta/2T$$ for all $$i$$. Then by triangle inequality the total variation distance between $$\\pi(0)^T$$ and $$\\pi$$ is at most $$\\delta$$.\n\nProof of Theorem 4.8\n\nTheorem 4.8. There exists an $$\\epsilon$$-DP differentially private algorithm that achieves a population\nrisk of $$O\\left(\\frac{GDd \\log(\\epsilon n/d)}{\\epsilon n} + \\frac{d \\log(\\epsilon n/d)}{\\sqrt{n}}\\right)$$.\n\nProof. We pick a maximal packing $$P$$ of $$O((D/r)d)$$ points, such that every point in $$K$$ is distance at\nmost $$r$$ from some point in $$P$$. By $$G$$-Lipschitzness, the risk of any point in $$P$$ for the DP-ERM/SCO\nproblems over $$K$$ are at most $$Gr$$ plus the risk of the same point for DP-ERM/SCO over $$PGD$$. The\nexponential mechanism over $$P$$ gives a DP-ERM risk bound of $$O(\\epsilon n \\log |P|)$$. Next, note that\nthe empirical loss of each point in $$P$$ is the average of $$n$$ random variables in $$[0, GD]$$ wlog. So,\nthe expected maximum difference between the empirical and population loss of any point in $$P$$ is\n$$O(GD \\sqrt{\\log |P|})$$. Putting it all together we get a DP-SCO expected risk bound of:\n$$O(Gr + GD \\epsilon n + d \\log(D/r) + d \\log(D/r) \\sqrt{n})$$.\n\nThis is approximately minimized by setting $$r = Dd/\\epsilon n$$. This gives a bound of:\n$$O(GD \\epsilon n + d \\log(\\epsilon n/d) + d \\log(\\epsilon n/d) \\sqrt{n})$$."}]}, {"page": 24, "text": "C       Extended related work\nFirst order stationary points.                    Progress towards privately finding a first-order stationary point\nis measured in (i) the norm of the empirical gradient at the solution x, i.e., \u2225\u2207FD(x)\u2225, and (ii)\nthe norm of the population gradient, i.e., \u2225\u2207FP(x)\u2225.                            We summarize compare these first-order\nguarantees achieved by Algorithm 1 with previous algorithms in Table 2:\n                                      References            Empirical              Population\n                                                                d1/4\n                                       [WYX17]                   \u221a n                   N/A\n                                                                d1/4                     \u221a d\n                                        [WX19]                 \u221a \u221a n                     \u221a n\n                                      [WJEG19]               (  nd)2/3                 N/A\n                                                                d1/4                    d1/4\n                                       [ZCH+20]                  \u221a n                     \u221a n\n                                         [TC22]          \u221a1n +    \u221a nd  2/3            N/A\n                                      [ABG+22]                \u221a  d  2/3           1         \u221a d\n                                                                n                n1/3 + (   n )1/2\nTable 2: Previous work in finding first-order stationary points. We omit logarithmic terms and\ndependencies on other parameters such as Lipschitz constant. \u201cN/A\u201d means we do not find an\nexplicit result in the work.\nSecond order stationary points.                      We say a point x is a Second-Order Stationary Point (SOSP),\nor a local minimum of a twice differentiable function g if \u2225\u2207g(x)\u22252 = 0 and smin(\u22072g(x)) \u2265                                    0.\nExact second-order stationary points can be extremely challenging to find [GHJY15]. Instead, it is\ncommon to measure the progress in terms of how well the solution approximates an SOSP.\nDefinition C.1 (approximate-SOSP, [AAZB+17]). We say x \u2208                                  Rd is an \u03b1-second order stationary\npoint (\u03b1-SOSP) for \u03c1-Hessian Lipschitz function g, if\n                                       \u2225\u2207g(x)\u22252 \u2264        \u03b1        smin(\u22072g(x)) \u2265         \u2212\u221a\u03c1\u03b1.\n                                         References         Empirical          Population\n                                                                d1/4\n                                          [WCX19]                \u221a n                N/A\n                                           [WX20]             ( d                   N/A\n                                                                n)4/7\n                                           [GW23]             ( d                   N/A\n                                                               \u221an)1/2                   \u221a\n                                                                 d             1          d\n                                             Ours            (  n )2/3       n1/3 + (    n )3/7\nTable 3: Summary of previous results in finding \u03b1-SOSP, where \u03b1 is demonstrated in the Table.\nOmit the logarithmic terms and the dependencies on other parameters like Lipschitz constant.\n\u201cN/A\u201d means we do not find an explicit result in the work.\n     Existing works in finding approximate SOSP privately give guarantees for the empirical function\nFD. We improve upon the state-of-the-art result and give the first guarantee for the population\nfunction FP, which is summarized in Table 3.\n                                                                    24", "md": "# Extended Related Work\n\n## Extended Related Work\n\nFirst order stationary points. Progress towards privately finding a first-order stationary point is measured in (i) the norm of the empirical gradient at the solution x, i.e., $$\\|\\nabla F_D(x)\\|$$, and (ii) the norm of the population gradient, i.e., $$\\|\\nabla F_P(x)\\|$$. We summarize compare these first-order guarantees achieved by Algorithm 1 with previous algorithms in Table 2:\n\n|References|Empirical|Population|\n|---|---|---|\n|[WYX17]|$\\sqrt{n}$|N/A|\n|[WX19]|$\\sqrt[4]{d}$|$\\sqrt{d}$|\n|[WJEG19]|$(nd)^{2/3}$|N/A|\n|[ZCH+20]|$\\sqrt{n}$|$\\sqrt{n}$|\n|[TC22]|$\\sqrt{1/n} + \\sqrt{nd}^{2/3}$|N/A|\n|[ABG+22]|$\\sqrt{d}^{2/3}$|$n^{1/3} + (n)^{1/2}$|\n\nSecond order stationary points. We say a point x is a Second-Order Stationary Point (SOSP), or a local minimum of a twice differentiable function g if $$\\|\\nabla g(x)\\|^2 = 0$$ and $$s_{\\min}(\\nabla^2 g(x)) \\geq 0$$. Exact second-order stationary points can be extremely challenging to find [GHJY15]. Instead, it is common to measure the progress in terms of how well the solution approximates an SOSP.\n\nDefinition C.1 (approximate-SOSP, [AAZB+17]): We say $$x \\in \\mathbb{R}^d$$ is an $$\\alpha$$-second order stationary point ($$\\alpha$$-SOSP) for $$\\rho$$-Hessian Lipschitz function g, if\n\n$$\\|\\nabla g(x)\\|^2 \\leq \\alpha, \\quad s_{\\min}(\\nabla^2 g(x)) \\geq -\\sqrt{\\rho\\alpha}.$$\n\n|References|Empirical|Population|\n|---|---|---|\n|[WCX19]|$\\sqrt{n}$|N/A|\n|[WX20]|$(d/n)^{4/7}$|N/A|\n|[GW23]|$(d\\sqrt{n})^{1/2}$|$\\sqrt{d}$|\n|Ours|$(n)^{2/3}$|$n^{1/3} + (n)^{3/7}$|\n\nExisting works in finding approximate SOSP privately give guarantees for the empirical function $$F_D$$. We improve upon the state-of-the-art result and give the first guarantee for the population function $$F_P$$, which is summarized in Table 3.", "images": [{"name": "page-24-20.jpg", "height": 18, "width": 223, "x": 194, "y": 214}, {"name": "page-24-1.jpg", "height": 14, "width": 223, "x": 194, "y": 148}, {"name": "page-24-11.jpg", "height": 34, "width": 223, "x": 194, "y": 180}, {"name": "page-24-33.jpg", "height": 18, "width": 201, "x": 205, "y": 500}, {"name": "page-24-22.jpg", "height": 45, "width": 223, "x": 194, "y": 233}, {"name": "page-24-32.jpg", "height": 14, "width": 201, "x": 205, "y": 486}, {"name": "page-24-5.jpg", "height": 18, "width": 223, "x": 194, "y": 162}, {"name": "page-24-34.jpg", "height": 15, "width": 201, "x": 205, "y": 518}, {"name": "page-24-35.jpg", "height": 31, "width": 201, "x": 205, "y": 533}], "items": [{"type": "heading", "lvl": 1, "value": "Extended Related Work", "md": "# Extended Related Work"}, {"type": "heading", "lvl": 2, "value": "Extended Related Work", "md": "## Extended Related Work"}, {"type": "text", "value": "First order stationary points. Progress towards privately finding a first-order stationary point is measured in (i) the norm of the empirical gradient at the solution x, i.e., $$\\|\\nabla F_D(x)\\|$$, and (ii) the norm of the population gradient, i.e., $$\\|\\nabla F_P(x)\\|$$. We summarize compare these first-order guarantees achieved by Algorithm 1 with previous algorithms in Table 2:", "md": "First order stationary points. Progress towards privately finding a first-order stationary point is measured in (i) the norm of the empirical gradient at the solution x, i.e., $$\\|\\nabla F_D(x)\\|$$, and (ii) the norm of the population gradient, i.e., $$\\|\\nabla F_P(x)\\|$$. We summarize compare these first-order guarantees achieved by Algorithm 1 with previous algorithms in Table 2:"}, {"type": "table", "rows": [["References", "Empirical", "Population"], ["[WYX17]", "$\\sqrt{n}$", "N/A"], ["[WX19]", "$\\sqrt[4]{d}$", "$\\sqrt{d}$"], ["[WJEG19]", "$(nd)^{2/3}$", "N/A"], ["[ZCH+20]", "$\\sqrt{n}$", "$\\sqrt{n}$"], ["[TC22]", "$\\sqrt{1/n} + \\sqrt{nd}^{2/3}$", "N/A"], ["[ABG+22]", "$\\sqrt{d}^{2/3}$", "$n^{1/3} + (n)^{1/2}$"]], "md": "|References|Empirical|Population|\n|---|---|---|\n|[WYX17]|$\\sqrt{n}$|N/A|\n|[WX19]|$\\sqrt[4]{d}$|$\\sqrt{d}$|\n|[WJEG19]|$(nd)^{2/3}$|N/A|\n|[ZCH+20]|$\\sqrt{n}$|$\\sqrt{n}$|\n|[TC22]|$\\sqrt{1/n} + \\sqrt{nd}^{2/3}$|N/A|\n|[ABG+22]|$\\sqrt{d}^{2/3}$|$n^{1/3} + (n)^{1/2}$|", "isPerfectTable": true, "csv": "\"References\",\"Empirical\",\"Population\"\n\"[WYX17]\",\"$\\sqrt{n}$\",\"N/A\"\n\"[WX19]\",\"$\\sqrt[4]{d}$\",\"$\\sqrt{d}$\"\n\"[WJEG19]\",\"$(nd)^{2/3}$\",\"N/A\"\n\"[ZCH+20]\",\"$\\sqrt{n}$\",\"$\\sqrt{n}$\"\n\"[TC22]\",\"$\\sqrt{1/n} + \\sqrt{nd}^{2/3}$\",\"N/A\"\n\"[ABG+22]\",\"$\\sqrt{d}^{2/3}$\",\"$n^{1/3} + (n)^{1/2}$\""}, {"type": "text", "value": "Second order stationary points. We say a point x is a Second-Order Stationary Point (SOSP), or a local minimum of a twice differentiable function g if $$\\|\\nabla g(x)\\|^2 = 0$$ and $$s_{\\min}(\\nabla^2 g(x)) \\geq 0$$. Exact second-order stationary points can be extremely challenging to find [GHJY15]. Instead, it is common to measure the progress in terms of how well the solution approximates an SOSP.\n\nDefinition C.1 (approximate-SOSP, [AAZB+17]): We say $$x \\in \\mathbb{R}^d$$ is an $$\\alpha$$-second order stationary point ($$\\alpha$$-SOSP) for $$\\rho$$-Hessian Lipschitz function g, if\n\n$$\\|\\nabla g(x)\\|^2 \\leq \\alpha, \\quad s_{\\min}(\\nabla^2 g(x)) \\geq -\\sqrt{\\rho\\alpha}.$$", "md": "Second order stationary points. We say a point x is a Second-Order Stationary Point (SOSP), or a local minimum of a twice differentiable function g if $$\\|\\nabla g(x)\\|^2 = 0$$ and $$s_{\\min}(\\nabla^2 g(x)) \\geq 0$$. Exact second-order stationary points can be extremely challenging to find [GHJY15]. Instead, it is common to measure the progress in terms of how well the solution approximates an SOSP.\n\nDefinition C.1 (approximate-SOSP, [AAZB+17]): We say $$x \\in \\mathbb{R}^d$$ is an $$\\alpha$$-second order stationary point ($$\\alpha$$-SOSP) for $$\\rho$$-Hessian Lipschitz function g, if\n\n$$\\|\\nabla g(x)\\|^2 \\leq \\alpha, \\quad s_{\\min}(\\nabla^2 g(x)) \\geq -\\sqrt{\\rho\\alpha}.$$"}, {"type": "table", "rows": [["References", "Empirical", "Population"], ["[WCX19]", "$\\sqrt{n}$", "N/A"], ["[WX20]", "$(d/n)^{4/7}$", "N/A"], ["[GW23]", "$(d\\sqrt{n})^{1/2}$", "$\\sqrt{d}$"], ["Ours", "$(n)^{2/3}$", "$n^{1/3} + (n)^{3/7}$"]], "md": "|References|Empirical|Population|\n|---|---|---|\n|[WCX19]|$\\sqrt{n}$|N/A|\n|[WX20]|$(d/n)^{4/7}$|N/A|\n|[GW23]|$(d\\sqrt{n})^{1/2}$|$\\sqrt{d}$|\n|Ours|$(n)^{2/3}$|$n^{1/3} + (n)^{3/7}$|", "isPerfectTable": true, "csv": "\"References\",\"Empirical\",\"Population\"\n\"[WCX19]\",\"$\\sqrt{n}$\",\"N/A\"\n\"[WX20]\",\"$(d/n)^{4/7}$\",\"N/A\"\n\"[GW23]\",\"$(d\\sqrt{n})^{1/2}$\",\"$\\sqrt{d}$\"\n\"Ours\",\"$(n)^{2/3}$\",\"$n^{1/3} + (n)^{3/7}$\""}, {"type": "text", "value": "Existing works in finding approximate SOSP privately give guarantees for the empirical function $$F_D$$. We improve upon the state-of-the-art result and give the first guarantee for the population function $$F_P$$, which is summarized in Table 3.", "md": "Existing works in finding approximate SOSP privately give guarantees for the empirical function $$F_D$$. We improve upon the state-of-the-art result and give the first guarantee for the population function $$F_P$$, which is summarized in Table 3."}]}], "job_id": "ebe2f8da-19c1-448a-8a43-89e4b7530402", "file_path": "./corpus/2302.09699.pdf"}