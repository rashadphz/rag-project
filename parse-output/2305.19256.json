{"pages": [{"page": 1, "text": "                                                                Ambient Diffusion:\n                           Learning Clean Distributions from Corrupted Data\n                                    Giannis Daras                              Kulin Shah                             Yuval Dagan\n                                      UT Austin                                UT Austin                              UC Berkeley\n                          giannisdaras@utexas.edu                    kulinshah@utexas.edu                      yuvald@berkeley.edu\n                                  Aravind Gollakota                    Alexandros G. Dimakis                         Adam Klivans\n                                      UT Austin                                UT Austin                                UT Austin\n                           aravindg@cs.utexas.edu                dimakis@austin.utexas.edu                      klivans@utexas.edu\n                                                                               Abstract\n                                   We present the first diffusion-based framework that can learn an unknown dis-\n                                   tribution using only highly-corrupted samples. This problem arises in scientific\n                                   applications where access to uncorrupted samples is impossible or expensive to\n                                   acquire. Another benefit of our approach is the ability to train generative models\n                                   that are less likely to memorize individual training samples since they never ob-\n                                   serve clean training data. Our main idea is to introduce               additional measurement\n                                   distortion   during the diffusion process and require the model to predict the original\n                                   corrupted image from the further corrupted image. We prove that our method\n                                   leads to models that learn the conditional expectation of the full uncorrupted image\n                                   given this additional measurement corruption. This holds for any corruption pro-\n                                   cess that satisfies some technical conditions (and in particular includes inpainting\n                                   and compressed sensing).           We train models on standard benchmarks (CelebA,\n                                   CIFAR-10 and AFHQ) and show that we can learn the distribution even when all\n                                   the training samples have        90%   of their pixels missing. We also show that we can\n                                   finetune foundation models on small corrupted datasets (e.g. MRI scans with block\n                                   corruptions) and learn the clean distribution without memorizing the training set.\n                        1    Introduction\n                        Diffusion generative models [48, 24, 51] are emerging as versatile and powerful frameworks for\narXiv:2305.19256v1 [cs.LG] 30 May 2023learning high-dimensional distributions and solving inverse problems [34, 11, 35, 28]. Numerous\n                        recent developments [52, 30] have led to text conditional foundation models like Dalle-2 [41], Latent\n                        Diffusion [45] and Imagen [47] with incredible performance in general image domains. Training\n                        these models requires access to high-quality datasets which may be expensive or impossible to obtain.\n                        For example, direct images of black holes cannot be observed [12, 19] and high-quality MRI images\n                        require long scanning times, causing patient discomfort and motion artifacts [28].\n                        Recently, Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] showed that diffusion models\n                        can memorize examples from their training set. Further, an adversary can extract dataset samples\n                        given only query access to the model, leading to privacy, security and copyright concerns. For many\n                        applications, we may want to learn the distribution but not individual training images e.g. we might\n                        want to learn the distribution of X-ray scans but not memorize images of specific patient scans from\n                        the dataset. Hence, we may want to introduce corruption as a design choice. We show that it is\n                        possible to train diffusions that learn a distribution of clean data by only observing highly corrupted\n                        samples.\n                        Preprint. Work in progress.", "md": "# Ambient Diffusion: Learning Clean Distributions from Corrupted Data\n\n## Ambient Diffusion: Learning Clean Distributions from Corrupted Data\n\nGiannis Daras (UT Austin), Kulin Shah (UT Austin), Yuval Dagan (UC Berkeley)\n\nEmail: giannisdaras@utexas.edu, kulinshah@utexas.edu, yuvald@berkeley.edu\n\nAravind Gollakota, Alexandros G. Dimakis, Adam Klivans (UT Austin)\n\nEmail: aravindg@cs.utexas.edu, dimakis@austin.utexas.edu, klivans@utexas.edu\n\n### Abstract\n\nWe present the first diffusion-based framework that can learn an unknown distribution using only highly-corrupted samples. This problem arises in scientific applications where access to uncorrupted samples is impossible or expensive to acquire. Another benefit of our approach is the ability to train generative models that are less likely to memorize individual training samples since they never observe clean training data. Our main idea is to introduce additional measurement distortion during the diffusion process and require the model to predict the original corrupted image from the further corrupted image. We prove that our method leads to models that learn the conditional expectation of the full uncorrupted image given this additional measurement corruption. This holds for any corruption process that satisfies some technical conditions (and in particular includes inpainting and compressed sensing). We train models on standard benchmarks (CelebA, CIFAR-10 and AFHQ) and show that we can learn the distribution even when all the training samples have 90% of their pixels missing. We also show that we can finetune foundation models on small corrupted datasets (e.g. MRI scans with block corruptions) and learn the clean distribution without memorizing the training set.\n\n### 1 Introduction\n\nDiffusion generative models are emerging as versatile and powerful frameworks for learning high-dimensional distributions and solving inverse problems. Numerous recent developments have led to text conditional foundation models like Dalle-2, Latent Diffusion, and Imagen with incredible performance in general image domains. Training these models requires access to high-quality datasets which may be expensive or impossible to obtain. For example, direct images of black holes cannot be observed and high-quality MRI images require long scanning times, causing patient discomfort and motion artifacts.\n\nRecently, Carlini et al., Somepalli et al., and Jagielski et al. showed that diffusion models can memorize examples from their training set. Further, an adversary can extract dataset samples given only query access to the model, leading to privacy, security and copyright concerns. For many applications, we may want to learn the distribution but not individual training images e.g. we might want to learn the distribution of X-ray scans but not memorize images of specific patient scans from the dataset. Hence, we may want to introduce corruption as a design choice. We show that it is possible to train diffusions that learn a distribution of clean data by only observing highly corrupted samples.\n\nPreprint. Work in progress.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Ambient Diffusion: Learning Clean Distributions from Corrupted Data", "md": "# Ambient Diffusion: Learning Clean Distributions from Corrupted Data"}, {"type": "heading", "lvl": 2, "value": "Ambient Diffusion: Learning Clean Distributions from Corrupted Data", "md": "## Ambient Diffusion: Learning Clean Distributions from Corrupted Data"}, {"type": "text", "value": "Giannis Daras (UT Austin), Kulin Shah (UT Austin), Yuval Dagan (UC Berkeley)\n\nEmail: giannisdaras@utexas.edu, kulinshah@utexas.edu, yuvald@berkeley.edu\n\nAravind Gollakota, Alexandros G. Dimakis, Adam Klivans (UT Austin)\n\nEmail: aravindg@cs.utexas.edu, dimakis@austin.utexas.edu, klivans@utexas.edu", "md": "Giannis Daras (UT Austin), Kulin Shah (UT Austin), Yuval Dagan (UC Berkeley)\n\nEmail: giannisdaras@utexas.edu, kulinshah@utexas.edu, yuvald@berkeley.edu\n\nAravind Gollakota, Alexandros G. Dimakis, Adam Klivans (UT Austin)\n\nEmail: aravindg@cs.utexas.edu, dimakis@austin.utexas.edu, klivans@utexas.edu"}, {"type": "heading", "lvl": 3, "value": "Abstract", "md": "### Abstract"}, {"type": "text", "value": "We present the first diffusion-based framework that can learn an unknown distribution using only highly-corrupted samples. This problem arises in scientific applications where access to uncorrupted samples is impossible or expensive to acquire. Another benefit of our approach is the ability to train generative models that are less likely to memorize individual training samples since they never observe clean training data. Our main idea is to introduce additional measurement distortion during the diffusion process and require the model to predict the original corrupted image from the further corrupted image. We prove that our method leads to models that learn the conditional expectation of the full uncorrupted image given this additional measurement corruption. This holds for any corruption process that satisfies some technical conditions (and in particular includes inpainting and compressed sensing). We train models on standard benchmarks (CelebA, CIFAR-10 and AFHQ) and show that we can learn the distribution even when all the training samples have 90% of their pixels missing. We also show that we can finetune foundation models on small corrupted datasets (e.g. MRI scans with block corruptions) and learn the clean distribution without memorizing the training set.", "md": "We present the first diffusion-based framework that can learn an unknown distribution using only highly-corrupted samples. This problem arises in scientific applications where access to uncorrupted samples is impossible or expensive to acquire. Another benefit of our approach is the ability to train generative models that are less likely to memorize individual training samples since they never observe clean training data. Our main idea is to introduce additional measurement distortion during the diffusion process and require the model to predict the original corrupted image from the further corrupted image. We prove that our method leads to models that learn the conditional expectation of the full uncorrupted image given this additional measurement corruption. This holds for any corruption process that satisfies some technical conditions (and in particular includes inpainting and compressed sensing). We train models on standard benchmarks (CelebA, CIFAR-10 and AFHQ) and show that we can learn the distribution even when all the training samples have 90% of their pixels missing. We also show that we can finetune foundation models on small corrupted datasets (e.g. MRI scans with block corruptions) and learn the clean distribution without memorizing the training set."}, {"type": "heading", "lvl": 3, "value": "1 Introduction", "md": "### 1 Introduction"}, {"type": "text", "value": "Diffusion generative models are emerging as versatile and powerful frameworks for learning high-dimensional distributions and solving inverse problems. Numerous recent developments have led to text conditional foundation models like Dalle-2, Latent Diffusion, and Imagen with incredible performance in general image domains. Training these models requires access to high-quality datasets which may be expensive or impossible to obtain. For example, direct images of black holes cannot be observed and high-quality MRI images require long scanning times, causing patient discomfort and motion artifacts.\n\nRecently, Carlini et al., Somepalli et al., and Jagielski et al. showed that diffusion models can memorize examples from their training set. Further, an adversary can extract dataset samples given only query access to the model, leading to privacy, security and copyright concerns. For many applications, we may want to learn the distribution but not individual training images e.g. we might want to learn the distribution of X-ray scans but not memorize images of specific patient scans from the dataset. Hence, we may want to introduce corruption as a design choice. We show that it is possible to train diffusions that learn a distribution of clean data by only observing highly corrupted samples.\n\nPreprint. Work in progress.", "md": "Diffusion generative models are emerging as versatile and powerful frameworks for learning high-dimensional distributions and solving inverse problems. Numerous recent developments have led to text conditional foundation models like Dalle-2, Latent Diffusion, and Imagen with incredible performance in general image domains. Training these models requires access to high-quality datasets which may be expensive or impossible to obtain. For example, direct images of black holes cannot be observed and high-quality MRI images require long scanning times, causing patient discomfort and motion artifacts.\n\nRecently, Carlini et al., Somepalli et al., and Jagielski et al. showed that diffusion models can memorize examples from their training set. Further, an adversary can extract dataset samples given only query access to the model, leading to privacy, security and copyright concerns. For many applications, we may want to learn the distribution but not individual training images e.g. we might want to learn the distribution of X-ray scans but not memorize images of specific patient scans from the dataset. Hence, we may want to introduce corruption as a design choice. We show that it is possible to train diffusions that learn a distribution of clean data by only observing highly corrupted samples.\n\nPreprint. Work in progress."}]}, {"page": 2, "text": "                                                                    Corrupted Training\n  Training Images        Generated samples    Nearest neighbors           Images             Generated samples    Nearest neighbors\nFigure 1:    Left panel:     Baseline method of vanilla finetuning Deepfloyd IF using                     3000   images from\nCelebA-HQ. We show generated sample images and nearest neighbors from the finetuning set. As\nshown, the generated samples are often near-identical copies from training data. This verifies related\nwork Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] that pointed out that diffusions\noften generate training samples.           Right panel:       We finetune the same foundation model (Deepfloyd\nIF) using our method and           3000   highly corrupted training images. The corruption adds noise and\nremoves     80  percent random pixels. We show generated samples and nearest neighbors from the\ntraining set. Our method still learns the clean distribution of faces (with some quality deterioration,\nas shown) but does not memorize training data. We emphasize that our training is performed without\never accessing clean training data.\nPrior work in supervised learning from corrupted data.                            The traditional approach to solving\nsuch problems involves training a restoration model using supervised learning to predict the clean\nimage based on the measurements [43, 44, 57, 39]. The seminal Noise2Noise [38] work introduced\na practical algorithm for learning how to denoise in the absence of any non-noisy images. This\nframework and its generalizations [5, 37, 53] have found applications in electron microscopy [16],\ntomographic image reconstruction [56], fluorescence image reconstruction [59], blind inverse prob-\nlems [20, 5], monocular depth estimation and proteomics [6]. Another related line of work uses\nStein\u2019s Unbiased Risk Estimate (SURE) to optimize an unbiased estimator of the denoising objective\nwithout access to non-noisy data [18]. We stress that the aforementioned research works study the\nproblem of     restoration, whereas are interested in the problem of               sampling    from the clean distribution.\nRestoration algorithms based on supervised learning are only effective when the corruption level is\nrelatively low [15]. However, it might be either not possible or not desirable to reconstruct individual\nsamples. Instead, the desired goal may be to learn togenerate                    fresh and completely unseen samples\nfrom the distribution of the uncorrupted data but              without reconstructing individual training samples.\nIndeed, for certain corruption processes, it is theoretically possible to perfectly learn a distribution\nonly from highly corrupted samples (such as just random one-dimensional projections), even though\nindividual sample denoising is usually impossible in such settings. Specifically, AmbientGAN [7]\nshowed that general       d dimensional distributions can be learned from              scalar   observations, by observing\nonly projections on one-dimensional random Gaussian vectors, in the infinite training data limit. The\ntheory requires an infinitely powerful discriminator and hence does not apply to diffusion models.\nOur contributions.        We present the first diffusion-based framework to learn an unknown distribution\nD  when the training set only contains highly-corrupted examples drawn from                             D. Specifically, we\nconsider the problem of learning to sample from the target distribution                           p 0(x 0 ) given corrupted\nsamples    Ax   0 where    A   \u223c   p(A)   is a random corruption matrix (with known realizations and prior\ndistribution) and      x 0  \u223c  p 0(x  0). Our main idea is to introduce            additional measurement distortion\nduring the diffusion process and require the model to predict the original corrupted image from the\nfurther corrupted image.                                        2", "md": "# Corrupted Training\n\n## Corrupted Training\n\n|Training Images|Generated samples|Nearest neighbors|Images|Generated samples|Nearest neighbors|\n|---|---|---|---|---|---|\n|Figure 1:|Left panel: Baseline method of vanilla finetuning Deepfloyd IF using $3000$ images from CelebA-HQ. We show generated sample images and nearest neighbors from the finetuning set. As shown, the generated samples are often near-identical copies from training data. This verifies related work Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] that pointed out that diffusions often generate training samples.|Right panel: We finetune the same foundation model (Deepfloyd IF) using our method and $3000$ highly corrupted training images. The corruption adds noise and removes $80$ percent random pixels. We show generated samples and nearest neighbors from the training set. Our method still learns the clean distribution of faces (with some quality deterioration, as shown) but does not memorize training data. We emphasize that our training is performed without ever accessing clean training data.| | | |\n\nPrior work in supervised learning from corrupted data. The traditional approach to solving such problems involves training a restoration model using supervised learning to predict the clean image based on the measurements [43, 44, 57, 39]. The seminal Noise2Noise [38] work introduced a practical algorithm for learning how to denoise in the absence of any non-noisy images. This framework and its generalizations [5, 37, 53] have found applications in electron microscopy [16], tomographic image reconstruction [56], fluorescence image reconstruction [59], blind inverse problems [20, 5], monocular depth estimation and proteomics [6]. Another related line of work uses Stein\u2019s Unbiased Risk Estimate (SURE) to optimize an unbiased estimator of the denoising objective without access to non-noisy data [18]. We stress that the aforementioned research works study the problem of restoration, whereas are interested in the problem of sampling from the clean distribution.\n\nRestoration algorithms based on supervised learning are only effective when the corruption level is relatively low [15]. However, it might be either not possible or not desirable to reconstruct individual samples. Instead, the desired goal may be to learn to generate fresh and completely unseen samples from the distribution of the uncorrupted data but without reconstructing individual training samples. Indeed, for certain corruption processes, it is theoretically possible to perfectly learn a distribution only from highly corrupted samples (such as just random one-dimensional projections), even though individual sample denoising is usually impossible in such settings. Specifically, AmbientGAN [7] showed that general d dimensional distributions can be learned from scalar observations, by observing only projections on one-dimensional random Gaussian vectors, in the infinite training data limit. The theory requires an infinitely powerful discriminator and hence does not apply to diffusion models.\n\nOur contributions. We present the first diffusion-based framework to learn an unknown distribution D when the training set only contains highly-corrupted examples drawn from D. Specifically, we consider the problem of learning to sample from the target distribution $$p_0(x_0)$$ given corrupted samples $$Ax_0$$ where $$A \\sim p(A)$$ is a random corruption matrix (with known realizations and prior distribution) and $$x_0 \\sim p_0(x_0)$$. Our main idea is to introduce additional measurement distortion during the diffusion process and require the model to predict the original corrupted image from the further corrupted image.", "images": [{"name": "img_p1_1", "height": 584, "width": 1200}], "items": [{"type": "heading", "lvl": 1, "value": "Corrupted Training", "md": "# Corrupted Training"}, {"type": "heading", "lvl": 2, "value": "Corrupted Training", "md": "## Corrupted Training"}, {"type": "table", "rows": [["Training Images", "Generated samples", "Nearest neighbors", "Images", "Generated samples", "Nearest neighbors"], ["Figure 1:", "Left panel: Baseline method of vanilla finetuning Deepfloyd IF using $3000$ images from CelebA-HQ. We show generated sample images and nearest neighbors from the finetuning set. As shown, the generated samples are often near-identical copies from training data. This verifies related work Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] that pointed out that diffusions often generate training samples.", "Right panel: We finetune the same foundation model (Deepfloyd IF) using our method and $3000$ highly corrupted training images. The corruption adds noise and removes $80$ percent random pixels. We show generated samples and nearest neighbors from the training set. Our method still learns the clean distribution of faces (with some quality deterioration, as shown) but does not memorize training data. We emphasize that our training is performed without ever accessing clean training data.", "", "", ""]], "md": "|Training Images|Generated samples|Nearest neighbors|Images|Generated samples|Nearest neighbors|\n|---|---|---|---|---|---|\n|Figure 1:|Left panel: Baseline method of vanilla finetuning Deepfloyd IF using $3000$ images from CelebA-HQ. We show generated sample images and nearest neighbors from the finetuning set. As shown, the generated samples are often near-identical copies from training data. This verifies related work Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] that pointed out that diffusions often generate training samples.|Right panel: We finetune the same foundation model (Deepfloyd IF) using our method and $3000$ highly corrupted training images. The corruption adds noise and removes $80$ percent random pixels. We show generated samples and nearest neighbors from the training set. Our method still learns the clean distribution of faces (with some quality deterioration, as shown) but does not memorize training data. We emphasize that our training is performed without ever accessing clean training data.| | | |", "isPerfectTable": true, "csv": "\"Training Images\",\"Generated samples\",\"Nearest neighbors\",\"Images\",\"Generated samples\",\"Nearest neighbors\"\n\"Figure 1:\",\"Left panel: Baseline method of vanilla finetuning Deepfloyd IF using $3000$ images from CelebA-HQ. We show generated sample images and nearest neighbors from the finetuning set. As shown, the generated samples are often near-identical copies from training data. This verifies related work Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] that pointed out that diffusions often generate training samples.\",\"Right panel: We finetune the same foundation model (Deepfloyd IF) using our method and $3000$ highly corrupted training images. The corruption adds noise and removes $80$ percent random pixels. We show generated samples and nearest neighbors from the training set. Our method still learns the clean distribution of faces (with some quality deterioration, as shown) but does not memorize training data. We emphasize that our training is performed without ever accessing clean training data.\",\"\",\"\",\"\""}, {"type": "text", "value": "Prior work in supervised learning from corrupted data. The traditional approach to solving such problems involves training a restoration model using supervised learning to predict the clean image based on the measurements [43, 44, 57, 39]. The seminal Noise2Noise [38] work introduced a practical algorithm for learning how to denoise in the absence of any non-noisy images. This framework and its generalizations [5, 37, 53] have found applications in electron microscopy [16], tomographic image reconstruction [56], fluorescence image reconstruction [59], blind inverse problems [20, 5], monocular depth estimation and proteomics [6]. Another related line of work uses Stein\u2019s Unbiased Risk Estimate (SURE) to optimize an unbiased estimator of the denoising objective without access to non-noisy data [18]. We stress that the aforementioned research works study the problem of restoration, whereas are interested in the problem of sampling from the clean distribution.\n\nRestoration algorithms based on supervised learning are only effective when the corruption level is relatively low [15]. However, it might be either not possible or not desirable to reconstruct individual samples. Instead, the desired goal may be to learn to generate fresh and completely unseen samples from the distribution of the uncorrupted data but without reconstructing individual training samples. Indeed, for certain corruption processes, it is theoretically possible to perfectly learn a distribution only from highly corrupted samples (such as just random one-dimensional projections), even though individual sample denoising is usually impossible in such settings. Specifically, AmbientGAN [7] showed that general d dimensional distributions can be learned from scalar observations, by observing only projections on one-dimensional random Gaussian vectors, in the infinite training data limit. The theory requires an infinitely powerful discriminator and hence does not apply to diffusion models.\n\nOur contributions. We present the first diffusion-based framework to learn an unknown distribution D when the training set only contains highly-corrupted examples drawn from D. Specifically, we consider the problem of learning to sample from the target distribution $$p_0(x_0)$$ given corrupted samples $$Ax_0$$ where $$A \\sim p(A)$$ is a random corruption matrix (with known realizations and prior distribution) and $$x_0 \\sim p_0(x_0)$$. Our main idea is to introduce additional measurement distortion during the diffusion process and require the model to predict the original corrupted image from the further corrupted image.", "md": "Prior work in supervised learning from corrupted data. The traditional approach to solving such problems involves training a restoration model using supervised learning to predict the clean image based on the measurements [43, 44, 57, 39]. The seminal Noise2Noise [38] work introduced a practical algorithm for learning how to denoise in the absence of any non-noisy images. This framework and its generalizations [5, 37, 53] have found applications in electron microscopy [16], tomographic image reconstruction [56], fluorescence image reconstruction [59], blind inverse problems [20, 5], monocular depth estimation and proteomics [6]. Another related line of work uses Stein\u2019s Unbiased Risk Estimate (SURE) to optimize an unbiased estimator of the denoising objective without access to non-noisy data [18]. We stress that the aforementioned research works study the problem of restoration, whereas are interested in the problem of sampling from the clean distribution.\n\nRestoration algorithms based on supervised learning are only effective when the corruption level is relatively low [15]. However, it might be either not possible or not desirable to reconstruct individual samples. Instead, the desired goal may be to learn to generate fresh and completely unseen samples from the distribution of the uncorrupted data but without reconstructing individual training samples. Indeed, for certain corruption processes, it is theoretically possible to perfectly learn a distribution only from highly corrupted samples (such as just random one-dimensional projections), even though individual sample denoising is usually impossible in such settings. Specifically, AmbientGAN [7] showed that general d dimensional distributions can be learned from scalar observations, by observing only projections on one-dimensional random Gaussian vectors, in the infinite training data limit. The theory requires an infinitely powerful discriminator and hence does not apply to diffusion models.\n\nOur contributions. We present the first diffusion-based framework to learn an unknown distribution D when the training set only contains highly-corrupted examples drawn from D. Specifically, we consider the problem of learning to sample from the target distribution $$p_0(x_0)$$ given corrupted samples $$Ax_0$$ where $$A \\sim p(A)$$ is a random corruption matrix (with known realizations and prior distribution) and $$x_0 \\sim p_0(x_0)$$. Our main idea is to introduce additional measurement distortion during the diffusion process and require the model to predict the original corrupted image from the further corrupted image."}]}, {"page": 3, "text": "         Random inpainting           Further corruption                Block inpainting          Further corruption\n Figure 2: Illustration of our method: Given training data with deleted pixels, we corrupt further by\n erasing more (illustrated with green color). We feed the learner the further corrupted images and we\n evaluate it on the originally observed pixels. We can do this during training since the green pixel\nvalues are known to us. The score network learner has no way of knowing whether a pixel was\n missing from the beginning or whether it was corrupted by us. Hence, the score network learns to\n predict the clean image everywhere. Our method is analogous to grading a random subset of the\n questions in a test, but the students not knowing which questions will be graded.\n                                                                                 \u02dc                  \u02dc\n          \u2022 We provide an algorithm that provably learns                E[x   0|A(x   0 +  \u03c3 t\u03b7),  A], for all noise levels     t\n            and for   A\u02dc  \u223c  p( A\u02dc | A)   being a further corrupted version of          A. The result holds for a general\n            family of corruption processes           A  \u223c   p(A). For various corruption processes, we show that\n            the further degradation introduced by             A\u02dc can be very small.\n          \u2022 We use our algorithm to train diffusion models on standard benchmarks (CelebA, CIFAR-10\n            and AFHQ) with training data at different levels of corruption.\n          \u2022 Given the learned conditional expectations we provide an approximate sampler for the target\n            distribution    p 0(x  0).\n          \u2022 We show that for up to         90%    missing pixels, we can learn reasonably well the distribution\n            of uncorrupted images. We outperform the previous state-of-the-art AmbientGAN [7] and\n            natural baselines.\n          \u2022 We show that our models perform on par or even outperform state-of-the-art diffusion\n            models for solving certain inverse problems even without ever seeing a clean image during\n            training. Our models do so with a single prediction step while our baselines require hundreds\n            of diffusion steps.\n          \u2022 We use our algorithm to finetune foundational pretrained diffusion models. Our finetuning\n            can be done in a few hours on a single GPU and we can use it to learn distributions with a\n            few corrupted samples.\n          \u2022 We show that models trained on sufficiently corrupted data do not memorize their training\n            set. We measure the tradeoff between the amount of corruption (that controls the degree of\n            memorization), the amount of training data and the quality of the learned generator.\n          \u2022 We open-source our code and models: https://github.com/giannisdaras/ambient-diffusion.\n 2    Background\nTraining a diffusion model involves two steps. First, we design a corruption process that transforms\n the data distribution gradually into a distribution that we can sample from [52, 14]. Typically, this\n corruption process is described by an Ito SDE of the form:                    dx   =  f(x, t)dt     +  g(t)dw, where       w  is\n the standard Wiener process. Such corruption processes are                       reversible    and the reverse process is\n also described by an Ito SDE [3]:           dx   =  \u25af f(x, t)   \u2212g   2(t)\u2207   x log  p t(x) \u0001  dt +   g(t)dw. The designer\n of the diffusion model is usually free to choose the drift function    q  d\u03c3t2        f(\u00b7,  \u00b7) and the diffusion function\n g(\u00b7). Typical choices are setting    p     f(x, t) =     0, g(t) =         dt   (Variance Exploding SDE) or setting\n f(x, t) =      \u2212\u03b2(t)x, g(t) =            \u03b2(t)   (Variance Preserving SDE). Both of these choices lead to a\n Gaussian terminal distribution and are equivalent to a linear transformation in the input. The goal of\n diffusion model training is to learn the function             \u2207  x logp  t (x), which is known as the score function.\nTo simplify the presentation of the paper, we will focus on the Variance Exploding SDE that leads to\n conditional distributions       x t =   x 0 +   \u03c3t\u03b7.            3", "md": "# Document\n\n## Random inpainting\n\nFurther corruption\n\n## Block inpainting\n\nFurther corruption\n\nFigure 2: Illustration of our method: Given training data with deleted pixels, we corrupt further by erasing more (illustrated with green color). We feed the learner the further corrupted images and we evaluate it on the originally observed pixels. We can do this during training since the green pixel values are known to us. The score network learner has no way of knowing whether a pixel was missing from the beginning or whether it was corrupted by us. Hence, the score network learns to predict the clean image everywhere. Our method is analogous to grading a random subset of the questions in a test, but the students not knowing which questions will be graded.\n\n- We provide an algorithm that provably learns $E[x_0|A(x_0 + \\sigma t\\eta), A],$ for all noise levels $t$ and for $A' \\sim p(A' | A)$ being a further corrupted version of $A$. The result holds for a general family of corruption processes $A \\sim p(A)$. For various corruption processes, we show that the further degradation introduced by $A'$ can be very small.\n- We use our algorithm to train diffusion models on standard benchmarks (CelebA, CIFAR-10 and AFHQ) with training data at different levels of corruption.\n- Given the learned conditional expectations we provide an approximate sampler for the target distribution $p_0(x_0)$.\n- We show that for up to 90% missing pixels, we can learn reasonably well the distribution of uncorrupted images. We outperform the previous state-of-the-art AmbientGAN [7] and natural baselines.\n- We show that our models perform on par or even outperform state-of-the-art diffusion models for solving certain inverse problems even without ever seeing a clean image during training. Our models do so with a single prediction step while our baselines require hundreds of diffusion steps.\n- We use our algorithm to finetune foundational pretrained diffusion models. Our finetuning can be done in a few hours on a single GPU and we can use it to learn distributions with a few corrupted samples.\n- We show that models trained on sufficiently corrupted data do not memorize their training set. We measure the tradeoff between the amount of corruption (that controls the degree of memorization), the amount of training data and the quality of the learned generator.\n- We open-source our code and models: https://github.com/giannisdaras/ambient-diffusion.\n\n## Background\n\nTraining a diffusion model involves two steps. First, we design a corruption process that transforms the data distribution gradually into a distribution that we can sample from [52, 14]. Typically, this corruption process is described by an Ito SDE of the form: $$dx = f(x, t)dt + g(t)dw,$$ where $w$ is the standard Wiener process. Such corruption processes are reversible and the reverse process is also described by an Ito SDE: $$dx = \\tilde{f}(x, t) - \\tilde{g}^2(t)\\nabla_x \\log p_t(x) dt + \\tilde{g}(t)dw.$$ The designer of the diffusion model is usually free to choose the drift function $q \\, d\\sigma_t^2 f(\\cdot, \\cdot)$ and the diffusion function $g(\\cdot)$. Typical choices are setting $p f(x, t) = 0, g(t) = \\int dt$ (Variance Exploding SDE) or setting $f(x, t) = -\\beta(t)x, g(t) = \\beta(t)$ (Variance Preserving SDE). Both of these choices lead to a Gaussian terminal distribution and are equivalent to a linear transformation in the input. The goal of diffusion model training is to learn the function $\\nabla_x \\log p_t(x)$, which is known as the score function.\n\nTo simplify the presentation of the paper, we will focus on the Variance Exploding SDE that leads to conditional distributions $x_t = x_0 + \\sigma t\\eta$.", "images": [{"name": "img_p2_1", "height": 64, "width": 64}, {"name": "img_p2_2", "height": 64, "width": 64}, {"name": "img_p2_3", "height": 64, "width": 64}, {"name": "img_p2_4", "height": 64, "width": 64}], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 2, "value": "Random inpainting", "md": "## Random inpainting"}, {"type": "text", "value": "Further corruption", "md": "Further corruption"}, {"type": "heading", "lvl": 2, "value": "Block inpainting", "md": "## Block inpainting"}, {"type": "text", "value": "Further corruption\n\nFigure 2: Illustration of our method: Given training data with deleted pixels, we corrupt further by erasing more (illustrated with green color). We feed the learner the further corrupted images and we evaluate it on the originally observed pixels. We can do this during training since the green pixel values are known to us. The score network learner has no way of knowing whether a pixel was missing from the beginning or whether it was corrupted by us. Hence, the score network learns to predict the clean image everywhere. Our method is analogous to grading a random subset of the questions in a test, but the students not knowing which questions will be graded.\n\n- We provide an algorithm that provably learns $E[x_0|A(x_0 + \\sigma t\\eta), A],$ for all noise levels $t$ and for $A' \\sim p(A' | A)$ being a further corrupted version of $A$. The result holds for a general family of corruption processes $A \\sim p(A)$. For various corruption processes, we show that the further degradation introduced by $A'$ can be very small.\n- We use our algorithm to train diffusion models on standard benchmarks (CelebA, CIFAR-10 and AFHQ) with training data at different levels of corruption.\n- Given the learned conditional expectations we provide an approximate sampler for the target distribution $p_0(x_0)$.\n- We show that for up to 90% missing pixels, we can learn reasonably well the distribution of uncorrupted images. We outperform the previous state-of-the-art AmbientGAN [7] and natural baselines.\n- We show that our models perform on par or even outperform state-of-the-art diffusion models for solving certain inverse problems even without ever seeing a clean image during training. Our models do so with a single prediction step while our baselines require hundreds of diffusion steps.\n- We use our algorithm to finetune foundational pretrained diffusion models. Our finetuning can be done in a few hours on a single GPU and we can use it to learn distributions with a few corrupted samples.\n- We show that models trained on sufficiently corrupted data do not memorize their training set. We measure the tradeoff between the amount of corruption (that controls the degree of memorization), the amount of training data and the quality of the learned generator.\n- We open-source our code and models: https://github.com/giannisdaras/ambient-diffusion.", "md": "Further corruption\n\nFigure 2: Illustration of our method: Given training data with deleted pixels, we corrupt further by erasing more (illustrated with green color). We feed the learner the further corrupted images and we evaluate it on the originally observed pixels. We can do this during training since the green pixel values are known to us. The score network learner has no way of knowing whether a pixel was missing from the beginning or whether it was corrupted by us. Hence, the score network learns to predict the clean image everywhere. Our method is analogous to grading a random subset of the questions in a test, but the students not knowing which questions will be graded.\n\n- We provide an algorithm that provably learns $E[x_0|A(x_0 + \\sigma t\\eta), A],$ for all noise levels $t$ and for $A' \\sim p(A' | A)$ being a further corrupted version of $A$. The result holds for a general family of corruption processes $A \\sim p(A)$. For various corruption processes, we show that the further degradation introduced by $A'$ can be very small.\n- We use our algorithm to train diffusion models on standard benchmarks (CelebA, CIFAR-10 and AFHQ) with training data at different levels of corruption.\n- Given the learned conditional expectations we provide an approximate sampler for the target distribution $p_0(x_0)$.\n- We show that for up to 90% missing pixels, we can learn reasonably well the distribution of uncorrupted images. We outperform the previous state-of-the-art AmbientGAN [7] and natural baselines.\n- We show that our models perform on par or even outperform state-of-the-art diffusion models for solving certain inverse problems even without ever seeing a clean image during training. Our models do so with a single prediction step while our baselines require hundreds of diffusion steps.\n- We use our algorithm to finetune foundational pretrained diffusion models. Our finetuning can be done in a few hours on a single GPU and we can use it to learn distributions with a few corrupted samples.\n- We show that models trained on sufficiently corrupted data do not memorize their training set. We measure the tradeoff between the amount of corruption (that controls the degree of memorization), the amount of training data and the quality of the learned generator.\n- We open-source our code and models: https://github.com/giannisdaras/ambient-diffusion."}, {"type": "heading", "lvl": 2, "value": "Background", "md": "## Background"}, {"type": "text", "value": "Training a diffusion model involves two steps. First, we design a corruption process that transforms the data distribution gradually into a distribution that we can sample from [52, 14]. Typically, this corruption process is described by an Ito SDE of the form: $$dx = f(x, t)dt + g(t)dw,$$ where $w$ is the standard Wiener process. Such corruption processes are reversible and the reverse process is also described by an Ito SDE: $$dx = \\tilde{f}(x, t) - \\tilde{g}^2(t)\\nabla_x \\log p_t(x) dt + \\tilde{g}(t)dw.$$ The designer of the diffusion model is usually free to choose the drift function $q \\, d\\sigma_t^2 f(\\cdot, \\cdot)$ and the diffusion function $g(\\cdot)$. Typical choices are setting $p f(x, t) = 0, g(t) = \\int dt$ (Variance Exploding SDE) or setting $f(x, t) = -\\beta(t)x, g(t) = \\beta(t)$ (Variance Preserving SDE). Both of these choices lead to a Gaussian terminal distribution and are equivalent to a linear transformation in the input. The goal of diffusion model training is to learn the function $\\nabla_x \\log p_t(x)$, which is known as the score function.\n\nTo simplify the presentation of the paper, we will focus on the Variance Exploding SDE that leads to conditional distributions $x_t = x_0 + \\sigma t\\eta$.", "md": "Training a diffusion model involves two steps. First, we design a corruption process that transforms the data distribution gradually into a distribution that we can sample from [52, 14]. Typically, this corruption process is described by an Ito SDE of the form: $$dx = f(x, t)dt + g(t)dw,$$ where $w$ is the standard Wiener process. Such corruption processes are reversible and the reverse process is also described by an Ito SDE: $$dx = \\tilde{f}(x, t) - \\tilde{g}^2(t)\\nabla_x \\log p_t(x) dt + \\tilde{g}(t)dw.$$ The designer of the diffusion model is usually free to choose the drift function $q \\, d\\sigma_t^2 f(\\cdot, \\cdot)$ and the diffusion function $g(\\cdot)$. Typical choices are setting $p f(x, t) = 0, g(t) = \\int dt$ (Variance Exploding SDE) or setting $f(x, t) = -\\beta(t)x, g(t) = \\beta(t)$ (Variance Preserving SDE). Both of these choices lead to a Gaussian terminal distribution and are equivalent to a linear transformation in the input. The goal of diffusion model training is to learn the function $\\nabla_x \\log p_t(x)$, which is known as the score function.\n\nTo simplify the presentation of the paper, we will focus on the Variance Exploding SDE that leads to conditional distributions $x_t = x_0 + \\sigma t\\eta$."}]}, {"page": 4, "text": "Vincent [55] showed that we can learn the score function at level                      t by optimizing for the score-\nmatching objective:                              1                                  2\n                                      J(\u03b8) =     2 E (x0 ,xt) ||h \u03b8(x t, t) \u2212x   0 || .                                 (2.1)\nSpecifically, the score function can be written in terms of the minimizer of this objective as:\n                                        \u2207  xt logp  t (x t) =   h \u03b8\u2217 (x t, t)\u2212   x t.                                   (2.2)\n                                                                        \u03c3t\nThis result reveals a fundamental connection between the score-function and the best restoration\nmodel of    x 0  given   x t, known as Tweedie\u2019s Formula [17]. Specifically, the optimal                      h\u03b8 \u2217(x t , t) is\ngiven by   E[x  0 |x t], which means that                      best restoration\n                                                                 z   }|    {\n                                        \u2207 x t logp  t(x t ) =    E[x  0|x t]  \u2212  x t.                                   (2.3)\n                                                                        \u03c3t\nInspired by this restoration interpretation of diffusion models, the Soft/Cold Diffusion works [14,\n4] generalized diffusion models to look at non-Markovian corruption processes:                        x t =   C tx 0 +  \u03c3 t\u03b7.\nSpecifically, Soft Diffusion proposes the Soft Score Matching objective:\n                                                1                                         2\n                                 J soft(\u03b8) =    2E  (x0,x t) ||C t(h \u03b8 (x t , t)\u2212  x 0 )|| ,                            (2.4)\nand shows that it is sufficient to recover the score function via a generalized Tweedie\u2019s Formula:\n                                                               C tE[x  0 |x t]\u2212   x t\n                                       \u2207  xt logp  t (x t) =            \u03c3t           .                                  (2.5)\nFor these generalized models, the matrixC              tis a design choice (similar to how we could choose the\nfunctions   f, g). Most importantly, for        t= 0, the matrix     C  t becomes the identity matrix and the noise\n\u03c3t becomes zero, i.e. we observe samples from the true distribution.\n3    Method\nAs explained in the introduction, in many cases we do not observe uncorrupted images                          x0 , either by\ndesign (to avoid memorization and leaking of sensitive data) or because it is impossible to obtain\nclean data. Here we study the case where a learner only has access to linear measurements of the\nclean data, i.e.   y 0 =  Ax   0, and the corruption matrices        A   :R m\u00d7n    . We note that we are interested in\nnon-invertible corruption matrices. We ask two questions:\n       1.  Is it possible to learn      E[x  0 |A(x  0 +   \u03c3 t\u03b7), A]  for all noise levels      t, given only access to\n           corrupted samples       (y 0  =  Ax  0 , A)?\n       2.  If so, is it possible to use this restoration model         E[x  0|A(x   0 +  \u03c3 t\u03b7), A]   to recover   E[x  0 |x t]\n           for any noise level     t, and thus sample from the true distribution through the score function\n           as given by Tweedie\u2019s formula (Eq. 2.3)?\nWe investigate these questions in the rest of the paper. For the first, the answer is affirmative but only\nafter introducing additional corruptions, as we explain below. For the second, at every time step                           t,\nwe approximate       E[x  0|x t] directly using   E[x  0 |Ax  t, A]  (for a chosen    A) and substitute it into Eq. 2.3.\nEmpirically, we observe that the resulting approximate sampler yields good results.\n3.1    Training\nFor the sake of clarity, we first consider the case of random inpainting. If the image                  x 0 is viewed as a\nvector, we can think of the matrix         A  as a diagonal matrix with ones in the entries that correspond to\nthe preserved pixels and zeros in the erased pixels. We assume that                     p(A)   samples a matrix where\neach entry in the diagonal is sampled i.i.d. with a probability              1  \u2212  p to be  1  and  p  to be zero.\nWe would like to train a function            h \u03b8 which receives a corruption matrix              A  and a noisy version\nof a corrupted image,        y t =   A(x|  0 +{z\u03c3 t\u03b7)} where    \u03b7  \u223c N(0, I), and produces an estimate for the\n                                              xt\n                                                              4", "md": "Vincent [55] showed that we can learn the score function at level $t$ by optimizing for the score-matching objective:\n\n$$\nJ(\\theta) = \\frac{1}{2} E(x_0, x_t) ||h_\\theta(x_t, t) - x_0||. \\quad (2.1)\n$$\n\nSpecifically, the score function can be written in terms of the minimizer of this objective as:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = h_{\\theta^*}(x_t, t) - x_t. \\quad (2.2)\n$$\n\nThis result reveals a fundamental connection between the score-function and the best restoration model of $x_0$ given $x_t$, known as Tweedie\u2019s Formula [17]. Specifically, the optimal $h_{\\theta^*}(x_t, t)$ is given by $E[x_0 | x_t]$, which means that the best restoration is:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = E[x_0 | x_t] - x_t. \\quad (2.3)\n$$\n\nInspired by this restoration interpretation of diffusion models, the Soft/Cold Diffusion works [14, 4] generalized diffusion models to look at non-Markovian corruption processes: $x_t = C_tx_0 + \\sigma_t\\eta$. Specifically, Soft Diffusion proposes the Soft Score Matching objective:\n\n$$\nJ_{\\text{soft}}(\\theta) = \\frac{1}{2} E(x_0, x_t) ||C_t(h_\\theta(x_t, t) - x_0)||. \\quad (2.4)\n$$\n\nand shows that it is sufficient to recover the score function via a generalized Tweedie\u2019s Formula:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = \\frac{C_tE[x_0 | x_t] - x_t}{\\sigma_t}. \\quad (2.5)\n$$\n\nFor these generalized models, the matrix $C_t$ is a design choice (similar to how we could choose the functions $f, g$). Most importantly, for $t=0$, the matrix $C_t$ becomes the identity matrix and the noise $\\sigma_t$ becomes zero, i.e. we observe samples from the true distribution.\n\n### Method\n\nAs explained in the introduction, in many cases we do not observe uncorrupted images $x_0$, either by design (to avoid memorization and leaking of sensitive data) or because it is impossible to obtain clean data. Here we study the case where a learner only has access to linear measurements of the clean data, i.e. $y_0 = Ax_0$, and the corruption matrices $A: \\mathbb{R}^{m \\times n}$. We note that we are interested in non-invertible corruption matrices. We ask two questions:\n\n1. Is it possible to learn $E[x_0 | A(x_0 + \\sigma_t\\eta), A]$ for all noise levels $t$, given only access to corrupted samples $(y_0 = Ax_0, A)$?\n2. If so, is it possible to use this restoration model $E[x_0 | A(x_0 + \\sigma_t\\eta), A]$ to recover $E[x_0 | x_t]$ for any noise level $t$, and thus sample from the true distribution through the score function as given by Tweedie\u2019s formula (Eq. 2.3)?\n\nWe investigate these questions in the rest of the paper. For the first, the answer is affirmative but only after introducing additional corruptions, as we explain below. For the second, at every time step $t$, we approximate $E[x_0 | x_t]$ directly using $E[x_0 | Ax_t, A]$ (for a chosen $A$) and substitute it into Eq. 2.3. Empirically, we observe that the resulting approximate sampler yields good results.\n\n#### Training\n\nFor the sake of clarity, we first consider the case of random inpainting. If the image $x_0$ is viewed as a vector, we can think of the matrix $A$ as a diagonal matrix with ones in the entries that correspond to the preserved pixels and zeros in the erased pixels. We assume that $p(A)$ samples a matrix where each entry in the diagonal is sampled i.i.d. with a probability $1 - p$ to be 1 and $p$ to be zero. We would like to train a function $h_\\theta$ which receives a corruption matrix $A$ and a noisy version of a corrupted image, $y_t = A(x_0 + \\{z\\sigma_t\\eta\\})$ where $\\eta \\sim \\mathcal{N}(0, I)$, and produces an estimate for the $x_t$.", "images": [], "items": [{"type": "text", "value": "Vincent [55] showed that we can learn the score function at level $t$ by optimizing for the score-matching objective:\n\n$$\nJ(\\theta) = \\frac{1}{2} E(x_0, x_t) ||h_\\theta(x_t, t) - x_0||. \\quad (2.1)\n$$\n\nSpecifically, the score function can be written in terms of the minimizer of this objective as:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = h_{\\theta^*}(x_t, t) - x_t. \\quad (2.2)\n$$\n\nThis result reveals a fundamental connection between the score-function and the best restoration model of $x_0$ given $x_t$, known as Tweedie\u2019s Formula [17]. Specifically, the optimal $h_{\\theta^*}(x_t, t)$ is given by $E[x_0 | x_t]$, which means that the best restoration is:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = E[x_0 | x_t] - x_t. \\quad (2.3)\n$$\n\nInspired by this restoration interpretation of diffusion models, the Soft/Cold Diffusion works [14, 4] generalized diffusion models to look at non-Markovian corruption processes: $x_t = C_tx_0 + \\sigma_t\\eta$. Specifically, Soft Diffusion proposes the Soft Score Matching objective:\n\n$$\nJ_{\\text{soft}}(\\theta) = \\frac{1}{2} E(x_0, x_t) ||C_t(h_\\theta(x_t, t) - x_0)||. \\quad (2.4)\n$$\n\nand shows that it is sufficient to recover the score function via a generalized Tweedie\u2019s Formula:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = \\frac{C_tE[x_0 | x_t] - x_t}{\\sigma_t}. \\quad (2.5)\n$$\n\nFor these generalized models, the matrix $C_t$ is a design choice (similar to how we could choose the functions $f, g$). Most importantly, for $t=0$, the matrix $C_t$ becomes the identity matrix and the noise $\\sigma_t$ becomes zero, i.e. we observe samples from the true distribution.", "md": "Vincent [55] showed that we can learn the score function at level $t$ by optimizing for the score-matching objective:\n\n$$\nJ(\\theta) = \\frac{1}{2} E(x_0, x_t) ||h_\\theta(x_t, t) - x_0||. \\quad (2.1)\n$$\n\nSpecifically, the score function can be written in terms of the minimizer of this objective as:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = h_{\\theta^*}(x_t, t) - x_t. \\quad (2.2)\n$$\n\nThis result reveals a fundamental connection between the score-function and the best restoration model of $x_0$ given $x_t$, known as Tweedie\u2019s Formula [17]. Specifically, the optimal $h_{\\theta^*}(x_t, t)$ is given by $E[x_0 | x_t]$, which means that the best restoration is:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = E[x_0 | x_t] - x_t. \\quad (2.3)\n$$\n\nInspired by this restoration interpretation of diffusion models, the Soft/Cold Diffusion works [14, 4] generalized diffusion models to look at non-Markovian corruption processes: $x_t = C_tx_0 + \\sigma_t\\eta$. Specifically, Soft Diffusion proposes the Soft Score Matching objective:\n\n$$\nJ_{\\text{soft}}(\\theta) = \\frac{1}{2} E(x_0, x_t) ||C_t(h_\\theta(x_t, t) - x_0)||. \\quad (2.4)\n$$\n\nand shows that it is sufficient to recover the score function via a generalized Tweedie\u2019s Formula:\n\n$$\n\\nabla_{x_t} \\log p_t(x_t) = \\frac{C_tE[x_0 | x_t] - x_t}{\\sigma_t}. \\quad (2.5)\n$$\n\nFor these generalized models, the matrix $C_t$ is a design choice (similar to how we could choose the functions $f, g$). Most importantly, for $t=0$, the matrix $C_t$ becomes the identity matrix and the noise $\\sigma_t$ becomes zero, i.e. we observe samples from the true distribution."}, {"type": "heading", "lvl": 3, "value": "Method", "md": "### Method"}, {"type": "text", "value": "As explained in the introduction, in many cases we do not observe uncorrupted images $x_0$, either by design (to avoid memorization and leaking of sensitive data) or because it is impossible to obtain clean data. Here we study the case where a learner only has access to linear measurements of the clean data, i.e. $y_0 = Ax_0$, and the corruption matrices $A: \\mathbb{R}^{m \\times n}$. We note that we are interested in non-invertible corruption matrices. We ask two questions:\n\n1. Is it possible to learn $E[x_0 | A(x_0 + \\sigma_t\\eta), A]$ for all noise levels $t$, given only access to corrupted samples $(y_0 = Ax_0, A)$?\n2. If so, is it possible to use this restoration model $E[x_0 | A(x_0 + \\sigma_t\\eta), A]$ to recover $E[x_0 | x_t]$ for any noise level $t$, and thus sample from the true distribution through the score function as given by Tweedie\u2019s formula (Eq. 2.3)?\n\nWe investigate these questions in the rest of the paper. For the first, the answer is affirmative but only after introducing additional corruptions, as we explain below. For the second, at every time step $t$, we approximate $E[x_0 | x_t]$ directly using $E[x_0 | Ax_t, A]$ (for a chosen $A$) and substitute it into Eq. 2.3. Empirically, we observe that the resulting approximate sampler yields good results.", "md": "As explained in the introduction, in many cases we do not observe uncorrupted images $x_0$, either by design (to avoid memorization and leaking of sensitive data) or because it is impossible to obtain clean data. Here we study the case where a learner only has access to linear measurements of the clean data, i.e. $y_0 = Ax_0$, and the corruption matrices $A: \\mathbb{R}^{m \\times n}$. We note that we are interested in non-invertible corruption matrices. We ask two questions:\n\n1. Is it possible to learn $E[x_0 | A(x_0 + \\sigma_t\\eta), A]$ for all noise levels $t$, given only access to corrupted samples $(y_0 = Ax_0, A)$?\n2. If so, is it possible to use this restoration model $E[x_0 | A(x_0 + \\sigma_t\\eta), A]$ to recover $E[x_0 | x_t]$ for any noise level $t$, and thus sample from the true distribution through the score function as given by Tweedie\u2019s formula (Eq. 2.3)?\n\nWe investigate these questions in the rest of the paper. For the first, the answer is affirmative but only after introducing additional corruptions, as we explain below. For the second, at every time step $t$, we approximate $E[x_0 | x_t]$ directly using $E[x_0 | Ax_t, A]$ (for a chosen $A$) and substitute it into Eq. 2.3. Empirically, we observe that the resulting approximate sampler yields good results."}, {"type": "heading", "lvl": 4, "value": "Training", "md": "#### Training"}, {"type": "text", "value": "For the sake of clarity, we first consider the case of random inpainting. If the image $x_0$ is viewed as a vector, we can think of the matrix $A$ as a diagonal matrix with ones in the entries that correspond to the preserved pixels and zeros in the erased pixels. We assume that $p(A)$ samples a matrix where each entry in the diagonal is sampled i.i.d. with a probability $1 - p$ to be 1 and $p$ to be zero. We would like to train a function $h_\\theta$ which receives a corruption matrix $A$ and a noisy version of a corrupted image, $y_t = A(x_0 + \\{z\\sigma_t\\eta\\})$ where $\\eta \\sim \\mathcal{N}(0, I)$, and produces an estimate for the $x_t$.", "md": "For the sake of clarity, we first consider the case of random inpainting. If the image $x_0$ is viewed as a vector, we can think of the matrix $A$ as a diagonal matrix with ones in the entries that correspond to the preserved pixels and zeros in the erased pixels. We assume that $p(A)$ samples a matrix where each entry in the diagonal is sampled i.i.d. with a probability $1 - p$ to be 1 and $p$ to be zero. We would like to train a function $h_\\theta$ which receives a corruption matrix $A$ and a noisy version of a corrupted image, $y_t = A(x_0 + \\{z\\sigma_t\\eta\\})$ where $\\eta \\sim \\mathcal{N}(0, I)$, and produces an estimate for the $x_t$."}]}, {"page": 5, "text": "conditional expectation. The simplest idea would be to simply ignore the missing pixels and optimize\nfor:                         J corr  (\u03b8) =   1 E             ||A(h    \u03b8(A, Ax   t , t)\u2212   x0 )||2 ,                       (3.1)\n                               naive         2    (x0,x t,A)\nDespite the similarities with Soft Score Matching (Eq 2.4), this objective will not learn the conditional\nexpectation. The reason is that the learner is never penalized for performing arbitrarily poorly in\nthe missing pixels. Formally, any function                h  \u03b8\u2032 satisfying    Ah  \u03b8\u2032(A,   yt, t) =    AE[x   0 |Ax  t, A]  is a\nminimizer.\nInstead, we propose to         further corrupt     the samples before feeding them to the model, and ask the\nmodel to predict the original corrupted sample from the further corrupted image.\nConcretely, we randomly corrupt            A   to obtain   A\u02dc =  BA    for some matrix      B   that is selected randomly\ngiven   A. In our example of missing pixels,            A\u02dc is obtained from      A  by randomly erasing an additional\nfraction   \u03b4  of the pixels that survive after the corruption             A. Here,     B  will be diagonal where each\nelement is    1  with probability      1 \u2212  \u03b4 and   0 w.p.   \u03b4. We will penalize the model on recovering all the\n                                                                                                              \u02dc\npixels that are visible in the sample         Ax  0 : this includes both the pixels that survive in          Ax  0  and those\n                        \u02dc\nthat are erased by     A. The formal training objective is given by minimizing the following loss:\n                             corr         1                       \u0010       \u02dc   \u02dc               \u0011   2\n                           J      (\u03b8) =     E             \u02dc    A    h \u03b8 ( A, Ax  t, t) \u2212  x 0       ,                     (3.2)\n                                          2    (x0 ,xt,A,A)\nThe key idea behind our algorithm is as follows: the learner does not know if a missing pixel is missing\nbecause we never had it (and hence do not know the ground truth) or because it was deliberately\nerased as part of the further corruption (in which case we do know the ground truth). Thus, the best\nlearner cannot be inaccurate in the unobserved pixels because with non-zero probability it might\nbe evaluated on some of them. Notice that the trained model behaves as a denoiser in the observed\npixels and as an inpainter in the missing pixels. We also want to emphasize that the probability                           \u03b4 of\nfurther corruption can be arbitrarily small as long as it stays positive.\nThe idea of further corruption can be generalized from the case of random inpainting to a much\nbroader family of corruption processes. For example, if                    A   is a random Gaussian matrix with              m\nrows, we can form         A\u02dc  by deleting one row from           A  at random. If      A   is a block inpainting matrix\n(i.e. a random block of fixed size is missing from all of the training images), we can create                            A\u02dc  by\ncorrupting further with one more non-overlapping missing block. Examples of our further corruption\nare shown in Figure 2. In our Theory Section, we prove conditions under which it is possible to\n                   \u02dc      \u02dc\nrecover    E[x  0|Ax   t,A]  using our algorithm and samples             (y 0  =  Ax  0 , A). Our goal is to satisfy this\ncondition while adding minimal further corruption, i.e. while keepingA                     \u02dc close to   A.\n3.2    Sampling\nFixed mask sampling.            To sample from       p0 (x 0 ) using the standard diffusion formulation, we need\naccess to   \u2207  xt logp  t (x t), which is equivalent to having access to           E[x  0|x t] (see Eq. 2.3). Instead, our\n                                           \u02dc      \u02dc\nmodel is trained to predict        E[x  0|Ax   t,A]  for all matrices    A   in the support of     p(A).\nWe note that for random inpainting, the identity matrix is technically in the support of                    p(A). However,\nif the corruption probability        p  is at least a constant, the probability of seeing the identity matrix is\nexponentially small in the dimension of              x t. Hence, we should not expect our model to give good\n                        \u02dc       \u02dc\nestimates ofE[x      0 |Ax  t, A]  for corruption matrices       A  that belong to the tails of the distribution         p(A).\n                                                     \u02dc         \u02dc                                                      \u02dc      \u02dc\nThe simplest idea is to sample a mask               A   \u223c   p( A)  and approximate        E[x  0 |x t] with  E[x   0|Ax   t,A].\nUnder this approximation, the discretized sampling rule becomes:\n                                            \u03c3 t\u2212\u2206t           \u03c3 t \u2212  \u03c3 t\u2212\u2206t           \u02dc      \u02dc\n                                x t\u2212\u2206t   =           x  t +                  E[x  0|Ax   t,A].                            (3.3)\n                                               \u03c3 t                 \u03c3 t       |      {z       }\n                                            | {z }           |     {z      }         \u02c6\n                                               \u03b3 t                1\u2212\u03b3 t             x0\nThis idea works surprisingly well. Unless mentioned otherwise, we use it for all the experiments\nin the main paper and we show that we can generate samples that are reasonably close to the true\ndistribution (as shown by metrics such as FID and Inception) even with                      90%    of the pixels missing.\n                                                               5", "md": "# Conditional Expectation and Sampling\n\n## Conditional Expectation\n\nThe simplest idea would be to simply ignore the missing pixels and optimize for:\n\n$$\nJ_{\\text{corr}}(\\theta) = \\frac{1}{E} ||A(h_{\\theta}(A, Ax_t, t) - x_0)||^2 \\quad (3.1)\n$$\nInstead, we propose to further corrupt the samples before feeding them to the model, and ask the model to predict the original corrupted sample from the further corrupted image.\n\nThe formal training objective is given by minimizing the following loss:\n\n$$\nJ_{\\text{corr}}(\\theta) = \\frac{1}{2} E ||A \\cdot h_{\\theta}(A, Ax_t, t) - x_0||^2 \\quad (3.2)\n$$\n\n### Sampling\n\nFixed mask sampling. To sample from \\( p_0(x_0) \\) using the standard diffusion formulation, we need access to \\( \\nabla x_t \\log p_t(x_t) \\), which is equivalent to having access to \\( E[x_0|x_t] \\).\n\nThe discretized sampling rule becomes:\n\n$$\nx_{t-\\Delta t} = \\sigma_t - \\Delta t x_t + \\frac{\\sigma_t - \\sigma_{t-\\Delta t}}{\\sigma_t} E[x_0|Ax_t,A] \\quad (3.3)\n$$", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Conditional Expectation and Sampling", "md": "# Conditional Expectation and Sampling"}, {"type": "heading", "lvl": 2, "value": "Conditional Expectation", "md": "## Conditional Expectation"}, {"type": "text", "value": "The simplest idea would be to simply ignore the missing pixels and optimize for:\n\n$$\nJ_{\\text{corr}}(\\theta) = \\frac{1}{E} ||A(h_{\\theta}(A, Ax_t, t) - x_0)||^2 \\quad (3.1)\n$$\nInstead, we propose to further corrupt the samples before feeding them to the model, and ask the model to predict the original corrupted sample from the further corrupted image.\n\nThe formal training objective is given by minimizing the following loss:\n\n$$\nJ_{\\text{corr}}(\\theta) = \\frac{1}{2} E ||A \\cdot h_{\\theta}(A, Ax_t, t) - x_0||^2 \\quad (3.2)\n$$", "md": "The simplest idea would be to simply ignore the missing pixels and optimize for:\n\n$$\nJ_{\\text{corr}}(\\theta) = \\frac{1}{E} ||A(h_{\\theta}(A, Ax_t, t) - x_0)||^2 \\quad (3.1)\n$$\nInstead, we propose to further corrupt the samples before feeding them to the model, and ask the model to predict the original corrupted sample from the further corrupted image.\n\nThe formal training objective is given by minimizing the following loss:\n\n$$\nJ_{\\text{corr}}(\\theta) = \\frac{1}{2} E ||A \\cdot h_{\\theta}(A, Ax_t, t) - x_0||^2 \\quad (3.2)\n$$"}, {"type": "heading", "lvl": 3, "value": "Sampling", "md": "### Sampling"}, {"type": "text", "value": "Fixed mask sampling. To sample from \\( p_0(x_0) \\) using the standard diffusion formulation, we need access to \\( \\nabla x_t \\log p_t(x_t) \\), which is equivalent to having access to \\( E[x_0|x_t] \\).\n\nThe discretized sampling rule becomes:\n\n$$\nx_{t-\\Delta t} = \\sigma_t - \\Delta t x_t + \\frac{\\sigma_t - \\sigma_{t-\\Delta t}}{\\sigma_t} E[x_0|Ax_t,A] \\quad (3.3)\n$$", "md": "Fixed mask sampling. To sample from \\( p_0(x_0) \\) using the standard diffusion formulation, we need access to \\( \\nabla x_t \\log p_t(x_t) \\), which is equivalent to having access to \\( E[x_0|x_t] \\).\n\nThe discretized sampling rule becomes:\n\n$$\nx_{t-\\Delta t} = \\sigma_t - \\Delta t x_t + \\frac{\\sigma_t - \\sigma_{t-\\Delta t}}{\\sigma_t} E[x_0|Ax_t,A] \\quad (3.3)\n$$"}]}, {"page": 6, "text": " Sampling with Reconstruction Guidance.                  In the Fixed Mask Sampler, at any time             t, the prediction\n is a convex combination of the current value and the predicted denoised image. Ast                             \u2192   0, \u03b3 t \u2192   0.\n Hence, for the masked pixels, the fixed mask sampler outputs the conditional expectation of their\nvalue given the observed pixels. This leads to averaging effects as the corruption gets higher. To\n correct this problem, we add one more term in the update: the Reconstruction Guidance term. The\n issue with the previous sampler is that the model never sees certain pixels. We would like to evaluate\n the model using different masks. However, the model outputs for the denoised image might be very\n different when evaluated with different masks. To account for this problem, we add an additional\n term that enforces updates that lead to consistency on the reconstructed image. The update of the\n sampler with Reconstruction Guidance becomes:\n                                             \u02dc      \u02dc                  \u2032           \u02dc      \u02dc              \u02dc\u2032      \u02dc\u2032   2\n   x t\u2212\u2206t   =   \u03b3tx  t + (1  \u2212   \u03b3t)E[x   0|Ax  t ,A]  \u2212   w t\u2207  xt E A ||E[x   0|Ax  t ,A]  \u2212  E[x   0|A  x t, A  ]|| .   (3.4)\nThis sampler is inspired by the Reconstruction Guidance term used in Imagen [23] to enforce\n consistency and correct for the sampling drift caused by imperfect score matching [13]. We see\n modest improvements over the Fixed Mask Sampler for certain corruption ranges. We ablate this\n sampler in the Appendix, Section E.3.\n In the Appendix, Section A.1, we also prove that in theory, whenever it is possible to reconstruct\n p0(x  0)  from corrupted samples, it is also possible to reconstruct it using access to                      E[x   0|Ax   t, A].\n However, as stated in the Limitations section, we were not able to find any practical algorithm to do\n so.\n 4    Theory\nAs elaborated in Section 3, one of our key goals is to learn the best restoration model for the\n measurements at all noise levels, i.e., the function               h(A,\u02dc  y t, t) =   E[x  0 |yt, A].  We now show that\n under a certain assumption on the distribution of            A   and  A, the true population minimizer of Eq. 3.2 is\n indeed essentially of the form above. This assumption formalizes the notion that even conditional on\n \u02dc\n A, A   has considerable variability, and the latter ensures that the best way to predict                 Ax  0  as a function\n     \u02dc           \u02dc\n of Ax  t and   A  is to optimally predict      x 0  itself. All proofs are deferred to the Appendix.                  \u02dc\nTheorem 4.1.        Assume a joint distribution of corruption matrices               A  and further corruption        A. If for\n allA\u02dc  in the support it holds that       E A|A\u02dc[A  T A]  is full-rank, then the unique minimizer of the objective\n in equation 3.2 is given by                       \u02dc                       \u02dc       \u02dc\n                                            h \u03b8 \u2217( A, y t, t) =  E[x   0 | Ax  t, A]                                       (4.1)\nTwo simple examples that fit into this framework (see Corollaries A.1 and A.2 in the Appendix) are:\n         \u2022  Inpainting:    A   \u2208  R n\u00d7n   is a diagonal matrix where each entry              A ii \u223c   Ber(1   \u2212  p)  for some\n                                                                                                                     \u02dc\n            p >   0 (independently for each        i), and the additional noise is generated by drawing              A|A   such\n                  \u02dc                                                                                                    1\n            that  A ii =  A  ii \u00b7Ber(1    \u2212  \u03b4) for some small       \u03b4 >  0  (again independently for each          i).\n         \u2022  Gaussian measurements:             A   \u2208    R m\u00d7n    consists of     m   rows drawn independently from\n            N  (0, I n ), and  A\u02dc \u2208  R  m\u00d7n    is constructed conditional on        A   by zeroing out its last row.\n Notice that the minimizer in Eq 4.1 is not entirely of the form we originally desired, which was\n                                                                                \u02dc\n h(A,   y t, t) =  E[x  0  | Ax  t, A]. In place of     A, we now have         A, which is a further\u02dcdegraded matrix.\n Indeed, one trivial way to satisfy the condition in Theorem 4.1 is by forming                      A  completely indepen-\n dently of   A, e.g. by always setting        A\u02dc  = 0. However, in this case, the function we learn is not very\n useful. For this reason, we would like to add as little further noise as possible and ensure that                            A\u02dc\n is close to  A. In natural noise models such as the inpainting noise model, by letting the additional\n corruption probability      \u03b4  approach    0, we can indeed ensure that         A\u02dc follows a distribution very close to\n that of  A.\n    1Ber(q)    indicates a Bernoulli random variable with a probability ofq           to equal  1 and  1 \u2212  q for 0.\n                                                                6", "md": "# Sampling with Reconstruction Guidance\n\n## Sampling with Reconstruction Guidance\n\nIn the Fixed Mask Sampler, at any time \\(t\\), the prediction is a convex combination of the current value and the predicted denoised image. As \\(t \\rightarrow 0\\), \\(\\gamma t \\rightarrow 0\\). Hence, for the masked pixels, the fixed mask sampler outputs the conditional expectation of their value given the observed pixels. This leads to averaging effects as the corruption gets higher. To correct this problem, we add one more term in the update: the Reconstruction Guidance term. The issue with the previous sampler is that the model never sees certain pixels. We would like to evaluate the model using different masks. However, the model outputs for the denoised image might be very different when evaluated with different masks. To account for this problem, we add an additional term that enforces updates that lead to consistency on the reconstructed image. The update of the sampler with Reconstruction Guidance becomes:\n\n$$x_{t-\\Delta t} = \\gamma t x_t + (1 - \\gamma t)E[x_0|Ax_t, A] - w_t \\nabla x_t E_A ||E[x_0|Ax_t, A] - E[x_0|Ax_t, A]||^2$$\nThis sampler is inspired by the Reconstruction Guidance term used in Imagen [23] to enforce consistency and correct for the sampling drift caused by imperfect score matching [13]. We see modest improvements over the Fixed Mask Sampler for certain corruption ranges. We ablate this sampler in the Appendix, Section E.3.\n\nIn the Appendix, Section A.1, we also prove that in theory, whenever it is possible to reconstruct \\(p_0(x_0)\\) from corrupted samples, it is also possible to reconstruct it using access to \\(E[x_0|Ax_t, A]\\). However, as stated in the Limitations section, we were not able to find any practical algorithm to do so.\n\n### Theory\n\nAs elaborated in Section 3, one of our key goals is to learn the best restoration model for the measurements at all noise levels, i.e., the function \\(h(A,\\tilde{y}_t, t) = E[x_0 | y_t, A]\\). We now show that under a certain assumption on the distribution of \\(A\\) and \\(\\tilde{A}\\), the true population minimizer of Eq. 3.2 is indeed essentially of the form above. This assumption formalizes the notion that even conditional on \\(\\tilde{A}\\), \\(A\\) has considerable variability, and the latter ensures that the best way to predict \\(Ax_0\\) as a function of \\(Ax_t\\) and \\(A\\) is to optimally predict \\(x_0\\) itself. All proofs are deferred to the Appendix.\n\nTheorem 4.1. Assume a joint distribution of corruption matrices \\(A\\) and further corruption \\(\\tilde{A}\\). If for all \\(\\tilde{A}\\) in the support it holds that \\(E_{A|A\\tilde{A}}[A^TA]\\) is full-rank, then the unique minimizer of the objective in equation 3.2 is given by \\(h_{\\theta^*}(A, y_t, t) = E[x_0 | Ax_t, A]\\).\n\nTwo simple examples that fit into this framework (see Corollaries A.1 and A.2 in the Appendix) are:\n\n- Inpainting: \\(A \\in \\mathbb{R}^{n \\times n}\\) is a diagonal matrix where each entry \\(A_{ii} \\sim Ber(1 - p)\\) for some \\(p > 0\\) (independently for each \\(i\\)), and the additional noise is generated by drawing \\(\\tilde{A}|A\\) such that \\(A_{ii} = A_{ii} \\cdot Ber(1 - \\delta)\\) for some small \\(\\delta > 0\\) (again independently for each \\(i\\)).\n- Gaussian measurements: \\(A \\in \\mathbb{R}^{m \\times n}\\) consists of \\(m\\) rows drawn independently from \\(N(0, I_n)\\), and \\(\\tilde{A} \\in \\mathbb{R}^{m \\times n}\\) is constructed conditional on \\(A\\) by zeroing out its last row.\n\nNotice that the minimizer in Eq 4.1 is not entirely of the form we originally desired, which was \\(h(A, y_t, t) = E[x_0 | Ax_t, A]\\). In place of \\(A\\), we now have \\(\\tilde{A}\\), which is a further degraded matrix. Indeed, one trivial way to satisfy the condition in Theorem 4.1 is by forming \\(\\tilde{A}\\) completely independently of \\(A\\), e.g. by always setting \\(\\tilde{A} = 0\\). However, in this case, the function we learn is not very useful. For this reason, we would like to add as little further noise as possible and ensure that \\(\\tilde{A}\\) is close to \\(A\\). In natural noise models such as the inpainting noise model, by letting the additional corruption probability \\(\\delta\\) approach 0, we can indeed ensure that \\(\\tilde{A}\\) follows a distribution very close to that of \\(A\\).\n\n1Ber(q) indicates a Bernoulli random variable with a probability of \\(q\\) to equal 1 and \\(1 - q\\) for 0.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Sampling with Reconstruction Guidance", "md": "# Sampling with Reconstruction Guidance"}, {"type": "heading", "lvl": 2, "value": "Sampling with Reconstruction Guidance", "md": "## Sampling with Reconstruction Guidance"}, {"type": "text", "value": "In the Fixed Mask Sampler, at any time \\(t\\), the prediction is a convex combination of the current value and the predicted denoised image. As \\(t \\rightarrow 0\\), \\(\\gamma t \\rightarrow 0\\). Hence, for the masked pixels, the fixed mask sampler outputs the conditional expectation of their value given the observed pixels. This leads to averaging effects as the corruption gets higher. To correct this problem, we add one more term in the update: the Reconstruction Guidance term. The issue with the previous sampler is that the model never sees certain pixels. We would like to evaluate the model using different masks. However, the model outputs for the denoised image might be very different when evaluated with different masks. To account for this problem, we add an additional term that enforces updates that lead to consistency on the reconstructed image. The update of the sampler with Reconstruction Guidance becomes:\n\n$$x_{t-\\Delta t} = \\gamma t x_t + (1 - \\gamma t)E[x_0|Ax_t, A] - w_t \\nabla x_t E_A ||E[x_0|Ax_t, A] - E[x_0|Ax_t, A]||^2$$\nThis sampler is inspired by the Reconstruction Guidance term used in Imagen [23] to enforce consistency and correct for the sampling drift caused by imperfect score matching [13]. We see modest improvements over the Fixed Mask Sampler for certain corruption ranges. We ablate this sampler in the Appendix, Section E.3.\n\nIn the Appendix, Section A.1, we also prove that in theory, whenever it is possible to reconstruct \\(p_0(x_0)\\) from corrupted samples, it is also possible to reconstruct it using access to \\(E[x_0|Ax_t, A]\\). However, as stated in the Limitations section, we were not able to find any practical algorithm to do so.", "md": "In the Fixed Mask Sampler, at any time \\(t\\), the prediction is a convex combination of the current value and the predicted denoised image. As \\(t \\rightarrow 0\\), \\(\\gamma t \\rightarrow 0\\). Hence, for the masked pixels, the fixed mask sampler outputs the conditional expectation of their value given the observed pixels. This leads to averaging effects as the corruption gets higher. To correct this problem, we add one more term in the update: the Reconstruction Guidance term. The issue with the previous sampler is that the model never sees certain pixels. We would like to evaluate the model using different masks. However, the model outputs for the denoised image might be very different when evaluated with different masks. To account for this problem, we add an additional term that enforces updates that lead to consistency on the reconstructed image. The update of the sampler with Reconstruction Guidance becomes:\n\n$$x_{t-\\Delta t} = \\gamma t x_t + (1 - \\gamma t)E[x_0|Ax_t, A] - w_t \\nabla x_t E_A ||E[x_0|Ax_t, A] - E[x_0|Ax_t, A]||^2$$\nThis sampler is inspired by the Reconstruction Guidance term used in Imagen [23] to enforce consistency and correct for the sampling drift caused by imperfect score matching [13]. We see modest improvements over the Fixed Mask Sampler for certain corruption ranges. We ablate this sampler in the Appendix, Section E.3.\n\nIn the Appendix, Section A.1, we also prove that in theory, whenever it is possible to reconstruct \\(p_0(x_0)\\) from corrupted samples, it is also possible to reconstruct it using access to \\(E[x_0|Ax_t, A]\\). However, as stated in the Limitations section, we were not able to find any practical algorithm to do so."}, {"type": "heading", "lvl": 3, "value": "Theory", "md": "### Theory"}, {"type": "text", "value": "As elaborated in Section 3, one of our key goals is to learn the best restoration model for the measurements at all noise levels, i.e., the function \\(h(A,\\tilde{y}_t, t) = E[x_0 | y_t, A]\\). We now show that under a certain assumption on the distribution of \\(A\\) and \\(\\tilde{A}\\), the true population minimizer of Eq. 3.2 is indeed essentially of the form above. This assumption formalizes the notion that even conditional on \\(\\tilde{A}\\), \\(A\\) has considerable variability, and the latter ensures that the best way to predict \\(Ax_0\\) as a function of \\(Ax_t\\) and \\(A\\) is to optimally predict \\(x_0\\) itself. All proofs are deferred to the Appendix.\n\nTheorem 4.1. Assume a joint distribution of corruption matrices \\(A\\) and further corruption \\(\\tilde{A}\\). If for all \\(\\tilde{A}\\) in the support it holds that \\(E_{A|A\\tilde{A}}[A^TA]\\) is full-rank, then the unique minimizer of the objective in equation 3.2 is given by \\(h_{\\theta^*}(A, y_t, t) = E[x_0 | Ax_t, A]\\).\n\nTwo simple examples that fit into this framework (see Corollaries A.1 and A.2 in the Appendix) are:\n\n- Inpainting: \\(A \\in \\mathbb{R}^{n \\times n}\\) is a diagonal matrix where each entry \\(A_{ii} \\sim Ber(1 - p)\\) for some \\(p > 0\\) (independently for each \\(i\\)), and the additional noise is generated by drawing \\(\\tilde{A}|A\\) such that \\(A_{ii} = A_{ii} \\cdot Ber(1 - \\delta)\\) for some small \\(\\delta > 0\\) (again independently for each \\(i\\)).\n- Gaussian measurements: \\(A \\in \\mathbb{R}^{m \\times n}\\) consists of \\(m\\) rows drawn independently from \\(N(0, I_n)\\), and \\(\\tilde{A} \\in \\mathbb{R}^{m \\times n}\\) is constructed conditional on \\(A\\) by zeroing out its last row.\n\nNotice that the minimizer in Eq 4.1 is not entirely of the form we originally desired, which was \\(h(A, y_t, t) = E[x_0 | Ax_t, A]\\). In place of \\(A\\), we now have \\(\\tilde{A}\\), which is a further degraded matrix. Indeed, one trivial way to satisfy the condition in Theorem 4.1 is by forming \\(\\tilde{A}\\) completely independently of \\(A\\), e.g. by always setting \\(\\tilde{A} = 0\\). However, in this case, the function we learn is not very useful. For this reason, we would like to add as little further noise as possible and ensure that \\(\\tilde{A}\\) is close to \\(A\\). In natural noise models such as the inpainting noise model, by letting the additional corruption probability \\(\\delta\\) approach 0, we can indeed ensure that \\(\\tilde{A}\\) follows a distribution very close to that of \\(A\\).\n\n1Ber(q) indicates a Bernoulli random variable with a probability of \\(q\\) to equal 1 and \\(1 - q\\) for 0.", "md": "As elaborated in Section 3, one of our key goals is to learn the best restoration model for the measurements at all noise levels, i.e., the function \\(h(A,\\tilde{y}_t, t) = E[x_0 | y_t, A]\\). We now show that under a certain assumption on the distribution of \\(A\\) and \\(\\tilde{A}\\), the true population minimizer of Eq. 3.2 is indeed essentially of the form above. This assumption formalizes the notion that even conditional on \\(\\tilde{A}\\), \\(A\\) has considerable variability, and the latter ensures that the best way to predict \\(Ax_0\\) as a function of \\(Ax_t\\) and \\(A\\) is to optimally predict \\(x_0\\) itself. All proofs are deferred to the Appendix.\n\nTheorem 4.1. Assume a joint distribution of corruption matrices \\(A\\) and further corruption \\(\\tilde{A}\\). If for all \\(\\tilde{A}\\) in the support it holds that \\(E_{A|A\\tilde{A}}[A^TA]\\) is full-rank, then the unique minimizer of the objective in equation 3.2 is given by \\(h_{\\theta^*}(A, y_t, t) = E[x_0 | Ax_t, A]\\).\n\nTwo simple examples that fit into this framework (see Corollaries A.1 and A.2 in the Appendix) are:\n\n- Inpainting: \\(A \\in \\mathbb{R}^{n \\times n}\\) is a diagonal matrix where each entry \\(A_{ii} \\sim Ber(1 - p)\\) for some \\(p > 0\\) (independently for each \\(i\\)), and the additional noise is generated by drawing \\(\\tilde{A}|A\\) such that \\(A_{ii} = A_{ii} \\cdot Ber(1 - \\delta)\\) for some small \\(\\delta > 0\\) (again independently for each \\(i\\)).\n- Gaussian measurements: \\(A \\in \\mathbb{R}^{m \\times n}\\) consists of \\(m\\) rows drawn independently from \\(N(0, I_n)\\), and \\(\\tilde{A} \\in \\mathbb{R}^{m \\times n}\\) is constructed conditional on \\(A\\) by zeroing out its last row.\n\nNotice that the minimizer in Eq 4.1 is not entirely of the form we originally desired, which was \\(h(A, y_t, t) = E[x_0 | Ax_t, A]\\). In place of \\(A\\), we now have \\(\\tilde{A}\\), which is a further degraded matrix. Indeed, one trivial way to satisfy the condition in Theorem 4.1 is by forming \\(\\tilde{A}\\) completely independently of \\(A\\), e.g. by always setting \\(\\tilde{A} = 0\\). However, in this case, the function we learn is not very useful. For this reason, we would like to add as little further noise as possible and ensure that \\(\\tilde{A}\\) is close to \\(A\\). In natural noise models such as the inpainting noise model, by letting the additional corruption probability \\(\\delta\\) approach 0, we can indeed ensure that \\(\\tilde{A}\\) follows a distribution very close to that of \\(A\\).\n\n1Ber(q) indicates a Bernoulli random variable with a probability of \\(q\\) to equal 1 and \\(1 - q\\) for 0."}]}, {"page": 7, "text": "5    Experimental Evaluation\n5.1   Training from scratch on corrupted data\nOur first experiment is to train diffusion models from scratch using corrupted training data at different\nlevels of corruption. The corruption model we use for these experiments is random inpainting: we\n                                                                                          \u02dc\nform our dataset by deleting each pixel with probability       p. To create the matrix   A, we further delete\neach row of    A  with probability   \u03b4 \u2013 this removes an additional      \u03b4-fraction of the surviving pixels.\nUnless mentioned otherwise, we use        \u03b4 = 0.1. We train models on CIFAR-10, AFHQ, and CelebA-\nHQ. All our models are trained with corruption level          p \u2208 {0.0,0.2,0.4,0.6,0.8,      0.9}. We use the\nEDM [30] codebase to train our models. We replace convolutions with Gated Convolutions [58] \u02dc\nwhich are known to perform better for inpainting-type problems. To use the mask             A  as an additional\ninput to the model, we simply concatenate it with the imagex. The full training details can be found\nin the Appendix, Section C.\n             Dataset       Corruption Probability          Method       LPIPS      PSNR       NFE\n           CelebA-HQ                                         Ours       0.037      31.51        1\n                                                             DPS         0.053      28.21      100\n                                        0.6                              0.139      25.76      35\n                                                           DDRM          0.088      27.38      99\n                                                                         0.069      28.16      199\n                                                             Ours       0.084      26.80        1\n                                                             DPS         0.107      24.16      100\n                                        0.8                              0.316      20.37      35\n                                                           DDRM          0.188      22.96      99\n                                                                         0.153      23.82      199\n                                                             Ours       0.152      23.34        1\n                                                             DPS         0.168      20.89      100\n                                        0.9                              0.461      15.87      35\n                                                           DDRM          0.332      18.74      99\n                                                                         0.242      20.14      199\n              AFHQ                                           Ours        0.030      33.27       1\n                                                             DPS        0.020      34.06       100\n                                        0.4                              0.122      25.18      35\n                                                           DDRM          0.091      26.42      99\n                                                                         0.088      26.52      199\n                                                             Ours        0.062      29.46       1\n                                                             DPS        0.051      30.03       100\n                                        0.6                              0.246      20.76      35\n                                                           DDRM          0.166      22.79      99\n                                                                         0.160      22.93      199\n                                                             Ours        0.124     25.37        1\n                                                             DPS        0.107       25.30      100\n                                        0.8                              0.525      14.56      35\n                                                           DDRM          0.295      18.08      99\n                                                                         0.258      18.86      199\nTable 1: Comparison of our model (trained on corrupted data) with state-of-the-art diffusion models\non CelebA (DDIM [50] model) and AFHQ (EDM [30] model) for solving the random inpainting\ninverse problem. Our model performs on par with state-of-the-art diffusion inverse problem solvers,\neven though it has never seen uncorrupted training data. Further, this is achieved with a single score\nfunction evaluation. To solve this problem with a standard pre-trained diffusion model we need to\nuse a reconstruction algorithm (such as DPS [11] or DDRM [34]) that typically requires hundreds of\nsteps.\nWe first evaluate the restoration performance of our model for the task it was trained on (random\ninpainting and noise).     We compare with state-of-the-art diffusion models that were trained on\nclean data. Specifically, for AFHQ we compare with the state-of-the-art EDM model [30] and for\n                                                       7", "md": "# Experimental Evaluation\n\n## Experimental Evaluation\n\n### 5.1 Training from scratch on corrupted data\n\nOur first experiment is to train diffusion models from scratch using corrupted training data at different levels of corruption. The corruption model we use for these experiments is random inpainting: we form our dataset by deleting each pixel with probability $$p$$. To create the matrix $$A$$, we further delete each row of $$A$$ with probability $$\\delta$$ \u2013 this removes an additional $$\\delta$$-fraction of the surviving pixels. Unless mentioned otherwise, we use $$\\delta = 0.1$$. We train models on CIFAR-10, AFHQ, and CelebA-HQ. All our models are trained with corruption level $$p \\in \\{0.0, 0.2, 0.4, 0.6, 0.8, 0.9\\}$$. We use the EDM [30] codebase to train our models. We replace convolutions with Gated Convolutions [58] which are known to perform better for inpainting-type problems. To use the mask $$A$$ as an additional input to the model, we simply concatenate it with the image. The full training details can be found in the Appendix, Section C.\n\n|Dataset|Corruption Probability|Method|LPIPS|PSNR|NFE|\n|---|---|---|---|---|---|\n|CelebA-HQ|0.6|Ours|0.037|31.51|1|\n| | |DPS|0.053|28.21|100|\n|DDRM| | |0.139|25.76|35|\n| | |Ours|0.084|26.80|1|\n| | |DPS|0.107|24.16|100|\n|AFHQ|0.4|Ours|0.030|33.27|1|\n| | |DPS|0.020|34.06|100|\n|DDRM| | |0.122|25.18|35|\n| | |Ours|0.062|29.46|1|\n| | |DPS|0.051|30.03|100|\n\nTable 1: Comparison of our model (trained on corrupted data) with state-of-the-art diffusion models on CelebA (DDIM [50] model) and AFHQ (EDM [30] model) for solving the random inpainting inverse problem. Our model performs on par with state-of-the-art diffusion inverse problem solvers, even though it has never seen uncorrupted training data. Further, this is achieved with a single score function evaluation. To solve this problem with a standard pre-trained diffusion model we need to use a reconstruction algorithm (such as DPS [11] or DDRM [34]) that typically requires hundreds of steps.\n\nWe first evaluate the restoration performance of our model for the task it was trained on (random inpainting and noise). We compare with state-of-the-art diffusion models that were trained on clean data. Specifically, for AFHQ we compare with the state-of-the-art EDM model [30] and for", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Experimental Evaluation", "md": "# Experimental Evaluation"}, {"type": "heading", "lvl": 2, "value": "Experimental Evaluation", "md": "## Experimental Evaluation"}, {"type": "heading", "lvl": 3, "value": "5.1 Training from scratch on corrupted data", "md": "### 5.1 Training from scratch on corrupted data"}, {"type": "text", "value": "Our first experiment is to train diffusion models from scratch using corrupted training data at different levels of corruption. The corruption model we use for these experiments is random inpainting: we form our dataset by deleting each pixel with probability $$p$$. To create the matrix $$A$$, we further delete each row of $$A$$ with probability $$\\delta$$ \u2013 this removes an additional $$\\delta$$-fraction of the surviving pixels. Unless mentioned otherwise, we use $$\\delta = 0.1$$. We train models on CIFAR-10, AFHQ, and CelebA-HQ. All our models are trained with corruption level $$p \\in \\{0.0, 0.2, 0.4, 0.6, 0.8, 0.9\\}$$. We use the EDM [30] codebase to train our models. We replace convolutions with Gated Convolutions [58] which are known to perform better for inpainting-type problems. To use the mask $$A$$ as an additional input to the model, we simply concatenate it with the image. The full training details can be found in the Appendix, Section C.", "md": "Our first experiment is to train diffusion models from scratch using corrupted training data at different levels of corruption. The corruption model we use for these experiments is random inpainting: we form our dataset by deleting each pixel with probability $$p$$. To create the matrix $$A$$, we further delete each row of $$A$$ with probability $$\\delta$$ \u2013 this removes an additional $$\\delta$$-fraction of the surviving pixels. Unless mentioned otherwise, we use $$\\delta = 0.1$$. We train models on CIFAR-10, AFHQ, and CelebA-HQ. All our models are trained with corruption level $$p \\in \\{0.0, 0.2, 0.4, 0.6, 0.8, 0.9\\}$$. We use the EDM [30] codebase to train our models. We replace convolutions with Gated Convolutions [58] which are known to perform better for inpainting-type problems. To use the mask $$A$$ as an additional input to the model, we simply concatenate it with the image. The full training details can be found in the Appendix, Section C."}, {"type": "table", "rows": [["Dataset", "Corruption Probability", "Method", "LPIPS", "PSNR", "NFE"], ["CelebA-HQ", "0.6", "Ours", "0.037", "31.51", "1"], ["", "", "DPS", "0.053", "28.21", "100"], ["DDRM", "", "", "0.139", "25.76", "35"], ["", "", "Ours", "0.084", "26.80", "1"], ["", "", "DPS", "0.107", "24.16", "100"], ["AFHQ", "0.4", "Ours", "0.030", "33.27", "1"], ["", "", "DPS", "0.020", "34.06", "100"], ["DDRM", "", "", "0.122", "25.18", "35"], ["", "", "Ours", "0.062", "29.46", "1"], ["", "", "DPS", "0.051", "30.03", "100"]], "md": "|Dataset|Corruption Probability|Method|LPIPS|PSNR|NFE|\n|---|---|---|---|---|---|\n|CelebA-HQ|0.6|Ours|0.037|31.51|1|\n| | |DPS|0.053|28.21|100|\n|DDRM| | |0.139|25.76|35|\n| | |Ours|0.084|26.80|1|\n| | |DPS|0.107|24.16|100|\n|AFHQ|0.4|Ours|0.030|33.27|1|\n| | |DPS|0.020|34.06|100|\n|DDRM| | |0.122|25.18|35|\n| | |Ours|0.062|29.46|1|\n| | |DPS|0.051|30.03|100|", "isPerfectTable": true, "csv": "\"Dataset\",\"Corruption Probability\",\"Method\",\"LPIPS\",\"PSNR\",\"NFE\"\n\"CelebA-HQ\",\"0.6\",\"Ours\",\"0.037\",\"31.51\",\"1\"\n\"\",\"\",\"DPS\",\"0.053\",\"28.21\",\"100\"\n\"DDRM\",\"\",\"\",\"0.139\",\"25.76\",\"35\"\n\"\",\"\",\"Ours\",\"0.084\",\"26.80\",\"1\"\n\"\",\"\",\"DPS\",\"0.107\",\"24.16\",\"100\"\n\"AFHQ\",\"0.4\",\"Ours\",\"0.030\",\"33.27\",\"1\"\n\"\",\"\",\"DPS\",\"0.020\",\"34.06\",\"100\"\n\"DDRM\",\"\",\"\",\"0.122\",\"25.18\",\"35\"\n\"\",\"\",\"Ours\",\"0.062\",\"29.46\",\"1\"\n\"\",\"\",\"DPS\",\"0.051\",\"30.03\",\"100\""}, {"type": "text", "value": "Table 1: Comparison of our model (trained on corrupted data) with state-of-the-art diffusion models on CelebA (DDIM [50] model) and AFHQ (EDM [30] model) for solving the random inpainting inverse problem. Our model performs on par with state-of-the-art diffusion inverse problem solvers, even though it has never seen uncorrupted training data. Further, this is achieved with a single score function evaluation. To solve this problem with a standard pre-trained diffusion model we need to use a reconstruction algorithm (such as DPS [11] or DDRM [34]) that typically requires hundreds of steps.\n\nWe first evaluate the restoration performance of our model for the task it was trained on (random inpainting and noise). We compare with state-of-the-art diffusion models that were trained on clean data. Specifically, for AFHQ we compare with the state-of-the-art EDM model [30] and for", "md": "Table 1: Comparison of our model (trained on corrupted data) with state-of-the-art diffusion models on CelebA (DDIM [50] model) and AFHQ (EDM [30] model) for solving the random inpainting inverse problem. Our model performs on par with state-of-the-art diffusion inverse problem solvers, even though it has never seen uncorrupted training data. Further, this is achieved with a single score function evaluation. To solve this problem with a standard pre-trained diffusion model we need to use a reconstruction algorithm (such as DPS [11] or DDRM [34]) that typically requires hundreds of steps.\n\nWe first evaluate the restoration performance of our model for the task it was trained on (random inpainting and noise). We compare with state-of-the-art diffusion models that were trained on clean data. Specifically, for AFHQ we compare with the state-of-the-art EDM model [30] and for"}]}, {"page": 8, "text": "                 CIFAR-10 Inception Scores\n    10                          AmbientGAN                           Dataset     Corruption Probability     FID     Inception Score\n                                Diffusion No Further Corruption\n     9                          Ambient Diffusion                                          0.0              3.26\n                                                                                           0.2              4.18\n                                                                   CelebA-HQ               0.6              6.08         N/A\n     8                                                                                     0.8             11.19\n     7                                                                                     0.9             25.53\n                                                                                           0.0              2.41\n     6                                                                                     0.2              4.47\n                                                                                           0.4              6.96\n   Inception Score                                                   AFHQ                  0.6             10.11         N/A\n     5                                                                                     0.8             16.78\n     4                                                                                     0.9             41.00\n                                                                                           0.0              1.85         9.94\n                                                                                           0.2             11.70         7.97\n         0.0   0.1   0.2   0.3   0.4    0.5   0.6   0.7   0.8       CIFAR-10               0.4             18.85         7.45\n                       Corruption Probability                                              0.6             28.88         6.88\n Figure 3:   Performance on CIFAR-10 as a function of                                      0.8             46.27         6.14\n the corruption level. We compare our method with a dif-           Figure 4:     Inception/FID results on random in-\n fusion model trained without our further corruption trick         painting for models trained with our algorithm on\n and AmbientGAN [7]. Ambient Diffusion outperforms                 CelebA-HQ, AFHQ and CIFAR-10.\n both baselines for all ranges of corruption levels.\n CelebA we compare with DDIM [50]. These models were not trained to denoise, but we can use the\n prior learned in the denoiser as in [54, 29] to solve any inverse problem. We experiment with the\n state-of-the-art reconstruction algorithms: DDRM [34] and DPS [11].\nWe summarize the results in Table 1. Our model performs similarly to other diffusion models, even\n though it has never been trained on clean data. Further, it does so by requiring only one step, while\n all the baseline diffusion models require hundreds of steps to solve the same task with inferior or\n comparable performance. The performance of DDRM improves with more function evaluations at\n the cost of more computation. For DPS, we did not observe significant improvement by increasing\n the number of steps to more than          100. We include results with noisy inpainted measurements and\n comparisons with a supervised method in the Appendix, Section E, Tables 3, 4. We want to emphasize\n that all the baselines we compare against have an advantage: they are trained on                      uncorrupted      data.\n Instead, our models were only trained on corrupted data. This experiment indicates that: i) our\n training algorithm for learning the conditional expectation worked and ii) that the choice of corruption\n that diffusion models are trained to reverse matters for solving inverse problems.\n Next, we evaluate the performance of our diffusion models as generative models. To the best of\n our knowledge, the only generative baseline with quantitative results for training on corrupted data\n is AmbientGAN [7] which is trained on CIFAR-10. We further compare with a diffusion model\n trained without our further corruption algorithm. We plot the results in Figure 3. The diffusion\n model trained without our further corruption algorithm performs well for low corruption levels but\n collapses entirely for high corruption. Instead, our model trained with further corruption maintains\n reasonable corruption scores even for high corruption levels, outperforming the previous state-of-the-\n art AmbientGAN for all ranges of corruption levels.\n For CelebA-HQ and AFHQ we could not find any generative baselines trained on corrupted data to\n compare against. Nevertheless, we report FID and Inception Scores and summarize our results in\nTable 4 to encourage further research in this area. As shown in the Table, for CelebA-HQ and AFHQ,\nwe manage to maintain a decent FID score even with                  90%   of the pixels deleted. For CIFAR-10, the\n performance degrades faster, potentially because of the lower resolution of the training images.\n 5.2   Finetuning foundation models on corrupted data\nWe can apply our technique to finetune a foundational diffusion model. For all our experiments, we\n use Deepfloyd\u2019s IF model [2], which is one of the most powerful open-source diffusion generative\n models available. We choose this model over Stable Diffusion [46] because it works in the pixel\n space (and hence our algorithm directly applies).            8", "md": "# CIFAR-10 Inception Scores\n\n## CIFAR-10 Inception Scores\n\n|Dataset|Corruption Probability|FID|Inception Score|\n|---|---|---|---|\n|Ambient Diffusion| |0.0|3.26|\n|Ambient Diffusion| |0.2|4.18|\n|CelebA-HQ|0.6|6.08|N/A|\n| | |0.8|11.19|\n| | |0.9|25.53|\n| | |0.0|2.41|\n| | |0.2|4.47|\n| | |0.4|6.96|\n|AFHQ|0.6|10.11|N/A|\n| | |0.8|16.78|\n| | |0.9|41.00|\n| |0.0|1.85|9.94|\n| |0.2|11.70|7.97|\n|CIFAR-10|0.4|18.85|7.45|\n| |0.6|28.88|6.88|\n| |0.8|46.27|6.14|\n\nFigure 3: Performance on CIFAR-10 as a function of the corruption level. We compare our method with a diffusion model trained without our further corruption trick and AmbientGAN. Ambient Diffusion outperforms both baselines for all ranges of corruption levels.\n\nFigure 4: Inception/FID results on random inpainting for models trained with our algorithm on CelebA-HQ, AFHQ, and CIFAR-10.\n\nFor more details and comparisons, please refer to the full document.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "CIFAR-10 Inception Scores", "md": "# CIFAR-10 Inception Scores"}, {"type": "heading", "lvl": 2, "value": "CIFAR-10 Inception Scores", "md": "## CIFAR-10 Inception Scores"}, {"type": "table", "rows": [["Dataset", "Corruption Probability", "FID", "Inception Score"], ["Ambient Diffusion", "", "0.0", "3.26"], ["Ambient Diffusion", "", "0.2", "4.18"], ["CelebA-HQ", "0.6", "6.08", "N/A"], ["", "", "0.8", "11.19"], ["", "", "0.9", "25.53"], ["", "", "0.0", "2.41"], ["", "", "0.2", "4.47"], ["", "", "0.4", "6.96"], ["AFHQ", "0.6", "10.11", "N/A"], ["", "", "0.8", "16.78"], ["", "", "0.9", "41.00"], ["", "0.0", "1.85", "9.94"], ["", "0.2", "11.70", "7.97"], ["CIFAR-10", "0.4", "18.85", "7.45"], ["", "0.6", "28.88", "6.88"], ["", "0.8", "46.27", "6.14"]], "md": "|Dataset|Corruption Probability|FID|Inception Score|\n|---|---|---|---|\n|Ambient Diffusion| |0.0|3.26|\n|Ambient Diffusion| |0.2|4.18|\n|CelebA-HQ|0.6|6.08|N/A|\n| | |0.8|11.19|\n| | |0.9|25.53|\n| | |0.0|2.41|\n| | |0.2|4.47|\n| | |0.4|6.96|\n|AFHQ|0.6|10.11|N/A|\n| | |0.8|16.78|\n| | |0.9|41.00|\n| |0.0|1.85|9.94|\n| |0.2|11.70|7.97|\n|CIFAR-10|0.4|18.85|7.45|\n| |0.6|28.88|6.88|\n| |0.8|46.27|6.14|", "isPerfectTable": true, "csv": "\"Dataset\",\"Corruption Probability\",\"FID\",\"Inception Score\"\n\"Ambient Diffusion\",\"\",\"0.0\",\"3.26\"\n\"Ambient Diffusion\",\"\",\"0.2\",\"4.18\"\n\"CelebA-HQ\",\"0.6\",\"6.08\",\"N/A\"\n\"\",\"\",\"0.8\",\"11.19\"\n\"\",\"\",\"0.9\",\"25.53\"\n\"\",\"\",\"0.0\",\"2.41\"\n\"\",\"\",\"0.2\",\"4.47\"\n\"\",\"\",\"0.4\",\"6.96\"\n\"AFHQ\",\"0.6\",\"10.11\",\"N/A\"\n\"\",\"\",\"0.8\",\"16.78\"\n\"\",\"\",\"0.9\",\"41.00\"\n\"\",\"0.0\",\"1.85\",\"9.94\"\n\"\",\"0.2\",\"11.70\",\"7.97\"\n\"CIFAR-10\",\"0.4\",\"18.85\",\"7.45\"\n\"\",\"0.6\",\"28.88\",\"6.88\"\n\"\",\"0.8\",\"46.27\",\"6.14\""}, {"type": "text", "value": "Figure 3: Performance on CIFAR-10 as a function of the corruption level. We compare our method with a diffusion model trained without our further corruption trick and AmbientGAN. Ambient Diffusion outperforms both baselines for all ranges of corruption levels.\n\nFigure 4: Inception/FID results on random inpainting for models trained with our algorithm on CelebA-HQ, AFHQ, and CIFAR-10.\n\nFor more details and comparisons, please refer to the full document.", "md": "Figure 3: Performance on CIFAR-10 as a function of the corruption level. We compare our method with a diffusion model trained without our further corruption trick and AmbientGAN. Ambient Diffusion outperforms both baselines for all ranges of corruption levels.\n\nFigure 4: Inception/FID results on random inpainting for models trained with our algorithm on CelebA-HQ, AFHQ, and CIFAR-10.\n\nFor more details and comparisons, please refer to the full document."}]}, {"page": 9, "text": "Figure 5:     Left panel:    We finetune Deepfloyd\u2019s IF diffusion model to make it a generative model for MRI\nimages of brains with tumors. We use a small dataset [26] of only              155  images that was corrupted by removing\nlarge blocks as shown.      Right panel:     Generated samples from our finetuned model. As shown, the model learns\nthe statistics of full brain tumor MRI images. The training set was resized to             64  \u00d7  64  but the generated images\nare at256   \u00d7  256. The higher resolution is obtained by simply leveraging the power of the cascaded IF model.\nMemorization.           We show that we can finetune a foundational model on a limited dataset without\nmemorizing the training examples. This experiment is motivated by the recent works of Carlini\net al. [8], Somepalli et al. [49], and Jagielski et al. [27] that show that diffusion generative models\nmemorize training samples and they do it significantly more than previous generative models, such as\nGANs, especially when the training dataset is small. Specifically, Somepalli et al. [49] train diffusion\nmodels on subsets of size          {300,3000,      30000}    of CelebA and they show that models trained on                   300\nor  3000   memorize and blatantly copy images from their training set.\nWe replicate this training experiment by finetuning the IF model on a subset of CelebA with                                  3000\ntraining examples. Results are shown in Figure 1. Standard finetuning of Deepfloyd\u2019s IF on                                   3000\nimages memorizes samples and produces almost exact copies of the training set. Instead, if we\ncorrupt the images by deleting            80%    of the pixels prior to training and finetune, the memorization\ndecreases sharply and there are distinct differences between the generated images and their nearest\nneighbors from the dataset. This is in spite of finetuning until convergence.\n                          Distribution of Similarity Values to the nearest training sample\n                      600       Corruption probability = 0.8\n                                Corruption probability = 0.0\n                      500\n                      400\n                      300\n                      200\n                     Number of generated samples\n                      100\n                        0\n                        0.60       0.65      0.70      0.75      0.80      0.85      0.90       0.95      1.00\n                                                           Similarity Value\nFigure 6: Distribution of similarity values to the nearest neighbor in the dataset for a finetuned IF\nmodel on a 3000 samples CelebA subset. Please note that similarity values above                                   0.95   roughly\ncorrespond to the same person and similarities below                     0.75   typically correspond to random faces.\nTherefore the baseline finetuning process (red) often generates images that are near copies of the\ntraining set. On the contrary, our fine-tuning with corrupted samples (blue) shows a clear shift to the\nleft. Visually we never observed a near-identical image generated from our process, see also Figure 1\nfor qualitative results.\n                                                                 9", "md": "# Document\n\nFigure 5: Left panel: We finetune Deepfloyd\u2019s IF diffusion model to make it a generative model for MRI images of brains with tumors. We use a small dataset [26] of only 155 images that was corrupted by removing large blocks as shown. Right panel: Generated samples from our finetuned model. As shown, the model learns the statistics of full brain tumor MRI images. The training set was resized to 64 \u00d7 64 but the generated images are at 256 \u00d7 256. The higher resolution is obtained by simply leveraging the power of the cascaded IF model. Memorization. We show that we can finetune a foundational model on a limited dataset without memorizing the training examples. This experiment is motivated by the recent works of Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] that show that diffusion generative models memorize training samples and they do it significantly more than previous generative models, such as GANs, especially when the training dataset is small. Specifically, Somepalli et al. [49] train diffusion models on subsets of size {300, 3000, 30000} of CelebA and they show that models trained on 300 or 3000 memorize and blatantly copy images from their training set.\n\nWe replicate this training experiment by finetuning the IF model on a subset of CelebA with 3000 training examples. Results are shown in Figure 1. Standard finetuning of Deepfloyd\u2019s IF on 3000 images memorizes samples and produces almost exact copies of the training set. Instead, if we corrupt the images by deleting 80% of the pixels prior to training and finetune, the memorization decreases sharply and there are distinct differences between the generated images and their nearest neighbors from the dataset. This is in spite of finetuning until convergence.\n\n|Distribution of Similarity Values to the nearest training sample|\n|---|\n|600|Corruption probability = 0.8|\n|Corruption probability = 0.0|\n|500|\n|400|\n|300|\n|200|\n|Number of generated samples|\n|100|\n|0|\n|0.60|0.65|0.70|0.75|0.80|0.85|0.90|0.95|1.00|\n|Similarity Value|\n\nFigure 6: Distribution of similarity values to the nearest neighbor in the dataset for a finetuned IF model on a 3000 samples CelebA subset. Please note that similarity values above 0.95 roughly correspond to the same person and similarities below 0.75 typically correspond to random faces. Therefore the baseline finetuning process (red) often generates images that are near copies of the training set. On the contrary, our fine-tuning with corrupted samples (blue) shows a clear shift to the left. Visually we never observed a near-identical image generated from our process, see also Figure 1 for qualitative results.", "images": [{"name": "img_p8_1", "height": 357, "width": 357}, {"name": "img_p8_2", "height": 353, "width": 357}], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "Figure 5: Left panel: We finetune Deepfloyd\u2019s IF diffusion model to make it a generative model for MRI images of brains with tumors. We use a small dataset [26] of only 155 images that was corrupted by removing large blocks as shown. Right panel: Generated samples from our finetuned model. As shown, the model learns the statistics of full brain tumor MRI images. The training set was resized to 64 \u00d7 64 but the generated images are at 256 \u00d7 256. The higher resolution is obtained by simply leveraging the power of the cascaded IF model. Memorization. We show that we can finetune a foundational model on a limited dataset without memorizing the training examples. This experiment is motivated by the recent works of Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] that show that diffusion generative models memorize training samples and they do it significantly more than previous generative models, such as GANs, especially when the training dataset is small. Specifically, Somepalli et al. [49] train diffusion models on subsets of size {300, 3000, 30000} of CelebA and they show that models trained on 300 or 3000 memorize and blatantly copy images from their training set.\n\nWe replicate this training experiment by finetuning the IF model on a subset of CelebA with 3000 training examples. Results are shown in Figure 1. Standard finetuning of Deepfloyd\u2019s IF on 3000 images memorizes samples and produces almost exact copies of the training set. Instead, if we corrupt the images by deleting 80% of the pixels prior to training and finetune, the memorization decreases sharply and there are distinct differences between the generated images and their nearest neighbors from the dataset. This is in spite of finetuning until convergence.", "md": "Figure 5: Left panel: We finetune Deepfloyd\u2019s IF diffusion model to make it a generative model for MRI images of brains with tumors. We use a small dataset [26] of only 155 images that was corrupted by removing large blocks as shown. Right panel: Generated samples from our finetuned model. As shown, the model learns the statistics of full brain tumor MRI images. The training set was resized to 64 \u00d7 64 but the generated images are at 256 \u00d7 256. The higher resolution is obtained by simply leveraging the power of the cascaded IF model. Memorization. We show that we can finetune a foundational model on a limited dataset without memorizing the training examples. This experiment is motivated by the recent works of Carlini et al. [8], Somepalli et al. [49], and Jagielski et al. [27] that show that diffusion generative models memorize training samples and they do it significantly more than previous generative models, such as GANs, especially when the training dataset is small. Specifically, Somepalli et al. [49] train diffusion models on subsets of size {300, 3000, 30000} of CelebA and they show that models trained on 300 or 3000 memorize and blatantly copy images from their training set.\n\nWe replicate this training experiment by finetuning the IF model on a subset of CelebA with 3000 training examples. Results are shown in Figure 1. Standard finetuning of Deepfloyd\u2019s IF on 3000 images memorizes samples and produces almost exact copies of the training set. Instead, if we corrupt the images by deleting 80% of the pixels prior to training and finetune, the memorization decreases sharply and there are distinct differences between the generated images and their nearest neighbors from the dataset. This is in spite of finetuning until convergence."}, {"type": "table", "rows": [["Distribution of Similarity Values to the nearest training sample"], ["600", "Corruption probability = 0.8"], ["Corruption probability = 0.0"], ["500"], ["400"], ["300"], ["200"], ["Number of generated samples"], ["100"], ["0"], ["0.60", "0.65", "0.70", "0.75", "0.80", "0.85", "0.90", "0.95", "1.00"], ["Similarity Value"]], "md": "|Distribution of Similarity Values to the nearest training sample|\n|---|\n|600|Corruption probability = 0.8|\n|Corruption probability = 0.0|\n|500|\n|400|\n|300|\n|200|\n|Number of generated samples|\n|100|\n|0|\n|0.60|0.65|0.70|0.75|0.80|0.85|0.90|0.95|1.00|\n|Similarity Value|", "isPerfectTable": false, "csv": "\"Distribution of Similarity Values to the nearest training sample\"\n\"600\",\"Corruption probability = 0.8\"\n\"Corruption probability = 0.0\"\n\"500\"\n\"400\"\n\"300\"\n\"200\"\n\"Number of generated samples\"\n\"100\"\n\"0\"\n\"0.60\",\"0.65\",\"0.70\",\"0.75\",\"0.80\",\"0.85\",\"0.90\",\"0.95\",\"1.00\"\n\"Similarity Value\""}, {"type": "text", "value": "Figure 6: Distribution of similarity values to the nearest neighbor in the dataset for a finetuned IF model on a 3000 samples CelebA subset. Please note that similarity values above 0.95 roughly correspond to the same person and similarities below 0.75 typically correspond to random faces. Therefore the baseline finetuning process (red) often generates images that are near copies of the training set. On the contrary, our fine-tuning with corrupted samples (blue) shows a clear shift to the left. Visually we never observed a near-identical image generated from our process, see also Figure 1 for qualitative results.", "md": "Figure 6: Distribution of similarity values to the nearest neighbor in the dataset for a finetuned IF model on a 3000 samples CelebA subset. Please note that similarity values above 0.95 roughly correspond to the same person and similarities below 0.75 typically correspond to random faces. Therefore the baseline finetuning process (red) often generates images that are near copies of the training set. On the contrary, our fine-tuning with corrupted samples (blue) shows a clear shift to the left. Visually we never observed a near-identical image generated from our process, see also Figure 1 for qualitative results."}]}, {"page": 10, "text": "To quantify the memorization, we follow the methodology of Somepalli et al. [49]. Specifically, we\n generate 10000 images from each model and we use DINO [9]-v2 [42] to compute top-1                               similarity to\n the training images. Results are shown in Figure 6. Similarity values above                     0.95   roughly correspond\n to the same person while similarities below             0.75  typically correspond to random faces. The standard\n finetuning (Red) often generates images that are near-identical with the training set. Instead, fine-\n tuning with corrupted samples (blue) shows a clear shift to the left. Visually we never observed a\n near-copy generated from our process \u2013 see also Figure 1.\nWe repeat this experiment for models trained on the full CelebA dataset and at different levels of\n corruption. We include the results in Figure 8 of the Appendix. As shown, the more we increase the\n corruption level the more the distribution of similarities shifts to the left, indicating less memorization.\n However, this comes at the cost of decreased performance, as reported in Table 4.\n New domains and different corruption.                We show that we can also finetune a pre-trained foundation\n model on a     new domain      given a limited-sized dataset in a few hours in a single GPU. Figure 5 shows\n generated samples from a finetuned model on a dataset containing                    155   examples of brain tumor MRI\n images [26]. As shown, the model learns the statistics of full brain tumor MRI images while only\n trained on brain-tumor images that have a random box obfuscating                       25%    of the image. The training\n set was resized to     64  \u00d764    but the generated images are at         256  \u00d7  256   by simply leveraging the power\n of the cascaded Deepfloyd IF.\n Limitations.     Our work has several limitations. First, there is a tradeoff between generator quality and\n corruption levels. For higher corruption, it is less likely that our generator memorizes parts of training\n examples, but at a cost of degrading quality. Precisely characterizing this trade-off is an open research\n problem. Further, in this work, we only experimented with very simple approximation algorithms to\n estimateE[x     0 |x t] using our trained models. Additionally, we cannot make any strict privacy claim\n about the protection of any training sample without making assumptions about the data distribution.\nWe show in the Appendix that it is possible to recover                 E[x  0|x  t]exactly using our restoration oracle,\n but we do not have an algorithm to do so. Finally, our method cannot handle measurements that also\n have noise. Future work could potentially address this limitation by exploiting SURE regularization\n as in [1].\n Acknowledgements.             The authors would like to thank Tom Goldstein for insightful discussions that\n benefited this work. This research has been supported by NSF Grants CCF 1763702, AF 1901292,\n CNS 2148141, Tripods CCF 1934932, NSF AI Institute for Foundations of Machine Learning (IFML)\n 2019844, the Texas Advanced Computing Center (TACC) and research gifts by Western Digital,\nWNCG IAP, UT Austin Machine Learning Lab (MLL), Cisco and the Archie Straiton Endowed\n Faculty Fellowship. Giannis Daras has been supported by the Onassis Fellowship (Scholarship ID: F\n ZS 012-1/2022-2023), the Bodossaki Fellowship and the Leventis Fellowship.\n References\n  [1]    Asad Aali, Marius Arvinte, Sidharth Kumar, and Jonathan I Tamir. \u201cSolving Inverse Prob-\n         lems with Score-Based Generative Priors learned from Noisy Data\u201d. In:                                arXiv preprint\n         arXiv:2305.01166         (2023) (page 10).\n  [2]    Stability AI.    Deepfloyd IF.     https://github.com/deep-floyd/IF. 2013 (pages 8, 17).\n  [3]    Brian D.O. Anderson. \u201cReverse-time diffusion equation models\u201d. In:                      Stochastic Processes and\n         their Applications      12.3 (1982), pp. 313\u2013326 (page 3).\n  [4]    Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie S Li, Hamid Kazemi, Furong Huang, Micah\n         Goldblum, Jonas Geiping, and Tom Goldstein. \u201cCold diffusion: Inverting arbitrary image\n         transforms without noise\u201d. In:          arXiv preprint arXiv:2208.09392             (2022) (page 4).\n  [5]    Joshua Batson and Loic Royer. \u201cNoise2self: Blind denoising by self-supervision\u201d. In:                          Interna-\n         tional Conference on Machine Learning. PMLR. 2019, pp. 524\u2013533 (page 2).\n  [6]    Felix JB B\u00e4uerlein and Wolfgang Baumeister. \u201cTowards visual proteomics at high resolution\u201d.\n         In:  Journal of Molecular Biology           433.20 (2021), p. 167187 (page 2).\n  [7]    Ashish Bora, Eric Price, and Alexandros G Dimakis. \u201cAmbientGAN: Generative models from\n         lossy measurements\u201d. In:         International conference on learning representations. 2018 (pages 2,\n         3, 8).\n                                                               10", "md": "To quantify the memorization, we follow the methodology of Somepalli et al. [49]. Specifically, we generate 10000 images from each model and we use DINO $$[9]-v2 [42]$$ to compute top-1 similarity to the training images. Results are shown in Figure 6. Similarity values above $$0.95$$ roughly correspond to the same person while similarities below $$0.75$$ typically correspond to random faces. The standard finetuning (Red) often generates images that are near-identical with the training set. Instead, fine-tuning with corrupted samples (blue) shows a clear shift to the left. Visually we never observed a near-copy generated from our process \u2013 see also Figure 1.\n\nWe repeat this experiment for models trained on the full CelebA dataset and at different levels of corruption. We include the results in Figure 8 of the Appendix. As shown, the more we increase the corruption level the more the distribution of similarities shifts to the left, indicating less memorization. However, this comes at the cost of decreased performance, as reported in Table 4.\n\nNew domains and different corruption. We show that we can also finetune a pre-trained foundation model on a new domain given a limited-sized dataset in a few hours in a single GPU. Figure 5 shows generated samples from a finetuned model on a dataset containing $$155$$ examples of brain tumor MRI images [26]. As shown, the model learns the statistics of full brain tumor MRI images while only trained on brain-tumor images that have a random box obfuscating $$25\\%$$ of the image. The training set was resized to $$64 \\times 64$$ but the generated images are at $$256 \\times 256$$ by simply leveraging the power of the cascaded Deepfloyd IF.\n\nLimitations. Our work has several limitations. First, there is a tradeoff between generator quality and corruption levels. For higher corruption, it is less likely that our generator memorizes parts of training examples, but at a cost of degrading quality. Precisely characterizing this trade-off is an open research problem. Further, in this work, we only experimented with very simple approximation algorithms to estimate $$E[x_0 | x_t]$$ using our trained models. Additionally, we cannot make any strict privacy claim about the protection of any training sample without making assumptions about the data distribution.\n\nWe show in the Appendix that it is possible to recover $$E[x_0 | x_t]$$ exactly using our restoration oracle, but we do not have an algorithm to do so. Finally, our method cannot handle measurements that also have noise. Future work could potentially address this limitation by exploiting SURE regularization as in [1].\n\nAcknowledgements. The authors would like to thank Tom Goldstein for insightful discussions that benefited this work. This research has been supported by NSF Grants CCF 1763702, AF 1901292, CNS 2148141, Tripods CCF 1934932, NSF AI Institute for Foundations of Machine Learning (IFML) 2019844, the Texas Advanced Computing Center (TACC) and research gifts by Western Digital, WNCG IAP, UT Austin Machine Learning Lab (MLL), Cisco and the Archie Straiton Endowed Faculty Fellowship. Giannis Daras has been supported by the Onassis Fellowship (Scholarship ID: F ZS 012-1/2022-2023), the Bodossaki Fellowship and the Leventis Fellowship.\n\nReferences\n1. Asad Aali, Marius Arvinte, Sidharth Kumar, and Jonathan I Tamir. \u201cSolving Inverse Problems with Score-Based Generative Priors learned from Noisy Data\u201d. In: arXiv preprint arXiv:2305.01166 (2023) (page 10).\n2. Stability AI. Deepfloyd IF. [https://github.com/deep-floyd/IF](https://github.com/deep-floyd/IF). 2013 (pages 8, 17).\n3. Brian D.O. Anderson. \u201cReverse-time diffusion equation models\u201d. In: Stochastic Processes and their Applications 12.3 (1982), pp. 313\u2013326 (page 3).\n4. Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie S Li, Hamid Kazemi, Furong Huang, Micah Goldblum, Jonas Geiping, and Tom Goldstein. \u201cCold diffusion: Inverting arbitrary image transforms without noise\u201d. In: arXiv preprint arXiv:2208.09392 (2022) (page 4).\n5. Joshua Batson and Loic Royer. \u201cNoise2self: Blind denoising by self-supervision\u201d. In: International Conference on Machine Learning. PMLR. 2019, pp. 524\u2013533 (page 2).\n6. Felix JB B\u00e4uerlein and Wolfgang Baumeister. \u201cTowards visual proteomics at high resolution\u201d. In: Journal of Molecular Biology 433.20 (2021), p. 167187 (page 2).\n7. Ashish Bora, Eric Price, and Alexandros G Dimakis. \u201cAmbientGAN: Generative models from lossy measurements\u201d. In: International conference on learning representations. 2018 (pages 2, 3, 8).", "images": [], "items": [{"type": "text", "value": "To quantify the memorization, we follow the methodology of Somepalli et al. [49]. Specifically, we generate 10000 images from each model and we use DINO $$[9]-v2 [42]$$ to compute top-1 similarity to the training images. Results are shown in Figure 6. Similarity values above $$0.95$$ roughly correspond to the same person while similarities below $$0.75$$ typically correspond to random faces. The standard finetuning (Red) often generates images that are near-identical with the training set. Instead, fine-tuning with corrupted samples (blue) shows a clear shift to the left. Visually we never observed a near-copy generated from our process \u2013 see also Figure 1.\n\nWe repeat this experiment for models trained on the full CelebA dataset and at different levels of corruption. We include the results in Figure 8 of the Appendix. As shown, the more we increase the corruption level the more the distribution of similarities shifts to the left, indicating less memorization. However, this comes at the cost of decreased performance, as reported in Table 4.\n\nNew domains and different corruption. We show that we can also finetune a pre-trained foundation model on a new domain given a limited-sized dataset in a few hours in a single GPU. Figure 5 shows generated samples from a finetuned model on a dataset containing $$155$$ examples of brain tumor MRI images [26]. As shown, the model learns the statistics of full brain tumor MRI images while only trained on brain-tumor images that have a random box obfuscating $$25\\%$$ of the image. The training set was resized to $$64 \\times 64$$ but the generated images are at $$256 \\times 256$$ by simply leveraging the power of the cascaded Deepfloyd IF.\n\nLimitations. Our work has several limitations. First, there is a tradeoff between generator quality and corruption levels. For higher corruption, it is less likely that our generator memorizes parts of training examples, but at a cost of degrading quality. Precisely characterizing this trade-off is an open research problem. Further, in this work, we only experimented with very simple approximation algorithms to estimate $$E[x_0 | x_t]$$ using our trained models. Additionally, we cannot make any strict privacy claim about the protection of any training sample without making assumptions about the data distribution.\n\nWe show in the Appendix that it is possible to recover $$E[x_0 | x_t]$$ exactly using our restoration oracle, but we do not have an algorithm to do so. Finally, our method cannot handle measurements that also have noise. Future work could potentially address this limitation by exploiting SURE regularization as in [1].\n\nAcknowledgements. The authors would like to thank Tom Goldstein for insightful discussions that benefited this work. This research has been supported by NSF Grants CCF 1763702, AF 1901292, CNS 2148141, Tripods CCF 1934932, NSF AI Institute for Foundations of Machine Learning (IFML) 2019844, the Texas Advanced Computing Center (TACC) and research gifts by Western Digital, WNCG IAP, UT Austin Machine Learning Lab (MLL), Cisco and the Archie Straiton Endowed Faculty Fellowship. Giannis Daras has been supported by the Onassis Fellowship (Scholarship ID: F ZS 012-1/2022-2023), the Bodossaki Fellowship and the Leventis Fellowship.\n\nReferences\n1. Asad Aali, Marius Arvinte, Sidharth Kumar, and Jonathan I Tamir. \u201cSolving Inverse Problems with Score-Based Generative Priors learned from Noisy Data\u201d. In: arXiv preprint arXiv:2305.01166 (2023) (page 10).\n2. Stability AI. Deepfloyd IF. [https://github.com/deep-floyd/IF](https://github.com/deep-floyd/IF). 2013 (pages 8, 17).\n3. Brian D.O. Anderson. \u201cReverse-time diffusion equation models\u201d. In: Stochastic Processes and their Applications 12.3 (1982), pp. 313\u2013326 (page 3).\n4. Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie S Li, Hamid Kazemi, Furong Huang, Micah Goldblum, Jonas Geiping, and Tom Goldstein. \u201cCold diffusion: Inverting arbitrary image transforms without noise\u201d. In: arXiv preprint arXiv:2208.09392 (2022) (page 4).\n5. Joshua Batson and Loic Royer. \u201cNoise2self: Blind denoising by self-supervision\u201d. In: International Conference on Machine Learning. PMLR. 2019, pp. 524\u2013533 (page 2).\n6. Felix JB B\u00e4uerlein and Wolfgang Baumeister. \u201cTowards visual proteomics at high resolution\u201d. In: Journal of Molecular Biology 433.20 (2021), p. 167187 (page 2).\n7. Ashish Bora, Eric Price, and Alexandros G Dimakis. \u201cAmbientGAN: Generative models from lossy measurements\u201d. In: International conference on learning representations. 2018 (pages 2, 3, 8).", "md": "To quantify the memorization, we follow the methodology of Somepalli et al. [49]. Specifically, we generate 10000 images from each model and we use DINO $$[9]-v2 [42]$$ to compute top-1 similarity to the training images. Results are shown in Figure 6. Similarity values above $$0.95$$ roughly correspond to the same person while similarities below $$0.75$$ typically correspond to random faces. The standard finetuning (Red) often generates images that are near-identical with the training set. Instead, fine-tuning with corrupted samples (blue) shows a clear shift to the left. Visually we never observed a near-copy generated from our process \u2013 see also Figure 1.\n\nWe repeat this experiment for models trained on the full CelebA dataset and at different levels of corruption. We include the results in Figure 8 of the Appendix. As shown, the more we increase the corruption level the more the distribution of similarities shifts to the left, indicating less memorization. However, this comes at the cost of decreased performance, as reported in Table 4.\n\nNew domains and different corruption. We show that we can also finetune a pre-trained foundation model on a new domain given a limited-sized dataset in a few hours in a single GPU. Figure 5 shows generated samples from a finetuned model on a dataset containing $$155$$ examples of brain tumor MRI images [26]. As shown, the model learns the statistics of full brain tumor MRI images while only trained on brain-tumor images that have a random box obfuscating $$25\\%$$ of the image. The training set was resized to $$64 \\times 64$$ but the generated images are at $$256 \\times 256$$ by simply leveraging the power of the cascaded Deepfloyd IF.\n\nLimitations. Our work has several limitations. First, there is a tradeoff between generator quality and corruption levels. For higher corruption, it is less likely that our generator memorizes parts of training examples, but at a cost of degrading quality. Precisely characterizing this trade-off is an open research problem. Further, in this work, we only experimented with very simple approximation algorithms to estimate $$E[x_0 | x_t]$$ using our trained models. Additionally, we cannot make any strict privacy claim about the protection of any training sample without making assumptions about the data distribution.\n\nWe show in the Appendix that it is possible to recover $$E[x_0 | x_t]$$ exactly using our restoration oracle, but we do not have an algorithm to do so. Finally, our method cannot handle measurements that also have noise. Future work could potentially address this limitation by exploiting SURE regularization as in [1].\n\nAcknowledgements. The authors would like to thank Tom Goldstein for insightful discussions that benefited this work. This research has been supported by NSF Grants CCF 1763702, AF 1901292, CNS 2148141, Tripods CCF 1934932, NSF AI Institute for Foundations of Machine Learning (IFML) 2019844, the Texas Advanced Computing Center (TACC) and research gifts by Western Digital, WNCG IAP, UT Austin Machine Learning Lab (MLL), Cisco and the Archie Straiton Endowed Faculty Fellowship. Giannis Daras has been supported by the Onassis Fellowship (Scholarship ID: F ZS 012-1/2022-2023), the Bodossaki Fellowship and the Leventis Fellowship.\n\nReferences\n1. Asad Aali, Marius Arvinte, Sidharth Kumar, and Jonathan I Tamir. \u201cSolving Inverse Problems with Score-Based Generative Priors learned from Noisy Data\u201d. In: arXiv preprint arXiv:2305.01166 (2023) (page 10).\n2. Stability AI. Deepfloyd IF. [https://github.com/deep-floyd/IF](https://github.com/deep-floyd/IF). 2013 (pages 8, 17).\n3. Brian D.O. Anderson. \u201cReverse-time diffusion equation models\u201d. In: Stochastic Processes and their Applications 12.3 (1982), pp. 313\u2013326 (page 3).\n4. Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie S Li, Hamid Kazemi, Furong Huang, Micah Goldblum, Jonas Geiping, and Tom Goldstein. \u201cCold diffusion: Inverting arbitrary image transforms without noise\u201d. In: arXiv preprint arXiv:2208.09392 (2022) (page 4).\n5. Joshua Batson and Loic Royer. \u201cNoise2self: Blind denoising by self-supervision\u201d. In: International Conference on Machine Learning. PMLR. 2019, pp. 524\u2013533 (page 2).\n6. Felix JB B\u00e4uerlein and Wolfgang Baumeister. \u201cTowards visual proteomics at high resolution\u201d. In: Journal of Molecular Biology 433.20 (2021), p. 167187 (page 2).\n7. Ashish Bora, Eric Price, and Alexandros G Dimakis. \u201cAmbientGAN: Generative models from lossy measurements\u201d. In: International conference on learning representations. 2018 (pages 2, 3, 8)."}]}, {"page": 11, "text": " [8]  Nicholas Carlini, Florian Tram\u00e8r, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Kather-\n      ine Lee, Adam Roberts, Tom Brown, Dawn Song, \u00dalfar Erlingsson, Alina Oprea, and Colin\n      Raffel. \u201cExtracting Training Data from Large Language Models\u201d. In:                         30th USENIX Secu-\n      rity Symposium (USENIX Security 21). 2021, pp. 2633\u20132650.                         ISBN: 978-1-939133-24-3.\n      URL:    https://www.usenix.org/conference/usenixsecurity21/presentation/\n      carlini-extracting             (visited on 11/10/2022) (pages 1, 2, 9).\n [9]  Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski,\n      and Armand Joulin. \u201cEmerging properties in self-supervised vision transformers\u201d. In:                          Pro-\n      ceedings of the IEEE/CVF international conference on computer vision. 2021, pp. 9650\u20139660\n      (page 10).\n[10]  Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru R Zhang. \u201cSampling is\n      as easy as learning the score: theory for diffusion models with minimal data assumptions\u201d. In:\n      arXiv preprint arXiv:2209.11215           (2022) (pages 15, 16).\n[11]  Hyungjin Chung, Jeongsol Kim, Michael Thompson Mccann, Marc Louis Klasky, and Jong\n      Chul Ye. \u201cDiffusion Posterior Sampling for General Noisy Inverse Problems\u201d. In:                     The Eleventh\n      International Conference on Learning Representations. 2023.                    URL:   https://openreview.\n      net/forum?id=OnD9zGAGT0k                (pages 1, 7, 8, 20).\n[12]  The Event Horizon Telescope Collaboration et al. \u201cFirst M87 Event Horizon Telescope Results.\n      IV. Imaging the Central Supermassive Black Hole\u201d. In:                   The Astrophysical Journal Letters\n      875.1 (Apr. 2019), p. L4.         DOI:   10.3847/2041- 8213/ab0e85.                 URL:   https://dx.doi.\n      org/10.3847/2041-8213/ab0e85                   (page 1).\n[13]  Giannis Daras, Yuval Dagan, Alexandros G Dimakis, and Constantinos Daskalakis. \u201cConsistent\n      diffusion models: Mitigating sampling drift by learning to be consistent\u201d. In:                    arXiv preprint\n      arXiv:2302.09057        (2023) (page 6).\n[14]  Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alex Dimakis, and Peyman Milanfar.\n      \u201cSoft Diffusion: Score Matching with General Corruptions\u201d. In:                     Transactions on Machine\n      Learning Research       (2023).   ISSN: 2835-8856.      URL:   https://openreview.net/forum?id=\n      W98rebBxlQ       (pages 3, 4).\n[15]  Mauricio Delbracio and Peyman Milanfar. \u201cInversion by direct iteration: An alternative\n      to denoising diffusion for image restoration\u201d. In:              arXiv preprint arXiv:2303.11435            (2023)\n      (page 2).\n[16]  Jeffrey M Ede. \u201cDeep learning in electron microscopy\u201d. In:                  Machine Learning: Science and\n      Technology     2.1 (2021), p. 011004 (page 2).\n[17]  Bradley Efron. \u201cTweedie\u2019s formula and selection bias\u201d. In:               Journal of the American Statistical\n      Association    106.496 (2011), pp. 1602\u20131614 (page 4).\n[18]  Yonina C. Eldar. \u201cGeneralized SURE for Exponential Families: Applications to Regulariza-\n      tion\u201d. In:  IEEE Transactions on Signal Processing             57.2 (2009), pp. 471\u2013481.        DOI:   10.1109/\n      TSP.2008.2008212           (page 2).\n[19]  Angela F Gao, Oscar Leong, He Sun, and Katherine L Bouman. \u201cImage Reconstruction\n      without Explicit Priors\u201d. In:       ICASSP 2023-2023 IEEE International Conference on Acoustics,\n      Speech and Signal Processing (ICASSP). IEEE. 2023, pp. 1\u20135 (page 1).\n[20]  Shi Guo, Zifei Yan, Kai Zhang, Wangmeng Zuo, and Lei Zhang. \u201cToward convolutional blind\n      denoising of real photographs\u201d. In:           Proceedings of the IEEE/CVF conference on computer\n      vision and pattern recognition. 2019, pp. 1712\u20131722 (page 2).\n[21]  Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. \u201cMasked\n      autoencoders are scalable vision learners\u201d. In:            Proceedings of the IEEE/CVF Conference on\n      Computer Vision and Pattern Recognition. 2022, pp. 16000\u201316009 (page 18).\n[22]  Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.\n      \u201cGans trained by a two time-scale update rule converge to a local nash equilibrium\u201d. In:\n      Advances in neural information processing systems                30 (2017) (page 17).\n[23]  Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko,\n      Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. \u201cImagen video:\n      High definition video generation with diffusion models\u201d. In:               arXiv preprint arXiv:2210.02303\n      (2022) (page 6).\n[24]  Jonathan Ho, Ajay Jain, and Pieter Abbeel. \u201cDenoising diffusion probabilistic models\u201d. In:\n      Advances in Neural Information Processing Systems                 33 (2020), pp. 6840\u20136851 (pages 1, 17).\n                                                          11", "md": "# References\n\n# References\n\n|[8]|Nicholas Carlini, Florian Tram\u00e8r, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, \u00dalfar Erlingsson, Alina Oprea, and Colin Raffel. \u201cExtracting Training Data from Large Language Models\u201d. In: 30th USENIX Security Symposium (USENIX Security 21). 2021, pp. 2633\u20132650. ISBN: 978-1-939133-24-3. URL: (link) (visited on 11/10/2022) (pages 1, 2, 9).|\n|---|---|\n|[9]|Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. \u201cEmerging properties in self-supervised vision transformers\u201d. In: Proceedings of the IEEE/CVF international conference on computer vision. 2021, pp. 9650\u20139660 (page 10).|\n|[10]|Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru R Zhang. \u201cSampling is as easy as learning the score: theory for diffusion models with minimal data assumptions\u201d. In: arXiv preprint arXiv:2209.11215 (2022) (pages 15, 16).|\n|[11]|Hyungjin Chung, Jeongsol Kim, Michael Thompson Mccann, Marc Louis Klasky, and Jong Chul Ye. \u201cDiffusion Posterior Sampling for General Noisy Inverse Problems\u201d. In: The Eleventh International Conference on Learning Representations. 2023. URL: (link) (pages 1, 7, 8, 20).|\n|[12]|The Event Horizon Telescope Collaboration et al. \u201cFirst M87 Event Horizon Telescope Results. IV. Imaging the Central Supermassive Black Hole\u201d. In: The Astrophysical Journal Letters 875.1 (Apr. 2019), p. L4. DOI: 10.3847/2041-8213/ab0e85. URL: (link) (page 1).|\n|[13]|Giannis Daras, Yuval Dagan, Alexandros G Dimakis, and Constantinos Daskalakis. \u201cConsistent diffusion models: Mitigating sampling drift by learning to be consistent\u201d. In: arXiv preprint arXiv:2302.09057 (2023) (page 6).|\n|[14]|Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alex Dimakis, and Peyman Milanfar. \u201cSoft Diffusion: Score Matching with General Corruptions\u201d. In: Transactions on Machine Learning Research (2023). ISSN: 2835-8856. URL: (link) (pages 3, 4).|\n|[15]|Mauricio Delbracio and Peyman Milanfar. \u201cInversion by direct iteration: An alternative to denoising diffusion for image restoration\u201d. In: arXiv preprint arXiv:2303.11435 (2023) (page 2).|\n|[16]|Jeffrey M Ede. \u201cDeep learning in electron microscopy\u201d. In: Machine Learning: Science and Technology 2.1 (2021), p. 011004 (page 2).|\n|[17]|Bradley Efron. \u201cTweedie\u2019s formula and selection bias\u201d. In: Journal of the American Statistical Association 106.496 (2011), pp. 1602\u20131614 (page 4).|\n|[18]|Yonina C. Eldar. \u201cGeneralized SURE for Exponential Families: Applications to Regularization\u201d. In: IEEE Transactions on Signal Processing 57.2 (2009), pp. 471\u2013481. DOI: 10.1109/TSP.2008.2008212 (page 2).|\n|[19]|Angela F Gao, Oscar Leong, He Sun, and Katherine L Bouman. \u201cImage Reconstruction without Explicit Priors\u201d. In: ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE. 2023, pp. 1\u20135 (page 1).|\n|[20]|Shi Guo, Zifei Yan, Kai Zhang, Wangmeng Zuo, and Lei Zhang. \u201cToward convolutional blind denoising of real photographs\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 1712\u20131722 (page 2).|\n|[21]|Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. \u201cMasked autoencoders are scalable vision learners\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 16000\u201316009 (page 18).|\n|[22]|Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. \u201cGans trained by a two time-scale update rule converge to a local nash equilibrium\u201d. In: Advances in neural information processing systems 30 (2017) (page 17).|\n|[23]|Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. \u201cImagen video: High definition video generation with diffusion models\u201d. In: arXiv preprint arXiv:2210.02303 (2022) (page 6).|\n|[24]|Jonathan Ho, Ajay Jain, and Pieter Abbeel. \u201cDenoising diffusion probabilistic models\u201d. In: Advances in Neural Information Processing Systems 33 (2020), pp. 6840\u20136851 (pages 1, 17).|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "table", "rows": [["[8]", "Nicholas Carlini, Florian Tram\u00e8r, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, \u00dalfar Erlingsson, Alina Oprea, and Colin Raffel. \u201cExtracting Training Data from Large Language Models\u201d. In: 30th USENIX Security Symposium (USENIX Security 21). 2021, pp. 2633\u20132650. ISBN: 978-1-939133-24-3. URL: (link) (visited on 11/10/2022) (pages 1, 2, 9)."], ["[9]", "Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. \u201cEmerging properties in self-supervised vision transformers\u201d. In: Proceedings of the IEEE/CVF international conference on computer vision. 2021, pp. 9650\u20139660 (page 10)."], ["[10]", "Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru R Zhang. \u201cSampling is as easy as learning the score: theory for diffusion models with minimal data assumptions\u201d. In: arXiv preprint arXiv:2209.11215 (2022) (pages 15, 16)."], ["[11]", "Hyungjin Chung, Jeongsol Kim, Michael Thompson Mccann, Marc Louis Klasky, and Jong Chul Ye. \u201cDiffusion Posterior Sampling for General Noisy Inverse Problems\u201d. In: The Eleventh International Conference on Learning Representations. 2023. URL: (link) (pages 1, 7, 8, 20)."], ["[12]", "The Event Horizon Telescope Collaboration et al. \u201cFirst M87 Event Horizon Telescope Results. IV. Imaging the Central Supermassive Black Hole\u201d. In: The Astrophysical Journal Letters 875.1 (Apr. 2019), p. L4. DOI: 10.3847/2041-8213/ab0e85. URL: (link) (page 1)."], ["[13]", "Giannis Daras, Yuval Dagan, Alexandros G Dimakis, and Constantinos Daskalakis. \u201cConsistent diffusion models: Mitigating sampling drift by learning to be consistent\u201d. In: arXiv preprint arXiv:2302.09057 (2023) (page 6)."], ["[14]", "Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alex Dimakis, and Peyman Milanfar. \u201cSoft Diffusion: Score Matching with General Corruptions\u201d. In: Transactions on Machine Learning Research (2023). ISSN: 2835-8856. URL: (link) (pages 3, 4)."], ["[15]", "Mauricio Delbracio and Peyman Milanfar. \u201cInversion by direct iteration: An alternative to denoising diffusion for image restoration\u201d. In: arXiv preprint arXiv:2303.11435 (2023) (page 2)."], ["[16]", "Jeffrey M Ede. \u201cDeep learning in electron microscopy\u201d. In: Machine Learning: Science and Technology 2.1 (2021), p. 011004 (page 2)."], ["[17]", "Bradley Efron. \u201cTweedie\u2019s formula and selection bias\u201d. In: Journal of the American Statistical Association 106.496 (2011), pp. 1602\u20131614 (page 4)."], ["[18]", "Yonina C. Eldar. \u201cGeneralized SURE for Exponential Families: Applications to Regularization\u201d. In: IEEE Transactions on Signal Processing 57.2 (2009), pp. 471\u2013481. DOI: 10.1109/TSP.2008.2008212 (page 2)."], ["[19]", "Angela F Gao, Oscar Leong, He Sun, and Katherine L Bouman. \u201cImage Reconstruction without Explicit Priors\u201d. In: ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE. 2023, pp. 1\u20135 (page 1)."], ["[20]", "Shi Guo, Zifei Yan, Kai Zhang, Wangmeng Zuo, and Lei Zhang. \u201cToward convolutional blind denoising of real photographs\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 1712\u20131722 (page 2)."], ["[21]", "Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. \u201cMasked autoencoders are scalable vision learners\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 16000\u201316009 (page 18)."], ["[22]", "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. \u201cGans trained by a two time-scale update rule converge to a local nash equilibrium\u201d. In: Advances in neural information processing systems 30 (2017) (page 17)."], ["[23]", "Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. \u201cImagen video: High definition video generation with diffusion models\u201d. In: arXiv preprint arXiv:2210.02303 (2022) (page 6)."], ["[24]", "Jonathan Ho, Ajay Jain, and Pieter Abbeel. \u201cDenoising diffusion probabilistic models\u201d. In: Advances in Neural Information Processing Systems 33 (2020), pp. 6840\u20136851 (pages 1, 17)."]], "md": "|[8]|Nicholas Carlini, Florian Tram\u00e8r, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, \u00dalfar Erlingsson, Alina Oprea, and Colin Raffel. \u201cExtracting Training Data from Large Language Models\u201d. In: 30th USENIX Security Symposium (USENIX Security 21). 2021, pp. 2633\u20132650. ISBN: 978-1-939133-24-3. URL: (link) (visited on 11/10/2022) (pages 1, 2, 9).|\n|---|---|\n|[9]|Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. \u201cEmerging properties in self-supervised vision transformers\u201d. In: Proceedings of the IEEE/CVF international conference on computer vision. 2021, pp. 9650\u20139660 (page 10).|\n|[10]|Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru R Zhang. \u201cSampling is as easy as learning the score: theory for diffusion models with minimal data assumptions\u201d. In: arXiv preprint arXiv:2209.11215 (2022) (pages 15, 16).|\n|[11]|Hyungjin Chung, Jeongsol Kim, Michael Thompson Mccann, Marc Louis Klasky, and Jong Chul Ye. \u201cDiffusion Posterior Sampling for General Noisy Inverse Problems\u201d. In: The Eleventh International Conference on Learning Representations. 2023. URL: (link) (pages 1, 7, 8, 20).|\n|[12]|The Event Horizon Telescope Collaboration et al. \u201cFirst M87 Event Horizon Telescope Results. IV. Imaging the Central Supermassive Black Hole\u201d. In: The Astrophysical Journal Letters 875.1 (Apr. 2019), p. L4. DOI: 10.3847/2041-8213/ab0e85. URL: (link) (page 1).|\n|[13]|Giannis Daras, Yuval Dagan, Alexandros G Dimakis, and Constantinos Daskalakis. \u201cConsistent diffusion models: Mitigating sampling drift by learning to be consistent\u201d. In: arXiv preprint arXiv:2302.09057 (2023) (page 6).|\n|[14]|Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alex Dimakis, and Peyman Milanfar. \u201cSoft Diffusion: Score Matching with General Corruptions\u201d. In: Transactions on Machine Learning Research (2023). ISSN: 2835-8856. URL: (link) (pages 3, 4).|\n|[15]|Mauricio Delbracio and Peyman Milanfar. \u201cInversion by direct iteration: An alternative to denoising diffusion for image restoration\u201d. In: arXiv preprint arXiv:2303.11435 (2023) (page 2).|\n|[16]|Jeffrey M Ede. \u201cDeep learning in electron microscopy\u201d. In: Machine Learning: Science and Technology 2.1 (2021), p. 011004 (page 2).|\n|[17]|Bradley Efron. \u201cTweedie\u2019s formula and selection bias\u201d. In: Journal of the American Statistical Association 106.496 (2011), pp. 1602\u20131614 (page 4).|\n|[18]|Yonina C. Eldar. \u201cGeneralized SURE for Exponential Families: Applications to Regularization\u201d. In: IEEE Transactions on Signal Processing 57.2 (2009), pp. 471\u2013481. DOI: 10.1109/TSP.2008.2008212 (page 2).|\n|[19]|Angela F Gao, Oscar Leong, He Sun, and Katherine L Bouman. \u201cImage Reconstruction without Explicit Priors\u201d. In: ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE. 2023, pp. 1\u20135 (page 1).|\n|[20]|Shi Guo, Zifei Yan, Kai Zhang, Wangmeng Zuo, and Lei Zhang. \u201cToward convolutional blind denoising of real photographs\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 1712\u20131722 (page 2).|\n|[21]|Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. \u201cMasked autoencoders are scalable vision learners\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 16000\u201316009 (page 18).|\n|[22]|Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. \u201cGans trained by a two time-scale update rule converge to a local nash equilibrium\u201d. In: Advances in neural information processing systems 30 (2017) (page 17).|\n|[23]|Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. \u201cImagen video: High definition video generation with diffusion models\u201d. In: arXiv preprint arXiv:2210.02303 (2022) (page 6).|\n|[24]|Jonathan Ho, Ajay Jain, and Pieter Abbeel. \u201cDenoising diffusion probabilistic models\u201d. In: Advances in Neural Information Processing Systems 33 (2020), pp. 6840\u20136851 (pages 1, 17).|", "isPerfectTable": true, "csv": "\"[8]\",\"Nicholas Carlini, Florian Tram\u00e8r, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, \u00dalfar Erlingsson, Alina Oprea, and Colin Raffel. \u201cExtracting Training Data from Large Language Models\u201d. In: 30th USENIX Security Symposium (USENIX Security 21). 2021, pp. 2633\u20132650. ISBN: 978-1-939133-24-3. URL: (link) (visited on 11/10/2022) (pages 1, 2, 9).\"\n\"[9]\",\"Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. \u201cEmerging properties in self-supervised vision transformers\u201d. In: Proceedings of the IEEE/CVF international conference on computer vision. 2021, pp. 9650\u20139660 (page 10).\"\n\"[10]\",\"Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru R Zhang. \u201cSampling is as easy as learning the score: theory for diffusion models with minimal data assumptions\u201d. In: arXiv preprint arXiv:2209.11215 (2022) (pages 15, 16).\"\n\"[11]\",\"Hyungjin Chung, Jeongsol Kim, Michael Thompson Mccann, Marc Louis Klasky, and Jong Chul Ye. \u201cDiffusion Posterior Sampling for General Noisy Inverse Problems\u201d. In: The Eleventh International Conference on Learning Representations. 2023. URL: (link) (pages 1, 7, 8, 20).\"\n\"[12]\",\"The Event Horizon Telescope Collaboration et al. \u201cFirst M87 Event Horizon Telescope Results. IV. Imaging the Central Supermassive Black Hole\u201d. In: The Astrophysical Journal Letters 875.1 (Apr. 2019), p. L4. DOI: 10.3847/2041-8213/ab0e85. URL: (link) (page 1).\"\n\"[13]\",\"Giannis Daras, Yuval Dagan, Alexandros G Dimakis, and Constantinos Daskalakis. \u201cConsistent diffusion models: Mitigating sampling drift by learning to be consistent\u201d. In: arXiv preprint arXiv:2302.09057 (2023) (page 6).\"\n\"[14]\",\"Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alex Dimakis, and Peyman Milanfar. \u201cSoft Diffusion: Score Matching with General Corruptions\u201d. In: Transactions on Machine Learning Research (2023). ISSN: 2835-8856. URL: (link) (pages 3, 4).\"\n\"[15]\",\"Mauricio Delbracio and Peyman Milanfar. \u201cInversion by direct iteration: An alternative to denoising diffusion for image restoration\u201d. In: arXiv preprint arXiv:2303.11435 (2023) (page 2).\"\n\"[16]\",\"Jeffrey M Ede. \u201cDeep learning in electron microscopy\u201d. In: Machine Learning: Science and Technology 2.1 (2021), p. 011004 (page 2).\"\n\"[17]\",\"Bradley Efron. \u201cTweedie\u2019s formula and selection bias\u201d. In: Journal of the American Statistical Association 106.496 (2011), pp. 1602\u20131614 (page 4).\"\n\"[18]\",\"Yonina C. Eldar. \u201cGeneralized SURE for Exponential Families: Applications to Regularization\u201d. In: IEEE Transactions on Signal Processing 57.2 (2009), pp. 471\u2013481. DOI: 10.1109/TSP.2008.2008212 (page 2).\"\n\"[19]\",\"Angela F Gao, Oscar Leong, He Sun, and Katherine L Bouman. \u201cImage Reconstruction without Explicit Priors\u201d. In: ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE. 2023, pp. 1\u20135 (page 1).\"\n\"[20]\",\"Shi Guo, Zifei Yan, Kai Zhang, Wangmeng Zuo, and Lei Zhang. \u201cToward convolutional blind denoising of real photographs\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 1712\u20131722 (page 2).\"\n\"[21]\",\"Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. \u201cMasked autoencoders are scalable vision learners\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 16000\u201316009 (page 18).\"\n\"[22]\",\"Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. \u201cGans trained by a two time-scale update rule converge to a local nash equilibrium\u201d. In: Advances in neural information processing systems 30 (2017) (page 17).\"\n\"[23]\",\"Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. \u201cImagen video: High definition video generation with diffusion models\u201d. In: arXiv preprint arXiv:2210.02303 (2022) (page 6).\"\n\"[24]\",\"Jonathan Ho, Ajay Jain, and Pieter Abbeel. \u201cDenoising diffusion probabilistic models\u201d. In: Advances in Neural Information Processing Systems 33 (2020), pp. 6840\u20136851 (pages 1, 17).\""}]}, {"page": 12, "text": "[25]  Jonathan Ho, Chitwan Saharia, William Chan, David J Fleet, Mohammad Norouzi, and Tim\n      Salimans. \u201cCascaded Diffusion Models for High Fidelity Image Generation.\u201d In:                             J. Mach.\n      Learn. Res.    23.47 (2022), pp. 1\u201333 (page 17).\n[26]  \u201cHuggingface Brain Tumor MRI Dataset\u201d. In: (2020).                     URL:   https://huggingface.co/\n      datasets/miladfa7/Brain- MRI- Images- for- Brain- Tumor- Detection/                                      (pages 9,\n      10).\n[27]  Matthew Jagielski, Om Thakkar, Florian Tram\u00e8r, Daphne Ippolito, Katherine Lee, Nicholas\n      Carlini, Eric Wallace, Shuang Song, Abhradeep Thakurta, Nicolas Papernot, and Chiyuan\n      Zhang. \u201cMeasuring Forgetting of Memorized Training Examples\u201d. In:                        arxiv:2207.00099[cs]\n      (June 2022).     DOI:   10.48550/arXiv.2207.00099. arXiv:                   2207.00099 [cs].          URL:   http:\n      //arxiv.org/abs/2207.00099                  (visited on 11/10/2022) (pages 1, 2, 9).\n[28]  Ajil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G Dimakis, and Jon Tamir.\n      \u201cRobust compressed sensing mri with deep generative priors\u201d. In:                 Advances in Neural Informa-\n      tion Processing Systems        34 (2021), pp. 14938\u201314954 (page 1).\n[29]  Zahra Kadkhodaie and Eero P Simoncelli. \u201cSolving linear inverse problems using the prior\n      implicit in a denoiser\u201d. In:      arXiv preprint arXiv:2007.13640           (2020) (page 8).\n[30]  Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. \u201cElucidating the design space of\n      diffusion-based generative models\u201d. In:            arXiv preprint arXiv:2206.00364           (2022) (pages 1, 7,\n      16\u201318).\n[31]  Tero Karras, Miika Aittala, Samuli Laine, Erik H\u00e4rk\u00f6nen, Janne Hellsten, Jaakko Lehtinen, and\n      Timo Aila. \u201cAlias-free generative adversarial networks\u201d. In:                Advances in Neural Information\n      Processing Systems        34 (2021), pp. 852\u2013863 (page 16).\n[32]  Tero Karras, Samuli Laine, and Timo Aila. \u201cA style-based generator architecture for generative\n      adversarial networks\u201d. In:        Proceedings of the IEEE/CVF conference on computer vision and\n      pattern recognition. 2019, pp. 4401\u20134410 (page 16).\n[33]  Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila.\n      \u201cAnalyzing and improving the image quality of stylegan\u201d. In:                  Proceedings of the IEEE/CVF\n      conference on computer vision and pattern recognition. 2020, pp. 8110\u20138119 (page 16).\n[34]  Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. \u201cDenoising Diffusion Restora-\n      tion Models\u201d. In:      Advances in Neural Information Processing Systems                 (pages 1, 7, 8, 20).\n[35]  Bahjat Kawar, Gregory Vaksman, and Michael Elad. \u201cSNIPS: Solving noisy inverse problems\n      stochastically\u201d. In:    Advances in Neural Information Processing Systems                34 (2021), pp. 21757\u2013\n      21769 (page 1).\n[36]  Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, and Il-Chul Moon. \u201cSoft\n      truncation: A universal training technique of score-based diffusion model for high precision\n      score estimation\u201d. In:     International Conference on Machine Learning. PMLR. 2022, pp. 11201\u2013\n      11228 (page 16).\n[37]  Alexander Krull, Tim-Oliver Buchholz, and Florian Jug. \u201cNoise2void-learning denoising from\n      single noisy images\u201d. In:        Proceedings of the IEEE/CVF conference on computer vision and\n      pattern recognition. 2019, pp. 2129\u20132137 (page 2).\n[38]  Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala,\n      and Timo Aila. \u201cNoise2Noise: Learning image restoration without clean data\u201d. In:                             arXiv\n      preprint arXiv:1803.04189          (2018) (page 2).\n[39]  Hongyu Liu, Bin Jiang, Yi Xiao, and Chao Yang. \u201cCoherent Semantic Attention for Image\n      Inpainting\u201d. In:    2019 IEEE/CVF International Conference on Computer Vision (ICCV)                          (Oct.\n      2019).    DOI:  10.1109/iccv.2019.00427.                 URL:   http://dx.doi.org/10.1109/ICCV.\n      2019.00427        (page 2).\n[40]  Sachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. \u201cPulse: Self-\n      supervised photo upsampling via latent space exploration of generative models\u201d. In:                      Proceed-\n      ings of the ieee/cvf conference on computer vision and pattern recognition. 2020, pp. 2437\u2013\n      2445 (page 16).\n[41]  Alex Nichol, Aditya Ramesh, Pamela Mishkin, Prafulla Dariwal, Joanne Jang, and Mark Chen.\n      DALL\u00b7E 2 Pre-Training Mitigations. June 2022.                 URL:   https://openai.com/blog/dall-\n      e-2-pre-training-mitigations/                    (visited on 11/10/2022) (page 1).\n                                                           12", "md": "Jonathan Ho, Chitwan Saharia, William Chan, David J Fleet, Mohammad Norouzi, and Tim Salimans. \u201cCascaded Diffusion Models for High Fidelity Image Generation.\u201d In: J. Mach. Learn. Res. 23.47 (2022), pp. 1\u201333 (page 17).\n\u201cHuggingface Brain Tumor MRI Dataset\u201d. In: (2020). URL: https://huggingface.co/datasets/miladfa7/Brain-MRI-Images-for-Brain-Tumor-Detection/ (pages 9, 10).\nMatthew Jagielski, Om Thakkar, Florian Tram\u00e8r, Daphne Ippolito, Katherine Lee, Nicholas Carlini, Eric Wallace, Shuang Song, Abhradeep Thakurta, Nicolas Papernot, and Chiyuan Zhang. \u201cMeasuring Forgetting of Memorized Training Examples\u201d. In: arXiv:2207.00099[cs] (June 2022). DOI: 10.48550/arXiv.2207.00099. arXiv: 2207.00099 [cs]. URL: http://arxiv.org/abs/2207.00099 (visited on 11/10/2022) (pages 1, 2, 9).\nAjil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G Dimakis, and Jon Tamir. \u201cRobust compressed sensing MRI with deep generative priors\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 14938\u201314954 (page 1).\nZahra Kadkhodaie and Eero P Simoncelli. \u201cSolving linear inverse problems using the prior implicit in a denoiser\u201d. In: arXiv preprint arXiv:2007.13640 (2020) (page 8).\nTero Karras, Miika Aittala, Timo Aila, and Samuli Laine. \u201cElucidating the design space of diffusion-based generative models\u201d. In: arXiv preprint arXiv:2206.00364 (2022) (pages 1, 7, 16\u201318).\nTero Karras, Miika Aittala, Samuli Laine, Erik H\u00e4rk\u00f6nen, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. \u201cAlias-free generative adversarial networks\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 852\u2013863 (page 16).\nTero Karras, Samuli Laine, and Timo Aila. \u201cA style-based generator architecture for generative adversarial networks\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 4401\u20134410 (page 16).\nTero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. \u201cAnalyzing and improving the image quality of stylegan\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020, pp. 8110\u20138119 (page 16).\nBahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. \u201cDenoising Diffusion Restoration Models\u201d. In: Advances in Neural Information Processing Systems (pages 1, 7, 8, 20).\nBahjat Kawar, Gregory Vaksman, and Michael Elad. \u201cSNIPS: Solving noisy inverse problems stochastically\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 21757\u201321769 (page 1).\nDongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, and Il-Chul Moon. \u201cSoft truncation: A universal training technique of score-based diffusion model for high precision score estimation\u201d. In: International Conference on Machine Learning. PMLR. 2022, pp. 11201\u201311228 (page 16).\nAlexander Krull, Tim-Oliver Buchholz, and Florian Jug. \u201cNoise2void-learning denoising from single noisy images\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 2129\u20132137 (page 2).\nJaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, and Timo Aila. \u201cNoise2Noise: Learning image restoration without clean data\u201d. In: arXiv preprint arXiv:1803.04189 (2018) (page 2).\nHongyu Liu, Bin Jiang, Yi Xiao, and Chao Yang. \u201cCoherent Semantic Attention for Image Inpainting\u201d. In: 2019 IEEE/CVF International Conference on Computer Vision (ICCV) (Oct. 2019). DOI: 10.1109/iccv.2019.00427. URL: http://dx.doi.org/10.1109/ICCV.2019.00427 (page 2).\nSachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. \u201cPulse: Self-supervised photo upsampling via latent space exploration of generative models\u201d. In: Proceedings of the ieee/cvf conference on computer vision and pattern recognition. 2020, pp. 2437\u20132445 (page 16).\nAlex Nichol, Aditya Ramesh, Pamela Mishkin, Prafulla Dariwal, Joanne Jang, and Mark Chen. DALL\u00b7E 2 Pre-Training Mitigations. June 2022. URL: https://openai.com/blog/dall-e-2-pre-training-mitigations/ (visited on 11/10/2022) (page 1).", "images": [], "items": [{"type": "text", "value": "Jonathan Ho, Chitwan Saharia, William Chan, David J Fleet, Mohammad Norouzi, and Tim Salimans. \u201cCascaded Diffusion Models for High Fidelity Image Generation.\u201d In: J. Mach. Learn. Res. 23.47 (2022), pp. 1\u201333 (page 17).\n\u201cHuggingface Brain Tumor MRI Dataset\u201d. In: (2020). URL: https://huggingface.co/datasets/miladfa7/Brain-MRI-Images-for-Brain-Tumor-Detection/ (pages 9, 10).\nMatthew Jagielski, Om Thakkar, Florian Tram\u00e8r, Daphne Ippolito, Katherine Lee, Nicholas Carlini, Eric Wallace, Shuang Song, Abhradeep Thakurta, Nicolas Papernot, and Chiyuan Zhang. \u201cMeasuring Forgetting of Memorized Training Examples\u201d. In: arXiv:2207.00099[cs] (June 2022). DOI: 10.48550/arXiv.2207.00099. arXiv: 2207.00099 [cs]. URL: http://arxiv.org/abs/2207.00099 (visited on 11/10/2022) (pages 1, 2, 9).\nAjil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G Dimakis, and Jon Tamir. \u201cRobust compressed sensing MRI with deep generative priors\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 14938\u201314954 (page 1).\nZahra Kadkhodaie and Eero P Simoncelli. \u201cSolving linear inverse problems using the prior implicit in a denoiser\u201d. In: arXiv preprint arXiv:2007.13640 (2020) (page 8).\nTero Karras, Miika Aittala, Timo Aila, and Samuli Laine. \u201cElucidating the design space of diffusion-based generative models\u201d. In: arXiv preprint arXiv:2206.00364 (2022) (pages 1, 7, 16\u201318).\nTero Karras, Miika Aittala, Samuli Laine, Erik H\u00e4rk\u00f6nen, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. \u201cAlias-free generative adversarial networks\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 852\u2013863 (page 16).\nTero Karras, Samuli Laine, and Timo Aila. \u201cA style-based generator architecture for generative adversarial networks\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 4401\u20134410 (page 16).\nTero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. \u201cAnalyzing and improving the image quality of stylegan\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020, pp. 8110\u20138119 (page 16).\nBahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. \u201cDenoising Diffusion Restoration Models\u201d. In: Advances in Neural Information Processing Systems (pages 1, 7, 8, 20).\nBahjat Kawar, Gregory Vaksman, and Michael Elad. \u201cSNIPS: Solving noisy inverse problems stochastically\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 21757\u201321769 (page 1).\nDongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, and Il-Chul Moon. \u201cSoft truncation: A universal training technique of score-based diffusion model for high precision score estimation\u201d. In: International Conference on Machine Learning. PMLR. 2022, pp. 11201\u201311228 (page 16).\nAlexander Krull, Tim-Oliver Buchholz, and Florian Jug. \u201cNoise2void-learning denoising from single noisy images\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 2129\u20132137 (page 2).\nJaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, and Timo Aila. \u201cNoise2Noise: Learning image restoration without clean data\u201d. In: arXiv preprint arXiv:1803.04189 (2018) (page 2).\nHongyu Liu, Bin Jiang, Yi Xiao, and Chao Yang. \u201cCoherent Semantic Attention for Image Inpainting\u201d. In: 2019 IEEE/CVF International Conference on Computer Vision (ICCV) (Oct. 2019). DOI: 10.1109/iccv.2019.00427. URL: http://dx.doi.org/10.1109/ICCV.2019.00427 (page 2).\nSachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. \u201cPulse: Self-supervised photo upsampling via latent space exploration of generative models\u201d. In: Proceedings of the ieee/cvf conference on computer vision and pattern recognition. 2020, pp. 2437\u20132445 (page 16).\nAlex Nichol, Aditya Ramesh, Pamela Mishkin, Prafulla Dariwal, Joanne Jang, and Mark Chen. DALL\u00b7E 2 Pre-Training Mitigations. June 2022. URL: https://openai.com/blog/dall-e-2-pre-training-mitigations/ (visited on 11/10/2022) (page 1).", "md": "Jonathan Ho, Chitwan Saharia, William Chan, David J Fleet, Mohammad Norouzi, and Tim Salimans. \u201cCascaded Diffusion Models for High Fidelity Image Generation.\u201d In: J. Mach. Learn. Res. 23.47 (2022), pp. 1\u201333 (page 17).\n\u201cHuggingface Brain Tumor MRI Dataset\u201d. In: (2020). URL: https://huggingface.co/datasets/miladfa7/Brain-MRI-Images-for-Brain-Tumor-Detection/ (pages 9, 10).\nMatthew Jagielski, Om Thakkar, Florian Tram\u00e8r, Daphne Ippolito, Katherine Lee, Nicholas Carlini, Eric Wallace, Shuang Song, Abhradeep Thakurta, Nicolas Papernot, and Chiyuan Zhang. \u201cMeasuring Forgetting of Memorized Training Examples\u201d. In: arXiv:2207.00099[cs] (June 2022). DOI: 10.48550/arXiv.2207.00099. arXiv: 2207.00099 [cs]. URL: http://arxiv.org/abs/2207.00099 (visited on 11/10/2022) (pages 1, 2, 9).\nAjil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G Dimakis, and Jon Tamir. \u201cRobust compressed sensing MRI with deep generative priors\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 14938\u201314954 (page 1).\nZahra Kadkhodaie and Eero P Simoncelli. \u201cSolving linear inverse problems using the prior implicit in a denoiser\u201d. In: arXiv preprint arXiv:2007.13640 (2020) (page 8).\nTero Karras, Miika Aittala, Timo Aila, and Samuli Laine. \u201cElucidating the design space of diffusion-based generative models\u201d. In: arXiv preprint arXiv:2206.00364 (2022) (pages 1, 7, 16\u201318).\nTero Karras, Miika Aittala, Samuli Laine, Erik H\u00e4rk\u00f6nen, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. \u201cAlias-free generative adversarial networks\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 852\u2013863 (page 16).\nTero Karras, Samuli Laine, and Timo Aila. \u201cA style-based generator architecture for generative adversarial networks\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 4401\u20134410 (page 16).\nTero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. \u201cAnalyzing and improving the image quality of stylegan\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020, pp. 8110\u20138119 (page 16).\nBahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. \u201cDenoising Diffusion Restoration Models\u201d. In: Advances in Neural Information Processing Systems (pages 1, 7, 8, 20).\nBahjat Kawar, Gregory Vaksman, and Michael Elad. \u201cSNIPS: Solving noisy inverse problems stochastically\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 21757\u201321769 (page 1).\nDongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, and Il-Chul Moon. \u201cSoft truncation: A universal training technique of score-based diffusion model for high precision score estimation\u201d. In: International Conference on Machine Learning. PMLR. 2022, pp. 11201\u201311228 (page 16).\nAlexander Krull, Tim-Oliver Buchholz, and Florian Jug. \u201cNoise2void-learning denoising from single noisy images\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 2129\u20132137 (page 2).\nJaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, and Timo Aila. \u201cNoise2Noise: Learning image restoration without clean data\u201d. In: arXiv preprint arXiv:1803.04189 (2018) (page 2).\nHongyu Liu, Bin Jiang, Yi Xiao, and Chao Yang. \u201cCoherent Semantic Attention for Image Inpainting\u201d. In: 2019 IEEE/CVF International Conference on Computer Vision (ICCV) (Oct. 2019). DOI: 10.1109/iccv.2019.00427. URL: http://dx.doi.org/10.1109/ICCV.2019.00427 (page 2).\nSachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. \u201cPulse: Self-supervised photo upsampling via latent space exploration of generative models\u201d. In: Proceedings of the ieee/cvf conference on computer vision and pattern recognition. 2020, pp. 2437\u20132445 (page 16).\nAlex Nichol, Aditya Ramesh, Pamela Mishkin, Prafulla Dariwal, Joanne Jang, and Mark Chen. DALL\u00b7E 2 Pre-Training Mitigations. June 2022. URL: https://openai.com/blog/dall-e-2-pre-training-mitigations/ (visited on 11/10/2022) (page 1)."}]}, {"page": 13, "text": "[42]  Maxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov,\n      Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. \u201cDINOv2:\n      Learning Robust Visual Features without Supervision\u201d. In:                arXiv preprint arXiv:2304.07193\n      (2023) (page 10).\n[43]  Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. \u201cCon-\n      text encoders: Feature learning by inpainting\u201d. In:             Proceedings of the IEEE conference on\n      computer vision and pattern recognition. 2016, pp. 2536\u20132544 (page 2).\n[44]  Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, and\n      Daniel Cohen-Or. \u201cEncoding in Style: a StyleGAN Encoder for Image-to-Image Translation\u201d.\n      In: arXiv preprint arXiv:2008.00951           (2020) (page 2).\n[45]  Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer.\n      \u201cHigh-resolution image synthesis with latent diffusion models\u201d. In:                       Proceedings of the\n      IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 10684\u201310695\n      (page 1).\n[46]  Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer.\n      \u201cHigh-resolution image synthesis with latent diffusion models\u201d. In:                       Proceedings of the\n      IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 10684\u201310695\n      (page 8).\n[47]  Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton,\n      Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.\n      \u201cPhotorealistic text-to-image diffusion models with deep language understanding\u201d. In:                         Ad-\n      vances in Neural Information Processing Systems               35 (2022), pp. 36479\u201336494 (page 1).\n[48]  Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. \u201cDeep unsu-\n      pervised learning using nonequilibrium thermodynamics\u201d. In:                    International Conference on\n      Machine Learning. PMLR. 2015, pp. 2256\u20132265 (page 1).\n[49]  Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein.\n      \u201cDiffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models\u201d. In:\n      arXiv preprint arXiv:2212.03860           (2022) (pages 1, 2, 9, 10).\n[50]  Jiaming Song, Chenlin Meng, and Stefano Ermon. \u201cDenoising diffusion implicit models\u201d. In:\n      arXiv preprint arXiv:2010.02502           (2020) (pages 7, 8, 18).\n[51]  Yang Song and Stefano Ermon. \u201cGenerative modeling by estimating gradients of the data\n      distribution\u201d. In:   Advances in Neural Information Processing Systems                 32 (2019) (page 1).\n[52]  Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and\n      Ben Poole. \u201cScore-based generative modeling through stochastic differential equations\u201d. In:\n      arXiv preprint arXiv:2011.13456           (2020) (pages 1, 3, 17).\n[53]  Juli\u00e1n Tachella, Dongdong Chen, and Mike Davies. \u201cUnsupervised Learning From Incomplete\n      Measurements for Inverse Problems\u201d. In:             arXiv preprint arXiv:2201.12151          (2022) (page 2).\n[54]  Singanallur V Venkatakrishnan, Charles A Bouman, and Brendt Wohlberg. \u201cPlug-and-play\n      priors for model based reconstruction\u201d. In:             2013 IEEE Global Conference on Signal and\n      Information Processing. IEEE. 2013, pp. 945\u2013948 (page 8).\n[55]  Pascal Vincent. \u201cA connection between score matching and denoising autoencoders\u201d. In:\n      Neural computation       23.7 (2011), pp. 1661\u20131674 (page 4).\n[56]  Ge Wang, Jong Chul Ye, and Bruno De Man. \u201cDeep learning for tomographic image recon-\n      struction\u201d. In:   Nature Machine Intelligence         2.12 (2020), pp. 737\u2013748 (page 2).\n[57]  Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas Huang. \u201cFree-Form\n      Image Inpainting With Gated Convolution\u201d. In:                2019 IEEE/CVF International Conference\n      on Computer Vision (ICCV)            (Oct. 2019).    DOI:   10.1109/iccv.2019.00457.                URL:   http:\n      //dx.doi.org/10.1109/ICCV.2019.00457                       (page 2).\n[58]  Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas S Huang. \u201cFree-form\n      image inpainting with gated convolution\u201d. In:              Proceedings of the IEEE/CVF international\n      conference on computer vision. 2019, pp. 4471\u20134480 (pages 7, 16).\n[59]  Yide Zhang, Yinhao Zhu, Evan Nichols, Qingfei Wang, Siyuan Zhang, Cody Smith, and Scott\n      Howard. \u201cA poisson-gaussian denoising dataset with real fluorescence microscopy images\u201d.\n      In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\n      2019, pp. 11710\u201311718 (page 2).\n                                                          13", "md": "- Maxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov,\nPierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. \u201cDINOv2:\nLearning Robust Visual Features without Supervision\u201d. In: *arXiv preprint arXiv:2304.07193*\n(2023) (page 10).\n- Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. \u201cContext encoders: Feature learning by inpainting\u201d. In: *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2016, pp. 2536\u20132544 (page 2).\n- Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, and\nDaniel Cohen-Or. \u201cEncoding in Style: a StyleGAN Encoder for Image-to-Image Translation\u201d.\nIn: *arXiv preprint arXiv:2008.00951* (2020) (page 2).\n- Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer.\n\u201cHigh-resolution image synthesis with latent diffusion models\u201d. In: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2022, pp. 10684\u201310695\n(page 1).\n- Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer.\n\u201cHigh-resolution image synthesis with latent diffusion models\u201d. In: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2022, pp. 10684\u201310695\n(page 8).\n- Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton,\nKamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.\n\u201cPhotorealistic text-to-image diffusion models with deep language understanding\u201d. In: *Advances in Neural Information Processing Systems*\n35 (2022), pp. 36479\u201336494 (page 1).\n- Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. \u201cDeep unsupervised learning using nonequilibrium thermodynamics\u201d. In: *International Conference on Machine Learning*. PMLR. 2015, pp. 2256\u20132265 (page 1).\n- Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein.\n\u201cDiffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models\u201d. In:\n*arXiv preprint arXiv:2212.03860* (2022) (pages 1, 2, 9, 10).\n- Jiaming Song, Chenlin Meng, and Stefano Ermon. \u201cDenoising diffusion implicit models\u201d. In:\n*arXiv preprint arXiv:2010.02502* (2020) (pages 7, 8, 18).\n- Yang Song and Stefano Ermon. \u201cGenerative modeling by estimating gradients of the data distribution\u201d. In: *Advances in Neural Information Processing Systems*\n32 (2019) (page 1).\n- Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and\nBen Poole. \u201cScore-based generative modeling through stochastic differential equations\u201d. In:\n*arXiv preprint arXiv:2011.13456* (2020) (pages 1, 3, 17).\n- Juli\u00e1n Tachella, Dongdong Chen, and Mike Davies. \u201cUnsupervised Learning From Incomplete\nMeasurements for Inverse Problems\u201d. In: *arXiv preprint arXiv:2201.12151* (2022) (page 2).\n- Singanallur V Venkatakrishnan, Charles A Bouman, and Brendt Wohlberg. \u201cPlug-and-play\npriors for model based reconstruction\u201d. In: *2013 IEEE Global Conference on Signal and Information Processing*. IEEE. 2013, pp. 945\u2013948 (page 8).\n- Pascal Vincent. \u201cA connection between score matching and denoising autoencoders\u201d. In:\n*Neural computation* 23.7 (2011), pp. 1661\u20131674 (page 4).\n- Ge Wang, Jong Chul Ye, and Bruno De Man. \u201cDeep learning for tomographic image reconstruction\u201d. In: *Nature Machine Intelligence*\n2.12 (2020), pp. 737\u2013748 (page 2).\n- Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas Huang. \u201cFree-Form\nImage Inpainting With Gated Convolution\u201d. In: *2019 IEEE/CVF International Conference on Computer Vision (ICCV)*\n(Oct. 2019). DOI: 10.1109/iccv.2019.00457. URL: http://dx.doi.org/10.1109/ICCV.2019.00457 (page 2).\n- Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas S Huang. \u201cFree-form\nimage inpainting with gated convolution\u201d. In: *Proceedings of the IEEE/CVF international conference on computer vision*. 2019, pp. 4471\u20134480 (pages 7, 16).\n- Yide Zhang, Yinhao Zhu, Evan Nichols, Qingfei Wang, Siyuan Zhang, Cody Smith, and Scott\nHoward. \u201cA poisson-gaussian denoising dataset with real fluorescence microscopy images\u201d.\nIn: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*.\n2019, pp. 11710\u201311718 (page 2).", "images": [], "items": [{"type": "text", "value": "- Maxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov,\nPierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. \u201cDINOv2:\nLearning Robust Visual Features without Supervision\u201d. In: *arXiv preprint arXiv:2304.07193*\n(2023) (page 10).\n- Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. \u201cContext encoders: Feature learning by inpainting\u201d. In: *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2016, pp. 2536\u20132544 (page 2).\n- Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, and\nDaniel Cohen-Or. \u201cEncoding in Style: a StyleGAN Encoder for Image-to-Image Translation\u201d.\nIn: *arXiv preprint arXiv:2008.00951* (2020) (page 2).\n- Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer.\n\u201cHigh-resolution image synthesis with latent diffusion models\u201d. In: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2022, pp. 10684\u201310695\n(page 1).\n- Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer.\n\u201cHigh-resolution image synthesis with latent diffusion models\u201d. In: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2022, pp. 10684\u201310695\n(page 8).\n- Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton,\nKamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.\n\u201cPhotorealistic text-to-image diffusion models with deep language understanding\u201d. In: *Advances in Neural Information Processing Systems*\n35 (2022), pp. 36479\u201336494 (page 1).\n- Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. \u201cDeep unsupervised learning using nonequilibrium thermodynamics\u201d. In: *International Conference on Machine Learning*. PMLR. 2015, pp. 2256\u20132265 (page 1).\n- Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein.\n\u201cDiffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models\u201d. In:\n*arXiv preprint arXiv:2212.03860* (2022) (pages 1, 2, 9, 10).\n- Jiaming Song, Chenlin Meng, and Stefano Ermon. \u201cDenoising diffusion implicit models\u201d. In:\n*arXiv preprint arXiv:2010.02502* (2020) (pages 7, 8, 18).\n- Yang Song and Stefano Ermon. \u201cGenerative modeling by estimating gradients of the data distribution\u201d. In: *Advances in Neural Information Processing Systems*\n32 (2019) (page 1).\n- Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and\nBen Poole. \u201cScore-based generative modeling through stochastic differential equations\u201d. In:\n*arXiv preprint arXiv:2011.13456* (2020) (pages 1, 3, 17).\n- Juli\u00e1n Tachella, Dongdong Chen, and Mike Davies. \u201cUnsupervised Learning From Incomplete\nMeasurements for Inverse Problems\u201d. In: *arXiv preprint arXiv:2201.12151* (2022) (page 2).\n- Singanallur V Venkatakrishnan, Charles A Bouman, and Brendt Wohlberg. \u201cPlug-and-play\npriors for model based reconstruction\u201d. In: *2013 IEEE Global Conference on Signal and Information Processing*. IEEE. 2013, pp. 945\u2013948 (page 8).\n- Pascal Vincent. \u201cA connection between score matching and denoising autoencoders\u201d. In:\n*Neural computation* 23.7 (2011), pp. 1661\u20131674 (page 4).\n- Ge Wang, Jong Chul Ye, and Bruno De Man. \u201cDeep learning for tomographic image reconstruction\u201d. In: *Nature Machine Intelligence*\n2.12 (2020), pp. 737\u2013748 (page 2).\n- Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas Huang. \u201cFree-Form\nImage Inpainting With Gated Convolution\u201d. In: *2019 IEEE/CVF International Conference on Computer Vision (ICCV)*\n(Oct. 2019). DOI: 10.1109/iccv.2019.00457. URL: http://dx.doi.org/10.1109/ICCV.2019.00457 (page 2).\n- Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas S Huang. \u201cFree-form\nimage inpainting with gated convolution\u201d. In: *Proceedings of the IEEE/CVF international conference on computer vision*. 2019, pp. 4471\u20134480 (pages 7, 16).\n- Yide Zhang, Yinhao Zhu, Evan Nichols, Qingfei Wang, Siyuan Zhang, Cody Smith, and Scott\nHoward. \u201cA poisson-gaussian denoising dataset with real fluorescence microscopy images\u201d.\nIn: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*.\n2019, pp. 11710\u201311718 (page 2).", "md": "- Maxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov,\nPierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. \u201cDINOv2:\nLearning Robust Visual Features without Supervision\u201d. In: *arXiv preprint arXiv:2304.07193*\n(2023) (page 10).\n- Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. \u201cContext encoders: Feature learning by inpainting\u201d. In: *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2016, pp. 2536\u20132544 (page 2).\n- Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, and\nDaniel Cohen-Or. \u201cEncoding in Style: a StyleGAN Encoder for Image-to-Image Translation\u201d.\nIn: *arXiv preprint arXiv:2008.00951* (2020) (page 2).\n- Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer.\n\u201cHigh-resolution image synthesis with latent diffusion models\u201d. In: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2022, pp. 10684\u201310695\n(page 1).\n- Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer.\n\u201cHigh-resolution image synthesis with latent diffusion models\u201d. In: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2022, pp. 10684\u201310695\n(page 8).\n- Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton,\nKamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.\n\u201cPhotorealistic text-to-image diffusion models with deep language understanding\u201d. In: *Advances in Neural Information Processing Systems*\n35 (2022), pp. 36479\u201336494 (page 1).\n- Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. \u201cDeep unsupervised learning using nonequilibrium thermodynamics\u201d. In: *International Conference on Machine Learning*. PMLR. 2015, pp. 2256\u20132265 (page 1).\n- Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein.\n\u201cDiffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models\u201d. In:\n*arXiv preprint arXiv:2212.03860* (2022) (pages 1, 2, 9, 10).\n- Jiaming Song, Chenlin Meng, and Stefano Ermon. \u201cDenoising diffusion implicit models\u201d. In:\n*arXiv preprint arXiv:2010.02502* (2020) (pages 7, 8, 18).\n- Yang Song and Stefano Ermon. \u201cGenerative modeling by estimating gradients of the data distribution\u201d. In: *Advances in Neural Information Processing Systems*\n32 (2019) (page 1).\n- Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and\nBen Poole. \u201cScore-based generative modeling through stochastic differential equations\u201d. In:\n*arXiv preprint arXiv:2011.13456* (2020) (pages 1, 3, 17).\n- Juli\u00e1n Tachella, Dongdong Chen, and Mike Davies. \u201cUnsupervised Learning From Incomplete\nMeasurements for Inverse Problems\u201d. In: *arXiv preprint arXiv:2201.12151* (2022) (page 2).\n- Singanallur V Venkatakrishnan, Charles A Bouman, and Brendt Wohlberg. \u201cPlug-and-play\npriors for model based reconstruction\u201d. In: *2013 IEEE Global Conference on Signal and Information Processing*. IEEE. 2013, pp. 945\u2013948 (page 8).\n- Pascal Vincent. \u201cA connection between score matching and denoising autoencoders\u201d. In:\n*Neural computation* 23.7 (2011), pp. 1661\u20131674 (page 4).\n- Ge Wang, Jong Chul Ye, and Bruno De Man. \u201cDeep learning for tomographic image reconstruction\u201d. In: *Nature Machine Intelligence*\n2.12 (2020), pp. 737\u2013748 (page 2).\n- Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas Huang. \u201cFree-Form\nImage Inpainting With Gated Convolution\u201d. In: *2019 IEEE/CVF International Conference on Computer Vision (ICCV)*\n(Oct. 2019). DOI: 10.1109/iccv.2019.00457. URL: http://dx.doi.org/10.1109/ICCV.2019.00457 (page 2).\n- Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas S Huang. \u201cFree-form\nimage inpainting with gated convolution\u201d. In: *Proceedings of the IEEE/CVF international conference on computer vision*. 2019, pp. 4471\u20134480 (pages 7, 16).\n- Yide Zhang, Yinhao Zhu, Evan Nichols, Qingfei Wang, Siyuan Zhang, Cody Smith, and Scott\nHoward. \u201cA poisson-gaussian denoising dataset with real fluorescence microscopy images\u201d.\nIn: *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*.\n2019, pp. 11710\u201311718 (page 2)."}]}, {"page": 14, "text": " A     Proofs\n Proof of Theorem 4.1.        Let  h \u03b8\u2217 be a minimizer of equation 3.2, and for brevity let\n                                      \u02dc      \u02dc             \u02dc      \u02dc                \u02dc      \u02dc\n                                  f( Ax   t, A) =   h \u03b8 \u2217( Ax  t,A)   \u2212  E[x  0 | Ax  t, A]\n be the difference between        h \u03b8\u2217  and the claimed optimal solution. We will now argue that                 f  must be\n identically zero.                                     \u02dc      \u02dc\n First, by adding and subtracting         AE[x    0 | Ax   t,A], we can expand the objective value achieved at\n \u03b8 =  \u03b8 \u2217 in equation 3.2 as follows:\n         corr   \u2217                    \u0014                          \u02dc      \u02dc             \u02dc      \u02dc    2 \u0015\n       J     (\u03b8  ) =   E x 0,xt,A,A\u02dc     (Ax  0 \u2212   AE[x   0 | Ax  t ,A])  \u2212  Af( Ax     t,A))\n                                     \u0014                         \u02dc      \u02dc   2\u0015                   \u0014         \u02dc      \u02dc   2 \u0015\n                    =  E x 0,xt,A,A\u02dc     Ax  0 \u2212  AE[x    0 | Ax  t,A]       +   E x0 ,xt,A,A\u02dc    Af( Ax    t ,A)\n                                          h                       \u02dc      \u02dc   T       \u02dc      \u02dc  i\n                      \u2212   2E x 0,xt ,A,A\u02dc  (Ax   0 \u2212  AE[x   0  |Ax   t,A])    Af( Ax    t,A)    .\n Here the first term is the irreducible error, while the third term vanishes by the tower law of expecta-\n tions:                          h                        \u02dc      \u02dc  T        \u02dc      \u02dc i\n                   E x0,x t,A,A\u02dc  (Ax  h0 \u2212  AE[x    0 | Ax  t,A])    Af( Ax    t, A)       i\n                                                           \u02dc      \u02dc   T   T        \u02dc      \u02dc\n                   =   E        \u02dc \u02dc     (x  0 \u2212  E[x  0 | Ax   t,A])   A    Af( Ax    t,A)\n                         x 0,A,A,Ax\u0014 t               h                  \u02dc      \u02dc iT     T       \u02dc      \u02dc  \u0015\n                   =   E    \u02dc  \u02dc     E        \u02dc  \u02dc     x 0 \u2212  E[x  0  |Ax   t,A]     A    Af( Ax    t,A)\n                         A,A,Ax   th   x 0|A,A,Ax   t                                                   i\n                                                \u02dc      \u02dc               \u02dc      \u02dc   T   T        \u02dc      \u02dc\n                   =   E    \u02dc  \u02dc     (E[x  0  |Ax   t,A]  \u2212  E[x  0  |Ax   t,A])    A   Af( Ax    t,A)\n                   = 0.  A,A,Axt\nThus the only part of       J corr(\u03b8 \u2217 ) that actually depends on the parameter value             \u03b8 \u2217 is the second term.\nWe now show that the second term can be made to vanish and that this occurs precisely when                              f   is\n identically 0:                          \u0014         \u02dc      \u02dc   2 \u0015\n                           E x0 ,xt,A,A\u02dc    Af( Ax     t,A)\n                                             h     \u02dc      \u02dc  T   T       \u02dc      \u02dc  i\n                            =  E x0 ,xt,A,A\u02dc   f( Ax  t ,A)    A   Af( Ax    t, A)\n                                           h    \u02dc      \u02dc  T               \u0002   T   ]     \u02dc      \u02dc  i\n                            =  E         \u02dc  f( Ax   t,A)    E           \u02dc   A   A   f( Ax   t, A)\n                                 x0 ,xt,A                     A|x 0 ,xt,A\n                                           h    \u02dc      \u02dc  T        \u0002   T   ]     \u02dc      \u02dc  i\n                            =  E x0 ,xt,A\u02dc  f( Ax   t,A)    E A|A\u02dc   A   A   f( Ax   t,A)    .\n For every    A\u02dc and   x 0 ,x t, by assumption we have that            E A|A\u02dc \u0002A  TA  ] is full-rank, and so the inner\n                                                  \u02dc      \u02dc\n quadratic form is minimized when             f( Ax  t ,A) = 0. Further, the term as a whole vanishes exactly\nwhen this holds for every        A\u02dc and  x 0 ,x t in the support, which means         f  must be identically zero.\n Corollary A.1(Inpainting noise model).              Consider the following inpainting noise model:             A  \u2208  R n\u00d7n\n is a diagonal matrix where each entry           A  ii\u223c   Ber(1   \u2212  p)  for some   p >   0  (independently for each       i),\n and the additional noise is generated by drawingA|Asuch that \u02dc                 A\u02dcii =  A ii Ber(1   \u2212\u03b4)    for some small\n \u03b4 >  0  (again independently for each         i). Then the unique minimizer of the objective in equation 3.2 is\n                                              \u2217   \u02dc      \u02dc               \u02dc      \u02dc\n                                           h \u03b8 ( Ax  t, A) =    E[x  0 |Ax   t,A].\nProof.    By Theorem 4.1, what we must show is that for any               A\u02dc in the support,    E A|A\u02dc [A T A]  is full-rank.\n                                         \u02dc\n Fix any particular realization of      A, which will be a diagonal matrix with only             0s and   1s. For indices    i\n          \u02dc                                                                    \u02dc\nwhere    A ii = 1, we know that for any         A  drawn conditional on        A,  A ii = 1  as well, i.e.\n                                              Pr(A   ii= 1   | A\u02dcii = 1) = 1.\n                                                              14", "md": "# Proofs\n\n## Proof of Theorem 4.1\n\nLet \\( h_{\\theta^*} \\) be a minimizer of equation 3.2, and for brevity let\n\n$$\nf(Ax_t, A) = h_{\\theta^*}(Ax_t, A) - E[x_0 | Ax_t, A]\n$$\nbe the difference between \\( h_{\\theta^*} \\) and the claimed optimal solution. We will now argue that \\( f \\) must be identically zero.\n\nFirst, by adding and subtracting \\( AE[x_0 | Ax_t, A] \\), we can expand the objective value achieved at \\( \\theta = \\theta^* \\) in equation 3.2 as follows:\n\n$$\n\\begin{align*}\nJ_{\\text{corr}}^*(\\theta) & = Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A]) - Af(Ax_t, A) \\\\\n& = Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A]) + Ex_0,xt,A,A^*Af(Ax_t, A) \\\\\n& - 2Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A])Af(Ax_t, A).\n\\end{align*}\n$$\nHere the first term is the irreducible error, while the third term vanishes by the tower law of expectations:\n\n$$\n\\begin{align*}\n& E[x_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A])Af(Ax_t, A)] \\\\\n& = E[\\tilde{x}_0 - E[x_0 | Ax_t, A] \\, | \\, Ax_t] A \\, Af(Ax_t, A) \\\\\n& = E[E[x_0 | Ax_t, A] - E[x_0 | Ax_t, A] \\, | \\, Ax_t] A \\, Af(Ax_t, A) \\\\\n& = 0.\n\\end{align*}\n$$\nThus the only part of \\( J_{\\text{corr}}(\\theta^*) \\) that actually depends on the parameter value \\( \\theta^* \\) is the second term.\n\nWe now show that the second term can be made to vanish and that this occurs precisely when \\( f \\) is identically 0:\n\n$$\n\\begin{align*}\n& Ex_0,xt,A,A^*Af(Ax_t, A) \\\\\n& = Ex_0,xt,A,A^*f(Ax_t, A) A \\, Af(Ax_t, A) \\\\\n& = E[f(Ax_t, A) \\, | \\, Ax_t] E[A \\, | \\, x_0,xt,A] A \\, Af(Ax_t, A) \\\\\n& = Ex_0,xt,A^*f(Ax_t, A) E[A \\, | \\, A^*] A \\, Af(Ax_t, A).\n\\end{align*}\n$$\nFor every \\( A^* \\) and \\( x_0,xt \\), by assumption we have that \\( E[A \\, | \\, A^*] \\) is full-rank, and so the inner quadratic form is minimized when \\( f(Ax_t, A) = 0 \\). Further, the term as a whole vanishes exactly when this holds for every \\( A^* \\) and \\( x_0,xt \\) in the support, which means \\( f \\) must be identically zero.\n\n### Corollary A.1 (Inpainting noise model)\n\nConsider the following inpainting noise model: \\( A \\in \\mathbb{R}^{n \\times n} \\) is a diagonal matrix where each entry \\( A_{ii} \\sim \\text{Ber}(1 - p) \\) for some \\( p > 0 \\) (independently for each \\( i \\)), and the additional noise is generated by drawing \\( A|A \\) such that \\( \\tilde{A}_{ii} = A_{ii} \\, \\text{Ber}(1 - \\delta) \\) for some small \\( \\delta > 0 \\) (again independently for each \\( i \\)). Then the unique minimizer of the objective in equation 3.2 is\n\n$$\nh_{\\theta}(Ax_t, A) = E[x_0 | Ax_t, A].\n$$\n### Proof:\n\nBy Theorem 4.1, what we must show is that for any \\( A^* \\) in the support, \\( E[A \\, | \\, A^*][A^T A] \\) is full-rank.\n\nFix any particular realization of \\( A \\), which will be a diagonal matrix with only \\( 0 \\)s and \\( 1 \\)s. For indices \\( i \\) where \\( A_{ii} = 1 \\), we know that for any \\( A \\) drawn conditional on \\( A^* \\), \\( A_{ii} = 1 \\) as well, i.e.\n\n$$\n\\text{Pr}(A_{ii} = 1 \\, | \\, \\tilde{A}_{ii} = 1) = 1.\n$$", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Proofs", "md": "# Proofs"}, {"type": "heading", "lvl": 2, "value": "Proof of Theorem 4.1", "md": "## Proof of Theorem 4.1"}, {"type": "text", "value": "Let \\( h_{\\theta^*} \\) be a minimizer of equation 3.2, and for brevity let\n\n$$\nf(Ax_t, A) = h_{\\theta^*}(Ax_t, A) - E[x_0 | Ax_t, A]\n$$\nbe the difference between \\( h_{\\theta^*} \\) and the claimed optimal solution. We will now argue that \\( f \\) must be identically zero.\n\nFirst, by adding and subtracting \\( AE[x_0 | Ax_t, A] \\), we can expand the objective value achieved at \\( \\theta = \\theta^* \\) in equation 3.2 as follows:\n\n$$\n\\begin{align*}\nJ_{\\text{corr}}^*(\\theta) & = Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A]) - Af(Ax_t, A) \\\\\n& = Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A]) + Ex_0,xt,A,A^*Af(Ax_t, A) \\\\\n& - 2Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A])Af(Ax_t, A).\n\\end{align*}\n$$\nHere the first term is the irreducible error, while the third term vanishes by the tower law of expectations:\n\n$$\n\\begin{align*}\n& E[x_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A])Af(Ax_t, A)] \\\\\n& = E[\\tilde{x}_0 - E[x_0 | Ax_t, A] \\, | \\, Ax_t] A \\, Af(Ax_t, A) \\\\\n& = E[E[x_0 | Ax_t, A] - E[x_0 | Ax_t, A] \\, | \\, Ax_t] A \\, Af(Ax_t, A) \\\\\n& = 0.\n\\end{align*}\n$$\nThus the only part of \\( J_{\\text{corr}}(\\theta^*) \\) that actually depends on the parameter value \\( \\theta^* \\) is the second term.\n\nWe now show that the second term can be made to vanish and that this occurs precisely when \\( f \\) is identically 0:\n\n$$\n\\begin{align*}\n& Ex_0,xt,A,A^*Af(Ax_t, A) \\\\\n& = Ex_0,xt,A,A^*f(Ax_t, A) A \\, Af(Ax_t, A) \\\\\n& = E[f(Ax_t, A) \\, | \\, Ax_t] E[A \\, | \\, x_0,xt,A] A \\, Af(Ax_t, A) \\\\\n& = Ex_0,xt,A^*f(Ax_t, A) E[A \\, | \\, A^*] A \\, Af(Ax_t, A).\n\\end{align*}\n$$\nFor every \\( A^* \\) and \\( x_0,xt \\), by assumption we have that \\( E[A \\, | \\, A^*] \\) is full-rank, and so the inner quadratic form is minimized when \\( f(Ax_t, A) = 0 \\). Further, the term as a whole vanishes exactly when this holds for every \\( A^* \\) and \\( x_0,xt \\) in the support, which means \\( f \\) must be identically zero.", "md": "Let \\( h_{\\theta^*} \\) be a minimizer of equation 3.2, and for brevity let\n\n$$\nf(Ax_t, A) = h_{\\theta^*}(Ax_t, A) - E[x_0 | Ax_t, A]\n$$\nbe the difference between \\( h_{\\theta^*} \\) and the claimed optimal solution. We will now argue that \\( f \\) must be identically zero.\n\nFirst, by adding and subtracting \\( AE[x_0 | Ax_t, A] \\), we can expand the objective value achieved at \\( \\theta = \\theta^* \\) in equation 3.2 as follows:\n\n$$\n\\begin{align*}\nJ_{\\text{corr}}^*(\\theta) & = Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A]) - Af(Ax_t, A) \\\\\n& = Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A]) + Ex_0,xt,A,A^*Af(Ax_t, A) \\\\\n& - 2Ex_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A])Af(Ax_t, A).\n\\end{align*}\n$$\nHere the first term is the irreducible error, while the third term vanishes by the tower law of expectations:\n\n$$\n\\begin{align*}\n& E[x_0,xt,A,A^*(Ax_0 - AE[x_0 | Ax_t, A])Af(Ax_t, A)] \\\\\n& = E[\\tilde{x}_0 - E[x_0 | Ax_t, A] \\, | \\, Ax_t] A \\, Af(Ax_t, A) \\\\\n& = E[E[x_0 | Ax_t, A] - E[x_0 | Ax_t, A] \\, | \\, Ax_t] A \\, Af(Ax_t, A) \\\\\n& = 0.\n\\end{align*}\n$$\nThus the only part of \\( J_{\\text{corr}}(\\theta^*) \\) that actually depends on the parameter value \\( \\theta^* \\) is the second term.\n\nWe now show that the second term can be made to vanish and that this occurs precisely when \\( f \\) is identically 0:\n\n$$\n\\begin{align*}\n& Ex_0,xt,A,A^*Af(Ax_t, A) \\\\\n& = Ex_0,xt,A,A^*f(Ax_t, A) A \\, Af(Ax_t, A) \\\\\n& = E[f(Ax_t, A) \\, | \\, Ax_t] E[A \\, | \\, x_0,xt,A] A \\, Af(Ax_t, A) \\\\\n& = Ex_0,xt,A^*f(Ax_t, A) E[A \\, | \\, A^*] A \\, Af(Ax_t, A).\n\\end{align*}\n$$\nFor every \\( A^* \\) and \\( x_0,xt \\), by assumption we have that \\( E[A \\, | \\, A^*] \\) is full-rank, and so the inner quadratic form is minimized when \\( f(Ax_t, A) = 0 \\). Further, the term as a whole vanishes exactly when this holds for every \\( A^* \\) and \\( x_0,xt \\) in the support, which means \\( f \\) must be identically zero."}, {"type": "heading", "lvl": 3, "value": "Corollary A.1 (Inpainting noise model)", "md": "### Corollary A.1 (Inpainting noise model)"}, {"type": "text", "value": "Consider the following inpainting noise model: \\( A \\in \\mathbb{R}^{n \\times n} \\) is a diagonal matrix where each entry \\( A_{ii} \\sim \\text{Ber}(1 - p) \\) for some \\( p > 0 \\) (independently for each \\( i \\)), and the additional noise is generated by drawing \\( A|A \\) such that \\( \\tilde{A}_{ii} = A_{ii} \\, \\text{Ber}(1 - \\delta) \\) for some small \\( \\delta > 0 \\) (again independently for each \\( i \\)). Then the unique minimizer of the objective in equation 3.2 is\n\n$$\nh_{\\theta}(Ax_t, A) = E[x_0 | Ax_t, A].\n$$", "md": "Consider the following inpainting noise model: \\( A \\in \\mathbb{R}^{n \\times n} \\) is a diagonal matrix where each entry \\( A_{ii} \\sim \\text{Ber}(1 - p) \\) for some \\( p > 0 \\) (independently for each \\( i \\)), and the additional noise is generated by drawing \\( A|A \\) such that \\( \\tilde{A}_{ii} = A_{ii} \\, \\text{Ber}(1 - \\delta) \\) for some small \\( \\delta > 0 \\) (again independently for each \\( i \\)). Then the unique minimizer of the objective in equation 3.2 is\n\n$$\nh_{\\theta}(Ax_t, A) = E[x_0 | Ax_t, A].\n$$"}, {"type": "heading", "lvl": 3, "value": "Proof:", "md": "### Proof:"}, {"type": "text", "value": "By Theorem 4.1, what we must show is that for any \\( A^* \\) in the support, \\( E[A \\, | \\, A^*][A^T A] \\) is full-rank.\n\nFix any particular realization of \\( A \\), which will be a diagonal matrix with only \\( 0 \\)s and \\( 1 \\)s. For indices \\( i \\) where \\( A_{ii} = 1 \\), we know that for any \\( A \\) drawn conditional on \\( A^* \\), \\( A_{ii} = 1 \\) as well, i.e.\n\n$$\n\\text{Pr}(A_{ii} = 1 \\, | \\, \\tilde{A}_{ii} = 1) = 1.\n$$", "md": "By Theorem 4.1, what we must show is that for any \\( A^* \\) in the support, \\( E[A \\, | \\, A^*][A^T A] \\) is full-rank.\n\nFix any particular realization of \\( A \\), which will be a diagonal matrix with only \\( 0 \\)s and \\( 1 \\)s. For indices \\( i \\) where \\( A_{ii} = 1 \\), we know that for any \\( A \\) drawn conditional on \\( A^* \\), \\( A_{ii} = 1 \\) as well, i.e.\n\n$$\n\\text{Pr}(A_{ii} = 1 \\, | \\, \\tilde{A}_{ii} = 1) = 1.\n$$"}]}, {"page": 15, "text": "And for indices     i where    A\u02dcii = 0, by Bayes\u2019 rule we have\n  Pr(A      = 1   |A\u02dc    = 0) =                    Pr(A   ii = 1,A  \u02dc ii = 0)                   =     (1  \u2212  p)\u03b4     =:   q.\n         ii           ii           Pr(A   ii = 0,A   \u02dcii = 0) + Pr(A      ii = 1,  A\u02dcii = 0)        (1 \u2212  p)\u03b4  +   p\nThus we see that      E A|A\u02dc [A T A] =   E  A|A\u02dc[A]  is a diagonal matrix whose entries are           1 wherever    A\u02dc ii = 1\nand  q  wherever    A\u02dcii = 0. This is clearly of full rank since         q >   0.\nCorollary A.2      (Gaussian measurements noise model).                 Consider the following noise model where\nwe only observe       m  independent Gaussian measurements of the ground truth, and then one of the\nmeasurements is further omitted:          A  \u2208  R m\u00d7n    consists of   m  rows drawn independently from           N  (0, I n ),\nandA  \u02dc \u2208  R  m\u00d7n   is constructed conditional on        Aby zeroing out its last row. Then the unique minimizer\nof the objective in equation 3.2 is              \u02dc      \u02dc                \u02dc      \u02dc\n                                          h \u03b8 \u2217( Ax  t,A) =    E[x   0 |Ax   t,A].\nProof.   Again by Theorem 4.1, we must show that for any                 A\u02dc  in the support,    E A|A\u02dc [A T A]  is full-rank.\n                             \u02dc\nFix any realization of      A, which will have the following form:\n                                   \uf8ee             a1T             \uf8f9\n                                   \uf8ef               .             \uf8fa\n                                   \uf8ef               .             \uf8fa\n                            A\u02dc  =  \uf8ef             T .             \uf8fa  .\n                                   \uf8f0           am\u22121              \uf8fb\n                                             \u02dc   0 T\nThen it is clear that conditional on        A,  A  has the following distribution:\n                                   \uf8ee             a1T             \uf8f9\n                                   \uf8ef               .             \uf8fa\n                                   \uf8ef               .             \uf8fa\n                       A  | A\u02dc  =  \uf8ef             T .             \uf8fa     where      b m  \u223c N(0, I    n ).\n                                   \uf8f0           am\u22121              \uf8fb\nHere   bm   is drawn entirely independently from bmT       N   (0, In ). Elementary manipulations now reveal that\n          T                           \u02dc T \u02dc           T       \u02dc T \u02dc\nE A|A\u02dc [A   A] =   E  bm \u223cN(0,I  n )[ A  A   +  bm  b m ] = A     A  +  In , which is clearly full rank (indeed, it is\nPSD with strictly positive eigenvalues).\nA.1     Reduction\nIn this section we argue that if there is an algorithm that recovers the target distribution                  p 0(x 0 ) from\ni.i.d. samples    (Ax  0 , A) where    A  \u223c   p(A)   and  x 0  \u223c  p0 (x 0 ), then, there is an algorithm that recovers\np 0(x 0 ) without sample access, but instead, using access to an oracle that given                      t, x  and  A   in the\nsupport of    p(A), returns    E[x  0  |Ax   t].\nIndeed, for any     A, Chen et al. [10] show that it is possible to recover the distribution of                 Ax   0 given\naccess to   E[Ax    0 | Ax  t ]for any   t and   x  under some minimal assumptions on the data distribution\np 0(x 0 ), see [10, Assumptions 1-3]. Using our oracle and using this theorem, we can recover the\ndistribution ofAx      0 for all  A  in the support. By sampling from these distributions, one can as well\nobtain samples of       Ax  0  for A   \u223c  p(A)   and   x 0  \u223c  p 0(x  0). Hence, if these samples are sufficient to\nrecover   p 0(x 0 ), then, having an oracle to these conditional expectations is sufficient as well.\nThis intuition can be formalized as follows.                Fix a distribution      pA (A)   over corruption matrices.\nFor a distribution      p0 (x 0), denote by     corrupt(p     A, p 0) the distribution over pairs        (A, Ax    0) where\nA   \u223c   p A(A)    and  x 0  \u223c    p0(x  0).  We say that      it is possible to reconstruct         p0 (x 0 ) from random\ncorruptions     A  \u223c   p  (A)   if the following holds: for any two distributions,              p  (x   ) and  p \u2032 (x \u2032) that\n                        A                                                                         0   0          0    0\nsatisfy Assumptions 1-3 of Chen et al. [10], if              corrupt(p    A , p0) = corrupt(p      A , p\u2032 ), then  p 0 =   p\u2032 .\n                                                                                                        0                   0\nSimilarly, we say that         it is possible to reconstruct         p0(x  0) from conditional expectations given\nA  \u223c  p(A)    if the following holds: for any distribution           p  (x   ) and   p\u2032(x  \u2032) that satisfy Assumptions\n                                                                       0    0         0    0\n1-3 of Chen et al. [10], if for all     x,  t and  A   in the support of    p A ,\n                E (x  ,x )\u223cp     (x  ,x )[x 0  |Ax   t =  x] =   E (x \u2032,x \u2032)\u223cp \u2032  (x \u2032,x\u2032)[x \u2032  |Ax   \u2032 =  x]           (A.1)\n                     0   t    0,t  0   t                              0   t    0,t   0  t    0        t\n                                                              15", "md": "# Math Equations and Text\n\nAnd for indices i where $$A_{\\tilde{ii}} = 0$$, by Bayes\u2019 rule we have\n\n$$Pr(A = 1 | A_{\\tilde{i}} = 0) = \\frac{Pr(A_{ii} = 1, A_{\\tilde{ii}} = 0)}{Pr(A_{ii} = 0, A_{\\tilde{ii}} = 0) + Pr(A_{ii} = 1, A_{\\tilde{ii}} = 0)} = (1 - p)\\delta =: q.$$\n\nThus we see that $$E[A|A_{\\tilde{}}][A^TA] = E[A|A_{\\tilde{}}][A]$$ is a diagonal matrix whose entries are 1 wherever $$A_{\\tilde{ii}} = 1$$ and q wherever $$A_{\\tilde{ii}} = 0$$. This is clearly of full rank since q > 0.\n\n## Corollary A.2 (Gaussian measurements noise model)\n\nConsider the following noise model where we only observe m independent Gaussian measurements of the ground truth, and then one of the measurements is further omitted: $$A \\in \\mathbb{R}^{m \\times n}$$ consists of m rows drawn independently from $$N(0, I_n)$$, and $$A_{\\tilde{ } } \\in \\mathbb{R}^{m \\times n}$$ is constructed conditional on A by zeroing out its last row. Then the unique minimizer of the objective in equation 3.2 is $$h_{\\theta^*}(Ax_t, A) = E[x_0 | Ax_t, A].$$\n\n## Proof\n\nAgain by Theorem 4.1, we must show that for any $$A_{\\tilde{}}$$ in the support, $$E[A|A_{\\tilde{}}][A^TA]$$ is full-rank.\n\nFix any realization of A, which will have the following form:\n\n[a1^T]\n...\n[am-1]\n\nThen it is clear that conditional on A, A has the following distribution:\n\n[a1^T]\n...\n[am-1]\n\nHere bm is drawn entirely independently from $$N(0, I_n)$$. Elementary manipulations now reveal that $$E[A|A_{\\tilde{}}][A^TA] = E[bm \\sim N(0, I_n)[A^TA + b_mb_m] = A^TA + I_n$$, which is clearly full rank (indeed, it is PSD with strictly positive eigenvalues).\n\n## A.1 Reduction\n\nIn this section we argue that if there is an algorithm that recovers the target distribution $$p_0(x_0)$$ from i.i.d. samples $$(Ax_0, A)$$ where $$A \\sim p(A)$$ and $$x_0 \\sim p_0(x_0)$$, then, there is an algorithm that recovers $$p_0(x_0)$$ without sample access, but instead, using access to an oracle that given t, x and A in the support of $$p(A)$$, returns $$E[x_0 | Ax_t]$$. Indeed, for any A, Chen et al. [10] show that it is possible to recover the distribution of $$Ax_0$$ given access to $$E[Ax_0 | Ax_t]$$ for any t and x under some minimal assumptions on the data distribution $$p_0(x_0)$$, see [10, Assumptions 1-3]. Using our oracle and using this theorem, we can recover the distribution of $$Ax_0$$ for all A in the support. By sampling from these distributions, one can as well obtain samples of $$Ax_0$$ for $$A \\sim p(A)$$ and $$x_0 \\sim p_0(x_0)$$. Hence, if these samples are sufficient to recover $$p_0(x_0)$$, then, having an oracle to these conditional expectations is sufficient as well.\n\nThis intuition can be formalized as follows. Fix a distribution $$p_A(A)$$ over corruption matrices. For a distribution $$p_0(x_0)$$, denote by corrupt($$p_A, p_0$$) the distribution over pairs $$(A, Ax_0)$$ where $$A \\sim p_A(A)$$ and $$x_0 \\sim p_0(x_0)$$. We say that it is possible to reconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p(A)$$ if the following holds: for any two distributions, $$p(x), p'(x)$$ that satisfy Assumptions 1-3 of Chen et al. [10], if corrupt($$p_A, p_0$$) = corrupt($$p_A, p'$$), then $$p_0 = p'$$.\n\nSimilarly, we say that it is possible to reconstruct $$p_0(x_0)$$ from conditional expectations given $$A \\sim p(A)$$ if the following holds: for any distribution $$p(x), p'(x)$$ that satisfy Assumptions 1-3 of Chen et al. [10], if for all x, t and A in the support of $$p_A$$, $$E(x, x') \\sim p(x, x')[x_0 | Ax_t = x] = E(x', x') \\sim p'(x', x')[x' | Ax' = x]$$. (A.1)", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Text", "md": "# Math Equations and Text"}, {"type": "text", "value": "And for indices i where $$A_{\\tilde{ii}} = 0$$, by Bayes\u2019 rule we have\n\n$$Pr(A = 1 | A_{\\tilde{i}} = 0) = \\frac{Pr(A_{ii} = 1, A_{\\tilde{ii}} = 0)}{Pr(A_{ii} = 0, A_{\\tilde{ii}} = 0) + Pr(A_{ii} = 1, A_{\\tilde{ii}} = 0)} = (1 - p)\\delta =: q.$$\n\nThus we see that $$E[A|A_{\\tilde{}}][A^TA] = E[A|A_{\\tilde{}}][A]$$ is a diagonal matrix whose entries are 1 wherever $$A_{\\tilde{ii}} = 1$$ and q wherever $$A_{\\tilde{ii}} = 0$$. This is clearly of full rank since q > 0.", "md": "And for indices i where $$A_{\\tilde{ii}} = 0$$, by Bayes\u2019 rule we have\n\n$$Pr(A = 1 | A_{\\tilde{i}} = 0) = \\frac{Pr(A_{ii} = 1, A_{\\tilde{ii}} = 0)}{Pr(A_{ii} = 0, A_{\\tilde{ii}} = 0) + Pr(A_{ii} = 1, A_{\\tilde{ii}} = 0)} = (1 - p)\\delta =: q.$$\n\nThus we see that $$E[A|A_{\\tilde{}}][A^TA] = E[A|A_{\\tilde{}}][A]$$ is a diagonal matrix whose entries are 1 wherever $$A_{\\tilde{ii}} = 1$$ and q wherever $$A_{\\tilde{ii}} = 0$$. This is clearly of full rank since q > 0."}, {"type": "heading", "lvl": 2, "value": "Corollary A.2 (Gaussian measurements noise model)", "md": "## Corollary A.2 (Gaussian measurements noise model)"}, {"type": "text", "value": "Consider the following noise model where we only observe m independent Gaussian measurements of the ground truth, and then one of the measurements is further omitted: $$A \\in \\mathbb{R}^{m \\times n}$$ consists of m rows drawn independently from $$N(0, I_n)$$, and $$A_{\\tilde{ } } \\in \\mathbb{R}^{m \\times n}$$ is constructed conditional on A by zeroing out its last row. Then the unique minimizer of the objective in equation 3.2 is $$h_{\\theta^*}(Ax_t, A) = E[x_0 | Ax_t, A].$$", "md": "Consider the following noise model where we only observe m independent Gaussian measurements of the ground truth, and then one of the measurements is further omitted: $$A \\in \\mathbb{R}^{m \\times n}$$ consists of m rows drawn independently from $$N(0, I_n)$$, and $$A_{\\tilde{ } } \\in \\mathbb{R}^{m \\times n}$$ is constructed conditional on A by zeroing out its last row. Then the unique minimizer of the objective in equation 3.2 is $$h_{\\theta^*}(Ax_t, A) = E[x_0 | Ax_t, A].$$"}, {"type": "heading", "lvl": 2, "value": "Proof", "md": "## Proof"}, {"type": "text", "value": "Again by Theorem 4.1, we must show that for any $$A_{\\tilde{}}$$ in the support, $$E[A|A_{\\tilde{}}][A^TA]$$ is full-rank.\n\nFix any realization of A, which will have the following form:\n\n[a1^T]\n...\n[am-1]\n\nThen it is clear that conditional on A, A has the following distribution:\n\n[a1^T]\n...\n[am-1]\n\nHere bm is drawn entirely independently from $$N(0, I_n)$$. Elementary manipulations now reveal that $$E[A|A_{\\tilde{}}][A^TA] = E[bm \\sim N(0, I_n)[A^TA + b_mb_m] = A^TA + I_n$$, which is clearly full rank (indeed, it is PSD with strictly positive eigenvalues).", "md": "Again by Theorem 4.1, we must show that for any $$A_{\\tilde{}}$$ in the support, $$E[A|A_{\\tilde{}}][A^TA]$$ is full-rank.\n\nFix any realization of A, which will have the following form:\n\n[a1^T]\n...\n[am-1]\n\nThen it is clear that conditional on A, A has the following distribution:\n\n[a1^T]\n...\n[am-1]\n\nHere bm is drawn entirely independently from $$N(0, I_n)$$. Elementary manipulations now reveal that $$E[A|A_{\\tilde{}}][A^TA] = E[bm \\sim N(0, I_n)[A^TA + b_mb_m] = A^TA + I_n$$, which is clearly full rank (indeed, it is PSD with strictly positive eigenvalues)."}, {"type": "heading", "lvl": 2, "value": "A.1 Reduction", "md": "## A.1 Reduction"}, {"type": "text", "value": "In this section we argue that if there is an algorithm that recovers the target distribution $$p_0(x_0)$$ from i.i.d. samples $$(Ax_0, A)$$ where $$A \\sim p(A)$$ and $$x_0 \\sim p_0(x_0)$$, then, there is an algorithm that recovers $$p_0(x_0)$$ without sample access, but instead, using access to an oracle that given t, x and A in the support of $$p(A)$$, returns $$E[x_0 | Ax_t]$$. Indeed, for any A, Chen et al. [10] show that it is possible to recover the distribution of $$Ax_0$$ given access to $$E[Ax_0 | Ax_t]$$ for any t and x under some minimal assumptions on the data distribution $$p_0(x_0)$$, see [10, Assumptions 1-3]. Using our oracle and using this theorem, we can recover the distribution of $$Ax_0$$ for all A in the support. By sampling from these distributions, one can as well obtain samples of $$Ax_0$$ for $$A \\sim p(A)$$ and $$x_0 \\sim p_0(x_0)$$. Hence, if these samples are sufficient to recover $$p_0(x_0)$$, then, having an oracle to these conditional expectations is sufficient as well.\n\nThis intuition can be formalized as follows. Fix a distribution $$p_A(A)$$ over corruption matrices. For a distribution $$p_0(x_0)$$, denote by corrupt($$p_A, p_0$$) the distribution over pairs $$(A, Ax_0)$$ where $$A \\sim p_A(A)$$ and $$x_0 \\sim p_0(x_0)$$. We say that it is possible to reconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p(A)$$ if the following holds: for any two distributions, $$p(x), p'(x)$$ that satisfy Assumptions 1-3 of Chen et al. [10], if corrupt($$p_A, p_0$$) = corrupt($$p_A, p'$$), then $$p_0 = p'$$.\n\nSimilarly, we say that it is possible to reconstruct $$p_0(x_0)$$ from conditional expectations given $$A \\sim p(A)$$ if the following holds: for any distribution $$p(x), p'(x)$$ that satisfy Assumptions 1-3 of Chen et al. [10], if for all x, t and A in the support of $$p_A$$, $$E(x, x') \\sim p(x, x')[x_0 | Ax_t = x] = E(x', x') \\sim p'(x', x')[x' | Ax' = x]$$. (A.1)", "md": "In this section we argue that if there is an algorithm that recovers the target distribution $$p_0(x_0)$$ from i.i.d. samples $$(Ax_0, A)$$ where $$A \\sim p(A)$$ and $$x_0 \\sim p_0(x_0)$$, then, there is an algorithm that recovers $$p_0(x_0)$$ without sample access, but instead, using access to an oracle that given t, x and A in the support of $$p(A)$$, returns $$E[x_0 | Ax_t]$$. Indeed, for any A, Chen et al. [10] show that it is possible to recover the distribution of $$Ax_0$$ given access to $$E[Ax_0 | Ax_t]$$ for any t and x under some minimal assumptions on the data distribution $$p_0(x_0)$$, see [10, Assumptions 1-3]. Using our oracle and using this theorem, we can recover the distribution of $$Ax_0$$ for all A in the support. By sampling from these distributions, one can as well obtain samples of $$Ax_0$$ for $$A \\sim p(A)$$ and $$x_0 \\sim p_0(x_0)$$. Hence, if these samples are sufficient to recover $$p_0(x_0)$$, then, having an oracle to these conditional expectations is sufficient as well.\n\nThis intuition can be formalized as follows. Fix a distribution $$p_A(A)$$ over corruption matrices. For a distribution $$p_0(x_0)$$, denote by corrupt($$p_A, p_0$$) the distribution over pairs $$(A, Ax_0)$$ where $$A \\sim p_A(A)$$ and $$x_0 \\sim p_0(x_0)$$. We say that it is possible to reconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p(A)$$ if the following holds: for any two distributions, $$p(x), p'(x)$$ that satisfy Assumptions 1-3 of Chen et al. [10], if corrupt($$p_A, p_0$$) = corrupt($$p_A, p'$$), then $$p_0 = p'$$.\n\nSimilarly, we say that it is possible to reconstruct $$p_0(x_0)$$ from conditional expectations given $$A \\sim p(A)$$ if the following holds: for any distribution $$p(x), p'(x)$$ that satisfy Assumptions 1-3 of Chen et al. [10], if for all x, t and A in the support of $$p_A$$, $$E(x, x') \\sim p(x, x')[x_0 | Ax_t = x] = E(x', x') \\sim p'(x', x')[x' | Ax' = x]$$. (A.1)"}]}, {"page": 16, "text": " then  p 0  =   p\u2032 . Here,    p0,t(x  0,x  t) is obtained by sampling           x 0  \u223c  p 0  and   x t =   x 0  +  \u03c3 t\u03b7  where\n                 0\n \u03b7  \u223c N(0, I). Similarly,        p\u2032   (x \u2032 ,x \u2032) is obtained by the same process where               x \u2032 is instead sampled\n                                  0,t    0    t                                                        0\n from  p \u2032 . We state the following lemma:\n         0\n Lemma A.3.       Fix a distribution     pA (A). If it is possible to reconstruct       p0 (x 0 ) from random corruptions\n y0  =   Ax  0 , A  \u223c   p A (A), then it is possible to reconstruct            p 0(x 0 ) given access to an oracle that\n computes the conditional expectations             E[x  0 |Ax  t, A], for  A  \u223c   p A (A)  and   x t =   x 0 +  \u03c3 t\u03b7.\nProof.    Assume that it is possible to reconstruct          p 0(x  0) from random corruptions          A  \u223c   p A(A)   and we\nwill prove that it is possible to reconstruct           p 0(x 0 ) from conditional expectations given            A   \u223c  p A (A).\nTo do so, let    p  (x   ) and  p \u2032(x  \u2032) be two distributions that satisfy Assumptions 1-3 of Chen et al. [10].\n                   0   0          0    0\nAssume that equation A.1 holds. We will prove that                      p0  =   p\u2032 . Fix some      A  in the support of      p A .\n By Chen et al. [10], there is an algorithm that samples from the distribution of0                      Ax   0, x 0 \u223c   p0 (x 0),\n that only has access to        E[Ax    0  | Ax  t , A]  and similarly, there is an algorithm that samples from\n the distribution of      Ax   \u2032 that only has access to         E[Ax    \u2032  | Ax   \u2032, A].   Since these two conditional\n expectations are assumed to be0the same, then the distribution of       0         t     Ax  0  equals the distribution of\n Ax  \u2032. Consequently,       corrupt(p     A , p0) = corrupt(p       A , p\u2032). By the assumption that it is possible to\n     0                                                                   0                                \u2032\n reconstruct    p0 (x 0)  from random corruptions          A  \u223c   pA (A), this implies that      p 0 =   p0 . This completes\n the proof.\n B     Broader Impact and Risks\n Generative models in general hold the potential to have far-reaching impacts on society in a variety of\n forms, coupled with several associated risks [40, 32, 33, 31]. Among other potential applications, they\n can be utilized to create deceptive images and perpetuate societal biases. To the best of our knowledge,\n our paper does not amplify any of these existing risks. Regarding the included MRI results, we want\n to clarify that we make no claim that such results are diagnostically useful. This experiment serves\n only as a toy demonstration that it can be potentially feasible to learn the distribution of MRI scans\nwith corrupted samples. Significant further research must be done in collaboration with radiologists\n before our algorithm gets tested in clinical trials. Finally, we want to underline again that even though\n our approach seems to mitigate the memorization issue in generative models, we cannot guarantee\n the privacy of any training sample unless we make assumptions about the data distribution. Hence,\nwe strongly discourage using this algorithm in applications where privacy is important before this\n research topic is investigated further.\n C     Training Details\nWe      open-source        our    code      and    models       to   facilitate     further     research      in   this    area:\n https://github.com/giannisdaras/ambient-diffusion.\n Models trained from scratch.                We trained models from scratch at different corruption levels on\n CelebA-HQ, AFHQ and CIFAR-10. The resolution of the first two datasets was set to                               64  \u00d7   64  and\n for CIFAR-10 we trained on           32  \u00d7  32.\nWe started from EDM\u2019s [30] official implementation and made some necessary changes. Architec-\n turally, the only change we made was to replace the convolutional layers with Gated Convolutions [58]\n that are known to perform well for inpainting problems. We observed that this change stabilized the\n training significantly, especially in the high-corruptions regime. As in EDM, we use the architecture\n from the DDPM++ [36] paper.\nTo avoid additional design complexity, we tried to keep our hyperparameters as close as possible to\n the EDM paper. We observed that for high corruption levels, it was useful to add gradient clipping,\n otherwise, the training would often diverge. For all our experiments, we use gradient clipping with\n max-norm set to       1.0. We underline that unfortunately, even with gradient clipping, the training at\n high corruption levels (p       \u2265  0.8), still diverges sometimes. Whenever this happened, we restarted the\n training from an earlier checkpoint. We list the rest of the hyperparameters we used in Table 2.\nTraining diffusion models from scratch is quite computationally intensive. We trained all our models\n for 200000     iterations. Our CIFAR-10 models required                 \u2248  2 days of training each on         6 A100 GPUs.\n Our AFHQ and CelebA-HQ models required                      \u2248   6  days of training each on        6  A100 GPUs. These\n                                                               16", "md": "then $$p_0 = p'$$ . Here, $$p_{0,t}(x_0,x_t)$$ is obtained by sampling $$x_0 \\sim p_0$$ and $$x_t = x_0 + \\sigma t\\eta$$ where\n\n$$\\eta \\sim N(0, I)$$. Similarly, $$p' (x',x')$$ is obtained by the same process where $$x'$$ is instead sampled\n\nfrom $$p'$$ . We state the following lemma:\n\nLemma A.3. Fix a distribution $$p_A(A)$$. If it is possible to reconstruct $$p_0(x_0)$$ from random corruptions\n\n$$y_0 = Ax_0$$, $$A \\sim p_A(A)$$, then it is possible to reconstruct $$p_0(x_0)$$ given access to an oracle that\n\ncomputes the conditional expectations $$E[x_0 |Ax_t, A]$$, for $$A \\sim p_A(A)$$ and $$x_t = x_0 + \\sigma t\\eta$$.\n\nProof. Assume that it is possible to reconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p_A(A)$$ and we\n\nwill prove that it is possible to reconstruct $$p_0(x_0)$$ from conditional expectations given $$A \\sim p_A(A)$$.\n\nTo do so, let $$p_0(x)$$ and $$p'(x')$$ be two distributions that satisfy Assumptions 1-3 of Chen et al. [10].\n\nAssume that equation A.1 holds. We will prove that $$p_0 = p'$$ . Fix some $$A$$ in the support of $$p_A$$.\n\nBy Chen et al. [10], there is an algorithm that samples from the distribution of $$Ax_0, x_0 \\sim p_0(x_0)$$,\n\nthat only has access to $$E[Ax_0 | Ax_t , A]$$ and similarly, there is an algorithm that samples from\n\nthe distribution of $$Ax'$$ that only has access to $$E[Ax' | Ax', A]$$. Since these two conditional\n\nexpectations are assumed to be the same, then the distribution of $$Ax_0$$ equals the distribution of\n\n$$Ax'$$ . Consequently, $$corrupt(p_A, p_0) = corrupt(p_A, p')$$. By the assumption that it is possible to\n\nreconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p_A(A)$$, this implies that $$p_0 = p'$$ . This completes\n\nthe proof.\n\nB Broader Impact and Risks\n\nGenerative models in general hold the potential to have far-reaching impacts on society in a variety of\n\nforms, coupled with several associated risks [40, 32, 33, 31]. Among other potential applications, they\n\ncan be utilized to create deceptive images and perpetuate societal biases. To the best of our knowledge,\n\nour paper does not amplify any of these existing risks. Regarding the included MRI results, we want\n\nto clarify that we make no claim that such results are diagnostically useful. This experiment serves\n\nonly as a toy demonstration that it can be potentially feasible to learn the distribution of MRI scans\n\nwith corrupted samples. Significant further research must be done in collaboration with radiologists\n\nbefore our algorithm gets tested in clinical trials. Finally, we want to underline again that even though\n\nour approach seems to mitigate the memorization issue in generative models, we cannot guarantee\n\nthe privacy of any training sample unless we make assumptions about the data distribution. Hence,\n\nwe strongly discourage using this algorithm in applications where privacy is important before this\n\nresearch topic is investigated further.\n\nC Training Details\n\nWe open-source our code and models to facilitate further research in this area:\n\nhttps://github.com/giannisdaras/ambient-diffusion.\n\nModels trained from scratch. We trained models from scratch at different corruption levels on\n\nCelebA-HQ, AFHQ and CIFAR-10. The resolution of the first two datasets was set to $$64 \\times 64$$ and\n\nfor CIFAR-10 we trained on $$32 \\times 32$$.\n\nWe started from EDM\u2019s [30] official implementation and made some necessary changes. Architec-\n\nturally, the only change we made was to replace the convolutional layers with Gated Convolutions [58]\n\nthat are known to perform well for inpainting problems. We observed that this change stabilized the\n\ntraining significantly, especially in the high-corruptions regime. As in EDM, we use the architecture\n\nfrom the DDPM++ [36] paper.\n\nTo avoid additional design complexity, we tried to keep our hyperparameters as close as possible to\n\nthe EDM paper. We observed that for high corruption levels, it was useful to add gradient clipping,\n\notherwise, the training would often diverge. For all our experiments, we use gradient clipping with\n\nmax-norm set to $$1.0$$. We underline that unfortunately, even with gradient clipping, the training at\n\nhigh corruption levels ($$p \\geq 0.8$$), still diverges sometimes. Whenever this happened, we restarted the\n\ntraining from an earlier checkpoint. We list the rest of the hyperparameters we used in Table 2.\n\nTraining diffusion models from scratch is quite computationally intensive. We trained all our models\n\nfor $$200000$$ iterations. Our CIFAR-10 models required $$\\approx 2$$ days of training each on $$6$$ A100 GPUs.\n\nOur AFHQ and CelebA-HQ models required $$\\approx 6$$ days of training each on $$6$$ A100 GPUs.", "images": [], "items": [{"type": "text", "value": "then $$p_0 = p'$$ . Here, $$p_{0,t}(x_0,x_t)$$ is obtained by sampling $$x_0 \\sim p_0$$ and $$x_t = x_0 + \\sigma t\\eta$$ where\n\n$$\\eta \\sim N(0, I)$$. Similarly, $$p' (x',x')$$ is obtained by the same process where $$x'$$ is instead sampled\n\nfrom $$p'$$ . We state the following lemma:\n\nLemma A.3. Fix a distribution $$p_A(A)$$. If it is possible to reconstruct $$p_0(x_0)$$ from random corruptions\n\n$$y_0 = Ax_0$$, $$A \\sim p_A(A)$$, then it is possible to reconstruct $$p_0(x_0)$$ given access to an oracle that\n\ncomputes the conditional expectations $$E[x_0 |Ax_t, A]$$, for $$A \\sim p_A(A)$$ and $$x_t = x_0 + \\sigma t\\eta$$.\n\nProof. Assume that it is possible to reconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p_A(A)$$ and we\n\nwill prove that it is possible to reconstruct $$p_0(x_0)$$ from conditional expectations given $$A \\sim p_A(A)$$.\n\nTo do so, let $$p_0(x)$$ and $$p'(x')$$ be two distributions that satisfy Assumptions 1-3 of Chen et al. [10].\n\nAssume that equation A.1 holds. We will prove that $$p_0 = p'$$ . Fix some $$A$$ in the support of $$p_A$$.\n\nBy Chen et al. [10], there is an algorithm that samples from the distribution of $$Ax_0, x_0 \\sim p_0(x_0)$$,\n\nthat only has access to $$E[Ax_0 | Ax_t , A]$$ and similarly, there is an algorithm that samples from\n\nthe distribution of $$Ax'$$ that only has access to $$E[Ax' | Ax', A]$$. Since these two conditional\n\nexpectations are assumed to be the same, then the distribution of $$Ax_0$$ equals the distribution of\n\n$$Ax'$$ . Consequently, $$corrupt(p_A, p_0) = corrupt(p_A, p')$$. By the assumption that it is possible to\n\nreconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p_A(A)$$, this implies that $$p_0 = p'$$ . This completes\n\nthe proof.\n\nB Broader Impact and Risks\n\nGenerative models in general hold the potential to have far-reaching impacts on society in a variety of\n\nforms, coupled with several associated risks [40, 32, 33, 31]. Among other potential applications, they\n\ncan be utilized to create deceptive images and perpetuate societal biases. To the best of our knowledge,\n\nour paper does not amplify any of these existing risks. Regarding the included MRI results, we want\n\nto clarify that we make no claim that such results are diagnostically useful. This experiment serves\n\nonly as a toy demonstration that it can be potentially feasible to learn the distribution of MRI scans\n\nwith corrupted samples. Significant further research must be done in collaboration with radiologists\n\nbefore our algorithm gets tested in clinical trials. Finally, we want to underline again that even though\n\nour approach seems to mitigate the memorization issue in generative models, we cannot guarantee\n\nthe privacy of any training sample unless we make assumptions about the data distribution. Hence,\n\nwe strongly discourage using this algorithm in applications where privacy is important before this\n\nresearch topic is investigated further.\n\nC Training Details\n\nWe open-source our code and models to facilitate further research in this area:\n\nhttps://github.com/giannisdaras/ambient-diffusion.\n\nModels trained from scratch. We trained models from scratch at different corruption levels on\n\nCelebA-HQ, AFHQ and CIFAR-10. The resolution of the first two datasets was set to $$64 \\times 64$$ and\n\nfor CIFAR-10 we trained on $$32 \\times 32$$.\n\nWe started from EDM\u2019s [30] official implementation and made some necessary changes. Architec-\n\nturally, the only change we made was to replace the convolutional layers with Gated Convolutions [58]\n\nthat are known to perform well for inpainting problems. We observed that this change stabilized the\n\ntraining significantly, especially in the high-corruptions regime. As in EDM, we use the architecture\n\nfrom the DDPM++ [36] paper.\n\nTo avoid additional design complexity, we tried to keep our hyperparameters as close as possible to\n\nthe EDM paper. We observed that for high corruption levels, it was useful to add gradient clipping,\n\notherwise, the training would often diverge. For all our experiments, we use gradient clipping with\n\nmax-norm set to $$1.0$$. We underline that unfortunately, even with gradient clipping, the training at\n\nhigh corruption levels ($$p \\geq 0.8$$), still diverges sometimes. Whenever this happened, we restarted the\n\ntraining from an earlier checkpoint. We list the rest of the hyperparameters we used in Table 2.\n\nTraining diffusion models from scratch is quite computationally intensive. We trained all our models\n\nfor $$200000$$ iterations. Our CIFAR-10 models required $$\\approx 2$$ days of training each on $$6$$ A100 GPUs.\n\nOur AFHQ and CelebA-HQ models required $$\\approx 6$$ days of training each on $$6$$ A100 GPUs.", "md": "then $$p_0 = p'$$ . Here, $$p_{0,t}(x_0,x_t)$$ is obtained by sampling $$x_0 \\sim p_0$$ and $$x_t = x_0 + \\sigma t\\eta$$ where\n\n$$\\eta \\sim N(0, I)$$. Similarly, $$p' (x',x')$$ is obtained by the same process where $$x'$$ is instead sampled\n\nfrom $$p'$$ . We state the following lemma:\n\nLemma A.3. Fix a distribution $$p_A(A)$$. If it is possible to reconstruct $$p_0(x_0)$$ from random corruptions\n\n$$y_0 = Ax_0$$, $$A \\sim p_A(A)$$, then it is possible to reconstruct $$p_0(x_0)$$ given access to an oracle that\n\ncomputes the conditional expectations $$E[x_0 |Ax_t, A]$$, for $$A \\sim p_A(A)$$ and $$x_t = x_0 + \\sigma t\\eta$$.\n\nProof. Assume that it is possible to reconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p_A(A)$$ and we\n\nwill prove that it is possible to reconstruct $$p_0(x_0)$$ from conditional expectations given $$A \\sim p_A(A)$$.\n\nTo do so, let $$p_0(x)$$ and $$p'(x')$$ be two distributions that satisfy Assumptions 1-3 of Chen et al. [10].\n\nAssume that equation A.1 holds. We will prove that $$p_0 = p'$$ . Fix some $$A$$ in the support of $$p_A$$.\n\nBy Chen et al. [10], there is an algorithm that samples from the distribution of $$Ax_0, x_0 \\sim p_0(x_0)$$,\n\nthat only has access to $$E[Ax_0 | Ax_t , A]$$ and similarly, there is an algorithm that samples from\n\nthe distribution of $$Ax'$$ that only has access to $$E[Ax' | Ax', A]$$. Since these two conditional\n\nexpectations are assumed to be the same, then the distribution of $$Ax_0$$ equals the distribution of\n\n$$Ax'$$ . Consequently, $$corrupt(p_A, p_0) = corrupt(p_A, p')$$. By the assumption that it is possible to\n\nreconstruct $$p_0(x_0)$$ from random corruptions $$A \\sim p_A(A)$$, this implies that $$p_0 = p'$$ . This completes\n\nthe proof.\n\nB Broader Impact and Risks\n\nGenerative models in general hold the potential to have far-reaching impacts on society in a variety of\n\nforms, coupled with several associated risks [40, 32, 33, 31]. Among other potential applications, they\n\ncan be utilized to create deceptive images and perpetuate societal biases. To the best of our knowledge,\n\nour paper does not amplify any of these existing risks. Regarding the included MRI results, we want\n\nto clarify that we make no claim that such results are diagnostically useful. This experiment serves\n\nonly as a toy demonstration that it can be potentially feasible to learn the distribution of MRI scans\n\nwith corrupted samples. Significant further research must be done in collaboration with radiologists\n\nbefore our algorithm gets tested in clinical trials. Finally, we want to underline again that even though\n\nour approach seems to mitigate the memorization issue in generative models, we cannot guarantee\n\nthe privacy of any training sample unless we make assumptions about the data distribution. Hence,\n\nwe strongly discourage using this algorithm in applications where privacy is important before this\n\nresearch topic is investigated further.\n\nC Training Details\n\nWe open-source our code and models to facilitate further research in this area:\n\nhttps://github.com/giannisdaras/ambient-diffusion.\n\nModels trained from scratch. We trained models from scratch at different corruption levels on\n\nCelebA-HQ, AFHQ and CIFAR-10. The resolution of the first two datasets was set to $$64 \\times 64$$ and\n\nfor CIFAR-10 we trained on $$32 \\times 32$$.\n\nWe started from EDM\u2019s [30] official implementation and made some necessary changes. Architec-\n\nturally, the only change we made was to replace the convolutional layers with Gated Convolutions [58]\n\nthat are known to perform well for inpainting problems. We observed that this change stabilized the\n\ntraining significantly, especially in the high-corruptions regime. As in EDM, we use the architecture\n\nfrom the DDPM++ [36] paper.\n\nTo avoid additional design complexity, we tried to keep our hyperparameters as close as possible to\n\nthe EDM paper. We observed that for high corruption levels, it was useful to add gradient clipping,\n\notherwise, the training would often diverge. For all our experiments, we use gradient clipping with\n\nmax-norm set to $$1.0$$. We underline that unfortunately, even with gradient clipping, the training at\n\nhigh corruption levels ($$p \\geq 0.8$$), still diverges sometimes. Whenever this happened, we restarted the\n\ntraining from an earlier checkpoint. We list the rest of the hyperparameters we used in Table 2.\n\nTraining diffusion models from scratch is quite computationally intensive. We trained all our models\n\nfor $$200000$$ iterations. Our CIFAR-10 models required $$\\approx 2$$ days of training each on $$6$$ A100 GPUs.\n\nOur AFHQ and CelebA-HQ models required $$\\approx 6$$ days of training each on $$6$$ A100 GPUs."}]}, {"page": 17, "text": "                                         Table 2: Training Hyperparameters\n  Dataset         Iters      Batch    LR      SDE     p                          \u03b4       Aug. Prob.    Ch. Multipliers   Dropout\n  CIFAR-10                   512      1e-3            {0.2, 0.4,0.6, 0.8}                0.12          (1, 1, 1, 1)      0.13\n  AFHQ            200000     256      2e-4    VP      {0.2, 0.4,0.6, 0.8,0.9}    0.1     0.15          (1, 2, 2, 2)      0.25\n  CelebA-HQ                                           {0.2, 0.6,0.8}                                                     0.1\n                                                      0.9                        0.3\n numbers roughly match the performance reported in the EDM paper, indicating that the extra\n corruption we need to do on matrix           A  does not increase training time.\n Due to the increased computational complexity of training these models, we could not extensively\n optimize the hyperparameters, e.g. the            \u03b4 probability in our extra corruption. For higher corruption,\n e.g. for  p = 0.9, we noticed that we had to increase            \u03b4 in order for the model to learn to perform well\n on the unobserved pixels.\n Finetuning Deepfloyd\u2019s IF.             We access Deepfloyd\u2019s IF [2] model through the                diffusers       library.\nThe model is a Cascaded Diffusion Model [25]. The first part of the pipeline is a text-conditional\n diffusion model that outputs images at resolution64             \u00d764. Next in the pipeline, there are two diffusion\n models that are conditioned both in the input text and the low-resolution output of the previous stage.\nThe first upscaling module increases the resolution from               64  \u00d7  64  to 256  \u00d7  256   and the final one from\n256   \u00d7  256   to 1024   \u00d7  1024.\nTo reduce the computational requirements of the finetuning, we only finetune the first text-conditional\n diffusion model that works with         64\u00d7    64  resolution images. Once the finetuning is completed, we use\n again the whole model to generate high-resolution images.\n For the finetuning, we set the training batch size to           32  and the learning rate to      3e  \u22126. We train for a\n maximum of      15000    steps and we keep the checkpoint that gives the lowest error on the pixels that we\n further corrupted. To further reduce the computational requirements, we use an 8-bit Adam Optimizer\n and we train with half-precision.\n For our CelebA finetuning experiments, we set                \u03b4  = 0.1   and  p  = 0.8. We experiment with the full\n training set, a subset of size       3000   (see Figure 1) and a subset of          300. For the model trained with\n only  300   heavily corrupted samples, we did not observe memorization but the samples were of very\n low quality. Intuitively, our algorithm provides a way to control the trade-off between memorization\n and fidelity. Fully exploring this trade-off is a very promising direction for future work. For our\n MRI experiments, we use two non-overlapping blocks that each obfuscate                       25%    of the image and we\n evaluate the model in one of them.\nAll of our fine-tuning experiments can be completed in a few hours. Training for                          15000   iterations\n takes  \u2248  10  hours on an A100 GPU, but we usually get the best checkpoints earlier in the training.\n D     Evaluation Details\n FID evaluation.         Our FID [22] score is computed with respect to the training set, as is standard\n practice, e.g. see [24, 30, 52]. For each of our models trained from scratch, we generate                             50000\n images using the seeds        0 \u2212  49999. Once we generate our images, we use the code provided in the\n official implementation of the EDM [30] paper for the FID computation.\n E     Additional Experiments\n E.1    Restoration performance with noisy measurements\n In Table 1 of the main paper, we compare the restoration performance of our models and vanilla\n diffusion models (trained with uncorrupted images). We compare the restoration performance in the\n task of random inpainting because it is straightforward to use our models to solve this inverse problem.\n It is potentially feasible to use our trained generative models to solve any (linear or non-linear) inverse\n problem but we leave this direction for future work.         17", "md": "|Dataset|Iters|Batch|LR|SDE|p|\u03b4|Aug. Prob.|Ch. Multipliers|Dropout|\n|---|---|---|---|---|---|---|---|---|---|\n|CIFAR-10| |512|1e-3| |{0.2, 0.4, 0.6, 0.8}|0.12|(1, 1, 1, 1)|0.13| |\n|AFHQ|200000|256|2e-4|VP|{0.2, 0.4, 0.6, 0.8, 0.9}|0.1|0.15|(1, 2, 2, 2)|0.25|\n|CelebA-HQ| | | |{0.2, 0.6, 0.8, 0.9}|0.1| | | |0.3|\n\nNumbers roughly match the performance reported in the EDM paper, indicating that the extra corruption we need to do on matrix \\( A \\) does not increase training time.\n\nDue to the increased computational complexity of training these models, we could not extensively optimize the hyperparameters, e.g. the \\( \\delta \\) probability in our extra corruption. For higher corruption, e.g. for \\( p = 0.9 \\), we noticed that we had to increase \\( \\delta \\) in order for the model to learn to perform well on the unobserved pixels.\n\nFinetuning Deepfloyd\u2019s IF. We access Deepfloyd\u2019s IF [2] model through the diffusers library. The model is a Cascaded Diffusion Model [25]. The first part of the pipeline is a text-conditional diffusion model that outputs images at resolution \\( 64 \\times 64 \\). Next in the pipeline, there are two diffusion models that are conditioned both on the input text and the low-resolution output of the previous stage.\n\nThe first upscaling module increases the resolution from \\( 64 \\times 64 \\) to \\( 256 \\times 256 \\) and the final one from \\( 256 \\times 256 \\) to \\( 1024 \\times 1024 \\).\n\nTo reduce the computational requirements of the finetuning, we only finetune the first text-conditional diffusion model that works with \\( 64 \\times 64 \\) resolution images. Once the finetuning is completed, we use again the whole model to generate high-resolution images.\n\nFor the finetuning, we set the training batch size to \\( 32 \\) and the learning rate to \\( 3e-6 \\). We train for a maximum of \\( 15000 \\) steps and we keep the checkpoint that gives the lowest error on the pixels that we further corrupted. To further reduce the computational requirements, we use an 8-bit Adam Optimizer and we train with half-precision.\n\nFor our CelebA finetuning experiments, we set \\( \\delta = 0.1 \\) and \\( p = 0.8 \\). We experiment with the full training set, a subset of size \\( 3000 \\) (see Figure 1) and a subset of \\( 300 \\). For the model trained with only \\( 300 \\) heavily corrupted samples, we did not observe memorization but the samples were of very low quality. Intuitively, our algorithm provides a way to control the trade-off between memorization and fidelity. Fully exploring this trade-off is a very promising direction for future work.\n\nFor our MRI experiments, we use two non-overlapping blocks that each obfuscate \\( 25\\% \\) of the image and we evaluate the model in one of them.\n\nAll of our fine-tuning experiments can be completed in a few hours. Training for \\( 15000 \\) iterations takes approximately 10 hours on an A100 GPU, but we usually get the best checkpoints earlier in the training.\n\n### Evaluation Details\n\nFID evaluation. Our FID [22] score is computed with respect to the training set, as is standard practice, e.g. see [24, 30, 52]. For each of our models trained from scratch, we generate \\( 50000 \\) images using the seeds \\( 0 - 49999 \\). Once we generate our images, we use the code provided in the official implementation of the EDM [30] paper for the FID computation.\n\n### Additional Experiments\n\n#### Restoration performance with noisy measurements\n\nIn Table 1 of the main paper, we compare the restoration performance of our models and vanilla diffusion models (trained with uncorrupted images). We compare the restoration performance in the task of random inpainting because it is straightforward to use our models to solve this inverse problem. It is potentially feasible to use our trained generative models to solve any (linear or non-linear) inverse problem but we leave this direction for future work.", "images": [], "items": [{"type": "table", "rows": [["Dataset", "Iters", "Batch", "LR", "SDE", "p", "\u03b4", "Aug. Prob.", "Ch. Multipliers", "Dropout"], ["CIFAR-10", "", "512", "1e-3", "", "{0.2, 0.4, 0.6, 0.8}", "0.12", "(1, 1, 1, 1)", "0.13", ""], ["AFHQ", "200000", "256", "2e-4", "VP", "{0.2, 0.4, 0.6, 0.8, 0.9}", "0.1", "0.15", "(1, 2, 2, 2)", "0.25"], ["CelebA-HQ", "", "", "", "{0.2, 0.6, 0.8, 0.9}", "0.1", "", "", "", "0.3"]], "md": "|Dataset|Iters|Batch|LR|SDE|p|\u03b4|Aug. Prob.|Ch. Multipliers|Dropout|\n|---|---|---|---|---|---|---|---|---|---|\n|CIFAR-10| |512|1e-3| |{0.2, 0.4, 0.6, 0.8}|0.12|(1, 1, 1, 1)|0.13| |\n|AFHQ|200000|256|2e-4|VP|{0.2, 0.4, 0.6, 0.8, 0.9}|0.1|0.15|(1, 2, 2, 2)|0.25|\n|CelebA-HQ| | | |{0.2, 0.6, 0.8, 0.9}|0.1| | | |0.3|", "isPerfectTable": true, "csv": "\"Dataset\",\"Iters\",\"Batch\",\"LR\",\"SDE\",\"p\",\"\u03b4\",\"Aug. Prob.\",\"Ch. Multipliers\",\"Dropout\"\n\"CIFAR-10\",\"\",\"512\",\"1e-3\",\"\",\"{0.2, 0.4, 0.6, 0.8}\",\"0.12\",\"(1, 1, 1, 1)\",\"0.13\",\"\"\n\"AFHQ\",\"200000\",\"256\",\"2e-4\",\"VP\",\"{0.2, 0.4, 0.6, 0.8, 0.9}\",\"0.1\",\"0.15\",\"(1, 2, 2, 2)\",\"0.25\"\n\"CelebA-HQ\",\"\",\"\",\"\",\"{0.2, 0.6, 0.8, 0.9}\",\"0.1\",\"\",\"\",\"\",\"0.3\""}, {"type": "text", "value": "Numbers roughly match the performance reported in the EDM paper, indicating that the extra corruption we need to do on matrix \\( A \\) does not increase training time.\n\nDue to the increased computational complexity of training these models, we could not extensively optimize the hyperparameters, e.g. the \\( \\delta \\) probability in our extra corruption. For higher corruption, e.g. for \\( p = 0.9 \\), we noticed that we had to increase \\( \\delta \\) in order for the model to learn to perform well on the unobserved pixels.\n\nFinetuning Deepfloyd\u2019s IF. We access Deepfloyd\u2019s IF [2] model through the diffusers library. The model is a Cascaded Diffusion Model [25]. The first part of the pipeline is a text-conditional diffusion model that outputs images at resolution \\( 64 \\times 64 \\). Next in the pipeline, there are two diffusion models that are conditioned both on the input text and the low-resolution output of the previous stage.\n\nThe first upscaling module increases the resolution from \\( 64 \\times 64 \\) to \\( 256 \\times 256 \\) and the final one from \\( 256 \\times 256 \\) to \\( 1024 \\times 1024 \\).\n\nTo reduce the computational requirements of the finetuning, we only finetune the first text-conditional diffusion model that works with \\( 64 \\times 64 \\) resolution images. Once the finetuning is completed, we use again the whole model to generate high-resolution images.\n\nFor the finetuning, we set the training batch size to \\( 32 \\) and the learning rate to \\( 3e-6 \\). We train for a maximum of \\( 15000 \\) steps and we keep the checkpoint that gives the lowest error on the pixels that we further corrupted. To further reduce the computational requirements, we use an 8-bit Adam Optimizer and we train with half-precision.\n\nFor our CelebA finetuning experiments, we set \\( \\delta = 0.1 \\) and \\( p = 0.8 \\). We experiment with the full training set, a subset of size \\( 3000 \\) (see Figure 1) and a subset of \\( 300 \\). For the model trained with only \\( 300 \\) heavily corrupted samples, we did not observe memorization but the samples were of very low quality. Intuitively, our algorithm provides a way to control the trade-off between memorization and fidelity. Fully exploring this trade-off is a very promising direction for future work.\n\nFor our MRI experiments, we use two non-overlapping blocks that each obfuscate \\( 25\\% \\) of the image and we evaluate the model in one of them.\n\nAll of our fine-tuning experiments can be completed in a few hours. Training for \\( 15000 \\) iterations takes approximately 10 hours on an A100 GPU, but we usually get the best checkpoints earlier in the training.", "md": "Numbers roughly match the performance reported in the EDM paper, indicating that the extra corruption we need to do on matrix \\( A \\) does not increase training time.\n\nDue to the increased computational complexity of training these models, we could not extensively optimize the hyperparameters, e.g. the \\( \\delta \\) probability in our extra corruption. For higher corruption, e.g. for \\( p = 0.9 \\), we noticed that we had to increase \\( \\delta \\) in order for the model to learn to perform well on the unobserved pixels.\n\nFinetuning Deepfloyd\u2019s IF. We access Deepfloyd\u2019s IF [2] model through the diffusers library. The model is a Cascaded Diffusion Model [25]. The first part of the pipeline is a text-conditional diffusion model that outputs images at resolution \\( 64 \\times 64 \\). Next in the pipeline, there are two diffusion models that are conditioned both on the input text and the low-resolution output of the previous stage.\n\nThe first upscaling module increases the resolution from \\( 64 \\times 64 \\) to \\( 256 \\times 256 \\) and the final one from \\( 256 \\times 256 \\) to \\( 1024 \\times 1024 \\).\n\nTo reduce the computational requirements of the finetuning, we only finetune the first text-conditional diffusion model that works with \\( 64 \\times 64 \\) resolution images. Once the finetuning is completed, we use again the whole model to generate high-resolution images.\n\nFor the finetuning, we set the training batch size to \\( 32 \\) and the learning rate to \\( 3e-6 \\). We train for a maximum of \\( 15000 \\) steps and we keep the checkpoint that gives the lowest error on the pixels that we further corrupted. To further reduce the computational requirements, we use an 8-bit Adam Optimizer and we train with half-precision.\n\nFor our CelebA finetuning experiments, we set \\( \\delta = 0.1 \\) and \\( p = 0.8 \\). We experiment with the full training set, a subset of size \\( 3000 \\) (see Figure 1) and a subset of \\( 300 \\). For the model trained with only \\( 300 \\) heavily corrupted samples, we did not observe memorization but the samples were of very low quality. Intuitively, our algorithm provides a way to control the trade-off between memorization and fidelity. Fully exploring this trade-off is a very promising direction for future work.\n\nFor our MRI experiments, we use two non-overlapping blocks that each obfuscate \\( 25\\% \\) of the image and we evaluate the model in one of them.\n\nAll of our fine-tuning experiments can be completed in a few hours. Training for \\( 15000 \\) iterations takes approximately 10 hours on an A100 GPU, but we usually get the best checkpoints earlier in the training."}, {"type": "heading", "lvl": 3, "value": "Evaluation Details", "md": "### Evaluation Details"}, {"type": "text", "value": "FID evaluation. Our FID [22] score is computed with respect to the training set, as is standard practice, e.g. see [24, 30, 52]. For each of our models trained from scratch, we generate \\( 50000 \\) images using the seeds \\( 0 - 49999 \\). Once we generate our images, we use the code provided in the official implementation of the EDM [30] paper for the FID computation.", "md": "FID evaluation. Our FID [22] score is computed with respect to the training set, as is standard practice, e.g. see [24, 30, 52]. For each of our models trained from scratch, we generate \\( 50000 \\) images using the seeds \\( 0 - 49999 \\). Once we generate our images, we use the code provided in the official implementation of the EDM [30] paper for the FID computation."}, {"type": "heading", "lvl": 3, "value": "Additional Experiments", "md": "### Additional Experiments"}, {"type": "heading", "lvl": 4, "value": "Restoration performance with noisy measurements", "md": "#### Restoration performance with noisy measurements"}, {"type": "text", "value": "In Table 1 of the main paper, we compare the restoration performance of our models and vanilla diffusion models (trained with uncorrupted images). We compare the restoration performance in the task of random inpainting because it is straightforward to use our models to solve this inverse problem. It is potentially feasible to use our trained generative models to solve any (linear or non-linear) inverse problem but we leave this direction for future work.", "md": "In Table 1 of the main paper, we compare the restoration performance of our models and vanilla diffusion models (trained with uncorrupted images). We compare the restoration performance in the task of random inpainting because it is straightforward to use our models to solve this inverse problem. It is potentially feasible to use our trained generative models to solve any (linear or non-linear) inverse problem but we leave this direction for future work."}]}, {"page": 18, "text": " In this section, we further compare our models (trained with randomly inpainted images) in the task\n of inpainting with noisy measurements. Concretely, we want to predict                x0 , given measurements\n yt =  A(x   0 + \u03c3 yt \u03b7),  \u03b7  \u223c N(0, I). As in the rest of the paper, we assume that the mask matrix\n A is known. We can solve this problem with one model prediction using our trained models since\n according to Eq. 4.1, we are learning:     h   (y , A, t) =  E[x   |Ax    =  y , A].\n                                               \u03b8   t               0     t     t\nWe use the EDM [30] state-of-the-art model trained on AFHQ as our baseline (as we did in the main\n paper). To use this pre-trained model to solve the noisy random inpainting inverse problem, we need a\n reconstruction algorithm. We experiment again with DPS and DDRM which can both handle inverse\n problems with noise in the measurements. We present our results in Table 3. As shown, our models\n significantly outperform the EDM models that use the DDRM reconstruction algorithm and perform\n on par with the EDM models that use the DPS reconstruction algorithm.\n Dataset     Corruption Probability       Measurement Noise (\u03c3     y0)    Method      LPIPS     PSNR       NFE\n  AFHQ                                                                      Ours      0.0861     29.46       1\n                                                                            DPS       0.0846     29.83     100\n                        0.4                           0.05                            0.2061     24.47      35\n                                                                          DDRM        0.1739     25.38      99\n                                                                                      0.1677     25.58     199\n                                                                            Ours      0.1031     27.40       1\n                                                                            DPS       0.0949     27.92     100\n                        0.6                           0.05                            0.4066     18.73      35\n                                                                          DDRM        0.3626     19.49      99\n                                                                                      0.3506     19.70     199\n                                                                            Ours      0.1792     23.21       1\n                                                                            DPS       0.1778     23.01     100\n                        0.8                           0.05                            0.5879     13.65      35\n                                                                          DDRM        0.5802     13.99      99\n                                                                                      0.5753     14.09     199\nTable 3:  Comparison of our model (trained on corrupted data) with state-of-the-art diffusion models on CelebA\n(DDIM [50] model) and AFHQ (EDM [30] model) for solving the random inpainting inverse problem with\n noise.\n E.2   Comparison with Supervised Methods\n For completeness, we include a comparison with Masked AutoEncoders [21], a state-of-the-art\n supervised method for solving the random inpainting problem. The official repository of this paper\n does not include models trained on AFHQ. We compare with the available models that are trained on\n the iNaturalist dataset which is the most semantically close dataset we could find. We emphasize that\n this model was trained with access to uncorrupted images. Results are shown in 4. As shown, our\n method and DPS outperform this supervised baseline. We underline that this experiment is included\n for completeness and does not exclude the possibility that there are more performant supervised\n alternatives for random inpainting.\n                   Corruption Probability          Method       LPIPS       PSNR       NFE\n                                                     Ours        0.0304      33.27        1\n                                0.4                  DPS        0.0203      34.06       100\n                                                     MAE         0.0752      28.88        1\n                                                     Ours        0.0628      29.46        1\n                                0.6                  DPS        0.0518      30.03       100\n                                                     MAE         0.0995      25.89        1\n                                                     Ours        0.1245     25.37         1\n                                0.8                  DPS        0.1078       25.30      100\n                                                     MAE         0.1794      22.01        1\nTable 4: Comparison with the MAE [21], a state-of-the-art supervised method for solving the\n restoration task of random inpainting.\n                                                        18", "md": "In this section, we further compare our models (trained with randomly inpainted images) in the task\nof inpainting with noisy measurements. Concretely, we want to predict \\( x_0 \\), given measurements\n\\( y_t = A(x_0 + \\sigma y_t \\eta) \\), \\( \\eta \\sim N(0, I) \\). As in the rest of the paper, we assume that the mask matrix\nA is known. We can solve this problem with one model prediction using our trained models since\naccording to Eq. 4.1, we are learning:  \\( h(y, A, t) = E[x |Ax = y, A] \\).\n\nWe use the EDM [30] state-of-the-art model trained on AFHQ as our baseline (as we did in the main\npaper). To use this pre-trained model to solve the noisy random inpainting inverse problem, we need a\nreconstruction algorithm. We experiment again with DPS and DDRM which can both handle inverse\nproblems with noise in the measurements. We present our results in Table 3. As shown, our models\nsignificantly outperform the EDM models that use the DDRM reconstruction algorithm and perform\non par with the EDM models that use the DPS reconstruction algorithm.\n\n| Dataset | Corruption Probability | Measurement Noise (\\( \\sigma y_0 \\)) | Method | LPIPS | PSNR | NFE |\n|---------|-------------------------|-------------------------------------|--------|-------|------|-----|\n| AFHQ    |                         |                                     | Ours   | 0.0861| 29.46| 1   |\n|         |                         |                                     | DPS    | 0.0846| 29.83| 100 |\n|         | 0.4                     | 0.05                                |        | 0.2061| 24.47| 35  |\n|         |                         |                                     | DDRM   | 0.1739| 25.38| 99  |\n|         |                         |                                     |        | 0.1677| 25.58| 199 |\n|         |                         |                                     | Ours   | 0.1031| 27.40| 1   |\n|         |                         |                                     | DPS    | 0.0949| 27.92| 100 |\n|         | 0.6                     | 0.05                                |        | 0.4066| 18.73| 35  |\n|         |                         |                                     | DDRM   | 0.3626| 19.49| 99  |\n|         |                         |                                     |        | 0.3506| 19.70| 199 |\n|         |                         |                                     | Ours   | 0.1792| 23.21| 1   |\n|         |                         |                                     | DPS    | 0.1778| 23.01| 100 |\n|         | 0.8                     | 0.05                                |        | 0.5879| 13.65| 35  |\n|         |                         |                                     | DDRM   | 0.5802| 13.99| 99  |\n|         |                         |                                     |        | 0.5753| 14.09| 199 |\n\nTable 3: Comparison of our model (trained on corrupted data) with state-of-the-art diffusion models on CelebA\n(DDIM [50] model) and AFHQ (EDM [30] model) for solving the random inpainting inverse problem with\nnoise.\n\n### E.2 Comparison with Supervised Methods\n\nFor completeness, we include a comparison with Masked AutoEncoders [21], a state-of-the-art\nsupervised method for solving the random inpainting problem. The official repository of this paper\ndoes not include models trained on AFHQ. We compare with the available models that are trained on\nthe iNaturalist dataset which is the most semantically close dataset we could find. We emphasize that\nthis model was trained with access to uncorrupted images. Results are shown in Table 4. As shown, our\nmethod and DPS outperform this supervised baseline. We underline that this experiment is included\nfor completeness and does not exclude the possibility that there are more performant supervised\nalternatives for random inpainting.\n\n| Corruption Probability | Method | LPIPS | PSNR | NFE |\n|------------------------|--------|-------|------|-----|\n| 0.4                    | Ours   | 0.0304| 33.27| 1   |\n|                        | DPS    | 0.0203| 34.06| 100 |\n|                        | MAE    | 0.0752| 28.88| 1   |\n| 0.6                    | Ours   | 0.0628| 29.46| 1   |\n|                        | DPS    | 0.0518| 30.03| 100 |\n|                        | MAE    | 0.0995| 25.89| 1   |\n| 0.8                    | Ours   | 0.1245| 25.37| 1   |\n|                        | DPS    | 0.1078| 25.30| 100 |\n|                        | MAE    | 0.1794| 22.01| 1   |\n\nTable 4: Comparison with the MAE [21], a state-of-the-art supervised method for solving the\nrestoration task of random inpainting.", "images": [], "items": [{"type": "text", "value": "In this section, we further compare our models (trained with randomly inpainted images) in the task\nof inpainting with noisy measurements. Concretely, we want to predict \\( x_0 \\), given measurements\n\\( y_t = A(x_0 + \\sigma y_t \\eta) \\), \\( \\eta \\sim N(0, I) \\). As in the rest of the paper, we assume that the mask matrix\nA is known. We can solve this problem with one model prediction using our trained models since\naccording to Eq. 4.1, we are learning:  \\( h(y, A, t) = E[x |Ax = y, A] \\).\n\nWe use the EDM [30] state-of-the-art model trained on AFHQ as our baseline (as we did in the main\npaper). To use this pre-trained model to solve the noisy random inpainting inverse problem, we need a\nreconstruction algorithm. We experiment again with DPS and DDRM which can both handle inverse\nproblems with noise in the measurements. We present our results in Table 3. As shown, our models\nsignificantly outperform the EDM models that use the DDRM reconstruction algorithm and perform\non par with the EDM models that use the DPS reconstruction algorithm.", "md": "In this section, we further compare our models (trained with randomly inpainted images) in the task\nof inpainting with noisy measurements. Concretely, we want to predict \\( x_0 \\), given measurements\n\\( y_t = A(x_0 + \\sigma y_t \\eta) \\), \\( \\eta \\sim N(0, I) \\). As in the rest of the paper, we assume that the mask matrix\nA is known. We can solve this problem with one model prediction using our trained models since\naccording to Eq. 4.1, we are learning:  \\( h(y, A, t) = E[x |Ax = y, A] \\).\n\nWe use the EDM [30] state-of-the-art model trained on AFHQ as our baseline (as we did in the main\npaper). To use this pre-trained model to solve the noisy random inpainting inverse problem, we need a\nreconstruction algorithm. We experiment again with DPS and DDRM which can both handle inverse\nproblems with noise in the measurements. We present our results in Table 3. As shown, our models\nsignificantly outperform the EDM models that use the DDRM reconstruction algorithm and perform\non par with the EDM models that use the DPS reconstruction algorithm."}, {"type": "table", "rows": [["Dataset", "Corruption Probability", "Measurement Noise (\\( \\sigma y_0 \\))", "Method", "LPIPS", "PSNR", "NFE"], ["AFHQ", "", "", "Ours", "0.0861", "29.46", "1"], ["", "", "", "DPS", "0.0846", "29.83", "100"], ["", "0.4", "0.05", "", "0.2061", "24.47", "35"], ["", "", "", "DDRM", "0.1739", "25.38", "99"], ["", "", "", "", "0.1677", "25.58", "199"], ["", "", "", "Ours", "0.1031", "27.40", "1"], ["", "", "", "DPS", "0.0949", "27.92", "100"], ["", "0.6", "0.05", "", "0.4066", "18.73", "35"], ["", "", "", "DDRM", "0.3626", "19.49", "99"], ["", "", "", "", "0.3506", "19.70", "199"], ["", "", "", "Ours", "0.1792", "23.21", "1"], ["", "", "", "DPS", "0.1778", "23.01", "100"], ["", "0.8", "0.05", "", "0.5879", "13.65", "35"], ["", "", "", "DDRM", "0.5802", "13.99", "99"], ["", "", "", "", "0.5753", "14.09", "199"]], "md": "| Dataset | Corruption Probability | Measurement Noise (\\( \\sigma y_0 \\)) | Method | LPIPS | PSNR | NFE |\n|---------|-------------------------|-------------------------------------|--------|-------|------|-----|\n| AFHQ    |                         |                                     | Ours   | 0.0861| 29.46| 1   |\n|         |                         |                                     | DPS    | 0.0846| 29.83| 100 |\n|         | 0.4                     | 0.05                                |        | 0.2061| 24.47| 35  |\n|         |                         |                                     | DDRM   | 0.1739| 25.38| 99  |\n|         |                         |                                     |        | 0.1677| 25.58| 199 |\n|         |                         |                                     | Ours   | 0.1031| 27.40| 1   |\n|         |                         |                                     | DPS    | 0.0949| 27.92| 100 |\n|         | 0.6                     | 0.05                                |        | 0.4066| 18.73| 35  |\n|         |                         |                                     | DDRM   | 0.3626| 19.49| 99  |\n|         |                         |                                     |        | 0.3506| 19.70| 199 |\n|         |                         |                                     | Ours   | 0.1792| 23.21| 1   |\n|         |                         |                                     | DPS    | 0.1778| 23.01| 100 |\n|         | 0.8                     | 0.05                                |        | 0.5879| 13.65| 35  |\n|         |                         |                                     | DDRM   | 0.5802| 13.99| 99  |\n|         |                         |                                     |        | 0.5753| 14.09| 199 |", "isPerfectTable": true, "csv": "\"Dataset\",\"Corruption Probability\",\"Measurement Noise (\\( \\sigma y_0 \\))\",\"Method\",\"LPIPS\",\"PSNR\",\"NFE\"\n\"AFHQ\",\"\",\"\",\"Ours\",\"0.0861\",\"29.46\",\"1\"\n\"\",\"\",\"\",\"DPS\",\"0.0846\",\"29.83\",\"100\"\n\"\",\"0.4\",\"0.05\",\"\",\"0.2061\",\"24.47\",\"35\"\n\"\",\"\",\"\",\"DDRM\",\"0.1739\",\"25.38\",\"99\"\n\"\",\"\",\"\",\"\",\"0.1677\",\"25.58\",\"199\"\n\"\",\"\",\"\",\"Ours\",\"0.1031\",\"27.40\",\"1\"\n\"\",\"\",\"\",\"DPS\",\"0.0949\",\"27.92\",\"100\"\n\"\",\"0.6\",\"0.05\",\"\",\"0.4066\",\"18.73\",\"35\"\n\"\",\"\",\"\",\"DDRM\",\"0.3626\",\"19.49\",\"99\"\n\"\",\"\",\"\",\"\",\"0.3506\",\"19.70\",\"199\"\n\"\",\"\",\"\",\"Ours\",\"0.1792\",\"23.21\",\"1\"\n\"\",\"\",\"\",\"DPS\",\"0.1778\",\"23.01\",\"100\"\n\"\",\"0.8\",\"0.05\",\"\",\"0.5879\",\"13.65\",\"35\"\n\"\",\"\",\"\",\"DDRM\",\"0.5802\",\"13.99\",\"99\"\n\"\",\"\",\"\",\"\",\"0.5753\",\"14.09\",\"199\""}, {"type": "text", "value": "Table 3: Comparison of our model (trained on corrupted data) with state-of-the-art diffusion models on CelebA\n(DDIM [50] model) and AFHQ (EDM [30] model) for solving the random inpainting inverse problem with\nnoise.", "md": "Table 3: Comparison of our model (trained on corrupted data) with state-of-the-art diffusion models on CelebA\n(DDIM [50] model) and AFHQ (EDM [30] model) for solving the random inpainting inverse problem with\nnoise."}, {"type": "heading", "lvl": 3, "value": "E.2 Comparison with Supervised Methods", "md": "### E.2 Comparison with Supervised Methods"}, {"type": "text", "value": "For completeness, we include a comparison with Masked AutoEncoders [21], a state-of-the-art\nsupervised method for solving the random inpainting problem. The official repository of this paper\ndoes not include models trained on AFHQ. We compare with the available models that are trained on\nthe iNaturalist dataset which is the most semantically close dataset we could find. We emphasize that\nthis model was trained with access to uncorrupted images. Results are shown in Table 4. As shown, our\nmethod and DPS outperform this supervised baseline. We underline that this experiment is included\nfor completeness and does not exclude the possibility that there are more performant supervised\nalternatives for random inpainting.", "md": "For completeness, we include a comparison with Masked AutoEncoders [21], a state-of-the-art\nsupervised method for solving the random inpainting problem. The official repository of this paper\ndoes not include models trained on AFHQ. We compare with the available models that are trained on\nthe iNaturalist dataset which is the most semantically close dataset we could find. We emphasize that\nthis model was trained with access to uncorrupted images. Results are shown in Table 4. As shown, our\nmethod and DPS outperform this supervised baseline. We underline that this experiment is included\nfor completeness and does not exclude the possibility that there are more performant supervised\nalternatives for random inpainting."}, {"type": "table", "rows": [["Corruption Probability", "Method", "LPIPS", "PSNR", "NFE"], ["0.4", "Ours", "0.0304", "33.27", "1"], ["", "DPS", "0.0203", "34.06", "100"], ["", "MAE", "0.0752", "28.88", "1"], ["0.6", "Ours", "0.0628", "29.46", "1"], ["", "DPS", "0.0518", "30.03", "100"], ["", "MAE", "0.0995", "25.89", "1"], ["0.8", "Ours", "0.1245", "25.37", "1"], ["", "DPS", "0.1078", "25.30", "100"], ["", "MAE", "0.1794", "22.01", "1"]], "md": "| Corruption Probability | Method | LPIPS | PSNR | NFE |\n|------------------------|--------|-------|------|-----|\n| 0.4                    | Ours   | 0.0304| 33.27| 1   |\n|                        | DPS    | 0.0203| 34.06| 100 |\n|                        | MAE    | 0.0752| 28.88| 1   |\n| 0.6                    | Ours   | 0.0628| 29.46| 1   |\n|                        | DPS    | 0.0518| 30.03| 100 |\n|                        | MAE    | 0.0995| 25.89| 1   |\n| 0.8                    | Ours   | 0.1245| 25.37| 1   |\n|                        | DPS    | 0.1078| 25.30| 100 |\n|                        | MAE    | 0.1794| 22.01| 1   |", "isPerfectTable": true, "csv": "\"Corruption Probability\",\"Method\",\"LPIPS\",\"PSNR\",\"NFE\"\n\"0.4\",\"Ours\",\"0.0304\",\"33.27\",\"1\"\n\"\",\"DPS\",\"0.0203\",\"34.06\",\"100\"\n\"\",\"MAE\",\"0.0752\",\"28.88\",\"1\"\n\"0.6\",\"Ours\",\"0.0628\",\"29.46\",\"1\"\n\"\",\"DPS\",\"0.0518\",\"30.03\",\"100\"\n\"\",\"MAE\",\"0.0995\",\"25.89\",\"1\"\n\"0.8\",\"Ours\",\"0.1245\",\"25.37\",\"1\"\n\"\",\"DPS\",\"0.1078\",\"25.30\",\"100\"\n\"\",\"MAE\",\"0.1794\",\"22.01\",\"1\""}, {"type": "text", "value": "Table 4: Comparison with the MAE [21], a state-of-the-art supervised method for solving the\nrestoration task of random inpainting.", "md": "Table 4: Comparison with the MAE [21], a state-of-the-art supervised method for solving the\nrestoration task of random inpainting."}]}, {"page": 19, "text": " E.3    Sampler Ablation\n By Lemma A.3, if it is possible to learn        p0 (x 0) using corrupted samples then it is also possible to use\n our learned model to sample from           p0 (x 0). Even though such an algorithm exists, we do not know\nwhich one it is.\n In the paper, we proposed to simple ideas for sampling, the Fixed Mask Sampler and the Reconstruc-\n tion Guidance Sampler. The Fixed Mask Sampler fixes a mask throughout the sampling process.\n Hence, sampling with this algorithm is equivalent to first sampling some pixels from the marginals\n of p 0(x 0)  and then completing the rest of the pixels with the best reconstruction (the conditional\n expectation) in the last step. This simple sampler performs remarkably well and we use it throughout\n the main paper.\nTo demonstrate that we can further improve the sampling performance, we proposed the Reconstruc-\n tion Guidance sampler that takes into account all the pixels by forcing predictions of the model with\n different masks to be consistent. In Table 5 we ablate the performance of this alternative sampler. For\n the reconstruction guidance sampler, we select each time four masks at random and we add an extra\n update term to the Fixed Mask Sampler that ensures that the predictions of the Fixed Mask Sampler\n are not very different compared to the predictions with the other four masks (that have different\n context regarding the current iteratex        t ). We set the guidance parameter         w t to the value   5e  \u2212  4. As\n shown, this sampler improves the performance, especially for the low corruption probabilities where\n the extra masks give significant information about the current state to the predictions given only\n one fixed mask. However, the benefits of this sampler are vanishing for higher corruption. Given\n that the two samples perform on par and that the Reconstruction Guidance Sampler is much more\n computationally intensive (we need one extra prediction per step for each extra mask), we choose to\n use the Fixed Mask Sampler for all the experiments in the paper.\n                Sampler Type                Corruption Probability              FID       Inception Score\n                                                          0.2                  11.70              7.97\n                                                          0.4                  18.85              7.45\n                  Fixed Mask                              0.6                  28.88              6.88\n                                                          0.8                  46.27             6.14\n                                                          0.2                  11.59             8.01\n                                                          0.4                  18.52             7.51\n          Reconstruction Guidance                         0.6                  28.90             6.91\n                                                          0.8                  46.31              6.13\n Table 5: Comparison between the Fixed Mask sampler and the Reconstruction Guidance Sampler.\n E.4    Additional Figures\n Figure 7 shows reconstructions of AFHQ corrupted images with the EDM AFHQ model trained on\n clean data (columns 3, 4) and our model trained on corrupted data (column 5). The restoration task\n is random inpainting at probability         p = 0.8. The last two rows also have measurement noise with\n \u03c3y0  = 0.05.\n In Figure 8, we repeat the experiment of Figure 6 of the main paper but for models trained on the full\n CelebA dataset and at different levels of corruption. As shown, increasing the corruption level leads\n to a clear shift of the distribution to the left, indicating less memorization. This comes at the cost of\n decreased performance, as reported in Table 4.\n In the remaining pages, we include uncurated unconditional generations of our models trained at\n different corruption levelsp. Results are shown in Figures 9,10,11.\n                                                            19", "md": "# Sampler Ablation\n\n## E.3 Sampler Ablation\n\nBy Lemma A.3, if it is possible to learn $$p_0(x_0)$$ using corrupted samples then it is also possible to use our learned model to sample from $$p_0(x_0)$$. Even though such an algorithm exists, we do not know which one it is.\n\nIn the paper, we proposed two simple ideas for sampling, the Fixed Mask Sampler and the Reconstruction Guidance Sampler. The Fixed Mask Sampler fixes a mask throughout the sampling process. Hence, sampling with this algorithm is equivalent to first sampling some pixels from the marginals of $$p_0(x_0)$$ and then completing the rest of the pixels with the best reconstruction (the conditional expectation) in the last step. This simple sampler performs remarkably well and we use it throughout the main paper.\n\nTo demonstrate that we can further improve the sampling performance, we proposed the Reconstruction Guidance sampler that takes into account all the pixels by forcing predictions of the model with different masks to be consistent. In Table 5 we ablate the performance of this alternative sampler. For the reconstruction guidance sampler, we select each time four masks at random and we add an extra update term to the Fixed Mask Sampler that ensures that the predictions of the Fixed Mask Sampler are not very different compared to the predictions with the other four masks (that have different context regarding the current iteration $$t$$). We set the guidance parameter $$w_t$$ to the value $$5e^{-4}$$. As shown, this sampler improves the performance, especially for the low corruption probabilities where the extra masks give significant information about the current state to the predictions given only one fixed mask. However, the benefits of this sampler are vanishing for higher corruption. Given that the two samples perform on par and that the Reconstruction Guidance Sampler is much more computationally intensive (we need one extra prediction per step for each extra mask), we choose to use the Fixed Mask Sampler for all the experiments in the paper.\n\n|Sampler Type|Corruption Probability|FID|Inception Score|\n|---|---|---|---|\n|Fixed Mask|0.2|11.70|7.97|\n|Fixed Mask|0.4|18.85|7.45|\n|Fixed Mask|0.6|28.88|6.88|\n|Fixed Mask|0.8|46.27|6.14|\n|Reconstruction Guidance|0.2|11.59|8.01|\n|Reconstruction Guidance|0.4|18.52|7.51|\n|Reconstruction Guidance|0.6|28.90|6.91|\n|Reconstruction Guidance|0.8|46.31|6.13|\n\nTable 5: Comparison between the Fixed Mask sampler and the Reconstruction Guidance Sampler.\n\n## E.4 Additional Figures\n\nFigure 7 shows reconstructions of AFHQ corrupted images with the EDM AFHQ model trained on clean data (columns 3, 4) and our model trained on corrupted data (column 5). The restoration task is random inpainting at probability $$p = 0.8$$. The last two rows also have measurement noise with $$\\sigma_{y0} = 0.05$$.\n\nIn Figure 8, we repeat the experiment of Figure 6 of the main paper but for models trained on the full CelebA dataset and at different levels of corruption. As shown, increasing the corruption level leads to a clear shift of the distribution to the left, indicating less memorization. This comes at the cost of decreased performance, as reported in Table 4.\n\nIn the remaining pages, we include uncurated unconditional generations of our models trained at different corruption levels. Results are shown in Figures 9, 10, 11.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Sampler Ablation", "md": "# Sampler Ablation"}, {"type": "heading", "lvl": 2, "value": "E.3 Sampler Ablation", "md": "## E.3 Sampler Ablation"}, {"type": "text", "value": "By Lemma A.3, if it is possible to learn $$p_0(x_0)$$ using corrupted samples then it is also possible to use our learned model to sample from $$p_0(x_0)$$. Even though such an algorithm exists, we do not know which one it is.\n\nIn the paper, we proposed two simple ideas for sampling, the Fixed Mask Sampler and the Reconstruction Guidance Sampler. The Fixed Mask Sampler fixes a mask throughout the sampling process. Hence, sampling with this algorithm is equivalent to first sampling some pixels from the marginals of $$p_0(x_0)$$ and then completing the rest of the pixels with the best reconstruction (the conditional expectation) in the last step. This simple sampler performs remarkably well and we use it throughout the main paper.\n\nTo demonstrate that we can further improve the sampling performance, we proposed the Reconstruction Guidance sampler that takes into account all the pixels by forcing predictions of the model with different masks to be consistent. In Table 5 we ablate the performance of this alternative sampler. For the reconstruction guidance sampler, we select each time four masks at random and we add an extra update term to the Fixed Mask Sampler that ensures that the predictions of the Fixed Mask Sampler are not very different compared to the predictions with the other four masks (that have different context regarding the current iteration $$t$$). We set the guidance parameter $$w_t$$ to the value $$5e^{-4}$$. As shown, this sampler improves the performance, especially for the low corruption probabilities where the extra masks give significant information about the current state to the predictions given only one fixed mask. However, the benefits of this sampler are vanishing for higher corruption. Given that the two samples perform on par and that the Reconstruction Guidance Sampler is much more computationally intensive (we need one extra prediction per step for each extra mask), we choose to use the Fixed Mask Sampler for all the experiments in the paper.", "md": "By Lemma A.3, if it is possible to learn $$p_0(x_0)$$ using corrupted samples then it is also possible to use our learned model to sample from $$p_0(x_0)$$. Even though such an algorithm exists, we do not know which one it is.\n\nIn the paper, we proposed two simple ideas for sampling, the Fixed Mask Sampler and the Reconstruction Guidance Sampler. The Fixed Mask Sampler fixes a mask throughout the sampling process. Hence, sampling with this algorithm is equivalent to first sampling some pixels from the marginals of $$p_0(x_0)$$ and then completing the rest of the pixels with the best reconstruction (the conditional expectation) in the last step. This simple sampler performs remarkably well and we use it throughout the main paper.\n\nTo demonstrate that we can further improve the sampling performance, we proposed the Reconstruction Guidance sampler that takes into account all the pixels by forcing predictions of the model with different masks to be consistent. In Table 5 we ablate the performance of this alternative sampler. For the reconstruction guidance sampler, we select each time four masks at random and we add an extra update term to the Fixed Mask Sampler that ensures that the predictions of the Fixed Mask Sampler are not very different compared to the predictions with the other four masks (that have different context regarding the current iteration $$t$$). We set the guidance parameter $$w_t$$ to the value $$5e^{-4}$$. As shown, this sampler improves the performance, especially for the low corruption probabilities where the extra masks give significant information about the current state to the predictions given only one fixed mask. However, the benefits of this sampler are vanishing for higher corruption. Given that the two samples perform on par and that the Reconstruction Guidance Sampler is much more computationally intensive (we need one extra prediction per step for each extra mask), we choose to use the Fixed Mask Sampler for all the experiments in the paper."}, {"type": "table", "rows": [["Sampler Type", "Corruption Probability", "FID", "Inception Score"], ["Fixed Mask", "0.2", "11.70", "7.97"], ["Fixed Mask", "0.4", "18.85", "7.45"], ["Fixed Mask", "0.6", "28.88", "6.88"], ["Fixed Mask", "0.8", "46.27", "6.14"], ["Reconstruction Guidance", "0.2", "11.59", "8.01"], ["Reconstruction Guidance", "0.4", "18.52", "7.51"], ["Reconstruction Guidance", "0.6", "28.90", "6.91"], ["Reconstruction Guidance", "0.8", "46.31", "6.13"]], "md": "|Sampler Type|Corruption Probability|FID|Inception Score|\n|---|---|---|---|\n|Fixed Mask|0.2|11.70|7.97|\n|Fixed Mask|0.4|18.85|7.45|\n|Fixed Mask|0.6|28.88|6.88|\n|Fixed Mask|0.8|46.27|6.14|\n|Reconstruction Guidance|0.2|11.59|8.01|\n|Reconstruction Guidance|0.4|18.52|7.51|\n|Reconstruction Guidance|0.6|28.90|6.91|\n|Reconstruction Guidance|0.8|46.31|6.13|", "isPerfectTable": true, "csv": "\"Sampler Type\",\"Corruption Probability\",\"FID\",\"Inception Score\"\n\"Fixed Mask\",\"0.2\",\"11.70\",\"7.97\"\n\"Fixed Mask\",\"0.4\",\"18.85\",\"7.45\"\n\"Fixed Mask\",\"0.6\",\"28.88\",\"6.88\"\n\"Fixed Mask\",\"0.8\",\"46.27\",\"6.14\"\n\"Reconstruction Guidance\",\"0.2\",\"11.59\",\"8.01\"\n\"Reconstruction Guidance\",\"0.4\",\"18.52\",\"7.51\"\n\"Reconstruction Guidance\",\"0.6\",\"28.90\",\"6.91\"\n\"Reconstruction Guidance\",\"0.8\",\"46.31\",\"6.13\""}, {"type": "text", "value": "Table 5: Comparison between the Fixed Mask sampler and the Reconstruction Guidance Sampler.", "md": "Table 5: Comparison between the Fixed Mask sampler and the Reconstruction Guidance Sampler."}, {"type": "heading", "lvl": 2, "value": "E.4 Additional Figures", "md": "## E.4 Additional Figures"}, {"type": "text", "value": "Figure 7 shows reconstructions of AFHQ corrupted images with the EDM AFHQ model trained on clean data (columns 3, 4) and our model trained on corrupted data (column 5). The restoration task is random inpainting at probability $$p = 0.8$$. The last two rows also have measurement noise with $$\\sigma_{y0} = 0.05$$.\n\nIn Figure 8, we repeat the experiment of Figure 6 of the main paper but for models trained on the full CelebA dataset and at different levels of corruption. As shown, increasing the corruption level leads to a clear shift of the distribution to the left, indicating less memorization. This comes at the cost of decreased performance, as reported in Table 4.\n\nIn the remaining pages, we include uncurated unconditional generations of our models trained at different corruption levels. Results are shown in Figures 9, 10, 11.", "md": "Figure 7 shows reconstructions of AFHQ corrupted images with the EDM AFHQ model trained on clean data (columns 3, 4) and our model trained on corrupted data (column 5). The restoration task is random inpainting at probability $$p = 0.8$$. The last two rows also have measurement noise with $$\\sigma_{y0} = 0.05$$.\n\nIn Figure 8, we repeat the experiment of Figure 6 of the main paper but for models trained on the full CelebA dataset and at different levels of corruption. As shown, increasing the corruption level leads to a clear shift of the distribution to the left, indicating less memorization. This comes at the cost of decreased performance, as reported in Table 4.\n\nIn the remaining pages, we include uncurated unconditional generations of our models trained at different corruption levels. Results are shown in Figures 9, 10, 11."}]}, {"page": 20, "text": "             Input            Ground Truth             DDRM [34]                DPS [11]                 Ours\nFigure 7: Reconstructions of AFHQ corrupted images with the EDM AFHQ model trained on clean\ndata (columns 3, 4) and our model trained on corrupted data (column 5). The restoration task is\nrandom inpainting at probability           p  = 0.6. The last two rows also have measurement noise with\n\u03c3 y0  = 0.05.        Distribution of Similarity Values to the nearest training sample\n                           Corruption probability = 0.0\n                           Corruption probability0.1\n                           Corruption probability0.4\n                 400       Corruption probability = 0.6\n              I            Corruption probability0.8\n             1300\n             5   200\n             1   100\n                   0.60       0.65       0.70       0.75       0.80       0.85       0.90       0.95       1.00\n                                                        Similarity Value\nFigure 8: Distribution of similarity values to the nearest neighbor in the dataset for finetuned IF\nmodels on the full CelebA dataset at different levels of corruption. Please note that similarity values\nabove   0.95  roughly correspond to the same person, while similarities below0.75                  correspond to almost\nrandom faces. As shown, increasing the corruption level leads to a clear shift of the distribution to\nthe left, indicating less memorization.\n                                                             20", "md": "# Document\n\n## Input Ground Truth DDRM [34] DPS [11] Ours\n\nFigure 7: Reconstructions of AFHQ corrupted images with the EDM AFHQ model trained on clean\ndata (columns 3, 4) and our model trained on corrupted data (column 5). The restoration task is\nrandom inpainting at probability $$p = 0.6$$. The last two rows also have measurement noise with\n$$\\sigma_{y0} = 0.05$$. Distribution of Similarity Values to the nearest training sample\n\n| |Corruption probability = 0.0|Corruption probability = 0.1|Corruption probability = 0.4|Corruption probability = 0.6|Corruption probability = 0.8|\n|---|---|---|---|---|---|\n|400| | | | | |\n|1300| | | | | |\n|5|200| | | | |\n|1|100| | | | |\n\n$$0.60 \\quad 0.65 \\quad 0.70 \\quad 0.75 \\quad 0.80 \\quad 0.85 \\quad 0.90 \\quad 0.95 \\quad 1.00$$ Similarity Value\n\nFigure 8: Distribution of similarity values to the nearest neighbor in the dataset for finetuned IF\nmodels on the full CelebA dataset at different levels of corruption. Please note that similarity values\nabove $$0.95$$ roughly correspond to the same person, while similarities below $$0.75$$ correspond to almost\nrandom faces. As shown, increasing the corruption level leads to a clear shift of the distribution to\nthe left, indicating less memorization.\n\n20", "images": [{"name": "img_p19_1", "height": 64, "width": 64}, {"name": "img_p19_2", "height": 64, "width": 64}, {"name": "img_p19_3", "height": 64, "width": 64}, {"name": "img_p19_4", "height": 64, "width": 64}, {"name": "img_p19_5", "height": 64, "width": 64}, {"name": "img_p19_6", "height": 64, "width": 64}, {"name": "img_p19_7", "height": 64, "width": 64}, {"name": "img_p19_8", "height": 64, "width": 64}, {"name": "img_p19_9", "height": 64, "width": 64}, {"name": "img_p19_10", "height": 64, "width": 64}, {"name": "img_p19_11", "height": 64, "width": 64}, {"name": "img_p19_12", "height": 64, "width": 64}, {"name": "img_p19_13", "height": 64, "width": 64}, {"name": "img_p19_14", "height": 64, "width": 64}, {"name": "img_p19_15", "height": 64, "width": 64}, {"name": "img_p19_16", "height": 64, "width": 64}, {"name": "img_p19_17", "height": 64, "width": 64}, {"name": "img_p19_18", "height": 64, "width": 64}, {"name": "img_p19_19", "height": 64, "width": 64}, {"name": "img_p19_20", "height": 64, "width": 64}, {"name": "img_p19_21", "height": 609, "width": 951}], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 2, "value": "Input Ground Truth DDRM [34] DPS [11] Ours", "md": "## Input Ground Truth DDRM [34] DPS [11] Ours"}, {"type": "text", "value": "Figure 7: Reconstructions of AFHQ corrupted images with the EDM AFHQ model trained on clean\ndata (columns 3, 4) and our model trained on corrupted data (column 5). The restoration task is\nrandom inpainting at probability $$p = 0.6$$. The last two rows also have measurement noise with\n$$\\sigma_{y0} = 0.05$$. Distribution of Similarity Values to the nearest training sample", "md": "Figure 7: Reconstructions of AFHQ corrupted images with the EDM AFHQ model trained on clean\ndata (columns 3, 4) and our model trained on corrupted data (column 5). The restoration task is\nrandom inpainting at probability $$p = 0.6$$. The last two rows also have measurement noise with\n$$\\sigma_{y0} = 0.05$$. Distribution of Similarity Values to the nearest training sample"}, {"type": "table", "rows": [["", "Corruption probability = 0.0", "Corruption probability = 0.1", "Corruption probability = 0.4", "Corruption probability = 0.6", "Corruption probability = 0.8"], ["400", "", "", "", "", ""], ["1300", "", "", "", "", ""], ["5", "200", "", "", "", ""], ["1", "100", "", "", "", ""]], "md": "| |Corruption probability = 0.0|Corruption probability = 0.1|Corruption probability = 0.4|Corruption probability = 0.6|Corruption probability = 0.8|\n|---|---|---|---|---|---|\n|400| | | | | |\n|1300| | | | | |\n|5|200| | | | |\n|1|100| | | | |", "isPerfectTable": true, "csv": "\"\",\"Corruption probability = 0.0\",\"Corruption probability = 0.1\",\"Corruption probability = 0.4\",\"Corruption probability = 0.6\",\"Corruption probability = 0.8\"\n\"400\",\"\",\"\",\"\",\"\",\"\"\n\"1300\",\"\",\"\",\"\",\"\",\"\"\n\"5\",\"200\",\"\",\"\",\"\",\"\"\n\"1\",\"100\",\"\",\"\",\"\",\"\""}, {"type": "text", "value": "$$0.60 \\quad 0.65 \\quad 0.70 \\quad 0.75 \\quad 0.80 \\quad 0.85 \\quad 0.90 \\quad 0.95 \\quad 1.00$$ Similarity Value\n\nFigure 8: Distribution of similarity values to the nearest neighbor in the dataset for finetuned IF\nmodels on the full CelebA dataset at different levels of corruption. Please note that similarity values\nabove $$0.95$$ roughly correspond to the same person, while similarities below $$0.75$$ correspond to almost\nrandom faces. As shown, increasing the corruption level leads to a clear shift of the distribution to\nthe left, indicating less memorization.\n\n20", "md": "$$0.60 \\quad 0.65 \\quad 0.70 \\quad 0.75 \\quad 0.80 \\quad 0.85 \\quad 0.90 \\quad 0.95 \\quad 1.00$$ Similarity Value\n\nFigure 8: Distribution of similarity values to the nearest neighbor in the dataset for finetuned IF\nmodels on the full CelebA dataset at different levels of corruption. Please note that similarity values\nabove $$0.95$$ roughly correspond to the same person, while similarities below $$0.75$$ correspond to almost\nrandom faces. As shown, increasing the corruption level leads to a clear shift of the distribution to\nthe left, indicating less memorization.\n\n20"}]}, {"page": 21, "text": "                CelebA dataset,      p = 0.6, \u03b4   = 0.1          Uncurated samples from our model\n                CelebA dataset,      p = 0.8, \u03b4   = 0.1          Uncurated samples from our model\n                CelebA dataset,      p = 0.9, \u03b4   = 0.3          Uncurated samples from our model\nFigure 9: Left column: CelebA-HQ training dataset with random inpainting at different levels of\ncorruption   p (the survival probability is      (1 \u2212   p) \u00b7(1  \u2212   \u03b4)). Right column: Unconditional generations\nfrom our models trained with the corresponding parameters. As shown, the generations become\nslightly worse as we increase the level of corruption, but we can reasonably well learn the distribution\neven with    93%   pixels missing (on average) from each training image.\n                                                             21", "md": "CelebA dataset, $$p = 0.6, \\delta = 0.1$$ Uncurated samples from our model\n\nCelebA dataset, $$p = 0.8, \\delta = 0.1$$ Uncurated samples from our model\n\nCelebA dataset, $$p = 0.9, \\delta = 0.3$$ Uncurated samples from our model\n\nFigure 9: Left column: CelebA-HQ training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 93% pixels missing (on average) from each training image.\n\n21", "images": [{"name": "img_p20_1", "height": 476, "width": 476}, {"name": "img_p20_2", "height": 476, "width": 476}, {"name": "img_p20_3", "height": 476, "width": 476}, {"name": "img_p20_4", "height": 476, "width": 476}, {"name": "img_p20_5", "height": 476, "width": 476}, {"name": "img_p20_6", "height": 476, "width": 476}], "items": [{"type": "text", "value": "CelebA dataset, $$p = 0.6, \\delta = 0.1$$ Uncurated samples from our model\n\nCelebA dataset, $$p = 0.8, \\delta = 0.1$$ Uncurated samples from our model\n\nCelebA dataset, $$p = 0.9, \\delta = 0.3$$ Uncurated samples from our model\n\nFigure 9: Left column: CelebA-HQ training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 93% pixels missing (on average) from each training image.\n\n21", "md": "CelebA dataset, $$p = 0.6, \\delta = 0.1$$ Uncurated samples from our model\n\nCelebA dataset, $$p = 0.8, \\delta = 0.1$$ Uncurated samples from our model\n\nCelebA dataset, $$p = 0.9, \\delta = 0.3$$ Uncurated samples from our model\n\nFigure 9: Left column: CelebA-HQ training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 93% pixels missing (on average) from each training image.\n\n21"}]}, {"page": 22, "text": "AFHQ dataset,  p = 0.4, \u03b4  = 0.1      Uncurated samples from our model\nAFHQ dataset,  p = 0.6, \u03b4  = 0.1      Uncurated samples from our model\nAFHQ dataset,  p = 0.8, \u03b4  = 0.1      Uncurated samples from our model\n                                  22", "md": "AFHQ dataset, $$p = 0.4, \\delta = 0.1$$ Uncurated samples from our model\n\nAFHQ dataset, $$p = 0.6, \\delta = 0.1$$ Uncurated samples from our model\n\nAFHQ dataset, $$p = 0.8, \\delta = 0.1$$ Uncurated samples from our model", "images": [{"name": "img_p21_1", "height": 476, "width": 476}, {"name": "img_p21_2", "height": 476, "width": 476}, {"name": "img_p21_3", "height": 476, "width": 476}, {"name": "img_p21_4", "height": 476, "width": 476}, {"name": "img_p21_5", "height": 476, "width": 476}, {"name": "img_p21_6", "height": 476, "width": 476}], "items": [{"type": "text", "value": "AFHQ dataset, $$p = 0.4, \\delta = 0.1$$ Uncurated samples from our model\n\nAFHQ dataset, $$p = 0.6, \\delta = 0.1$$ Uncurated samples from our model\n\nAFHQ dataset, $$p = 0.8, \\delta = 0.1$$ Uncurated samples from our model", "md": "AFHQ dataset, $$p = 0.4, \\delta = 0.1$$ Uncurated samples from our model\n\nAFHQ dataset, $$p = 0.6, \\delta = 0.1$$ Uncurated samples from our model\n\nAFHQ dataset, $$p = 0.8, \\delta = 0.1$$ Uncurated samples from our model"}]}, {"page": 23, "text": "                 AFHQ dataset,       p = 0.9, \u03b4   = 0.1           Uncurated samples from our model\nFigure 10: Left column: AFHQ training dataset with random inpainting at different levels of\ncorruption    p (the survival probability is      (1 \u2212   p) \u00b7(1  \u2212   \u03b4)). Right column: Unconditional generations\nfrom our models trained with the corresponding parameters. As shown, the generations become\nslightly worse as we increase the level of corruption, but we can reasonably well learn the distribution\neven with    91%   pixels missing (on average) from each training image.\n                                                              23", "md": "AFHQ dataset, $$p = 0.9, \\delta = 0.1$$ Uncurated samples from our model\n\nFigure 10: Left column: AFHQ training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 91% pixels missing (on average) from each training image.\n\n23", "images": [{"name": "img_p22_1", "height": 476, "width": 476}, {"name": "img_p22_2", "height": 476, "width": 476}], "items": [{"type": "text", "value": "AFHQ dataset, $$p = 0.9, \\delta = 0.1$$ Uncurated samples from our model\n\nFigure 10: Left column: AFHQ training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 91% pixels missing (on average) from each training image.\n\n23", "md": "AFHQ dataset, $$p = 0.9, \\delta = 0.1$$ Uncurated samples from our model\n\nFigure 10: Left column: AFHQ training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 91% pixels missing (on average) from each training image.\n\n23"}]}, {"page": 24, "text": "                           CIFAR-10 training dataset,           Uncurated samples from our\n                           p  = 0.2, \u03b4   = 0.1                  model\n                           CIFAR-10 training dataset,           Uncurated samples from our\n                           p  = 0.4, \u03b4   = 0.1                  model\n                           CIFAR-10 training dataset,           Uncurated samples from our\n                           p  = 0.6, \u03b4   = 0.1                  model\n                           CIFAR-10 training dataset,           Uncurated samples from our\n                           p  = 0.8, \u03b4   = 0.1                  model\nFigure 11: Left column: CIFAR-10 training dataset with random inpainting at different levels of\ncorruption    p (the survival probability is      (1  \u2212  p)  \u00b7(1  \u2212  \u03b4)). Right column: Unconditional generations\nfrom our models trained with the corresponding parameters. As shown, the generations become\nslightly worse as we increase the level of corruption, but we can reasonably well learn the distribution\neven with high corruption.                                    24", "md": "# CIFAR-10 Training Dataset\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.2, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.4, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.6, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.8, \\delta = 0.1$$\n\nFigure 11: Left column: CIFAR-10 training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with high corruption.\n\n24", "images": [{"name": "img_p23_1", "height": 333, "width": 333}, {"name": "img_p23_2", "height": 333, "width": 333}, {"name": "img_p23_3", "height": 333, "width": 333}, {"name": "img_p23_4", "height": 333, "width": 333}, {"name": "img_p23_5", "height": 333, "width": 333}, {"name": "img_p23_6", "height": 333, "width": 333}, {"name": "img_p23_7", "height": 333, "width": 333}, {"name": "img_p23_8", "height": 333, "width": 333}], "items": [{"type": "heading", "lvl": 1, "value": "CIFAR-10 Training Dataset", "md": "# CIFAR-10 Training Dataset"}, {"type": "text", "value": "CIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.2, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.4, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.6, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.8, \\delta = 0.1$$\n\nFigure 11: Left column: CIFAR-10 training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with high corruption.\n\n24", "md": "CIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.2, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.4, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.6, \\delta = 0.1$$\n\nCIFAR-10 training dataset, Uncurated samples from our\n\n$$p = 0.8, \\delta = 0.1$$\n\nFigure 11: Left column: CIFAR-10 training dataset with random inpainting at different levels of corruption $$p$$ (the survival probability is $$(1 - p) \\cdot (1 - \\delta)$$). Right column: Unconditional generations from our models trained with the corresponding parameters. As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with high corruption.\n\n24"}]}], "job_id": "8b8f9fab-11bd-4759-ae99-a15873980199", "file_path": "./corpus/2305.19256.pdf"}