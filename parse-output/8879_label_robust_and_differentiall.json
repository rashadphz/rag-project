{"pages": [{"page": 1, "text": "       Label Robust and Differentially Private Linear\n Regression: Computational and Statistical Efficiency\n                              Xiyang Liu                                       Prateek Jain\n       Paul Allen School of Computer Science & Engineering                   Google Research\n                      University of Washington                            prajain@google.com\n                   xiyangl@cs.washington.edu\n            Weihao Kong                                         Sewoong Oh\n           Google Research               Paul Allen School of Computer Science & Engineering\n     weihaokong@google.com                   University of Washington, and Google Research\n                                                     sewoong@cs.washington.edu\n                                           Arun Sai Suggala\n                                            Google Research\n                                         arunss@google.com\n                                               Abstract\n          We study the canonical problem of linear regression under (\u03b5, \u03b4)-differential privacy\n          when the datapoints are sampled i.i.d. from a distribution and a fraction of response\n          variables are adversarially corrupted. We provide the first provably efficient \u2013 both\n          computationally and statistically \u2013 method for this problem, assuming standard\n          assumptions on the data distribution. Our algorithm is a variant of the popular\n          differentially private stochastic gradient descent (DP-SGD) algorithm with two\n          key innovations: a full-batch gradient descent to improve sample complexity and\n          a novel adaptive clipping to guarantee robustness. Our method requires only\n          linear time in input size, and still matches the information theoretical optimal\n          sample complexity up to a data distribution dependent condition number factor.\n          Interestingly, the same algorithm, when applied to a setting where there is no\n          adversarial corruption, still improves upon the existing state-of-the-art and achieves\n          a near optimal sample complexity.\n1    Introduction\nDifferential Privacy (DP) [33] is a standard notion of privacy widely adopted by both industry\nand government [76, 35, 36, 2]. With widespread usage of ML and statistical techniques, DP\nbecomes even more critical to ensure private information of participating individuals is not revealed\nin any form via the learned model. An statistical estimator is said to be (\u03b5, \u03b4)-differentially private\nif presence/absence of an individual\u2019s data point in the dataset does not significantly change the\nestimated output. Smaller \u03b5 > 0 and \u03b4 \u2208     [0, 1] imply stronger privacy guarantees.\nWhile privacy preserving statistical estimators have been studied extensively in recent past, several\ncritical questions remain open (see App. A for a survey). Consider the canonical statistical task\nof linear regression with n i.i.d. samples, {(xi \u2208     Rd, yi \u2208   R)}ni=1, drawn from xi \u223c      N(0, \u03a3),\nyi = x\u22a4 i w\u2217 + zi, zi \u223c  N(0, \u03c32) and E[xizi] = 0 for some true parameter w\u2217         \u2208  Rd. The error is\nmeasured in (1/\u03c3)\u2225   w\u02c6\u2212   w\u2217\u2225\u03a3 := (1/\u03c3)\u2225\u03a31/2( \u02c6   w \u2212  w\u2217)\u2225, which correctly accounts for the signal-\nto-noise ratio in each direction; in the direction of large eigenvalue of \u03a3, we have larger signal in xi\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).", "md": "# Document\n\n## Label Robust and Differentially Private Linear Regression: Computational and Statistical Efficiency\n\nXiyang Liu - Paul Allen School of Computer Science & Engineering, University of Washington - xiyangl@cs.washington.edu\n\nPrateek Jain - Google Research - prajain@google.com\n\nWeihao Kong - Google Research - weihaokong@google.com\n\nSewoong Oh - Paul Allen School of Computer Science & Engineering, University of Washington, and Google Research - sewoong@cs.washington.edu\n\nArun Sai Suggala - Google Research - arunss@google.com\n\n### Abstract\n\nWe study the canonical problem of linear regression under (\u03b5, \u03b4)-differential privacy when the datapoints are sampled i.i.d. from a distribution and a fraction of response variables are adversarially corrupted. We provide the first provably efficient \u2013 both computationally and statistically \u2013 method for this problem, assuming standard assumptions on the data distribution. Our algorithm is a variant of the popular differentially private stochastic gradient descent (DP-SGD) algorithm with two key innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness. Our method requires only linear time in input size, and still matches the information theoretical optimal sample complexity up to a data distribution dependent condition number factor. Interestingly, the same algorithm, when applied to a setting where there is no adversarial corruption, still improves upon the existing state-of-the-art and achieves a near optimal sample complexity.\n\n### Introduction\n\nDifferential Privacy (DP) [33] is a standard notion of privacy widely adopted by both industry and government [76, 35, 36, 2]. With widespread usage of ML and statistical techniques, DP becomes even more critical to ensure private information of participating individuals is not revealed in any form via the learned model. A statistical estimator is said to be (\u03b5, \u03b4)-differentially private if presence/absence of an individual\u2019s data point in the dataset does not significantly change the estimated output. Smaller \u03b5 > 0 and \u03b4 \u2208 [0, 1] imply stronger privacy guarantees.\n\nWhile privacy preserving statistical estimators have been studied extensively in recent past, several critical questions remain open (see App. A for a survey). Consider the canonical statistical task of linear regression with n i.i.d. samples, {($$x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R}$$)}_{i=1}^n, drawn from $$x_i \\sim N(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$, $$z_i \\sim N(0, \\sigma^2)$$ and $$E[x_iz_i] = 0$$ for some true parameter $$w^* \\in \\mathbb{R}^d$$. The error is measured in $$(1/\\sigma) \\lVert \\hat{w} - w^* \\rVert_\\Sigma := (1/\\sigma) \\lVert \\Sigma^{1/2}(\\hat{w} - w^*) \\rVert$$, which correctly accounts for the signal-to-noise ratio in each direction; in the direction of large eigenvalue of $$\\Sigma$$, we have larger signal in $$x_i$$.\n\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 2, "value": "Label Robust and Differentially Private Linear Regression: Computational and Statistical Efficiency", "md": "## Label Robust and Differentially Private Linear Regression: Computational and Statistical Efficiency"}, {"type": "text", "value": "Xiyang Liu - Paul Allen School of Computer Science & Engineering, University of Washington - xiyangl@cs.washington.edu\n\nPrateek Jain - Google Research - prajain@google.com\n\nWeihao Kong - Google Research - weihaokong@google.com\n\nSewoong Oh - Paul Allen School of Computer Science & Engineering, University of Washington, and Google Research - sewoong@cs.washington.edu\n\nArun Sai Suggala - Google Research - arunss@google.com", "md": "Xiyang Liu - Paul Allen School of Computer Science & Engineering, University of Washington - xiyangl@cs.washington.edu\n\nPrateek Jain - Google Research - prajain@google.com\n\nWeihao Kong - Google Research - weihaokong@google.com\n\nSewoong Oh - Paul Allen School of Computer Science & Engineering, University of Washington, and Google Research - sewoong@cs.washington.edu\n\nArun Sai Suggala - Google Research - arunss@google.com"}, {"type": "heading", "lvl": 3, "value": "Abstract", "md": "### Abstract"}, {"type": "text", "value": "We study the canonical problem of linear regression under (\u03b5, \u03b4)-differential privacy when the datapoints are sampled i.i.d. from a distribution and a fraction of response variables are adversarially corrupted. We provide the first provably efficient \u2013 both computationally and statistically \u2013 method for this problem, assuming standard assumptions on the data distribution. Our algorithm is a variant of the popular differentially private stochastic gradient descent (DP-SGD) algorithm with two key innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness. Our method requires only linear time in input size, and still matches the information theoretical optimal sample complexity up to a data distribution dependent condition number factor. Interestingly, the same algorithm, when applied to a setting where there is no adversarial corruption, still improves upon the existing state-of-the-art and achieves a near optimal sample complexity.", "md": "We study the canonical problem of linear regression under (\u03b5, \u03b4)-differential privacy when the datapoints are sampled i.i.d. from a distribution and a fraction of response variables are adversarially corrupted. We provide the first provably efficient \u2013 both computationally and statistically \u2013 method for this problem, assuming standard assumptions on the data distribution. Our algorithm is a variant of the popular differentially private stochastic gradient descent (DP-SGD) algorithm with two key innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness. Our method requires only linear time in input size, and still matches the information theoretical optimal sample complexity up to a data distribution dependent condition number factor. Interestingly, the same algorithm, when applied to a setting where there is no adversarial corruption, still improves upon the existing state-of-the-art and achieves a near optimal sample complexity."}, {"type": "heading", "lvl": 3, "value": "Introduction", "md": "### Introduction"}, {"type": "text", "value": "Differential Privacy (DP) [33] is a standard notion of privacy widely adopted by both industry and government [76, 35, 36, 2]. With widespread usage of ML and statistical techniques, DP becomes even more critical to ensure private information of participating individuals is not revealed in any form via the learned model. A statistical estimator is said to be (\u03b5, \u03b4)-differentially private if presence/absence of an individual\u2019s data point in the dataset does not significantly change the estimated output. Smaller \u03b5 > 0 and \u03b4 \u2208 [0, 1] imply stronger privacy guarantees.\n\nWhile privacy preserving statistical estimators have been studied extensively in recent past, several critical questions remain open (see App. A for a survey). Consider the canonical statistical task of linear regression with n i.i.d. samples, {($$x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R}$$)}_{i=1}^n, drawn from $$x_i \\sim N(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$, $$z_i \\sim N(0, \\sigma^2)$$ and $$E[x_iz_i] = 0$$ for some true parameter $$w^* \\in \\mathbb{R}^d$$. The error is measured in $$(1/\\sigma) \\lVert \\hat{w} - w^* \\rVert_\\Sigma := (1/\\sigma) \\lVert \\Sigma^{1/2}(\\hat{w} - w^*) \\rVert$$, which correctly accounts for the signal-to-noise ratio in each direction; in the direction of large eigenvalue of $$\\Sigma$$, we have larger signal in $$x_i$$.\n\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).", "md": "Differential Privacy (DP) [33] is a standard notion of privacy widely adopted by both industry and government [76, 35, 36, 2]. With widespread usage of ML and statistical techniques, DP becomes even more critical to ensure private information of participating individuals is not revealed in any form via the learned model. A statistical estimator is said to be (\u03b5, \u03b4)-differentially private if presence/absence of an individual\u2019s data point in the dataset does not significantly change the estimated output. Smaller \u03b5 > 0 and \u03b4 \u2208 [0, 1] imply stronger privacy guarantees.\n\nWhile privacy preserving statistical estimators have been studied extensively in recent past, several critical questions remain open (see App. A for a survey). Consider the canonical statistical task of linear regression with n i.i.d. samples, {($$x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R}$$)}_{i=1}^n, drawn from $$x_i \\sim N(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$, $$z_i \\sim N(0, \\sigma^2)$$ and $$E[x_iz_i] = 0$$ for some true parameter $$w^* \\in \\mathbb{R}^d$$. The error is measured in $$(1/\\sigma) \\lVert \\hat{w} - w^* \\rVert_\\Sigma := (1/\\sigma) \\lVert \\Sigma^{1/2}(\\hat{w} - w^*) \\rVert$$, which correctly accounts for the signal-to-noise ratio in each direction; in the direction of large eigenvalue of $$\\Sigma$$, we have larger signal in $$x_i$$.\n\n37th Conference on Neural Information Processing Systems (NeurIPS 2023)."}]}, {"page": 2, "text": " but the noise zi remains the same. We expect smaller errors in those directions, which is accounted\n for in the error measure (1/\u03c3)\u2225  w\u02c6\u2212   w\u2217\u2225\u03a3.\n Minimax optimal sample complexity for estimating the optimal linear regression model with DP\nwas recently established. For the lower bound, using recently introduced score attack technique,\n [16, Theorem 3.1] shows that n = \u2126(d/\u03b12 + d/(\u03b5\u03b1)) samples are necessary to achieve an error of\n(1/\u03c3)\u2225  w\u02c6\u2212  w\u2217\u2225\u03a3 = \u03b1 (in expectation). For the matching upper bound, High-dimensional Propose-\nTest-Release (HPTR) in [61] and Robust-to-Private in [10] show that n = \u02dc     O(d/\u03b12+d/(\u03b5\u03b1)) samples\n are also sufficient. The first term of d/\u03b12 is the fundamental sample complexity even if privacy is not\n required, and the second term of d/(\u03b5\u03b1) is the cost of privacy.\nThis implies that, statistically, the problem appears to be solved. However, computationally, the\n problem is still open despite multiple studies of the problem. That is, the statistical optimal algorithms\n still take exponential time.\nAfter a series of efforts in computationally efficient approaches as surveyed in App. A, [81] achieves\n the best known sample complexity of n = \u02dc     O(d/\u03b12 + \u03bad/(\u03b5\u03b1) + \u03ba2d/\u03b5), where \u03ba is the condition\n number of the covariance \u03a3 of the covariates. Compared to HPTR, the cost of computational\n efficiency is factor of \u03ba in the second term and the third term that is unnecessary. As the condition\n number can be quite large, improving the dependence on \u03ba is of utmost importance. Furthermore, the\n technique of [81] strictly requires sampling without replacement, whose analysis relies on having an\n explicit form of the end-to-end update. In particular, their analysis technique is not applicable to the\n case with corrupted samples.\n In contrast, we propose a novel method (Alg. 1) that builds upon full-batch gradient descent and\n applies a carefully chosen adaptive clipping which is a general technique used in practice as well\n [1]. Together with an intuitive but intricate analysis technique, we improve the sample complexity to\n n = \u02dcO(d/\u03b12 + \u03ba1/2d/(\u03b5\u03b1)).\n Corollary 1.1 (Corollary of Thm. 3.1 for sub-Gaussian data). Alg. 1 is (\u03b5, \u03b4)-DP. Let S =\n {(xi, yi)}n\n           i=1 be a dataset of i.i.d. samples with xi \u223c   N(0, \u03a3), yi = x\u22a4  i w\u2217 + zi and zi \u223c   N(0, \u03c32)\n for some unknown true parameter w\u2217           = \u03a3\u22121E[yixi] \u2208       Rd and unknown \u03a3 and \u03c32.           Then\n n = \u02dcO(d/\u03b12 + \u03ba1/2d/(\u03b5\u03b1)) samples are sufficient for Alg. 1 to achieve (1/\u03c3)\u2225        w\u02c6\u2212   w\u2217\u2225\u03a3 = \u02dc O(\u03b1)\n with high probability, where \u03ba := \u03bbmax(\u03a3)/\u03bbmin(\u03a3).\n Due to space constraints, we focus on sub-Gaussian distributions in the main text and provide\n comparisons to prior work in Tab. 1. Our analysis in App. H applies to a more general family of\n light-tailed distributions, called sub-Weibull. Next, when the noise in the samples is heavy-tailed, a\n similar algorithm can be applied with carefully chosen clipping thresholds to account for the heavier\n tail. Concretely, for k-th moment bounded distributions, the tail of the distribution gets increasingly\n heavier with smaller k. This would require larger number of samples to achieve the same accuracy,\nwhich is captured in our sample complexity of n = \u02dc        O(d/\u03b12k/(k\u22121) + \u03ba1/2d/(\u03b5\u03b1k/(k\u22121))). We\n explain the heavy-tailed setting, provide a detailed analysis and a proof, and discuss the results in\nApp. L. This is the first efficient algorithm with provable guarantees achieving (\u03b5, \u03b4)-DP.\n Corollary 1.2 (informal version of Coro. L.7 for heavy-tailed noise). Alg. 4 is (\u03b5, \u03b4)-DP. Let\n S = {(xi, yi)}n i=1 be a dataset of i.i.d. samples with xi \u223c       N(0, \u03a3), yi = x\u22a4  i w\u2217  + zi, and the\n zero-mean, independent, and heavy-tailed noise zi satisfies E[|z/\u03c3|k] = O(1) for some unknown\n true parameter w\u2217   \u2208  Rd and unknown \u03a3 and \u03c32. Then n = \u02dc       O(d/\u03b12k/(k\u22121) + \u03ba1/2d/(\u03b5\u03b1k/(k\u22121)))\n samples are sufficient for Alg. 4 in App. L to achieve an error rate of (1/\u03c3)\u2225  \u02c6\n high probability, where \u03ba := \u03bbmax(\u03a3)/\u03bbmin(\u03a3).                                   w \u2212  w\u2217\u2225\u03a3 = \u02dc  O(\u03b1) with\n Perhaps surprisingly, we show that Alg. 1 is also robust against label-corruption, where an adversary\n selects an arbitrary \u03b1corrupt fraction of the data points and changes their response variables arbitrarily.\n Ideally, we want a robust algorithm against a stronger adversary who can corrupt the covariates also.\n However, even for a simpler problem of private mean estimation, achieving robustness against such a\n strong adversary with O(d) samples requires heavy machinery (convex relaxations of sum-of-squares\n optimization) with significantly more computations (although polynomial) [45].\n Our lower bound in Prop. 3.9, together with the lower bound in [16] on the uncorrupted case, shows\n that n = \u2126(d/\u03b12 + d/(\u03b5\u03b1)) samples are necessary to achieve an error rate of (1/\u03c3)\u2225          \u02c6\n                                                                                             w \u2212  w\u2217\u2225\u03a3 =\n O(\u03b1 + \u03b1corrupt). In particular, it is impossible to achieve an error below \u03b1corrupt even if we have\n                                                     2", "md": "but the noise zi remains the same. We expect smaller errors in those directions, which is accounted for in the error measure $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma}$$. Minimax optimal sample complexity for estimating the optimal linear regression model with DP was recently established. For the lower bound, using recently introduced score attack technique, [16, Theorem 3.1] shows that $$n = \\Omega\\left(\\frac{d}{\\alpha^2} + \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are necessary to achieve an error of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\alpha$$ (in expectation). For the matching upper bound, High-dimensional Propose-Test-Release (HPTR) in [61] and Robust-to-Private in [10] show that $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2}+\\frac{d}{\\epsilon \\alpha}\\right)$$ samples are also sufficient. The first term of $$\\frac{d}{\\alpha^2}$$ is the fundamental sample complexity even if privacy is not required, and the second term of $$\\frac{d}{\\epsilon \\alpha}$$ is the cost of privacy.\n\nThis implies that, statistically, the problem appears to be solved. However, computationally, the problem is still open despite multiple studies of the problem. That is, the statistical optimal algorithms still take exponential time.\n\nAfter a series of efforts in computationally efficient approaches as surveyed in App. A, [81] achieves the best known sample complexity of $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa \\frac{d}{\\epsilon \\alpha} + \\kappa^2 \\frac{d}{\\epsilon}\\right)$$, where $$\\kappa$$ is the condition number of the covariance $$\\Sigma$$ of the covariates. Compared to HPTR, the cost of computational efficiency is a factor of $$\\kappa$$ in the second term and the third term that is unnecessary. As the condition number can be quite large, improving the dependence on $$\\kappa$$ is of utmost importance. Furthermore, the technique of [81] strictly requires sampling without replacement, whose analysis relies on having an explicit form of the end-to-end update. In particular, their analysis technique is not applicable to the case with corrupted samples.\n\nIn contrast, we propose a novel method (Alg. 1) that builds upon full-batch gradient descent and applies a carefully chosen adaptive clipping which is a general technique used in practice as well [1]. Together with an intuitive but intricate analysis technique, we improve the sample complexity to $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha}\\right)$$.\n\nCorollary 1.1 (Corollary of Thm. 3.1 for sub-Gaussian data). Alg. 1 is $$(\\epsilon, \\delta)$$-DP. Let $$S = \\{(x_i, y_i)\\}_{i=1}^n$$ be a dataset of i.i.d. samples with $$x_i \\sim \\mathcal{N}(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$ and $$z_i \\sim \\mathcal{N}(0, \\sigma^2)$$ for some unknown true parameter $$w^* = \\Sigma^{-1}E[y_i x_i] \\in \\mathbb{R}^d$$ and unknown $$\\Sigma$$ and $$\\sigma^2$$. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are sufficient for Alg. 1 to achieve $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ with high probability, where $$\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)$$.\n\nDue to space constraints, we focus on sub-Gaussian distributions in the main text and provide comparisons to prior work in Tab. 1. Our analysis in App. H applies to a more general family of light-tailed distributions, called sub-Weibull. Next, when the noise in the samples is heavy-tailed, a similar algorithm can be applied with carefully chosen clipping thresholds to account for the heavier tail. Concretely, for $$k$$-th moment bounded distributions, the tail of the distribution gets increasingly heavier with smaller $$k$$. This would require a larger number of samples to achieve the same accuracy, which is captured in our sample complexity of $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^{2k/(k-1)}} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha^{k/(k-1)}}\\right)$$. We explain the heavy-tailed setting, provide a detailed analysis and a proof, and discuss the results in App. L. This is the first efficient algorithm with provable guarantees achieving $$(\\epsilon, \\delta)$$-DP.\n\nCorollary 1.2 (informal version of Coro. L.7 for heavy-tailed noise). Alg. 4 is $$(\\epsilon, \\delta)$$-DP. Let $$S = \\{(x_i, y_i)\\}_{i=1}^n$$ be a dataset of i.i.d. samples with $$x_i \\sim \\mathcal{N}(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$, and the zero-mean, independent, and heavy-tailed noise $$z_i$$ satisfies $$E[|z/\\sigma|^k] = O(1)$$ for some unknown true parameter $$w^* \\in \\mathbb{R}^d$$ and unknown $$\\Sigma$$ and $$\\sigma^2$$. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^{2k/(k-1)}} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha^{k/(k-1)}}\\right)$$ samples are sufficient for Alg. 4 in App. L to achieve an error rate of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ with high probability, where $$\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)$$.\n\nPerhaps surprisingly, we show that Alg. 1 is also robust against label-corruption, where an adversary selects an arbitrary $$\\alpha_{\\text{corrupt}}$$ fraction of the data points and changes their response variables arbitrarily. Ideally, we want a robust algorithm against a stronger adversary who can corrupt the covariates also. However, even for a simpler problem of private mean estimation, achieving robustness against such a strong adversary with $$O(d)$$ samples requires heavy machinery (convex relaxations of sum-of-squares optimization) with significantly more computations (although polynomial) [45].\n\nOur lower bound in Prop. 3.9, together with the lower bound in [16] on the uncorrupted case, shows that $$n = \\Omega\\left(\\frac{d}{\\alpha^2} + \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are necessary to achieve an error rate of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = O(\\alpha + \\alpha_{\\text{corrupt}})$$. In particular, it is impossible to achieve an error below $$\\alpha_{\\text{corrupt}}$$ even if we have", "images": [], "items": [{"type": "text", "value": "but the noise zi remains the same. We expect smaller errors in those directions, which is accounted for in the error measure $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma}$$. Minimax optimal sample complexity for estimating the optimal linear regression model with DP was recently established. For the lower bound, using recently introduced score attack technique, [16, Theorem 3.1] shows that $$n = \\Omega\\left(\\frac{d}{\\alpha^2} + \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are necessary to achieve an error of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\alpha$$ (in expectation). For the matching upper bound, High-dimensional Propose-Test-Release (HPTR) in [61] and Robust-to-Private in [10] show that $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2}+\\frac{d}{\\epsilon \\alpha}\\right)$$ samples are also sufficient. The first term of $$\\frac{d}{\\alpha^2}$$ is the fundamental sample complexity even if privacy is not required, and the second term of $$\\frac{d}{\\epsilon \\alpha}$$ is the cost of privacy.\n\nThis implies that, statistically, the problem appears to be solved. However, computationally, the problem is still open despite multiple studies of the problem. That is, the statistical optimal algorithms still take exponential time.\n\nAfter a series of efforts in computationally efficient approaches as surveyed in App. A, [81] achieves the best known sample complexity of $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa \\frac{d}{\\epsilon \\alpha} + \\kappa^2 \\frac{d}{\\epsilon}\\right)$$, where $$\\kappa$$ is the condition number of the covariance $$\\Sigma$$ of the covariates. Compared to HPTR, the cost of computational efficiency is a factor of $$\\kappa$$ in the second term and the third term that is unnecessary. As the condition number can be quite large, improving the dependence on $$\\kappa$$ is of utmost importance. Furthermore, the technique of [81] strictly requires sampling without replacement, whose analysis relies on having an explicit form of the end-to-end update. In particular, their analysis technique is not applicable to the case with corrupted samples.\n\nIn contrast, we propose a novel method (Alg. 1) that builds upon full-batch gradient descent and applies a carefully chosen adaptive clipping which is a general technique used in practice as well [1]. Together with an intuitive but intricate analysis technique, we improve the sample complexity to $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha}\\right)$$.\n\nCorollary 1.1 (Corollary of Thm. 3.1 for sub-Gaussian data). Alg. 1 is $$(\\epsilon, \\delta)$$-DP. Let $$S = \\{(x_i, y_i)\\}_{i=1}^n$$ be a dataset of i.i.d. samples with $$x_i \\sim \\mathcal{N}(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$ and $$z_i \\sim \\mathcal{N}(0, \\sigma^2)$$ for some unknown true parameter $$w^* = \\Sigma^{-1}E[y_i x_i] \\in \\mathbb{R}^d$$ and unknown $$\\Sigma$$ and $$\\sigma^2$$. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are sufficient for Alg. 1 to achieve $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ with high probability, where $$\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)$$.\n\nDue to space constraints, we focus on sub-Gaussian distributions in the main text and provide comparisons to prior work in Tab. 1. Our analysis in App. H applies to a more general family of light-tailed distributions, called sub-Weibull. Next, when the noise in the samples is heavy-tailed, a similar algorithm can be applied with carefully chosen clipping thresholds to account for the heavier tail. Concretely, for $$k$$-th moment bounded distributions, the tail of the distribution gets increasingly heavier with smaller $$k$$. This would require a larger number of samples to achieve the same accuracy, which is captured in our sample complexity of $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^{2k/(k-1)}} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha^{k/(k-1)}}\\right)$$. We explain the heavy-tailed setting, provide a detailed analysis and a proof, and discuss the results in App. L. This is the first efficient algorithm with provable guarantees achieving $$(\\epsilon, \\delta)$$-DP.\n\nCorollary 1.2 (informal version of Coro. L.7 for heavy-tailed noise). Alg. 4 is $$(\\epsilon, \\delta)$$-DP. Let $$S = \\{(x_i, y_i)\\}_{i=1}^n$$ be a dataset of i.i.d. samples with $$x_i \\sim \\mathcal{N}(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$, and the zero-mean, independent, and heavy-tailed noise $$z_i$$ satisfies $$E[|z/\\sigma|^k] = O(1)$$ for some unknown true parameter $$w^* \\in \\mathbb{R}^d$$ and unknown $$\\Sigma$$ and $$\\sigma^2$$. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^{2k/(k-1)}} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha^{k/(k-1)}}\\right)$$ samples are sufficient for Alg. 4 in App. L to achieve an error rate of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ with high probability, where $$\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)$$.\n\nPerhaps surprisingly, we show that Alg. 1 is also robust against label-corruption, where an adversary selects an arbitrary $$\\alpha_{\\text{corrupt}}$$ fraction of the data points and changes their response variables arbitrarily. Ideally, we want a robust algorithm against a stronger adversary who can corrupt the covariates also. However, even for a simpler problem of private mean estimation, achieving robustness against such a strong adversary with $$O(d)$$ samples requires heavy machinery (convex relaxations of sum-of-squares optimization) with significantly more computations (although polynomial) [45].\n\nOur lower bound in Prop. 3.9, together with the lower bound in [16] on the uncorrupted case, shows that $$n = \\Omega\\left(\\frac{d}{\\alpha^2} + \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are necessary to achieve an error rate of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = O(\\alpha + \\alpha_{\\text{corrupt}})$$. In particular, it is impossible to achieve an error below $$\\alpha_{\\text{corrupt}}$$ even if we have", "md": "but the noise zi remains the same. We expect smaller errors in those directions, which is accounted for in the error measure $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma}$$. Minimax optimal sample complexity for estimating the optimal linear regression model with DP was recently established. For the lower bound, using recently introduced score attack technique, [16, Theorem 3.1] shows that $$n = \\Omega\\left(\\frac{d}{\\alpha^2} + \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are necessary to achieve an error of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\alpha$$ (in expectation). For the matching upper bound, High-dimensional Propose-Test-Release (HPTR) in [61] and Robust-to-Private in [10] show that $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2}+\\frac{d}{\\epsilon \\alpha}\\right)$$ samples are also sufficient. The first term of $$\\frac{d}{\\alpha^2}$$ is the fundamental sample complexity even if privacy is not required, and the second term of $$\\frac{d}{\\epsilon \\alpha}$$ is the cost of privacy.\n\nThis implies that, statistically, the problem appears to be solved. However, computationally, the problem is still open despite multiple studies of the problem. That is, the statistical optimal algorithms still take exponential time.\n\nAfter a series of efforts in computationally efficient approaches as surveyed in App. A, [81] achieves the best known sample complexity of $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa \\frac{d}{\\epsilon \\alpha} + \\kappa^2 \\frac{d}{\\epsilon}\\right)$$, where $$\\kappa$$ is the condition number of the covariance $$\\Sigma$$ of the covariates. Compared to HPTR, the cost of computational efficiency is a factor of $$\\kappa$$ in the second term and the third term that is unnecessary. As the condition number can be quite large, improving the dependence on $$\\kappa$$ is of utmost importance. Furthermore, the technique of [81] strictly requires sampling without replacement, whose analysis relies on having an explicit form of the end-to-end update. In particular, their analysis technique is not applicable to the case with corrupted samples.\n\nIn contrast, we propose a novel method (Alg. 1) that builds upon full-batch gradient descent and applies a carefully chosen adaptive clipping which is a general technique used in practice as well [1]. Together with an intuitive but intricate analysis technique, we improve the sample complexity to $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha}\\right)$$.\n\nCorollary 1.1 (Corollary of Thm. 3.1 for sub-Gaussian data). Alg. 1 is $$(\\epsilon, \\delta)$$-DP. Let $$S = \\{(x_i, y_i)\\}_{i=1}^n$$ be a dataset of i.i.d. samples with $$x_i \\sim \\mathcal{N}(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$ and $$z_i \\sim \\mathcal{N}(0, \\sigma^2)$$ for some unknown true parameter $$w^* = \\Sigma^{-1}E[y_i x_i] \\in \\mathbb{R}^d$$ and unknown $$\\Sigma$$ and $$\\sigma^2$$. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are sufficient for Alg. 1 to achieve $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ with high probability, where $$\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)$$.\n\nDue to space constraints, we focus on sub-Gaussian distributions in the main text and provide comparisons to prior work in Tab. 1. Our analysis in App. H applies to a more general family of light-tailed distributions, called sub-Weibull. Next, when the noise in the samples is heavy-tailed, a similar algorithm can be applied with carefully chosen clipping thresholds to account for the heavier tail. Concretely, for $$k$$-th moment bounded distributions, the tail of the distribution gets increasingly heavier with smaller $$k$$. This would require a larger number of samples to achieve the same accuracy, which is captured in our sample complexity of $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^{2k/(k-1)}} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha^{k/(k-1)}}\\right)$$. We explain the heavy-tailed setting, provide a detailed analysis and a proof, and discuss the results in App. L. This is the first efficient algorithm with provable guarantees achieving $$(\\epsilon, \\delta)$$-DP.\n\nCorollary 1.2 (informal version of Coro. L.7 for heavy-tailed noise). Alg. 4 is $$(\\epsilon, \\delta)$$-DP. Let $$S = \\{(x_i, y_i)\\}_{i=1}^n$$ be a dataset of i.i.d. samples with $$x_i \\sim \\mathcal{N}(0, \\Sigma)$$, $$y_i = x_i^T w^* + z_i$$, and the zero-mean, independent, and heavy-tailed noise $$z_i$$ satisfies $$E[|z/\\sigma|^k] = O(1)$$ for some unknown true parameter $$w^* \\in \\mathbb{R}^d$$ and unknown $$\\Sigma$$ and $$\\sigma^2$$. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^{2k/(k-1)}} + \\kappa^{1/2} \\frac{d}{\\epsilon \\alpha^{k/(k-1)}}\\right)$$ samples are sufficient for Alg. 4 in App. L to achieve an error rate of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ with high probability, where $$\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)$$.\n\nPerhaps surprisingly, we show that Alg. 1 is also robust against label-corruption, where an adversary selects an arbitrary $$\\alpha_{\\text{corrupt}}$$ fraction of the data points and changes their response variables arbitrarily. Ideally, we want a robust algorithm against a stronger adversary who can corrupt the covariates also. However, even for a simpler problem of private mean estimation, achieving robustness against such a strong adversary with $$O(d)$$ samples requires heavy machinery (convex relaxations of sum-of-squares optimization) with significantly more computations (although polynomial) [45].\n\nOur lower bound in Prop. 3.9, together with the lower bound in [16] on the uncorrupted case, shows that $$n = \\Omega\\left(\\frac{d}{\\alpha^2} + \\frac{d}{\\epsilon \\alpha}\\right)$$ samples are necessary to achieve an error rate of $$\\left(\\frac{1}{\\sigma}\\right)\\| \\hat{w} - w^* \\|_{\\Sigma} = O(\\alpha + \\alpha_{\\text{corrupt}})$$. In particular, it is impossible to achieve an error below $$\\alpha_{\\text{corrupt}}$$ even if we have"}]}, {"page": 3, "text": " Table 1: Suppose data is drawn from a linear model in d-dimensions from sub-Gaussian covariates\n with covariance \u03a3 and sub-Gaussian noise with variance \u03c32. To achieve an error rate of (1/\u03c3)\u2225                                            w\u02c6\u2212\n w\u2217\u2225\u03a3 = \u03b1 with (\u03b5, \u03b4)-DP, DP-RobGD requires the least number of samples among computationally\n efficient algorithms. This improves over [81] by a factor of \u03ba1/2 in the second term, where \u03ba is the\n condition number of \u03a3. We hide polylogarithmic factors in d, \u03ba and 1/\u03b4. \u2660DP-Theil-Sen is only\n analyzed when \u03ba = 1 and its dependence \u03bac is unknown.\n                      Algorithm                                                   Runtime         Sample Complexity\n                      TukeyEM [6]                                                 poly            no guarantee\n                                                                                                   d2       d\n                      DP-Theil-Sen [74] \u2660                                         poly             \u03b12 +    \u03b5\u03b1\u03bac\n                                                                                                    d       d\n                      DP-AMBSSGD [81]                                             poly             \u03b12 +    \u03b5\u03b1\u03ba + \u03ba2d    \u03b5\n                                                                                                    d       d\n                      DP-RobGD [Theorem 3.8]                                      poly             \u03b12 +    \u03b5\u03b1\u03ba1/2\n                                                                                                    d       d\n                      HPTR [61], Robust-to-private [10]                           exp              \u03b12 +    \u03b5\u03b1\n                                                                                                    d       d\n                      Lower Bound [16]                                                             \u03b12 +    \u03b5\u03b1\n infinite samples (Prop. 3.9), and hence there is no need to aim for \u03b1 < \u03b1corrupt. This lower bound is\n matched by exponential time approaches, HPTR in [61] and Robust-to-Private in [10], which also\n guarantee robustness. Currently, there is no effi                   cient algorithm that can guarantee both privacy and\n robustness for linear regression. To this end, we provide the first effi                             cient algorithm guaranteeing\n both, with a sample complexity that is optimal up to a \u03ba1/2 factor.\n Corollary 1.3 (Corollary of Thm. H.3 for sub-Gaussian data with adversarial label corruption).\n Under the hypotheses of Coro. 1.1, suppose \u03b1corrupt-fraction of the labels are corrupted arbitrarily.\nThen n = \u02dc       O(d/\u03b12 + \u03ba1/2d/(\u03b5\u03b1)) samples are suffi                        cient for Alg. 1 to achieve an error rate of\n(1/\u03c3)\u2225     \u02c6\n           w \u2212    w\u2217\u2225\u03a3 = \u02dc     O(\u03b1 + \u03b1corrupt) with high probability, where \u03ba := \u03bbmax(\u03a3)/\u03bbmin(\u03a3).\nWhen \u03b1corrupt = 0, this recovers the non-robust result from Coro. 1.1. A similar robustness guarantee\n also holds for heavy-tailed settings. We provide a formal statement in App. L\n Contributions. For a canonical problem of private linear regression under sub-Gaussian distributions,\n the best known efficient algorithm [81] requires\n                                                   n = \u02dc  O      d                           ,\n                                                                \u03b12 + \u03bad  \u03b5\u03b1 + \u03ba2d    \u03b5\n to achieve (1/\u03c3)\u2225         \u02c6\n                           w \u2212    w\u2217\u2225\u03a3 = \u03b1. We provide the first efficient algorithm that improves this to\n                                                      n = \u02dc  O      d                     ,\n                                                                   \u03b12 + \u03ba1/2d  \u03b5\u03b1\n which nearly matches the exponential-time algorithms [61, 10] and the lower bound [16] up to \u03ba1/2\n in the second term. For the same problem, we show that the same algorithm is the first to achieve\n robustness against adversarial corruption of the labels.\n Under a heavy-tailed distribution of the noise, we provide the first computationally efficient algorithm,\n to the best of our knowledge, that achieves a sample complexity close to that of an exponential-time\n algorithm of [61]. There is no matching lower bound in the heavy-tailed setting. This is also the\n first effi cient algorithm to achieve robustness against adversarial corruption of the labels under\n heavy-tailed noise.\n 2     Problem formulation and background\nWhen there is no adversary, we present our results under the standard linear model with sub-Gaussian\n covariates and noise. In App. H, we present a more general family of (K, a)-sub-Weibull distributions\n that recovers the standard sub-Gaussian family as a special case when a = 0.5. The necessity of such\n assumptions on the tail is explained in Sec. 3.4.\n Assumption 2.1 (sub-Gaussian model). We have i.i.d. samples S = {(xi \u2208                                         Rd, yi \u2208     R)}n  i=1 from\n a distribution P\u03a3,w\u2217,\u03c32 of a linear model yi = \u27e8xi, w\u2217\u27e9                            + zi, where the input vector xi has zero\n                                                                       3", "md": "|Algorithm|Runtime|Sample Complexity|\n|---|---|---|\n|TukeyEM [6]|poly|no guarantee|\n|DP-Theil-Sen [74] \u2660|poly|$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa_c}{d}$|\n|DP-AMBSSGD [81]|poly|$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa + \\kappa^2d}{d}$|\n|DP-RobGD [Theorem 3.8]|poly|$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa^{1/2}}{d}$|\n|HPTR [61], Robust-to-private [10]|exp|$\\alpha^2 + \\frac{\\varepsilon\\alpha}{d}$|\n|Lower Bound [16]| |$\\alpha^2 + \\frac{\\varepsilon\\alpha}{d}$|\n\nCorollary 1.3 (Corollary of Thm. H.3 for sub-Gaussian data with adversarial label corruption). Under the hypotheses of Coro. 1.1, suppose \u03b1corrupt-fraction of the labels are corrupted arbitrarily. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2 + \\kappa^{1/2}d/(\\varepsilon\\alpha)}\\right)$$ samples are sufficient for Alg. 1 to achieve an error rate of $$(1/\\sigma)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha + \\alpha_{\\text{corrupt}})$$ with high probability, where $$\\kappa := \\frac{\\lambda_{\\text{max}}(\\Sigma)}{\\lambda_{\\text{min}}(\\Sigma)}$$. When \u03b1corrupt = 0, this recovers the non-robust result from Coro. 1.1. A similar robustness guarantee also holds for heavy-tailed settings. We provide a formal statement in App. L\n\nContributions. For a canonical problem of private linear regression under sub-Gaussian distributions, the best known efficient algorithm [81] requires\n\n$$n = \\tilde{O}\\left(\\frac{\\alpha^2 + \\kappa d}{\\varepsilon\\alpha + \\kappa^2d \\varepsilon}\\right)$$\n\nto achieve $$(1/\\sigma)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\alpha$$. We provide the first efficient algorithm that improves this to\n\n$$n = \\tilde{O}\\left(\\frac{\\alpha^2 + \\kappa^{1/2}d \\varepsilon\\alpha}{d}\\right)$$\n\nwhich nearly matches the exponential-time algorithms [61, 10] and the lower bound [16] up to $$\\kappa^{1/2}$$ in the second term. For the same problem, we show that the same algorithm is the first to achieve robustness against adversarial corruption of the labels.\n\nUnder a heavy-tailed distribution of the noise, we provide the first computationally efficient algorithm, to the best of our knowledge, that achieves a sample complexity close to that of an exponential-time algorithm of [61]. There is no matching lower bound in the heavy-tailed setting. This is also the first efficient algorithm to achieve robustness against adversarial corruption of the labels under heavy-tailed noise.\n\n## Problem formulation and background\n\nWhen there is no adversary, we present our results under the standard linear model with sub-Gaussian covariates and noise. In App. H, we present a more general family of (K, a)-sub-Weibull distributions that recovers the standard sub-Gaussian family as a special case when a = 0.5. The necessity of such assumptions on the tail is explained in Sec. 3.4.\n\nAssumption 2.1 (sub-Gaussian model). We have i.i.d. samples $$S = \\{(x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R})\\}_{i=1}^n$$ from a distribution $$P_{\\Sigma,w^*,\\sigma^2}$$ of a linear model $$y_i = \\langle x_i, w^* \\rangle + z_i$$, where the input vector $$x_i$$ has zero mean.", "images": [], "items": [{"type": "table", "rows": [["Algorithm", "Runtime", "Sample Complexity"], ["TukeyEM [6]", "poly", "no guarantee"], ["DP-Theil-Sen [74] \u2660", "poly", "$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa_c}{d}$"], ["DP-AMBSSGD [81]", "poly", "$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa + \\kappa^2d}{d}$"], ["DP-RobGD [Theorem 3.8]", "poly", "$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa^{1/2}}{d}$"], ["HPTR [61], Robust-to-private [10]", "exp", "$\\alpha^2 + \\frac{\\varepsilon\\alpha}{d}$"], ["Lower Bound [16]", "", "$\\alpha^2 + \\frac{\\varepsilon\\alpha}{d}$"]], "md": "|Algorithm|Runtime|Sample Complexity|\n|---|---|---|\n|TukeyEM [6]|poly|no guarantee|\n|DP-Theil-Sen [74] \u2660|poly|$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa_c}{d}$|\n|DP-AMBSSGD [81]|poly|$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa + \\kappa^2d}{d}$|\n|DP-RobGD [Theorem 3.8]|poly|$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa^{1/2}}{d}$|\n|HPTR [61], Robust-to-private [10]|exp|$\\alpha^2 + \\frac{\\varepsilon\\alpha}{d}$|\n|Lower Bound [16]| |$\\alpha^2 + \\frac{\\varepsilon\\alpha}{d}$|", "isPerfectTable": true, "csv": "\"Algorithm\",\"Runtime\",\"Sample Complexity\"\n\"TukeyEM [6]\",\"poly\",\"no guarantee\"\n\"DP-Theil-Sen [74] \u2660\",\"poly\",\"$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa_c}{d}$\"\n\"DP-AMBSSGD [81]\",\"poly\",\"$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa + \\kappa^2d}{d}$\"\n\"DP-RobGD [Theorem 3.8]\",\"poly\",\"$\\alpha^2 + \\frac{\\varepsilon\\alpha\\kappa^{1/2}}{d}$\"\n\"HPTR [61], Robust-to-private [10]\",\"exp\",\"$\\alpha^2 + \\frac{\\varepsilon\\alpha}{d}$\"\n\"Lower Bound [16]\",\"\",\"$\\alpha^2 + \\frac{\\varepsilon\\alpha}{d}$\""}, {"type": "text", "value": "Corollary 1.3 (Corollary of Thm. H.3 for sub-Gaussian data with adversarial label corruption). Under the hypotheses of Coro. 1.1, suppose \u03b1corrupt-fraction of the labels are corrupted arbitrarily. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2 + \\kappa^{1/2}d/(\\varepsilon\\alpha)}\\right)$$ samples are sufficient for Alg. 1 to achieve an error rate of $$(1/\\sigma)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha + \\alpha_{\\text{corrupt}})$$ with high probability, where $$\\kappa := \\frac{\\lambda_{\\text{max}}(\\Sigma)}{\\lambda_{\\text{min}}(\\Sigma)}$$. When \u03b1corrupt = 0, this recovers the non-robust result from Coro. 1.1. A similar robustness guarantee also holds for heavy-tailed settings. We provide a formal statement in App. L\n\nContributions. For a canonical problem of private linear regression under sub-Gaussian distributions, the best known efficient algorithm [81] requires\n\n$$n = \\tilde{O}\\left(\\frac{\\alpha^2 + \\kappa d}{\\varepsilon\\alpha + \\kappa^2d \\varepsilon}\\right)$$\n\nto achieve $$(1/\\sigma)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\alpha$$. We provide the first efficient algorithm that improves this to\n\n$$n = \\tilde{O}\\left(\\frac{\\alpha^2 + \\kappa^{1/2}d \\varepsilon\\alpha}{d}\\right)$$\n\nwhich nearly matches the exponential-time algorithms [61, 10] and the lower bound [16] up to $$\\kappa^{1/2}$$ in the second term. For the same problem, we show that the same algorithm is the first to achieve robustness against adversarial corruption of the labels.\n\nUnder a heavy-tailed distribution of the noise, we provide the first computationally efficient algorithm, to the best of our knowledge, that achieves a sample complexity close to that of an exponential-time algorithm of [61]. There is no matching lower bound in the heavy-tailed setting. This is also the first efficient algorithm to achieve robustness against adversarial corruption of the labels under heavy-tailed noise.", "md": "Corollary 1.3 (Corollary of Thm. H.3 for sub-Gaussian data with adversarial label corruption). Under the hypotheses of Coro. 1.1, suppose \u03b1corrupt-fraction of the labels are corrupted arbitrarily. Then $$n = \\tilde{O}\\left(\\frac{d}{\\alpha^2 + \\kappa^{1/2}d/(\\varepsilon\\alpha)}\\right)$$ samples are sufficient for Alg. 1 to achieve an error rate of $$(1/\\sigma)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha + \\alpha_{\\text{corrupt}})$$ with high probability, where $$\\kappa := \\frac{\\lambda_{\\text{max}}(\\Sigma)}{\\lambda_{\\text{min}}(\\Sigma)}$$. When \u03b1corrupt = 0, this recovers the non-robust result from Coro. 1.1. A similar robustness guarantee also holds for heavy-tailed settings. We provide a formal statement in App. L\n\nContributions. For a canonical problem of private linear regression under sub-Gaussian distributions, the best known efficient algorithm [81] requires\n\n$$n = \\tilde{O}\\left(\\frac{\\alpha^2 + \\kappa d}{\\varepsilon\\alpha + \\kappa^2d \\varepsilon}\\right)$$\n\nto achieve $$(1/\\sigma)\\| \\hat{w} - w^* \\|_{\\Sigma} = \\alpha$$. We provide the first efficient algorithm that improves this to\n\n$$n = \\tilde{O}\\left(\\frac{\\alpha^2 + \\kappa^{1/2}d \\varepsilon\\alpha}{d}\\right)$$\n\nwhich nearly matches the exponential-time algorithms [61, 10] and the lower bound [16] up to $$\\kappa^{1/2}$$ in the second term. For the same problem, we show that the same algorithm is the first to achieve robustness against adversarial corruption of the labels.\n\nUnder a heavy-tailed distribution of the noise, we provide the first computationally efficient algorithm, to the best of our knowledge, that achieves a sample complexity close to that of an exponential-time algorithm of [61]. There is no matching lower bound in the heavy-tailed setting. This is also the first efficient algorithm to achieve robustness against adversarial corruption of the labels under heavy-tailed noise."}, {"type": "heading", "lvl": 2, "value": "Problem formulation and background", "md": "## Problem formulation and background"}, {"type": "text", "value": "When there is no adversary, we present our results under the standard linear model with sub-Gaussian covariates and noise. In App. H, we present a more general family of (K, a)-sub-Weibull distributions that recovers the standard sub-Gaussian family as a special case when a = 0.5. The necessity of such assumptions on the tail is explained in Sec. 3.4.\n\nAssumption 2.1 (sub-Gaussian model). We have i.i.d. samples $$S = \\{(x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R})\\}_{i=1}^n$$ from a distribution $$P_{\\Sigma,w^*,\\sigma^2}$$ of a linear model $$y_i = \\langle x_i, w^* \\rangle + z_i$$, where the input vector $$x_i$$ has zero mean.", "md": "When there is no adversary, we present our results under the standard linear model with sub-Gaussian covariates and noise. In App. H, we present a more general family of (K, a)-sub-Weibull distributions that recovers the standard sub-Gaussian family as a special case when a = 0.5. The necessity of such assumptions on the tail is explained in Sec. 3.4.\n\nAssumption 2.1 (sub-Gaussian model). We have i.i.d. samples $$S = \\{(x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R})\\}_{i=1}^n$$ from a distribution $$P_{\\Sigma,w^*,\\sigma^2}$$ of a linear model $$y_i = \\langle x_i, w^* \\rangle + z_i$$, where the input vector $$x_i$$ has zero mean."}]}, {"page": 4, "text": "mean E[xi] = 0 and a positive definite covariance \u03a3 := E[xix\u22a4                                i ] \u227b   0, and the (input dependent)\nlabel noise zi has zero mean E[zi] = 0 and variance \u03c32 := E[z2                              i ]. We further assume E[xizi] = 0,\nwhich is equivalent to assuming that the true parameter w\u2217                           = \u03a3\u22121E[yixi]. We assume the marginal\ndistributions of xi and zi are K-sub-Gaussian with K = O(1), as defined below.\nDefinition 2.2. x \u2208          Rd is K-sub-Gaussian if for all v \u2208                  Rd, E      exp         \u27e8v,x\u27e92           \u2264   2.\nGiven a dataset S that is i.i.d. sampled from P\u03a32,w\u2217,\u03c32 satisfying Asmp. 2.1, our goal is to estimateK2E[\u27e8v,x\u27e92]\nw\u2217   that minimizes (1/\u03c3)\u2225           w\u02c6\u2212    w\u2217\u2225\u03a3 which is also equivalent to minimize the excess population risk,\ni.e., L(w\u2217) \u2212       L( \u02c6w) where L(w) := E(x,y)\u223cP\u03a3,w\u2217,\u03c32 [(y \u2212                      \u27e8w, x\u27e9)2].\nNotations. A vector x \u2208             Rd has the Euclidean norm \u2225x\u2225. For a matrix M, we use \u2225M\u22252 to denote\nthe spectral norm. The error is measured in \u2225                    w\u02c6\u2212    w\u2217\u2225\u03a3 := \u2225\u03a31/2( \u02c6         w \u2212    w\u2217)\u2225    for some PSD matrix\n\u03a3. The identity matrix is denoted by Id \u2208                   Rd\u00d7d. Let [n] = {1, 2, . . . , n}. \u02dc          O(\u00b7) hides some constants\nterms, K = \u0398(1), and poly-logarithmic terms in n, d, 1/\u03b5, log(1/\u03b4), 1/\u03b6, and 1/\u03b1corrupt. For a\nvector x \u2208      Rd, we define clipa(x) := x \u00b7 min{1, a/\u2225x\u2225}.\nBackground on DP. Differential Privacy is a standard measure of privacy leakage when data is\naccessed via queries, introduced by [33]. Two datasets S and S\u2032 are said to be neighbors if they\ndiffer at most by one entry, which is denoted by S \u223c                           S\u2032. A stochastic query q is said to be (\u03b5, \u03b4)-\ndifferentially private for some \u03b5 > 0 and \u03b4 \u2208                        [0, 1], if P(q(S) \u2208         A) \u2264      e\u03b5P(q(S) \u2208         A) + \u03b4, for\nall neighboring datasets S \u223c                S\u2032 and all subset A of the range of the query. We build upon two\nwidely used DP primitives, the Gaussian mechanism and the private histogram. A central concept in\nDP mechanism design is the sensitivity of a query, defined as \u2206q := sup                                  S\u223cS\u2032 \u2225q(S) \u2212          q(S\u2032)\u2225. We\ndescribe Gaussian mechanism and private histogram in App. B.\n2.1     Comparisons with the prior work\nThe state-of-the-art approach introduced by [81] is based on DP-SGD [71], where privacy is ensured\nby gradient norm clipping and the Gaussian mechanism. Two additional technical components are\nadaptive clipping and streaming SGD. Adaptive clipping with an appropriate threshold \u03b8t ensures\nthat no data point is clipped (under the sub-Gaussian assumption), while providing a bound on\nthe sensitivity of the average mini-batch gradient (to ensure we do not add too much noise). The\nstreaming approach, where each data point is only touched once and discarded, ensures independence\nbetween the past iterate wt and the gradients at round t + 1, which the analysis critically relies\non. For T = \u02dc        \u0398(\u03ba) iterations where \u03ba is the condition number of the covariance \u03a3, the dataset\nS = {(xi, yi)}n      i=1 is partitioned into {Bt}T \u22121       t=0 subsets of equal size: |Bt| = \u02dc              \u0398(n/\u03ba). At each round\nt, the gradients are clipped and averaged with additive Gaussian noise chosen to satisfy (\u03b5, \u03b4)-DP:\n           wt+1 \u2190         wt \u2212    \u03b7      1           clip\u03b8t(xi(w\u22a4     t xi \u2212    yi)) + \u03b8t        2 log(1.25/\u03b4)       \u03bdt     ,              (1)\n                                       |Bt|   i\u2208Bt                                                  \u03b5|Bt|\nwhere \u03bdt \u223c       N   (0, Id). In [81], a slight variation of this streaming SGD is shown to achieve an error\nof (1/\u03c3)\u2225wT \u2212          w\u2217\u2225\u03a3 = \u03b1 with n = \u02dc            O(d/\u03b12 + \u03bad/(\u03b5\u03b1) + \u03ba2d/\u03b5) samples (Row 3 in Tab. 1).\nOur technical innovations. Our approach builds upon such gradient based methods but makes\nseveral important innovations. First, we use full-batch gradient descent, as opposed to the streaming\nSGD above. Using all n samples reduces the sensitivity of the per-round gradient average by a\n\u03ba factor, and thus decreases the privacy noise added in each iteration. This improves the second\nterm of sample complexity from \u03bad/(\u03b5\u03b1) to \u03ba1/2d/(\u03b5\u03b1) and removes the third term completely.\nHowever, full-batch GD loses the independence that the streaming SGD enjoyed between wt and the\nsamples used in the round t + 1. This dependence makes the analysis more challenging. We instead\npropose using the resilience to precisely track the bias and variance of the (dependent) full-batch\naverage gradient. Resilience is a central concept in robust statistics that links the tail-property of the\ndistribution to the bias, which we explain in Sec. 5.\nNext, one critical component in achieving this improved sample complexity is the new analysis\ntechnique we introduce for tracking the end-to-end gradient updates. Since our gradient descent\nalgorithm is not guaranteed to make progress every step, we cannot use the vanilla one-step analysis.\n                                                                      4", "md": "Mean \\( E[x_i] = 0 \\) and a positive definite covariance \\( \\Sigma := E[x_ix_i^\\top] \\succ 0 \\), and the (input dependent) label noise \\( z_i \\) has zero mean \\( E[z_i] = 0 \\) and variance \\( \\sigma^2 := E[z_i^2] \\). We further assume \\( E[x_iz_i] = 0 \\), which is equivalent to assuming that the true parameter \\( w^* = \\Sigma^{-1}E[y_ix_i] \\). We assume the marginal distributions of \\( x_i \\) and \\( z_i \\) are \\( K \\)-sub-Gaussian with \\( K = O(1) \\), as defined below.\n\nDefinition 2.2. \\( x \\in \\mathbb{R}^d \\) is \\( K \\)-sub-Gaussian if for all \\( v \\in \\mathbb{R}^d \\), \\( E \\exp \\langle v,x \\rangle^2 \\leq 2 \\).\n\nGiven a dataset \\( S \\) that is i.i.d. sampled from \\( P_{\\Sigma^2,w^*,\\sigma^2} \\) satisfying Asmp. 2.1, our goal is to estimate \\( K^2E[\\langle v,x \\rangle^2] w^* \\) that minimizes \\( \\frac{1}{\\sigma} \\lVert \\hat{w} - w^* \\rVert_\\Sigma \\) which is also equivalent to minimize the excess population risk, i.e., \\( L(w^*) - L(\\hat{w}) \\) where \\( L(w) := E(x,y) \\sim P_{\\Sigma,w^*,\\sigma^2} [(y - \\langle w, x \\rangle)^2] \\).\n\nNotations. A vector \\( x \\in \\mathbb{R}^d \\) has the Euclidean norm \\( \\lVert x \\rVert \\). For a matrix \\( M \\), we use \\( \\lVert M \\rVert_2 \\) to denote the spectral norm. The error is measured in \\( \\lVert \\hat{w} - w^* \\rVert_\\Sigma := \\lVert \\Sigma^{1/2} (\\hat{w} - w^*) \\rVert \\) for some PSD matrix \\( \\Sigma \\). The identity matrix is denoted by \\( \\text{Id} \\in \\mathbb{R}^{d \\times d} \\). Let \\( [n] = \\{1, 2, ..., n\\} \\). \\( \\tilde{O}(\\cdot) \\) hides some constants terms, \\( K = \\Theta(1) \\), and poly-logarithmic terms in \\( n \\), \\( d \\), \\( \\frac{1}{\\epsilon} \\), \\( \\log(\\frac{1}{\\delta}) \\), \\( \\frac{1}{\\zeta} \\), and \\( \\frac{1}{\\alpha} \\) corrupt. For a vector \\( x \\in \\mathbb{R}^d \\), we define \\( \\text{clip}_a(x) := x \\cdot \\min\\{1, \\frac{a}{\\lVert x \\rVert}\\} \\).\n\nBackground on DP. Differential Privacy is a standard measure of privacy leakage when data is accessed via queries, introduced by [33]. Two datasets \\( S \\) and \\( S' \\) are said to be neighbors if they differ at most by one entry, which is denoted by \\( S \\sim S' \\). A stochastic query \\( q \\) is said to be \\( (\\epsilon, \\delta) \\)-differentially private for some \\( \\epsilon > 0 \\) and \\( \\delta \\in [0, 1] \\), if \\( P(q(S) \\in A) \\leq e^{\\epsilon} P(q(S) \\in A) + \\delta \\), for all neighboring datasets \\( S \\sim S' \\) and all subset \\( A \\) of the range of the query. We build upon two widely used DP primitives, the Gaussian mechanism and the private histogram. A central concept in DP mechanism design is the sensitivity of a query, defined as \\( \\Delta q := \\sup_{S \\sim S'} \\lVert q(S) - q(S') \\rVert \\). We describe Gaussian mechanism and private histogram in App. B.\n\n## 2.1 Comparisons with the prior work\n\nThe state-of-the-art approach introduced by [81] is based on DP-SGD [71], where privacy is ensured by gradient norm clipping and the Gaussian mechanism. Two additional technical components are adaptive clipping and streaming SGD. Adaptive clipping with an appropriate threshold \\( \\theta_t \\) ensures that no data point is clipped (under the sub-Gaussian assumption), while providing a bound on the sensitivity of the average mini-batch gradient (to ensure we do not add too much noise). The streaming approach, where each data point is only touched once and discarded, ensures independence between the past iterate \\( w_t \\) and the gradients at round \\( t + 1 \\), which the analysis critically relies on. For \\( T = \\tilde{\\Theta}(\\kappa) \\) iterations where \\( \\kappa \\) is the condition number of the covariance \\( \\Sigma \\), the dataset \\( S = \\{(x_i, y_i)\\}_{i=1}^n \\) is partitioned into \\(\\{B_t\\}_{t=0}^{T-1}\\) subsets of equal size: \\( \\lvert B_t \\rvert = \\tilde{\\Theta}(n/\\kappa) \\). At each round \\( t \\), the gradients are clipped and averaged with additive Gaussian noise chosen to satisfy \\( (\\epsilon, \\delta) \\)-DP:\n\n\\[ w_{t+1} \\leftarrow w_t - \\eta \\frac{1}{\\lvert B_t \\rvert} \\sum_{i \\in B_t} \\text{clip}_{\\theta_t}(x_i(w_t^\\top x_i - y_i)) + \\theta_t \\sqrt{\\frac{2 \\log(1.25/\\delta)}{\\epsilon \\lvert B_t \\rvert}} \\nu_t, \\quad (1) \\]\nwhere \\( \\nu_t \\sim \\mathcal{N}(0, \\text{Id}) \\). In [81], a slight variation of this streaming SGD is shown to achieve an error of \\( \\frac{1}{\\sigma} \\lVert w^T - w^* \\rVert_\\Sigma = \\alpha \\) with \\( n = \\tilde{O}(d/\\alpha^2 + \\kappa d/(\\epsilon \\alpha) + \\kappa^2 d/\\epsilon) \\) samples (Row 3 in Tab. 1).\n\nOur technical innovations. Our approach builds upon such gradient based methods but makes several important innovations. First, we use full-batch gradient descent, as opposed to the streaming SGD above. Using all \\( n \\) samples reduces the sensitivity of the per-round gradient average by a \\( \\kappa \\) factor, and thus decreases the privacy noise added in each iteration. This improves the second term of sample complexity from \\( \\kappa d/(\\epsilon \\alpha) \\) to \\( \\kappa^{1/2} d/(\\epsilon \\alpha) \\) and removes the third term completely. However, full-batch GD loses the independence that the streaming SGD enjoyed between \\( w_t \\) and the samples used in the round \\( t + 1 \\). This dependence makes the analysis more challenging. We instead propose using the resilience to precisely track the bias and variance of the (dependent) full-batch average gradient. Resilience is a central concept in robust statistics that links the tail-property of the distribution to the bias, which we explain in Sec. 5.\n\nNext, one critical component in achieving this improved sample complexity is the new analysis technique we introduce for tracking the end-to-end gradient updates. Since our gradient descent algorithm is not guaranteed to make progress every step, we cannot use the vanilla one-step analysis.", "images": [], "items": [{"type": "text", "value": "Mean \\( E[x_i] = 0 \\) and a positive definite covariance \\( \\Sigma := E[x_ix_i^\\top] \\succ 0 \\), and the (input dependent) label noise \\( z_i \\) has zero mean \\( E[z_i] = 0 \\) and variance \\( \\sigma^2 := E[z_i^2] \\). We further assume \\( E[x_iz_i] = 0 \\), which is equivalent to assuming that the true parameter \\( w^* = \\Sigma^{-1}E[y_ix_i] \\). We assume the marginal distributions of \\( x_i \\) and \\( z_i \\) are \\( K \\)-sub-Gaussian with \\( K = O(1) \\), as defined below.\n\nDefinition 2.2. \\( x \\in \\mathbb{R}^d \\) is \\( K \\)-sub-Gaussian if for all \\( v \\in \\mathbb{R}^d \\), \\( E \\exp \\langle v,x \\rangle^2 \\leq 2 \\).\n\nGiven a dataset \\( S \\) that is i.i.d. sampled from \\( P_{\\Sigma^2,w^*,\\sigma^2} \\) satisfying Asmp. 2.1, our goal is to estimate \\( K^2E[\\langle v,x \\rangle^2] w^* \\) that minimizes \\( \\frac{1}{\\sigma} \\lVert \\hat{w} - w^* \\rVert_\\Sigma \\) which is also equivalent to minimize the excess population risk, i.e., \\( L(w^*) - L(\\hat{w}) \\) where \\( L(w) := E(x,y) \\sim P_{\\Sigma,w^*,\\sigma^2} [(y - \\langle w, x \\rangle)^2] \\).\n\nNotations. A vector \\( x \\in \\mathbb{R}^d \\) has the Euclidean norm \\( \\lVert x \\rVert \\). For a matrix \\( M \\), we use \\( \\lVert M \\rVert_2 \\) to denote the spectral norm. The error is measured in \\( \\lVert \\hat{w} - w^* \\rVert_\\Sigma := \\lVert \\Sigma^{1/2} (\\hat{w} - w^*) \\rVert \\) for some PSD matrix \\( \\Sigma \\). The identity matrix is denoted by \\( \\text{Id} \\in \\mathbb{R}^{d \\times d} \\). Let \\( [n] = \\{1, 2, ..., n\\} \\). \\( \\tilde{O}(\\cdot) \\) hides some constants terms, \\( K = \\Theta(1) \\), and poly-logarithmic terms in \\( n \\), \\( d \\), \\( \\frac{1}{\\epsilon} \\), \\( \\log(\\frac{1}{\\delta}) \\), \\( \\frac{1}{\\zeta} \\), and \\( \\frac{1}{\\alpha} \\) corrupt. For a vector \\( x \\in \\mathbb{R}^d \\), we define \\( \\text{clip}_a(x) := x \\cdot \\min\\{1, \\frac{a}{\\lVert x \\rVert}\\} \\).\n\nBackground on DP. Differential Privacy is a standard measure of privacy leakage when data is accessed via queries, introduced by [33]. Two datasets \\( S \\) and \\( S' \\) are said to be neighbors if they differ at most by one entry, which is denoted by \\( S \\sim S' \\). A stochastic query \\( q \\) is said to be \\( (\\epsilon, \\delta) \\)-differentially private for some \\( \\epsilon > 0 \\) and \\( \\delta \\in [0, 1] \\), if \\( P(q(S) \\in A) \\leq e^{\\epsilon} P(q(S) \\in A) + \\delta \\), for all neighboring datasets \\( S \\sim S' \\) and all subset \\( A \\) of the range of the query. We build upon two widely used DP primitives, the Gaussian mechanism and the private histogram. A central concept in DP mechanism design is the sensitivity of a query, defined as \\( \\Delta q := \\sup_{S \\sim S'} \\lVert q(S) - q(S') \\rVert \\). We describe Gaussian mechanism and private histogram in App. B.", "md": "Mean \\( E[x_i] = 0 \\) and a positive definite covariance \\( \\Sigma := E[x_ix_i^\\top] \\succ 0 \\), and the (input dependent) label noise \\( z_i \\) has zero mean \\( E[z_i] = 0 \\) and variance \\( \\sigma^2 := E[z_i^2] \\). We further assume \\( E[x_iz_i] = 0 \\), which is equivalent to assuming that the true parameter \\( w^* = \\Sigma^{-1}E[y_ix_i] \\). We assume the marginal distributions of \\( x_i \\) and \\( z_i \\) are \\( K \\)-sub-Gaussian with \\( K = O(1) \\), as defined below.\n\nDefinition 2.2. \\( x \\in \\mathbb{R}^d \\) is \\( K \\)-sub-Gaussian if for all \\( v \\in \\mathbb{R}^d \\), \\( E \\exp \\langle v,x \\rangle^2 \\leq 2 \\).\n\nGiven a dataset \\( S \\) that is i.i.d. sampled from \\( P_{\\Sigma^2,w^*,\\sigma^2} \\) satisfying Asmp. 2.1, our goal is to estimate \\( K^2E[\\langle v,x \\rangle^2] w^* \\) that minimizes \\( \\frac{1}{\\sigma} \\lVert \\hat{w} - w^* \\rVert_\\Sigma \\) which is also equivalent to minimize the excess population risk, i.e., \\( L(w^*) - L(\\hat{w}) \\) where \\( L(w) := E(x,y) \\sim P_{\\Sigma,w^*,\\sigma^2} [(y - \\langle w, x \\rangle)^2] \\).\n\nNotations. A vector \\( x \\in \\mathbb{R}^d \\) has the Euclidean norm \\( \\lVert x \\rVert \\). For a matrix \\( M \\), we use \\( \\lVert M \\rVert_2 \\) to denote the spectral norm. The error is measured in \\( \\lVert \\hat{w} - w^* \\rVert_\\Sigma := \\lVert \\Sigma^{1/2} (\\hat{w} - w^*) \\rVert \\) for some PSD matrix \\( \\Sigma \\). The identity matrix is denoted by \\( \\text{Id} \\in \\mathbb{R}^{d \\times d} \\). Let \\( [n] = \\{1, 2, ..., n\\} \\). \\( \\tilde{O}(\\cdot) \\) hides some constants terms, \\( K = \\Theta(1) \\), and poly-logarithmic terms in \\( n \\), \\( d \\), \\( \\frac{1}{\\epsilon} \\), \\( \\log(\\frac{1}{\\delta}) \\), \\( \\frac{1}{\\zeta} \\), and \\( \\frac{1}{\\alpha} \\) corrupt. For a vector \\( x \\in \\mathbb{R}^d \\), we define \\( \\text{clip}_a(x) := x \\cdot \\min\\{1, \\frac{a}{\\lVert x \\rVert}\\} \\).\n\nBackground on DP. Differential Privacy is a standard measure of privacy leakage when data is accessed via queries, introduced by [33]. Two datasets \\( S \\) and \\( S' \\) are said to be neighbors if they differ at most by one entry, which is denoted by \\( S \\sim S' \\). A stochastic query \\( q \\) is said to be \\( (\\epsilon, \\delta) \\)-differentially private for some \\( \\epsilon > 0 \\) and \\( \\delta \\in [0, 1] \\), if \\( P(q(S) \\in A) \\leq e^{\\epsilon} P(q(S) \\in A) + \\delta \\), for all neighboring datasets \\( S \\sim S' \\) and all subset \\( A \\) of the range of the query. We build upon two widely used DP primitives, the Gaussian mechanism and the private histogram. A central concept in DP mechanism design is the sensitivity of a query, defined as \\( \\Delta q := \\sup_{S \\sim S'} \\lVert q(S) - q(S') \\rVert \\). We describe Gaussian mechanism and private histogram in App. B."}, {"type": "heading", "lvl": 2, "value": "2.1 Comparisons with the prior work", "md": "## 2.1 Comparisons with the prior work"}, {"type": "text", "value": "The state-of-the-art approach introduced by [81] is based on DP-SGD [71], where privacy is ensured by gradient norm clipping and the Gaussian mechanism. Two additional technical components are adaptive clipping and streaming SGD. Adaptive clipping with an appropriate threshold \\( \\theta_t \\) ensures that no data point is clipped (under the sub-Gaussian assumption), while providing a bound on the sensitivity of the average mini-batch gradient (to ensure we do not add too much noise). The streaming approach, where each data point is only touched once and discarded, ensures independence between the past iterate \\( w_t \\) and the gradients at round \\( t + 1 \\), which the analysis critically relies on. For \\( T = \\tilde{\\Theta}(\\kappa) \\) iterations where \\( \\kappa \\) is the condition number of the covariance \\( \\Sigma \\), the dataset \\( S = \\{(x_i, y_i)\\}_{i=1}^n \\) is partitioned into \\(\\{B_t\\}_{t=0}^{T-1}\\) subsets of equal size: \\( \\lvert B_t \\rvert = \\tilde{\\Theta}(n/\\kappa) \\). At each round \\( t \\), the gradients are clipped and averaged with additive Gaussian noise chosen to satisfy \\( (\\epsilon, \\delta) \\)-DP:\n\n\\[ w_{t+1} \\leftarrow w_t - \\eta \\frac{1}{\\lvert B_t \\rvert} \\sum_{i \\in B_t} \\text{clip}_{\\theta_t}(x_i(w_t^\\top x_i - y_i)) + \\theta_t \\sqrt{\\frac{2 \\log(1.25/\\delta)}{\\epsilon \\lvert B_t \\rvert}} \\nu_t, \\quad (1) \\]\nwhere \\( \\nu_t \\sim \\mathcal{N}(0, \\text{Id}) \\). In [81], a slight variation of this streaming SGD is shown to achieve an error of \\( \\frac{1}{\\sigma} \\lVert w^T - w^* \\rVert_\\Sigma = \\alpha \\) with \\( n = \\tilde{O}(d/\\alpha^2 + \\kappa d/(\\epsilon \\alpha) + \\kappa^2 d/\\epsilon) \\) samples (Row 3 in Tab. 1).\n\nOur technical innovations. Our approach builds upon such gradient based methods but makes several important innovations. First, we use full-batch gradient descent, as opposed to the streaming SGD above. Using all \\( n \\) samples reduces the sensitivity of the per-round gradient average by a \\( \\kappa \\) factor, and thus decreases the privacy noise added in each iteration. This improves the second term of sample complexity from \\( \\kappa d/(\\epsilon \\alpha) \\) to \\( \\kappa^{1/2} d/(\\epsilon \\alpha) \\) and removes the third term completely. However, full-batch GD loses the independence that the streaming SGD enjoyed between \\( w_t \\) and the samples used in the round \\( t + 1 \\). This dependence makes the analysis more challenging. We instead propose using the resilience to precisely track the bias and variance of the (dependent) full-batch average gradient. Resilience is a central concept in robust statistics that links the tail-property of the distribution to the bias, which we explain in Sec. 5.\n\nNext, one critical component in achieving this improved sample complexity is the new analysis technique we introduce for tracking the end-to-end gradient updates. Since our gradient descent algorithm is not guaranteed to make progress every step, we cannot use the vanilla one-step analysis.", "md": "The state-of-the-art approach introduced by [81] is based on DP-SGD [71], where privacy is ensured by gradient norm clipping and the Gaussian mechanism. Two additional technical components are adaptive clipping and streaming SGD. Adaptive clipping with an appropriate threshold \\( \\theta_t \\) ensures that no data point is clipped (under the sub-Gaussian assumption), while providing a bound on the sensitivity of the average mini-batch gradient (to ensure we do not add too much noise). The streaming approach, where each data point is only touched once and discarded, ensures independence between the past iterate \\( w_t \\) and the gradients at round \\( t + 1 \\), which the analysis critically relies on. For \\( T = \\tilde{\\Theta}(\\kappa) \\) iterations where \\( \\kappa \\) is the condition number of the covariance \\( \\Sigma \\), the dataset \\( S = \\{(x_i, y_i)\\}_{i=1}^n \\) is partitioned into \\(\\{B_t\\}_{t=0}^{T-1}\\) subsets of equal size: \\( \\lvert B_t \\rvert = \\tilde{\\Theta}(n/\\kappa) \\). At each round \\( t \\), the gradients are clipped and averaged with additive Gaussian noise chosen to satisfy \\( (\\epsilon, \\delta) \\)-DP:\n\n\\[ w_{t+1} \\leftarrow w_t - \\eta \\frac{1}{\\lvert B_t \\rvert} \\sum_{i \\in B_t} \\text{clip}_{\\theta_t}(x_i(w_t^\\top x_i - y_i)) + \\theta_t \\sqrt{\\frac{2 \\log(1.25/\\delta)}{\\epsilon \\lvert B_t \\rvert}} \\nu_t, \\quad (1) \\]\nwhere \\( \\nu_t \\sim \\mathcal{N}(0, \\text{Id}) \\). In [81], a slight variation of this streaming SGD is shown to achieve an error of \\( \\frac{1}{\\sigma} \\lVert w^T - w^* \\rVert_\\Sigma = \\alpha \\) with \\( n = \\tilde{O}(d/\\alpha^2 + \\kappa d/(\\epsilon \\alpha) + \\kappa^2 d/\\epsilon) \\) samples (Row 3 in Tab. 1).\n\nOur technical innovations. Our approach builds upon such gradient based methods but makes several important innovations. First, we use full-batch gradient descent, as opposed to the streaming SGD above. Using all \\( n \\) samples reduces the sensitivity of the per-round gradient average by a \\( \\kappa \\) factor, and thus decreases the privacy noise added in each iteration. This improves the second term of sample complexity from \\( \\kappa d/(\\epsilon \\alpha) \\) to \\( \\kappa^{1/2} d/(\\epsilon \\alpha) \\) and removes the third term completely. However, full-batch GD loses the independence that the streaming SGD enjoyed between \\( w_t \\) and the samples used in the round \\( t + 1 \\). This dependence makes the analysis more challenging. We instead propose using the resilience to precisely track the bias and variance of the (dependent) full-batch average gradient. Resilience is a central concept in robust statistics that links the tail-property of the distribution to the bias, which we explain in Sec. 5.\n\nNext, one critical component in achieving this improved sample complexity is the new analysis technique we introduce for tracking the end-to-end gradient updates. Since our gradient descent algorithm is not guaranteed to make progress every step, we cannot use the vanilla one-step analysis."}]}, {"page": 5, "text": " Taking the full end-to-end analysis by expanding the whole gradient trajectory will introduce too\n many correlated cross-terms which are very hard to control. Therefore, we leverage an every \u03ba-step\n analysis and show that the objective function at least decreases geometrically every \u03ba steps. To be\n more specific, our analysis technique in App. H (steps 3 and 4) opens up the iterative updates from the\n beginning to the end, and exploits the fact that \u03bbmax((\u03b7\u03a3)1/2(1 \u2212    \u03b7\u03a3)i(\u03b7\u03a3)1/2) is upper bounded\n by 1/(i + 1) when \u2225\u03b7\u03a3\u2225    \u2264  1. This technique is critical in achieving the near-optimal dependence in\n \u03ba. This might be of independent interest to other analysis of gradient-based algorithms. We refer to\n the beginning of step 3 in App. H for a detailed explanation.\n Finally, we propose a novel clipping that separately clips xi and (w\u22a4     t xi \u2212  yi) in the gradient,\n(w\u22a4t xi \u2212  yi)xi. This is critical in achieving robustness to label-corruption, as we explain in Sec. 3.1.\n 3   Label-robust and private linear regression\nWe introduce a novel gradient descent approach. This achieves an improved sample complexity\n compared to the state-of-the-art algorithm and robustness against label corruption.\n 3.1  Algorithm\n The skeleton of our approach in Alg. 1 is the general DP-SGD [1, 71] with adaptive clipping [7].\nWe partition the dataset into three equal-sized subsets: S1, S2, S3. S1 and S2 are used in adaptively\n estimating the clipping thresholds, and S3 is re-used every step to compute the average gradient.\n The standard adaptive clipping, e.g., [7, 81], is not robust against label-corruption. Under sub-\n Gaussian distribution, a positive fraction of the covariates, xi\u2019s, can be close to the origin. If the\n adversary chooses to corrupt those points with small norm, \u2225xi\u2225, they can make large changes in the\n corrupted residual, (yi \u2212w\u22a4t xi), while evading the standard clipping by the norm of the gradient; the\n norm of the gradient, \u2225xi(yi \u2212  w\u22a4t xi)\u2225 = \u2225xi\u2225|yi \u2212   w\u22a4t xi|, can remain under the threshold. This is\n problematic, since the bias due to the corrupted samples in the gradient scales proportionally to the\n magnitude of the residual (after clipping). To this end, we propose clipping the norm and the residual\n separately: clip\u0398(xi)clip \u03b8t w\u22a4t xi \u2212  yi . This keeps the sensitivity of gradient average bounded by\n \u0398(\u03b8t). The subsequent Gaussian mechanism in line 11 ensures (\u03b50, \u03b40)-DP at each round. Applying\n advanced composition in Lemma B.5 of T rounds, this ensures end-to-end (\u03b5, \u03b4)-DP.\n Novel adaptive clipping. When clipping with clip    \u0398(xi), the only purpose of clipping the covariate\n by its norm, \u2225xi\u2225, is to bound the sensitivity of the resulting clipped gradient. In particular, we do\n not need to make it robust as there is no corruption in the covariates. Ideally, we want to select\n the smallest threshold \u0398 that does not clip any of the covariates. Since the norm of a covariate is\n upper bounded by \u2225xi\u22252 \u2264      K2Tr(\u03a3) log(1/\u03b6) with probability 1 \u2212      \u03b6 (Lemma J.3), we estimate\n the unknown Tr(\u03a3) using Private Norm Estimator in Alg. 3 in App. F and set the norm threshold\n \u0398 = K     2\u0393 log(n/\u03b6) (Alg. 1 line 4). The n in the logarithm ensures that the union bound holds.\nWhen clipping with clip    \u03b8t(w\u22a4t xi \u2212  yi), the purpose of clipping the residual by its magnitude,\n |yi \u2212 w\u22a4t xi| = |(w\u2217 \u2212  wt)\u22a4xi + zi|, is to bound the sensitivity of the gradient and also to provide\n robustness against label-corruption. We want to choose a threshold that only clips corrupt data points\n and at most a few clean data points. In order to achieve an error (1/\u03c3)\u2225wT \u2212w\u2217\u2225\u03a3 = \u03b1, we know that\n any set of (1 \u2212 \u03b1) fraction of the clean data points is sufficient to get a good estimate of the average\n gradient. By clipping at |(w\u2217 \u2212wt)\u22a4xi + zi|2 \u2264    (\u2225wt \u2212w\u2217\u22252   \u03a3 + \u03c32)CK2 log(1/(2\u03b1)), Lemma J.3\n guarantees that the unclipped subset will be large enough, i.e., (1 \u2212    \u03b1)n. At the same time, this\n threshold on the residual is small enough to guarantee robustness against the label-corrupted samples.\nWe introduce the robust and DP Distance Estimator in Alg. 2 to estimate the unknown (squared and\n shifted) distance, \u2225wt\u2212w\u2217\u22252 \u03a3+\u03c32, and set the distance threshold \u03b8t = 2\u221a2\u03b3t      9C2K2 log(1/(2\u03b1))\n (Alg. 1 line 7). Both norm and distance estimation rely on DP histogram (Lemma B.2), but over a set\n of statistics computed on partitioned datasets, which we explain in detail in App. C.\n                                                    5", "md": "# Document\n\nTaking the full end-to-end analysis by expanding the whole gradient trajectory will introduce too\nmany correlated cross-terms which are very hard to control. Therefore, we leverage an every \u03ba-step\nanalysis and show that the objective function at least decreases geometrically every \u03ba steps. To be\nmore specific, our analysis technique in App. H (steps 3 and 4) opens up the iterative updates from the\nbeginning to the end, and exploits the fact that $$\\lambda_{\\text{max}}((\\eta\\Sigma)^{1/2}(1 - \\eta\\Sigma)^i(\\eta\\Sigma)^{1/2})$$ is upper bounded\nby $$\\frac{1}{(i + 1)}$$ when $$\\|\\eta\\Sigma\\| \\leq 1$$. This technique is critical in achieving the near-optimal dependence in\n\u03ba. This might be of independent interest to other analysis of gradient-based algorithms. We refer to\nthe beginning of step 3 in App. H for a detailed explanation.\nFinally, we propose a novel clipping that separately clips $$x_i$$ and $$(w^T_t x_i - y_i)$$ in the gradient,\n$$(w^T_t x_i - y_i)x_i$$. This is critical in achieving robustness to label-corruption, as we explain in Sec. 3.1.\n\n### Label-robust and private linear regression\n\nWe introduce a novel gradient descent approach. This achieves an improved sample complexity\ncompared to the state-of-the-art algorithm and robustness against label corruption.\n\n### Algorithm\n\nThe skeleton of our approach in Alg. 1 is the general DP-SGD [1, 71] with adaptive clipping [7].\nWe partition the dataset into three equal-sized subsets: S1, S2, S3. S1 and S2 are used in adaptively\nestimating the clipping thresholds, and S3 is re-used every step to compute the average gradient.\nThe standard adaptive clipping, e.g., [7, 81], is not robust against label-corruption. Under sub-\nGaussian distribution, a positive fraction of the covariates, $$x_i$$'s, can be close to the origin. If the\nadversary chooses to corrupt those points with small norm, $$\\|x_i\\|$$, they can make large changes in the\ncorrupted residual, $$(y_i - w^T_t x_i)$$, while evading the standard clipping by the norm of the gradient; the\nnorm of the gradient, $$\\|x_i(y_i - w^T_t x_i)\\| = \\|x_i\\||y_i - w^T_t x_i|$$, can remain under the threshold. This is\nproblematic, since the bias due to the corrupted samples in the gradient scales proportionally to the\nmagnitude of the residual (after clipping). To this end, we propose clipping the norm and the residual\nseparately: $$\\text{clip}_{\\Theta}(x_i)\\text{clip}_{\\theta_t}w^T_t x_i - y_i$$. This keeps the sensitivity of gradient average bounded by\n$$\\Theta(\\theta_t)$$. The subsequent Gaussian mechanism in line 11 ensures $$(\\epsilon_0, \\delta_0)$$-DP at each round. Applying\nadvanced composition in Lemma B.5 of T rounds, this ensures end-to-end $$(\\epsilon, \\delta)$$-DP.\n\nNovel adaptive clipping. When clipping with $$\\text{clip}_{\\Theta}(x_i)$$, the only purpose of clipping the covariate\nby its norm, $$\\|x_i\\|$$, is to bound the sensitivity of the resulting clipped gradient. In particular, we do\nnot need to make it robust as there is no corruption in the covariates. Ideally, we want to select\nthe smallest threshold $$\\Theta$$ that does not clip any of the covariates. Since the norm of a covariate is\nupper bounded by $$\\|x_i\\|^2 \\leq K^2\\text{Tr}(\\Sigma) \\log(1/\\zeta)$$ with probability $$1 - \\zeta$$ (Lemma J.3), we estimate\nthe unknown $$\\text{Tr}(\\Sigma)$$ using Private Norm Estimator in Alg. 3 in App. F and set the norm threshold\n$$\\Theta = K^2\\Gamma \\log(n/\\zeta)$$ (Alg. 1 line 4). The n in the logarithm ensures that the union bound holds.\nWhen clipping with $$\\text{clip}_{\\theta_t}(w^T_t x_i - y_i)$$, the purpose of clipping the residual by its magnitude,\n$$|y_i - w^T_t x_i| = |(w^* - w_t)^Tx_i + z_i|$$, is to bound the sensitivity of the gradient and also to provide\nrobustness against label-corruption. We want to choose a threshold that only clips corrupt data points\nand at most a few clean data points. In order to achieve an error $$(1/\\sigma)\\|w^T - w^*\\|\\Sigma = \\alpha$$, we know that\nany set of $$(1 - \\alpha)$$ fraction of the clean data points is sufficient to get a good estimate of the average\ngradient. By clipping at $$|(w^* - w_t)^Tx_i + z_i|^2 \\leq (\\|w_t - w^*\\|^2 \\Sigma + \\sigma^2)CK^2 \\log(1/(2\\alpha))$$, Lemma J.3\nguarantees that the unclipped subset will be large enough, i.e., $$(1 - \\alpha)n$$. At the same time, this\nthreshold on the residual is small enough to guarantee robustness against the label-corrupted samples.\n\nWe introduce the robust and DP Distance Estimator in Alg. 2 to estimate the unknown (squared and\nshifted) distance, $$\\|w_t - w^*\\|^2 \\Sigma + \\sigma^2$$, and set the distance threshold $$\\theta_t = 2\\sqrt{2}\\gamma_t 9C^2K^2 \\log(1/(2\\alpha))$$\n(Alg. 1 line 7). Both norm and distance estimation rely on DP histogram (Lemma B.2), but over a set\nof statistics computed on partitioned datasets, which we explain in detail in App. C.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "Taking the full end-to-end analysis by expanding the whole gradient trajectory will introduce too\nmany correlated cross-terms which are very hard to control. Therefore, we leverage an every \u03ba-step\nanalysis and show that the objective function at least decreases geometrically every \u03ba steps. To be\nmore specific, our analysis technique in App. H (steps 3 and 4) opens up the iterative updates from the\nbeginning to the end, and exploits the fact that $$\\lambda_{\\text{max}}((\\eta\\Sigma)^{1/2}(1 - \\eta\\Sigma)^i(\\eta\\Sigma)^{1/2})$$ is upper bounded\nby $$\\frac{1}{(i + 1)}$$ when $$\\|\\eta\\Sigma\\| \\leq 1$$. This technique is critical in achieving the near-optimal dependence in\n\u03ba. This might be of independent interest to other analysis of gradient-based algorithms. We refer to\nthe beginning of step 3 in App. H for a detailed explanation.\nFinally, we propose a novel clipping that separately clips $$x_i$$ and $$(w^T_t x_i - y_i)$$ in the gradient,\n$$(w^T_t x_i - y_i)x_i$$. This is critical in achieving robustness to label-corruption, as we explain in Sec. 3.1.", "md": "Taking the full end-to-end analysis by expanding the whole gradient trajectory will introduce too\nmany correlated cross-terms which are very hard to control. Therefore, we leverage an every \u03ba-step\nanalysis and show that the objective function at least decreases geometrically every \u03ba steps. To be\nmore specific, our analysis technique in App. H (steps 3 and 4) opens up the iterative updates from the\nbeginning to the end, and exploits the fact that $$\\lambda_{\\text{max}}((\\eta\\Sigma)^{1/2}(1 - \\eta\\Sigma)^i(\\eta\\Sigma)^{1/2})$$ is upper bounded\nby $$\\frac{1}{(i + 1)}$$ when $$\\|\\eta\\Sigma\\| \\leq 1$$. This technique is critical in achieving the near-optimal dependence in\n\u03ba. This might be of independent interest to other analysis of gradient-based algorithms. We refer to\nthe beginning of step 3 in App. H for a detailed explanation.\nFinally, we propose a novel clipping that separately clips $$x_i$$ and $$(w^T_t x_i - y_i)$$ in the gradient,\n$$(w^T_t x_i - y_i)x_i$$. This is critical in achieving robustness to label-corruption, as we explain in Sec. 3.1."}, {"type": "heading", "lvl": 3, "value": "Label-robust and private linear regression", "md": "### Label-robust and private linear regression"}, {"type": "text", "value": "We introduce a novel gradient descent approach. This achieves an improved sample complexity\ncompared to the state-of-the-art algorithm and robustness against label corruption.", "md": "We introduce a novel gradient descent approach. This achieves an improved sample complexity\ncompared to the state-of-the-art algorithm and robustness against label corruption."}, {"type": "heading", "lvl": 3, "value": "Algorithm", "md": "### Algorithm"}, {"type": "text", "value": "The skeleton of our approach in Alg. 1 is the general DP-SGD [1, 71] with adaptive clipping [7].\nWe partition the dataset into three equal-sized subsets: S1, S2, S3. S1 and S2 are used in adaptively\nestimating the clipping thresholds, and S3 is re-used every step to compute the average gradient.\nThe standard adaptive clipping, e.g., [7, 81], is not robust against label-corruption. Under sub-\nGaussian distribution, a positive fraction of the covariates, $$x_i$$'s, can be close to the origin. If the\nadversary chooses to corrupt those points with small norm, $$\\|x_i\\|$$, they can make large changes in the\ncorrupted residual, $$(y_i - w^T_t x_i)$$, while evading the standard clipping by the norm of the gradient; the\nnorm of the gradient, $$\\|x_i(y_i - w^T_t x_i)\\| = \\|x_i\\||y_i - w^T_t x_i|$$, can remain under the threshold. This is\nproblematic, since the bias due to the corrupted samples in the gradient scales proportionally to the\nmagnitude of the residual (after clipping). To this end, we propose clipping the norm and the residual\nseparately: $$\\text{clip}_{\\Theta}(x_i)\\text{clip}_{\\theta_t}w^T_t x_i - y_i$$. This keeps the sensitivity of gradient average bounded by\n$$\\Theta(\\theta_t)$$. The subsequent Gaussian mechanism in line 11 ensures $$(\\epsilon_0, \\delta_0)$$-DP at each round. Applying\nadvanced composition in Lemma B.5 of T rounds, this ensures end-to-end $$(\\epsilon, \\delta)$$-DP.\n\nNovel adaptive clipping. When clipping with $$\\text{clip}_{\\Theta}(x_i)$$, the only purpose of clipping the covariate\nby its norm, $$\\|x_i\\|$$, is to bound the sensitivity of the resulting clipped gradient. In particular, we do\nnot need to make it robust as there is no corruption in the covariates. Ideally, we want to select\nthe smallest threshold $$\\Theta$$ that does not clip any of the covariates. Since the norm of a covariate is\nupper bounded by $$\\|x_i\\|^2 \\leq K^2\\text{Tr}(\\Sigma) \\log(1/\\zeta)$$ with probability $$1 - \\zeta$$ (Lemma J.3), we estimate\nthe unknown $$\\text{Tr}(\\Sigma)$$ using Private Norm Estimator in Alg. 3 in App. F and set the norm threshold\n$$\\Theta = K^2\\Gamma \\log(n/\\zeta)$$ (Alg. 1 line 4). The n in the logarithm ensures that the union bound holds.\nWhen clipping with $$\\text{clip}_{\\theta_t}(w^T_t x_i - y_i)$$, the purpose of clipping the residual by its magnitude,\n$$|y_i - w^T_t x_i| = |(w^* - w_t)^Tx_i + z_i|$$, is to bound the sensitivity of the gradient and also to provide\nrobustness against label-corruption. We want to choose a threshold that only clips corrupt data points\nand at most a few clean data points. In order to achieve an error $$(1/\\sigma)\\|w^T - w^*\\|\\Sigma = \\alpha$$, we know that\nany set of $$(1 - \\alpha)$$ fraction of the clean data points is sufficient to get a good estimate of the average\ngradient. By clipping at $$|(w^* - w_t)^Tx_i + z_i|^2 \\leq (\\|w_t - w^*\\|^2 \\Sigma + \\sigma^2)CK^2 \\log(1/(2\\alpha))$$, Lemma J.3\nguarantees that the unclipped subset will be large enough, i.e., $$(1 - \\alpha)n$$. At the same time, this\nthreshold on the residual is small enough to guarantee robustness against the label-corrupted samples.\n\nWe introduce the robust and DP Distance Estimator in Alg. 2 to estimate the unknown (squared and\nshifted) distance, $$\\|w_t - w^*\\|^2 \\Sigma + \\sigma^2$$, and set the distance threshold $$\\theta_t = 2\\sqrt{2}\\gamma_t 9C^2K^2 \\log(1/(2\\alpha))$$\n(Alg. 1 line 7). Both norm and distance estimation rely on DP histogram (Lemma B.2), but over a set\nof statistics computed on partitioned datasets, which we explain in detail in App. C.", "md": "The skeleton of our approach in Alg. 1 is the general DP-SGD [1, 71] with adaptive clipping [7].\nWe partition the dataset into three equal-sized subsets: S1, S2, S3. S1 and S2 are used in adaptively\nestimating the clipping thresholds, and S3 is re-used every step to compute the average gradient.\nThe standard adaptive clipping, e.g., [7, 81], is not robust against label-corruption. Under sub-\nGaussian distribution, a positive fraction of the covariates, $$x_i$$'s, can be close to the origin. If the\nadversary chooses to corrupt those points with small norm, $$\\|x_i\\|$$, they can make large changes in the\ncorrupted residual, $$(y_i - w^T_t x_i)$$, while evading the standard clipping by the norm of the gradient; the\nnorm of the gradient, $$\\|x_i(y_i - w^T_t x_i)\\| = \\|x_i\\||y_i - w^T_t x_i|$$, can remain under the threshold. This is\nproblematic, since the bias due to the corrupted samples in the gradient scales proportionally to the\nmagnitude of the residual (after clipping). To this end, we propose clipping the norm and the residual\nseparately: $$\\text{clip}_{\\Theta}(x_i)\\text{clip}_{\\theta_t}w^T_t x_i - y_i$$. This keeps the sensitivity of gradient average bounded by\n$$\\Theta(\\theta_t)$$. The subsequent Gaussian mechanism in line 11 ensures $$(\\epsilon_0, \\delta_0)$$-DP at each round. Applying\nadvanced composition in Lemma B.5 of T rounds, this ensures end-to-end $$(\\epsilon, \\delta)$$-DP.\n\nNovel adaptive clipping. When clipping with $$\\text{clip}_{\\Theta}(x_i)$$, the only purpose of clipping the covariate\nby its norm, $$\\|x_i\\|$$, is to bound the sensitivity of the resulting clipped gradient. In particular, we do\nnot need to make it robust as there is no corruption in the covariates. Ideally, we want to select\nthe smallest threshold $$\\Theta$$ that does not clip any of the covariates. Since the norm of a covariate is\nupper bounded by $$\\|x_i\\|^2 \\leq K^2\\text{Tr}(\\Sigma) \\log(1/\\zeta)$$ with probability $$1 - \\zeta$$ (Lemma J.3), we estimate\nthe unknown $$\\text{Tr}(\\Sigma)$$ using Private Norm Estimator in Alg. 3 in App. F and set the norm threshold\n$$\\Theta = K^2\\Gamma \\log(n/\\zeta)$$ (Alg. 1 line 4). The n in the logarithm ensures that the union bound holds.\nWhen clipping with $$\\text{clip}_{\\theta_t}(w^T_t x_i - y_i)$$, the purpose of clipping the residual by its magnitude,\n$$|y_i - w^T_t x_i| = |(w^* - w_t)^Tx_i + z_i|$$, is to bound the sensitivity of the gradient and also to provide\nrobustness against label-corruption. We want to choose a threshold that only clips corrupt data points\nand at most a few clean data points. In order to achieve an error $$(1/\\sigma)\\|w^T - w^*\\|\\Sigma = \\alpha$$, we know that\nany set of $$(1 - \\alpha)$$ fraction of the clean data points is sufficient to get a good estimate of the average\ngradient. By clipping at $$|(w^* - w_t)^Tx_i + z_i|^2 \\leq (\\|w_t - w^*\\|^2 \\Sigma + \\sigma^2)CK^2 \\log(1/(2\\alpha))$$, Lemma J.3\nguarantees that the unclipped subset will be large enough, i.e., $$(1 - \\alpha)n$$. At the same time, this\nthreshold on the residual is small enough to guarantee robustness against the label-corrupted samples.\n\nWe introduce the robust and DP Distance Estimator in Alg. 2 to estimate the unknown (squared and\nshifted) distance, $$\\|w_t - w^*\\|^2 \\Sigma + \\sigma^2$$, and set the distance threshold $$\\theta_t = 2\\sqrt{2}\\gamma_t 9C^2K^2 \\log(1/(2\\alpha))$$\n(Alg. 1 line 7). Both norm and distance estimation rely on DP histogram (Lemma B.2), but over a set\nof statistics computed on partitioned datasets, which we explain in detail in App. C."}]}, {"page": 6, "text": "     Algorithm 1: Robust and Private Linear Regression\n     Input: S = {(xi, yi)}3n          i=1, DP parameters (\u03b5, \u03b4), T             , learning rate \u03b7, failure probability \u03b6, target\n                error \u03b1, distribution parameter K\n  1 Partition dataset S into three equal sized disjoint subsets S = S1 \u222a                              S2 \u222a    S3.\n               \u03b4                      \u03b5\n  2 \u03b40 \u2190      2T , \u03b50 \u2190                                    3, w0 \u2190       0\n                             4\u221aT log(1/\u03b40), \u03b60 \u2190           \u03b6\n  3 \u0393 \u2190      PrivateNormEstimator(S1, \u03b50, \u03b40, \u03b60)                                                  // using Alg. 3, App. F\n  4 \u0398 \u2190      K  \u221a  2\u0393 loga(n/\u03b60)\n  5 for t = 0, 1, 2, . . . , T \u2212        1 do\n  6       \u03b3t \u2190     PrivateDistanceEstimator(S2, wt, \u03b50, \u03b40, \u03b1, \u03b60)                                 // using Alg. 2, App. C\n  7       \u03b8t \u2190     2\u221a2\u03b3t \u00b7         9C2K2 log(1/(2\u03b1)).\n  8       Sample \u03bdt \u223c         N (0, Id)\n  9       \u02dc\n          g(t)   \u2190   clip\u0398(xi)clip\u03b8t(x\u22a4        i wt \u2212     yi)\n10        \u03d5ti= (     2 log(1.25/\u03b40)\u0398\u03b8t)/(\u03b50n)\n11        wt+1 \u2190       wt \u2212     \u03b7    1            g(t)  + \u03d5t\u03bdt\n12 Return wT                         n     i\u2208S3 \u02dc   i\n     3.2     Analysis without adversarial corruption\n    We show that Alg. 1 achieves an improved sample complexity. We provide the proof for a more\n     general class of distributions in App. H and a sketch of the proof in Sec. 5. We address the necessity\n     of the assumptions in Sec. 3.4, along with some lower bounds.\n     Theorem 3.1. Alg. 1 is (\u03b5, \u03b4)-DP. Under sub-Gaussian model of Asmp. 2.1, for any failure probability\n     \u03b6 \u2208   (0, 1) and target error rate \u03b1, if the sample size is large enough such that\n                                 \uf8eb                                                     K2dT 1/2 log( 1      \u03b4 )    log( 1\u03b6 ) \uf8f6\n                       n = \u02dc  O  \uf8edK2d log2  1             + d + log(1/\u03b6)           +                                         \uf8f8   ,              (2)\n                                                     \u03b6                \u03b12                                \u03b5\u03b1\n     with a large enough constant, then the choices of a step size \u03b7 = 1/(C\u03bbmax(\u03a3)) for any C \u2265                                                 1.1\n     and the number of iterations, T = \u02dc                   \u0398 (\u03ba log (\u2225w\u2217\u2225)) for a condition number of the covariance\n     \u03ba := \u03bbmax(\u03a3)/\u03bbmin(\u03a3), ensures that, with probability 1 \u2212                              \u03b6, Alg. 1 achieves\n                              E\u03bd1,\u00b7\u00b7\u00b7 ,\u03bdT \u223cN (0,Id)       \u2225wT \u2212      w\u2217\u22252  \u03a3    = \u02dc O     K4\u03c32\u03b12 log2            1        ,                     (3)\n                                                                                                                 \u03b1\n     where the expectation is taken over the noise added for DP, and \u02dc                            O and \u02dc   \u0398(\u00b7) hide logarithmic terms\n     in K, \u03c3, d, n, 1/\u03b5, log(1/\u03b4), 1/\u03b1, and \u03ba.\n     Remark 3.2. Omitting some constant and logarithmic terms, Alg. 1 requires\n                                                        n     =     O\u02dc     d                    ,                                               (4)\n                                                                          \u03b12 + \u03ba1/2d  \u03b5\u03b1\n     samples to ensure an error rate of (1/\u03c32)E[\u2225wT \u2212                         w\u2217\u22252  \u03a3] = \u02dc   O(\u03b12). From [16, Theorem 3.1], there\n     exists an n = \u2126(d/\u03b12 + d/(\u03b5\u03b1)) lower bound, and our upper bound matches this lower bound up\n     to a factor of \u03ba1/2 in the second term and other logarithmic factors. Eq. (4) is the best known rate\n     among all efficient private linear regression algorithms, strictly improving upon the state-of-the-art.\n     The best existing efficient algorithm by [81] requires n = \u02dc                        O(d/\u03b12 + \u03bad/(\u03b5\u03b1) + \u03ba2d/\u03b5) to achieve\n     the same error rate. Compared to Eq. (4), the second term is larger by a factor of \u03ba1/2 compared to\n     the second term in Eq. (4). Further, [81] requires \u03ba2d/\u03b5, which is not needed in Eq. (4).\n     Remark 3.3. Consider the standard settings of linear regression with xi \u223c                                          N  (0, Id) and zi \u223c\n     N  (0, \u03c32) such that the condition number is one, our bound given by Eq. (4) nearly matches the lower\n     bound ([16, Theorem 3.1]) up to logarithmic factors.\n     Remark 3.4. Note that the leading term in Eq. (4) is the first term d/\u03b12 when target error \u03b1 \u2264                                       \u03b5/\u03ba1/2.\n     Our first term is independent of \u03ba, which matches the lower bound for non-private linear regression.\n                                                                           6", "md": "# Robust and Private Linear Regression\n\n## Algorithm 1: Robust and Private Linear Regression\n\nInput: \\(S = \\{(x_i, y_i)\\}_{i=1}^n\\), DP parameters \\((\\varepsilon, \\delta)\\), \\(T\\), learning rate \\(\\eta\\), failure probability \\(\\zeta\\), target error \\(\\alpha\\), distribution parameter \\(K\\)\n\n1. Partition dataset \\(S\\) into three equal sized disjoint subsets \\(S = S_1 \\cup S_2 \\cup S_3\\).\n2. \\(\\delta_0 \\leftarrow 2T\\), \\(\\varepsilon_0 \\leftarrow 3\\), \\(w_0 \\leftarrow 0\\)\n3. \\(\\Gamma \\leftarrow \\text{PrivateNormEstimator}(S_1, \\varepsilon_0, \\delta_0, \\zeta_0)\\) // using Alg. 3, App. F\n4. \\(\\Theta \\leftarrow K \\sqrt{2\\Gamma \\log\\frac{n}{\\zeta_0}}\\)\n5. for \\(t = 0, 1, 2, ..., T - 1\\) do\n6. 1. \\(\\gamma_t \\leftarrow \\text{PrivateDistanceEstimator}(S_2, w_t, \\varepsilon_0, \\delta_0, \\alpha, \\zeta_0)\\) // using Alg. 2, App. C\n2. \\(\\theta_t \\leftarrow 2\\sqrt{2\\gamma_t} \\cdot 9C^2K^2 \\log\\frac{1}{2\\alpha}\\)\n3. Sample \\(\\nu_t \\sim \\mathcal{N}(0, I_d)\\)\n4. \\(\\tilde{g}(t) \\leftarrow \\text{clip}_{\\Theta}(x_i) \\text{clip}_{\\theta_t}(x_i^\\top w_t - y_i)\\)\n5. \\(\\varphi_{t,i} = \\frac{2\\log(1.25/\\delta_0)\\Theta\\theta_t}{\\varepsilon_0n}\\)\n6. \\(w_{t+1} \\leftarrow w_t - \\eta \\frac{1}{n} \\sum_{i \\in S_3} \\tilde{g}(t) + \\varphi_t\\nu_t\\)\n\nReturn \\(w_T\\)\n\n### Analysis without adversarial corruption\n\nWe show that Alg. 1 achieves an improved sample complexity. We provide the proof for a more general class of distributions in App. H and a sketch of the proof in Sec. 5. We address the necessity of the assumptions in Sec. 3.4, along with some lower bounds.\n\nTheorem 3.1. Alg. 1 is \\((\\varepsilon, \\delta)\\)-DP. Under sub-Gaussian model of Asmp. 2.1, for any failure probability \\(\\zeta \\in (0, 1)\\) and target error rate \\(\\alpha\\), if the sample size is large enough such that\n\n$$n = \\tilde{O}\\left(\\frac{K^2d\\Theta^{1/2}\\log\\left(\\frac{1}{\\delta}\\right)\\log\\left(\\frac{1}{\\zeta}\\right)}{\\zeta\\alpha^2\\epsilon\\alpha}\\right),$$\nwith a large enough constant, then the choices of a step size \\(\\eta = \\frac{1}{C\\lambda_{\\text{max}}(\\Sigma)}\\) for any \\(C \\geq 1.1\\) and the number of iterations, \\(T = \\tilde{O}\\left(\\Theta(\\kappa \\log(\\|w^*\\|))\\right)\\) for a condition number of the covariance \\(\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)\\), ensures that, with probability \\(1 - \\zeta\\), Alg. 1 achieves\n\n$$E_{\\nu_1,\\ldots,\\nu_T \\sim \\mathcal{N}(0,I_d)} \\left\\|w_T - w^*\\right\\|_2 \\Sigma = \\tilde{O}\\left(K^4\\sigma^2\\alpha^2\\log^2\\frac{1}{\\alpha}\\right),$$\nwhere the expectation is taken over the noise added for DP, and \\(\\tilde{O}\\) and \\(\\tilde{\\Theta}(\\cdot)\\) hide logarithmic terms in \\(K\\), \\(\\sigma\\), \\(d\\), \\(n\\), \\(1/\\epsilon\\), \\(\\log(1/\\delta)\\), \\(1/\\alpha\\), and \\(\\kappa\\).\n\nRemark 3.2. Omitting some constant and logarithmic terms, Alg. 1 requires\n\n$$n = O\\tilde{O}\\left(\\frac{d}{\\alpha^2 + \\kappa^{1/2}d\\epsilon\\alpha}\\right),$$\nsamples to ensure an error rate of \\(\\left(\\frac{1}{\\sigma^2}\\right)E\\left[\\left\\|w_T - w^*\\right\\|_2 \\Sigma\\right] = \\tilde{O}(\\alpha^2)\\). From [16, Theorem 3.1], there exists an \\(n = \\Omega(d/\\alpha^2 + d/(\\epsilon\\alpha))\\) lower bound, and our upper bound matches this lower bound up to a factor of \\(\\kappa^{1/2}\\) in the second term and other logarithmic factors. Eq. (4) is the best known rate among all efficient private linear regression algorithms, strictly improving upon the state-of-the-art.\n\nRemark 3.3. Consider the standard settings of linear regression with \\(x_i \\sim \\mathcal{N}(0, I_d)\\) and \\(z_i \\sim \\mathcal{N}(0, \\sigma^2)\\) such that the condition number is one, our bound given by Eq. (4) nearly matches the lower bound ([16, Theorem 3.1]) up to logarithmic factors.\n\nRemark 3.4. Note that the leading term in Eq. (4) is the first term \\(d/\\alpha^2\\) when target error \\(\\alpha \\leq \\epsilon/\\kappa^{1/2}\\). Our first term is independent of \\(\\kappa\\), which matches the lower bound for non-private linear regression.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Robust and Private Linear Regression", "md": "# Robust and Private Linear Regression"}, {"type": "heading", "lvl": 2, "value": "Algorithm 1: Robust and Private Linear Regression", "md": "## Algorithm 1: Robust and Private Linear Regression"}, {"type": "text", "value": "Input: \\(S = \\{(x_i, y_i)\\}_{i=1}^n\\), DP parameters \\((\\varepsilon, \\delta)\\), \\(T\\), learning rate \\(\\eta\\), failure probability \\(\\zeta\\), target error \\(\\alpha\\), distribution parameter \\(K\\)\n\n1. Partition dataset \\(S\\) into three equal sized disjoint subsets \\(S = S_1 \\cup S_2 \\cup S_3\\).\n2. \\(\\delta_0 \\leftarrow 2T\\), \\(\\varepsilon_0 \\leftarrow 3\\), \\(w_0 \\leftarrow 0\\)\n3. \\(\\Gamma \\leftarrow \\text{PrivateNormEstimator}(S_1, \\varepsilon_0, \\delta_0, \\zeta_0)\\) // using Alg. 3, App. F\n4. \\(\\Theta \\leftarrow K \\sqrt{2\\Gamma \\log\\frac{n}{\\zeta_0}}\\)\n5. for \\(t = 0, 1, 2, ..., T - 1\\) do\n6. 1. \\(\\gamma_t \\leftarrow \\text{PrivateDistanceEstimator}(S_2, w_t, \\varepsilon_0, \\delta_0, \\alpha, \\zeta_0)\\) // using Alg. 2, App. C\n2. \\(\\theta_t \\leftarrow 2\\sqrt{2\\gamma_t} \\cdot 9C^2K^2 \\log\\frac{1}{2\\alpha}\\)\n3. Sample \\(\\nu_t \\sim \\mathcal{N}(0, I_d)\\)\n4. \\(\\tilde{g}(t) \\leftarrow \\text{clip}_{\\Theta}(x_i) \\text{clip}_{\\theta_t}(x_i^\\top w_t - y_i)\\)\n5. \\(\\varphi_{t,i} = \\frac{2\\log(1.25/\\delta_0)\\Theta\\theta_t}{\\varepsilon_0n}\\)\n6. \\(w_{t+1} \\leftarrow w_t - \\eta \\frac{1}{n} \\sum_{i \\in S_3} \\tilde{g}(t) + \\varphi_t\\nu_t\\)\n\nReturn \\(w_T\\)", "md": "Input: \\(S = \\{(x_i, y_i)\\}_{i=1}^n\\), DP parameters \\((\\varepsilon, \\delta)\\), \\(T\\), learning rate \\(\\eta\\), failure probability \\(\\zeta\\), target error \\(\\alpha\\), distribution parameter \\(K\\)\n\n1. Partition dataset \\(S\\) into three equal sized disjoint subsets \\(S = S_1 \\cup S_2 \\cup S_3\\).\n2. \\(\\delta_0 \\leftarrow 2T\\), \\(\\varepsilon_0 \\leftarrow 3\\), \\(w_0 \\leftarrow 0\\)\n3. \\(\\Gamma \\leftarrow \\text{PrivateNormEstimator}(S_1, \\varepsilon_0, \\delta_0, \\zeta_0)\\) // using Alg. 3, App. F\n4. \\(\\Theta \\leftarrow K \\sqrt{2\\Gamma \\log\\frac{n}{\\zeta_0}}\\)\n5. for \\(t = 0, 1, 2, ..., T - 1\\) do\n6. 1. \\(\\gamma_t \\leftarrow \\text{PrivateDistanceEstimator}(S_2, w_t, \\varepsilon_0, \\delta_0, \\alpha, \\zeta_0)\\) // using Alg. 2, App. C\n2. \\(\\theta_t \\leftarrow 2\\sqrt{2\\gamma_t} \\cdot 9C^2K^2 \\log\\frac{1}{2\\alpha}\\)\n3. Sample \\(\\nu_t \\sim \\mathcal{N}(0, I_d)\\)\n4. \\(\\tilde{g}(t) \\leftarrow \\text{clip}_{\\Theta}(x_i) \\text{clip}_{\\theta_t}(x_i^\\top w_t - y_i)\\)\n5. \\(\\varphi_{t,i} = \\frac{2\\log(1.25/\\delta_0)\\Theta\\theta_t}{\\varepsilon_0n}\\)\n6. \\(w_{t+1} \\leftarrow w_t - \\eta \\frac{1}{n} \\sum_{i \\in S_3} \\tilde{g}(t) + \\varphi_t\\nu_t\\)\n\nReturn \\(w_T\\)"}, {"type": "heading", "lvl": 3, "value": "Analysis without adversarial corruption", "md": "### Analysis without adversarial corruption"}, {"type": "text", "value": "We show that Alg. 1 achieves an improved sample complexity. We provide the proof for a more general class of distributions in App. H and a sketch of the proof in Sec. 5. We address the necessity of the assumptions in Sec. 3.4, along with some lower bounds.\n\nTheorem 3.1. Alg. 1 is \\((\\varepsilon, \\delta)\\)-DP. Under sub-Gaussian model of Asmp. 2.1, for any failure probability \\(\\zeta \\in (0, 1)\\) and target error rate \\(\\alpha\\), if the sample size is large enough such that\n\n$$n = \\tilde{O}\\left(\\frac{K^2d\\Theta^{1/2}\\log\\left(\\frac{1}{\\delta}\\right)\\log\\left(\\frac{1}{\\zeta}\\right)}{\\zeta\\alpha^2\\epsilon\\alpha}\\right),$$\nwith a large enough constant, then the choices of a step size \\(\\eta = \\frac{1}{C\\lambda_{\\text{max}}(\\Sigma)}\\) for any \\(C \\geq 1.1\\) and the number of iterations, \\(T = \\tilde{O}\\left(\\Theta(\\kappa \\log(\\|w^*\\|))\\right)\\) for a condition number of the covariance \\(\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)\\), ensures that, with probability \\(1 - \\zeta\\), Alg. 1 achieves\n\n$$E_{\\nu_1,\\ldots,\\nu_T \\sim \\mathcal{N}(0,I_d)} \\left\\|w_T - w^*\\right\\|_2 \\Sigma = \\tilde{O}\\left(K^4\\sigma^2\\alpha^2\\log^2\\frac{1}{\\alpha}\\right),$$\nwhere the expectation is taken over the noise added for DP, and \\(\\tilde{O}\\) and \\(\\tilde{\\Theta}(\\cdot)\\) hide logarithmic terms in \\(K\\), \\(\\sigma\\), \\(d\\), \\(n\\), \\(1/\\epsilon\\), \\(\\log(1/\\delta)\\), \\(1/\\alpha\\), and \\(\\kappa\\).\n\nRemark 3.2. Omitting some constant and logarithmic terms, Alg. 1 requires\n\n$$n = O\\tilde{O}\\left(\\frac{d}{\\alpha^2 + \\kappa^{1/2}d\\epsilon\\alpha}\\right),$$\nsamples to ensure an error rate of \\(\\left(\\frac{1}{\\sigma^2}\\right)E\\left[\\left\\|w_T - w^*\\right\\|_2 \\Sigma\\right] = \\tilde{O}(\\alpha^2)\\). From [16, Theorem 3.1], there exists an \\(n = \\Omega(d/\\alpha^2 + d/(\\epsilon\\alpha))\\) lower bound, and our upper bound matches this lower bound up to a factor of \\(\\kappa^{1/2}\\) in the second term and other logarithmic factors. Eq. (4) is the best known rate among all efficient private linear regression algorithms, strictly improving upon the state-of-the-art.\n\nRemark 3.3. Consider the standard settings of linear regression with \\(x_i \\sim \\mathcal{N}(0, I_d)\\) and \\(z_i \\sim \\mathcal{N}(0, \\sigma^2)\\) such that the condition number is one, our bound given by Eq. (4) nearly matches the lower bound ([16, Theorem 3.1]) up to logarithmic factors.\n\nRemark 3.4. Note that the leading term in Eq. (4) is the first term \\(d/\\alpha^2\\) when target error \\(\\alpha \\leq \\epsilon/\\kappa^{1/2}\\). Our first term is independent of \\(\\kappa\\), which matches the lower bound for non-private linear regression.", "md": "We show that Alg. 1 achieves an improved sample complexity. We provide the proof for a more general class of distributions in App. H and a sketch of the proof in Sec. 5. We address the necessity of the assumptions in Sec. 3.4, along with some lower bounds.\n\nTheorem 3.1. Alg. 1 is \\((\\varepsilon, \\delta)\\)-DP. Under sub-Gaussian model of Asmp. 2.1, for any failure probability \\(\\zeta \\in (0, 1)\\) and target error rate \\(\\alpha\\), if the sample size is large enough such that\n\n$$n = \\tilde{O}\\left(\\frac{K^2d\\Theta^{1/2}\\log\\left(\\frac{1}{\\delta}\\right)\\log\\left(\\frac{1}{\\zeta}\\right)}{\\zeta\\alpha^2\\epsilon\\alpha}\\right),$$\nwith a large enough constant, then the choices of a step size \\(\\eta = \\frac{1}{C\\lambda_{\\text{max}}(\\Sigma)}\\) for any \\(C \\geq 1.1\\) and the number of iterations, \\(T = \\tilde{O}\\left(\\Theta(\\kappa \\log(\\|w^*\\|))\\right)\\) for a condition number of the covariance \\(\\kappa := \\lambda_{\\text{max}}(\\Sigma)/\\lambda_{\\text{min}}(\\Sigma)\\), ensures that, with probability \\(1 - \\zeta\\), Alg. 1 achieves\n\n$$E_{\\nu_1,\\ldots,\\nu_T \\sim \\mathcal{N}(0,I_d)} \\left\\|w_T - w^*\\right\\|_2 \\Sigma = \\tilde{O}\\left(K^4\\sigma^2\\alpha^2\\log^2\\frac{1}{\\alpha}\\right),$$\nwhere the expectation is taken over the noise added for DP, and \\(\\tilde{O}\\) and \\(\\tilde{\\Theta}(\\cdot)\\) hide logarithmic terms in \\(K\\), \\(\\sigma\\), \\(d\\), \\(n\\), \\(1/\\epsilon\\), \\(\\log(1/\\delta)\\), \\(1/\\alpha\\), and \\(\\kappa\\).\n\nRemark 3.2. Omitting some constant and logarithmic terms, Alg. 1 requires\n\n$$n = O\\tilde{O}\\left(\\frac{d}{\\alpha^2 + \\kappa^{1/2}d\\epsilon\\alpha}\\right),$$\nsamples to ensure an error rate of \\(\\left(\\frac{1}{\\sigma^2}\\right)E\\left[\\left\\|w_T - w^*\\right\\|_2 \\Sigma\\right] = \\tilde{O}(\\alpha^2)\\). From [16, Theorem 3.1], there exists an \\(n = \\Omega(d/\\alpha^2 + d/(\\epsilon\\alpha))\\) lower bound, and our upper bound matches this lower bound up to a factor of \\(\\kappa^{1/2}\\) in the second term and other logarithmic factors. Eq. (4) is the best known rate among all efficient private linear regression algorithms, strictly improving upon the state-of-the-art.\n\nRemark 3.3. Consider the standard settings of linear regression with \\(x_i \\sim \\mathcal{N}(0, I_d)\\) and \\(z_i \\sim \\mathcal{N}(0, \\sigma^2)\\) such that the condition number is one, our bound given by Eq. (4) nearly matches the lower bound ([16, Theorem 3.1]) up to logarithmic factors.\n\nRemark 3.4. Note that the leading term in Eq. (4) is the first term \\(d/\\alpha^2\\) when target error \\(\\alpha \\leq \\epsilon/\\kappa^{1/2}\\). Our first term is independent of \\(\\kappa\\), which matches the lower bound for non-private linear regression."}]}, {"page": 7, "text": "Remark 3.5. The third term \u03ba2d/\u03b5 in [81] is independent of error rate \u03b1 but scales as \u03ba2. This term\nis required to ensure the privacy noise added in each iteration is small enough for their DP-SGD\nto make progress (Appendix. B.2.2 in [81]). Our algorithm is based on full-batch gradient descent,\nwhich uses all n samples and thus reduces the sensitivity of gradient average by a \u03ba factor. As a result,\nwe show in Eq. (59) that our algorithm only requires n = \u02dc   O((1/\u03b5)    \u03ba1/2d/\u03b1) to make progress for\neach iteration. This is strictly smaller than our dominant term \u03ba1/2d/(\u03b5\u03b1) and does not show up in\nour final guarantee. We provide a formal proof in App. H.\nRemark 3.6. One of the key innovations in Alg. 1 is the adaptive distance estimator (Alg. 2 in App. C).\nThe goal is to privately estimate the (shifted) distance of the current estimate, i.e., \u2225wt \u2212w\u2217\u2225\u03a3 + \u03c32,\nwithout the knowledge of w\u2217. We show in Thm. C.1 that our novel distance estimator only requires\nan error-independent sample complexity n = \u02dc    O(\u03ba1/2  d/\u03b5) to achieve a constant multiplicative error.\nNote that the DP-STAT (Algorithm 3 in [81]) can also be used to estimate the distance. But it requires\nthe knowledge of domain size \u2225w\u2217\u2225\u03a3 + \u03c3. We completely remove this requirement, improve the\ndependence on K and log(n), and show it is also robust, as introduced in the next section. We provide\nthe algorithms and analysis in App. C and the formal proof in App. D.\n3.3   Robustness against label corruption\nWe assume there exists a good dataset Sgood that satisfies Asmp. 2.1. We only get access to a label-\ncorrupted dataset under the standard definition of label corruption, e.g., [15]. There are variations in\nliterature on the definition, which we survey in App. A.\nAssumption 3.7 (\u03b1corrupt-corruption). Given a dataset Sgood = {(xi, yi)}n     i=1, an adversary inspects\nall the data points, selects \u03b1corruptn data points denoted as Sr, and replaces the labels with arbitrary\nlabels while keeping the covariates unchanged. We let Sbad denote this set of \u03b1corruptn newly\nlabelled examples by the adversary. Let the resulting set be Scorrupt := Sgood \u222a     Sbad \\ Sr.\nOur goal is to estimate the unknown parameter w\u2217, given corrupted dataset Scorrupt, distribution\nparameter K, and (an upper bound on) the corruption level \u03b1corrupt.\nUnder the non-private scenario, i.e., \u03b5 = \u221e, recent advances led to optimal algorithms for linear\nregression that are robust to label corruptions [15, 21]; if the corruption level is smaller than the\ntarget error rate, i.e., \u03b1corrupt \u2264\u03b1, then n = \u02dc\n                                               O(d/\u03b12) samples are sufficient to achieve an error rate\nof (1/\u03c3)\u2225 w\u02c6\u2212   w\u2217\u2225\u03a3 = \u03b1. The sample complexity of d/\u03b12 is optimal as it matches the information\ntheoretic lower bound. The condition \u03b1corrupt \u2264     \u03b1 is necessary since it is information theoretically\nimpossible to achieve error \u03b1 less than \u03b1corrupt, as we prove in Prop. 3.9. Setting the target error to\nthe minimum possible value of \u03b1 = \u03b1corrupt, we say that these algorithms achieve optimal robustness\nsince the minimum robust error rate of (1/\u03c3)\u2225      w\u02c6\u2212   w\u2217\u2225\u03a3 = O(\u03b1corrupt) can be achieved with\nminimal sample complexity of n = \u02dc      O(d/\u03b12 corrupt). We aim to achieve such optimal robustness\nsimultaneously with differential privacy in a computationally efficient manner.\nTheorem 3.8. Under sub-Gaussian model of Asmp. 2.1 and \u03b1corrupt-corruption of Asmp. 3.7, if\nthe corruption level is below the target error rate, \u03b1 \u2265   \u03b1corrupt, then n = \u02dc O(d/\u03b12 + \u03ba1/2d/(\u03b5\u03b1))\nsamples are sufficient for Alg. 1 to achieve an error rate of (1/\u03c32)E[\u2225  w\u02c6\u2212   w\u2217\u22252\u03a3] = \u02dcO(\u03b12).\nThis is the first efficient approach to achieve robustness and (\u03b5, \u03b4)-DP simultaneously. The existing\nsuch algorithms take exponential time [61, Corollary C.2] and [10], but achieve optimal sample\ncomplexity of n = O(d/\u03b12 + d/(\u03b5\u03b1)). Notice that there is no dependence on \u03ba. It remains an open\nquestion if computationally efficient private linear regression algorithms can achieve such an optimal\n\u03ba-independent sample complexity. We make the first advance towards this ambitious goal with the\nabove theorem. Our sample complexity is sub-optimal only by a factor of \u221a\u03ba in the second term.\nThis is achieved by individually clipping the covariate, xi, and the residual, (w\u22a4 t xi \u2212  yi), in Alg. 1\nand carefully tracking the bias of clipping with the use of resilience in the analysis in App. H.\n3.4   Lower bounds\nNecessity of our assumptions. A tail assumption on the covariate xi such as Asmp. 2.1 is necessary\nto achieve n = O(d) sample complexity in Eq. (4). Even when the covariance \u03a3 is close to\nidentity, without further assumptions on the tail of covariate x, the result in [13] implies that for\n\u03b4 < 1/n, it is necessary for an (\u03b5, \u03b4)-DP estimator to have n = \u2126(d3/2/(\u03b5\u03b1)) samples to achieve\n                                                    7", "md": "## Remark 3.5\n\nThe third term $$\\frac{\\kappa^2d}{\\varepsilon}$$ in [81] is independent of error rate $$\\alpha$$ but scales as $$\\kappa^2$$. This term is required to ensure the privacy noise added in each iteration is small enough for their DP-SGD to make progress (Appendix. B.2.2 in [81]). Our algorithm is based on full-batch gradient descent, which uses all $$n$$ samples and thus reduces the sensitivity of gradient average by a $$\\kappa$$ factor. As a result, we show in Eq. (59) that our algorithm only requires $$n = \\tilde{O}\\left(\\frac{1}{\\varepsilon} \\kappa^{1/2}d/\\alpha\\right)$$ to make progress for each iteration. This is strictly smaller than our dominant term $$\\kappa^{1/2}d/(\\varepsilon\\alpha)$$ and does not show up in our final guarantee. We provide a formal proof in App. H.\n\n## Remark 3.6\n\nOne of the key innovations in Alg. 1 is the adaptive distance estimator (Alg. 2 in App. C). The goal is to privately estimate the (shifted) distance of the current estimate, i.e., $$\\|w_t - w^*\\|_\\Sigma + \\sigma^2$$, without the knowledge of $$w^*$$. We show in Thm. C.1 that our novel distance estimator only requires an error-independent sample complexity $$n = \\tilde{O}(\\kappa^{1/2}d/\\varepsilon)$$ to achieve a constant multiplicative error. Note that the DP-STAT (Algorithm 3 in [81]) can also be used to estimate the distance. But it requires the knowledge of domain size $$\\|w^*\\|_\\Sigma + \\sigma$$. We completely remove this requirement, improve the dependence on $$\\kappa$$ and $$\\log(n)$$, and show it is also robust, as introduced in the next section. We provide the algorithms and analysis in App. C and the formal proof in App. D.\n\n## Robustness against label corruption\n\nWe assume there exists a good dataset $$S_{\\text{good}}$$ that satisfies Asmp. 2.1. We only get access to a label-corrupted dataset under the standard definition of label corruption, e.g., [15]. There are variations in literature on the definition, which we survey in App. A.\n\nAssumption 3.7 ($$\\alpha_{\\text{corrupt-corruption}}$$). Given a dataset $$S_{\\text{good}} = \\{(x_i, y_i)\\}_{n i=1}$$, an adversary inspects all the data points, selects $$\\alpha_{\\text{corrupt}}n$$ data points denoted as $$S_r$$, and replaces the labels with arbitrary labels while keeping the covariates unchanged. We let $$S_{\\text{bad}}$$ denote this set of $$\\alpha_{\\text{corrupt}}n$$ newly labelled examples by the adversary. Let the resulting set be $$S_{\\text{corrupt}} := S_{\\text{good}} \\cup S_{\\text{bad}} \\setminus S_r$$. Our goal is to estimate the unknown parameter $$w^*$$, given corrupted dataset $$S_{\\text{corrupt}}$$, distribution parameter $$K$$, and (an upper bound on) the corruption level $$\\alpha_{\\text{corrupt}}$$.\n\nUnder the non-private scenario, i.e., $$\\varepsilon = \\infty$$, recent advances led to optimal algorithms for linear regression that are robust to label corruptions [15, 21]; if the corruption level is smaller than the target error rate, i.e., $$\\alpha_{\\text{corrupt}} \\leq \\alpha$$, then $$n = \\tilde{O}(d/\\alpha^2)$$ samples are sufficient to achieve an error rate of $$(1/\\sigma)\\| \\hat{w} - w^*\\|_\\Sigma = \\alpha$$. The sample complexity of $$d/\\alpha^2$$ is optimal as it matches the information theoretic lower bound. The condition $$\\alpha_{\\text{corrupt}} \\leq \\alpha$$ is necessary since it is information theoretically impossible to achieve error $$\\alpha$$ less than $$\\alpha_{\\text{corrupt}}$$, as we prove in Prop. 3.9. Setting the target error to the minimum possible value of $$\\alpha = \\alpha_{\\text{corrupt}}$$, we say that these algorithms achieve optimal robustness since the minimum robust error rate of $$(1/\\sigma)\\| \\hat{w} - w^*\\|_\\Sigma = O(\\alpha_{\\text{corrupt}})$$ can be achieved with minimal sample complexity of $$n = \\tilde{O}(d/\\alpha^2_{\\text{corrupt}})$$. We aim to achieve such optimal robustness simultaneously with differential privacy in a computationally efficient manner.\n\n## Theorem 3.8\n\nUnder sub-Gaussian model of Asmp. 2.1 and $$\\alpha_{\\text{corrupt-corruption}}$$ of Asmp. 3.7, if the corruption level is below the target error rate, $$\\alpha \\geq \\alpha_{\\text{corrupt}}$$, then $$n = \\tilde{O}(d/\\alpha^2 + \\kappa^{1/2}d/(\\varepsilon\\alpha))$$ samples are sufficient for Alg. 1 to achieve an error rate of $$(1/\\sigma^2)E[\\| \\hat{w} - w^*\\|_2^2\\Sigma] = \\tilde{O}(\\alpha^2)$$. This is the first efficient approach to achieve robustness and $$(\\varepsilon, \\delta)$$-DP simultaneously. The existing such algorithms take exponential time [61, Corollary C.2] and [10], but achieve optimal sample complexity of $$n = O(d/\\alpha^2 + d/(\\varepsilon\\alpha))$$. Notice that there is no dependence on $$\\kappa$$. It remains an open question if computationally efficient private linear regression algorithms can achieve such an optimal $$\\kappa$$-independent sample complexity. We make the first advance towards this ambitious goal with the above theorem. Our sample complexity is sub-optimal only by a factor of $$\\sqrt{\\kappa}$$ in the second term. This is achieved by individually clipping the covariate, $$x_i$$, and the residual, $$(w_t^T x_i - y_i)$$, in Alg. 1 and carefully tracking the bias of clipping with the use of resilience in the analysis in App. H.\n\n## Lower bounds\n\nNecessity of our assumptions. A tail assumption on the covariate $$x_i$$ such as Asmp. 2.1 is necessary to achieve $$n = O(d)$$ sample complexity in Eq. (4). Even when the covariance $$\\Sigma$$ is close to identity, without further assumptions on the tail of covariate $$x$$, the result in [13] implies that for $$\\delta < 1/n$$, it is necessary for an $$(\\varepsilon, \\delta)$$-DP estimator to have $$n = \\Omega(d^{3/2}/(\\varepsilon\\alpha))$$ samples to achieve.", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "Remark 3.5", "md": "## Remark 3.5"}, {"type": "text", "value": "The third term $$\\frac{\\kappa^2d}{\\varepsilon}$$ in [81] is independent of error rate $$\\alpha$$ but scales as $$\\kappa^2$$. This term is required to ensure the privacy noise added in each iteration is small enough for their DP-SGD to make progress (Appendix. B.2.2 in [81]). Our algorithm is based on full-batch gradient descent, which uses all $$n$$ samples and thus reduces the sensitivity of gradient average by a $$\\kappa$$ factor. As a result, we show in Eq. (59) that our algorithm only requires $$n = \\tilde{O}\\left(\\frac{1}{\\varepsilon} \\kappa^{1/2}d/\\alpha\\right)$$ to make progress for each iteration. This is strictly smaller than our dominant term $$\\kappa^{1/2}d/(\\varepsilon\\alpha)$$ and does not show up in our final guarantee. We provide a formal proof in App. H.", "md": "The third term $$\\frac{\\kappa^2d}{\\varepsilon}$$ in [81] is independent of error rate $$\\alpha$$ but scales as $$\\kappa^2$$. This term is required to ensure the privacy noise added in each iteration is small enough for their DP-SGD to make progress (Appendix. B.2.2 in [81]). Our algorithm is based on full-batch gradient descent, which uses all $$n$$ samples and thus reduces the sensitivity of gradient average by a $$\\kappa$$ factor. As a result, we show in Eq. (59) that our algorithm only requires $$n = \\tilde{O}\\left(\\frac{1}{\\varepsilon} \\kappa^{1/2}d/\\alpha\\right)$$ to make progress for each iteration. This is strictly smaller than our dominant term $$\\kappa^{1/2}d/(\\varepsilon\\alpha)$$ and does not show up in our final guarantee. We provide a formal proof in App. H."}, {"type": "heading", "lvl": 2, "value": "Remark 3.6", "md": "## Remark 3.6"}, {"type": "text", "value": "One of the key innovations in Alg. 1 is the adaptive distance estimator (Alg. 2 in App. C). The goal is to privately estimate the (shifted) distance of the current estimate, i.e., $$\\|w_t - w^*\\|_\\Sigma + \\sigma^2$$, without the knowledge of $$w^*$$. We show in Thm. C.1 that our novel distance estimator only requires an error-independent sample complexity $$n = \\tilde{O}(\\kappa^{1/2}d/\\varepsilon)$$ to achieve a constant multiplicative error. Note that the DP-STAT (Algorithm 3 in [81]) can also be used to estimate the distance. But it requires the knowledge of domain size $$\\|w^*\\|_\\Sigma + \\sigma$$. We completely remove this requirement, improve the dependence on $$\\kappa$$ and $$\\log(n)$$, and show it is also robust, as introduced in the next section. We provide the algorithms and analysis in App. C and the formal proof in App. D.", "md": "One of the key innovations in Alg. 1 is the adaptive distance estimator (Alg. 2 in App. C). The goal is to privately estimate the (shifted) distance of the current estimate, i.e., $$\\|w_t - w^*\\|_\\Sigma + \\sigma^2$$, without the knowledge of $$w^*$$. We show in Thm. C.1 that our novel distance estimator only requires an error-independent sample complexity $$n = \\tilde{O}(\\kappa^{1/2}d/\\varepsilon)$$ to achieve a constant multiplicative error. Note that the DP-STAT (Algorithm 3 in [81]) can also be used to estimate the distance. But it requires the knowledge of domain size $$\\|w^*\\|_\\Sigma + \\sigma$$. We completely remove this requirement, improve the dependence on $$\\kappa$$ and $$\\log(n)$$, and show it is also robust, as introduced in the next section. We provide the algorithms and analysis in App. C and the formal proof in App. D."}, {"type": "heading", "lvl": 2, "value": "Robustness against label corruption", "md": "## Robustness against label corruption"}, {"type": "text", "value": "We assume there exists a good dataset $$S_{\\text{good}}$$ that satisfies Asmp. 2.1. We only get access to a label-corrupted dataset under the standard definition of label corruption, e.g., [15]. There are variations in literature on the definition, which we survey in App. A.\n\nAssumption 3.7 ($$\\alpha_{\\text{corrupt-corruption}}$$). Given a dataset $$S_{\\text{good}} = \\{(x_i, y_i)\\}_{n i=1}$$, an adversary inspects all the data points, selects $$\\alpha_{\\text{corrupt}}n$$ data points denoted as $$S_r$$, and replaces the labels with arbitrary labels while keeping the covariates unchanged. We let $$S_{\\text{bad}}$$ denote this set of $$\\alpha_{\\text{corrupt}}n$$ newly labelled examples by the adversary. Let the resulting set be $$S_{\\text{corrupt}} := S_{\\text{good}} \\cup S_{\\text{bad}} \\setminus S_r$$. Our goal is to estimate the unknown parameter $$w^*$$, given corrupted dataset $$S_{\\text{corrupt}}$$, distribution parameter $$K$$, and (an upper bound on) the corruption level $$\\alpha_{\\text{corrupt}}$$.\n\nUnder the non-private scenario, i.e., $$\\varepsilon = \\infty$$, recent advances led to optimal algorithms for linear regression that are robust to label corruptions [15, 21]; if the corruption level is smaller than the target error rate, i.e., $$\\alpha_{\\text{corrupt}} \\leq \\alpha$$, then $$n = \\tilde{O}(d/\\alpha^2)$$ samples are sufficient to achieve an error rate of $$(1/\\sigma)\\| \\hat{w} - w^*\\|_\\Sigma = \\alpha$$. The sample complexity of $$d/\\alpha^2$$ is optimal as it matches the information theoretic lower bound. The condition $$\\alpha_{\\text{corrupt}} \\leq \\alpha$$ is necessary since it is information theoretically impossible to achieve error $$\\alpha$$ less than $$\\alpha_{\\text{corrupt}}$$, as we prove in Prop. 3.9. Setting the target error to the minimum possible value of $$\\alpha = \\alpha_{\\text{corrupt}}$$, we say that these algorithms achieve optimal robustness since the minimum robust error rate of $$(1/\\sigma)\\| \\hat{w} - w^*\\|_\\Sigma = O(\\alpha_{\\text{corrupt}})$$ can be achieved with minimal sample complexity of $$n = \\tilde{O}(d/\\alpha^2_{\\text{corrupt}})$$. We aim to achieve such optimal robustness simultaneously with differential privacy in a computationally efficient manner.", "md": "We assume there exists a good dataset $$S_{\\text{good}}$$ that satisfies Asmp. 2.1. We only get access to a label-corrupted dataset under the standard definition of label corruption, e.g., [15]. There are variations in literature on the definition, which we survey in App. A.\n\nAssumption 3.7 ($$\\alpha_{\\text{corrupt-corruption}}$$). Given a dataset $$S_{\\text{good}} = \\{(x_i, y_i)\\}_{n i=1}$$, an adversary inspects all the data points, selects $$\\alpha_{\\text{corrupt}}n$$ data points denoted as $$S_r$$, and replaces the labels with arbitrary labels while keeping the covariates unchanged. We let $$S_{\\text{bad}}$$ denote this set of $$\\alpha_{\\text{corrupt}}n$$ newly labelled examples by the adversary. Let the resulting set be $$S_{\\text{corrupt}} := S_{\\text{good}} \\cup S_{\\text{bad}} \\setminus S_r$$. Our goal is to estimate the unknown parameter $$w^*$$, given corrupted dataset $$S_{\\text{corrupt}}$$, distribution parameter $$K$$, and (an upper bound on) the corruption level $$\\alpha_{\\text{corrupt}}$$.\n\nUnder the non-private scenario, i.e., $$\\varepsilon = \\infty$$, recent advances led to optimal algorithms for linear regression that are robust to label corruptions [15, 21]; if the corruption level is smaller than the target error rate, i.e., $$\\alpha_{\\text{corrupt}} \\leq \\alpha$$, then $$n = \\tilde{O}(d/\\alpha^2)$$ samples are sufficient to achieve an error rate of $$(1/\\sigma)\\| \\hat{w} - w^*\\|_\\Sigma = \\alpha$$. The sample complexity of $$d/\\alpha^2$$ is optimal as it matches the information theoretic lower bound. The condition $$\\alpha_{\\text{corrupt}} \\leq \\alpha$$ is necessary since it is information theoretically impossible to achieve error $$\\alpha$$ less than $$\\alpha_{\\text{corrupt}}$$, as we prove in Prop. 3.9. Setting the target error to the minimum possible value of $$\\alpha = \\alpha_{\\text{corrupt}}$$, we say that these algorithms achieve optimal robustness since the minimum robust error rate of $$(1/\\sigma)\\| \\hat{w} - w^*\\|_\\Sigma = O(\\alpha_{\\text{corrupt}})$$ can be achieved with minimal sample complexity of $$n = \\tilde{O}(d/\\alpha^2_{\\text{corrupt}})$$. We aim to achieve such optimal robustness simultaneously with differential privacy in a computationally efficient manner."}, {"type": "heading", "lvl": 2, "value": "Theorem 3.8", "md": "## Theorem 3.8"}, {"type": "text", "value": "Under sub-Gaussian model of Asmp. 2.1 and $$\\alpha_{\\text{corrupt-corruption}}$$ of Asmp. 3.7, if the corruption level is below the target error rate, $$\\alpha \\geq \\alpha_{\\text{corrupt}}$$, then $$n = \\tilde{O}(d/\\alpha^2 + \\kappa^{1/2}d/(\\varepsilon\\alpha))$$ samples are sufficient for Alg. 1 to achieve an error rate of $$(1/\\sigma^2)E[\\| \\hat{w} - w^*\\|_2^2\\Sigma] = \\tilde{O}(\\alpha^2)$$. This is the first efficient approach to achieve robustness and $$(\\varepsilon, \\delta)$$-DP simultaneously. The existing such algorithms take exponential time [61, Corollary C.2] and [10], but achieve optimal sample complexity of $$n = O(d/\\alpha^2 + d/(\\varepsilon\\alpha))$$. Notice that there is no dependence on $$\\kappa$$. It remains an open question if computationally efficient private linear regression algorithms can achieve such an optimal $$\\kappa$$-independent sample complexity. We make the first advance towards this ambitious goal with the above theorem. Our sample complexity is sub-optimal only by a factor of $$\\sqrt{\\kappa}$$ in the second term. This is achieved by individually clipping the covariate, $$x_i$$, and the residual, $$(w_t^T x_i - y_i)$$, in Alg. 1 and carefully tracking the bias of clipping with the use of resilience in the analysis in App. H.", "md": "Under sub-Gaussian model of Asmp. 2.1 and $$\\alpha_{\\text{corrupt-corruption}}$$ of Asmp. 3.7, if the corruption level is below the target error rate, $$\\alpha \\geq \\alpha_{\\text{corrupt}}$$, then $$n = \\tilde{O}(d/\\alpha^2 + \\kappa^{1/2}d/(\\varepsilon\\alpha))$$ samples are sufficient for Alg. 1 to achieve an error rate of $$(1/\\sigma^2)E[\\| \\hat{w} - w^*\\|_2^2\\Sigma] = \\tilde{O}(\\alpha^2)$$. This is the first efficient approach to achieve robustness and $$(\\varepsilon, \\delta)$$-DP simultaneously. The existing such algorithms take exponential time [61, Corollary C.2] and [10], but achieve optimal sample complexity of $$n = O(d/\\alpha^2 + d/(\\varepsilon\\alpha))$$. Notice that there is no dependence on $$\\kappa$$. It remains an open question if computationally efficient private linear regression algorithms can achieve such an optimal $$\\kappa$$-independent sample complexity. We make the first advance towards this ambitious goal with the above theorem. Our sample complexity is sub-optimal only by a factor of $$\\sqrt{\\kappa}$$ in the second term. This is achieved by individually clipping the covariate, $$x_i$$, and the residual, $$(w_t^T x_i - y_i)$$, in Alg. 1 and carefully tracking the bias of clipping with the use of resilience in the analysis in App. H."}, {"type": "heading", "lvl": 2, "value": "Lower bounds", "md": "## Lower bounds"}, {"type": "text", "value": "Necessity of our assumptions. A tail assumption on the covariate $$x_i$$ such as Asmp. 2.1 is necessary to achieve $$n = O(d)$$ sample complexity in Eq. (4). Even when the covariance $$\\Sigma$$ is close to identity, without further assumptions on the tail of covariate $$x$$, the result in [13] implies that for $$\\delta < 1/n$$, it is necessary for an $$(\\varepsilon, \\delta)$$-DP estimator to have $$n = \\Omega(d^{3/2}/(\\varepsilon\\alpha))$$ samples to achieve.", "md": "Necessity of our assumptions. A tail assumption on the covariate $$x_i$$ such as Asmp. 2.1 is necessary to achieve $$n = O(d)$$ sample complexity in Eq. (4). Even when the covariance $$\\Sigma$$ is close to identity, without further assumptions on the tail of covariate $$x$$, the result in [13] implies that for $$\\delta < 1/n$$, it is necessary for an $$(\\varepsilon, \\delta)$$-DP estimator to have $$n = \\Omega(d^{3/2}/(\\varepsilon\\alpha))$$ samples to achieve."}]}, {"page": 8, "text": "     Von Pvate OLS                     Non Pmvata SGl       DP AMES-Gl        Dp Rnhou\nFigure 1: Performance of various techniques on DP linear regression. d = 10 in all the experiments.\nn = 107, \u03ba = 1 in the 2nd experiment. n = 107, \u03c3 = 1 in the 3rd experiment, where \u03ba is the\ncondition number of \u03a3 and \u03c32 is the variance of the label noise zi.\n\u2225w\u02c6\u2212  w\u2217\u2225\u03a3 = \u02dc  O(\u03b1) (see Eq. (3) in [83]). Note that this lower bound is a factor d1/2 larger than our\nupper bound that benefits from the additional tail assumption.\nA tail assumption on the noise zi such as Asmp. 2.1 is necessary to achieve n = O(d/(\u03b5\u03b1))\ndependence on the sample complexity in Eq. (4). For heavy-tailed noise, such as k-th moment\nbounded noise, the dependence can be signifi     cantly larger. [61, Proposition C.5] implies that for\n\u03b4 = e\u2212\u0398(d) and 4-th moment bounded xi and zi, any (\u03b5, \u03b4)-DP estimator requires n = \u2126(d/(\u03b5\u03b12)),\nwhich is a factor of 1/\u03b1 larger, to achieve (1/\u03c32)\u2225  \u02c6\n                                                     w \u2212  w\u2217\u2225\u03a3 = \u02dc O(\u03b1).\nThe assumption that only labels are corrupted is critical for Alg. 1. The average of the clipped\ngradients can be significantly more biased, if the adversary can place the covariates of the corrupted\nsamples in the same direction. In particular, the bound on the bias of our gradient step in Eq. (44)\nin App. H would no longer hold. Against such strong attacks, one requires additional steps to\nestimate the mean of the gradients robustly and privately, similar to those used in robust private mean\nestimation [60, 56, 44, 8]. There is no known linear-time algorithm to achieve this, and this is outside\nthe scope of this paper.\nLower bounds under label corruption. Under the \u03b1corrupt label corruption setting (Asmp. 3.7),\neven with infinite data and without privacy constraints, no algorithm is able to learn w\u2217  with \u21132 error\nbetter than \u03b1corrupt. We provide a formal derivation for completeness.\nProposition 3.9. Let D\u03a3,\u03c32,w\u2217,K be a class of distributions on (xi, yi) from sub-Gaussian model\nin Asmp. 2.1. Let Sn,\u03b1 be an \u03b1-corrupted dataset of n i.i.d. samples from some distribution D \u2208\nD\u03a3,\u03c32,w\u2217,K under Asmp. 3.7. Let M be a class of estimators that are functions over Sn,\u03b1. Then there\nexists a constant c such that minn, \u02c6                                      E[\u2225 \u02c6\n                                    w\u2208M maxSn,\u03b1,D\u2208D\u03a3,\u03c32,w\u2217,K,w\u2217,K              w \u2212  w\u2217\u22252 \u03a3] \u2265 c \u03b12 \u03c32.\nA proof is provided in App. I.1. A similar lower bound can be found in [11, Theorem 6.1].\n4    Experimental results\n4.1   DP Linear Regression\nWe present experimental results comparing our proposed technique (DP-ROBGD) with other base-\nlines. We consider non-corrupted regression in this section and defer corrupted regression to the\nApp. K. We begin by describing the problem setup and the baseline algorithms first.\nExperiment Setup. We generate data for all the experiments using the following generative model.\nThe parameter vector w\u2217    is uniformly sampled from the surface of a unit sphere. The covariates\n{xi}ni=1 are first sampled from N(0, \u03a3) and then projected to unit sphere. We consider diagonal\ncovariances \u03a3 of the following form: \u03a3[0, 0] = \u03ba, and \u03a3[i, i] = 1 for all i \u2265     1. Here \u03ba \u2265   1 is the\ncondition number of \u03a3. We generate noise zi from uniform distribution over [\u2212\u03c3, \u03c3]. Finally, the\nresponse variables are generated as follows yi = x\u22a4   i w\u2217 + zi. All the experiments presented below\nare repeated 5 times and the averaged results are presented. We set the DP parameters (\u03f5, \u03b4) as\n\u03f5 = 1, \u03b4 = min(10\u22126, n\u22122). Experiments for \u03f5 = 0.1 can be found in Fig. 2 in the App. K.\nBaseline Algorithms. We compare our estimator with the following baseline algorithms:\n  \u2022 Non private algorithms: ordinary least squares (OLS), one-pass stochastic gradient descent\n    with tail-averaging (SGD). For SGD, step-size is 1/(2\u03bbmax) and minibatch size is n/T, where\n    T = 3\u03ba log n.\n                                                   8", "md": "# Document\n\n## Figure 1: Performance of various techniques on DP linear regression.\n\nd = 10 in all the experiments.\n\nn = 107, \u03ba = 1 in the 2nd experiment. n = 107, \u03c3 = 1 in the 3rd experiment, where \u03ba is the condition number of \u03a3 and \u03c3^2 is the variance of the label noise zi.\n\n$$\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ (see Eq. (3) in [83]). Note that this lower bound is a factor d^(1/2) larger than our upper bound that benefits from the additional tail assumption.\n\nA tail assumption on the noise zi such as Asmp. 2.1 is necessary to achieve n = O(d/(\u03b5\u03b1)) dependence on the sample complexity in Eq. (4). For heavy-tailed noise, such as k-th moment bounded noise, the dependence can be significantly larger. [61, Proposition C.5] implies that for \u03b4 = e^(-\u0398(d)) and 4-th moment bounded xi and zi, any (\u03b5, \u03b4)-DP estimator requires n = \u2126(d/(\u03b5\u03b1^2)), which is a factor of 1/\u03b1 larger, to achieve (1/\u03c3^2)$$\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$.\n\nThe assumption that only labels are corrupted is critical for Alg. 1. The average of the clipped gradients can be significantly more biased, if the adversary can place the covariates of the corrupted samples in the same direction. In particular, the bound on the bias of our gradient step in Eq. (44) in App. H would no longer hold. Against such strong attacks, one requires additional steps to estimate the mean of the gradients robustly and privately, similar to those used in robust private mean estimation [60, 56, 44, 8]. There is no known linear-time algorithm to achieve this, and this is outside the scope of this paper.\n\nLower bounds under label corruption. Under the \u03b1-corrupt label corruption setting (Asmp. 3.7), even with infinite data and without privacy constraints, no algorithm is able to learn w^* with \u2113^2 error better than \u03b1-corrupt. We provide a formal derivation for completeness.\n\nProposition 3.9. Let D\u03a3,\u03c3^2,w^*,K be a class of distributions on (xi, yi) from sub-Gaussian model in Asmp. 2.1. Let Sn,\u03b1 be an \u03b1-corrupted dataset of n i.i.d. samples from some distribution D \u2208 D\u03a3,\u03c3^2,w^*,K under Asmp. 3.7. Let M be a class of estimators that are functions over Sn,\u03b1. Then there exists a constant c such that min_n, \\hat{w} \\in M E[\\| \\hat{w} - w^* \\|_2 \\Sigma] \\geq c \\alpha^2 \\sigma^2.\n\nA proof is provided in App. I.1. A similar lower bound can be found in [11, Theorem 6.1].\n\n## Experimental results\n\n### DP Linear Regression\n\nWe present experimental results comparing our proposed technique (DP-ROBGD) with other baselines. We consider non-corrupted regression in this section and defer corrupted regression to the App. K. We begin by describing the problem setup and the baseline algorithms first.\n\n#### Experiment Setup\n\nWe generate data for all the experiments using the following generative model. The parameter vector w^* is uniformly sampled from the surface of a unit sphere. The covariates {xi} from 1 to n are first sampled from N(0, \u03a3) and then projected to the unit sphere. We consider diagonal covariances \u03a3 of the following form: \u03a3[0, 0] = \u03ba, and \u03a3[i, i] = 1 for all i \u2265 1. Here \u03ba \u2265 1 is the condition number of \u03a3. We generate noise zi from a uniform distribution over [-\u03c3, \u03c3]. Finally, the response variables are generated as follows yi = x_i^T w^* + zi. All the experiments presented below are repeated 5 times and the averaged results are presented. We set the DP parameters (\u03f5, \u03b4) as \u03f5 = 1, \u03b4 = min(10^(-6), n^(-2)). Experiments for \u03f5 = 0.1 can be found in Fig. 2 in the App. K.\n\n#### Baseline Algorithms\n\nWe compare our estimator with the following baseline algorithms:\n\n- Non private algorithms: ordinary least squares (OLS), one-pass stochastic gradient descent with tail-averaging (SGD). For SGD, step-size is 1/(2\u03bb_max) and minibatch size is n/T, where T = 3\u03ba log n.", "images": [{"name": "page-8-2.jpg", "height": 91, "width": 116, "x": 366, "y": 72}, {"name": "page-8-0.jpg", "height": 91, "width": 116, "x": 130, "y": 72}, {"name": "page-8-1.jpg", "height": 91, "width": 116, "x": 248, "y": 72}, {"name": "page-8-3.jpg", "height": 13, "width": 394, "x": 109, "y": 163}], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 2, "value": "Figure 1: Performance of various techniques on DP linear regression.", "md": "## Figure 1: Performance of various techniques on DP linear regression."}, {"type": "text", "value": "d = 10 in all the experiments.\n\nn = 107, \u03ba = 1 in the 2nd experiment. n = 107, \u03c3 = 1 in the 3rd experiment, where \u03ba is the condition number of \u03a3 and \u03c3^2 is the variance of the label noise zi.\n\n$$\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ (see Eq. (3) in [83]). Note that this lower bound is a factor d^(1/2) larger than our upper bound that benefits from the additional tail assumption.\n\nA tail assumption on the noise zi such as Asmp. 2.1 is necessary to achieve n = O(d/(\u03b5\u03b1)) dependence on the sample complexity in Eq. (4). For heavy-tailed noise, such as k-th moment bounded noise, the dependence can be significantly larger. [61, Proposition C.5] implies that for \u03b4 = e^(-\u0398(d)) and 4-th moment bounded xi and zi, any (\u03b5, \u03b4)-DP estimator requires n = \u2126(d/(\u03b5\u03b1^2)), which is a factor of 1/\u03b1 larger, to achieve (1/\u03c3^2)$$\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$.\n\nThe assumption that only labels are corrupted is critical for Alg. 1. The average of the clipped gradients can be significantly more biased, if the adversary can place the covariates of the corrupted samples in the same direction. In particular, the bound on the bias of our gradient step in Eq. (44) in App. H would no longer hold. Against such strong attacks, one requires additional steps to estimate the mean of the gradients robustly and privately, similar to those used in robust private mean estimation [60, 56, 44, 8]. There is no known linear-time algorithm to achieve this, and this is outside the scope of this paper.\n\nLower bounds under label corruption. Under the \u03b1-corrupt label corruption setting (Asmp. 3.7), even with infinite data and without privacy constraints, no algorithm is able to learn w^* with \u2113^2 error better than \u03b1-corrupt. We provide a formal derivation for completeness.\n\nProposition 3.9. Let D\u03a3,\u03c3^2,w^*,K be a class of distributions on (xi, yi) from sub-Gaussian model in Asmp. 2.1. Let Sn,\u03b1 be an \u03b1-corrupted dataset of n i.i.d. samples from some distribution D \u2208 D\u03a3,\u03c3^2,w^*,K under Asmp. 3.7. Let M be a class of estimators that are functions over Sn,\u03b1. Then there exists a constant c such that min_n, \\hat{w} \\in M E[\\| \\hat{w} - w^* \\|_2 \\Sigma] \\geq c \\alpha^2 \\sigma^2.\n\nA proof is provided in App. I.1. A similar lower bound can be found in [11, Theorem 6.1].", "md": "d = 10 in all the experiments.\n\nn = 107, \u03ba = 1 in the 2nd experiment. n = 107, \u03c3 = 1 in the 3rd experiment, where \u03ba is the condition number of \u03a3 and \u03c3^2 is the variance of the label noise zi.\n\n$$\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$ (see Eq. (3) in [83]). Note that this lower bound is a factor d^(1/2) larger than our upper bound that benefits from the additional tail assumption.\n\nA tail assumption on the noise zi such as Asmp. 2.1 is necessary to achieve n = O(d/(\u03b5\u03b1)) dependence on the sample complexity in Eq. (4). For heavy-tailed noise, such as k-th moment bounded noise, the dependence can be significantly larger. [61, Proposition C.5] implies that for \u03b4 = e^(-\u0398(d)) and 4-th moment bounded xi and zi, any (\u03b5, \u03b4)-DP estimator requires n = \u2126(d/(\u03b5\u03b1^2)), which is a factor of 1/\u03b1 larger, to achieve (1/\u03c3^2)$$\\| \\hat{w} - w^* \\|_{\\Sigma} = \\tilde{O}(\\alpha)$$.\n\nThe assumption that only labels are corrupted is critical for Alg. 1. The average of the clipped gradients can be significantly more biased, if the adversary can place the covariates of the corrupted samples in the same direction. In particular, the bound on the bias of our gradient step in Eq. (44) in App. H would no longer hold. Against such strong attacks, one requires additional steps to estimate the mean of the gradients robustly and privately, similar to those used in robust private mean estimation [60, 56, 44, 8]. There is no known linear-time algorithm to achieve this, and this is outside the scope of this paper.\n\nLower bounds under label corruption. Under the \u03b1-corrupt label corruption setting (Asmp. 3.7), even with infinite data and without privacy constraints, no algorithm is able to learn w^* with \u2113^2 error better than \u03b1-corrupt. We provide a formal derivation for completeness.\n\nProposition 3.9. Let D\u03a3,\u03c3^2,w^*,K be a class of distributions on (xi, yi) from sub-Gaussian model in Asmp. 2.1. Let Sn,\u03b1 be an \u03b1-corrupted dataset of n i.i.d. samples from some distribution D \u2208 D\u03a3,\u03c3^2,w^*,K under Asmp. 3.7. Let M be a class of estimators that are functions over Sn,\u03b1. Then there exists a constant c such that min_n, \\hat{w} \\in M E[\\| \\hat{w} - w^* \\|_2 \\Sigma] \\geq c \\alpha^2 \\sigma^2.\n\nA proof is provided in App. I.1. A similar lower bound can be found in [11, Theorem 6.1]."}, {"type": "heading", "lvl": 2, "value": "Experimental results", "md": "## Experimental results"}, {"type": "heading", "lvl": 3, "value": "DP Linear Regression", "md": "### DP Linear Regression"}, {"type": "text", "value": "We present experimental results comparing our proposed technique (DP-ROBGD) with other baselines. We consider non-corrupted regression in this section and defer corrupted regression to the App. K. We begin by describing the problem setup and the baseline algorithms first.", "md": "We present experimental results comparing our proposed technique (DP-ROBGD) with other baselines. We consider non-corrupted regression in this section and defer corrupted regression to the App. K. We begin by describing the problem setup and the baseline algorithms first."}, {"type": "heading", "lvl": 4, "value": "Experiment Setup", "md": "#### Experiment Setup"}, {"type": "text", "value": "We generate data for all the experiments using the following generative model. The parameter vector w^* is uniformly sampled from the surface of a unit sphere. The covariates {xi} from 1 to n are first sampled from N(0, \u03a3) and then projected to the unit sphere. We consider diagonal covariances \u03a3 of the following form: \u03a3[0, 0] = \u03ba, and \u03a3[i, i] = 1 for all i \u2265 1. Here \u03ba \u2265 1 is the condition number of \u03a3. We generate noise zi from a uniform distribution over [-\u03c3, \u03c3]. Finally, the response variables are generated as follows yi = x_i^T w^* + zi. All the experiments presented below are repeated 5 times and the averaged results are presented. We set the DP parameters (\u03f5, \u03b4) as \u03f5 = 1, \u03b4 = min(10^(-6), n^(-2)). Experiments for \u03f5 = 0.1 can be found in Fig. 2 in the App. K.", "md": "We generate data for all the experiments using the following generative model. The parameter vector w^* is uniformly sampled from the surface of a unit sphere. The covariates {xi} from 1 to n are first sampled from N(0, \u03a3) and then projected to the unit sphere. We consider diagonal covariances \u03a3 of the following form: \u03a3[0, 0] = \u03ba, and \u03a3[i, i] = 1 for all i \u2265 1. Here \u03ba \u2265 1 is the condition number of \u03a3. We generate noise zi from a uniform distribution over [-\u03c3, \u03c3]. Finally, the response variables are generated as follows yi = x_i^T w^* + zi. All the experiments presented below are repeated 5 times and the averaged results are presented. We set the DP parameters (\u03f5, \u03b4) as \u03f5 = 1, \u03b4 = min(10^(-6), n^(-2)). Experiments for \u03f5 = 0.1 can be found in Fig. 2 in the App. K."}, {"type": "heading", "lvl": 4, "value": "Baseline Algorithms", "md": "#### Baseline Algorithms"}, {"type": "text", "value": "We compare our estimator with the following baseline algorithms:\n\n- Non private algorithms: ordinary least squares (OLS), one-pass stochastic gradient descent with tail-averaging (SGD). For SGD, step-size is 1/(2\u03bb_max) and minibatch size is n/T, where T = 3\u03ba log n.", "md": "We compare our estimator with the following baseline algorithms:\n\n- Non private algorithms: ordinary least squares (OLS), one-pass stochastic gradient descent with tail-averaging (SGD). For SGD, step-size is 1/(2\u03bb_max) and minibatch size is n/T, where T = 3\u03ba log n."}]}, {"page": 9, "text": "  \u2022 Private algorithms: sufficient statistics perturbation (DP-SSP) [38, 83], differentially private\n     stochastic gradient descent (DP-AMBSSGD) [81]. DP-SSP had the best empirical performance\n     among numerous techniques studied by [83], and DP-AMBSSGD has the best known theoretical\n     guarantees. The DP-SSP algorithm involves releasing XT X and XT y differentially privately\n     and computing (         XT X)\u22121       XT y. DP-AMBSSGD is a private version of SGD where the DP\n     noise is set adaptively according to the excess error in each iteration. For both algorithms, we use\n     the hyper-parameters recommended in their respective papers. To improve the performance of\n     DP-AMBSSGD, we reduce the theoretical clipping threshold by a constant factor.\nDP-ROBGD.              We implement Alg. 1 with the following key changes.                                   Instead of relying on\nPrivateNormEstimator to estimate \u0393, we set it to its true value Tr(\u03a3). This is done for a fair\ncomparison with DP-AMBSSGD which assumes the knowledge of Tr(\u03a3). Next, we use 20% of\nthe samples to compute \u03b3t in line 5 (instead of the 50% stated in Alg. 1). In our experiments we\nalso present results for a variant of our algorithm called DP-ROBGD* which outputs the best iterate\nbased on \u03b3t, instead of the last iterate. One could also perform tail-averaging instead of picking the\nbest iterate. Both these modifications are primarily used to reduce the variance in the output of Alg. 1\nand achieved similar performance in our experiments.\nResults. Figure 1 presents the performance of various algorithms as we vary n, \u03ba, \u03c3. It can be\nseen that DP-ROBGD outperforms DP-AMBSSGD in almost all the settings (and DP-ROBGD*\noutperforms DP-ROBGD in all cases). DP-SSP has poor performance when the noise \u03c3 is low, but\nperforms slightly better than DP-ROBGD in other settings. A major drawback of DP-SSP is its\ncomputational complexity which scales as O(nd2 + d\u03c9). In contrast, the computational complexity\nof DP-ROBGD has smaller dependence on d and scales as \u02dc                             O(nd\u03ba). Thus the latter is more compu-\ntationally efficient for high-dimensional problems. More experimental results on both robust and\nprivate linear regression can be found in the App. K.\n5     Sketch of the main ideas in the analysis\nWe provide the main ideas behind the proof of Thm. 3.1. The privacy proof is straightforward since\nno matter what clipping threshold we use the noise we add is always proportionally to the clipping\nthreshold which guarantees privacy. In the remainder, we focus on the utility analysis.\nThe proof of the utility heavily relies on the resilience [73] (also known as stability [27]), which states\nthat given a large enough sample set S, various statistics (for example, sample mean and sample\nvariance) of any large enough subset of S will be close to each other. We define resilience as follows.\nDefinition 5.1 ([61, Definition 23]). For some \u03b1 \u2208                            (0, 1), \u03c11 \u2208       R+, \u03c12 \u2208        R+, and \u03c13 \u2208         R+,\n\u03c14 \u2208     R+, we say dataset Sgood = {(xi \u2208                       Rd, yi \u2208       R)}n i=1 is (\u03b1, \u03c11, \u03c12, \u03c13, \u03c14)-resilient with\nrespect to (w\u2217, \u03a3, \u03c3) for some w\u2217                  \u2208  Rd, positive definite \u03a3 \u227b              0 \u2208    Rd\u00d7d, and \u03c3 > 0 if for any\nT \u2282    Sgood of size |T| \u2265          (1 \u2212   \u03b1)n, the following holds for all v \u2208                Rd:\n                                   1                \u27e8v, xi\u27e9(yi \u2212      x\u22a4i w\u2217)     \u2264   \u03c11  \u221a  v\u22a4\u03a3v \u03c3 ,                                  (5)\n                                  |T|   (xi,yi)\u2208T\n                                   1          \u27e8v, xi\u27e92 \u2212      v\u22a4\u03a3v      \u2264   \u03c12v\u22a4\u03a3v ,                                                   (6)\n                                  |T|   xi\u2208T\n                                   1                (yi \u2212    x\u22a4i w\u2217)2 \u2212     \u03c32    \u2264   \u03c13\u03c32 ,                                           (7)\n                                  |T|   (xi,yi)\u2208T\n                                   1                \u27e8v, xi\u27e9      \u2264  \u03c14  \u221a  v\u22a4\u03a3v .                                                      (8)\n                                  |T|   (xi,yi)\u2208T\nWe give an overview of the proof for non-robust case as follows. First, we introduce some notations.\nLet g(t)   := (x\u22a4   i wt  \u2212yi)xi be the raw gradient and \u02dc            g(t)  := clip\u0398(xi)clip\u03b8t(x\u22a4          i wt  \u2212yi) be the clipped\n       i                                                                i\ngradient. Note that when the data follows from our distributional assumption, with high probability,\nsamples are not clipped by the norm: clip                \u0398(xi) = xi. We can write down one step of gradient update\n                                                                     9", "md": "- Private algorithms: sufficient statistics perturbation (DP-SSP) [38, 83], differentially private stochastic gradient descent (DP-AMBSSGD) [81]. DP-SSP had the best empirical performance among numerous techniques studied by [83], and DP-AMBSSGD has the best known theoretical guarantees. The DP-SSP algorithm involves releasing $X^TX$ and $X^Ty$ differentially privately and computing $(X^TX)^{-1}X^Ty$. DP-AMBSSGD is a private version of SGD where the DP noise is set adaptively according to the excess error in each iteration. For both algorithms, we use the hyper-parameters recommended in their respective papers. To improve the performance of DP-AMBSSGD, we reduce the theoretical clipping threshold by a constant factor.\n- DP-ROBGD. We implement Alg. 1 with the following key changes. Instead of relying on PrivateNormEstimator to estimate \u0393, we set it to its true value Tr(\u03a3). This is done for a fair comparison with DP-AMBSSGD which assumes the knowledge of Tr(\u03a3). Next, we use 20% of the samples to compute \u03b3t in line 5 (instead of the 50% stated in Alg. 1). In our experiments we also present results for a variant of our algorithm called DP-ROBGD* which outputs the best iterate based on \u03b3t, instead of the last iterate. One could also perform tail-averaging instead of picking the best iterate. Both these modifications are primarily used to reduce the variance in the output of Alg. 1 and achieved similar performance in our experiments.\n- Results. Figure 1 presents the performance of various algorithms as we vary n, \u03ba, \u03c3. It can be seen that DP-ROBGD outperforms DP-AMBSSGD in almost all the settings (and DP-ROBGD* outperforms DP-ROBGD in all cases). DP-SSP has poor performance when the noise \u03c3 is low, but performs slightly better than DP-ROBGD in other settings. A major drawback of DP-SSP is its computational complexity which scales as $O(nd^2 + d\u03c9)$. In contrast, the computational complexity of DP-ROBGD has smaller dependence on d and scales as $\\tilde{O}(nd\u03ba)$. Thus the latter is more computationally efficient for high-dimensional problems. More experimental results on both robust and private linear regression can be found in the App. K.\n- Sketch of the main ideas in the analysis\n\nWe provide the main ideas behind the proof of Thm. 3.1. The privacy proof is straightforward since no matter what clipping threshold we use the noise we add is always proportionally to the clipping threshold which guarantees privacy. In the remainder, we focus on the utility analysis.\n\nThe proof of the utility heavily relies on the resilience [73] (also known as stability [27]), which states that given a large enough sample set S, various statistics (for example, sample mean and sample variance) of any large enough subset of S will be close to each other. We define resilience as follows.\n\nDefinition 5.1 ([61, Definition 23]). For some $$\u03b1 \\in (0, 1)$$, $$\u03c11 \\in \\mathbb{R}^+$$, $$\u03c12 \\in \\mathbb{R}^+$$, $$\u03c13 \\in \\mathbb{R}^+$$, $$\u03c14 \\in \\mathbb{R}^+$$, we say dataset $$S_{\\text{good}} = \\{(x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R)}\\}_{n i=1}$$ is $$(\u03b1, \u03c11, \u03c12, \u03c13, \u03c14)$$-resilient with respect to $$(w^*, \u03a3, \u03c3)$$ for some $$w^* \\in \\mathbb{R}^d$$, positive definite $$\u03a3 \\succ 0 \\in \\mathbb{R}^{d\u00d7d}$$, and $$\u03c3 > 0$$ if for any $$T \\subset S_{\\text{good}}$$ of size $$|T| \\geq (1 - \u03b1)n$$, the following holds for all $$v \\in \\mathbb{R}^d$$:\n\n$$\n\\begin{align*}\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} \\langle v, x_i \\rangle(y_i - x_i^Tw^*) \\leq \u03c11 \\sqrt{v^T\u03a3v} \u03c3, &(5) \\\\\n&\\frac{1}{|T|} \\sum_{x_i \\in T} \\langle v, x_i \\rangle^2 - v^T\u03a3v \\leq \u03c12v^T\u03a3v, &(6) \\\\\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} (y_i - x_i^Tw^*)^2 - \u03c3^2 \\leq \u03c13\u03c3^2, &(7) \\\\\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} \\langle v, x_i \\rangle \\leq \u03c14 \\sqrt{v^T\u03a3v}. &(8)\n\\end{align*}\n$$\n\nWe give an overview of the proof for non-robust case as follows. First, we introduce some notations. Let $$g(t) := (x_i^Tw_t - y_i)x_i$$ be the raw gradient and $$\\tilde{g}(t) := \\text{clip}_\u0398(x_i)\\text{clip}_\u03b8t(x_i^Tw_t - y_i)$$ be the clipped gradient. Note that when the data follows from our distributional assumption, with high probability, samples are not clipped by the norm: $$\\text{clip}_\u0398(x_i) = x_i$$. We can write down one step of gradient update.", "images": [], "items": [{"type": "text", "value": "- Private algorithms: sufficient statistics perturbation (DP-SSP) [38, 83], differentially private stochastic gradient descent (DP-AMBSSGD) [81]. DP-SSP had the best empirical performance among numerous techniques studied by [83], and DP-AMBSSGD has the best known theoretical guarantees. The DP-SSP algorithm involves releasing $X^TX$ and $X^Ty$ differentially privately and computing $(X^TX)^{-1}X^Ty$. DP-AMBSSGD is a private version of SGD where the DP noise is set adaptively according to the excess error in each iteration. For both algorithms, we use the hyper-parameters recommended in their respective papers. To improve the performance of DP-AMBSSGD, we reduce the theoretical clipping threshold by a constant factor.\n- DP-ROBGD. We implement Alg. 1 with the following key changes. Instead of relying on PrivateNormEstimator to estimate \u0393, we set it to its true value Tr(\u03a3). This is done for a fair comparison with DP-AMBSSGD which assumes the knowledge of Tr(\u03a3). Next, we use 20% of the samples to compute \u03b3t in line 5 (instead of the 50% stated in Alg. 1). In our experiments we also present results for a variant of our algorithm called DP-ROBGD* which outputs the best iterate based on \u03b3t, instead of the last iterate. One could also perform tail-averaging instead of picking the best iterate. Both these modifications are primarily used to reduce the variance in the output of Alg. 1 and achieved similar performance in our experiments.\n- Results. Figure 1 presents the performance of various algorithms as we vary n, \u03ba, \u03c3. It can be seen that DP-ROBGD outperforms DP-AMBSSGD in almost all the settings (and DP-ROBGD* outperforms DP-ROBGD in all cases). DP-SSP has poor performance when the noise \u03c3 is low, but performs slightly better than DP-ROBGD in other settings. A major drawback of DP-SSP is its computational complexity which scales as $O(nd^2 + d\u03c9)$. In contrast, the computational complexity of DP-ROBGD has smaller dependence on d and scales as $\\tilde{O}(nd\u03ba)$. Thus the latter is more computationally efficient for high-dimensional problems. More experimental results on both robust and private linear regression can be found in the App. K.\n- Sketch of the main ideas in the analysis\n\nWe provide the main ideas behind the proof of Thm. 3.1. The privacy proof is straightforward since no matter what clipping threshold we use the noise we add is always proportionally to the clipping threshold which guarantees privacy. In the remainder, we focus on the utility analysis.\n\nThe proof of the utility heavily relies on the resilience [73] (also known as stability [27]), which states that given a large enough sample set S, various statistics (for example, sample mean and sample variance) of any large enough subset of S will be close to each other. We define resilience as follows.\n\nDefinition 5.1 ([61, Definition 23]). For some $$\u03b1 \\in (0, 1)$$, $$\u03c11 \\in \\mathbb{R}^+$$, $$\u03c12 \\in \\mathbb{R}^+$$, $$\u03c13 \\in \\mathbb{R}^+$$, $$\u03c14 \\in \\mathbb{R}^+$$, we say dataset $$S_{\\text{good}} = \\{(x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R)}\\}_{n i=1}$$ is $$(\u03b1, \u03c11, \u03c12, \u03c13, \u03c14)$$-resilient with respect to $$(w^*, \u03a3, \u03c3)$$ for some $$w^* \\in \\mathbb{R}^d$$, positive definite $$\u03a3 \\succ 0 \\in \\mathbb{R}^{d\u00d7d}$$, and $$\u03c3 > 0$$ if for any $$T \\subset S_{\\text{good}}$$ of size $$|T| \\geq (1 - \u03b1)n$$, the following holds for all $$v \\in \\mathbb{R}^d$$:\n\n$$\n\\begin{align*}\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} \\langle v, x_i \\rangle(y_i - x_i^Tw^*) \\leq \u03c11 \\sqrt{v^T\u03a3v} \u03c3, &(5) \\\\\n&\\frac{1}{|T|} \\sum_{x_i \\in T} \\langle v, x_i \\rangle^2 - v^T\u03a3v \\leq \u03c12v^T\u03a3v, &(6) \\\\\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} (y_i - x_i^Tw^*)^2 - \u03c3^2 \\leq \u03c13\u03c3^2, &(7) \\\\\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} \\langle v, x_i \\rangle \\leq \u03c14 \\sqrt{v^T\u03a3v}. &(8)\n\\end{align*}\n$$\n\nWe give an overview of the proof for non-robust case as follows. First, we introduce some notations. Let $$g(t) := (x_i^Tw_t - y_i)x_i$$ be the raw gradient and $$\\tilde{g}(t) := \\text{clip}_\u0398(x_i)\\text{clip}_\u03b8t(x_i^Tw_t - y_i)$$ be the clipped gradient. Note that when the data follows from our distributional assumption, with high probability, samples are not clipped by the norm: $$\\text{clip}_\u0398(x_i) = x_i$$. We can write down one step of gradient update.", "md": "- Private algorithms: sufficient statistics perturbation (DP-SSP) [38, 83], differentially private stochastic gradient descent (DP-AMBSSGD) [81]. DP-SSP had the best empirical performance among numerous techniques studied by [83], and DP-AMBSSGD has the best known theoretical guarantees. The DP-SSP algorithm involves releasing $X^TX$ and $X^Ty$ differentially privately and computing $(X^TX)^{-1}X^Ty$. DP-AMBSSGD is a private version of SGD where the DP noise is set adaptively according to the excess error in each iteration. For both algorithms, we use the hyper-parameters recommended in their respective papers. To improve the performance of DP-AMBSSGD, we reduce the theoretical clipping threshold by a constant factor.\n- DP-ROBGD. We implement Alg. 1 with the following key changes. Instead of relying on PrivateNormEstimator to estimate \u0393, we set it to its true value Tr(\u03a3). This is done for a fair comparison with DP-AMBSSGD which assumes the knowledge of Tr(\u03a3). Next, we use 20% of the samples to compute \u03b3t in line 5 (instead of the 50% stated in Alg. 1). In our experiments we also present results for a variant of our algorithm called DP-ROBGD* which outputs the best iterate based on \u03b3t, instead of the last iterate. One could also perform tail-averaging instead of picking the best iterate. Both these modifications are primarily used to reduce the variance in the output of Alg. 1 and achieved similar performance in our experiments.\n- Results. Figure 1 presents the performance of various algorithms as we vary n, \u03ba, \u03c3. It can be seen that DP-ROBGD outperforms DP-AMBSSGD in almost all the settings (and DP-ROBGD* outperforms DP-ROBGD in all cases). DP-SSP has poor performance when the noise \u03c3 is low, but performs slightly better than DP-ROBGD in other settings. A major drawback of DP-SSP is its computational complexity which scales as $O(nd^2 + d\u03c9)$. In contrast, the computational complexity of DP-ROBGD has smaller dependence on d and scales as $\\tilde{O}(nd\u03ba)$. Thus the latter is more computationally efficient for high-dimensional problems. More experimental results on both robust and private linear regression can be found in the App. K.\n- Sketch of the main ideas in the analysis\n\nWe provide the main ideas behind the proof of Thm. 3.1. The privacy proof is straightforward since no matter what clipping threshold we use the noise we add is always proportionally to the clipping threshold which guarantees privacy. In the remainder, we focus on the utility analysis.\n\nThe proof of the utility heavily relies on the resilience [73] (also known as stability [27]), which states that given a large enough sample set S, various statistics (for example, sample mean and sample variance) of any large enough subset of S will be close to each other. We define resilience as follows.\n\nDefinition 5.1 ([61, Definition 23]). For some $$\u03b1 \\in (0, 1)$$, $$\u03c11 \\in \\mathbb{R}^+$$, $$\u03c12 \\in \\mathbb{R}^+$$, $$\u03c13 \\in \\mathbb{R}^+$$, $$\u03c14 \\in \\mathbb{R}^+$$, we say dataset $$S_{\\text{good}} = \\{(x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R)}\\}_{n i=1}$$ is $$(\u03b1, \u03c11, \u03c12, \u03c13, \u03c14)$$-resilient with respect to $$(w^*, \u03a3, \u03c3)$$ for some $$w^* \\in \\mathbb{R}^d$$, positive definite $$\u03a3 \\succ 0 \\in \\mathbb{R}^{d\u00d7d}$$, and $$\u03c3 > 0$$ if for any $$T \\subset S_{\\text{good}}$$ of size $$|T| \\geq (1 - \u03b1)n$$, the following holds for all $$v \\in \\mathbb{R}^d$$:\n\n$$\n\\begin{align*}\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} \\langle v, x_i \\rangle(y_i - x_i^Tw^*) \\leq \u03c11 \\sqrt{v^T\u03a3v} \u03c3, &(5) \\\\\n&\\frac{1}{|T|} \\sum_{x_i \\in T} \\langle v, x_i \\rangle^2 - v^T\u03a3v \\leq \u03c12v^T\u03a3v, &(6) \\\\\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} (y_i - x_i^Tw^*)^2 - \u03c3^2 \\leq \u03c13\u03c3^2, &(7) \\\\\n&\\frac{1}{|T|} \\sum_{(x_i,y_i) \\in T} \\langle v, x_i \\rangle \\leq \u03c14 \\sqrt{v^T\u03a3v}. &(8)\n\\end{align*}\n$$\n\nWe give an overview of the proof for non-robust case as follows. First, we introduce some notations. Let $$g(t) := (x_i^Tw_t - y_i)x_i$$ be the raw gradient and $$\\tilde{g}(t) := \\text{clip}_\u0398(x_i)\\text{clip}_\u03b8t(x_i^Tw_t - y_i)$$ be the clipped gradient. Note that when the data follows from our distributional assumption, with high probability, samples are not clipped by the norm: $$\\text{clip}_\u0398(x_i) = x_i$$. We can write down one step of gradient update."}]}, {"page": 10, "text": " (see Alg. 1) as follows:\n       wt+1 \u2212      w\u2217   =      I \u2212   \u03b7        xix\u22a4       (wt \u2212     w\u2217)   + \u03b7          xizi   + \u03b7         (g(t)   \u2212  \u02dc       \u2212  \u03b7\u03d5t\u03bdt   .\n                                                                                                                    g(t)\n                                     n  i\u2208S        i                         n  i\u2208S              n  i\u2208S     i         i )        (iv)\n                                                 (i)                              (ii)                     (iii)\n In the above equation, the first term is a contraction, meaning wt is moving toward w\u2217. The second\n term captures the noise from the randomness in the samples. The third term captures the bias\n introduced by the clipping operation, and the fourth term captures the added noise for privacy. The\n second term is standard and relatively easy to control, and our main focus is on the last two terms.\n The third term (\u03b7/n)                            \u2212  \u02dc\n                                                    g(t)\n                                    i\u2208S(g(t)i         i ) can be controlled using the resilience property. We prove\n that with our estimated threshold, the clipping will only affect a small amount of datapoints, whose\n contribution to the gradient is small collectively.\n Now we have controlled the deterministic bias. Then, we upper bound the fourth term, which is the\n noise for the purpose of privacy, and show the expected prediction error decrease in every gradient\n step. The diffi     culty is that, since our clipping threshold is adaptive, the decrease of the estimation\n error depends on the estimation error of all the previous steps. This causes that in some iterations, the\n estimation error actually increases. In order to get around this, we split the iterations into length \u03ba\n chunks, and argue that the maximum estimation error in a chunk must be a constant factor smaller\n than the previous chunk. This implies we will reach the desired error within \u02dc                                O(\u03ba) steps.\n 6     Conclusion\nWe provide a novel variant of DP-SGD algorithm for differentially private linear regression under\n label corruption. We show the first near-optimal rate that achieves privacy and robustness to label\n corruptions simultaneously. When there is no label corruption, our result also improves upon the\n state-of-the-art method [81] in terms of the condition number \u03ba. Compared to [81], our algorithm has\n two innovations: 1) we introduce a novel adaptive clipping, which is critical in achieving robustness\n against label corruptions; and 2) we use full batch gradient descent and a novel convergence analysis\n to get the near-optimal sample complexity.\n Acknowledgement\nWe thank Abhradeep Guha Thakurta for helpful discussions while working on this paper. This\n material is based upon work supported by the National Science Foundation under grants no. 2134012,\n 2019844, 2112471, and 2229876, and is supported in part by funds provided by the National Science\n Foundation, by the Department of Homeland Security, and by IBM. Any opinions, findings, and\n conclusions or recommendations expressed in this material are those of the author(s) and do not\n necessarily reflect the views of the National Science Foundation or its federal agency and industry\n partners.\n                                                                       10", "md": "(see Alg. 1) as follows:\n\n$$\nw_{t+1} - w^* = I - \\eta x_ix^T(w_t - w^*) + \\eta x_iz_i + \\eta \\left(g(t) - \\tilde{g} - \\eta\\phi_t\\nu_t\\right).\n$$\nIn the above equation, the first term is a contraction, meaning \\(w_t\\) is moving toward \\(w^*\\). The second term captures the noise from the randomness in the samples. The third term captures the bias introduced by the clipping operation, and the fourth term captures the added noise for privacy. The second term is standard and relatively easy to control, and our main focus is on the last two terms. The third term \\(\\left(\\frac{\\eta}{n} \\sum_{i \\in S} (g(t)_i - \\tilde{g}_i)\\right)\\) can be controlled using the resilience property. We prove that with our estimated threshold, the clipping will only affect a small amount of datapoints, whose contribution to the gradient is small collectively.\n\nNow we have controlled the deterministic bias. Then, we upper bound the fourth term, which is the noise for the purpose of privacy, and show the expected prediction error decrease in every gradient step. The difficulty is that, since our clipping threshold is adaptive, the decrease of the estimation error depends on the estimation error of all the previous steps. This causes that in some iterations, the estimation error actually increases. In order to get around this, we split the iterations into length \\(\\kappa\\) chunks, and argue that the maximum estimation error in a chunk must be a constant factor smaller than the previous chunk. This implies we will reach the desired error within \\(\\tilde{O}(\\kappa)\\) steps.\n\n6 Conclusion\n\nWe provide a novel variant of DP-SGD algorithm for differentially private linear regression under label corruption. We show the first near-optimal rate that achieves privacy and robustness to label corruptions simultaneously. When there is no label corruption, our result also improves upon the state-of-the-art method [81] in terms of the condition number \\(\\kappa\\). Compared to [81], our algorithm has two innovations: 1) we introduce a novel adaptive clipping, which is critical in achieving robustness against label corruptions; and 2) we use full batch gradient descent and a novel convergence analysis to get the near-optimal sample complexity.\n\nAcknowledgement\n\nWe thank Abhradeep Guha Thakurta for helpful discussions while working on this paper. This material is based upon work supported by the National Science Foundation under grants no. 2134012, 2019844, 2112471, and 2229876, and is supported in part by funds provided by the National Science Foundation, by the Department of Homeland Security, and by IBM. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation or its federal agency and industry partners.\n\n10", "images": [], "items": [{"type": "text", "value": "(see Alg. 1) as follows:\n\n$$\nw_{t+1} - w^* = I - \\eta x_ix^T(w_t - w^*) + \\eta x_iz_i + \\eta \\left(g(t) - \\tilde{g} - \\eta\\phi_t\\nu_t\\right).\n$$\nIn the above equation, the first term is a contraction, meaning \\(w_t\\) is moving toward \\(w^*\\). The second term captures the noise from the randomness in the samples. The third term captures the bias introduced by the clipping operation, and the fourth term captures the added noise for privacy. The second term is standard and relatively easy to control, and our main focus is on the last two terms. The third term \\(\\left(\\frac{\\eta}{n} \\sum_{i \\in S} (g(t)_i - \\tilde{g}_i)\\right)\\) can be controlled using the resilience property. We prove that with our estimated threshold, the clipping will only affect a small amount of datapoints, whose contribution to the gradient is small collectively.\n\nNow we have controlled the deterministic bias. Then, we upper bound the fourth term, which is the noise for the purpose of privacy, and show the expected prediction error decrease in every gradient step. The difficulty is that, since our clipping threshold is adaptive, the decrease of the estimation error depends on the estimation error of all the previous steps. This causes that in some iterations, the estimation error actually increases. In order to get around this, we split the iterations into length \\(\\kappa\\) chunks, and argue that the maximum estimation error in a chunk must be a constant factor smaller than the previous chunk. This implies we will reach the desired error within \\(\\tilde{O}(\\kappa)\\) steps.\n\n6 Conclusion\n\nWe provide a novel variant of DP-SGD algorithm for differentially private linear regression under label corruption. We show the first near-optimal rate that achieves privacy and robustness to label corruptions simultaneously. When there is no label corruption, our result also improves upon the state-of-the-art method [81] in terms of the condition number \\(\\kappa\\). Compared to [81], our algorithm has two innovations: 1) we introduce a novel adaptive clipping, which is critical in achieving robustness against label corruptions; and 2) we use full batch gradient descent and a novel convergence analysis to get the near-optimal sample complexity.\n\nAcknowledgement\n\nWe thank Abhradeep Guha Thakurta for helpful discussions while working on this paper. This material is based upon work supported by the National Science Foundation under grants no. 2134012, 2019844, 2112471, and 2229876, and is supported in part by funds provided by the National Science Foundation, by the Department of Homeland Security, and by IBM. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation or its federal agency and industry partners.\n\n10", "md": "(see Alg. 1) as follows:\n\n$$\nw_{t+1} - w^* = I - \\eta x_ix^T(w_t - w^*) + \\eta x_iz_i + \\eta \\left(g(t) - \\tilde{g} - \\eta\\phi_t\\nu_t\\right).\n$$\nIn the above equation, the first term is a contraction, meaning \\(w_t\\) is moving toward \\(w^*\\). The second term captures the noise from the randomness in the samples. The third term captures the bias introduced by the clipping operation, and the fourth term captures the added noise for privacy. The second term is standard and relatively easy to control, and our main focus is on the last two terms. The third term \\(\\left(\\frac{\\eta}{n} \\sum_{i \\in S} (g(t)_i - \\tilde{g}_i)\\right)\\) can be controlled using the resilience property. We prove that with our estimated threshold, the clipping will only affect a small amount of datapoints, whose contribution to the gradient is small collectively.\n\nNow we have controlled the deterministic bias. Then, we upper bound the fourth term, which is the noise for the purpose of privacy, and show the expected prediction error decrease in every gradient step. The difficulty is that, since our clipping threshold is adaptive, the decrease of the estimation error depends on the estimation error of all the previous steps. This causes that in some iterations, the estimation error actually increases. In order to get around this, we split the iterations into length \\(\\kappa\\) chunks, and argue that the maximum estimation error in a chunk must be a constant factor smaller than the previous chunk. This implies we will reach the desired error within \\(\\tilde{O}(\\kappa)\\) steps.\n\n6 Conclusion\n\nWe provide a novel variant of DP-SGD algorithm for differentially private linear regression under label corruption. We show the first near-optimal rate that achieves privacy and robustness to label corruptions simultaneously. When there is no label corruption, our result also improves upon the state-of-the-art method [81] in terms of the condition number \\(\\kappa\\). Compared to [81], our algorithm has two innovations: 1) we introduce a novel adaptive clipping, which is critical in achieving robustness against label corruptions; and 2) we use full batch gradient descent and a novel convergence analysis to get the near-optimal sample complexity.\n\nAcknowledgement\n\nWe thank Abhradeep Guha Thakurta for helpful discussions while working on this paper. This material is based upon work supported by the National Science Foundation under grants no. 2134012, 2019844, 2112471, and 2229876, and is supported in part by funds provided by the National Science Foundation, by the Department of Homeland Security, and by IBM. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation or its federal agency and industry partners.\n\n10"}]}, {"page": 11, "text": "References\n [1] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar,\n     and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC\n     conference on computer and communications security, pages 308\u2013318, 2016.\n [2] John M Abowd. The US Census Bureau adopts differential privacy. In Proceedings of the\n     24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages\n     2867\u20132867, 2018.\n [3] Anish Agarwal, Devavrat Shah, Dennis Shen, and Dogyoon Song. On robustness of principal\n     component regression. Advances in Neural Information Processing Systems, 32, 2019.\n [4] Daniel Alabi, Pravesh K Kothari, Pranay Tankala, Prayaag Venkat, and Fred Zhang. Privately\n     estimating a gaussian: Efficient, robust and optimal. arXiv preprint arXiv:2212.08018, 2022.\n [5] Daniel Alabi, Audra McMillan, Jayshree Sarathy, Adam Smith, and Salil Vadhan. Differentially\n     private simple linear regression. arXiv preprint arXiv:2007.05157, 2020.\n [6] Kareem Amin, Matthew Joseph, M\u00f3nica Ribero, and Sergei Vassilvitskii. Easy differentially\n     private linear regression. arXiv preprint arXiv:2208.07353, 2022.\n [7] Galen Andrew, Om Thakkar, Brendan McMahan, and Swaroop Ramaswamy. Differentially\n     private learning with adaptive clipping. Advances in Neural Information Processing Systems,\n     34, 2021.\n [8] Hassan Ashtiani and Christopher Liaw. Private and polynomial time algorithms for learning\n     gaussians and beyond. In Conference on Learning Theory, pages 1075\u20131076. PMLR, 2022.\n [9] Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimiza-\n     tion: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages\n     393\u2013403. PMLR, 2021.\n[10] Hilal Asi, Jonathan Ullman, and Lydia Zakynthinou. From robustness to privacy and back.\n     arXiv preprint arXiv:2302.01855, 2023.\n[11] Ainesh Bakshi and Adarsh Prasad. Robust linear regression: Optimal rates in polynomial time.\n     In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages\n     102\u2013115, 2021.\n[12] Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Guha Thakurta. Private stochastic\n     convex optimization with optimal rates. Advances in Neural Information Processing Systems,\n     32, 2019.\n[13] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Effi-\n     cient algorithms and tight error bounds. In 2014 IEEE 55th Annual Symposium on Foundations\n     of Computer Science, pages 464\u2013473. IEEE, 2014.\n[14] Kush Bhatia, Prateek Jain, Parameswaran Kamalaruban, and Purushottam Kar. Consistent\n     robust regression. Advances in Neural Information Processing Systems, 30, 2017.\n[15] Kush Bhatia, Prateek Jain, and Purushottam Kar. Robust regression via hard thresholding.\n     Advances in neural information processing systems, 28, 2015.\n[16] T Tony Cai, Yichen Wang, and Linjun Zhang. Score attack: A lower bound technique for\n     optimal differentially private learning. arXiv preprint arXiv:2303.07152, 2023.\n[17] Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate. Differentially private empirical\n     risk minimization. Journal of Machine Learning Research, 12(3), 2011.\n[18] Yu Cheng, Ilias Diakonikolas, and Rong Ge. High-dimensional robust mean estimation in\n     nearly-linear time. In Proceedings of the thirtieth annual ACM-SIAM symposium on discrete\n     algorithms, pages 2755\u20132771. SIAM, 2019.\n                                                11", "md": "# References\n\n## References\n\n|[1]|Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308\u2013318, 2016.|\n|---|---|\n|[2]|John M Abowd. The US Census Bureau adopts differential privacy. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 2867\u20132867, 2018.|\n|[3]|Anish Agarwal, Devavrat Shah, Dennis Shen, and Dogyoon Song. On robustness of principal component regression. Advances in Neural Information Processing Systems, 32, 2019.|\n|[4]|Daniel Alabi, Pravesh K Kothari, Pranay Tankala, Prayaag Venkat, and Fred Zhang. Privately estimating a gaussian: Efficient, robust and optimal. arXiv preprint arXiv:2212.08018, 2022.|\n|[5]|Daniel Alabi, Audra McMillan, Jayshree Sarathy, Adam Smith, and Salil Vadhan. Differentially private simple linear regression. arXiv preprint arXiv:2007.05157, 2020.|\n|[6]|Kareem Amin, Matthew Joseph, M\u00f3nica Ribero, and Sergei Vassilvitskii. Easy differentially private linear regression. arXiv preprint arXiv:2208.07353, 2022.|\n|[7]|Galen Andrew, Om Thakkar, Brendan McMahan, and Swaroop Ramaswamy. Differentially private learning with adaptive clipping. Advances in Neural Information Processing Systems, 34, 2021.|\n|[8]|Hassan Ashtiani and Christopher Liaw. Private and polynomial time algorithms for learning gaussians and beyond. In Conference on Learning Theory, pages 1075\u20131076. PMLR, 2022.|\n|[9]|Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021.|\n|[10]|Hilal Asi, Jonathan Ullman, and Lydia Zakynthinou. From robustness to privacy and back. arXiv preprint arXiv:2302.01855, 2023.|\n|[11]|Ainesh Bakshi and Adarsh Prasad. Robust linear regression: Optimal rates in polynomial time. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 102\u2013115, 2021.|\n|[12]|Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Guha Thakurta. Private stochastic convex optimization with optimal rates. Advances in Neural Information Processing Systems, 32, 2019.|\n|[13]|Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In 2014 IEEE 55th Annual Symposium on Foundations of Computer Science, pages 464\u2013473. IEEE, 2014.|\n|[14]|Kush Bhatia, Prateek Jain, Parameswaran Kamalaruban, and Purushottam Kar. Consistent robust regression. Advances in Neural Information Processing Systems, 30, 2017.|\n|[15]|Kush Bhatia, Prateek Jain, and Purushottam Kar. Robust regression via hard thresholding. Advances in neural information processing systems, 28, 2015.|\n|[16]|T Tony Cai, Yichen Wang, and Linjun Zhang. Score attack: A lower bound technique for optimal differentially private learning. arXiv preprint arXiv:2303.07152, 2023.|\n|[17]|Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate. Differentially private empirical risk minimization. Journal of Machine Learning Research, 12(3), 2011.|\n|[18]|Yu Cheng, Ilias Diakonikolas, and Rong Ge. High-dimensional robust mean estimation in nearly-linear time. In Proceedings of the thirtieth annual ACM-SIAM symposium on discrete algorithms, pages 2755\u20132771. SIAM, 2019.|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 2, "value": "References", "md": "## References"}, {"type": "table", "rows": [["[1]", "Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308\u2013318, 2016."], ["[2]", "John M Abowd. The US Census Bureau adopts differential privacy. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 2867\u20132867, 2018."], ["[3]", "Anish Agarwal, Devavrat Shah, Dennis Shen, and Dogyoon Song. On robustness of principal component regression. Advances in Neural Information Processing Systems, 32, 2019."], ["[4]", "Daniel Alabi, Pravesh K Kothari, Pranay Tankala, Prayaag Venkat, and Fred Zhang. Privately estimating a gaussian: Efficient, robust and optimal. arXiv preprint arXiv:2212.08018, 2022."], ["[5]", "Daniel Alabi, Audra McMillan, Jayshree Sarathy, Adam Smith, and Salil Vadhan. Differentially private simple linear regression. arXiv preprint arXiv:2007.05157, 2020."], ["[6]", "Kareem Amin, Matthew Joseph, M\u00f3nica Ribero, and Sergei Vassilvitskii. Easy differentially private linear regression. arXiv preprint arXiv:2208.07353, 2022."], ["[7]", "Galen Andrew, Om Thakkar, Brendan McMahan, and Swaroop Ramaswamy. Differentially private learning with adaptive clipping. Advances in Neural Information Processing Systems, 34, 2021."], ["[8]", "Hassan Ashtiani and Christopher Liaw. Private and polynomial time algorithms for learning gaussians and beyond. In Conference on Learning Theory, pages 1075\u20131076. PMLR, 2022."], ["[9]", "Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021."], ["[10]", "Hilal Asi, Jonathan Ullman, and Lydia Zakynthinou. From robustness to privacy and back. arXiv preprint arXiv:2302.01855, 2023."], ["[11]", "Ainesh Bakshi and Adarsh Prasad. Robust linear regression: Optimal rates in polynomial time. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 102\u2013115, 2021."], ["[12]", "Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Guha Thakurta. Private stochastic convex optimization with optimal rates. Advances in Neural Information Processing Systems, 32, 2019."], ["[13]", "Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In 2014 IEEE 55th Annual Symposium on Foundations of Computer Science, pages 464\u2013473. IEEE, 2014."], ["[14]", "Kush Bhatia, Prateek Jain, Parameswaran Kamalaruban, and Purushottam Kar. Consistent robust regression. Advances in Neural Information Processing Systems, 30, 2017."], ["[15]", "Kush Bhatia, Prateek Jain, and Purushottam Kar. Robust regression via hard thresholding. Advances in neural information processing systems, 28, 2015."], ["[16]", "T Tony Cai, Yichen Wang, and Linjun Zhang. Score attack: A lower bound technique for optimal differentially private learning. arXiv preprint arXiv:2303.07152, 2023."], ["[17]", "Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate. Differentially private empirical risk minimization. Journal of Machine Learning Research, 12(3), 2011."], ["[18]", "Yu Cheng, Ilias Diakonikolas, and Rong Ge. High-dimensional robust mean estimation in nearly-linear time. In Proceedings of the thirtieth annual ACM-SIAM symposium on discrete algorithms, pages 2755\u20132771. SIAM, 2019."]], "md": "|[1]|Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308\u2013318, 2016.|\n|---|---|\n|[2]|John M Abowd. The US Census Bureau adopts differential privacy. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 2867\u20132867, 2018.|\n|[3]|Anish Agarwal, Devavrat Shah, Dennis Shen, and Dogyoon Song. On robustness of principal component regression. Advances in Neural Information Processing Systems, 32, 2019.|\n|[4]|Daniel Alabi, Pravesh K Kothari, Pranay Tankala, Prayaag Venkat, and Fred Zhang. Privately estimating a gaussian: Efficient, robust and optimal. arXiv preprint arXiv:2212.08018, 2022.|\n|[5]|Daniel Alabi, Audra McMillan, Jayshree Sarathy, Adam Smith, and Salil Vadhan. Differentially private simple linear regression. arXiv preprint arXiv:2007.05157, 2020.|\n|[6]|Kareem Amin, Matthew Joseph, M\u00f3nica Ribero, and Sergei Vassilvitskii. Easy differentially private linear regression. arXiv preprint arXiv:2208.07353, 2022.|\n|[7]|Galen Andrew, Om Thakkar, Brendan McMahan, and Swaroop Ramaswamy. Differentially private learning with adaptive clipping. Advances in Neural Information Processing Systems, 34, 2021.|\n|[8]|Hassan Ashtiani and Christopher Liaw. Private and polynomial time algorithms for learning gaussians and beyond. In Conference on Learning Theory, pages 1075\u20131076. PMLR, 2022.|\n|[9]|Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021.|\n|[10]|Hilal Asi, Jonathan Ullman, and Lydia Zakynthinou. From robustness to privacy and back. arXiv preprint arXiv:2302.01855, 2023.|\n|[11]|Ainesh Bakshi and Adarsh Prasad. Robust linear regression: Optimal rates in polynomial time. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 102\u2013115, 2021.|\n|[12]|Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Guha Thakurta. Private stochastic convex optimization with optimal rates. Advances in Neural Information Processing Systems, 32, 2019.|\n|[13]|Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In 2014 IEEE 55th Annual Symposium on Foundations of Computer Science, pages 464\u2013473. IEEE, 2014.|\n|[14]|Kush Bhatia, Prateek Jain, Parameswaran Kamalaruban, and Purushottam Kar. Consistent robust regression. Advances in Neural Information Processing Systems, 30, 2017.|\n|[15]|Kush Bhatia, Prateek Jain, and Purushottam Kar. Robust regression via hard thresholding. Advances in neural information processing systems, 28, 2015.|\n|[16]|T Tony Cai, Yichen Wang, and Linjun Zhang. Score attack: A lower bound technique for optimal differentially private learning. arXiv preprint arXiv:2303.07152, 2023.|\n|[17]|Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate. Differentially private empirical risk minimization. Journal of Machine Learning Research, 12(3), 2011.|\n|[18]|Yu Cheng, Ilias Diakonikolas, and Rong Ge. High-dimensional robust mean estimation in nearly-linear time. In Proceedings of the thirtieth annual ACM-SIAM symposium on discrete algorithms, pages 2755\u20132771. SIAM, 2019.|", "isPerfectTable": true, "csv": "\"[1]\",\"Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308\u2013318, 2016.\"\n\"[2]\",\"John M Abowd. The US Census Bureau adopts differential privacy. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 2867\u20132867, 2018.\"\n\"[3]\",\"Anish Agarwal, Devavrat Shah, Dennis Shen, and Dogyoon Song. On robustness of principal component regression. Advances in Neural Information Processing Systems, 32, 2019.\"\n\"[4]\",\"Daniel Alabi, Pravesh K Kothari, Pranay Tankala, Prayaag Venkat, and Fred Zhang. Privately estimating a gaussian: Efficient, robust and optimal. arXiv preprint arXiv:2212.08018, 2022.\"\n\"[5]\",\"Daniel Alabi, Audra McMillan, Jayshree Sarathy, Adam Smith, and Salil Vadhan. Differentially private simple linear regression. arXiv preprint arXiv:2007.05157, 2020.\"\n\"[6]\",\"Kareem Amin, Matthew Joseph, M\u00f3nica Ribero, and Sergei Vassilvitskii. Easy differentially private linear regression. arXiv preprint arXiv:2208.07353, 2022.\"\n\"[7]\",\"Galen Andrew, Om Thakkar, Brendan McMahan, and Swaroop Ramaswamy. Differentially private learning with adaptive clipping. Advances in Neural Information Processing Systems, 34, 2021.\"\n\"[8]\",\"Hassan Ashtiani and Christopher Liaw. Private and polynomial time algorithms for learning gaussians and beyond. In Conference on Learning Theory, pages 1075\u20131076. PMLR, 2022.\"\n\"[9]\",\"Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021.\"\n\"[10]\",\"Hilal Asi, Jonathan Ullman, and Lydia Zakynthinou. From robustness to privacy and back. arXiv preprint arXiv:2302.01855, 2023.\"\n\"[11]\",\"Ainesh Bakshi and Adarsh Prasad. Robust linear regression: Optimal rates in polynomial time. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 102\u2013115, 2021.\"\n\"[12]\",\"Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Guha Thakurta. Private stochastic convex optimization with optimal rates. Advances in Neural Information Processing Systems, 32, 2019.\"\n\"[13]\",\"Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In 2014 IEEE 55th Annual Symposium on Foundations of Computer Science, pages 464\u2013473. IEEE, 2014.\"\n\"[14]\",\"Kush Bhatia, Prateek Jain, Parameswaran Kamalaruban, and Purushottam Kar. Consistent robust regression. Advances in Neural Information Processing Systems, 30, 2017.\"\n\"[15]\",\"Kush Bhatia, Prateek Jain, and Purushottam Kar. Robust regression via hard thresholding. Advances in neural information processing systems, 28, 2015.\"\n\"[16]\",\"T Tony Cai, Yichen Wang, and Linjun Zhang. Score attack: A lower bound technique for optimal differentially private learning. arXiv preprint arXiv:2303.07152, 2023.\"\n\"[17]\",\"Kamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate. Differentially private empirical risk minimization. Journal of Machine Learning Research, 12(3), 2011.\"\n\"[18]\",\"Yu Cheng, Ilias Diakonikolas, and Rong Ge. High-dimensional robust mean estimation in nearly-linear time. In Proceedings of the thirtieth annual ACM-SIAM symposium on discrete algorithms, pages 2755\u20132771. SIAM, 2019.\""}]}, {"page": 12, "text": "[19] Yeshwanth Cherapanamjeri, Efe Aras, Nilesh Tripuraneni, Michael I Jordan, Nicolas Flammar-\n      ion, and Peter L Bartlett. Optimal robust linear regression in nearly linear time. arXiv preprint\n      arXiv:2007.08137, 2020.\n[20] Christopher A. Choquette-Choo, Krishnamurthy Dvijotham, Krishna Pillutla, Arun Ganesh,\n      Thomas Steinke, and Abhradeep Thakurta. Correlated noise provably beats independent noise\n      for differentially private learning, 2023.\n[21] Arnak Dalalyan and Philip Thompson. Outlier-robust estimation of a sparse linear model using\n      \u21131 -penalized huber\u2019s m-estimator. Advances in neural information processing systems, 32,\n      2019.\n[22] Jules Depersin. A spectral algorithm for robust regression with subgaussian rates. arXiv preprint\n      arXiv:2007.06072, 2020.\n[23] Ilias Diakonikolas, Samuel B Hopkins, Daniel Kane, and Sushrut Karmalkar. Robustly learning\n      any clusterable mixture of gaussians. arXiv preprint arXiv:2005.06417, 2020.\n[24] Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart.\n      Robust estimators in high-dimensions without the computational intractability. SIAM Journal\n      on Computing, 48(2):742\u2013864, 2019.\n[25] Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Jacob Steinhardt, and Alistair Stew-\n      art. Sever: A robust meta-algorithm for stochastic optimization. In International Conference on\n      Machine Learning, pages 1596\u20131606, 2019.\n[26] Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair\n      Stewart. Being robust (in high dimensions) can be practical. In International Conference on\n      Machine Learning, pages 999\u20131008. PMLR, 2017.\n[27] Ilias Diakonikolas and Daniel M Kane. Recent advances in algorithmic high-dimensional robust\n      statistics. arXiv preprint arXiv:1911.05911, 2019.\n[28] Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. List-decodable robust mean estimation\n      and learning mixtures of spherical gaussians. In Proceedings of the 50th Annual ACM SIGACT\n      Symposium on Theory of Computing, pages 1047\u20131060, 2018.\n[29] Ilias Diakonikolas, Weihao Kong, and Alistair Stewart. Efficient algorithms and lower bounds\n      for robust linear regression. In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on\n      Discrete Algorithms, pages 2745\u20132754. SIAM, 2019.\n[30] Christos Dimitrakakis, Blaine Nelson, Aikaterini Mitrokotsa, and Benjamin IP Rubinstein.\n      Robust and private bayesian inference. In International Conference on Algorithmic Learning\n      Theory, pages 291\u2013305. Springer, 2014.\n[31] Yihe Dong, Samuel Hopkins, and Jerry Li. Quantum entropy scoring for fast robust mean\n      estimation and improved outlier detection. Advances in Neural Information Processing Systems,\n      32, 2019.\n[32] Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In Proceedings of the\n      forty-first annual ACM symposium on Theory of computing, pages 371\u2013380, 2009.\n[33] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to\n      sensitivity in private data analysis. In Theory of cryptography conference, pages 265\u2013284.\n      Springer, 2006.\n[34] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Founda-\n      tions and Trends in Theoretical Computer Science, 9(3-4):211\u2013407, 2014.\n[35] \u00dalfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. Rappor: Randomized aggregatable\n      privacy-preserving ordinal response. In Proceedings of the 2014 ACM SIGSAC conference on\n      computer and communications security, pages 1054\u20131067, 2014.\n                                                   12", "md": "1. Yeshwanth Cherapanamjeri, Efe Aras, Nilesh Tripuraneni, Michael I Jordan, Nicolas Flammarion, and Peter L Bartlett. *Optimal robust linear regression in nearly linear time.* arXiv preprint arXiv:2007.08137, 2020.\n2. Christopher A. Choquette-Choo, Krishnamurthy Dvijotham, Krishna Pillutla, Arun Ganesh, Thomas Steinke, and Abhradeep Thakurta. *Correlated noise provably beats independent noise for differentially private learning*, 2023.\n3. Arnak Dalalyan and Philip Thompson. *Outlier-robust estimation of a sparse linear model using $\\ell_1$-penalized Huber's M-estimator.* Advances in Neural Information Processing Systems, 32, 2019.\n4. Jules Depersin. *A spectral algorithm for robust regression with subgaussian rates.* arXiv preprint arXiv:2007.06072, 2020.\n5. Ilias Diakonikolas, Samuel B Hopkins, Daniel Kane, and Sushrut Karmalkar. *Robustly learning any clusterable mixture of Gaussians.* arXiv preprint arXiv:2005.06417, 2020.\n6. Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. *Robust estimators in high-dimensions without the computational intractability.* SIAM Journal on Computing, 48(2):742\u2013864, 2019.\n7. Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Jacob Steinhardt, and Alistair Stewart. *Sever: A robust meta-algorithm for stochastic optimization.* In International Conference on Machine Learning, pages 1596\u20131606, 2019.\n8. Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. *Being robust (in high dimensions) can be practical.* In International Conference on Machine Learning, pages 999\u20131008. PMLR, 2017.\n9. Ilias Diakonikolas and Daniel M Kane. *Recent advances in algorithmic high-dimensional robust statistics.* arXiv preprint arXiv:1911.05911, 2019.\n10. Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. *List-decodable robust mean estimation and learning mixtures of spherical Gaussians.* In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, pages 1047\u20131060, 2018.\n11. Ilias Diakonikolas, Weihao Kong, and Alistair Stewart. *Efficient algorithms and lower bounds for robust linear regression.* In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 2745\u20132754. SIAM, 2019.\n12. Christos Dimitrakakis, Blaine Nelson, Aikaterini Mitrokotsa, and Benjamin IP Rubinstein. *Robust and private Bayesian inference.* In International Conference on Algorithmic Learning Theory, pages 291\u2013305. Springer, 2014.\n13. Yihe Dong, Samuel Hopkins, and Jerry Li. *Quantum entropy scoring for fast robust mean estimation and improved outlier detection.* Advances in Neural Information Processing Systems, 32, 2019.\n14. Cynthia Dwork and Jing Lei. *Differential privacy and robust statistics.* In Proceedings of the forty-first annual ACM symposium on Theory of Computing, pages 371\u2013380, 2009.\n15. Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. *Calibrating noise to sensitivity in private data analysis.* In Theory of Cryptography Conference, pages 265\u2013284. Springer, 2006.\n16. Cynthia Dwork and Aaron Roth. *The algorithmic foundations of differential privacy.* Foundations and Trends in Theoretical Computer Science, 9(3-4):211\u2013407, 2014.\n17. \u00dalfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. *Rappor: Randomized aggregatable privacy-preserving ordinal response.* In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 1054\u20131067, 2014.", "images": [], "items": [{"type": "text", "value": "1. Yeshwanth Cherapanamjeri, Efe Aras, Nilesh Tripuraneni, Michael I Jordan, Nicolas Flammarion, and Peter L Bartlett. *Optimal robust linear regression in nearly linear time.* arXiv preprint arXiv:2007.08137, 2020.\n2. Christopher A. Choquette-Choo, Krishnamurthy Dvijotham, Krishna Pillutla, Arun Ganesh, Thomas Steinke, and Abhradeep Thakurta. *Correlated noise provably beats independent noise for differentially private learning*, 2023.\n3. Arnak Dalalyan and Philip Thompson. *Outlier-robust estimation of a sparse linear model using $\\ell_1$-penalized Huber's M-estimator.* Advances in Neural Information Processing Systems, 32, 2019.\n4. Jules Depersin. *A spectral algorithm for robust regression with subgaussian rates.* arXiv preprint arXiv:2007.06072, 2020.\n5. Ilias Diakonikolas, Samuel B Hopkins, Daniel Kane, and Sushrut Karmalkar. *Robustly learning any clusterable mixture of Gaussians.* arXiv preprint arXiv:2005.06417, 2020.\n6. Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. *Robust estimators in high-dimensions without the computational intractability.* SIAM Journal on Computing, 48(2):742\u2013864, 2019.\n7. Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Jacob Steinhardt, and Alistair Stewart. *Sever: A robust meta-algorithm for stochastic optimization.* In International Conference on Machine Learning, pages 1596\u20131606, 2019.\n8. Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. *Being robust (in high dimensions) can be practical.* In International Conference on Machine Learning, pages 999\u20131008. PMLR, 2017.\n9. Ilias Diakonikolas and Daniel M Kane. *Recent advances in algorithmic high-dimensional robust statistics.* arXiv preprint arXiv:1911.05911, 2019.\n10. Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. *List-decodable robust mean estimation and learning mixtures of spherical Gaussians.* In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, pages 1047\u20131060, 2018.\n11. Ilias Diakonikolas, Weihao Kong, and Alistair Stewart. *Efficient algorithms and lower bounds for robust linear regression.* In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 2745\u20132754. SIAM, 2019.\n12. Christos Dimitrakakis, Blaine Nelson, Aikaterini Mitrokotsa, and Benjamin IP Rubinstein. *Robust and private Bayesian inference.* In International Conference on Algorithmic Learning Theory, pages 291\u2013305. Springer, 2014.\n13. Yihe Dong, Samuel Hopkins, and Jerry Li. *Quantum entropy scoring for fast robust mean estimation and improved outlier detection.* Advances in Neural Information Processing Systems, 32, 2019.\n14. Cynthia Dwork and Jing Lei. *Differential privacy and robust statistics.* In Proceedings of the forty-first annual ACM symposium on Theory of Computing, pages 371\u2013380, 2009.\n15. Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. *Calibrating noise to sensitivity in private data analysis.* In Theory of Cryptography Conference, pages 265\u2013284. Springer, 2006.\n16. Cynthia Dwork and Aaron Roth. *The algorithmic foundations of differential privacy.* Foundations and Trends in Theoretical Computer Science, 9(3-4):211\u2013407, 2014.\n17. \u00dalfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. *Rappor: Randomized aggregatable privacy-preserving ordinal response.* In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 1054\u20131067, 2014.", "md": "1. Yeshwanth Cherapanamjeri, Efe Aras, Nilesh Tripuraneni, Michael I Jordan, Nicolas Flammarion, and Peter L Bartlett. *Optimal robust linear regression in nearly linear time.* arXiv preprint arXiv:2007.08137, 2020.\n2. Christopher A. Choquette-Choo, Krishnamurthy Dvijotham, Krishna Pillutla, Arun Ganesh, Thomas Steinke, and Abhradeep Thakurta. *Correlated noise provably beats independent noise for differentially private learning*, 2023.\n3. Arnak Dalalyan and Philip Thompson. *Outlier-robust estimation of a sparse linear model using $\\ell_1$-penalized Huber's M-estimator.* Advances in Neural Information Processing Systems, 32, 2019.\n4. Jules Depersin. *A spectral algorithm for robust regression with subgaussian rates.* arXiv preprint arXiv:2007.06072, 2020.\n5. Ilias Diakonikolas, Samuel B Hopkins, Daniel Kane, and Sushrut Karmalkar. *Robustly learning any clusterable mixture of Gaussians.* arXiv preprint arXiv:2005.06417, 2020.\n6. Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. *Robust estimators in high-dimensions without the computational intractability.* SIAM Journal on Computing, 48(2):742\u2013864, 2019.\n7. Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Jacob Steinhardt, and Alistair Stewart. *Sever: A robust meta-algorithm for stochastic optimization.* In International Conference on Machine Learning, pages 1596\u20131606, 2019.\n8. Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. *Being robust (in high dimensions) can be practical.* In International Conference on Machine Learning, pages 999\u20131008. PMLR, 2017.\n9. Ilias Diakonikolas and Daniel M Kane. *Recent advances in algorithmic high-dimensional robust statistics.* arXiv preprint arXiv:1911.05911, 2019.\n10. Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. *List-decodable robust mean estimation and learning mixtures of spherical Gaussians.* In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, pages 1047\u20131060, 2018.\n11. Ilias Diakonikolas, Weihao Kong, and Alistair Stewart. *Efficient algorithms and lower bounds for robust linear regression.* In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 2745\u20132754. SIAM, 2019.\n12. Christos Dimitrakakis, Blaine Nelson, Aikaterini Mitrokotsa, and Benjamin IP Rubinstein. *Robust and private Bayesian inference.* In International Conference on Algorithmic Learning Theory, pages 291\u2013305. Springer, 2014.\n13. Yihe Dong, Samuel Hopkins, and Jerry Li. *Quantum entropy scoring for fast robust mean estimation and improved outlier detection.* Advances in Neural Information Processing Systems, 32, 2019.\n14. Cynthia Dwork and Jing Lei. *Differential privacy and robust statistics.* In Proceedings of the forty-first annual ACM symposium on Theory of Computing, pages 371\u2013380, 2009.\n15. Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. *Calibrating noise to sensitivity in private data analysis.* In Theory of Cryptography Conference, pages 265\u2013284. Springer, 2006.\n16. Cynthia Dwork and Aaron Roth. *The algorithmic foundations of differential privacy.* Foundations and Trends in Theoretical Computer Science, 9(3-4):211\u2013407, 2014.\n17. \u00dalfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. *Rappor: Randomized aggregatable privacy-preserving ordinal response.* In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 1054\u20131067, 2014."}]}, {"page": 13, "text": "[36] Giulia Fanti, Vasyl Pihur, and \u00dalfar Erlingsson. Building a rappor with the unknown: Privacy-\n      preserving learning of associations and data dictionaries. Proceedings on Privacy Enhancing\n     Technologies, 2016(3):41\u201361, 2016.\n[37] Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization:\n      optimal rates in linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on\n     Theory of Computing, pages 439\u2013449, 2020.\n[38] James Foulds, Joseph Geumlek, Max Welling, and Kamalika Chaudhuri. On the theory and\n      practice of privacy-preserving bayesian data analysis. arXiv preprint arXiv:1603.07294, 2016.\n[39] Arun Ganesh, Mahdi Haghifam, Thomas Steinke, and Abhradeep Thakurta. Faster differentially\n      private convex optimization via second-order methods. arXiv preprint arXiv:2305.13209, 2023.\n[40] Arun Ganesh, Daogao Liu, Sewoong Oh, and Abhradeep Thakurta. Private (stochastic) non-\n      convex optimization revisited: Second-order stationary points and excess risks. arXiv preprint\n      arXiv:2302.09699, 2023.\n[41] Quan Geng, Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The staircase mechanism in\n      differential privacy. IEEE Journal of Selected Topics in Signal Processing, 9(7):1176\u20131184,\n      2015.\n[42] Antonious M Girgis, Deepesh Data, Suhas Diggavi, Ananda Theertha Suresh, and Peter Kairouz.\n      On the renyi differential privacy of the shuffle model. In Proceedings of the 2021 ACM SIGSAC\n     Conference on Computer and Communications Security, pages 2321\u20132341, 2021.\n[43] Sivakanth Gopi, Yin Tat Lee, and Lukas Wutschitz. Numerical composition of differential\n      privacy. Advances in Neural Information Processing Systems, 34:11631\u201311642, 2021.\n[44] Samuel B Hopkins, Gautam Kamath, and Mahbod Majid. Efficient mean estimation with pure\n      differential privacy via a sum-of-squares exponential mechanism. In Proceedings of the 54th\n     Annual ACM SIGACT Symposium on Theory of Computing, pages 1406\u20131417, 2022.\n[45] Samuel B Hopkins, Gautam Kamath, Mahbod Majid, and Shyam Narayanan. Robustness\n      implies privacy in statistical estimation. arXiv preprint arXiv:2212.05015, 2022.\n[46] Peter J Huber. Robust estimation of a location parameter. In Breakthroughs in statistics, pages\n     492\u2013518. Springer, 1992.\n[47] Arun Jambulapati, Jerry Li, and Kevin Tian. Robust sub-gaussian principal component analysis\n      and width-independent schatten packing. Advances in Neural Information Processing Systems,\n      33, 2020.\n[48] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. Extremal mechanisms for local differential\n      privacy. Advances in neural information processing systems, 27, 2014.\n[49] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential\n      privacy. In International conference on machine learning, pages 1376\u20131385. PMLR, 2015.\n[50] Gautam Kamath, Xingtu Liu, and Huanyu Zhang. Improved rates for differentially private\n      stochastic convex optimization with heavy-tailed data. arXiv preprint arXiv:2106.01336, 2021.\n[51] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. arXiv\n      preprint arXiv:1711.03908, 2017.\n[52] Ashish Khetan, Zachary C Lipton, and Animashree Anandkumar. Learning from noisy singly-\n      labeled data. In International Conference on Learning Representations, 2018.\n[53] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization\n      and high-dimensional regression. In Conference on Learning Theory, pages 25\u20131. JMLR\n     Workshop and Conference Proceedings, 2012.\n[54] Adam Klivans, Pravesh K Kothari, and Raghu Meka. Effi        cient algorithms for outlier-robust\n      regression. In Conference On Learning Theory, pages 1420\u20131430. PMLR, 2018.\n                                                 13", "md": "- [36] Giulia Fanti, Vasyl Pihur, and \u00dalfar Erlingsson. Building a rappor with the unknown: Privacy-preserving learning of associations and data dictionaries. Proceedings on Privacy Enhancing Technologies, 2016(3):41\u201361, 2016.\n- [37] Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: optimal rates in linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, pages 439\u2013449, 2020.\n- [38] James Foulds, Joseph Geumlek, Max Welling, and Kamalika Chaudhuri. On the theory and practice of privacy-preserving Bayesian data analysis. arXiv preprint arXiv:1603.07294, 2016.\n- [39] Arun Ganesh, Mahdi Haghifam, Thomas Steinke, and Abhradeep Thakurta. Faster differentially private convex optimization via second-order methods. arXiv preprint arXiv:2305.13209, 2023.\n- [40] Arun Ganesh, Daogao Liu, Sewoong Oh, and Abhradeep Thakurta. Private (stochastic) non-convex optimization revisited: Second-order stationary points and excess risks. arXiv preprint arXiv:2302.09699, 2023.\n- [41] Quan Geng, Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The staircase mechanism in differential privacy. IEEE Journal of Selected Topics in Signal Processing, 9(7):1176\u20131184, 2015.\n- [42] Antonious M Girgis, Deepesh Data, Suhas Diggavi, Ananda Theertha Suresh, and Peter Kairouz. On the Renyi differential privacy of the shuffle model. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 2321\u20132341, 2021.\n- [43] Sivakanth Gopi, Yin Tat Lee, and Lukas Wutschitz. Numerical composition of differential privacy. Advances in Neural Information Processing Systems, 34:11631\u201311642, 2021.\n- [44] Samuel B Hopkins, Gautam Kamath, and Mahbod Majid. Efficient mean estimation with pure differential privacy via a sum-of-squares exponential mechanism. In Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing, pages 1406\u20131417, 2022.\n- [45] Samuel B Hopkins, Gautam Kamath, Mahbod Majid, and Shyam Narayanan. Robustness implies privacy in statistical estimation. arXiv preprint arXiv:2212.05015, 2022.\n- [46] Peter J Huber. Robust estimation of a location parameter. In Breakthroughs in statistics, pages 492\u2013518. Springer, 1992.\n- [47] Arun Jambulapati, Jerry Li, and Kevin Tian. Robust sub-Gaussian principal component analysis and width-independent Schatten packing. Advances in Neural Information Processing Systems, 33, 2020.\n- [48] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. Extremal mechanisms for local differential privacy. Advances in Neural Information Processing Systems, 27, 2014.\n- [49] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy. In International conference on machine learning, pages 1376\u20131385. PMLR, 2015.\n- [50] Gautam Kamath, Xingtu Liu, and Huanyu Zhang. Improved rates for differentially private stochastic convex optimization with heavy-tailed data. arXiv preprint arXiv:2106.01336, 2021.\n- [51] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. arXiv preprint arXiv:1711.03908, 2017.\n- [52] Ashish Khetan, Zachary C Lipton, and Animashree Anandkumar. Learning from noisy singly-labeled data. In International Conference on Learning Representations, 2018.\n- [53] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In Conference on Learning Theory, pages 25\u20131. JMLR Workshop and Conference Proceedings, 2012.\n- [54] Adam Klivans, Pravesh K Kothari, and Raghu Meka. Efficient algorithms for outlier-robust regression. In Conference On Learning Theory, pages 1420\u20131430. PMLR, 2018.", "images": [], "items": [{"type": "text", "value": "- [36] Giulia Fanti, Vasyl Pihur, and \u00dalfar Erlingsson. Building a rappor with the unknown: Privacy-preserving learning of associations and data dictionaries. Proceedings on Privacy Enhancing Technologies, 2016(3):41\u201361, 2016.\n- [37] Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: optimal rates in linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, pages 439\u2013449, 2020.\n- [38] James Foulds, Joseph Geumlek, Max Welling, and Kamalika Chaudhuri. On the theory and practice of privacy-preserving Bayesian data analysis. arXiv preprint arXiv:1603.07294, 2016.\n- [39] Arun Ganesh, Mahdi Haghifam, Thomas Steinke, and Abhradeep Thakurta. Faster differentially private convex optimization via second-order methods. arXiv preprint arXiv:2305.13209, 2023.\n- [40] Arun Ganesh, Daogao Liu, Sewoong Oh, and Abhradeep Thakurta. Private (stochastic) non-convex optimization revisited: Second-order stationary points and excess risks. arXiv preprint arXiv:2302.09699, 2023.\n- [41] Quan Geng, Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The staircase mechanism in differential privacy. IEEE Journal of Selected Topics in Signal Processing, 9(7):1176\u20131184, 2015.\n- [42] Antonious M Girgis, Deepesh Data, Suhas Diggavi, Ananda Theertha Suresh, and Peter Kairouz. On the Renyi differential privacy of the shuffle model. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 2321\u20132341, 2021.\n- [43] Sivakanth Gopi, Yin Tat Lee, and Lukas Wutschitz. Numerical composition of differential privacy. Advances in Neural Information Processing Systems, 34:11631\u201311642, 2021.\n- [44] Samuel B Hopkins, Gautam Kamath, and Mahbod Majid. Efficient mean estimation with pure differential privacy via a sum-of-squares exponential mechanism. In Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing, pages 1406\u20131417, 2022.\n- [45] Samuel B Hopkins, Gautam Kamath, Mahbod Majid, and Shyam Narayanan. Robustness implies privacy in statistical estimation. arXiv preprint arXiv:2212.05015, 2022.\n- [46] Peter J Huber. Robust estimation of a location parameter. In Breakthroughs in statistics, pages 492\u2013518. Springer, 1992.\n- [47] Arun Jambulapati, Jerry Li, and Kevin Tian. Robust sub-Gaussian principal component analysis and width-independent Schatten packing. Advances in Neural Information Processing Systems, 33, 2020.\n- [48] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. Extremal mechanisms for local differential privacy. Advances in Neural Information Processing Systems, 27, 2014.\n- [49] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy. In International conference on machine learning, pages 1376\u20131385. PMLR, 2015.\n- [50] Gautam Kamath, Xingtu Liu, and Huanyu Zhang. Improved rates for differentially private stochastic convex optimization with heavy-tailed data. arXiv preprint arXiv:2106.01336, 2021.\n- [51] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. arXiv preprint arXiv:1711.03908, 2017.\n- [52] Ashish Khetan, Zachary C Lipton, and Animashree Anandkumar. Learning from noisy singly-labeled data. In International Conference on Learning Representations, 2018.\n- [53] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In Conference on Learning Theory, pages 25\u20131. JMLR Workshop and Conference Proceedings, 2012.\n- [54] Adam Klivans, Pravesh K Kothari, and Raghu Meka. Efficient algorithms for outlier-robust regression. In Conference On Learning Theory, pages 1420\u20131430. PMLR, 2018.", "md": "- [36] Giulia Fanti, Vasyl Pihur, and \u00dalfar Erlingsson. Building a rappor with the unknown: Privacy-preserving learning of associations and data dictionaries. Proceedings on Privacy Enhancing Technologies, 2016(3):41\u201361, 2016.\n- [37] Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: optimal rates in linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, pages 439\u2013449, 2020.\n- [38] James Foulds, Joseph Geumlek, Max Welling, and Kamalika Chaudhuri. On the theory and practice of privacy-preserving Bayesian data analysis. arXiv preprint arXiv:1603.07294, 2016.\n- [39] Arun Ganesh, Mahdi Haghifam, Thomas Steinke, and Abhradeep Thakurta. Faster differentially private convex optimization via second-order methods. arXiv preprint arXiv:2305.13209, 2023.\n- [40] Arun Ganesh, Daogao Liu, Sewoong Oh, and Abhradeep Thakurta. Private (stochastic) non-convex optimization revisited: Second-order stationary points and excess risks. arXiv preprint arXiv:2302.09699, 2023.\n- [41] Quan Geng, Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The staircase mechanism in differential privacy. IEEE Journal of Selected Topics in Signal Processing, 9(7):1176\u20131184, 2015.\n- [42] Antonious M Girgis, Deepesh Data, Suhas Diggavi, Ananda Theertha Suresh, and Peter Kairouz. On the Renyi differential privacy of the shuffle model. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 2321\u20132341, 2021.\n- [43] Sivakanth Gopi, Yin Tat Lee, and Lukas Wutschitz. Numerical composition of differential privacy. Advances in Neural Information Processing Systems, 34:11631\u201311642, 2021.\n- [44] Samuel B Hopkins, Gautam Kamath, and Mahbod Majid. Efficient mean estimation with pure differential privacy via a sum-of-squares exponential mechanism. In Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing, pages 1406\u20131417, 2022.\n- [45] Samuel B Hopkins, Gautam Kamath, Mahbod Majid, and Shyam Narayanan. Robustness implies privacy in statistical estimation. arXiv preprint arXiv:2212.05015, 2022.\n- [46] Peter J Huber. Robust estimation of a location parameter. In Breakthroughs in statistics, pages 492\u2013518. Springer, 1992.\n- [47] Arun Jambulapati, Jerry Li, and Kevin Tian. Robust sub-Gaussian principal component analysis and width-independent Schatten packing. Advances in Neural Information Processing Systems, 33, 2020.\n- [48] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. Extremal mechanisms for local differential privacy. Advances in Neural Information Processing Systems, 27, 2014.\n- [49] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy. In International conference on machine learning, pages 1376\u20131385. PMLR, 2015.\n- [50] Gautam Kamath, Xingtu Liu, and Huanyu Zhang. Improved rates for differentially private stochastic convex optimization with heavy-tailed data. arXiv preprint arXiv:2106.01336, 2021.\n- [51] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. arXiv preprint arXiv:1711.03908, 2017.\n- [52] Ashish Khetan, Zachary C Lipton, and Animashree Anandkumar. Learning from noisy singly-labeled data. In International Conference on Learning Representations, 2018.\n- [53] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In Conference on Learning Theory, pages 25\u20131. JMLR Workshop and Conference Proceedings, 2012.\n- [54] Adam Klivans, Pravesh K Kothari, and Raghu Meka. Efficient algorithms for outlier-robust regression. In Conference On Learning Theory, pages 1420\u20131430. PMLR, 2018."}]}, {"page": 14, "text": "[55] Weihao Kong, Rajat Sen, Pranjal Awasthi, and Abhimanyu Das. Trimmed maximum likelihood\n      estimation for robust learning in generalized linear models. arXiv preprint arXiv:2206.04777,\n      2022.\n[56] Pravesh K Kothari, Pasin Manurangsi, and Ameya Velingker. Private robust estimation by\n      stabilizing convex relaxations. arXiv preprint arXiv:2112.03548, 2021.\n[57] Arun Kumar Kuchibhotla and Abhishek Chakrabortty. Moving beyond sub-gaussianity in\n      high-dimensional statistics: Applications in covariance estimation and linear regression. arXiv\n      preprint arXiv:1804.02605, 2018.\n[58] Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. Private non-smooth empirical risk minimiza-\n      tion and stochastic convex optimization in subquadratic steps. arXiv preprint arXiv:2103.15352,\n      2021.\n[59] Xiyang Liu, Weihao Kong, Prateek Jain, and Sewoong Oh. DP-PCA: Statistically optimal and\n      differentially private pca. In Advances in Neural Information Processing Systems, 2022.\n[60] Xiyang Liu, Weihao Kong, Sham Kakade, and Sewoong Oh. Robust and differentially private\n      mean estimation. Advances in Neural Information Processing Systems, 34, 2021.\n[61] Xiyang Liu, Weihao Kong, and Sewoong Oh. Differential privacy and robust statistics in high\n      dimensions. In Conference on Learning Theory, pages 1167\u20131246. PMLR, 2022.\n[62] Frank D McSherry. Privacy integrated queries: an extensible platform for privacy-preserving\n      data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Manage-\n      ment of data, pages 19\u201330, 2009.\n[63] Jason Milionis, Alkis Kalavasis, Dimitris Fotakis, and Stratis Ioannidis. Differentially private\n      regression with unbounded covariates. In International Conference on Artificial Intelligence\n      and Statistics, pages 3242\u20133273. PMLR, 2022.\n[64] Kentaro Minami, HItomi Arai, Issei Sato, and Hiroshi Nakagawa. Differential privacy without\n      sensitivity. In Advances in Neural Information Processing Systems, pages 956\u2013964, 2016.\n[65] Darakhshan J Mir. Differential privacy: an exploration of the privacy-utility landscape. Rutgers\n     The State University of New Jersey-New Brunswick, 2013.\n[66] Ilya Mironov. R\u00e9nyi differential privacy. In 2017 IEEE 30th computer security foundations\n      symposium (CSF), pages 263\u2013275. IEEE, 2017.\n[67] Ankit Pensia, Varun Jog, and Po-Ling Loh. Robust regression with covariate filtering: Heavy\n      tails and adversarial contamination. arXiv preprint arXiv:2009.12976, 2020.\n[68] Adarsh Prasad, Arun Sai Suggala, Sivaraman Balakrishnan, and Pradeep Ravikumar. Robust\n      estimation via robust gradient estimation. arXiv preprint arXiv:1802.06485, 2018.\n[69] Holger Sambale. Some notes on concentration for \u03b1-subexponential random variables. arXiv\n      preprint arXiv:2002.10761, 2020.\n[70] Or Sheffet. Old techniques in differentially private linear regression. In Algorithmic Learning\n     Theory, pages 789\u2013827. PMLR, 2019.\n[71] Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. Stochastic gradient descent with\n      differentially private updates. In 2013 IEEE global conference on signal and information\n      processing, pages 245\u2013248. IEEE, 2013.\n[72] Shuang Song, Om Thakkar, and Abhradeep Thakurta. Characterizing private clipped gradient\n      descent on convex generalized linear problems. arXiv preprint arXiv:2006.06783, 2020.\n[73] Jacob Steinhardt, Moses Charikar, and Gregory Valiant. Resilience: A criterion for learning in\n      the presence of arbitrary outliers. arXiv preprint arXiv:1703.04940, 2017.\n                                                 14", "md": "- Weihao Kong, Rajat Sen, Pranjal Awasthi, and Abhimanyu Das. *Trimmed maximum likelihood estimation for robust learning in generalized linear models.* arXiv preprint arXiv:2206.04777, 2022.\n- Pravesh K Kothari, Pasin Manurangsi, and Ameya Velingker. *Private robust estimation by stabilizing convex relaxations.* arXiv preprint arXiv:2112.03548, 2021.\n- Arun Kumar Kuchibhotla and Abhishek Chakrabortty. *Moving beyond sub-gaussianity in high-dimensional statistics: Applications in covariance estimation and linear regression.* arXiv preprint arXiv:1804.02605, 2018.\n- Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. *Private non-smooth empirical risk minimization and stochastic convex optimization in subquadratic steps.* arXiv preprint arXiv:2103.15352, 2021.\n- Xiyang Liu, Weihao Kong, Prateek Jain, and Sewoong Oh. *DP-PCA: Statistically optimal and differentially private pca. In Advances in Neural Information Processing Systems*, 2022.\n- Xiyang Liu, Weihao Kong, Sham Kakade, and Sewoong Oh. *Robust and differentially private mean estimation. Advances in Neural Information Processing Systems*, 34, 2021.\n- Xiyang Liu, Weihao Kong, and Sewoong Oh. *Differential privacy and robust statistics in high dimensions. In Conference on Learning Theory*, pages 1167\u20131246. PMLR, 2022.\n- Frank D McSherry. *Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data*, pages 19\u201330, 2009.\n- Jason Milionis, Alkis Kalavasis, Dimitris Fotakis, and Stratis Ioannidis. *Differentially private regression with unbounded covariates. In International Conference on Artificial Intelligence and Statistics*, pages 3242\u20133273. PMLR, 2022.\n- Kentaro Minami, HItomi Arai, Issei Sato, and Hiroshi Nakagawa. *Differential privacy without sensitivity. In Advances in Neural Information Processing Systems*, pages 956\u2013964, 2016.\n- Darakhshan J Mir. *Differential privacy: an exploration of the privacy-utility landscape.* Rutgers The State University of New Jersey-New Brunswick, 2013.\n- Ilya Mironov. *R\u00e9nyi differential privacy.* In 2017 IEEE 30th computer security foundations symposium (CSF), pages 263\u2013275. IEEE, 2017.\n- Ankit Pensia, Varun Jog, and Po-Ling Loh. *Robust regression with covariate filtering: Heavy tails and adversarial contamination.* arXiv preprint arXiv:2009.12976, 2020.\n- Adarsh Prasad, Arun Sai Suggala, Sivaraman Balakrishnan, and Pradeep Ravikumar. *Robust estimation via robust gradient estimation.* arXiv preprint arXiv:1802.06485, 2018.\n- Holger Sambale. *Some notes on concentration for \u03b1-subexponential random variables.* arXiv preprint arXiv:2002.10761, 2020.\n- Or Sheffet. *Old techniques in differentially private linear regression. In Algorithmic Learning Theory*, pages 789\u2013827. PMLR, 2019.\n- Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. *Stochastic gradient descent with differentially private updates.* In 2013 IEEE global conference on signal and information processing, pages 245\u2013248. IEEE, 2013.\n- Shuang Song, Om Thakkar, and Abhradeep Thakurta. *Characterizing private clipped gradient descent on convex generalized linear problems.* arXiv preprint arXiv:2006.06783, 2020.\n- Jacob Steinhardt, Moses Charikar, and Gregory Valiant. *Resilience: A criterion for learning in the presence of arbitrary outliers.* arXiv preprint arXiv:1703.04940, 2017.", "images": [], "items": [{"type": "text", "value": "- Weihao Kong, Rajat Sen, Pranjal Awasthi, and Abhimanyu Das. *Trimmed maximum likelihood estimation for robust learning in generalized linear models.* arXiv preprint arXiv:2206.04777, 2022.\n- Pravesh K Kothari, Pasin Manurangsi, and Ameya Velingker. *Private robust estimation by stabilizing convex relaxations.* arXiv preprint arXiv:2112.03548, 2021.\n- Arun Kumar Kuchibhotla and Abhishek Chakrabortty. *Moving beyond sub-gaussianity in high-dimensional statistics: Applications in covariance estimation and linear regression.* arXiv preprint arXiv:1804.02605, 2018.\n- Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. *Private non-smooth empirical risk minimization and stochastic convex optimization in subquadratic steps.* arXiv preprint arXiv:2103.15352, 2021.\n- Xiyang Liu, Weihao Kong, Prateek Jain, and Sewoong Oh. *DP-PCA: Statistically optimal and differentially private pca. In Advances in Neural Information Processing Systems*, 2022.\n- Xiyang Liu, Weihao Kong, Sham Kakade, and Sewoong Oh. *Robust and differentially private mean estimation. Advances in Neural Information Processing Systems*, 34, 2021.\n- Xiyang Liu, Weihao Kong, and Sewoong Oh. *Differential privacy and robust statistics in high dimensions. In Conference on Learning Theory*, pages 1167\u20131246. PMLR, 2022.\n- Frank D McSherry. *Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data*, pages 19\u201330, 2009.\n- Jason Milionis, Alkis Kalavasis, Dimitris Fotakis, and Stratis Ioannidis. *Differentially private regression with unbounded covariates. In International Conference on Artificial Intelligence and Statistics*, pages 3242\u20133273. PMLR, 2022.\n- Kentaro Minami, HItomi Arai, Issei Sato, and Hiroshi Nakagawa. *Differential privacy without sensitivity. In Advances in Neural Information Processing Systems*, pages 956\u2013964, 2016.\n- Darakhshan J Mir. *Differential privacy: an exploration of the privacy-utility landscape.* Rutgers The State University of New Jersey-New Brunswick, 2013.\n- Ilya Mironov. *R\u00e9nyi differential privacy.* In 2017 IEEE 30th computer security foundations symposium (CSF), pages 263\u2013275. IEEE, 2017.\n- Ankit Pensia, Varun Jog, and Po-Ling Loh. *Robust regression with covariate filtering: Heavy tails and adversarial contamination.* arXiv preprint arXiv:2009.12976, 2020.\n- Adarsh Prasad, Arun Sai Suggala, Sivaraman Balakrishnan, and Pradeep Ravikumar. *Robust estimation via robust gradient estimation.* arXiv preprint arXiv:1802.06485, 2018.\n- Holger Sambale. *Some notes on concentration for \u03b1-subexponential random variables.* arXiv preprint arXiv:2002.10761, 2020.\n- Or Sheffet. *Old techniques in differentially private linear regression. In Algorithmic Learning Theory*, pages 789\u2013827. PMLR, 2019.\n- Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. *Stochastic gradient descent with differentially private updates.* In 2013 IEEE global conference on signal and information processing, pages 245\u2013248. IEEE, 2013.\n- Shuang Song, Om Thakkar, and Abhradeep Thakurta. *Characterizing private clipped gradient descent on convex generalized linear problems.* arXiv preprint arXiv:2006.06783, 2020.\n- Jacob Steinhardt, Moses Charikar, and Gregory Valiant. *Resilience: A criterion for learning in the presence of arbitrary outliers.* arXiv preprint arXiv:1703.04940, 2017.", "md": "- Weihao Kong, Rajat Sen, Pranjal Awasthi, and Abhimanyu Das. *Trimmed maximum likelihood estimation for robust learning in generalized linear models.* arXiv preprint arXiv:2206.04777, 2022.\n- Pravesh K Kothari, Pasin Manurangsi, and Ameya Velingker. *Private robust estimation by stabilizing convex relaxations.* arXiv preprint arXiv:2112.03548, 2021.\n- Arun Kumar Kuchibhotla and Abhishek Chakrabortty. *Moving beyond sub-gaussianity in high-dimensional statistics: Applications in covariance estimation and linear regression.* arXiv preprint arXiv:1804.02605, 2018.\n- Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. *Private non-smooth empirical risk minimization and stochastic convex optimization in subquadratic steps.* arXiv preprint arXiv:2103.15352, 2021.\n- Xiyang Liu, Weihao Kong, Prateek Jain, and Sewoong Oh. *DP-PCA: Statistically optimal and differentially private pca. In Advances in Neural Information Processing Systems*, 2022.\n- Xiyang Liu, Weihao Kong, Sham Kakade, and Sewoong Oh. *Robust and differentially private mean estimation. Advances in Neural Information Processing Systems*, 34, 2021.\n- Xiyang Liu, Weihao Kong, and Sewoong Oh. *Differential privacy and robust statistics in high dimensions. In Conference on Learning Theory*, pages 1167\u20131246. PMLR, 2022.\n- Frank D McSherry. *Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data*, pages 19\u201330, 2009.\n- Jason Milionis, Alkis Kalavasis, Dimitris Fotakis, and Stratis Ioannidis. *Differentially private regression with unbounded covariates. In International Conference on Artificial Intelligence and Statistics*, pages 3242\u20133273. PMLR, 2022.\n- Kentaro Minami, HItomi Arai, Issei Sato, and Hiroshi Nakagawa. *Differential privacy without sensitivity. In Advances in Neural Information Processing Systems*, pages 956\u2013964, 2016.\n- Darakhshan J Mir. *Differential privacy: an exploration of the privacy-utility landscape.* Rutgers The State University of New Jersey-New Brunswick, 2013.\n- Ilya Mironov. *R\u00e9nyi differential privacy.* In 2017 IEEE 30th computer security foundations symposium (CSF), pages 263\u2013275. IEEE, 2017.\n- Ankit Pensia, Varun Jog, and Po-Ling Loh. *Robust regression with covariate filtering: Heavy tails and adversarial contamination.* arXiv preprint arXiv:2009.12976, 2020.\n- Adarsh Prasad, Arun Sai Suggala, Sivaraman Balakrishnan, and Pradeep Ravikumar. *Robust estimation via robust gradient estimation.* arXiv preprint arXiv:1802.06485, 2018.\n- Holger Sambale. *Some notes on concentration for \u03b1-subexponential random variables.* arXiv preprint arXiv:2002.10761, 2020.\n- Or Sheffet. *Old techniques in differentially private linear regression. In Algorithmic Learning Theory*, pages 789\u2013827. PMLR, 2019.\n- Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. *Stochastic gradient descent with differentially private updates.* In 2013 IEEE global conference on signal and information processing, pages 245\u2013248. IEEE, 2013.\n- Shuang Song, Om Thakkar, and Abhradeep Thakurta. *Characterizing private clipped gradient descent on convex generalized linear problems.* arXiv preprint arXiv:2006.06783, 2020.\n- Jacob Steinhardt, Moses Charikar, and Gregory Valiant. *Resilience: A criterion for learning in the presence of arbitrary outliers.* arXiv preprint arXiv:1703.04940, 2017."}]}, {"page": 15, "text": "[74] Thomas Steinke and Alexander Knop. Differentially Private Linear Regression via Medi-\n      ans. https://openreview.net/pdf?id=JSBgIaxAXk9, 2022. [Online; accessed 28-April-\n      2023].\n[75] Arun Sai Suggala, Kush Bhatia, Pradeep Ravikumar, and Prateek Jain. Adaptive hard threshold-\n      ing for near-optimal consistent robust regression. In Conference on Learning Theory, pages\n      2892\u20132897. PMLR, 2019.\n[76] Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, and Xiaofeng Wang. Pri-\n      vacy loss in apple\u2019s implementation of differential privacy on macos 10.12. arXiv preprint\n      arXiv:1709.02753, 2017.\n[77] Henri Theil. A rank-invariant method of linear and polynomial regression analysis. Indagationes\n      mathematicae, 12(85):173, 1950.\n[78] Kiran K Thekumparampil, Ashish Khetan, Zinan Lin, and Sewoong Oh.                   Robustness of\n      conditional gans to noisy labels. Advances in neural information processing systems, 31, 2018.\n[79] John W Tukey. Mathematics and the picturing of data. In Proceedings of the International\n      Congress of Mathematicians, Vancouver, 1975, volume 2, pages 523\u2013531, 1975.\n[80] John W Tukey and Donald H McLaughlin. Less vulnerable confidence and significance\n      procedures for location based on a single sample: Trimming/winsorization 1. Sankhy\u00af        a: The\n      Indian Journal of Statistics, Series A, pages 331\u2013352, 1963.\n[81] Prateek Varshney, Abhradeep Thakurta, and Prateek Jain. (nearly) optimal private linear\n      regression via adaptive clipping. arXiv preprint arXiv:2207.04686, 2022.\n[82] Duy Vu and Aleksandra Slavkovic. Differential privacy for clinical trial data: Preliminary\n      evaluations. In 2009 IEEE International Conference on Data Mining Workshops, pages 138\u2013143.\n      IEEE, 2009.\n[83] Yu-Xiang Wang. Revisiting differentially private linear regression: optimal and adaptive\n      prediction & estimation in unbounded domain. arXiv preprint arXiv:1803.02596, 2018.\n[84] Yu-Xiang Wang, Borja Balle, and Shiva Prasad Kasiviswanathan. Subsampled r\u00e9nyi differential\n      privacy and analytical moments accountant. In The 22nd International Conference on Artificial\n      Intelligence and Statistics, pages 1226\u20131235. PMLR, 2019.\n[85] Yu-Xiang Wang, Stephen Fienberg, and Alex Smola. Privacy for free: Posterior sampling\n      and stochastic gradient monte carlo. In International Conference on Machine Learning, pages\n      2493\u20132502. PMLR, 2015.\n[86] Xi Wu, Fengan Li, Arun Kumar, Kamalika Chaudhuri, Somesh Jha, and Jeffrey Naughton. Bolt-\n      on differential privacy for scalable stochastic gradient descent-based analytics. In Proceedings\n      of the 2017 ACM International Conference on Management of Data, pages 1307\u20131322, 2017.\n[87] Liang Zhang, Kiran Koshy Thekumparampil, Sewoong Oh, and Niao He. Bring your own\n      algorithm for optimal differentially private stochastic minimax optimization. arXiv preprint\n      arXiv:2206.00363, 2022.\n[88] Liang Zhang, Kiran Koshy Thekumparampil, Sewoong Oh, and Niao He.                         DPZero:\n      dimension-independent and differentially private zeroth-order optimization. arXiv preprint\n      arXiv:2310.09639, 2023.\n[89] Banghua Zhu, Jiantao Jiao, and Jacob Steinhardt. Generalized resilience and robust statistics.\n      arXiv preprint arXiv:1909.08755, 2019.\n[90] Yuqing Zhu, Jinshuo Dong, and Yu-Xiang Wang. Optimal accounting of differential privacy\n      via characteristic function. In International Conference on Artificial Intelligence and Statistics,\n      pages 4782\u20134817. PMLR, 2022.\n                                                   15", "md": "1. Thomas Steinke and Alexander Knop. Differentially Private Linear Regression via Medians. Link to paper, 2022. [Online; accessed 28-April-2023].\n2. Arun Sai Suggala, Kush Bhatia, Pradeep Ravikumar, and Prateek Jain. Adaptive hard thresholding for near-optimal consistent robust regression. In Conference on Learning Theory, pages 2892\u20132897. PMLR, 2019.\n3. Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, and Xiaofeng Wang. Privacy loss in Apple\u2019s implementation of differential privacy on macOS 10.12. arXiv preprint arXiv:1709.02753, 2017.\n4. Henri Theil. A rank-invariant method of linear and polynomial regression analysis. Indagationes mathematicae, 12(85):173, 1950.\n5. Kiran K Thekumparampil, Ashish Khetan, Zinan Lin, and Sewoong Oh. Robustness of conditional GANs to noisy labels. Advances in Neural Information Processing Systems, 31, 2018.\n6. John W Tukey. Mathematics and the picturing of data. In Proceedings of the International Congress of Mathematicians, Vancouver, 1975, volume 2, pages 523\u2013531, 1975.\n7. John W Tukey and Donald H McLaughlin. Less vulnerable confidence and significance procedures for location based on a single sample: Trimming/winsorization 1. Sankhy\u00af a: The Indian Journal of Statistics, Series A, pages 331\u2013352, 1963.\n8. Prateek Varshney, Abhradeep Thakurta, and Prateek Jain. (Nearly) optimal private linear regression via adaptive clipping. arXiv preprint arXiv:2207.04686, 2022.\n9. Duy Vu and Aleksandra Slavkovic. Differential privacy for clinical trial data: Preliminary evaluations. In 2009 IEEE International Conference on Data Mining Workshops, pages 138\u2013143. IEEE, 2009.\n10. Yu-Xiang Wang. Revisiting differentially private linear regression: optimal and adaptive prediction & estimation in unbounded domain. arXiv preprint arXiv:1803.02596, 2018.\n11. Yu-Xiang Wang, Borja Balle, and Shiva Prasad Kasiviswanathan. Subsampled R\u00e9nyi differential privacy and analytical moments accountant. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 1226\u20131235. PMLR, 2019.\n12. Yu-Xiang Wang, Stephen Fienberg, and Alex Smola. Privacy for free: Posterior sampling and stochastic gradient Monte Carlo. In International Conference on Machine Learning, pages 2493\u20132502. PMLR, 2015.\n13. Xi Wu, Fengan Li, Arun Kumar, Kamalika Chaudhuri, Somesh Jha, and Jeffrey Naughton. Bolt-on differential privacy for scalable stochastic gradient descent-based analytics. In Proceedings of the 2017 ACM International Conference on Management of Data, pages 1307\u20131322, 2017.\n14. Liang Zhang, Kiran Koshy Thekumparampil, Sewoong Oh, and Niao He. Bring your own algorithm for optimal differentially private stochastic minimax optimization. arXiv preprint arXiv:2206.00363, 2022.\n15. Liang Zhang, Kiran Koshy Thekumparampil, Sewoong Oh, and Niao He. DPZero: dimension-independent and differentially private zeroth-order optimization. arXiv preprint arXiv:2310.09639, 2023.\n16. Banghua Zhu, Jiantao Jiao, and Jacob Steinhardt. Generalized resilience and robust statistics. arXiv preprint arXiv:1909.08755, 2019.\n17. Yuqing Zhu, Jinshuo Dong, and Yu-Xiang Wang. Optimal accounting of differential privacy via characteristic function. In International Conference on Artificial Intelligence and Statistics, pages 4782\u20134817. PMLR, 2022.", "images": [], "items": [{"type": "text", "value": "1. Thomas Steinke and Alexander Knop. Differentially Private Linear Regression via Medians. Link to paper, 2022. [Online; accessed 28-April-2023].\n2. Arun Sai Suggala, Kush Bhatia, Pradeep Ravikumar, and Prateek Jain. Adaptive hard thresholding for near-optimal consistent robust regression. In Conference on Learning Theory, pages 2892\u20132897. PMLR, 2019.\n3. Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, and Xiaofeng Wang. Privacy loss in Apple\u2019s implementation of differential privacy on macOS 10.12. arXiv preprint arXiv:1709.02753, 2017.\n4. Henri Theil. A rank-invariant method of linear and polynomial regression analysis. Indagationes mathematicae, 12(85):173, 1950.\n5. Kiran K Thekumparampil, Ashish Khetan, Zinan Lin, and Sewoong Oh. Robustness of conditional GANs to noisy labels. Advances in Neural Information Processing Systems, 31, 2018.\n6. John W Tukey. Mathematics and the picturing of data. In Proceedings of the International Congress of Mathematicians, Vancouver, 1975, volume 2, pages 523\u2013531, 1975.\n7. John W Tukey and Donald H McLaughlin. Less vulnerable confidence and significance procedures for location based on a single sample: Trimming/winsorization 1. Sankhy\u00af a: The Indian Journal of Statistics, Series A, pages 331\u2013352, 1963.\n8. Prateek Varshney, Abhradeep Thakurta, and Prateek Jain. (Nearly) optimal private linear regression via adaptive clipping. arXiv preprint arXiv:2207.04686, 2022.\n9. Duy Vu and Aleksandra Slavkovic. Differential privacy for clinical trial data: Preliminary evaluations. In 2009 IEEE International Conference on Data Mining Workshops, pages 138\u2013143. IEEE, 2009.\n10. Yu-Xiang Wang. Revisiting differentially private linear regression: optimal and adaptive prediction & estimation in unbounded domain. arXiv preprint arXiv:1803.02596, 2018.\n11. Yu-Xiang Wang, Borja Balle, and Shiva Prasad Kasiviswanathan. Subsampled R\u00e9nyi differential privacy and analytical moments accountant. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 1226\u20131235. PMLR, 2019.\n12. Yu-Xiang Wang, Stephen Fienberg, and Alex Smola. Privacy for free: Posterior sampling and stochastic gradient Monte Carlo. In International Conference on Machine Learning, pages 2493\u20132502. PMLR, 2015.\n13. Xi Wu, Fengan Li, Arun Kumar, Kamalika Chaudhuri, Somesh Jha, and Jeffrey Naughton. Bolt-on differential privacy for scalable stochastic gradient descent-based analytics. In Proceedings of the 2017 ACM International Conference on Management of Data, pages 1307\u20131322, 2017.\n14. Liang Zhang, Kiran Koshy Thekumparampil, Sewoong Oh, and Niao He. Bring your own algorithm for optimal differentially private stochastic minimax optimization. arXiv preprint arXiv:2206.00363, 2022.\n15. Liang Zhang, Kiran Koshy Thekumparampil, Sewoong Oh, and Niao He. DPZero: dimension-independent and differentially private zeroth-order optimization. arXiv preprint arXiv:2310.09639, 2023.\n16. Banghua Zhu, Jiantao Jiao, and Jacob Steinhardt. Generalized resilience and robust statistics. arXiv preprint arXiv:1909.08755, 2019.\n17. Yuqing Zhu, Jinshuo Dong, and Yu-Xiang Wang. Optimal accounting of differential privacy via characteristic function. In International Conference on Artificial Intelligence and Statistics, pages 4782\u20134817. PMLR, 2022.", "md": "1. Thomas Steinke and Alexander Knop. Differentially Private Linear Regression via Medians. Link to paper, 2022. [Online; accessed 28-April-2023].\n2. Arun Sai Suggala, Kush Bhatia, Pradeep Ravikumar, and Prateek Jain. Adaptive hard thresholding for near-optimal consistent robust regression. In Conference on Learning Theory, pages 2892\u20132897. PMLR, 2019.\n3. Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, and Xiaofeng Wang. Privacy loss in Apple\u2019s implementation of differential privacy on macOS 10.12. arXiv preprint arXiv:1709.02753, 2017.\n4. Henri Theil. A rank-invariant method of linear and polynomial regression analysis. Indagationes mathematicae, 12(85):173, 1950.\n5. Kiran K Thekumparampil, Ashish Khetan, Zinan Lin, and Sewoong Oh. Robustness of conditional GANs to noisy labels. Advances in Neural Information Processing Systems, 31, 2018.\n6. John W Tukey. Mathematics and the picturing of data. In Proceedings of the International Congress of Mathematicians, Vancouver, 1975, volume 2, pages 523\u2013531, 1975.\n7. John W Tukey and Donald H McLaughlin. Less vulnerable confidence and significance procedures for location based on a single sample: Trimming/winsorization 1. Sankhy\u00af a: The Indian Journal of Statistics, Series A, pages 331\u2013352, 1963.\n8. Prateek Varshney, Abhradeep Thakurta, and Prateek Jain. (Nearly) optimal private linear regression via adaptive clipping. arXiv preprint arXiv:2207.04686, 2022.\n9. Duy Vu and Aleksandra Slavkovic. Differential privacy for clinical trial data: Preliminary evaluations. In 2009 IEEE International Conference on Data Mining Workshops, pages 138\u2013143. IEEE, 2009.\n10. Yu-Xiang Wang. Revisiting differentially private linear regression: optimal and adaptive prediction & estimation in unbounded domain. arXiv preprint arXiv:1803.02596, 2018.\n11. Yu-Xiang Wang, Borja Balle, and Shiva Prasad Kasiviswanathan. Subsampled R\u00e9nyi differential privacy and analytical moments accountant. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 1226\u20131235. PMLR, 2019.\n12. Yu-Xiang Wang, Stephen Fienberg, and Alex Smola. Privacy for free: Posterior sampling and stochastic gradient Monte Carlo. In International Conference on Machine Learning, pages 2493\u20132502. PMLR, 2015.\n13. Xi Wu, Fengan Li, Arun Kumar, Kamalika Chaudhuri, Somesh Jha, and Jeffrey Naughton. Bolt-on differential privacy for scalable stochastic gradient descent-based analytics. In Proceedings of the 2017 ACM International Conference on Management of Data, pages 1307\u20131322, 2017.\n14. Liang Zhang, Kiran Koshy Thekumparampil, Sewoong Oh, and Niao He. Bring your own algorithm for optimal differentially private stochastic minimax optimization. arXiv preprint arXiv:2206.00363, 2022.\n15. Liang Zhang, Kiran Koshy Thekumparampil, Sewoong Oh, and Niao He. DPZero: dimension-independent and differentially private zeroth-order optimization. arXiv preprint arXiv:2310.09639, 2023.\n16. Banghua Zhu, Jiantao Jiao, and Jacob Steinhardt. Generalized resilience and robust statistics. arXiv preprint arXiv:1909.08755, 2019.\n17. Yuqing Zhu, Jinshuo Dong, and Yu-Xiang Wang. Optimal accounting of differential privacy via characteristic function. In International Conference on Artificial Intelligence and Statistics, pages 4782\u20134817. PMLR, 2022."}]}], "job_id": "4f0e367c-a551-4249-8cf4-f119e5fe9ebc", "file_path": "./corpus/8879_label_robust_and_differentiall.pdf"}