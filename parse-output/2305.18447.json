{"pages": [{"page": 1, "text": "                       Unleashing the Power of Randomization in\n                               Auditing Differentially Private ML\n                               Krishna Pillutla1            Galen Andrew1               Peter Kairouz1\n                           H. Brendan McMahan1                   Alina Oprea1,2            Sewoong Oh1,3\n                           1Google Research        2Northeastern University        3University of Washington\narXiv:2305.18447v1  [cs.LG]  29 May 2023                        Abstract\n                    We present a rigorous methodology for auditing differentially private machine learning algorithms\n                by adding multiple carefully designed examples called canaries. We take a first principles approach\n                based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands\n                the definition of differential privacy to handle randomized datasets. This gives us the freedom to design\n                randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with\n                K canaries versus K \u2212   1 canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d.,\n                LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple\n                statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage\n                of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new\n                recipe demonstrates significant improvements in sample complexity, both theoretically and empirically,\n                using synthetic and real data. Further, recent advances in designing stronger canaries can be readily\n                incorporated into the new framework.\n          1     Introduction\n          Differential privacy (DP), introduced in [21], has gained widespread adoption by governments, companies,\n          and researchers by formally ensuring plausible deniability for participating individuals. This is achieved by\n          guaranteeing that a curious observer of the output of a query cannot be confident in their answer to the\n          following binary hypothesis test: did a particular individual participate in the dataset or not? For example,\n          introducing sufficient randomness when training a model on a certain dataset ensures a desired level of\n          differential privacy. This in turn ensures that an individual\u2019s sensitive information cannot be inferred from\n          the trained model with high confidence. However, calibrating the right amount of noise can be a challenging\n          process. It is easy to make mistakes when implementing a DP mechanism as it can involve intricacies like\n          micro-batching, sensitivity analysis, and privacy accounting. Even with a correct implementation, there\n          are several known incidents of published DP algorithms with miscalculated privacy guarantees that falsely\n          report higher levels of privacy [16, 33, 39, 46, 56, 57]. Data-driven approaches to auditing a mechanism for\n          a violation of a claimed privacy guarantee can significantly mitigate the danger of unintentionally leaking\n          sensitive data.\n              Popular approaches for auditing privacy share three common components [e.g. 30\u201332, 44, 68]. Conceptually,\n          these approaches are founded on the definition of DP and involve producing counterexamples that potentially\n          violate the DP condition. Algorithmically, this leads to the standard recipe of injecting a single carefully\n          designed example, referred to as a canary, and running a statistical hypothesis test for its presence from\n          the outcome of the mechanism. Analytically, a high-confidence bound on the DP condition is derived by\n          calculating the confidence intervals of the corresponding Bernoulli random variables from n independent trials\n          of the mechanism.\n              Recent advances adopt this standard approach and focus on designing stronger canaries to reduce the\n          number of trials required to successfully audit DP [e.g. 30\u201332, 38, 44, 68]. However, each independent trial\n          can be as costly as training a model from scratch; refuting a false claim of (\u03b5, \u03b4)-DP with minimal number\n                                                                    1", "md": "# Unleashing the Power of Randomization in Auditing Differentially Private ML\n\n# Unleashing the Power of Randomization in Auditing Differentially Private ML\n\nKrishna Pillutla1, Galen Andrew1, Peter Kairouz1, H. Brendan McMahan1, Alina Oprea1,2, Sewoong Oh1,3\n\n1Google Research, 2Northeastern University, 3University of Washington\n\narXiv:2305.18447v1 [cs.LG] 29 May 2023\n\n## Abstract\n\nWe present a rigorous methodology for auditing differentially private machine learning algorithms by adding multiple carefully designed examples called canaries. We take a first principles approach based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands the definition of differential privacy to handle randomized datasets. This gives us the freedom to design randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with K canaries versus K - 1 canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new recipe demonstrates significant improvements in sample complexity, both theoretically and empirically, using synthetic and real data. Further, recent advances in designing stronger canaries can be readily incorporated into the new framework.\n\n## Introduction\n\nDifferential privacy (DP), introduced in [21], has gained widespread adoption by governments, companies, and researchers by formally ensuring plausible deniability for participating individuals. This is achieved by guaranteeing that a curious observer of the output of a query cannot be confident in their answer to the following binary hypothesis test: did a particular individual participate in the dataset or not? For example, introducing sufficient randomness when training a model on a certain dataset ensures a desired level of differential privacy. This in turn ensures that an individual\u2019s sensitive information cannot be inferred from the trained model with high confidence. However, calibrating the right amount of noise can be a challenging process. It is easy to make mistakes when implementing a DP mechanism as it can involve intricacies like micro-batching, sensitivity analysis, and privacy accounting. Even with a correct implementation, there are several known incidents of published DP algorithms with miscalculated privacy guarantees that falsely report higher levels of privacy [16, 33, 39, 46, 56, 57]. Data-driven approaches to auditing a mechanism for a violation of a claimed privacy guarantee can significantly mitigate the danger of unintentionally leaking sensitive data.\n\nPopular approaches for auditing privacy share three common components [e.g. 30\u201332, 44, 68]. Conceptually, these approaches are founded on the definition of DP and involve producing counterexamples that potentially violate the DP condition. Algorithmically, this leads to the standard recipe of injecting a single carefully designed example, referred to as a canary, and running a statistical hypothesis test for its presence from the outcome of the mechanism. Analytically, a high-confidence bound on the DP condition is derived by calculating the confidence intervals of the corresponding Bernoulli random variables from n independent trials of the mechanism.\n\nRecent advances adopt this standard approach and focus on designing stronger canaries to reduce the number of trials required to successfully audit DP [e.g. 30\u201332, 38, 44, 68]. However, each independent trial can be as costly as training a model from scratch; refuting a false claim of (\u03b5, \u03b4)-DP with minimal number", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Unleashing the Power of Randomization in Auditing Differentially Private ML", "md": "# Unleashing the Power of Randomization in Auditing Differentially Private ML"}, {"type": "heading", "lvl": 1, "value": "Unleashing the Power of Randomization in Auditing Differentially Private ML", "md": "# Unleashing the Power of Randomization in Auditing Differentially Private ML"}, {"type": "text", "value": "Krishna Pillutla1, Galen Andrew1, Peter Kairouz1, H. Brendan McMahan1, Alina Oprea1,2, Sewoong Oh1,3\n\n1Google Research, 2Northeastern University, 3University of Washington\n\narXiv:2305.18447v1 [cs.LG] 29 May 2023", "md": "Krishna Pillutla1, Galen Andrew1, Peter Kairouz1, H. Brendan McMahan1, Alina Oprea1,2, Sewoong Oh1,3\n\n1Google Research, 2Northeastern University, 3University of Washington\n\narXiv:2305.18447v1 [cs.LG] 29 May 2023"}, {"type": "heading", "lvl": 2, "value": "Abstract", "md": "## Abstract"}, {"type": "text", "value": "We present a rigorous methodology for auditing differentially private machine learning algorithms by adding multiple carefully designed examples called canaries. We take a first principles approach based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands the definition of differential privacy to handle randomized datasets. This gives us the freedom to design randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with K canaries versus K - 1 canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new recipe demonstrates significant improvements in sample complexity, both theoretically and empirically, using synthetic and real data. Further, recent advances in designing stronger canaries can be readily incorporated into the new framework.", "md": "We present a rigorous methodology for auditing differentially private machine learning algorithms by adding multiple carefully designed examples called canaries. We take a first principles approach based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands the definition of differential privacy to handle randomized datasets. This gives us the freedom to design randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with K canaries versus K - 1 canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new recipe demonstrates significant improvements in sample complexity, both theoretically and empirically, using synthetic and real data. Further, recent advances in designing stronger canaries can be readily incorporated into the new framework."}, {"type": "heading", "lvl": 2, "value": "Introduction", "md": "## Introduction"}, {"type": "text", "value": "Differential privacy (DP), introduced in [21], has gained widespread adoption by governments, companies, and researchers by formally ensuring plausible deniability for participating individuals. This is achieved by guaranteeing that a curious observer of the output of a query cannot be confident in their answer to the following binary hypothesis test: did a particular individual participate in the dataset or not? For example, introducing sufficient randomness when training a model on a certain dataset ensures a desired level of differential privacy. This in turn ensures that an individual\u2019s sensitive information cannot be inferred from the trained model with high confidence. However, calibrating the right amount of noise can be a challenging process. It is easy to make mistakes when implementing a DP mechanism as it can involve intricacies like micro-batching, sensitivity analysis, and privacy accounting. Even with a correct implementation, there are several known incidents of published DP algorithms with miscalculated privacy guarantees that falsely report higher levels of privacy [16, 33, 39, 46, 56, 57]. Data-driven approaches to auditing a mechanism for a violation of a claimed privacy guarantee can significantly mitigate the danger of unintentionally leaking sensitive data.\n\nPopular approaches for auditing privacy share three common components [e.g. 30\u201332, 44, 68]. Conceptually, these approaches are founded on the definition of DP and involve producing counterexamples that potentially violate the DP condition. Algorithmically, this leads to the standard recipe of injecting a single carefully designed example, referred to as a canary, and running a statistical hypothesis test for its presence from the outcome of the mechanism. Analytically, a high-confidence bound on the DP condition is derived by calculating the confidence intervals of the corresponding Bernoulli random variables from n independent trials of the mechanism.\n\nRecent advances adopt this standard approach and focus on designing stronger canaries to reduce the number of trials required to successfully audit DP [e.g. 30\u201332, 38, 44, 68]. However, each independent trial can be as costly as training a model from scratch; refuting a false claim of (\u03b5, \u03b4)-DP with minimal number", "md": "Differential privacy (DP), introduced in [21], has gained widespread adoption by governments, companies, and researchers by formally ensuring plausible deniability for participating individuals. This is achieved by guaranteeing that a curious observer of the output of a query cannot be confident in their answer to the following binary hypothesis test: did a particular individual participate in the dataset or not? For example, introducing sufficient randomness when training a model on a certain dataset ensures a desired level of differential privacy. This in turn ensures that an individual\u2019s sensitive information cannot be inferred from the trained model with high confidence. However, calibrating the right amount of noise can be a challenging process. It is easy to make mistakes when implementing a DP mechanism as it can involve intricacies like micro-batching, sensitivity analysis, and privacy accounting. Even with a correct implementation, there are several known incidents of published DP algorithms with miscalculated privacy guarantees that falsely report higher levels of privacy [16, 33, 39, 46, 56, 57]. Data-driven approaches to auditing a mechanism for a violation of a claimed privacy guarantee can significantly mitigate the danger of unintentionally leaking sensitive data.\n\nPopular approaches for auditing privacy share three common components [e.g. 30\u201332, 44, 68]. Conceptually, these approaches are founded on the definition of DP and involve producing counterexamples that potentially violate the DP condition. Algorithmically, this leads to the standard recipe of injecting a single carefully designed example, referred to as a canary, and running a statistical hypothesis test for its presence from the outcome of the mechanism. Analytically, a high-confidence bound on the DP condition is derived by calculating the confidence intervals of the corresponding Bernoulli random variables from n independent trials of the mechanism.\n\nRecent advances adopt this standard approach and focus on designing stronger canaries to reduce the number of trials required to successfully audit DP [e.g. 30\u201332, 38, 44, 68]. However, each independent trial can be as costly as training a model from scratch; refuting a false claim of (\u03b5, \u03b4)-DP with minimal number"}]}, {"page": 2, "text": " of samples is of utmost importance. In practice, standard auditing can require training on the range of\n thousands to hundreds of thousands of models [e.g., 59]. Unfortunately, under the standard recipe, we are\n fundamentally limited by the 1/\u221an sample dependence of the Bernoulli confidence intervals.\n Contributions. We break this 1/\u221an barrier by rethinking auditing from first principles.\n 1. Lifted DP: We propose to audit an equivalent definition of DP, which we call Lifted DP in \u00a73.1. This\n      gives an auditor the freedom to design a counter-example consisting of random datasets and rejection sets.\n      This enables adding random canaries, which is critical in the next step. Theorem 3 shows that violation\n      of Lifted DP implies violation of DP, justifying our framework.\n 2. Auditing Lifted DP with Multiple Random Canaries: We propose adding K > 1 canaries under\n      the alternative hypothesis and comparing it against a dataset with K \u2212                                              1 canaries, leaving one canary\n      out. If the canaries are deterministic, we need K separate null hypotheses; each hypothesis leaves one\n      canary out. Our new recipe overcomes this inefficiency in \u00a73.2 by drawing random canaries independently\n      from the same distribution. This ensures the exchangeability of the test statistics, allowing us to reuse\n      each privately trained model to run multiple hypothesis tests in a principled manner. This is critical in\n      making the confidence interval sample efficient.\n 3. Adaptive Confidence Intervals: Due to the symmetry of our design, the test statistics follow a\n      special distribution that we call eXchangeable Bernoulli (XBern).                                               Auditing privacy boils down to\n      computing confidence intervals on the average test statistic over the K canaries included in the dataset.                            \u221a\n      If the test statistics are independent, the resulting confidence interval scales as 1/                                                  nK. However, in\n      practice, the dependence is non-zero and unknown. We propose a new and principled family of confidence\n      intervals in \u00a73.3 that adapts to the empirical higher-order correlations between the test statistics. This\n      gives significantly smaller confidence intervals when the actual dependence is small, both theoretically\n      (Proposition 4) and empirically.\n 4. Numerical Results: We audit an unknown Gaussian mechanism with black-box access and demonstrate\n      (up to) 16\u00d7 improvement in the sample complexity. We also show how to seamlessly lift recently proposed\n      canary designs in our recipe to improve the sample complexity on real data.\n 2       Background\nWe describe the standard recipe to audit DP. Formally, we adopt the so-called add/remove definition of\n differential privacy; our constructions also seamlessly extend to other choices of neighborhoods as we explain\n in \u00a7B.2.\n Definition 1 (Differential privacy). A pair of datasets, (D0, D1), is said to be neighboring if their sizes\n differ by one and the datasets differ in one entry: |D1 \\ D0| + |D0 \\ D1| = 1. A randomized mechanism\n A : Z\u2217       \u2192    R is said to be (\u03b5, \u03b4)-Differentially Private (DP) for some \u03b5 \u2265                                         0 and \u03b4 \u2208         [0, 1] if it satisfies\n PA(A(D1) \u2208          R) \u2264     e\u03b5 PA(A(D0) \u2208            R) + \u03b4, which is equivalent to\n                                                          \u03b5   \u2265     log    PA(A(D1) \u2208            R) \u2212     \u03b4     ,                                                     (1)\n  for all pairs of neighboring datasets, (D0, D1), and all measurable sets, R \u2282 PA(A(D0) \u2208          R)                  R, of the output space R, where\n PA is over the randomness internal to the mechanism A. Here, Z\u2217                                           is a space of datasets.\n      For small \u03b5 and \u03b4, one cannot infer from the output whether a particular individual is in the dataset\n or not with a high success probability. For a formal connection, we refer to [34]. This naturally leads to a\n standard procedure for auditing a mechanism A claiming (\u03b5, \u03b4)-DP: present (D0, D1, R) \u2208                                                      Z\u2217   \u00d7 Z\u2217     \u00d7 R that\nviolates Eq. (1) as a piece of evidence. Such a counter-example confirms that an adversary attempting to test\n the participation of an individual will succeed with sufficient probability, thus removing the potential for\n plausible deniability for the participants.\n                                                                                    2", "md": "of samples is of utmost importance. In practice, standard auditing can require training on the range of thousands to hundreds of thousands of models [e.g., 59]. Unfortunately, under the standard recipe, we are fundamentally limited by the \\( \\frac{1}{\\sqrt{n}} \\) sample dependence of the Bernoulli confidence intervals.\n\nContributions: We break this \\( \\frac{1}{\\sqrt{n}} \\) barrier by rethinking auditing from first principles.\n\n1. Lifted DP: We propose to audit an equivalent definition of DP, which we call Lifted DP in \u00a73.1. This gives an auditor the freedom to design a counter-example consisting of random datasets and rejection sets. This enables adding random canaries, which is critical in the next step. Theorem 3 shows that violation of Lifted DP implies violation of DP, justifying our framework.\n2. Auditing Lifted DP with Multiple Random Canaries: We propose adding \\( K > 1 \\) canaries under the alternative hypothesis and comparing it against a dataset with \\( K - 1 \\) canaries, leaving one canary out. If the canaries are deterministic, we need \\( K \\) separate null hypotheses; each hypothesis leaves one canary out. Our new recipe overcomes this inefficiency in \u00a73.2 by drawing random canaries independently from the same distribution. This ensures the exchangeability of the test statistics, allowing us to reuse each privately trained model to run multiple hypothesis tests in a principled manner. This is critical in making the confidence interval sample efficient.\n3. Adaptive Confidence Intervals: Due to the symmetry of our design, the test statistics follow a special distribution that we call eXchangeable Bernoulli (XBern). Auditing privacy boils down to computing confidence intervals on the average test statistic over the \\( K \\) canaries included in the dataset. If the test statistics are independent, the resulting confidence interval scales as \\( \\frac{1}{nK} \\). However, in practice, the dependence is non-zero and unknown. We propose a new and principled family of confidence intervals in \u00a73.3 that adapts to the empirical higher-order correlations between the test statistics. This gives significantly smaller confidence intervals when the actual dependence is small, both theoretically (Proposition 4) and empirically.\n4. Numerical Results: We audit an unknown Gaussian mechanism with black-box access and demonstrate (up to) 16\u00d7 improvement in the sample complexity. We also show how to seamlessly lift recently proposed canary designs in our recipe to improve the sample complexity on real data.\n\n## Background\n\nWe describe the standard recipe to audit DP. Formally, we adopt the so-called add/remove definition of differential privacy; our constructions also seamlessly extend to other choices of neighborhoods as we explain in \u00a7B.2.\n\nDefinition 1 (Differential privacy): A pair of datasets, \\( (D_0, D_1) \\), is said to be neighboring if their sizes differ by one and the datasets differ in one entry: \\( |D_1 \\backslash D_0| + |D_0 \\backslash D_1| = 1 \\). A randomized mechanism \\( A : Z^* \\rightarrow R \\) is said to be \\( (\\epsilon, \\delta) \\)-Differentially Private (DP) for some \\( \\epsilon \\geq 0 \\) and \\( \\delta \\in [0, 1] \\) if it satisfies \\( P_A(A(D_1) \\in R) \\leq e^{\\epsilon} P_A(A(D_0) \\in R) + \\delta \\), which is equivalent to \\( \\epsilon \\geq \\log P_A(A(D_1) \\in R) - \\delta \\) for all pairs of neighboring datasets, \\( (D_0, D_1) \\), and all measurable sets, \\( R \\subset PA(A(D_0) \\in R) \\), of the output space \\( R \\), where \\( P_A \\) is over the randomness internal to the mechanism \\( A \\). Here, \\( Z^* \\) is a space of datasets.\n\nFor small \\( \\epsilon \\) and \\( \\delta \\), one cannot infer from the output whether a particular individual is in the dataset or not with a high success probability. For a formal connection, we refer to [34]. This naturally leads to a standard procedure for auditing a mechanism \\( A \\) claiming \\( (\\epsilon, \\delta) \\)-DP: present \\( (D_0, D_1, R) \\in Z^* \\times Z^* \\times R \\) that violates Eq. (1) as a piece of evidence. Such a counter-example confirms that an adversary attempting to test the participation of an individual will succeed with sufficient probability, thus removing the potential for plausible deniability for the participants.", "images": [], "items": [{"type": "text", "value": "of samples is of utmost importance. In practice, standard auditing can require training on the range of thousands to hundreds of thousands of models [e.g., 59]. Unfortunately, under the standard recipe, we are fundamentally limited by the \\( \\frac{1}{\\sqrt{n}} \\) sample dependence of the Bernoulli confidence intervals.\n\nContributions: We break this \\( \\frac{1}{\\sqrt{n}} \\) barrier by rethinking auditing from first principles.\n\n1. Lifted DP: We propose to audit an equivalent definition of DP, which we call Lifted DP in \u00a73.1. This gives an auditor the freedom to design a counter-example consisting of random datasets and rejection sets. This enables adding random canaries, which is critical in the next step. Theorem 3 shows that violation of Lifted DP implies violation of DP, justifying our framework.\n2. Auditing Lifted DP with Multiple Random Canaries: We propose adding \\( K > 1 \\) canaries under the alternative hypothesis and comparing it against a dataset with \\( K - 1 \\) canaries, leaving one canary out. If the canaries are deterministic, we need \\( K \\) separate null hypotheses; each hypothesis leaves one canary out. Our new recipe overcomes this inefficiency in \u00a73.2 by drawing random canaries independently from the same distribution. This ensures the exchangeability of the test statistics, allowing us to reuse each privately trained model to run multiple hypothesis tests in a principled manner. This is critical in making the confidence interval sample efficient.\n3. Adaptive Confidence Intervals: Due to the symmetry of our design, the test statistics follow a special distribution that we call eXchangeable Bernoulli (XBern). Auditing privacy boils down to computing confidence intervals on the average test statistic over the \\( K \\) canaries included in the dataset. If the test statistics are independent, the resulting confidence interval scales as \\( \\frac{1}{nK} \\). However, in practice, the dependence is non-zero and unknown. We propose a new and principled family of confidence intervals in \u00a73.3 that adapts to the empirical higher-order correlations between the test statistics. This gives significantly smaller confidence intervals when the actual dependence is small, both theoretically (Proposition 4) and empirically.\n4. Numerical Results: We audit an unknown Gaussian mechanism with black-box access and demonstrate (up to) 16\u00d7 improvement in the sample complexity. We also show how to seamlessly lift recently proposed canary designs in our recipe to improve the sample complexity on real data.", "md": "of samples is of utmost importance. In practice, standard auditing can require training on the range of thousands to hundreds of thousands of models [e.g., 59]. Unfortunately, under the standard recipe, we are fundamentally limited by the \\( \\frac{1}{\\sqrt{n}} \\) sample dependence of the Bernoulli confidence intervals.\n\nContributions: We break this \\( \\frac{1}{\\sqrt{n}} \\) barrier by rethinking auditing from first principles.\n\n1. Lifted DP: We propose to audit an equivalent definition of DP, which we call Lifted DP in \u00a73.1. This gives an auditor the freedom to design a counter-example consisting of random datasets and rejection sets. This enables adding random canaries, which is critical in the next step. Theorem 3 shows that violation of Lifted DP implies violation of DP, justifying our framework.\n2. Auditing Lifted DP with Multiple Random Canaries: We propose adding \\( K > 1 \\) canaries under the alternative hypothesis and comparing it against a dataset with \\( K - 1 \\) canaries, leaving one canary out. If the canaries are deterministic, we need \\( K \\) separate null hypotheses; each hypothesis leaves one canary out. Our new recipe overcomes this inefficiency in \u00a73.2 by drawing random canaries independently from the same distribution. This ensures the exchangeability of the test statistics, allowing us to reuse each privately trained model to run multiple hypothesis tests in a principled manner. This is critical in making the confidence interval sample efficient.\n3. Adaptive Confidence Intervals: Due to the symmetry of our design, the test statistics follow a special distribution that we call eXchangeable Bernoulli (XBern). Auditing privacy boils down to computing confidence intervals on the average test statistic over the \\( K \\) canaries included in the dataset. If the test statistics are independent, the resulting confidence interval scales as \\( \\frac{1}{nK} \\). However, in practice, the dependence is non-zero and unknown. We propose a new and principled family of confidence intervals in \u00a73.3 that adapts to the empirical higher-order correlations between the test statistics. This gives significantly smaller confidence intervals when the actual dependence is small, both theoretically (Proposition 4) and empirically.\n4. Numerical Results: We audit an unknown Gaussian mechanism with black-box access and demonstrate (up to) 16\u00d7 improvement in the sample complexity. We also show how to seamlessly lift recently proposed canary designs in our recipe to improve the sample complexity on real data."}, {"type": "heading", "lvl": 2, "value": "Background", "md": "## Background"}, {"type": "text", "value": "We describe the standard recipe to audit DP. Formally, we adopt the so-called add/remove definition of differential privacy; our constructions also seamlessly extend to other choices of neighborhoods as we explain in \u00a7B.2.\n\nDefinition 1 (Differential privacy): A pair of datasets, \\( (D_0, D_1) \\), is said to be neighboring if their sizes differ by one and the datasets differ in one entry: \\( |D_1 \\backslash D_0| + |D_0 \\backslash D_1| = 1 \\). A randomized mechanism \\( A : Z^* \\rightarrow R \\) is said to be \\( (\\epsilon, \\delta) \\)-Differentially Private (DP) for some \\( \\epsilon \\geq 0 \\) and \\( \\delta \\in [0, 1] \\) if it satisfies \\( P_A(A(D_1) \\in R) \\leq e^{\\epsilon} P_A(A(D_0) \\in R) + \\delta \\), which is equivalent to \\( \\epsilon \\geq \\log P_A(A(D_1) \\in R) - \\delta \\) for all pairs of neighboring datasets, \\( (D_0, D_1) \\), and all measurable sets, \\( R \\subset PA(A(D_0) \\in R) \\), of the output space \\( R \\), where \\( P_A \\) is over the randomness internal to the mechanism \\( A \\). Here, \\( Z^* \\) is a space of datasets.\n\nFor small \\( \\epsilon \\) and \\( \\delta \\), one cannot infer from the output whether a particular individual is in the dataset or not with a high success probability. For a formal connection, we refer to [34]. This naturally leads to a standard procedure for auditing a mechanism \\( A \\) claiming \\( (\\epsilon, \\delta) \\)-DP: present \\( (D_0, D_1, R) \\in Z^* \\times Z^* \\times R \\) that violates Eq. (1) as a piece of evidence. Such a counter-example confirms that an adversary attempting to test the participation of an individual will succeed with sufficient probability, thus removing the potential for plausible deniability for the participants.", "md": "We describe the standard recipe to audit DP. Formally, we adopt the so-called add/remove definition of differential privacy; our constructions also seamlessly extend to other choices of neighborhoods as we explain in \u00a7B.2.\n\nDefinition 1 (Differential privacy): A pair of datasets, \\( (D_0, D_1) \\), is said to be neighboring if their sizes differ by one and the datasets differ in one entry: \\( |D_1 \\backslash D_0| + |D_0 \\backslash D_1| = 1 \\). A randomized mechanism \\( A : Z^* \\rightarrow R \\) is said to be \\( (\\epsilon, \\delta) \\)-Differentially Private (DP) for some \\( \\epsilon \\geq 0 \\) and \\( \\delta \\in [0, 1] \\) if it satisfies \\( P_A(A(D_1) \\in R) \\leq e^{\\epsilon} P_A(A(D_0) \\in R) + \\delta \\), which is equivalent to \\( \\epsilon \\geq \\log P_A(A(D_1) \\in R) - \\delta \\) for all pairs of neighboring datasets, \\( (D_0, D_1) \\), and all measurable sets, \\( R \\subset PA(A(D_0) \\in R) \\), of the output space \\( R \\), where \\( P_A \\) is over the randomness internal to the mechanism \\( A \\). Here, \\( Z^* \\) is a space of datasets.\n\nFor small \\( \\epsilon \\) and \\( \\delta \\), one cannot infer from the output whether a particular individual is in the dataset or not with a high success probability. For a formal connection, we refer to [34]. This naturally leads to a standard procedure for auditing a mechanism \\( A \\) claiming \\( (\\epsilon, \\delta) \\)-DP: present \\( (D_0, D_1, R) \\in Z^* \\times Z^* \\times R \\) that violates Eq. (1) as a piece of evidence. Such a counter-example confirms that an adversary attempting to test the participation of an individual will succeed with sufficient probability, thus removing the potential for plausible deniability for the participants."}]}, {"page": 3, "text": " Standard Recipe: Adding a Single Canary.                                             When auditing DP model training (using e.g. DP-\n SGD [1, 53]), the following recipe is now standard for designing a counter-example (D0, D1, R) [30\u201332, 44, 68].\nA training dataset D0 is assumed to be given. This ensures that the model under scrutiny matches the\n use-case and is called a null hypothesis. Next, under a corresponding alternative hypothesis, a neighboring\n dataset D1 = D0 \u222a            {c} is constructed by adding a single carefully-designed example c \u2208                                     Z, known as a canary.\n Finally, Eq. (1) is evaluated with a choice of R called a rejection set. For example, one can reject the null\n hypothesis (and claim the presence of the canary) if the loss on the canary is smaller than a fixed threshold;\n R is a set of models satisfying this rejection rule.\n Bernoulli Confidence Intervals. Once a counter-example (D0, D1, R) is selected, we are left to evaluate\n the DP condition in Eq. (1). Since the two probabilities in the condition cannot be directly evaluated, we\n rely on the samples of the output from the mechanism, e.g., models trained with DP-SGD. This is equivalent\n to estimating the expectation, P(A(D) \u2208                         R) for D \u2208        {D0, D1}, of a Bernoulli random variable, I(A(D) \u2208                             R),\n from n i.i.d. samples. Providing high confidence intervals for Bernoulli distributions is a well-studied problem\nwith several off-the-shelf techniques, such as Clopper-Pearson, Jeffreys, Bernstein, and Wilson intervals.\n Concretely, let \u02c6       Pn(A(D) \u2208          R) denote the empirical probability of the model falling in the rejection set in\n n independent runs. The standard intervals scale as |P(A(D0) \u2208                                             R) \u2212      \u02c6\n |P(A(D1) \u2208          R) \u2212     \u02c6                                                                                      Pn(A(D0) \u2208           R)| \u2264      C0n\u22121/2 and\n                             Pn(A(D1) \u2208           R)| \u2264      C1n\u22121/2 for constants C0 and C1 independent of n. If A satisfies a\n claimed (\u03b5, \u03b4)-DP in Eq. (1), then the following finite-sample lower bound holds with high confidence:\n                                                                         \u02c6\n                                            \u03b5   \u2265     \u02c6                  Pn(A(D1) \u2208          R) \u2212     C1n\u22121/2 \u2212         \u03b4\n                                                      \u03b5n = log              \u02c6                                                 .                                   (2)\n                                                                            Pn(A(D0) \u2208          R) + C0n\u22121/2\n  Auditing(\u03b5, \u03b4)-DP amounts to testing the violation of this condition. This is fundamentally limited by the\n n\u22121/2 dependence of the Bernoulli confidence intervals. Our goal is to break this barrier.\n Notation. While the DP condition is symmetric in (D0, D1), we use D0, D1 to refer to specific hypotheses.\n For symmetry, we need to check both conditions: Eq. (1) and its counterpart with D0, D1 interchanged. We\n omit this second condition for notational convenience. We use the shorthand [k] := {1, 2, . . . , k}. We refer to\n random variables by boldfaced letters (e.g. D is a random dataset while D is a fixed dataset).\n Related Work. We provide detailed survey in Appendix A. A stronger canary (and its rejection set) can\n increase the RHS of (1). The resulting hypothesis test can tolerate larger confidence intervals, thus requiring\n fewer samples. This has been the focus of recent breakthroughs in privacy auditing in [31, 38, 40, 44, 59].\nThey build upon membership inference attacks [e.g. 12, 52, 67] to measure memorization. Our aim is not to\n innovate in this front. Instead, our framework can seamlessly adopt recently designed canaries and inherit\n their strengths as demonstrated in \u00a75 and \u00a76.\n      Random canaries have been used in prior work, but for making the canary out-of-distribution in a\n computationally efficient manner. No variance reduction is achieved by such random canaries. Adding\n multiple (deterministic) canaries has been explored in literature, but for different purposes. [31, 38] include\n multiple copies of the same canary to make the canary easier to detect, while paying for group privacy since\n the paired datasets differ in multiple entries (see \u00a73.2 for a detailed discussion).\n      [41, 68] propose adding multiple distinct canaries to reuse each trained model for multiple hypothesis\n testing. However, each canary is not any stronger than a single canary case, and the resulting auditing\n suffers from group privacy. When computing the lower bound of \u03b5, however, group privacy is ignored and\n the test statistics are assumed to be independent without rigorous justification. [2] avoids group privacy in\n the federated scenario where the canary has the freedom to return a canary gradient update of choice. The\n prescribed random gradient shows good empirical performance. The confidence interval is not rigorously\n derived. Our recipe on injecting multiple canaries without a group privacy cost with rigorous confidence\n intervals can be incorporated into these works to give provable lower bounds.\n                                                                                    3", "md": "# Standard Recipe: Adding a Single Canary\n\n## Standard Recipe: Adding a Single Canary\n\nWhen auditing DP model training (using e.g. DP-SGD [1, 53]), the following recipe is now standard for designing a counter-example (D0, D1, R) [30\u201332, 44, 68].\n\nA training dataset D0 is assumed to be given. This ensures that the model under scrutiny matches the use-case and is called a null hypothesis. Next, under a corresponding alternative hypothesis, a neighboring dataset D1 = D0 \u222a {c} is constructed by adding a single carefully-designed example c \u2208 Z, known as a canary.\n\nFinally, Eq. (1) is evaluated with a choice of R called a rejection set. For example, one can reject the null hypothesis (and claim the presence of the canary) if the loss on the canary is smaller than a fixed threshold; R is a set of models satisfying this rejection rule.\n\nBernoulli Confidence Intervals. Once a counter-example (D0, D1, R) is selected, we are left to evaluate the DP condition in Eq. (1). Since the two probabilities in the condition cannot be directly evaluated, we rely on the samples of the output from the mechanism, e.g., models trained with DP-SGD. This is equivalent to estimating the expectation, P(A(D) \u2208 R) for D \u2208 {D0, D1}, of a Bernoulli random variable, I(A(D) \u2208 R), from n i.i.d. samples. Providing high confidence intervals for Bernoulli distributions is a well-studied problem with several off-the-shelf techniques, such as Clopper-Pearson, Jeffreys, Bernstein, and Wilson intervals.\n\nConcretely, let \\( \\hat{P}_n(A(D) \\in R) \\) denote the empirical probability of the model falling in the rejection set in n independent runs. The standard intervals scale as \\( |\\hat{P}(A(D0) \\in R) - \\hat{P}(A(D1) \\in R)| \\leq C_0 n^{-1/2} \\) and \\( |\\hat{P}(A(D1) \\in R)| \\leq C_1 n^{-1/2} \\) for constants C0 and C1 independent of n. If A satisfies a claimed (\u03b5, \u03b4)-DP in Eq. (1), then the following finite-sample lower bound holds with high confidence:\n\n$$ \\epsilon \\geq \\hat{P}_n(A(D1) \\in R) - C_1 n^{-1/2} - \\delta $$\n$$ \\epsilon n = \\log \\frac{\\hat{P}_n(A(D0) \\in R) + C_0 n^{-1/2}}{\\hat{P}_n(A(D1) \\in R)} $$ Auditing(\u03b5, \u03b4)-DP amounts to testing the violation of this condition. This is fundamentally limited by the n^{-1/2} dependence of the Bernoulli confidence intervals. Our goal is to break this barrier.\n\nNotation. While the DP condition is symmetric in (D0, D1), we use D0, D1 to refer to specific hypotheses. For symmetry, we need to check both conditions: Eq. (1) and its counterpart with D0, D1 interchanged. We omit this second condition for notational convenience. We use the shorthand [k] := {1, 2, . . . , k}. We refer to random variables by boldfaced letters (e.g. D is a random dataset while D is a fixed dataset).\n\nRelated Work. We provide detailed survey in Appendix A. A stronger canary (and its rejection set) can increase the RHS of (1). The resulting hypothesis test can tolerate larger confidence intervals, thus requiring fewer samples. This has been the focus of recent breakthroughs in privacy auditing in [31, 38, 40, 44, 59]. They build upon membership inference attacks [e.g. 12, 52, 67] to measure memorization. Our aim is not to innovate in this front. Instead, our framework can seamlessly adopt recently designed canaries and inherit their strengths as demonstrated in \u00a75 and \u00a76.\n\nRandom canaries have been used in prior work, but for making the canary out-of-distribution in a computationally efficient manner. No variance reduction is achieved by such random canaries. Adding multiple (deterministic) canaries has been explored in literature, but for different purposes. [31, 38] include multiple copies of the same canary to make the canary easier to detect, while paying for group privacy since the paired datasets differ in multiple entries (see \u00a73.2 for a detailed discussion).\n\n[41, 68] propose adding multiple distinct canaries to reuse each trained model for multiple hypothesis testing. However, each canary is not any stronger than a single canary case, and the resulting auditing suffers from group privacy. When computing the lower bound of \u03b5, however, group privacy is ignored and the test statistics are assumed to be independent without rigorous justification. [2] avoids group privacy in the federated scenario where the canary has the freedom to return a canary gradient update of choice. The prescribed random gradient shows good empirical performance. The confidence interval is not rigorously derived. Our recipe on injecting multiple canaries without a group privacy cost with rigorous confidence intervals can be incorporated into these works to give provable lower bounds.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Standard Recipe: Adding a Single Canary", "md": "# Standard Recipe: Adding a Single Canary"}, {"type": "heading", "lvl": 2, "value": "Standard Recipe: Adding a Single Canary", "md": "## Standard Recipe: Adding a Single Canary"}, {"type": "text", "value": "When auditing DP model training (using e.g. DP-SGD [1, 53]), the following recipe is now standard for designing a counter-example (D0, D1, R) [30\u201332, 44, 68].\n\nA training dataset D0 is assumed to be given. This ensures that the model under scrutiny matches the use-case and is called a null hypothesis. Next, under a corresponding alternative hypothesis, a neighboring dataset D1 = D0 \u222a {c} is constructed by adding a single carefully-designed example c \u2208 Z, known as a canary.\n\nFinally, Eq. (1) is evaluated with a choice of R called a rejection set. For example, one can reject the null hypothesis (and claim the presence of the canary) if the loss on the canary is smaller than a fixed threshold; R is a set of models satisfying this rejection rule.\n\nBernoulli Confidence Intervals. Once a counter-example (D0, D1, R) is selected, we are left to evaluate the DP condition in Eq. (1). Since the two probabilities in the condition cannot be directly evaluated, we rely on the samples of the output from the mechanism, e.g., models trained with DP-SGD. This is equivalent to estimating the expectation, P(A(D) \u2208 R) for D \u2208 {D0, D1}, of a Bernoulli random variable, I(A(D) \u2208 R), from n i.i.d. samples. Providing high confidence intervals for Bernoulli distributions is a well-studied problem with several off-the-shelf techniques, such as Clopper-Pearson, Jeffreys, Bernstein, and Wilson intervals.\n\nConcretely, let \\( \\hat{P}_n(A(D) \\in R) \\) denote the empirical probability of the model falling in the rejection set in n independent runs. The standard intervals scale as \\( |\\hat{P}(A(D0) \\in R) - \\hat{P}(A(D1) \\in R)| \\leq C_0 n^{-1/2} \\) and \\( |\\hat{P}(A(D1) \\in R)| \\leq C_1 n^{-1/2} \\) for constants C0 and C1 independent of n. If A satisfies a claimed (\u03b5, \u03b4)-DP in Eq. (1), then the following finite-sample lower bound holds with high confidence:\n\n$$ \\epsilon \\geq \\hat{P}_n(A(D1) \\in R) - C_1 n^{-1/2} - \\delta $$\n$$ \\epsilon n = \\log \\frac{\\hat{P}_n(A(D0) \\in R) + C_0 n^{-1/2}}{\\hat{P}_n(A(D1) \\in R)} $$ Auditing(\u03b5, \u03b4)-DP amounts to testing the violation of this condition. This is fundamentally limited by the n^{-1/2} dependence of the Bernoulli confidence intervals. Our goal is to break this barrier.\n\nNotation. While the DP condition is symmetric in (D0, D1), we use D0, D1 to refer to specific hypotheses. For symmetry, we need to check both conditions: Eq. (1) and its counterpart with D0, D1 interchanged. We omit this second condition for notational convenience. We use the shorthand [k] := {1, 2, . . . , k}. We refer to random variables by boldfaced letters (e.g. D is a random dataset while D is a fixed dataset).\n\nRelated Work. We provide detailed survey in Appendix A. A stronger canary (and its rejection set) can increase the RHS of (1). The resulting hypothesis test can tolerate larger confidence intervals, thus requiring fewer samples. This has been the focus of recent breakthroughs in privacy auditing in [31, 38, 40, 44, 59]. They build upon membership inference attacks [e.g. 12, 52, 67] to measure memorization. Our aim is not to innovate in this front. Instead, our framework can seamlessly adopt recently designed canaries and inherit their strengths as demonstrated in \u00a75 and \u00a76.\n\nRandom canaries have been used in prior work, but for making the canary out-of-distribution in a computationally efficient manner. No variance reduction is achieved by such random canaries. Adding multiple (deterministic) canaries has been explored in literature, but for different purposes. [31, 38] include multiple copies of the same canary to make the canary easier to detect, while paying for group privacy since the paired datasets differ in multiple entries (see \u00a73.2 for a detailed discussion).\n\n[41, 68] propose adding multiple distinct canaries to reuse each trained model for multiple hypothesis testing. However, each canary is not any stronger than a single canary case, and the resulting auditing suffers from group privacy. When computing the lower bound of \u03b5, however, group privacy is ignored and the test statistics are assumed to be independent without rigorous justification. [2] avoids group privacy in the federated scenario where the canary has the freedom to return a canary gradient update of choice. The prescribed random gradient shows good empirical performance. The confidence interval is not rigorously derived. Our recipe on injecting multiple canaries without a group privacy cost with rigorous confidence intervals can be incorporated into these works to give provable lower bounds.", "md": "When auditing DP model training (using e.g. DP-SGD [1, 53]), the following recipe is now standard for designing a counter-example (D0, D1, R) [30\u201332, 44, 68].\n\nA training dataset D0 is assumed to be given. This ensures that the model under scrutiny matches the use-case and is called a null hypothesis. Next, under a corresponding alternative hypothesis, a neighboring dataset D1 = D0 \u222a {c} is constructed by adding a single carefully-designed example c \u2208 Z, known as a canary.\n\nFinally, Eq. (1) is evaluated with a choice of R called a rejection set. For example, one can reject the null hypothesis (and claim the presence of the canary) if the loss on the canary is smaller than a fixed threshold; R is a set of models satisfying this rejection rule.\n\nBernoulli Confidence Intervals. Once a counter-example (D0, D1, R) is selected, we are left to evaluate the DP condition in Eq. (1). Since the two probabilities in the condition cannot be directly evaluated, we rely on the samples of the output from the mechanism, e.g., models trained with DP-SGD. This is equivalent to estimating the expectation, P(A(D) \u2208 R) for D \u2208 {D0, D1}, of a Bernoulli random variable, I(A(D) \u2208 R), from n i.i.d. samples. Providing high confidence intervals for Bernoulli distributions is a well-studied problem with several off-the-shelf techniques, such as Clopper-Pearson, Jeffreys, Bernstein, and Wilson intervals.\n\nConcretely, let \\( \\hat{P}_n(A(D) \\in R) \\) denote the empirical probability of the model falling in the rejection set in n independent runs. The standard intervals scale as \\( |\\hat{P}(A(D0) \\in R) - \\hat{P}(A(D1) \\in R)| \\leq C_0 n^{-1/2} \\) and \\( |\\hat{P}(A(D1) \\in R)| \\leq C_1 n^{-1/2} \\) for constants C0 and C1 independent of n. If A satisfies a claimed (\u03b5, \u03b4)-DP in Eq. (1), then the following finite-sample lower bound holds with high confidence:\n\n$$ \\epsilon \\geq \\hat{P}_n(A(D1) \\in R) - C_1 n^{-1/2} - \\delta $$\n$$ \\epsilon n = \\log \\frac{\\hat{P}_n(A(D0) \\in R) + C_0 n^{-1/2}}{\\hat{P}_n(A(D1) \\in R)} $$ Auditing(\u03b5, \u03b4)-DP amounts to testing the violation of this condition. This is fundamentally limited by the n^{-1/2} dependence of the Bernoulli confidence intervals. Our goal is to break this barrier.\n\nNotation. While the DP condition is symmetric in (D0, D1), we use D0, D1 to refer to specific hypotheses. For symmetry, we need to check both conditions: Eq. (1) and its counterpart with D0, D1 interchanged. We omit this second condition for notational convenience. We use the shorthand [k] := {1, 2, . . . , k}. We refer to random variables by boldfaced letters (e.g. D is a random dataset while D is a fixed dataset).\n\nRelated Work. We provide detailed survey in Appendix A. A stronger canary (and its rejection set) can increase the RHS of (1). The resulting hypothesis test can tolerate larger confidence intervals, thus requiring fewer samples. This has been the focus of recent breakthroughs in privacy auditing in [31, 38, 40, 44, 59]. They build upon membership inference attacks [e.g. 12, 52, 67] to measure memorization. Our aim is not to innovate in this front. Instead, our framework can seamlessly adopt recently designed canaries and inherit their strengths as demonstrated in \u00a75 and \u00a76.\n\nRandom canaries have been used in prior work, but for making the canary out-of-distribution in a computationally efficient manner. No variance reduction is achieved by such random canaries. Adding multiple (deterministic) canaries has been explored in literature, but for different purposes. [31, 38] include multiple copies of the same canary to make the canary easier to detect, while paying for group privacy since the paired datasets differ in multiple entries (see \u00a73.2 for a detailed discussion).\n\n[41, 68] propose adding multiple distinct canaries to reuse each trained model for multiple hypothesis testing. However, each canary is not any stronger than a single canary case, and the resulting auditing suffers from group privacy. When computing the lower bound of \u03b5, however, group privacy is ignored and the test statistics are assumed to be independent without rigorous justification. [2] avoids group privacy in the federated scenario where the canary has the freedom to return a canary gradient update of choice. The prescribed random gradient shows good empirical performance. The confidence interval is not rigorously derived. Our recipe on injecting multiple canaries without a group privacy cost with rigorous confidence intervals can be incorporated into these works to give provable lower bounds."}]}, {"page": 4, "text": "    An independent and concurrent work [55] also considers auditing with randomized canaries that are\n Poisson-sampled, i.e., each canary is included or excluded independently with equal probability. Their recipe\n involves computing an empirical lower bound by comparing the accuracy (rather than the full confusion matrix\n as in our case) from the possibly dependent guesses with the worst-case randomized response mechanism.\n This allows them to use multiple dependent observations from a single trial. Their confidence intervals, unlike\n the ones we give here, are non-adaptive and worst-case.\n 3     A New Framework for Auditing DP Mechanisms with Multiple\n       Canaries\n We define Lifted DP, a new definition of privacy that is equivalent to DP (\u00a73.1). This allows us to define a new\n recipe for auditing with multiple random canaries, as opposed to a single deterministic canary in the standard\n recipe, and reuse each trained model to run multiple correlated hypothesis tests in a principled manner\n(\u00a73.2). The resulting test statistics form a vector of dependent but exchangeable indicators (which we call an\n eXchangeable Bernoulli or XBern distribution), as opposed to a single Bernoulli distribution. We leverage\n this exchangeability to give confidence intervals for the XBern distribution that can potentially improve with\n the number of injected canaries (\u00a73.3). The pseudocode of our approach is provided in Algorithm 1.\n 3.1    From DP to Lifted DP\n To enlarge the design space of counter-examples, we introduce an equivalent definition of DP.\n Definition 2 (Lifted differential privacy). Let P denote a joint probability distribution over (D0, D1, R)\n where (D0, D1) \u2208   Z\u2217 \u00d7 Z\u2217  is a pair of random datasets that are neighboring (as in the standard definition of\n neighborhood in Definition 1) with probability one and let R \u2282      R denote a random rejection set. We say\n that a randomized mechanism A : Z\u2217      \u2192  R satisfies (\u03b5, \u03b4)-Lifted Differential Privacy (LiDP) for some \u03b5 \u2265  0\n and \u03b4 \u2208 [0, 1] if, for all P independent of A, we have\n                               PA,P(A(D1) \u2208    R)   \u2264   e\u03b5 PA,P(A(D0) \u2208   R) + \u03b4 .                            (3)\n    In Appendix A.3, we discuss connections between Lifted DP and other existing extensions of DP, such\n as Bayesian DP and Pufferfish, that also consider randomized datasets. The following theorem shows that\n LiDP is equivalent to the standard DP, which justifies our framework of checking the above condition; if a\n mechanism A violates the above condition then it violates (\u03b5, \u03b4)-DP.\n Theorem 3. A randomized algorithm A is (\u03b5, \u03b4)-LiDP iff A is (\u03b5, \u03b4)-DP.\n    A proof is provided in Appendix B. In contrast to DP, LiDP involves probabilities over both the internal\n randomness of the algorithm A and the distribution P over (D0, D1, R). This gives the auditor greater\n freedom to search over a lifted space of joint distributions over the paired datasets and a rejection set; hence\n the name Lifted DP. Auditing LiDP amounts to constructing a randomized (as emphasized by the boldface\n letters) counter-example (D0, D1, R) that violates (3) as evidence.\n 3.2    From a Single Deterministic Canary to Multiple Random Canaries\n Our strategy is to turn the LiDP condition in Eq. (3) into another condition in Eq. (4) below; this allows\n the auditor to reuse samples, running multiple hypothesis tests on each sample. This derivation critically\n relies on our carefully designed recipe that incorporates three crucial features: (a) binary hypothesis tests\n between pairs of stochastically coupled datasets containing K canaries and K \u2212      1 canaries, respectively, for\n some fixed integer K, (b) sampling those canaries i.i.d. from the same distribution, and (c) choice of rejection\n sets, where each rejection set only depends on a single left-out canary. We introduce the following recipe,\n also presented in Algorithm 1.\n                                                        4", "md": "# Document\n\nAn independent and concurrent work [55] also considers auditing with randomized canaries that are Poisson-sampled, i.e., each canary is included or excluded independently with equal probability. Their recipe involves computing an empirical lower bound by comparing the accuracy (rather than the full confusion matrix as in our case) from the possibly dependent guesses with the worst-case randomized response mechanism. This allows them to use multiple dependent observations from a single trial. Their confidence intervals, unlike the ones we give here, are non-adaptive and worst-case.\n\n### A New Framework for Auditing DP Mechanisms with Multiple Canaries\n\nWe define Lifted DP, a new definition of privacy that is equivalent to DP (\u00a73.1). This allows us to define a new recipe for auditing with multiple random canaries, as opposed to a single deterministic canary in the standard recipe, and reuse each trained model to run multiple correlated hypothesis tests in a principled manner (\u00a73.2). The resulting test statistics form a vector of dependent but exchangeable indicators (which we call an eXchangeable Bernoulli or XBern distribution), as opposed to a single Bernoulli distribution. We leverage this exchangeability to give confidence intervals for the XBern distribution that can potentially improve with the number of injected canaries (\u00a73.3). The pseudocode of our approach is provided in Algorithm 1.\n\n#### 3.1 From DP to Lifted DP\n\nTo enlarge the design space of counter-examples, we introduce an equivalent definition of DP.\n\nDefinition 2 (Lifted differential privacy). Let P denote a joint probability distribution over ($$D_0, D_1, R$$) where ($$D_0, D_1$$) \u2208 $$Z^* \\times Z^*$$ is a pair of random datasets that are neighboring (as in the standard definition of neighborhood in Definition 1) with probability one and let $$R \\subset R$$ denote a random rejection set. We say that a randomized mechanism $$A : Z^* \\rightarrow R$$ satisfies $$(\\epsilon, \\delta)$$-Lifted Differential Privacy (LiDP) for some $$\\epsilon \\geq 0$$ and $$\\delta \\in [0, 1]$$ if, for all P independent of A, we have\n\n$$P_{A,P}(A(D_1) \\in R) \\leq e^{\\epsilon} P_{A,P}(A(D_0) \\in R) + \\delta$$\n\nIn Appendix A.3, we discuss connections between Lifted DP and other existing extensions of DP, such as Bayesian DP and Pufferfish, that also consider randomized datasets. The following theorem shows that LiDP is equivalent to the standard DP, which justifies our framework of checking the above condition; if a mechanism A violates the above condition then it violates $$(\\epsilon, \\delta)$$-DP.\n\nTheorem 3. A randomized algorithm A is $$(\\epsilon, \\delta)$$-LiDP iff A is $$(\\epsilon, \\delta)$$-DP.\n\nA proof is provided in Appendix B. In contrast to DP, LiDP involves probabilities over both the internal randomness of the algorithm A and the distribution P over ($$D_0, D_1, R$$). This gives the auditor greater freedom to search over a lifted space of joint distributions over the paired datasets and a rejection set; hence the name Lifted DP. Auditing LiDP amounts to constructing a randomized (as emphasized by the boldface letters) counter-example ($$D_0, D_1, R$$) that violates (3) as evidence.\n\n#### 3.2 From a Single Deterministic Canary to Multiple Random Canaries\n\nOur strategy is to turn the LiDP condition in Eq. (3) into another condition in Eq. (4) below; this allows the auditor to reuse samples, running multiple hypothesis tests on each sample. This derivation critically relies on our carefully designed recipe that incorporates three crucial features: (a) binary hypothesis tests between pairs of stochastically coupled datasets containing K canaries and K - 1 canaries, respectively, for some fixed integer K, (b) sampling those canaries i.i.d. from the same distribution, and (c) choice of rejection sets, where each rejection set only depends on a single left-out canary. We introduce the following recipe, also presented in Algorithm 1.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "An independent and concurrent work [55] also considers auditing with randomized canaries that are Poisson-sampled, i.e., each canary is included or excluded independently with equal probability. Their recipe involves computing an empirical lower bound by comparing the accuracy (rather than the full confusion matrix as in our case) from the possibly dependent guesses with the worst-case randomized response mechanism. This allows them to use multiple dependent observations from a single trial. Their confidence intervals, unlike the ones we give here, are non-adaptive and worst-case.", "md": "An independent and concurrent work [55] also considers auditing with randomized canaries that are Poisson-sampled, i.e., each canary is included or excluded independently with equal probability. Their recipe involves computing an empirical lower bound by comparing the accuracy (rather than the full confusion matrix as in our case) from the possibly dependent guesses with the worst-case randomized response mechanism. This allows them to use multiple dependent observations from a single trial. Their confidence intervals, unlike the ones we give here, are non-adaptive and worst-case."}, {"type": "heading", "lvl": 3, "value": "A New Framework for Auditing DP Mechanisms with Multiple Canaries", "md": "### A New Framework for Auditing DP Mechanisms with Multiple Canaries"}, {"type": "text", "value": "We define Lifted DP, a new definition of privacy that is equivalent to DP (\u00a73.1). This allows us to define a new recipe for auditing with multiple random canaries, as opposed to a single deterministic canary in the standard recipe, and reuse each trained model to run multiple correlated hypothesis tests in a principled manner (\u00a73.2). The resulting test statistics form a vector of dependent but exchangeable indicators (which we call an eXchangeable Bernoulli or XBern distribution), as opposed to a single Bernoulli distribution. We leverage this exchangeability to give confidence intervals for the XBern distribution that can potentially improve with the number of injected canaries (\u00a73.3). The pseudocode of our approach is provided in Algorithm 1.", "md": "We define Lifted DP, a new definition of privacy that is equivalent to DP (\u00a73.1). This allows us to define a new recipe for auditing with multiple random canaries, as opposed to a single deterministic canary in the standard recipe, and reuse each trained model to run multiple correlated hypothesis tests in a principled manner (\u00a73.2). The resulting test statistics form a vector of dependent but exchangeable indicators (which we call an eXchangeable Bernoulli or XBern distribution), as opposed to a single Bernoulli distribution. We leverage this exchangeability to give confidence intervals for the XBern distribution that can potentially improve with the number of injected canaries (\u00a73.3). The pseudocode of our approach is provided in Algorithm 1."}, {"type": "heading", "lvl": 4, "value": "3.1 From DP to Lifted DP", "md": "#### 3.1 From DP to Lifted DP"}, {"type": "text", "value": "To enlarge the design space of counter-examples, we introduce an equivalent definition of DP.\n\nDefinition 2 (Lifted differential privacy). Let P denote a joint probability distribution over ($$D_0, D_1, R$$) where ($$D_0, D_1$$) \u2208 $$Z^* \\times Z^*$$ is a pair of random datasets that are neighboring (as in the standard definition of neighborhood in Definition 1) with probability one and let $$R \\subset R$$ denote a random rejection set. We say that a randomized mechanism $$A : Z^* \\rightarrow R$$ satisfies $$(\\epsilon, \\delta)$$-Lifted Differential Privacy (LiDP) for some $$\\epsilon \\geq 0$$ and $$\\delta \\in [0, 1]$$ if, for all P independent of A, we have\n\n$$P_{A,P}(A(D_1) \\in R) \\leq e^{\\epsilon} P_{A,P}(A(D_0) \\in R) + \\delta$$\n\nIn Appendix A.3, we discuss connections between Lifted DP and other existing extensions of DP, such as Bayesian DP and Pufferfish, that also consider randomized datasets. The following theorem shows that LiDP is equivalent to the standard DP, which justifies our framework of checking the above condition; if a mechanism A violates the above condition then it violates $$(\\epsilon, \\delta)$$-DP.\n\nTheorem 3. A randomized algorithm A is $$(\\epsilon, \\delta)$$-LiDP iff A is $$(\\epsilon, \\delta)$$-DP.\n\nA proof is provided in Appendix B. In contrast to DP, LiDP involves probabilities over both the internal randomness of the algorithm A and the distribution P over ($$D_0, D_1, R$$). This gives the auditor greater freedom to search over a lifted space of joint distributions over the paired datasets and a rejection set; hence the name Lifted DP. Auditing LiDP amounts to constructing a randomized (as emphasized by the boldface letters) counter-example ($$D_0, D_1, R$$) that violates (3) as evidence.", "md": "To enlarge the design space of counter-examples, we introduce an equivalent definition of DP.\n\nDefinition 2 (Lifted differential privacy). Let P denote a joint probability distribution over ($$D_0, D_1, R$$) where ($$D_0, D_1$$) \u2208 $$Z^* \\times Z^*$$ is a pair of random datasets that are neighboring (as in the standard definition of neighborhood in Definition 1) with probability one and let $$R \\subset R$$ denote a random rejection set. We say that a randomized mechanism $$A : Z^* \\rightarrow R$$ satisfies $$(\\epsilon, \\delta)$$-Lifted Differential Privacy (LiDP) for some $$\\epsilon \\geq 0$$ and $$\\delta \\in [0, 1]$$ if, for all P independent of A, we have\n\n$$P_{A,P}(A(D_1) \\in R) \\leq e^{\\epsilon} P_{A,P}(A(D_0) \\in R) + \\delta$$\n\nIn Appendix A.3, we discuss connections between Lifted DP and other existing extensions of DP, such as Bayesian DP and Pufferfish, that also consider randomized datasets. The following theorem shows that LiDP is equivalent to the standard DP, which justifies our framework of checking the above condition; if a mechanism A violates the above condition then it violates $$(\\epsilon, \\delta)$$-DP.\n\nTheorem 3. A randomized algorithm A is $$(\\epsilon, \\delta)$$-LiDP iff A is $$(\\epsilon, \\delta)$$-DP.\n\nA proof is provided in Appendix B. In contrast to DP, LiDP involves probabilities over both the internal randomness of the algorithm A and the distribution P over ($$D_0, D_1, R$$). This gives the auditor greater freedom to search over a lifted space of joint distributions over the paired datasets and a rejection set; hence the name Lifted DP. Auditing LiDP amounts to constructing a randomized (as emphasized by the boldface letters) counter-example ($$D_0, D_1, R$$) that violates (3) as evidence."}, {"type": "heading", "lvl": 4, "value": "3.2 From a Single Deterministic Canary to Multiple Random Canaries", "md": "#### 3.2 From a Single Deterministic Canary to Multiple Random Canaries"}, {"type": "text", "value": "Our strategy is to turn the LiDP condition in Eq. (3) into another condition in Eq. (4) below; this allows the auditor to reuse samples, running multiple hypothesis tests on each sample. This derivation critically relies on our carefully designed recipe that incorporates three crucial features: (a) binary hypothesis tests between pairs of stochastically coupled datasets containing K canaries and K - 1 canaries, respectively, for some fixed integer K, (b) sampling those canaries i.i.d. from the same distribution, and (c) choice of rejection sets, where each rejection set only depends on a single left-out canary. We introduce the following recipe, also presented in Algorithm 1.", "md": "Our strategy is to turn the LiDP condition in Eq. (3) into another condition in Eq. (4) below; this allows the auditor to reuse samples, running multiple hypothesis tests on each sample. This derivation critically relies on our carefully designed recipe that incorporates three crucial features: (a) binary hypothesis tests between pairs of stochastically coupled datasets containing K canaries and K - 1 canaries, respectively, for some fixed integer K, (b) sampling those canaries i.i.d. from the same distribution, and (c) choice of rejection sets, where each rejection set only depends on a single left-out canary. We introduce the following recipe, also presented in Algorithm 1."}]}, {"page": 5, "text": "      We fix a given training set D and a canary distribution Pcanary over Z. This ensures that the model under\nscrutiny is close to the use-case. Under the alternative hypothesis, we train a model on a randomized training\ndataset D1 = D \u222a               {c1, . . . , cK}, augmented with K random canaries drawn i.i.d. from Pcanary. Conceptually,\nthis is to be tested against K leave-one-out (LOO) null hypotheses. Under the kth null hypothesis for each\nk \u2208    [K], we construct a coupled dataset, D0,k = D \u222a                                {c1, . . . , ck\u22121, ck+1, . . . cK}, with K \u2212                   1 canaries, leaving\nthe kth canary out. This coupling of K \u2212                              1 canaries ensures that (D0,k, D1) is neighboring with probability\none. For each left-out canary, the auditor runs a binary hypothesis test with a choice of a random rejection set\nRk. We restrict Rk to depend only on the canary ck that is being tested and not the index k. For example,\nRk can be the set of models achieving a loss on the canary ck below a predefined threshold \u03c4.\n      The goal of this LOO construction is to reuse each trained private model to run multiple tests such that the\naveraged test statistic has a smaller variance for a given number of models. Under the standard definition of DP,\none can still use the above LOO construction but with fixed and deterministic canaries. This gives no variance\ngain because evaluating P(A(D0,k) \u2208                          Rk) in Eq. (1) or its averaged counterpart (1/K)  K                                 k=1 P(A(D0,k) \u2208             Rk)\nrequires training one model to get one sample from the test statistic I(A(D0,k) \u2208                                                      Rk). The key ingredient in\nreusing trained models is randomization.\n      We build upon the LiDP condition in Eq. (3) by noting that the test statistics are exchangeable for\ni.i.d. canaries.           Specifically, we have for any k \u2208                           [K] that P(A(D0,k) \u2208                     Rk) = P(A(D0,K) \u2208                     RK) =\nP(A(D0,K) \u2208             R\u2032 j) for any canary c\u2032            j drawn i.i.d. from Pcanary and its corresponding rejection set R\u2032                                            j that\nare statistically independent of D0,K. Therefore, we can rewrite the right side of Eq. (3) by testing m i.i.d.\ncanaries c\u2032                  m \u223c     Pcanary using a single trained model A(D0,K) as\n                 1, . . . , c\u2032\n                                     1    K    PA,P(A(D1) \u2208             Rk)       \u2264      e\u03b5    m   PA,P(A(D0,K) \u2208                R\u2032 j) + \u03b4 .                                  (4)\n                                    K    k=1                                             m   j=1\n      Checking this condition is sufficient for auditing LiDP and, via Theorem 3, for auditing DP. For each\nmodel trained on D1, we record the test statistics of K (correlated) binary hypothesis tests. This is denoted\nby a random vector x = (I(A(D1) \u2208                                Rk))K   k=1 \u2208      {0, 1}K, where Rk is a rejection set that checks for the\npresence of the kth canary. Similar to the standard recipe, we train n models to obtain n i.i.d. samples\nx(1)   , . . . , x(n) \u2208    {0, 1}K to estimate the left side of (4) using the empirical mean:\n                                                              \u02c6               n     1    K\n                                                              \u00b51 := 1                         x(i)     \u2208   [0, 1] ,                                                           (5)\n                                                                         n   i=1   K   k=1      k\n where the subscript one in \u02c6                   \u00b51 denotes that this is the empirical first moment. Ideally, if the K tests are   \u221a\nindependent, the corresponding confidence interval is smaller by a factor of                                                          K. In practice, it depends\non how correlated the K test are. We derive principled confidence intervals that leverage the empirically\nmeasured correlations in \u00a73.3. We can define y \u2208                                 {0, 1}m and its mean \u02c6              \u03bd1 analogously for the null hypothesis.\nWe provide pseudocode in Algorithm 1 as an example guideline for applying our recipe to auditing DP\ntraining, where f\u03b8(z) is the loss evaluated on an example z for a model \u03b8. XBernLower() and XBernUpper()\nrespectively return the lower and upper adaptive confidence intervals from \u00a73.3. We instantiate Algorithm 1\nwith concrete examples of canary design in \u00a75.\nOur Recipe vs. Multiple Deterministic Canaries. An alternative with deterministic canaries would be\nto test between D0 with no canaries and D1 with K canaries such that we can get K samples from a single\ntrained model on D0, one for each of the K test statistics {I(A(D0) \u2208                                              Rk)}K   k=1. However, due to the fact that\nD1 and D0 are now at Hamming distance K, this suffers from group privacy; we are required to audit for a\nmuch larger privacy leakage of (K\u03b5, ((eK\u03b5 \u2212                               1)/(e\u03b5 \u2212      1))\u03b4)-DP. Under the (deterministic) LOO construction,\nthis translates into (1/K)  K                   k=1 P(A(D1) \u2208             Rk) \u2264      eK\u03b5(1/K)  K          k=1 P(A(D0) \u2208             Rk) + ((eK\u03b5 \u2212            1)/(e\u03b5 \u2212       1))\u03b4,\napplying probabilistic method such that if one canary violates the group privacy condition then the average\nalso violates it. We can reuse a single trained model to get K test statistics in the above condition, but each\ncanary is distinct and not any stronger than the one from (\u03b5, \u03b4)-DP auditing. One cannot obtain stronger\n                                                                                        5", "md": "# Math Equations and Text\n\nWe fix a given training set D and a canary distribution Pcanary over Z. This ensures that the model under scrutiny is close to the use-case. Under the alternative hypothesis, we train a model on a randomized training dataset D1 = D \u222a {c1, . . . , cK}, augmented with K random canaries drawn i.i.d. from Pcanary. Conceptually, this is to be tested against K leave-one-out (LOO) null hypotheses. Under the kth null hypothesis for each k \u2208 [K], we construct a coupled dataset, D0,k = D \u222a {c1, . . . , ck-1, ck+1, . . . cK}, with K - 1 canaries, leaving the kth canary out. This coupling of K - 1 canaries ensures that (D0,k, D1) is neighboring with probability one. For each left-out canary, the auditor runs a binary hypothesis test with a choice of a random rejection set Rk. We restrict Rk to depend only on the canary ck that is being tested and not the index k. For example, Rk can be the set of models achieving a loss on the canary ck below a predefined threshold \u03c4.\n\n$$\\text{The goal of this LOO construction is to reuse each trained private model to run multiple tests such that the averaged test statistic has a smaller variance for a given number of models. Under the standard definition of DP, one can still use the above LOO construction but with fixed and deterministic canaries. This gives no variance gain because evaluating } P(A(D0,k) \\in Rk</sub}) \\text{ in Eq. (1) or its averaged counterpart } \\left(\\frac{1}{K}\\sum_{k=1}^{K} P(A(D0,k) \\in Rk</sub}) \\text{ requires training one model to get one sample from the test statistic } I(A(D0,k) \\in Rk}). \\text{ The key ingredient in reusing trained models is randomization.}$$\n\nWe build upon the LiDP condition in Eq. (3) by noting that the test statistics are exchangeable for i.i.d. canaries. Specifically, we have for any k \u2208 [K] that P(A(D0,k) \\in Rk) = P(A(D0,K) \\in RK) = P(A(D0,K) \\in R'j) \\text{ for any canary } c'j \\text{ drawn i.i.d. from Pcanary and its corresponding rejection set } R'j \\text{ that are statistically independent of } D0,K. \\text{ Therefore, we can rewrite the right side of Eq. (3) by testing m i.i.d. canaries } c'1, . . . , c'm \\sim Pcanary \\text{ using a single trained model } A(D0,K) \\text{ as}$$\n\n$$\\sum_{k=1}^{K} P(A, P(A(D1) \\in Rk</sub}) \\leq e^{\\epsilon m} \\sum_{j=1}^{m} P(A, P(A(D0,K) \\in R'j</sub}) + \\delta. \\text{ (4)}$$\n\nChecking this condition is sufficient for auditing LiDP and, via Theorem 3, for auditing DP. For each model trained on D1, we record the test statistics of K (correlated) binary hypothesis tests. This is denoted by a random vector x = (I(A(D1) \\in Rk))Kk=1 \\in {0, 1}K, where Rk is a rejection set that checks for the presence of the kth canary. Similar to the standard recipe, we train n models to obtain n i.i.d. samples x(1), . . . , x(n) \\in {0, 1}K to estimate the left side of (4) using the empirical mean:\n\n$$\\hat{\\mu}_1 := \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{K} \\sum_{k=1}^{K} x^{(i)}_k \\in [0, 1], \\text{ (5)}$$\n\nwhere the subscript one in \\hat{\\mu}_1 denotes that this is the empirical first moment. Ideally, if the K tests are independent, the corresponding confidence interval is smaller by a factor of \\sqrt{K}. In practice, it depends on how correlated the K test are. We derive principled confidence intervals that leverage the empirically measured correlations in \u00a73.3. We can define y \\in {0, 1}m and its mean \\hat{\\nu}_1 analogously for the null hypothesis. We provide pseudocode in Algorithm 1 as an example guideline for applying our recipe to auditing DP training, where f\u03b8(z) is the loss evaluated on an example z for a model \u03b8. XBernLower() and XBernUpper() respectively return the lower and upper adaptive confidence intervals from \u00a73.3. We instantiate Algorithm 1 with concrete examples of canary design in \u00a75.\n\nOur Recipe vs. Multiple Deterministic Canaries. An alternative with deterministic canaries would be to test between D0 with no canaries and D1 with K canaries such that we can get K samples from a single trained model on D0, one for each of the K test statistics {I(A(D0) \\in Rk)}Kk=1. However, due to the fact that D1 and D0 are now at Hamming distance K, this suffers from group privacy; we are required to audit for a much larger privacy leakage of (K\u03b5, ((eK\u03b5 - 1)/(e\u03b5 - 1))\u03b4)-DP. Under the (deterministic) LOO construction, this translates into \\left(\\frac{1}{K} \\sum_{k=1}^{K} P(A(D1) \\in Rk</sub}) \\leq eK\u03b5\\left(\\frac{1}{K} \\sum_{k=1}^{K} P(A(D0) \\in Rk</sub}) + \\left(\\frac{eK\u03b5 - 1}{e\u03b5 - 1}\\right)\u03b4\\right>, \\text{ applying probabilistic method such that if one canary violates the group privacy condition then the average also violates it. We can reuse a single trained model to get K test statistics in the above condition, but each canary is distinct and not any stronger than the one from (\u03b5, \u03b4)-DP auditing. One cannot obtain stronger}$$", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Text", "md": "# Math Equations and Text"}, {"type": "text", "value": "We fix a given training set D and a canary distribution Pcanary over Z. This ensures that the model under scrutiny is close to the use-case. Under the alternative hypothesis, we train a model on a randomized training dataset D1 = D \u222a {c1, . . . , cK}, augmented with K random canaries drawn i.i.d. from Pcanary. Conceptually, this is to be tested against K leave-one-out (LOO) null hypotheses. Under the kth null hypothesis for each k \u2208 [K], we construct a coupled dataset, D0,k = D \u222a {c1, . . . , ck-1, ck+1, . . . cK}, with K - 1 canaries, leaving the kth canary out. This coupling of K - 1 canaries ensures that (D0,k, D1) is neighboring with probability one. For each left-out canary, the auditor runs a binary hypothesis test with a choice of a random rejection set Rk. We restrict Rk to depend only on the canary ck that is being tested and not the index k. For example, Rk can be the set of models achieving a loss on the canary ck below a predefined threshold \u03c4.\n\n$$\\text{The goal of this LOO construction is to reuse each trained private model to run multiple tests such that the averaged test statistic has a smaller variance for a given number of models. Under the standard definition of DP, one can still use the above LOO construction but with fixed and deterministic canaries. This gives no variance gain because evaluating } P(A(D0,k) \\in Rk</sub}) \\text{ in Eq. (1) or its averaged counterpart } \\left(\\frac{1}{K}\\sum_{k=1}^{K} P(A(D0,k) \\in Rk</sub}) \\text{ requires training one model to get one sample from the test statistic } I(A(D0,k) \\in Rk}). \\text{ The key ingredient in reusing trained models is randomization.}$$\n\nWe build upon the LiDP condition in Eq. (3) by noting that the test statistics are exchangeable for i.i.d. canaries. Specifically, we have for any k \u2208 [K] that P(A(D0,k) \\in Rk) = P(A(D0,K) \\in RK) = P(A(D0,K) \\in R'j) \\text{ for any canary } c'j \\text{ drawn i.i.d. from Pcanary and its corresponding rejection set } R'j \\text{ that are statistically independent of } D0,K. \\text{ Therefore, we can rewrite the right side of Eq. (3) by testing m i.i.d. canaries } c'1, . . . , c'm \\sim Pcanary \\text{ using a single trained model } A(D0,K) \\text{ as}$$\n\n$$\\sum_{k=1}^{K} P(A, P(A(D1) \\in Rk</sub}) \\leq e^{\\epsilon m} \\sum_{j=1}^{m} P(A, P(A(D0,K) \\in R'j</sub}) + \\delta. \\text{ (4)}$$\n\nChecking this condition is sufficient for auditing LiDP and, via Theorem 3, for auditing DP. For each model trained on D1, we record the test statistics of K (correlated) binary hypothesis tests. This is denoted by a random vector x = (I(A(D1) \\in Rk))Kk=1 \\in {0, 1}K, where Rk is a rejection set that checks for the presence of the kth canary. Similar to the standard recipe, we train n models to obtain n i.i.d. samples x(1), . . . , x(n) \\in {0, 1}K to estimate the left side of (4) using the empirical mean:\n\n$$\\hat{\\mu}_1 := \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{K} \\sum_{k=1}^{K} x^{(i)}_k \\in [0, 1], \\text{ (5)}$$\n\nwhere the subscript one in \\hat{\\mu}_1 denotes that this is the empirical first moment. Ideally, if the K tests are independent, the corresponding confidence interval is smaller by a factor of \\sqrt{K}. In practice, it depends on how correlated the K test are. We derive principled confidence intervals that leverage the empirically measured correlations in \u00a73.3. We can define y \\in {0, 1}m and its mean \\hat{\\nu}_1 analogously for the null hypothesis. We provide pseudocode in Algorithm 1 as an example guideline for applying our recipe to auditing DP training, where f\u03b8(z) is the loss evaluated on an example z for a model \u03b8. XBernLower() and XBernUpper() respectively return the lower and upper adaptive confidence intervals from \u00a73.3. We instantiate Algorithm 1 with concrete examples of canary design in \u00a75.\n\nOur Recipe vs. Multiple Deterministic Canaries. An alternative with deterministic canaries would be to test between D0 with no canaries and D1 with K canaries such that we can get K samples from a single trained model on D0, one for each of the K test statistics {I(A(D0) \\in Rk)}Kk=1. However, due to the fact that D1 and D0 are now at Hamming distance K, this suffers from group privacy; we are required to audit for a much larger privacy leakage of (K\u03b5, ((eK\u03b5 - 1)/(e\u03b5 - 1))\u03b4)-DP. Under the (deterministic) LOO construction, this translates into \\left(\\frac{1}{K} \\sum_{k=1}^{K} P(A(D1) \\in Rk</sub}) \\leq eK\u03b5\\left(\\frac{1}{K} \\sum_{k=1}^{K} P(A(D0) \\in Rk</sub}) + \\left(\\frac{eK\u03b5 - 1}{e\u03b5 - 1}\\right)\u03b4\\right>, \\text{ applying probabilistic method such that if one canary violates the group privacy condition then the average also violates it. We can reuse a single trained model to get K test statistics in the above condition, but each canary is distinct and not any stronger than the one from (\u03b5, \u03b4)-DP auditing. One cannot obtain stronger}$$", "md": "We fix a given training set D and a canary distribution Pcanary over Z. This ensures that the model under scrutiny is close to the use-case. Under the alternative hypothesis, we train a model on a randomized training dataset D1 = D \u222a {c1, . . . , cK}, augmented with K random canaries drawn i.i.d. from Pcanary. Conceptually, this is to be tested against K leave-one-out (LOO) null hypotheses. Under the kth null hypothesis for each k \u2208 [K], we construct a coupled dataset, D0,k = D \u222a {c1, . . . , ck-1, ck+1, . . . cK}, with K - 1 canaries, leaving the kth canary out. This coupling of K - 1 canaries ensures that (D0,k, D1) is neighboring with probability one. For each left-out canary, the auditor runs a binary hypothesis test with a choice of a random rejection set Rk. We restrict Rk to depend only on the canary ck that is being tested and not the index k. For example, Rk can be the set of models achieving a loss on the canary ck below a predefined threshold \u03c4.\n\n$$\\text{The goal of this LOO construction is to reuse each trained private model to run multiple tests such that the averaged test statistic has a smaller variance for a given number of models. Under the standard definition of DP, one can still use the above LOO construction but with fixed and deterministic canaries. This gives no variance gain because evaluating } P(A(D0,k) \\in Rk</sub}) \\text{ in Eq. (1) or its averaged counterpart } \\left(\\frac{1}{K}\\sum_{k=1}^{K} P(A(D0,k) \\in Rk</sub}) \\text{ requires training one model to get one sample from the test statistic } I(A(D0,k) \\in Rk}). \\text{ The key ingredient in reusing trained models is randomization.}$$\n\nWe build upon the LiDP condition in Eq. (3) by noting that the test statistics are exchangeable for i.i.d. canaries. Specifically, we have for any k \u2208 [K] that P(A(D0,k) \\in Rk) = P(A(D0,K) \\in RK) = P(A(D0,K) \\in R'j) \\text{ for any canary } c'j \\text{ drawn i.i.d. from Pcanary and its corresponding rejection set } R'j \\text{ that are statistically independent of } D0,K. \\text{ Therefore, we can rewrite the right side of Eq. (3) by testing m i.i.d. canaries } c'1, . . . , c'm \\sim Pcanary \\text{ using a single trained model } A(D0,K) \\text{ as}$$\n\n$$\\sum_{k=1}^{K} P(A, P(A(D1) \\in Rk</sub}) \\leq e^{\\epsilon m} \\sum_{j=1}^{m} P(A, P(A(D0,K) \\in R'j</sub}) + \\delta. \\text{ (4)}$$\n\nChecking this condition is sufficient for auditing LiDP and, via Theorem 3, for auditing DP. For each model trained on D1, we record the test statistics of K (correlated) binary hypothesis tests. This is denoted by a random vector x = (I(A(D1) \\in Rk))Kk=1 \\in {0, 1}K, where Rk is a rejection set that checks for the presence of the kth canary. Similar to the standard recipe, we train n models to obtain n i.i.d. samples x(1), . . . , x(n) \\in {0, 1}K to estimate the left side of (4) using the empirical mean:\n\n$$\\hat{\\mu}_1 := \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{K} \\sum_{k=1}^{K} x^{(i)}_k \\in [0, 1], \\text{ (5)}$$\n\nwhere the subscript one in \\hat{\\mu}_1 denotes that this is the empirical first moment. Ideally, if the K tests are independent, the corresponding confidence interval is smaller by a factor of \\sqrt{K}. In practice, it depends on how correlated the K test are. We derive principled confidence intervals that leverage the empirically measured correlations in \u00a73.3. We can define y \\in {0, 1}m and its mean \\hat{\\nu}_1 analogously for the null hypothesis. We provide pseudocode in Algorithm 1 as an example guideline for applying our recipe to auditing DP training, where f\u03b8(z) is the loss evaluated on an example z for a model \u03b8. XBernLower() and XBernUpper() respectively return the lower and upper adaptive confidence intervals from \u00a73.3. We instantiate Algorithm 1 with concrete examples of canary design in \u00a75.\n\nOur Recipe vs. Multiple Deterministic Canaries. An alternative with deterministic canaries would be to test between D0 with no canaries and D1 with K canaries such that we can get K samples from a single trained model on D0, one for each of the K test statistics {I(A(D0) \\in Rk)}Kk=1. However, due to the fact that D1 and D0 are now at Hamming distance K, this suffers from group privacy; we are required to audit for a much larger privacy leakage of (K\u03b5, ((eK\u03b5 - 1)/(e\u03b5 - 1))\u03b4)-DP. Under the (deterministic) LOO construction, this translates into \\left(\\frac{1}{K} \\sum_{k=1}^{K} P(A(D1) \\in Rk</sub}) \\leq eK\u03b5\\left(\\frac{1}{K} \\sum_{k=1}^{K} P(A(D0) \\in Rk</sub}) + \\left(\\frac{eK\u03b5 - 1}{e\u03b5 - 1}\\right)\u03b4\\right>, \\text{ applying probabilistic method such that if one canary violates the group privacy condition then the average also violates it. We can reuse a single trained model to get K test statistics in the above condition, but each canary is distinct and not any stronger than the one from (\u03b5, \u03b4)-DP auditing. One cannot obtain stronger}$$"}]}, {"page": 6, "text": "Algorithm 1 Auditing Lifted DP\nInput: Sample size n, number of canaries K, number of null tests m, DP mechanism A, training set D,\n      canary generating distribution Pcanary, threshold \u03c4, failure probability \u03b2, privacy \u03b4 \u2208                                                        [0, 1].\n  1: for i = 1, . . . , n do\n  2:        Randomly generate K + m canaries {c1, . . . , cK, c\u2032                                            m} i.i.d. from Pcanary.\n  3:        D0 \u2190       D \u222a     {c1, . . . , cK\u22121}, D1 \u2190              D \u222a     {c1, . . . , cK}   1, . . . , c\u2032\n  4:        Train two models \u03b80 \u2190                   A(D0) and \u03b81 \u2190                A(D1)K                            I(f\u03b80(c\u2032                m\n  5:        Record test statistics x(i) \u2190                     I(f\u03b81(ck) < \u03c4)            k=1 and y(i) \u2190                         j) < \u03c4)       j=1\n  6: Set p     1 \u2190     XBernLower             {x(i)}i\u2208[n], \u03b2/2           and p0 \u2190          XBernUpper             {y(i)}i\u2208[n], \u03b2/2\n  7: Return \u02c6        \u03b5n \u2190      log    (p1 \u2212      \u03b4)/p0       and a guarantee that P(\u03b5 < \u02c6                   \u03b5n) \u2264     \u03b2.\ncounterexamples without sacrificing the sample gain. For example, we can repeat the same canary K times\nas proposed in [31]. This makes it easier to detect the canary, making a stronger counter-example, but there\nis no sample gain as we only get one test statistic per trained model. With deterministic canaries, there is no\nway to avoid this group privacy cost while our recipe does not incur it.\n3.3         From Bernoulli Intervals to Higher-Order Exchangeable Bernoulli (XBern)\n            Intervals\nThe LiDP condition in Eq. (4) critically relies on the canaries being sampled i.i.d. and the rejection set only\ndepending on the corresponding canary. For such a symmetric design, auditing boils down to deriving a\nConfidence Interval (CI) for a special family of distributions that we call Exchangeable Bernoulli (XBern).\nRecall that xk := I(A(D1) \u2208                        Rk) denotes the test statistic for the kth canary. By the symmetry of our\ndesign, x \u2208         {0, 1}K is an exchangeable random vector that is distributed as an exponential family. Further,\nthe distribution of x is fully defined by a K-dimensional parameter (\u00b51, . . . , \u00b5K) where \u00b5\u2113                                                         is the \u2113th moment\nof x. We call this family XBern. Specifically, this implies permutation invariance of the higher-order\nmoments: E[xj1 \u00b7 \u00b7 \u00b7 xj\u2113] = E[xk1 \u00b7 \u00b7 \u00b7 xk\u2113] for any distinct sets of indices (jl)l\u2208[\u2113] and (kl)l\u2208[\u2113] for any \u2113                                                          \u2264   K.\nFor example, \u00b51 := E[(1/K)  K                       k=1 xk], which is the LHS of (4). Using samples from this XBern, we aim to\nderive a CI on \u00b51 around the empirical mean \u02c6                                \u00b51 in (5). Bernstein\u2019s inequality applied to our test statistic\nm1 := (1/K)  K             k=1 xk gives,       | \u02c6                       2 log(2/\u03b2)\n                                                \u00b51 \u2212     \u00b51|      \u2264                n         Var(m1) + 2 log(2/\u03b2)      3n         ,                                         (6)\nw.p. at least 1 \u2212           \u03b2. Bounding Var(m1) \u2264                     \u00b51(1 \u2212     \u00b51) since m1 \u2208            [0, 1] a.s. and numerically solving the above\ninequality for \u00b51 gives a CI that scales as 1/\u221an \u2014 see Figure 2 (left). We call this the 1st-order Bernstein\nbound, as it depends only on the 1st moment \u00b51. Our strategy is to measure the (higher-order) correlations\nbetween xk\u2019s to derive a tighter CI that adapts to the given instance. This idea applies to any standard CI.\nWe derive and analyze the higher order Bernstein intervals here, and experiments use Wilson intervals from\nAppendix C; see also Figure 2 (right).\n      Concretely, we can leverage the 2nd order correlation by expanding\n                   Var(m1) = 1         K (\u00b51 \u2212       \u00b52) + (\u00b52 \u2212          \u00b521)     where        \u00b5  2 :=    K(K \u2212  1     1)   k1<k2\u2208[K]      E [xk1xk2] .\n Ideally, when the second order correlation \u00b52 \u2212                                   \u00b521 = E[x1x2] \u2212            E[x1]E[x2] equals 0, we have Var(m1) =\n\u00b51(1 \u2212      \u00b51)/K, a factor of K improvement over the worst-case. Our higher-order CIs adapt to the actual\nlevel of correlation of x by further estimating the 2nd moment \u00b52 from samples. Let \u00b52 be the first-order\n                                                                                        6", "md": "# Algorithm 1: Auditing Lifted DP\n\n## Algorithm 1: Auditing Lifted DP\n\nInput: Sample size n, number of canaries K, number of null tests m, DP mechanism A, training set D, canary generating distribution Pcanary, threshold \u03c4, failure probability \u03b2, privacy \u03b4 \u2208 [0, 1].\n\n1: for i = 1, . . . , n do\n2:    Randomly generate K + m canaries {c1, . . . , cK, c'm} i.i.d. from Pcanary.\n3:    D0 \u2190 D \u222a {c1, . . . , cK-1}, D1 \u2190 D \u222a {c1, . . . , cK, c'm}\n4:    Train two models \u03b80 \u2190 A(D0) and \u03b81 \u2190 A(D1)\n5:    Record test statistics x(i) \u2190 I(f\u03b81(ck) &lt; \u03c4) for k=1 and y(i) \u2190 I(f\u03b81(c'j) &lt; \u03c4) for j=1\n6: Set p1 \u2190 XBernLower {x(i)}i\u2208[n], \u03b2/2 and p0 \u2190 XBernUpper {y(i)}i\u2208[n], \u03b2/2\n7: Return \u02c6\u03b5n \u2190 log(p1 - \u03b4)/p0 and a guarantee that P(\u03b5 &lt; \u02c6\u03b5n) \u2264 \u03b2.\n\nCounterexamples without sacrificing the sample gain. For example, we can repeat the same canary K times as proposed in [31]. This makes it easier to detect the canary, making a stronger counter-example, but there is no sample gain as we only get one test statistic per trained model. With deterministic canaries, there is no way to avoid this group privacy cost while our recipe does not incur it.\n\n### 3.3 From Bernoulli Intervals to Higher-Order Exchangeable Bernoulli (XBern) Intervals\n\nThe LiDP condition in Eq. (4) critically relies on the canaries being sampled i.i.d. and the rejection set only depending on the corresponding canary. For such a symmetric design, auditing boils down to deriving a Confidence Interval (CI) for a special family of distributions that we call Exchangeable Bernoulli (XBern). Recall that $$x_k := I(A(D_1) \\in R_k)$$ denotes the test statistic for the kth canary. By the symmetry of our design, x \u2208 {0, 1}K is an exchangeable random vector that is distributed as an exponential family. Further, the distribution of x is fully defined by a K-dimensional parameter (\u00b51, . . . , \u00b5K) where \u00b5\u2113 is the \u2113th moment of x. We call this family XBern. Specifically, this implies permutation invariance of the higher-order moments: $$E[x_{j_1} \\cdot \\ldots \\cdot x_{j_\u2113}] = E[x_{k_1} \\cdot \\ldots \\cdot x_{k_\u2113}]$$ for any distinct sets of indices (jl)l\u2208[\u2113] and (kl)l\u2208[\u2113] for any \u2113 \u2264 K. For example, $$\\mu_1 := E[(1/K) \\sum_{k=1}^{K} x_k]$$, which is the LHS of (4). Using samples from this XBern, we aim to derive a CI on \u00b51 around the empirical mean $$\\hat{\\mu}_1$$ in (5). Bernstein\u2019s inequality applied to our test statistic $$m_1 := (1/K) \\sum_{k=1}^{K} x_k$$ gives, $$|\\hat{\\mu}_1 - \\mu_1| \\leq \\sqrt{\\frac{2 \\log(2/\u03b2)}{n} \\text{Var}(m_1) + 2 \\log(2/\u03b2) \\sqrt{3n}}$$, w.p. at least 1 - \u03b2. Bounding Var(m1) \u2264 \u00b51(1 - \u00b51) since $$m_1 \\in [0, 1]$$ a.s. and numerically solving the above inequality for \u00b51 gives a CI that scales as 1/\u221an \u2014 see Figure 2 (left). We call this the 1st-order Bernstein bound, as it depends only on the 1st moment \u00b51. Our strategy is to measure the (higher-order) correlations between xk's to derive a tighter CI that adapts to the given instance. This idea applies to any standard CI.\n\nWe derive and analyze the higher order Bernstein intervals here, and experiments use Wilson intervals from Appendix C; see also Figure 2 (right).\n\nConcretely, we can leverage the 2nd order correlation by expanding\n\nVar(m1) = 1/K (\u00b51 - \u00b52) + (\u00b52 - \u00b522) where \u00b52 := 1/K(K - 1) \u03a3k1<k2\u2208[K] E[xk1xk2].\n\nIdeally, when the second order correlation \u00b52 - \u00b522 = E[x1x2] - E[x1]E[x2] equals 0, we have Var(m1) = \u00b51(1 - \u00b51)/K, a factor of K improvement over the worst-case. Our higher-order CIs adapt to the actual level of correlation of x by further estimating the 2nd moment \u00b52 from samples. Let \u00b52 be the first-order.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Algorithm 1: Auditing Lifted DP", "md": "# Algorithm 1: Auditing Lifted DP"}, {"type": "heading", "lvl": 2, "value": "Algorithm 1: Auditing Lifted DP", "md": "## Algorithm 1: Auditing Lifted DP"}, {"type": "text", "value": "Input: Sample size n, number of canaries K, number of null tests m, DP mechanism A, training set D, canary generating distribution Pcanary, threshold \u03c4, failure probability \u03b2, privacy \u03b4 \u2208 [0, 1].\n\n1: for i = 1, . . . , n do\n2:    Randomly generate K + m canaries {c1, . . . , cK, c'm} i.i.d. from Pcanary.\n3:    D0 \u2190 D \u222a {c1, . . . , cK-1}, D1 \u2190 D \u222a {c1, . . . , cK, c'm}\n4:    Train two models \u03b80 \u2190 A(D0) and \u03b81 \u2190 A(D1)\n5:    Record test statistics x(i) \u2190 I(f\u03b81(ck) &lt; \u03c4) for k=1 and y(i) \u2190 I(f\u03b81(c'j) &lt; \u03c4) for j=1\n6: Set p1 \u2190 XBernLower {x(i)}i\u2208[n], \u03b2/2 and p0 \u2190 XBernUpper {y(i)}i\u2208[n], \u03b2/2\n7: Return \u02c6\u03b5n \u2190 log(p1 - \u03b4)/p0 and a guarantee that P(\u03b5 &lt; \u02c6\u03b5n) \u2264 \u03b2.\n\nCounterexamples without sacrificing the sample gain. For example, we can repeat the same canary K times as proposed in [31]. This makes it easier to detect the canary, making a stronger counter-example, but there is no sample gain as we only get one test statistic per trained model. With deterministic canaries, there is no way to avoid this group privacy cost while our recipe does not incur it.", "md": "Input: Sample size n, number of canaries K, number of null tests m, DP mechanism A, training set D, canary generating distribution Pcanary, threshold \u03c4, failure probability \u03b2, privacy \u03b4 \u2208 [0, 1].\n\n1: for i = 1, . . . , n do\n2:    Randomly generate K + m canaries {c1, . . . , cK, c'm} i.i.d. from Pcanary.\n3:    D0 \u2190 D \u222a {c1, . . . , cK-1}, D1 \u2190 D \u222a {c1, . . . , cK, c'm}\n4:    Train two models \u03b80 \u2190 A(D0) and \u03b81 \u2190 A(D1)\n5:    Record test statistics x(i) \u2190 I(f\u03b81(ck) &lt; \u03c4) for k=1 and y(i) \u2190 I(f\u03b81(c'j) &lt; \u03c4) for j=1\n6: Set p1 \u2190 XBernLower {x(i)}i\u2208[n], \u03b2/2 and p0 \u2190 XBernUpper {y(i)}i\u2208[n], \u03b2/2\n7: Return \u02c6\u03b5n \u2190 log(p1 - \u03b4)/p0 and a guarantee that P(\u03b5 &lt; \u02c6\u03b5n) \u2264 \u03b2.\n\nCounterexamples without sacrificing the sample gain. For example, we can repeat the same canary K times as proposed in [31]. This makes it easier to detect the canary, making a stronger counter-example, but there is no sample gain as we only get one test statistic per trained model. With deterministic canaries, there is no way to avoid this group privacy cost while our recipe does not incur it."}, {"type": "heading", "lvl": 3, "value": "3.3 From Bernoulli Intervals to Higher-Order Exchangeable Bernoulli (XBern) Intervals", "md": "### 3.3 From Bernoulli Intervals to Higher-Order Exchangeable Bernoulli (XBern) Intervals"}, {"type": "text", "value": "The LiDP condition in Eq. (4) critically relies on the canaries being sampled i.i.d. and the rejection set only depending on the corresponding canary. For such a symmetric design, auditing boils down to deriving a Confidence Interval (CI) for a special family of distributions that we call Exchangeable Bernoulli (XBern). Recall that $$x_k := I(A(D_1) \\in R_k)$$ denotes the test statistic for the kth canary. By the symmetry of our design, x \u2208 {0, 1}K is an exchangeable random vector that is distributed as an exponential family. Further, the distribution of x is fully defined by a K-dimensional parameter (\u00b51, . . . , \u00b5K) where \u00b5\u2113 is the \u2113th moment of x. We call this family XBern. Specifically, this implies permutation invariance of the higher-order moments: $$E[x_{j_1} \\cdot \\ldots \\cdot x_{j_\u2113}] = E[x_{k_1} \\cdot \\ldots \\cdot x_{k_\u2113}]$$ for any distinct sets of indices (jl)l\u2208[\u2113] and (kl)l\u2208[\u2113] for any \u2113 \u2264 K. For example, $$\\mu_1 := E[(1/K) \\sum_{k=1}^{K} x_k]$$, which is the LHS of (4). Using samples from this XBern, we aim to derive a CI on \u00b51 around the empirical mean $$\\hat{\\mu}_1$$ in (5). Bernstein\u2019s inequality applied to our test statistic $$m_1 := (1/K) \\sum_{k=1}^{K} x_k$$ gives, $$|\\hat{\\mu}_1 - \\mu_1| \\leq \\sqrt{\\frac{2 \\log(2/\u03b2)}{n} \\text{Var}(m_1) + 2 \\log(2/\u03b2) \\sqrt{3n}}$$, w.p. at least 1 - \u03b2. Bounding Var(m1) \u2264 \u00b51(1 - \u00b51) since $$m_1 \\in [0, 1]$$ a.s. and numerically solving the above inequality for \u00b51 gives a CI that scales as 1/\u221an \u2014 see Figure 2 (left). We call this the 1st-order Bernstein bound, as it depends only on the 1st moment \u00b51. Our strategy is to measure the (higher-order) correlations between xk's to derive a tighter CI that adapts to the given instance. This idea applies to any standard CI.\n\nWe derive and analyze the higher order Bernstein intervals here, and experiments use Wilson intervals from Appendix C; see also Figure 2 (right).\n\nConcretely, we can leverage the 2nd order correlation by expanding\n\nVar(m1) = 1/K (\u00b51 - \u00b52) + (\u00b52 - \u00b522) where \u00b52 := 1/K(K - 1) \u03a3k1<k2\u2208[K] E[xk1xk2].\n\nIdeally, when the second order correlation \u00b52 - \u00b522 = E[x1x2] - E[x1]E[x2] equals 0, we have Var(m1) = \u00b51(1 - \u00b51)/K, a factor of K improvement over the worst-case. Our higher-order CIs adapt to the actual level of correlation of x by further estimating the 2nd moment \u00b52 from samples. Let \u00b52 be the first-order.", "md": "The LiDP condition in Eq. (4) critically relies on the canaries being sampled i.i.d. and the rejection set only depending on the corresponding canary. For such a symmetric design, auditing boils down to deriving a Confidence Interval (CI) for a special family of distributions that we call Exchangeable Bernoulli (XBern). Recall that $$x_k := I(A(D_1) \\in R_k)$$ denotes the test statistic for the kth canary. By the symmetry of our design, x \u2208 {0, 1}K is an exchangeable random vector that is distributed as an exponential family. Further, the distribution of x is fully defined by a K-dimensional parameter (\u00b51, . . . , \u00b5K) where \u00b5\u2113 is the \u2113th moment of x. We call this family XBern. Specifically, this implies permutation invariance of the higher-order moments: $$E[x_{j_1} \\cdot \\ldots \\cdot x_{j_\u2113}] = E[x_{k_1} \\cdot \\ldots \\cdot x_{k_\u2113}]$$ for any distinct sets of indices (jl)l\u2208[\u2113] and (kl)l\u2208[\u2113] for any \u2113 \u2264 K. For example, $$\\mu_1 := E[(1/K) \\sum_{k=1}^{K} x_k]$$, which is the LHS of (4). Using samples from this XBern, we aim to derive a CI on \u00b51 around the empirical mean $$\\hat{\\mu}_1$$ in (5). Bernstein\u2019s inequality applied to our test statistic $$m_1 := (1/K) \\sum_{k=1}^{K} x_k$$ gives, $$|\\hat{\\mu}_1 - \\mu_1| \\leq \\sqrt{\\frac{2 \\log(2/\u03b2)}{n} \\text{Var}(m_1) + 2 \\log(2/\u03b2) \\sqrt{3n}}$$, w.p. at least 1 - \u03b2. Bounding Var(m1) \u2264 \u00b51(1 - \u00b51) since $$m_1 \\in [0, 1]$$ a.s. and numerically solving the above inequality for \u00b51 gives a CI that scales as 1/\u221an \u2014 see Figure 2 (left). We call this the 1st-order Bernstein bound, as it depends only on the 1st moment \u00b51. Our strategy is to measure the (higher-order) correlations between xk's to derive a tighter CI that adapts to the given instance. This idea applies to any standard CI.\n\nWe derive and analyze the higher order Bernstein intervals here, and experiments use Wilson intervals from Appendix C; see also Figure 2 (right).\n\nConcretely, we can leverage the 2nd order correlation by expanding\n\nVar(m1) = 1/K (\u00b51 - \u00b52) + (\u00b52 - \u00b522) where \u00b52 := 1/K(K - 1) \u03a3k1<k2\u2208[K] E[xk1xk2].\n\nIdeally, when the second order correlation \u00b52 - \u00b522 = E[x1x2] - E[x1]E[x2] equals 0, we have Var(m1) = \u00b51(1 - \u00b51)/K, a factor of K improvement over the worst-case. Our higher-order CIs adapt to the actual level of correlation of x by further estimating the 2nd moment \u00b52 from samples. Let \u00b52 be the first-order."}]}, {"page": 7, "text": "                                                                                                                                                 Computing the Bernstein C.I. by Root-Finding                                  Leading Coeffi      cient of Wilson vs. Bernstein\n                                                                                                                                                                                       |\u00b5 \u2212    \u02c6                                                                             Bernstein\n                        z2                                                                                                                                                                     \u00b5|                        3.5                                                 Wilson\n                                                                                     z1 + z2                                                                                           a     \u00b5(1 \u2212    \u00b5) + b             3.0\n                                                                                                                                                                                                                       Coefficient\n                                                                              z1 + z2 + \u03c3\u03be                                                                                                                               2.5\n                                                                                                                                                                                                                         2.0\n                                                                       z1 + z2 + c + \u03c3\u03be                                                                                                                                  1.5\n                                                            z1                                                                                                                                                           1.0\n Figure 1: Bias illustration: Consider the sum query                                                                                                             \u00b5       \u00b5        \u00b5                                           10\u22123                    10\u22122                    10\u22121\n                                                                                                                                                                                                                                               Failure Probability \u03b2\n z1 + z2 with 2 inputs. Its DP version produces a point\n in the blue circle w.h.p. due to the noise \u03be \u223c                                                                      N    (0, I)                Figure 2: Left: The Bernstein CI [\u00b5, \u00b5] can be found by\n scaled by \u03c3. When auditing with a random canary c, it                                                                                          equating the two sides of Bernstein\u2019s inequality in Eq. (6).\n contributes additional randomness (red disc) leading to                                                                                        Right: The asymptotic Wilson CI is a tightening of the\n a smaller effective privacy parameter \u03b5.                                                                                                       Bernstein CI with a smaller 1/\u221an coefficient (shown here)\n                                                                                                                                                and no 1/n term.\n Bernstein upper bound on \u00b52 such that P(\u00b52 \u2264                                                                                    \u00b52) \u2265            1 \u2212        \u03b2. On this event,\n   Combining this with (6) gives us the 2nd-order Bernstein bound on \u00b51, valid w.p. 1 \u2212   Var(m1)                      \u2264         K1(\u00b51 \u2212                \u00b52) + (\u00b52 \u2212                      \u00b52  1) .                                                                  2\u03b2. Since            (7)\n \u00b5   2 \u2272        \u02c6\n                \u00b52 + 1/\u221an where \u02c6                                \u00b52 is the empirical estimate of \u00b52, the 2nd-order bound scales as\n                                                                                  |\u00b51 \u2212            \u02c6                               1                     1                                        1\n                                                                                                  \u00b51|           \u2272                                              \u00b52 \u2212           \u02c6\nwhere constants and log factors are omitted. Thus, our 2nd-order CI can be as small as 1/                                       nK +                     n   | \u02c6             \u00b52  1| +         n3/4 ,                                    \u221a    nK +           1/n3/4 (when                (8)\n \u02c6\n \u00b52                                                                                                                                                                                                                                      \u00b52 \u2212           \u02c6\n     1 \u2248        \u00b52) or as large as 1/\u221an (in the worst-case). With small enough correlations of |                                                                                                                                          \u02c6            \u00b52   1| = O(1/K),\n this suggests a choice of K = O(\u221an) to get CI of 1/n3/4. In practice, the correlation is controlled by the\n design of the canary. For the Gaussian mechanism with random canaries, the correlation indeed empirically\n decays as 1/K, as we see in \u00a74. While the CI decreases monotonically with K, this incurs a larger bias due\n to the additional randomness from adding more canaries. The optimal choice of K balances the bias and\nvariance; we return to this in \u00a74.\n Higher-order intervals. We can recursively apply this method by expanding the variance of higher-order\n statistics, and derive higher-order Bernstein bounds. The next recursion uses empirical 3rd and 4th moments\n \u02c6\n \u00b53 and \u02c6            \u00b54 to get the 4th-order Bernstein bound which scales as\n                                                           |\u00b51 \u2212           \u02c6                         1                     1                                         1                                                    1\n                                                                          \u00b51| \u2272                                                  \u00b52 \u2212            \u02c6\n                                                                                                                                                \u00b52                            \u00b5    4 \u2212        \u02c6\n Ideally, when the 4th-order correlation is small enough, |                                       nK +                    n |     \u02c6                 1| +      \u02c6  n3/4 |        \u02c6             \u00b52  2|1/4 +              n7/8 .                                                            (9)\n                                                                                                                                                             \u00b54 \u2212            \u02c6\n correlation, \u02c6                  \u00b52 \u2212            \u02c6                                                                                                                          \u00b52  2| = O(1/K), (along with the 2nd-order\n                                                \u00b52  1) this 4th-order CI scales as 1/n7/8 with a choice of K = O(n3/4) improving upon the\n2nd-order CI of 1/n3/4. We can recursively derive even higher-order CIs, but we find \u00a74 that the gains\n diminish rapidly. In general, the \u2113th order Bernstein bounds achieve CIs scaling as 1/n(2\u2113\u22121)/2\u2113                                                                                                                                                           with a choice\n of K = O(n(\u2113\u22121)/\u2113). This shows that the higher-order confidence interval is decreasing in the order \u2113                                                                                                                                                                         of the\n correlations used; we refer to Appendix C for details.\n Proposition 4. For any positive integer \u2113                                                                             that is a power of two and K = \u2308n(\u2113\u22121)/\u2113\u2309, suppose we have n\nsamples from a K-dimensional XBern distribution with parameters (\u00b51, . . . , \u00b5K                                                                                                                                 ). If all \u2113\u2032th-order correlations\nscale as 1/K, i.e., |\u00b52\u2113\u2032 \u2212                                          \u00b52  \u2113\u2032  | = O(1/K), for all \u2113\u2032 \u2264                                         \u2113    and \u2113\u2032 is a power of two, then the \u2113th-order Bernstein\nbound is |\u00b51 \u2212                           \u02c6\n                                        \u00b51| = O(1/n(2\u2113\u22121)/(2\u2113)).\n                                                                                                                                              7", "md": "# Math Equations and Tables\n\n## Computing the Bernstein C.I. by Root-Finding\n\nLeading Coefficient of Wilson vs. Bernstein\n\n|$\\left|\\mu - \\hat{\\mu}\\right|$|3.5|\n|---|---|\n|$a\\mu(1 - \\mu) + b$|3.0|\n|$\\text{Coefficient}$|2.5|\n| |2.0|\n| |1.5|\n|$\\mu \\quad \\mu \\quad \\mu$|1.0|\n\nFigure 1: Bias illustration: Consider the sum query $$z1 + z2$$ with 2 inputs. Its DP version produces a point in the blue circle w.h.p. due to the noise $$\\xi \\sim N(0, I)$$ scaled by $$\\sigma$$. When auditing with a random canary c, it contributes additional randomness (red disc) leading to a smaller effective privacy parameter $$\\epsilon$$.\n\nBernstein upper bound on $$\\mu^2$$ such that $$P(\\mu^2 \\leq \\hat{\\mu}^2) \\geq 1 - \\beta$$. On this event,\n\nCombining this with (6) gives us the 2nd-order Bernstein bound on $$\\mu_1$$, valid w.p. $$1 - \\text{Var}(m1) \\leq K1(\\mu_1 - \\hat{\\mu}_2) + (\\hat{\\mu}_2 - \\mu_2) \\leq 2\\beta$$. Since (7)\n\n$$\\mu_2 \\lesssim \\hat{\\mu}_2 + 1/\\sqrt{n}$$ where $$\\hat{\\mu}_2$$ is the empirical estimate of $$\\mu_2$$, the 2nd-order bound scales as\n\n$$\\left|\\mu_1 - \\hat{\\mu}_1\\right| \\lesssim \\frac{1}{\\sqrt{n}}(\\mu_2 - \\hat{\\mu}_2) + n| \\hat{\\mu}_2 - \\mu_2 | + n^{3/4}$$, $$\\sqrt{n}K + \\frac{1}{n^{3/4}}$$ (when (8)\n\n$$\\left|\\hat{\\mu}_2 - \\mu_1\\right| \\approx \\hat{\\mu}_2$$ or as large as $$1/\\sqrt{n}$$ (in the worst-case). With small enough correlations of $$\\left|\\hat{\\mu}_2 - \\mu_1\\right| = O(1/K)$$, this suggests a choice of $$K = O(\\sqrt{n})$$ to get CI of $$1/n^{3/4}$$. In practice, the correlation is controlled by the design of the canary. For the Gaussian mechanism with random canaries, the correlation indeed empirically decays as $$1/K$$, as we see in \u00a74. While the CI decreases monotonically with $$K$$, this incurs a larger bias due to the additional randomness from adding more canaries. The optimal choice of $$K$$ balances the bias and variance; we return to this in \u00a74.\n\nHigher-order intervals. We can recursively apply this method by expanding the variance of higher-order statistics, and derive higher-order Bernstein bounds. The next recursion uses empirical 3rd and 4th moments $$\\hat{\\mu}_3$$ and $$\\hat{\\mu}_4$$ to get the 4th-order Bernstein bound which scales as\n\n$$\\left|\\mu_1 - \\hat{\\mu}_1\\right| \\lesssim \\frac{1}{n^{7/8}}$$ with a choice of $$K = O(n^{3/4})$$ improving upon the 2nd-order CI of $$1/n^{3/4}$$. We can recursively derive even higher-order CIs, but we find \u00a74 that the gains diminish rapidly. In general, the $$\\ell$$th order Bernstein bounds achieve CIs scaling as $$1/n^{(2\\ell-1)/2\\ell}$$ with a choice of $$K = O(n^{(\\ell-1)/\\ell})$$. This shows that the higher-order confidence interval is decreasing in the order $$\\ell$$ of the correlations used; we refer to Appendix C for details.\n\nProposition 4. For any positive integer $$\\ell$$ that is a power of two and $$K = \\lceil n(\\ell-1)/\\ell \\rceil$$, suppose we have $$n$$ samples from a $$K$$-dimensional XBern distribution with parameters $$(\\mu_1, . . . , \\mu_K)$$. If all $$\\ell'$$th-order correlations scale as $$1/K$$, i.e., $$|\\mu_{2\\ell'} - \\mu_{\\ell'}^2| = O(1/K)$$, for all $$\\ell' \\leq \\ell$$ and $$\\ell'$$ is a power of two, then the $$\\ell$$th-order Bernstein bound is $$|\\mu_1 - \\hat{\\mu}_1| = O(1/n^{(2\\ell-1)/(2\\ell)})$$.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Tables", "md": "# Math Equations and Tables"}, {"type": "heading", "lvl": 2, "value": "Computing the Bernstein C.I. by Root-Finding", "md": "## Computing the Bernstein C.I. by Root-Finding"}, {"type": "text", "value": "Leading Coefficient of Wilson vs. Bernstein", "md": "Leading Coefficient of Wilson vs. Bernstein"}, {"type": "table", "rows": [["$\\left", "\\mu - \\hat{\\mu}\\right", "$", "3.5"], ["$a\\mu(1 - \\mu) + b$", "3.0"], ["$\\text{Coefficient}$", "2.5"], ["", "2.0"], ["", "1.5"], ["$\\mu \\quad \\mu \\quad \\mu$", "1.0"]], "md": "|$\\left|\\mu - \\hat{\\mu}\\right|$|3.5|\n|---|---|\n|$a\\mu(1 - \\mu) + b$|3.0|\n|$\\text{Coefficient}$|2.5|\n| |2.0|\n| |1.5|\n|$\\mu \\quad \\mu \\quad \\mu$|1.0|", "isPerfectTable": false, "csv": "\"$\\left\",\"\\mu - \\hat{\\mu}\\right\",\"$\",\"3.5\"\n\"$a\\mu(1 - \\mu) + b$\",\"3.0\"\n\"$\\text{Coefficient}$\",\"2.5\"\n\"\",\"2.0\"\n\"\",\"1.5\"\n\"$\\mu \\quad \\mu \\quad \\mu$\",\"1.0\""}, {"type": "text", "value": "Figure 1: Bias illustration: Consider the sum query $$z1 + z2$$ with 2 inputs. Its DP version produces a point in the blue circle w.h.p. due to the noise $$\\xi \\sim N(0, I)$$ scaled by $$\\sigma$$. When auditing with a random canary c, it contributes additional randomness (red disc) leading to a smaller effective privacy parameter $$\\epsilon$$.\n\nBernstein upper bound on $$\\mu^2$$ such that $$P(\\mu^2 \\leq \\hat{\\mu}^2) \\geq 1 - \\beta$$. On this event,\n\nCombining this with (6) gives us the 2nd-order Bernstein bound on $$\\mu_1$$, valid w.p. $$1 - \\text{Var}(m1) \\leq K1(\\mu_1 - \\hat{\\mu}_2) + (\\hat{\\mu}_2 - \\mu_2) \\leq 2\\beta$$. Since (7)\n\n$$\\mu_2 \\lesssim \\hat{\\mu}_2 + 1/\\sqrt{n}$$ where $$\\hat{\\mu}_2$$ is the empirical estimate of $$\\mu_2$$, the 2nd-order bound scales as\n\n$$\\left|\\mu_1 - \\hat{\\mu}_1\\right| \\lesssim \\frac{1}{\\sqrt{n}}(\\mu_2 - \\hat{\\mu}_2) + n| \\hat{\\mu}_2 - \\mu_2 | + n^{3/4}$$, $$\\sqrt{n}K + \\frac{1}{n^{3/4}}$$ (when (8)\n\n$$\\left|\\hat{\\mu}_2 - \\mu_1\\right| \\approx \\hat{\\mu}_2$$ or as large as $$1/\\sqrt{n}$$ (in the worst-case). With small enough correlations of $$\\left|\\hat{\\mu}_2 - \\mu_1\\right| = O(1/K)$$, this suggests a choice of $$K = O(\\sqrt{n})$$ to get CI of $$1/n^{3/4}$$. In practice, the correlation is controlled by the design of the canary. For the Gaussian mechanism with random canaries, the correlation indeed empirically decays as $$1/K$$, as we see in \u00a74. While the CI decreases monotonically with $$K$$, this incurs a larger bias due to the additional randomness from adding more canaries. The optimal choice of $$K$$ balances the bias and variance; we return to this in \u00a74.\n\nHigher-order intervals. We can recursively apply this method by expanding the variance of higher-order statistics, and derive higher-order Bernstein bounds. The next recursion uses empirical 3rd and 4th moments $$\\hat{\\mu}_3$$ and $$\\hat{\\mu}_4$$ to get the 4th-order Bernstein bound which scales as\n\n$$\\left|\\mu_1 - \\hat{\\mu}_1\\right| \\lesssim \\frac{1}{n^{7/8}}$$ with a choice of $$K = O(n^{3/4})$$ improving upon the 2nd-order CI of $$1/n^{3/4}$$. We can recursively derive even higher-order CIs, but we find \u00a74 that the gains diminish rapidly. In general, the $$\\ell$$th order Bernstein bounds achieve CIs scaling as $$1/n^{(2\\ell-1)/2\\ell}$$ with a choice of $$K = O(n^{(\\ell-1)/\\ell})$$. This shows that the higher-order confidence interval is decreasing in the order $$\\ell$$ of the correlations used; we refer to Appendix C for details.\n\nProposition 4. For any positive integer $$\\ell$$ that is a power of two and $$K = \\lceil n(\\ell-1)/\\ell \\rceil$$, suppose we have $$n$$ samples from a $$K$$-dimensional XBern distribution with parameters $$(\\mu_1, . . . , \\mu_K)$$. If all $$\\ell'$$th-order correlations scale as $$1/K$$, i.e., $$|\\mu_{2\\ell'} - \\mu_{\\ell'}^2| = O(1/K)$$, for all $$\\ell' \\leq \\ell$$ and $$\\ell'$$ is a power of two, then the $$\\ell$$th-order Bernstein bound is $$|\\mu_1 - \\hat{\\mu}_1| = O(1/n^{(2\\ell-1)/(2\\ell)})$$.", "md": "Figure 1: Bias illustration: Consider the sum query $$z1 + z2$$ with 2 inputs. Its DP version produces a point in the blue circle w.h.p. due to the noise $$\\xi \\sim N(0, I)$$ scaled by $$\\sigma$$. When auditing with a random canary c, it contributes additional randomness (red disc) leading to a smaller effective privacy parameter $$\\epsilon$$.\n\nBernstein upper bound on $$\\mu^2$$ such that $$P(\\mu^2 \\leq \\hat{\\mu}^2) \\geq 1 - \\beta$$. On this event,\n\nCombining this with (6) gives us the 2nd-order Bernstein bound on $$\\mu_1$$, valid w.p. $$1 - \\text{Var}(m1) \\leq K1(\\mu_1 - \\hat{\\mu}_2) + (\\hat{\\mu}_2 - \\mu_2) \\leq 2\\beta$$. Since (7)\n\n$$\\mu_2 \\lesssim \\hat{\\mu}_2 + 1/\\sqrt{n}$$ where $$\\hat{\\mu}_2$$ is the empirical estimate of $$\\mu_2$$, the 2nd-order bound scales as\n\n$$\\left|\\mu_1 - \\hat{\\mu}_1\\right| \\lesssim \\frac{1}{\\sqrt{n}}(\\mu_2 - \\hat{\\mu}_2) + n| \\hat{\\mu}_2 - \\mu_2 | + n^{3/4}$$, $$\\sqrt{n}K + \\frac{1}{n^{3/4}}$$ (when (8)\n\n$$\\left|\\hat{\\mu}_2 - \\mu_1\\right| \\approx \\hat{\\mu}_2$$ or as large as $$1/\\sqrt{n}$$ (in the worst-case). With small enough correlations of $$\\left|\\hat{\\mu}_2 - \\mu_1\\right| = O(1/K)$$, this suggests a choice of $$K = O(\\sqrt{n})$$ to get CI of $$1/n^{3/4}$$. In practice, the correlation is controlled by the design of the canary. For the Gaussian mechanism with random canaries, the correlation indeed empirically decays as $$1/K$$, as we see in \u00a74. While the CI decreases monotonically with $$K$$, this incurs a larger bias due to the additional randomness from adding more canaries. The optimal choice of $$K$$ balances the bias and variance; we return to this in \u00a74.\n\nHigher-order intervals. We can recursively apply this method by expanding the variance of higher-order statistics, and derive higher-order Bernstein bounds. The next recursion uses empirical 3rd and 4th moments $$\\hat{\\mu}_3$$ and $$\\hat{\\mu}_4$$ to get the 4th-order Bernstein bound which scales as\n\n$$\\left|\\mu_1 - \\hat{\\mu}_1\\right| \\lesssim \\frac{1}{n^{7/8}}$$ with a choice of $$K = O(n^{3/4})$$ improving upon the 2nd-order CI of $$1/n^{3/4}$$. We can recursively derive even higher-order CIs, but we find \u00a74 that the gains diminish rapidly. In general, the $$\\ell$$th order Bernstein bounds achieve CIs scaling as $$1/n^{(2\\ell-1)/2\\ell}$$ with a choice of $$K = O(n^{(\\ell-1)/\\ell})$$. This shows that the higher-order confidence interval is decreasing in the order $$\\ell$$ of the correlations used; we refer to Appendix C for details.\n\nProposition 4. For any positive integer $$\\ell$$ that is a power of two and $$K = \\lceil n(\\ell-1)/\\ell \\rceil$$, suppose we have $$n$$ samples from a $$K$$-dimensional XBern distribution with parameters $$(\\mu_1, . . . , \\mu_K)$$. If all $$\\ell'$$th-order correlations scale as $$1/K$$, i.e., $$|\\mu_{2\\ell'} - \\mu_{\\ell'}^2| = O(1/K)$$, for all $$\\ell' \\leq \\ell$$ and $$\\ell'$$ is a power of two, then the $$\\ell$$th-order Bernstein bound is $$|\\mu_1 - \\hat{\\mu}_1| = O(1/n^{(2\\ell-1)/(2\\ell)})$$."}]}, {"page": 8, "text": "                      \u03b5 = 2.0, K = \u221an, d = 105                                                        \u03b5 = 4.0, n = 4096, d = 104                                       1.7           \u03b5 = 4.0, n = 4096, K = \u221an\n     Empirical lower bound \u02c6                                                       Empirical lower bound \u02c6                                                           Empirical lower bound \u02c6\n     \u03b50.8                                                                          \u03b5 1.70                                                                            \u03b5\n                                                                                     1.65                                                                              1.6\n      0.6                                                                            1.60                                                                              1.5\n      0.4                                                                            1.55                                                                              1.4\n                                                                                     1.50                                                                              1.3\n      0.2            29            211 4\u00d7 gain     213   16\u00d7 gain 215                1.45          21          23           25          27          29                 1.2   102            103            104            105            106\n                              Number of trials n                                                           Number of canaries K                                                                    Dimension d\n                                 DP + Wilson                          LiDP + 1st-Order Wilson                               LiDP + 2nd-Order Wilson                                LiDP + 4th-Order Wilson\nFigure 3: Left: For Gaussian mechanisms, the proposed LiDP-based auditing with K canaries provides significant\ngain in the require number of trials to achieve a desired level of lower bound \u02c6                                                                            \u03b5 on the privacy. Center: Increasing the\nnumber of canaries trades off the bias and the variance, with our prescribed K = \u221an achieving a good performance.\nRight: Increasing the dimension makes the canaries less correlated, thus achieving smaller confidence intervals, and\nlarger \u02c6      \u03b5. The shaded area denotes the standard error over 25 repetitions.\n4            Simulations: Auditing the Gaussian Mechanism\nSetup. We consider a simple sum query q(D) =  z\u2208D z over the unit sphere Z = {z \u2208                                                                                                                  Rd : \u2225z\u22252 = 1}. We\nwant to audit a Gaussian mechanism that returns q(D) + \u03c3\u03be with standard Gaussian \u03be \u223c                                                                                                                          N    (0, Id) and \u03c3\ncalibrated to ensure (\u03b5, \u03b4)-DP. We assume black-box access, where we do not know what mechanism we are\nauditing and we only access it through samples of the outcomes. A white-box audit is discussed in \u00a7A.1. We\napply our new recipe with canaries sampled uniformly at random from Z. Following standard methods [e.g.\n22], we declare that a canary ck is present if c\u22a4                                                       k A(D) > \u03c4 for a threshold \u03c4 learned from separate samples.\nFor more details and additional results, see Appendix E. A broad range of values of K (between 32 and 256 in\nFigure 3 middle) leads to good performance in auditing LiDP. We use K = \u221an (as suggested by our analysis\nin (8)) and the 2nd-order Wilson estimator (as gains diminish rapidly afterward) as a reliable default.\nSample Complexity Gains. In Figure 3 (left), the proposed approach of injecting K canaries with the\n2nd order Wilson interval (denoted \u201cLiDP +2nd-Order Wilson\u201d) reduces the number of trials, n, needed to\nreach the same empirical lower bound, \u02c6                                               \u03b5, by 4\u00d7 to 16\u00d7, compared to the baseline of injecting a single canary\n(denoted \u201cDP+Wilson\u201d). We achieve \u02c6                                                   \u03b5n = 0.85 with n = 4096 (while the baseline requires n = 65536) and\n \u02c6\n\u03b5n = 0.67 with n = 1024 (while the baseline requires n = 4096).\nNumber of Canaries and Bias-Variance Tradeoffs. In Fig. 3 (middle), LiDP auditing with 2nd/4th-order\nCIs improve with increasing canaries up to a point and then decreases. This is due to a bias-variance tradeoff,\nwhich we investigate further in Figure 4 (left). Let \u02c6                                                            \u03b5(K, \u2113) denote the empirical privacy lower bound with K\ncanaries using an \u2113th order interval, e.g., the baseline is \u02c6                                                                 \u03b5(1, 1). Let the bias from injecting K canaries and\nthe variance gain from \u2113th-order interval respectively be\n                                        \u2206Bias(K) := \u02c6                  \u03b5(K, 1) \u2212             \u02c6\n                                                                                            \u03b5(1, 1) ,             and           \u2206Var(K, \u2113) := \u02c6                  \u03b5(K, \u2113) \u2212            \u02c6\n                                                                                                                                                                                      \u03b5(K, 1) .                                        (10)\nIn Figure 4 (left), the gain \u2206Bias(K) from bias is negative and gets worse with increasing K; when testing\nfor each canary, the K \u2212                                 1 other canaries introduce more randomness that makes the test more private and\nhence lowers the \u02c6                     \u03b5. The gain \u2206Var(K) in variance is positive and increases with K before saturating. This\nimproved \u201cvariance\u201d of the estimate is a key benefit of our framework. The net improvement \u02c6                                                                                                                  \u03b5(K, \u2113) \u2212            \u02c6\n                                                                                                                                                                                                                                   \u03b5(1, 1)\nis a sum of these two effects. This trade-off between bias and variance explains the concave shape of \u02c6                                                                                                                         \u03b5 in K.\nCorrelation between Canaries. Based on (8), this improvement in the variance can further be examined\nby looking at the term |                              \u02c6\n                                                     \u00b52 \u2212         \u02c6\n                                                                 \u00b52  1| that leads to a narrower 2nd-order Wilson interval. The log-log plot of this\n                                                                                                                       8", "md": "$$\n\\epsilon = 2.0, K = \\sqrt{n}, d = 105 \\quad \\epsilon = 4.0, n = 4096, d = 104 \\quad 1.7 \\quad \\epsilon = 4.0, n = 4096, K = \\sqrt{n}\n$$\n\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|---|---|---|\n|\u03b50.8|\u03b5 1.70|\u03b5|\n|0.6|1.60|1.5|\n|0.4|1.55|1.4|\n| |1.50|1.3|\n|0.2|29|211 4\u00d7 gain|213 16\u00d7 gain|215|1.45|21|23|25|27|29|1.2|102|103|104|105|106|\n|Number of trials n|Number of canaries K|Dimension d|\n|DP + Wilson|LiDP + 1st-Order Wilson|LiDP + 2nd-Order Wilson|LiDP + 4th-Order Wilson|\n\nFigure 3: Left: For Gaussian mechanisms, the proposed LiDP-based auditing with K canaries provides significant gain in the require number of trials to achieve a desired level of lower bound \u02c6 \u03b5 on the privacy. Center: Increasing the number of canaries trades off the bias and the variance, with our prescribed K = \u221an achieving a good performance. Right: Increasing the dimension makes the canaries less correlated, thus achieving smaller confidence intervals, and larger \u02c6 \u03b5. The shaded area denotes the standard error over 25 repetitions.\n\n$$\n4 \\quad \\text{Simulations: Auditing the Gaussian Mechanism}\n$$\n\nSetup. We consider a simple sum query $$q(D) = \\sum_{z \\in D} z$$ over the unit sphere $$Z = \\{z \\in \\mathbb{R}^d : \\|z\\|_2 = 1\\}$$. We want to audit a Gaussian mechanism that returns $$q(D) + \\sigma \\xi$$ with standard Gaussian $$\\xi \\sim \\mathcal{N}(0, I_d)$$ and $$\\sigma$$ calibrated to ensure $$(\\epsilon, \\delta)$$-DP. We assume black-box access, where we do not know what mechanism we are auditing and we only access it through samples of the outcomes. A white-box audit is discussed in \u00a7A.1. We apply our new recipe with canaries sampled uniformly at random from $$Z$$. Following standard methods [e.g. 22], we declare that a canary $$c_k$$ is present if $$c_k^\\top A(D) > \\tau$$ for a threshold $$\\tau$$ learned from separate samples. For more details and additional results, see Appendix E. A broad range of values of $$K$$ (between 32 and 256 in Figure 3 middle) leads to good performance in auditing LiDP. We use $$K = \\sqrt{n}$$ (as suggested by our analysis in (8)) and the 2nd-order Wilson estimator (as gains diminish rapidly afterward) as a reliable default.\n\nSample Complexity Gains. In Figure 3 (left), the proposed approach of injecting $$K$$ canaries with the 2nd order Wilson interval (denoted \u201cLiDP + 2nd-Order Wilson\u201d) reduces the number of trials, $$n$$, needed to reach the same empirical lower bound, $$\\hat{\\epsilon}$$, by 4\u00d7 to 16\u00d7, compared to the baseline of injecting a single canary (denoted \u201cDP+Wilson\u201d). We achieve $$\\hat{\\epsilon} n = 0.85$$ with $$n = 4096$$ (while the baseline requires $$n = 65536$$) and $$\\hat{\\epsilon} n = 0.67$$ with $$n = 1024$$ (while the baseline requires $$n = 4096$$).\n\nNumber of Canaries and Bias-Variance Tradeoffs. In Fig. 3 (middle), LiDP auditing with 2nd/4th-order CIs improve with increasing canaries up to a point and then decreases. This is due to a bias-variance tradeoff, which we investigate further in Figure 4 (left). Let $$\\hat{\\epsilon}(K, \\ell)$$ denote the empirical privacy lower bound with $$K$$ canaries using an $$\\ell$$th order interval, e.g., the baseline is $$\\hat{\\epsilon}(1, 1)$$. Let the bias from injecting $$K$$ canaries and the variance gain from $$\\ell$$th-order interval respectively be\n\n$$\n\\Delta \\text{Bias}(K) := \\hat{\\epsilon}(K, 1) - \\hat{\\epsilon}(1, 1) \\quad \\text{and} \\quad \\Delta \\text{Var}(K, \\ell) := \\hat{\\epsilon}(K, \\ell) - \\hat{\\epsilon}(K, 1)\n$$\n\nIn Figure 4 (left), the gain $$\\Delta \\text{Bias}(K)$$ from bias is negative and gets worse with increasing $$K$$; when testing for each canary, the $$K - 1$$ other canaries introduce more randomness that makes the test more private and hence lowers the $$\\hat{\\epsilon}$$. The gain $$\\Delta \\text{Var}(K)$$ in variance is positive and increases with $$K$$ before saturating. This improved \u201cvariance\u201d of the estimate is a key benefit of our framework. The net improvement $$\\hat{\\epsilon}(K, \\ell) - \\hat{\\epsilon}(1, 1)$$ is a sum of these two effects. This trade-off between bias and variance explains the concave shape of $$\\hat{\\epsilon}$$ in $$K$$.\n\nCorrelation between Canaries. Based on (8), this improvement in the variance can further be examined by looking at the term $$|\\hat{\\mu}_2 - \\hat{\\mu}_2^1|$$ that leads to a narrower 2nd-order Wilson interval. The log-log plot of this", "images": [], "items": [{"type": "text", "value": "$$\n\\epsilon = 2.0, K = \\sqrt{n}, d = 105 \\quad \\epsilon = 4.0, n = 4096, d = 104 \\quad 1.7 \\quad \\epsilon = 4.0, n = 4096, K = \\sqrt{n}\n$$", "md": "$$\n\\epsilon = 2.0, K = \\sqrt{n}, d = 105 \\quad \\epsilon = 4.0, n = 4096, d = 104 \\quad 1.7 \\quad \\epsilon = 4.0, n = 4096, K = \\sqrt{n}\n$$"}, {"type": "table", "rows": [["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6"], ["\u03b50.8", "\u03b5 1.70", "\u03b5"], ["0.6", "1.60", "1.5"], ["0.4", "1.55", "1.4"], ["", "1.50", "1.3"], ["0.2", "29", "211 4\u00d7 gain", "213 16\u00d7 gain", "215", "1.45", "21", "23", "25", "27", "29", "1.2", "102", "103", "104", "105", "106"], ["Number of trials n", "Number of canaries K", "Dimension d"], ["DP + Wilson", "LiDP + 1st-Order Wilson", "LiDP + 2nd-Order Wilson", "LiDP + 4th-Order Wilson"]], "md": "|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|---|---|---|\n|\u03b50.8|\u03b5 1.70|\u03b5|\n|0.6|1.60|1.5|\n|0.4|1.55|1.4|\n| |1.50|1.3|\n|0.2|29|211 4\u00d7 gain|213 16\u00d7 gain|215|1.45|21|23|25|27|29|1.2|102|103|104|105|106|\n|Number of trials n|Number of canaries K|Dimension d|\n|DP + Wilson|LiDP + 1st-Order Wilson|LiDP + 2nd-Order Wilson|LiDP + 4th-Order Wilson|", "isPerfectTable": false, "csv": "\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\"\n\"\u03b50.8\",\"\u03b5 1.70\",\"\u03b5\"\n\"0.6\",\"1.60\",\"1.5\"\n\"0.4\",\"1.55\",\"1.4\"\n\"\",\"1.50\",\"1.3\"\n\"0.2\",\"29\",\"211 4\u00d7 gain\",\"213 16\u00d7 gain\",\"215\",\"1.45\",\"21\",\"23\",\"25\",\"27\",\"29\",\"1.2\",\"102\",\"103\",\"104\",\"105\",\"106\"\n\"Number of trials n\",\"Number of canaries K\",\"Dimension d\"\n\"DP + Wilson\",\"LiDP + 1st-Order Wilson\",\"LiDP + 2nd-Order Wilson\",\"LiDP + 4th-Order Wilson\""}, {"type": "text", "value": "Figure 3: Left: For Gaussian mechanisms, the proposed LiDP-based auditing with K canaries provides significant gain in the require number of trials to achieve a desired level of lower bound \u02c6 \u03b5 on the privacy. Center: Increasing the number of canaries trades off the bias and the variance, with our prescribed K = \u221an achieving a good performance. Right: Increasing the dimension makes the canaries less correlated, thus achieving smaller confidence intervals, and larger \u02c6 \u03b5. The shaded area denotes the standard error over 25 repetitions.\n\n$$\n4 \\quad \\text{Simulations: Auditing the Gaussian Mechanism}\n$$\n\nSetup. We consider a simple sum query $$q(D) = \\sum_{z \\in D} z$$ over the unit sphere $$Z = \\{z \\in \\mathbb{R}^d : \\|z\\|_2 = 1\\}$$. We want to audit a Gaussian mechanism that returns $$q(D) + \\sigma \\xi$$ with standard Gaussian $$\\xi \\sim \\mathcal{N}(0, I_d)$$ and $$\\sigma$$ calibrated to ensure $$(\\epsilon, \\delta)$$-DP. We assume black-box access, where we do not know what mechanism we are auditing and we only access it through samples of the outcomes. A white-box audit is discussed in \u00a7A.1. We apply our new recipe with canaries sampled uniformly at random from $$Z$$. Following standard methods [e.g. 22], we declare that a canary $$c_k$$ is present if $$c_k^\\top A(D) > \\tau$$ for a threshold $$\\tau$$ learned from separate samples. For more details and additional results, see Appendix E. A broad range of values of $$K$$ (between 32 and 256 in Figure 3 middle) leads to good performance in auditing LiDP. We use $$K = \\sqrt{n}$$ (as suggested by our analysis in (8)) and the 2nd-order Wilson estimator (as gains diminish rapidly afterward) as a reliable default.\n\nSample Complexity Gains. In Figure 3 (left), the proposed approach of injecting $$K$$ canaries with the 2nd order Wilson interval (denoted \u201cLiDP + 2nd-Order Wilson\u201d) reduces the number of trials, $$n$$, needed to reach the same empirical lower bound, $$\\hat{\\epsilon}$$, by 4\u00d7 to 16\u00d7, compared to the baseline of injecting a single canary (denoted \u201cDP+Wilson\u201d). We achieve $$\\hat{\\epsilon} n = 0.85$$ with $$n = 4096$$ (while the baseline requires $$n = 65536$$) and $$\\hat{\\epsilon} n = 0.67$$ with $$n = 1024$$ (while the baseline requires $$n = 4096$$).\n\nNumber of Canaries and Bias-Variance Tradeoffs. In Fig. 3 (middle), LiDP auditing with 2nd/4th-order CIs improve with increasing canaries up to a point and then decreases. This is due to a bias-variance tradeoff, which we investigate further in Figure 4 (left). Let $$\\hat{\\epsilon}(K, \\ell)$$ denote the empirical privacy lower bound with $$K$$ canaries using an $$\\ell$$th order interval, e.g., the baseline is $$\\hat{\\epsilon}(1, 1)$$. Let the bias from injecting $$K$$ canaries and the variance gain from $$\\ell$$th-order interval respectively be\n\n$$\n\\Delta \\text{Bias}(K) := \\hat{\\epsilon}(K, 1) - \\hat{\\epsilon}(1, 1) \\quad \\text{and} \\quad \\Delta \\text{Var}(K, \\ell) := \\hat{\\epsilon}(K, \\ell) - \\hat{\\epsilon}(K, 1)\n$$\n\nIn Figure 4 (left), the gain $$\\Delta \\text{Bias}(K)$$ from bias is negative and gets worse with increasing $$K$$; when testing for each canary, the $$K - 1$$ other canaries introduce more randomness that makes the test more private and hence lowers the $$\\hat{\\epsilon}$$. The gain $$\\Delta \\text{Var}(K)$$ in variance is positive and increases with $$K$$ before saturating. This improved \u201cvariance\u201d of the estimate is a key benefit of our framework. The net improvement $$\\hat{\\epsilon}(K, \\ell) - \\hat{\\epsilon}(1, 1)$$ is a sum of these two effects. This trade-off between bias and variance explains the concave shape of $$\\hat{\\epsilon}$$ in $$K$$.\n\nCorrelation between Canaries. Based on (8), this improvement in the variance can further be examined by looking at the term $$|\\hat{\\mu}_2 - \\hat{\\mu}_2^1|$$ that leads to a narrower 2nd-order Wilson interval. The log-log plot of this", "md": "Figure 3: Left: For Gaussian mechanisms, the proposed LiDP-based auditing with K canaries provides significant gain in the require number of trials to achieve a desired level of lower bound \u02c6 \u03b5 on the privacy. Center: Increasing the number of canaries trades off the bias and the variance, with our prescribed K = \u221an achieving a good performance. Right: Increasing the dimension makes the canaries less correlated, thus achieving smaller confidence intervals, and larger \u02c6 \u03b5. The shaded area denotes the standard error over 25 repetitions.\n\n$$\n4 \\quad \\text{Simulations: Auditing the Gaussian Mechanism}\n$$\n\nSetup. We consider a simple sum query $$q(D) = \\sum_{z \\in D} z$$ over the unit sphere $$Z = \\{z \\in \\mathbb{R}^d : \\|z\\|_2 = 1\\}$$. We want to audit a Gaussian mechanism that returns $$q(D) + \\sigma \\xi$$ with standard Gaussian $$\\xi \\sim \\mathcal{N}(0, I_d)$$ and $$\\sigma$$ calibrated to ensure $$(\\epsilon, \\delta)$$-DP. We assume black-box access, where we do not know what mechanism we are auditing and we only access it through samples of the outcomes. A white-box audit is discussed in \u00a7A.1. We apply our new recipe with canaries sampled uniformly at random from $$Z$$. Following standard methods [e.g. 22], we declare that a canary $$c_k$$ is present if $$c_k^\\top A(D) > \\tau$$ for a threshold $$\\tau$$ learned from separate samples. For more details and additional results, see Appendix E. A broad range of values of $$K$$ (between 32 and 256 in Figure 3 middle) leads to good performance in auditing LiDP. We use $$K = \\sqrt{n}$$ (as suggested by our analysis in (8)) and the 2nd-order Wilson estimator (as gains diminish rapidly afterward) as a reliable default.\n\nSample Complexity Gains. In Figure 3 (left), the proposed approach of injecting $$K$$ canaries with the 2nd order Wilson interval (denoted \u201cLiDP + 2nd-Order Wilson\u201d) reduces the number of trials, $$n$$, needed to reach the same empirical lower bound, $$\\hat{\\epsilon}$$, by 4\u00d7 to 16\u00d7, compared to the baseline of injecting a single canary (denoted \u201cDP+Wilson\u201d). We achieve $$\\hat{\\epsilon} n = 0.85$$ with $$n = 4096$$ (while the baseline requires $$n = 65536$$) and $$\\hat{\\epsilon} n = 0.67$$ with $$n = 1024$$ (while the baseline requires $$n = 4096$$).\n\nNumber of Canaries and Bias-Variance Tradeoffs. In Fig. 3 (middle), LiDP auditing with 2nd/4th-order CIs improve with increasing canaries up to a point and then decreases. This is due to a bias-variance tradeoff, which we investigate further in Figure 4 (left). Let $$\\hat{\\epsilon}(K, \\ell)$$ denote the empirical privacy lower bound with $$K$$ canaries using an $$\\ell$$th order interval, e.g., the baseline is $$\\hat{\\epsilon}(1, 1)$$. Let the bias from injecting $$K$$ canaries and the variance gain from $$\\ell$$th-order interval respectively be\n\n$$\n\\Delta \\text{Bias}(K) := \\hat{\\epsilon}(K, 1) - \\hat{\\epsilon}(1, 1) \\quad \\text{and} \\quad \\Delta \\text{Var}(K, \\ell) := \\hat{\\epsilon}(K, \\ell) - \\hat{\\epsilon}(K, 1)\n$$\n\nIn Figure 4 (left), the gain $$\\Delta \\text{Bias}(K)$$ from bias is negative and gets worse with increasing $$K$$; when testing for each canary, the $$K - 1$$ other canaries introduce more randomness that makes the test more private and hence lowers the $$\\hat{\\epsilon}$$. The gain $$\\Delta \\text{Var}(K)$$ in variance is positive and increases with $$K$$ before saturating. This improved \u201cvariance\u201d of the estimate is a key benefit of our framework. The net improvement $$\\hat{\\epsilon}(K, \\ell) - \\hat{\\epsilon}(1, 1)$$ is a sum of these two effects. This trade-off between bias and variance explains the concave shape of $$\\hat{\\epsilon}$$ in $$K$$.\n\nCorrelation between Canaries. Based on (8), this improvement in the variance can further be examined by looking at the term $$|\\hat{\\mu}_2 - \\hat{\\mu}_2^1|$$ that leads to a narrower 2nd-order Wilson interval. The log-log plot of this"}]}, {"page": 9, "text": "                      \u03b5 = 4.0, n = 4096, d = 104                                                     \u03b5 = 2.0, n = 4096, d = 105                                                   \u03b5 = 1.0, n = 65536, K = \u221an\n    Difference of empirical \u02c6\n    \u03b5   0.20                                                                         Correlation Measure                                                              10\u22124\n                                                                                       10\u22123                                                                         Moment statistics\n        0.15                                                                           10\u22124                                                                           10\u22125\n        0.10\n        0.05                                                                           10\u22125                                                                           10\u22126\n        0.00                                                                           10\u22126                                                                           10\u22127\n      \u22120.05                                                                            10\u22127                                                                           10\u22128\n      \u22120.10          21         23         25         27         29                    10\u22128          22          24          26          28          210                     102           103          104   105         106\n                           Number of canaries K                                                           Number of canaries K                                                                  Dimension d\n                                                                                                        1/K                                | \u02c6\n                                                                                                                                            \u00b52       \u00b54|                               1/d                        | \u02c6\n                                                                                                                                                                                                                   \u00b52     \u00b54|\n                         K = \u221an                             Var. Gain                                   | \u02c6                                    2 \u2212    \u02c6                                                              2 \u2212  \u02c6\n                                                                                                         \u00b52       \u00b52|                                                                  | \u02c6\n                         Bias Gain                          Net Gain                                                                                                                    \u00b52       \u00b52|\n                                                                                                            1 \u2212    \u02c6                                                                      1 \u2212    \u02c6\nFigure 4: Left: Separating the effects of bias and variance in auditing LiDP; cf. definition (10). Center & Right:\nThe correlations between the test statistics of the canaries decrease with K and d, achieving smaller CIs.\nterm in Figure 4 (middle) is nearly parallel to the dotted 1/K line (slope = \u22120.93), meaning that it decays                    \u221a\nroughly as 1/K.1 This indicates that we get close to a 1/                                                                          nK confidence interval as desired. Similarly, we\nget that |            \u02c6\n                     \u00b54 \u2212         \u02c6\n                                  \u00b52 2| decays roughly as 1/K (slope = \u22121.05). However, the 4th-order estimator offers only\nmarginal additional improvements in the small \u03b5 regime (see Appendix E). Thus, the gain diminishes rapidly\nin the order of our estimators.\nEffect of Dimension on the Bias and Variance. As the dimension d increases, the LiDP-based lower\nbound becomes tighter monotonically as we show in Figure 3 (right). This is due to both the bias gain, as\nin (10), improving (less negative) and the variance gain improving (more positive). With increasing d, the\nvariance of our estimate reduces because the canaries become less correlated. Guided by Eq. (8,9), we measure\nthe relevant correlation measures |                                           \u02c6\n                                                                             \u00b52 \u2212         \u02c6\n                                                                                         \u00b52                  \u00b54 \u2212         \u02c6\n                                                                                             1| and |         \u02c6          \u00b52  2| in Figure 4 (right). Both decay approximate as\n1/d (slope = \u22121.06 and \u22121.00 respectively, ignoring the outlier at d = 106). This suggests that, for Gaussian\nmechanisms, the corresponding XBern distribution resulting from our recipe behaves favorably as d increases.\n5           Lifting Existing Canary Designs\nSeveral prior works [e.g., 31, 40, 44, 59], focus on designing stronger canaries to improve the lower bound on\n\u03b5. We provide two concrete examples of how to lift these canary designs to be compatible with our framework\nwhile inheriting their strengths. We refer to Appendix D for further details.\n       We impose two criteria on the distribution Pcanary over canaries for auditing LiDP. First, the injected\ncanaries are easy to detect, so that the probabilities on the left side of (4) are large and those on the right\nside are small. Second, a canary c \u223c                                               Pcanary, if included in the training of a model \u03b8, is unlikely to change\nthe membership of \u03b8 \u2208                              Rc\u2032 for an independent canary c\u2032 \u223c                                              Pcanary. Existing canary designs already impose\nthe first condition to audit DP using (1). The second condition ensures that the canaries are uncorrelated,\nallowing our adaptive CIs to be smaller, as we discussed in \u00a73.3.\nData Poisoning via Tail Singular Vectors. ClipBKD [31] adds as canaries the tail singular vector of the\ninput data (e.g., images). This ensures that the canary is out of distribution, allowing for easy detection. We\nlift ClipBKD by defining the distribution Pcanary as the uniform distribution over the p tail singular vectors\nof the input data. If p is small relative to the dimension d of the data, then they are still out of distribution,\nand hence, easy to detect. For the second condition, the orthogonality of the singular vectors ensures the\ninteraction between canaries is minimal, as measured empirically.\n      1The plot of y = cxa in log-log scale is a straight line with slope a and intercept log c.\n                                                                                                                     9", "md": "# Math Equations and Table\n\n$$\u03b5 = 4.0, n = 4096, d = 104 \\quad \u03b5 = 2.0, n = 4096, d = 105 \\quad \u03b5 = 1.0, n = 65536, K = \\sqrt{n}$$\n\n|Difference of empirical \u02c6 \u03b5|Correlation Measure|Moment statistics|\n|---|---|---|\n|0.20|10-4|10-4|\n|0.15|10-3|10-5|\n|0.10| |10-6|\n|0.05| |10-7|\n|0.00| |10-8|\n|-0.05| | |\n|-0.10| | |\n\nFigure 4: Left: Separating the effects of bias and variance in auditing LiDP; cf. definition (10). Center & Right:\nThe correlations between the test statistics of the canaries decrease with K and d, achieving smaller CIs.\nterm in Figure 4 (middle) is nearly parallel to the dotted 1/K line (slope = -0.93), meaning that it decays roughly as 1/K.\nThis indicates that we get close to a 1/\u221anK confidence interval as desired. Similarly, we get that $$|\\hat{\\mu}_4 - \\hat{\\mu}_2^2|$$\ndecays roughly as 1/K (slope = -1.05). However, the 4th-order estimator offers only marginal additional improvements in the small \u03b5 regime (see Appendix E).\nThus, the gain diminishes rapidly in the order of our estimators.\n\nEffect of Dimension on the Bias and Variance. As the dimension d increases, the LiDP-based lower bound becomes tighter monotonically as we show in Figure 3 (right).\nThis is due to both the bias gain, as in (10), improving (less negative) and the variance gain improving (more positive). With increasing d, the variance of our estimate reduces\nbecause the canaries become less correlated. Guided by Eq. (8,9), we measure the relevant correlation measures $$|\\hat{\\mu}_2 - \\hat{\\mu}_2|$$ and $$|\\hat{\\mu}_4 - \\hat{\\mu}_2^2|$$\nin Figure 4 (right). Both decay approximate as 1/d (slope = -1.06 and -1.00 respectively, ignoring the outlier at d = 106). This suggests that, for Gaussian mechanisms,\nthe corresponding XBern distribution resulting from our recipe behaves favorably as d increases.\n\nLifting Existing Canary Designs\nSeveral prior works [e.g., 31, 40, 44, 59], focus on designing stronger canaries to improve the lower bound on \u03b5. We provide two concrete examples of how to lift these canary designs\nto be compatible with our framework while inheriting their strengths. We refer to Appendix D for further details.\n\nWe impose two criteria on the distribution Pcanary over canaries for auditing LiDP. First, the injected canaries are easy to detect, so that the probabilities on the left side of (4) are large\nand those on the right side are small. Second, a canary $$c \\sim P_{canary}$$, if included in the training of a model $$\\theta$$, is unlikely to change the membership of $$\\theta \\in R_{c'}$$\nfor an independent canary $$c' \\sim P_{canary}$$. Existing canary designs already impose the first condition to audit DP using (1). The second condition ensures that the canaries are uncorrelated,\nallowing our adaptive CIs to be smaller, as we discussed in \u00a73.3.\n\nData Poisoning via Tail Singular Vectors. ClipBKD [31] adds as canaries the tail singular vector of the input data (e.g., images). This ensures that the canary is out of distribution,\nallowing for easy detection. We lift ClipBKD by defining the distribution $$P_{canary}$$ as the uniform distribution over the p tail singular vectors of the input data. If p is small relative\nto the dimension d of the data, then they are still out of distribution, and hence, easy to detect. For the second condition, the orthogonality of the singular vectors ensures the interaction\nbetween canaries is minimal, as measured empirically.\n\n1The plot of $$y = cx^a$$ in log-log scale is a straight line with slope a and intercept log c.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Table", "md": "# Math Equations and Table"}, {"type": "text", "value": "$$\u03b5 = 4.0, n = 4096, d = 104 \\quad \u03b5 = 2.0, n = 4096, d = 105 \\quad \u03b5 = 1.0, n = 65536, K = \\sqrt{n}$$", "md": "$$\u03b5 = 4.0, n = 4096, d = 104 \\quad \u03b5 = 2.0, n = 4096, d = 105 \\quad \u03b5 = 1.0, n = 65536, K = \\sqrt{n}$$"}, {"type": "table", "rows": [["Difference of empirical \u02c6 \u03b5", "Correlation Measure", "Moment statistics"], ["0.20", "10-4", "10-4"], ["0.15", "10-3", "10-5"], ["0.10", "", "10-6"], ["0.05", "", "10-7"], ["0.00", "", "10-8"], ["-0.05", "", ""], ["-0.10", "", ""]], "md": "|Difference of empirical \u02c6 \u03b5|Correlation Measure|Moment statistics|\n|---|---|---|\n|0.20|10-4|10-4|\n|0.15|10-3|10-5|\n|0.10| |10-6|\n|0.05| |10-7|\n|0.00| |10-8|\n|-0.05| | |\n|-0.10| | |", "isPerfectTable": true, "csv": "\"Difference of empirical \u02c6 \u03b5\",\"Correlation Measure\",\"Moment statistics\"\n\"0.20\",\"10-4\",\"10-4\"\n\"0.15\",\"10-3\",\"10-5\"\n\"0.10\",\"\",\"10-6\"\n\"0.05\",\"\",\"10-7\"\n\"0.00\",\"\",\"10-8\"\n\"-0.05\",\"\",\"\"\n\"-0.10\",\"\",\"\""}, {"type": "text", "value": "Figure 4: Left: Separating the effects of bias and variance in auditing LiDP; cf. definition (10). Center & Right:\nThe correlations between the test statistics of the canaries decrease with K and d, achieving smaller CIs.\nterm in Figure 4 (middle) is nearly parallel to the dotted 1/K line (slope = -0.93), meaning that it decays roughly as 1/K.\nThis indicates that we get close to a 1/\u221anK confidence interval as desired. Similarly, we get that $$|\\hat{\\mu}_4 - \\hat{\\mu}_2^2|$$\ndecays roughly as 1/K (slope = -1.05). However, the 4th-order estimator offers only marginal additional improvements in the small \u03b5 regime (see Appendix E).\nThus, the gain diminishes rapidly in the order of our estimators.\n\nEffect of Dimension on the Bias and Variance. As the dimension d increases, the LiDP-based lower bound becomes tighter monotonically as we show in Figure 3 (right).\nThis is due to both the bias gain, as in (10), improving (less negative) and the variance gain improving (more positive). With increasing d, the variance of our estimate reduces\nbecause the canaries become less correlated. Guided by Eq. (8,9), we measure the relevant correlation measures $$|\\hat{\\mu}_2 - \\hat{\\mu}_2|$$ and $$|\\hat{\\mu}_4 - \\hat{\\mu}_2^2|$$\nin Figure 4 (right). Both decay approximate as 1/d (slope = -1.06 and -1.00 respectively, ignoring the outlier at d = 106). This suggests that, for Gaussian mechanisms,\nthe corresponding XBern distribution resulting from our recipe behaves favorably as d increases.\n\nLifting Existing Canary Designs\nSeveral prior works [e.g., 31, 40, 44, 59], focus on designing stronger canaries to improve the lower bound on \u03b5. We provide two concrete examples of how to lift these canary designs\nto be compatible with our framework while inheriting their strengths. We refer to Appendix D for further details.\n\nWe impose two criteria on the distribution Pcanary over canaries for auditing LiDP. First, the injected canaries are easy to detect, so that the probabilities on the left side of (4) are large\nand those on the right side are small. Second, a canary $$c \\sim P_{canary}$$, if included in the training of a model $$\\theta$$, is unlikely to change the membership of $$\\theta \\in R_{c'}$$\nfor an independent canary $$c' \\sim P_{canary}$$. Existing canary designs already impose the first condition to audit DP using (1). The second condition ensures that the canaries are uncorrelated,\nallowing our adaptive CIs to be smaller, as we discussed in \u00a73.3.\n\nData Poisoning via Tail Singular Vectors. ClipBKD [31] adds as canaries the tail singular vector of the input data (e.g., images). This ensures that the canary is out of distribution,\nallowing for easy detection. We lift ClipBKD by defining the distribution $$P_{canary}$$ as the uniform distribution over the p tail singular vectors of the input data. If p is small relative\nto the dimension d of the data, then they are still out of distribution, and hence, easy to detect. For the second condition, the orthogonality of the singular vectors ensures the interaction\nbetween canaries is minimal, as measured empirically.\n\n1The plot of $$y = cx^a$$ in log-log scale is a straight line with slope a and intercept log c.", "md": "Figure 4: Left: Separating the effects of bias and variance in auditing LiDP; cf. definition (10). Center & Right:\nThe correlations between the test statistics of the canaries decrease with K and d, achieving smaller CIs.\nterm in Figure 4 (middle) is nearly parallel to the dotted 1/K line (slope = -0.93), meaning that it decays roughly as 1/K.\nThis indicates that we get close to a 1/\u221anK confidence interval as desired. Similarly, we get that $$|\\hat{\\mu}_4 - \\hat{\\mu}_2^2|$$\ndecays roughly as 1/K (slope = -1.05). However, the 4th-order estimator offers only marginal additional improvements in the small \u03b5 regime (see Appendix E).\nThus, the gain diminishes rapidly in the order of our estimators.\n\nEffect of Dimension on the Bias and Variance. As the dimension d increases, the LiDP-based lower bound becomes tighter monotonically as we show in Figure 3 (right).\nThis is due to both the bias gain, as in (10), improving (less negative) and the variance gain improving (more positive). With increasing d, the variance of our estimate reduces\nbecause the canaries become less correlated. Guided by Eq. (8,9), we measure the relevant correlation measures $$|\\hat{\\mu}_2 - \\hat{\\mu}_2|$$ and $$|\\hat{\\mu}_4 - \\hat{\\mu}_2^2|$$\nin Figure 4 (right). Both decay approximate as 1/d (slope = -1.06 and -1.00 respectively, ignoring the outlier at d = 106). This suggests that, for Gaussian mechanisms,\nthe corresponding XBern distribution resulting from our recipe behaves favorably as d increases.\n\nLifting Existing Canary Designs\nSeveral prior works [e.g., 31, 40, 44, 59], focus on designing stronger canaries to improve the lower bound on \u03b5. We provide two concrete examples of how to lift these canary designs\nto be compatible with our framework while inheriting their strengths. We refer to Appendix D for further details.\n\nWe impose two criteria on the distribution Pcanary over canaries for auditing LiDP. First, the injected canaries are easy to detect, so that the probabilities on the left side of (4) are large\nand those on the right side are small. Second, a canary $$c \\sim P_{canary}$$, if included in the training of a model $$\\theta$$, is unlikely to change the membership of $$\\theta \\in R_{c'}$$\nfor an independent canary $$c' \\sim P_{canary}$$. Existing canary designs already impose the first condition to audit DP using (1). The second condition ensures that the canaries are uncorrelated,\nallowing our adaptive CIs to be smaller, as we discussed in \u00a73.3.\n\nData Poisoning via Tail Singular Vectors. ClipBKD [31] adds as canaries the tail singular vector of the input data (e.g., images). This ensures that the canary is out of distribution,\nallowing for easy detection. We lift ClipBKD by defining the distribution $$P_{canary}$$ as the uniform distribution over the p tail singular vectors of the input data. If p is small relative\nto the dimension d of the data, then they are still out of distribution, and hence, easy to detect. For the second condition, the orthogonality of the singular vectors ensures the interaction\nbetween canaries is minimal, as measured empirically.\n\n1The plot of $$y = cx^a$$ in log-log scale is a straight line with slope a and intercept log c."}]}, {"page": 10, "text": "            Dataset / Model                C.I./           Data Poisoning Canary              Random Gradient Canary\n                                        (Wilson)        \u03b5 = 2    \u03b5 = 4    \u03b5 = 8    \u03b5 = 16     \u03b5 = 2    \u03b5 = 4    \u03b5 = 8  \u03b5 = 16\n           FMNIST / Linear               2nd-Ord.        0.68     3.31     2.55      4.38      2.69     3.34     5.98   5.06\n                                         4th-Ord.        0.42     2.68     2.29      3.76      2.66     2.70     7.75   4.19\n            FMNIST / MLP                 2nd-Ord.        4.80     1.46     2.95      1.60      4.62     2.88     2.33   5.46\n                                         4th-Ord.        4.42     2.49     2.37      1.30      3.95     2.81     2.02   4.60\n            Purchase / MLP               2nd-Ord.        3.14     1.06     1.41      9.28      1.41    0.71      4.30   2.84\n                                         4th-Ord.        2.84     1.09     1.36      6.99      1.29     0.42     4.35   2.38\nTable 1: The (multiplicative) improvement in the sample complexity from auditing LiDP with K = 16 canaries\ncompared to auditing DP with n = 1000 trials. We determine this factor by linearly interpolating/extrapolating \u02c6               \u03b5n; cf.\nFigure 5 (left) for a visual representation of these numbers. For instance, an improvement of 3.31 means LiDP needs\nn \u2248   1000/3.31 \u2248    302 trials to reach the same empirical lower bound that DP reaches at n = 1000.\nRandom Gradients. The approach of [2] samples random vectors (of the right norm) as canary gradients,\nassuming a grey-box access where we can inject gradients. Since random vectors are nearly orthogonal to any\nfixed vector in high dimensions, their presence is easy to detect with a dot product. Similarly, any two i.i.d.\ncanary gradients are roughly orthogonal, leading to minimal interactions.\n6      Experiments\nWe compare the proposed LiDP auditing recipe relative to the standard one for DP training of machine\nlearning models. We will open-source the code to replicate these results.\nSetup. We test with two classification tasks: FMNIST [64] is a 10-class grayscale image classification dataset,\nwhile Purchase-100 is a sparse dataset with 600 binary features and 100 classes [19, 52]. We train a linear\nmodel and a multi-layer perceptron (MLP) with 2 hidden layers using DP-SGD [1] to achieve (\u03b5, 10\u22125)-DP\nwith varying values of \u03b5. The training is performed using cross-entropy for a fixed epoch budget and a batch\nsize of 100. We refer to Appendix F for specific details.\nAuditing. We audit the LiDP using the two types of canaries from \u00a75: data poisoning and random gradient\ncanaries. We vary the number K of canaries and the number n of trials. We track the empirical lower bound\nobtained from the Wilson family of confidence intervals. We compare this with auditing DP, which coincides\nwith auditing LiDP with K = 1 canary. We audit only the final model in all the experiments.\nSample Complexity Gain. Table 1 shows the reduction in the sample complexity from auditing LiDP.\nFor each canary type, auditing LiDP is better 11 out of the 12 settings considered. The average improvement\n(i.e., the harmonic mean over the table) for data poisoning is 2.3\u00d7, while for random gradients, it is 3.0\u00d7.\nSince each trial is a full model training run, this improvement can be quite significant in practice. This\nimprovement can also be seen visually in Figure 5 (left two).\nNumber of Canaries. We see from Figure 5 (right two) that LiDP auditing on real data behaves similar\nto Figure 3 in \u00a74. We also observe the bias-variance tradeoff in the case of data poisoning (center right).\nThe choice K = \u221an is competitive with the best value of K, validating our heuristic. Overall, these results\nshow that the insights from \u00a74 hold even with the significantly more complicated DP mechanism involved in\ntraining models privately.\n                                                                   10", "md": "|Dataset / Model|C.I.|Data Poisoning Canary|Random Gradient Canary|\n|---|---|---|---|\n|FMNIST / Linear|2nd-Ord.|0.68|2.69|\n| |4th-Ord.|0.42|2.66|\n|FMNIST / MLP|2nd-Ord.|4.80|4.62|\n| |4th-Ord.|4.42|3.95|\n|Purchase / MLP|2nd-Ord.|3.14|1.41|\n| |4th-Ord.|2.84|1.29|\n\nTable 1: The (multiplicative) improvement in the sample complexity from auditing LiDP with K = 16 canaries compared to auditing DP with n = 1000 trials. We determine this factor by linearly interpolating/extrapolating $$\\hat{\\varepsilon}_n$$; cf. Figure 5 (left) for a visual representation of these numbers. For instance, an improvement of 3.31 means LiDP needs $$n \\approx \\frac{1000}{3.31} \\approx 302$$ trials to reach the same empirical lower bound that DP reaches at n = 1000.\n\nRandom Gradients. The approach of [2] samples random vectors (of the right norm) as canary gradients, assuming a grey-box access where we can inject gradients. Since random vectors are nearly orthogonal to any fixed vector in high dimensions, their presence is easy to detect with a dot product. Similarly, any two i.i.d. canary gradients are roughly orthogonal, leading to minimal interactions.\n\n## Experiments\n\nWe compare the proposed LiDP auditing recipe relative to the standard one for DP training of machine learning models. We will open-source the code to replicate these results.\n\nSetup. We test with two classification tasks: FMNIST [64] is a 10-class grayscale image classification dataset, while Purchase-100 is a sparse dataset with 600 binary features and 100 classes [19, 52]. We train a linear model and a multi-layer perceptron (MLP) with 2 hidden layers using DP-SGD [1] to achieve (\u03b5, 10^-5)-DP with varying values of \u03b5. The training is performed using cross-entropy for a fixed epoch budget and a batch size of 100. We refer to Appendix F for specific details.\n\nAuditing. We audit the LiDP using the two types of canaries from \u00a75: data poisoning and random gradient canaries. We vary the number K of canaries and the number n of trials. We track the empirical lower bound obtained from the Wilson family of confidence intervals. We compare this with auditing DP, which coincides with auditing LiDP with K = 1 canary. We audit only the final model in all the experiments.\n\nSample Complexity Gain. Table 1 shows the reduction in the sample complexity from auditing LiDP. For each canary type, auditing LiDP is better 11 out of the 12 settings considered. The average improvement (i.e., the harmonic mean over the table) for data poisoning is 2.3\u00d7, while for random gradients, it is 3.0\u00d7. Since each trial is a full model training run, this improvement can be quite significant in practice. This improvement can also be seen visually in Figure 5 (left two).\n\nNumber of Canaries. We see from Figure 5 (right two) that LiDP auditing on real data behaves similar to Figure 3 in \u00a74. We also observe the bias-variance tradeoff in the case of data poisoning (center right). The choice K = $$\\sqrt{n}$$ is competitive with the best value of K, validating our heuristic. Overall, these results show that the insights from \u00a74 hold even with the significantly more complicated DP mechanism involved in training models privately.", "images": [], "items": [{"type": "table", "rows": [["Dataset / Model", "C.I.", "Data Poisoning Canary", "Random Gradient Canary"], ["FMNIST / Linear", "2nd-Ord.", "0.68", "2.69"], ["", "4th-Ord.", "0.42", "2.66"], ["FMNIST / MLP", "2nd-Ord.", "4.80", "4.62"], ["", "4th-Ord.", "4.42", "3.95"], ["Purchase / MLP", "2nd-Ord.", "3.14", "1.41"], ["", "4th-Ord.", "2.84", "1.29"]], "md": "|Dataset / Model|C.I.|Data Poisoning Canary|Random Gradient Canary|\n|---|---|---|---|\n|FMNIST / Linear|2nd-Ord.|0.68|2.69|\n| |4th-Ord.|0.42|2.66|\n|FMNIST / MLP|2nd-Ord.|4.80|4.62|\n| |4th-Ord.|4.42|3.95|\n|Purchase / MLP|2nd-Ord.|3.14|1.41|\n| |4th-Ord.|2.84|1.29|", "isPerfectTable": true, "csv": "\"Dataset / Model\",\"C.I.\",\"Data Poisoning Canary\",\"Random Gradient Canary\"\n\"FMNIST / Linear\",\"2nd-Ord.\",\"0.68\",\"2.69\"\n\"\",\"4th-Ord.\",\"0.42\",\"2.66\"\n\"FMNIST / MLP\",\"2nd-Ord.\",\"4.80\",\"4.62\"\n\"\",\"4th-Ord.\",\"4.42\",\"3.95\"\n\"Purchase / MLP\",\"2nd-Ord.\",\"3.14\",\"1.41\"\n\"\",\"4th-Ord.\",\"2.84\",\"1.29\""}, {"type": "text", "value": "Table 1: The (multiplicative) improvement in the sample complexity from auditing LiDP with K = 16 canaries compared to auditing DP with n = 1000 trials. We determine this factor by linearly interpolating/extrapolating $$\\hat{\\varepsilon}_n$$; cf. Figure 5 (left) for a visual representation of these numbers. For instance, an improvement of 3.31 means LiDP needs $$n \\approx \\frac{1000}{3.31} \\approx 302$$ trials to reach the same empirical lower bound that DP reaches at n = 1000.\n\nRandom Gradients. The approach of [2] samples random vectors (of the right norm) as canary gradients, assuming a grey-box access where we can inject gradients. Since random vectors are nearly orthogonal to any fixed vector in high dimensions, their presence is easy to detect with a dot product. Similarly, any two i.i.d. canary gradients are roughly orthogonal, leading to minimal interactions.", "md": "Table 1: The (multiplicative) improvement in the sample complexity from auditing LiDP with K = 16 canaries compared to auditing DP with n = 1000 trials. We determine this factor by linearly interpolating/extrapolating $$\\hat{\\varepsilon}_n$$; cf. Figure 5 (left) for a visual representation of these numbers. For instance, an improvement of 3.31 means LiDP needs $$n \\approx \\frac{1000}{3.31} \\approx 302$$ trials to reach the same empirical lower bound that DP reaches at n = 1000.\n\nRandom Gradients. The approach of [2] samples random vectors (of the right norm) as canary gradients, assuming a grey-box access where we can inject gradients. Since random vectors are nearly orthogonal to any fixed vector in high dimensions, their presence is easy to detect with a dot product. Similarly, any two i.i.d. canary gradients are roughly orthogonal, leading to minimal interactions."}, {"type": "heading", "lvl": 2, "value": "Experiments", "md": "## Experiments"}, {"type": "text", "value": "We compare the proposed LiDP auditing recipe relative to the standard one for DP training of machine learning models. We will open-source the code to replicate these results.\n\nSetup. We test with two classification tasks: FMNIST [64] is a 10-class grayscale image classification dataset, while Purchase-100 is a sparse dataset with 600 binary features and 100 classes [19, 52]. We train a linear model and a multi-layer perceptron (MLP) with 2 hidden layers using DP-SGD [1] to achieve (\u03b5, 10^-5)-DP with varying values of \u03b5. The training is performed using cross-entropy for a fixed epoch budget and a batch size of 100. We refer to Appendix F for specific details.\n\nAuditing. We audit the LiDP using the two types of canaries from \u00a75: data poisoning and random gradient canaries. We vary the number K of canaries and the number n of trials. We track the empirical lower bound obtained from the Wilson family of confidence intervals. We compare this with auditing DP, which coincides with auditing LiDP with K = 1 canary. We audit only the final model in all the experiments.\n\nSample Complexity Gain. Table 1 shows the reduction in the sample complexity from auditing LiDP. For each canary type, auditing LiDP is better 11 out of the 12 settings considered. The average improvement (i.e., the harmonic mean over the table) for data poisoning is 2.3\u00d7, while for random gradients, it is 3.0\u00d7. Since each trial is a full model training run, this improvement can be quite significant in practice. This improvement can also be seen visually in Figure 5 (left two).\n\nNumber of Canaries. We see from Figure 5 (right two) that LiDP auditing on real data behaves similar to Figure 3 in \u00a74. We also observe the bias-variance tradeoff in the case of data poisoning (center right). The choice K = $$\\sqrt{n}$$ is competitive with the best value of K, validating our heuristic. Overall, these results show that the insights from \u00a74 hold even with the significantly more complicated DP mechanism involved in training models privately.", "md": "We compare the proposed LiDP auditing recipe relative to the standard one for DP training of machine learning models. We will open-source the code to replicate these results.\n\nSetup. We test with two classification tasks: FMNIST [64] is a 10-class grayscale image classification dataset, while Purchase-100 is a sparse dataset with 600 binary features and 100 classes [19, 52]. We train a linear model and a multi-layer perceptron (MLP) with 2 hidden layers using DP-SGD [1] to achieve (\u03b5, 10^-5)-DP with varying values of \u03b5. The training is performed using cross-entropy for a fixed epoch budget and a batch size of 100. We refer to Appendix F for specific details.\n\nAuditing. We audit the LiDP using the two types of canaries from \u00a75: data poisoning and random gradient canaries. We vary the number K of canaries and the number n of trials. We track the empirical lower bound obtained from the Wilson family of confidence intervals. We compare this with auditing DP, which coincides with auditing LiDP with K = 1 canary. We audit only the final model in all the experiments.\n\nSample Complexity Gain. Table 1 shows the reduction in the sample complexity from auditing LiDP. For each canary type, auditing LiDP is better 11 out of the 12 settings considered. The average improvement (i.e., the harmonic mean over the table) for data poisoning is 2.3\u00d7, while for random gradients, it is 3.0\u00d7. Since each trial is a full model training run, this improvement can be quite significant in practice. This improvement can also be seen visually in Figure 5 (left two).\n\nNumber of Canaries. We see from Figure 5 (right two) that LiDP auditing on real data behaves similar to Figure 3 in \u00a74. We also observe the bias-variance tradeoff in the case of data poisoning (center right). The choice K = $$\\sqrt{n}$$ is competitive with the best value of K, validating our heuristic. Overall, these results show that the insights from \u00a74 hold even with the significantly more complicated DP mechanism involved in training models privately."}]}, {"page": 11, "text": "       0.25    Purchase-MLP + Data Poisoning, \u03b5 = 2                                    0.25 FMNIST-Linear + Random Gradient, \u03b5 = 2                           0.25    Purchase-MLP + Data Poisoning, \u03b5 = 2                      FMNIST-Linear + Random Gradient, \u03b5 = 4\n     Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6                                                Empirical lower bound \u02c6                                     Empirical lower bound \u02c6\n     \u03b5 0.20                                                                          \u03b5 0.20                                                                 \u03b50.20                                                       \u03b5 0.20\n       0.15                                                                            0.15                                             2.69\u00d7                0.15                                                         0.15\n       0.10                                             3.14\u00d7                          0.10                                                                  0.10                                                         0.10\n       0.05                                                                            0.05                                                                  0.05\n                                                                                                                                                                                                                          0.05\n       0.00                                                                            0.00                                                                  0.00\n                27                  28                  29                  210                27                   28                  29           210             20        21         22        23     24  25  26                   21          23          25     27  29\n                                Number of trials n                                                             Number of trials n                                                  Number of canaries K                                         Number of canaries K\n                                                 K = \u221an                            DP + Wilson                             LiDP + 1st-Order Wilson                           LiDP + 2nd-Order Wilson                   LiDP + 4th-Order Wilson\n Figure 5: Left two: LiDP-based auditing with K > 1 canaries achieves the same lower bound \u02c6                                                                                                                                                 \u03b5 on the privacy loss\n with fewer trials. Right two: LiDP auditing is robust to K; the prescribed K = \u221an is a reliable default.\n 7               Conclusion\nWe introduce a new framework for auditing differentially private learning. Diverging from the standard\n practice of adding a single deterministic canary, we propose a new recipe of adding multiple i.i.d. random\n canaries. This is made rigorous by an expanded definition of privacy that we call LiDP. We provide novel\n higher-order confidence intervals that can automatically adapt to the level of correlation in the data. We\n empirically demonstrate that there is a potentially significant gain in sample dependence of the confidence\n intervals, achieving favourable bias-variance tradeoff.\n           Although any rigorous statistical auditing approach can benefit from our framework, it is not yet clear\n how other popular approaches [e.g. 12] for measuring memorization can be improved with randomization.\n Bridging this gap is an important practical direction for future research. It is also worth considering how our\n approach can be adapted to audit the diverse definitions of privacy in machine learning [e.g. 27].\n Broader Impact.                                                  Auditing private training involves a trade-off between the computational cost and\n the tightness of the guarantee. This may not be appropriate for all practical settings. For deployment in\n production, it worth further studying approaches with minimal computational overhead [e.g. 2, 12].\n Acknowledgements\nWe acknowledge Lang Liu for helpful discussions regarding hypothesis testing and conditional probability,\n and Matthew Jagielski for help in debugging.\n References\n    [1] M. Abadi, A. Chu, I. J. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep Learning\n               with Differential Privacy. In Proc. of the 2016 ACM SIGSAC Conf. on Computer and Communications\n               Security (CCS\u201916), pages 308\u2013318, 2016.\n    [2] G. Andrew, P. Kairouz, S. Oh, A. Oprea, H. B. McMahan, and V. Suriyakumar. One-shot Empirical\n               Privacy Estimation for Federated Learning. arXiv preprint arXiv:2302.03098, 2023.\n    [3] \u00a8      O. Askin, T. Kutta, and H. Dette. Statistical Quantification of Differential Privacy: A Local Approach.\n               In 2022 IEEE Symposium on Security and Privacy (SP), pages 402\u2013421. IEEE, 2022.\n    [4] B. Balle, G. Barthe, M. Gaboardi, J. Hsu, and T. Sato. Hypothesis Testing Interpretations and Renyi\n               Differential Privacy. In The 23rd International Conference on Artificial Intelligence and Statistics,\n               volume 108, pages 2496\u20132506. PMLR, 2020.\n                                                                                                                                                        11", "md": "# Document\n\n$$0.25 \\text{ Purchase-MLP + Data Poisoning, } \\varepsilon = 2 \\quad 0.25 \\text{ FMNIST-Linear + Random Gradient, } \\varepsilon = 2$$\n\n$$0.25 \\text{ Purchase-MLP + Data Poisoning, } \\varepsilon = 2 \\quad \\text{FMNIST-Linear + Random Gradient, } \\varepsilon = 4$$\n\n|Empirical lower bound $\\hat{\\ }$|Empirical lower bound $\\hat{\\ }$|Empirical lower bound $\\hat{\\ }$|Empirical lower bound $\\hat{\\ }$|\n|---|---|---|---|\n|$\\varepsilon 0.20$|$\\varepsilon 0.20$|$\\varepsilon 0.20$|$\\varepsilon 0.20$|\n|0.15|0.15|$2.69\\times 0.15$|0.15|\n|0.10|$3.14\\times 0.10$|0.10|0.10|\n|0.05|0.05|0.05|0.05|\n|0.00|0.00|0.00|0.00|\n\n| |Number of trials $n$| |Number of canaries $K$|\n|---|---|---|---|\n|$K = \\sqrt{n}$|DP + Wilson|LiDP + 1st-Order Wilson|LiDP + 2nd-Order Wilson|LiDP + 4th-Order Wilson|\n\nFigure 5: Left two: LiDP-based auditing with $K > 1$ canaries achieves the same lower bound $\\hat{\\ }$ on the privacy loss\nwith fewer trials. Right two: LiDP auditing is robust to $K$; the prescribed $K = \\sqrt{n}$ is a reliable default.\n\nConclusion\n\nWe introduce a new framework for auditing differentially private learning. Diverging from the standard\npractice of adding a single deterministic canary, we propose a new recipe of adding multiple i.i.d. random\ncanaries. This is made rigorous by an expanded definition of privacy that we call LiDP. We provide novel\nhigher-order confidence intervals that can automatically adapt to the level of correlation in the data. We\nempirically demonstrate that there is a potentially significant gain in sample dependence of the confidence\nintervals, achieving favourable bias-variance tradeoff.\n\nAlthough any rigorous statistical auditing approach can benefit from our framework, it is not yet clear\nhow other popular approaches [e.g. 12] for measuring memorization can be improved with randomization.\nBridging this gap is an important practical direction for future research. It is also worth considering how our\napproach can be adapted to audit the diverse definitions of privacy in machine learning [e.g. 27].\n\nBroader Impact. Auditing private training involves a trade-off between the computational cost and\nthe tightness of the guarantee. This may not be appropriate for all practical settings. For deployment in\nproduction, it worth further studying approaches with minimal computational overhead [e.g. 2, 12].\n\nAcknowledgements\n\nWe acknowledge Lang Liu for helpful discussions regarding hypothesis testing and conditional probability,\nand Matthew Jagielski for help in debugging.\n\nReferences\n\n[1] M. Abadi, A. Chu, I. J. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep Learning\nwith Differential Privacy. In Proc. of the 2016 ACM SIGSAC Conf. on Computer and Communications\nSecurity (CCS\u201916), pages 308\u2013318, 2016.\n\n[2] G. Andrew, P. Kairouz, S. Oh, A. Oprea, H. B. McMahan, and V. Suriyakumar. One-shot Empirical\nPrivacy Estimation for Federated Learning. arXiv preprint arXiv:2302.03098, 2023.\n\n[3] O. Askin, T. Kutta, and H. Dette. Statistical Quantification of Differential Privacy: A Local Approach.\nIn 2022 IEEE Symposium on Security and Privacy (SP), pages 402\u2013421. IEEE, 2022.\n\n[4] B. Balle, G. Barthe, M. Gaboardi, J. Hsu, and T. Sato. Hypothesis Testing Interpretations and Renyi\nDifferential Privacy. In The 23rd International Conference on Artificial Intelligence and Statistics,\nvolume 108, pages 2496\u20132506. PMLR, 2020.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "$$0.25 \\text{ Purchase-MLP + Data Poisoning, } \\varepsilon = 2 \\quad 0.25 \\text{ FMNIST-Linear + Random Gradient, } \\varepsilon = 2$$\n\n$$0.25 \\text{ Purchase-MLP + Data Poisoning, } \\varepsilon = 2 \\quad \\text{FMNIST-Linear + Random Gradient, } \\varepsilon = 4$$", "md": "$$0.25 \\text{ Purchase-MLP + Data Poisoning, } \\varepsilon = 2 \\quad 0.25 \\text{ FMNIST-Linear + Random Gradient, } \\varepsilon = 2$$\n\n$$0.25 \\text{ Purchase-MLP + Data Poisoning, } \\varepsilon = 2 \\quad \\text{FMNIST-Linear + Random Gradient, } \\varepsilon = 4$$"}, {"type": "table", "rows": [["Empirical lower bound $\\hat{\\ }$", "Empirical lower bound $\\hat{\\ }$", "Empirical lower bound $\\hat{\\ }$", "Empirical lower bound $\\hat{\\ }$"], ["$\\varepsilon 0.20$", "$\\varepsilon 0.20$", "$\\varepsilon 0.20$", "$\\varepsilon 0.20$"], ["0.15", "0.15", "$2.69\\times 0.15$", "0.15"], ["0.10", "$3.14\\times 0.10$", "0.10", "0.10"], ["0.05", "0.05", "0.05", "0.05"], ["0.00", "0.00", "0.00", "0.00"]], "md": "|Empirical lower bound $\\hat{\\ }$|Empirical lower bound $\\hat{\\ }$|Empirical lower bound $\\hat{\\ }$|Empirical lower bound $\\hat{\\ }$|\n|---|---|---|---|\n|$\\varepsilon 0.20$|$\\varepsilon 0.20$|$\\varepsilon 0.20$|$\\varepsilon 0.20$|\n|0.15|0.15|$2.69\\times 0.15$|0.15|\n|0.10|$3.14\\times 0.10$|0.10|0.10|\n|0.05|0.05|0.05|0.05|\n|0.00|0.00|0.00|0.00|", "isPerfectTable": true, "csv": "\"Empirical lower bound $\\hat{\\ }$\",\"Empirical lower bound $\\hat{\\ }$\",\"Empirical lower bound $\\hat{\\ }$\",\"Empirical lower bound $\\hat{\\ }$\"\n\"$\\varepsilon 0.20$\",\"$\\varepsilon 0.20$\",\"$\\varepsilon 0.20$\",\"$\\varepsilon 0.20$\"\n\"0.15\",\"0.15\",\"$2.69\\times 0.15$\",\"0.15\"\n\"0.10\",\"$3.14\\times 0.10$\",\"0.10\",\"0.10\"\n\"0.05\",\"0.05\",\"0.05\",\"0.05\"\n\"0.00\",\"0.00\",\"0.00\",\"0.00\""}, {"type": "table", "rows": [["", "Number of trials $n$", "", "Number of canaries $K$"], ["$K = \\sqrt{n}$", "DP + Wilson", "LiDP + 1st-Order Wilson", "LiDP + 2nd-Order Wilson", "LiDP + 4th-Order Wilson"]], "md": "| |Number of trials $n$| |Number of canaries $K$|\n|---|---|---|---|\n|$K = \\sqrt{n}$|DP + Wilson|LiDP + 1st-Order Wilson|LiDP + 2nd-Order Wilson|LiDP + 4th-Order Wilson|", "isPerfectTable": false, "csv": "\"\",\"Number of trials $n$\",\"\",\"Number of canaries $K$\"\n\"$K = \\sqrt{n}$\",\"DP + Wilson\",\"LiDP + 1st-Order Wilson\",\"LiDP + 2nd-Order Wilson\",\"LiDP + 4th-Order Wilson\""}, {"type": "text", "value": "Figure 5: Left two: LiDP-based auditing with $K > 1$ canaries achieves the same lower bound $\\hat{\\ }$ on the privacy loss\nwith fewer trials. Right two: LiDP auditing is robust to $K$; the prescribed $K = \\sqrt{n}$ is a reliable default.\n\nConclusion\n\nWe introduce a new framework for auditing differentially private learning. Diverging from the standard\npractice of adding a single deterministic canary, we propose a new recipe of adding multiple i.i.d. random\ncanaries. This is made rigorous by an expanded definition of privacy that we call LiDP. We provide novel\nhigher-order confidence intervals that can automatically adapt to the level of correlation in the data. We\nempirically demonstrate that there is a potentially significant gain in sample dependence of the confidence\nintervals, achieving favourable bias-variance tradeoff.\n\nAlthough any rigorous statistical auditing approach can benefit from our framework, it is not yet clear\nhow other popular approaches [e.g. 12] for measuring memorization can be improved with randomization.\nBridging this gap is an important practical direction for future research. It is also worth considering how our\napproach can be adapted to audit the diverse definitions of privacy in machine learning [e.g. 27].\n\nBroader Impact. Auditing private training involves a trade-off between the computational cost and\nthe tightness of the guarantee. This may not be appropriate for all practical settings. For deployment in\nproduction, it worth further studying approaches with minimal computational overhead [e.g. 2, 12].\n\nAcknowledgements\n\nWe acknowledge Lang Liu for helpful discussions regarding hypothesis testing and conditional probability,\nand Matthew Jagielski for help in debugging.\n\nReferences\n\n[1] M. Abadi, A. Chu, I. J. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep Learning\nwith Differential Privacy. In Proc. of the 2016 ACM SIGSAC Conf. on Computer and Communications\nSecurity (CCS\u201916), pages 308\u2013318, 2016.\n\n[2] G. Andrew, P. Kairouz, S. Oh, A. Oprea, H. B. McMahan, and V. Suriyakumar. One-shot Empirical\nPrivacy Estimation for Federated Learning. arXiv preprint arXiv:2302.03098, 2023.\n\n[3] O. Askin, T. Kutta, and H. Dette. Statistical Quantification of Differential Privacy: A Local Approach.\nIn 2022 IEEE Symposium on Security and Privacy (SP), pages 402\u2013421. IEEE, 2022.\n\n[4] B. Balle, G. Barthe, M. Gaboardi, J. Hsu, and T. Sato. Hypothesis Testing Interpretations and Renyi\nDifferential Privacy. In The 23rd International Conference on Artificial Intelligence and Statistics,\nvolume 108, pages 2496\u20132506. PMLR, 2020.", "md": "Figure 5: Left two: LiDP-based auditing with $K > 1$ canaries achieves the same lower bound $\\hat{\\ }$ on the privacy loss\nwith fewer trials. Right two: LiDP auditing is robust to $K$; the prescribed $K = \\sqrt{n}$ is a reliable default.\n\nConclusion\n\nWe introduce a new framework for auditing differentially private learning. Diverging from the standard\npractice of adding a single deterministic canary, we propose a new recipe of adding multiple i.i.d. random\ncanaries. This is made rigorous by an expanded definition of privacy that we call LiDP. We provide novel\nhigher-order confidence intervals that can automatically adapt to the level of correlation in the data. We\nempirically demonstrate that there is a potentially significant gain in sample dependence of the confidence\nintervals, achieving favourable bias-variance tradeoff.\n\nAlthough any rigorous statistical auditing approach can benefit from our framework, it is not yet clear\nhow other popular approaches [e.g. 12] for measuring memorization can be improved with randomization.\nBridging this gap is an important practical direction for future research. It is also worth considering how our\napproach can be adapted to audit the diverse definitions of privacy in machine learning [e.g. 27].\n\nBroader Impact. Auditing private training involves a trade-off between the computational cost and\nthe tightness of the guarantee. This may not be appropriate for all practical settings. For deployment in\nproduction, it worth further studying approaches with minimal computational overhead [e.g. 2, 12].\n\nAcknowledgements\n\nWe acknowledge Lang Liu for helpful discussions regarding hypothesis testing and conditional probability,\nand Matthew Jagielski for help in debugging.\n\nReferences\n\n[1] M. Abadi, A. Chu, I. J. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep Learning\nwith Differential Privacy. In Proc. of the 2016 ACM SIGSAC Conf. on Computer and Communications\nSecurity (CCS\u201916), pages 308\u2013318, 2016.\n\n[2] G. Andrew, P. Kairouz, S. Oh, A. Oprea, H. B. McMahan, and V. Suriyakumar. One-shot Empirical\nPrivacy Estimation for Federated Learning. arXiv preprint arXiv:2302.03098, 2023.\n\n[3] O. Askin, T. Kutta, and H. Dette. Statistical Quantification of Differential Privacy: A Local Approach.\nIn 2022 IEEE Symposium on Security and Privacy (SP), pages 402\u2013421. IEEE, 2022.\n\n[4] B. Balle, G. Barthe, M. Gaboardi, J. Hsu, and T. Sato. Hypothesis Testing Interpretations and Renyi\nDifferential Privacy. In The 23rd International Conference on Artificial Intelligence and Statistics,\nvolume 108, pages 2496\u20132506. PMLR, 2020."}]}, {"page": 12, "text": " [5] G. Barthe, B. K\u00a8 opf, F. Olmedo, and S. Zanella Beguelin.       Probabilistic Relational Reasoning for\n    Differential Privacy. ACM SIGPLAN Notices, 47(1):97\u2013110, 2012.\n [6] G. Barthe, G. Danezis, B. Gr\u00b4\n                                 egoire, C. Kunz, and S. Zanella-Beguelin. Verified Computational Differential\n    Privacy with Applications to Smart Metering. In 2013 IEEE 26th Computer Security Foundations\n    Symposium, pages 287\u2013301. IEEE, 2013.\n [7] G. Barthe, M. Gaboardi, E. J. G. Arias, J. Hsu, C. Kunz, and P.-Y. Strub. Proving differential privacy\n    in Hoare logic. In 2014 IEEE 27th Computer Security Foundations Symposium, pages 411\u2013424. IEEE,\n    2014.\n [8] R. Bhaskar, A. Bhowmick, V. Goyal, S. Laxman, and A. Thakurta. Noiseless Database Privacy. In\n    International Conference on the Theory and Application of Cryptology and Information Security, pages\n    215\u2013232. Springer, 2011.\n [9] B. Bichsel, S. Steffen, I. Bogunovic, and M. Vechev. DP-Sniper: Black-Box Discovery of Differential\n    Privacy Violations using Classifiers. In 2021 IEEE Symposium on Security and Privacy (SP), pages\n    391\u2013409. IEEE, 2021.\n[10] M. Bun and T. Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower\n    Bounds. In Theory of Cryptography Conference, pages 635\u2013658. Springer, 2016.\n[11] M. Bun, J. Ullman, and S. Vadhan. Fingerprinting Codes and the Price of Approximate Differential\n    Privacy. SIAM Journal on Computing, 47(5):1888\u20131938, 2018.\n[12] N. Carlini, C. Liu, \u00b4\n                         U. Erlingsson, J. Kos, and D. Song. The Secret Sharer: Evaluating and Testing\n    Unintended Memorization in Neural Networks. In USENIX Security Symposium, volume 267, 2019.\n[13] N. Carlini, F. Tramer, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee, A. Roberts, T. Brown, D. Song,\n    U. Erlingsson, A. Oprea, and C. Raffel. Extracting Training Data from Large Language Models. In 30th\n    USENIX Security Symposium (USENIX Security 2021), 2021.\n[14] N. Carlini, S. Chien, M. Nasr, S. Song, A. Terzis, and F. Tramer. Membership Inference Attacks\n    from First Principles.    In IEEE Symposium on Security and Privacy (SP), pages 1519\u20131519, Los\n    Alamitos, CA, USA, May 2022. IEEE Computer Society. doi: 10.1109/SP46214.2022.00090. URL\n    https://doi.ieeecomputersociety.org/10.1109/SP46214.2022.00090.\n[15] N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tramer, and C. Zhang. Quantifying Memorization Across\n    Neural Language Models. In The Eleventh International Conference on Learning Representations, 2023.\n    URL https://openreview.net/forum?id=TatRHT_1cK.\n[16] Y. Chen and A. Machanavajjhala. On the privacy properties of variants on the sparse vector technique.\n    arXiv preprint arXiv:1508.07306, 2015.\n[17] Z. Ding, Y. Wang, G. Wang, D. Zhang, and D. Kifer. Detecting violations of differential privacy. In\n    Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages\n    475\u2013489, 2018.\n[18] K. Dixit, M. Jha, S. Raskhodnikova, and A. Thakurta.          Testing Lipschitz Property over Product\n    Distribution and its Applications to Statistical Data Privacy. In Theory of Cryptography Conference,\n    pages 418\u2013436. Springer, 2013.\n[19] W. C. DMDave, Todd B.        Acquire valued shoppers challenge, 2014.       URL https://kaggle.com/\n    competitions/acquire-valued-shoppers-challenge.\n[20] C. Dwork and G. N. Rothblum. Concentrated Differential Privacy. arXiv preprint arXiv:1603.01887,\n    2016.\n                                                      12", "md": "1. G. Barthe, B. K\u00a8 opf, F. Olmedo, and S. Zanella Beguelin. Probabilistic Relational Reasoning for Differential Privacy. ACM SIGPLAN Notices, 47(1):97\u2013110, 2012.\n2. G. Barthe, G. Danezis, B. Gr\u00b4egoire, C. Kunz, and S. Zanella-Beguelin. Verified Computational Differential Privacy with Applications to Smart Metering. In 2013 IEEE 26th Computer Security Foundations Symposium, pages 287\u2013301. IEEE, 2013.\n3. G. Barthe, M. Gaboardi, E. J. G. Arias, J. Hsu, C. Kunz, and P.-Y. Strub. Proving differential privacy in Hoare logic. In 2014 IEEE 27th Computer Security Foundations Symposium, pages 411\u2013424. IEEE, 2014.\n4. R. Bhaskar, A. Bhowmick, V. Goyal, S. Laxman, and A. Thakurta. Noiseless Database Privacy. In International Conference on the Theory and Application of Cryptology and Information Security, pages 215\u2013232. Springer, 2011.\n5. B. Bichsel, S. Steffen, I. Bogunovic, and M. Vechev. DP-Sniper: Black-Box Discovery of Differential Privacy Violations using Classifiers. In 2021 IEEE Symposium on Security and Privacy (SP), pages 391\u2013409. IEEE, 2021.\n6. M. Bun and T. Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. In Theory of Cryptography Conference, pages 635\u2013658. Springer, 2016.\n7. M. Bun, J. Ullman, and S. Vadhan. Fingerprinting Codes and the Price of Approximate Differential Privacy. SIAM Journal on Computing, 47(5):1888\u20131938, 2018.\n8. N. Carlini, C. Liu, \u00b4U. Erlingsson, J. Kos, and D. Song. The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks. In USENIX Security Symposium, volume 267, 2019.\n9. N. Carlini, F. Tramer, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee, A. Roberts, T. Brown, D. Song, U. Erlingsson, A. Oprea, and C. Raffel. Extracting Training Data from Large Language Models. In 30th USENIX Security Symposium (USENIX Security 2021), 2021.\n10. N. Carlini, S. Chien, M. Nasr, S. Song, A. Terzis, and F. Tramer. Membership Inference Attacks from First Principles. In IEEE Symposium on Security and Privacy (SP), pages 1519\u20131519, Los Alamitos, CA, USA, May 2022. IEEE Computer Society. doi: 10.1109/SP46214.2022.00090. URL https://doi.ieeecomputersociety.org/10.1109/SP46214.2022.00090.\n11. N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tramer, and C. Zhang. Quantifying Memorization Across Neural Language Models. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=TatRHT_1cK.\n12. Y. Chen and A. Machanavajjhala. On the privacy properties of variants on the sparse vector technique. arXiv preprint arXiv:1508.07306, 2015.\n13. Z. Ding, Y. Wang, G. Wang, D. Zhang, and D. Kifer. Detecting violations of differential privacy. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 475\u2013489, 2018.\n14. K. Dixit, M. Jha, S. Raskhodnikova, and A. Thakurta. Testing Lipschitz Property over Product Distribution and its Applications to Statistical Data Privacy. In Theory of Cryptography Conference, pages 418\u2013436. Springer, 2013.\n15. W. C. DMDave, Todd B. Acquire valued shoppers challenge, 2014. URL https://kaggle.com/competitions/acquire-valued-shoppers-challenge.\n16. C. Dwork and G. N. Rothblum. Concentrated Differential Privacy. arXiv preprint arXiv:1603.01887, 2016.", "images": [], "items": [{"type": "text", "value": "1. G. Barthe, B. K\u00a8 opf, F. Olmedo, and S. Zanella Beguelin. Probabilistic Relational Reasoning for Differential Privacy. ACM SIGPLAN Notices, 47(1):97\u2013110, 2012.\n2. G. Barthe, G. Danezis, B. Gr\u00b4egoire, C. Kunz, and S. Zanella-Beguelin. Verified Computational Differential Privacy with Applications to Smart Metering. In 2013 IEEE 26th Computer Security Foundations Symposium, pages 287\u2013301. IEEE, 2013.\n3. G. Barthe, M. Gaboardi, E. J. G. Arias, J. Hsu, C. Kunz, and P.-Y. Strub. Proving differential privacy in Hoare logic. In 2014 IEEE 27th Computer Security Foundations Symposium, pages 411\u2013424. IEEE, 2014.\n4. R. Bhaskar, A. Bhowmick, V. Goyal, S. Laxman, and A. Thakurta. Noiseless Database Privacy. In International Conference on the Theory and Application of Cryptology and Information Security, pages 215\u2013232. Springer, 2011.\n5. B. Bichsel, S. Steffen, I. Bogunovic, and M. Vechev. DP-Sniper: Black-Box Discovery of Differential Privacy Violations using Classifiers. In 2021 IEEE Symposium on Security and Privacy (SP), pages 391\u2013409. IEEE, 2021.\n6. M. Bun and T. Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. In Theory of Cryptography Conference, pages 635\u2013658. Springer, 2016.\n7. M. Bun, J. Ullman, and S. Vadhan. Fingerprinting Codes and the Price of Approximate Differential Privacy. SIAM Journal on Computing, 47(5):1888\u20131938, 2018.\n8. N. Carlini, C. Liu, \u00b4U. Erlingsson, J. Kos, and D. Song. The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks. In USENIX Security Symposium, volume 267, 2019.\n9. N. Carlini, F. Tramer, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee, A. Roberts, T. Brown, D. Song, U. Erlingsson, A. Oprea, and C. Raffel. Extracting Training Data from Large Language Models. In 30th USENIX Security Symposium (USENIX Security 2021), 2021.\n10. N. Carlini, S. Chien, M. Nasr, S. Song, A. Terzis, and F. Tramer. Membership Inference Attacks from First Principles. In IEEE Symposium on Security and Privacy (SP), pages 1519\u20131519, Los Alamitos, CA, USA, May 2022. IEEE Computer Society. doi: 10.1109/SP46214.2022.00090. URL https://doi.ieeecomputersociety.org/10.1109/SP46214.2022.00090.\n11. N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tramer, and C. Zhang. Quantifying Memorization Across Neural Language Models. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=TatRHT_1cK.\n12. Y. Chen and A. Machanavajjhala. On the privacy properties of variants on the sparse vector technique. arXiv preprint arXiv:1508.07306, 2015.\n13. Z. Ding, Y. Wang, G. Wang, D. Zhang, and D. Kifer. Detecting violations of differential privacy. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 475\u2013489, 2018.\n14. K. Dixit, M. Jha, S. Raskhodnikova, and A. Thakurta. Testing Lipschitz Property over Product Distribution and its Applications to Statistical Data Privacy. In Theory of Cryptography Conference, pages 418\u2013436. Springer, 2013.\n15. W. C. DMDave, Todd B. Acquire valued shoppers challenge, 2014. URL https://kaggle.com/competitions/acquire-valued-shoppers-challenge.\n16. C. Dwork and G. N. Rothblum. Concentrated Differential Privacy. arXiv preprint arXiv:1603.01887, 2016.", "md": "1. G. Barthe, B. K\u00a8 opf, F. Olmedo, and S. Zanella Beguelin. Probabilistic Relational Reasoning for Differential Privacy. ACM SIGPLAN Notices, 47(1):97\u2013110, 2012.\n2. G. Barthe, G. Danezis, B. Gr\u00b4egoire, C. Kunz, and S. Zanella-Beguelin. Verified Computational Differential Privacy with Applications to Smart Metering. In 2013 IEEE 26th Computer Security Foundations Symposium, pages 287\u2013301. IEEE, 2013.\n3. G. Barthe, M. Gaboardi, E. J. G. Arias, J. Hsu, C. Kunz, and P.-Y. Strub. Proving differential privacy in Hoare logic. In 2014 IEEE 27th Computer Security Foundations Symposium, pages 411\u2013424. IEEE, 2014.\n4. R. Bhaskar, A. Bhowmick, V. Goyal, S. Laxman, and A. Thakurta. Noiseless Database Privacy. In International Conference on the Theory and Application of Cryptology and Information Security, pages 215\u2013232. Springer, 2011.\n5. B. Bichsel, S. Steffen, I. Bogunovic, and M. Vechev. DP-Sniper: Black-Box Discovery of Differential Privacy Violations using Classifiers. In 2021 IEEE Symposium on Security and Privacy (SP), pages 391\u2013409. IEEE, 2021.\n6. M. Bun and T. Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. In Theory of Cryptography Conference, pages 635\u2013658. Springer, 2016.\n7. M. Bun, J. Ullman, and S. Vadhan. Fingerprinting Codes and the Price of Approximate Differential Privacy. SIAM Journal on Computing, 47(5):1888\u20131938, 2018.\n8. N. Carlini, C. Liu, \u00b4U. Erlingsson, J. Kos, and D. Song. The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks. In USENIX Security Symposium, volume 267, 2019.\n9. N. Carlini, F. Tramer, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee, A. Roberts, T. Brown, D. Song, U. Erlingsson, A. Oprea, and C. Raffel. Extracting Training Data from Large Language Models. In 30th USENIX Security Symposium (USENIX Security 2021), 2021.\n10. N. Carlini, S. Chien, M. Nasr, S. Song, A. Terzis, and F. Tramer. Membership Inference Attacks from First Principles. In IEEE Symposium on Security and Privacy (SP), pages 1519\u20131519, Los Alamitos, CA, USA, May 2022. IEEE Computer Society. doi: 10.1109/SP46214.2022.00090. URL https://doi.ieeecomputersociety.org/10.1109/SP46214.2022.00090.\n11. N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tramer, and C. Zhang. Quantifying Memorization Across Neural Language Models. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=TatRHT_1cK.\n12. Y. Chen and A. Machanavajjhala. On the privacy properties of variants on the sparse vector technique. arXiv preprint arXiv:1508.07306, 2015.\n13. Z. Ding, Y. Wang, G. Wang, D. Zhang, and D. Kifer. Detecting violations of differential privacy. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 475\u2013489, 2018.\n14. K. Dixit, M. Jha, S. Raskhodnikova, and A. Thakurta. Testing Lipschitz Property over Product Distribution and its Applications to Statistical Data Privacy. In Theory of Cryptography Conference, pages 418\u2013436. Springer, 2013.\n15. W. C. DMDave, Todd B. Acquire valued shoppers challenge, 2014. URL https://kaggle.com/competitions/acquire-valued-shoppers-challenge.\n16. C. Dwork and G. N. Rothblum. Concentrated Differential Privacy. arXiv preprint arXiv:1603.01887, 2016."}]}, {"page": 13, "text": "[21] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating Noise to Sensitivity in Private Data\n     Analysis. In Proc. of the Third Conf. on Theory of Cryptography (TCC), pages 265\u2013284, 2006. URL\n     http://dx.doi.org/10.1007/11681878_14.\n[22] C. Dwork, A. Smith, T. Steinke, J. Ullman, and S. Vadhan. Robust Traceability from Trace Amounts. In\n     2015 IEEE 56th Annual Symposium on Foundations of Computer Science, pages 650\u2013669. IEEE, 2015.\n[23] M. Gaboardi, A. Haeberlen, J. Hsu, A. Narayan, and B. C. Pierce. Linear Dependent Types for\n     Differential Privacy.  In Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on\n     Principles of programming languages, pages 357\u2013370, 2013.\n[24] A. C. Gilbert and A. McMillan. Property Testing for Differential Privacy. In 2018 56th Annual Allerton\n     Conference on Communication, Control, and Computing (Allerton), pages 249\u2013258. IEEE, 2018.\n[25] C. Guo, B. Karrer, K. Chaudhuri, and L. van der Maaten. Bounding Training Data Reconstruction\n     in Private (Deep) Learning. In Proceedings of the 39th International Conference on Machine Learning,\n     volume 162 of Proceedings of Machine Learning Research, pages 8056\u20138071, 17\u201323 Jul 2022.\n[26] Y. Han, J. Jiao, and T. Weissman. Minimax estimation of divergences between discrete distributions.\n     IEEE Journal on Selected Areas in Information Theory, 1(3):814\u2013823, 2020.\n[27] A. Hannun, C. Guo, and L. van der Maaten. Measuring Data Leakage in Machine-Learning Models with\n     Fisher Information. In UAI, pages 760\u2013770, 2021.\n[28] J. Hayes, S. Mahloujifar, and B. Balle. Bounding Training Data Reconstruction in DP-SGD, 2023.\n[29] N. Homer, S. Szelinger, M. Redman, D. Duggan, W. Tembe, J. Muehling, J. V. Pearson, D. A. Stephan,\n     S. F. Nelson, and D. W. Craig. Resolving individuals contributing trace amounts of DNA to highly\n     complex mixtures using high-density SNP genotyping microarrays. PLoS genetics, 4(8):e1000167, 2008.\n[30] S. L. Hyland and S. Tople. An Empirical Study on the Intrinsic Privacy of SGD. arXiv preprint\n     arXiv:1912.02919, 2019.\n[31] M. Jagielski, J. Ullman, and A. Oprea. Auditing differentially private machine learning: How private is\n     private SGD? Advances in Neural Information Processing Systems, 33:22205\u201322216, 2020.\n[32] B. Jayaraman and D. Evans. Evaluating Differentially Private Machine Learning in Practice. In USENIX\n     Security Symposium, pages 1895\u20131912, 2019.\n[33] M. Johnson. fix prng key reuse in differential privacy example. https://github.com/google/jax/\n     pull/3646, 2020.\n[34] P. Kairouz, S. Oh, and P. Viswanath. The composition theorem for differential privacy. In International\n     conference on machine learning, pages 1376\u20131385. PMLR, 2015.\n[35] D. Kifer and A. Machanavajjhala. Pufferfish: A framework for mathematical privacy definitions. ACM\n     Transactions on Database Systems (TODS), 39(1):1\u201336, 2014.\n[36] T. Kutta, \u00a8O. Askin, and M. Dunsche. Lower Bounds for R\u00b4enyi Differential Privacy in a Black-Box\n     Setting. arXiv preprint arXiv:2212.04739, 2022.\n[37] X. Liu and S. Oh. Minimax Optimal Estimation of Approximate Differential Privacy on Neighboring\n     Databases. In Advances in Neural Information Processing Systems, volume 32, 2019.\n[38] F. Lu, J. Munoz, M. Fuchs, T. LeBlond, E. Zaresky-Williams, E. Raff, F. Ferraro, and B. Testa. A\n     General Framework for Auditing Differentially Private Machine Learning. In NeurIPS, 2022.\n                                                     13", "md": "# References\n\n## References\n\n1. C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating Noise to Sensitivity in Private Data Analysis. In Proc. of the Third Conf. on Theory of Cryptography (TCC), pages 265\u2013284, 2006. URL http://dx.doi.org/10.1007/11681878_14.\n2. C. Dwork, A. Smith, T. Steinke, J. Ullman, and S. Vadhan. Robust Traceability from Trace Amounts. In 2015 IEEE 56th Annual Symposium on Foundations of Computer Science, pages 650\u2013669. IEEE, 2015.\n3. M. Gaboardi, A. Haeberlen, J. Hsu, A. Narayan, and B. C. Pierce. Linear Dependent Types for Differential Privacy. In Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages 357\u2013370, 2013.\n4. A. C. Gilbert and A. McMillan. Property Testing for Differential Privacy. In 2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pages 249\u2013258. IEEE, 2018.\n5. C. Guo, B. Karrer, K. Chaudhuri, and L. van der Maaten. Bounding Training Data Reconstruction in Private (Deep) Learning. In Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 8056\u20138071, 17\u201323 Jul 2022.\n6. Y. Han, J. Jiao, and T. Weissman. Minimax estimation of divergences between discrete distributions. IEEE Journal on Selected Areas in Information Theory, 1(3):814\u2013823, 2020.\n7. A. Hannun, C. Guo, and L. van der Maaten. Measuring Data Leakage in Machine-Learning Models with Fisher Information. In UAI, pages 760\u2013770, 2021.\n8. J. Hayes, S. Mahloujifar, and B. Balle. Bounding Training Data Reconstruction in DP-SGD, 2023.\n9. N. Homer, S. Szelinger, M. Redman, D. Duggan, W. Tembe, J. Muehling, J. V. Pearson, D. A. Stephan, S. F. Nelson, and D. W. Craig. Resolving individuals contributing trace amounts of DNA to highly complex mixtures using high-density SNP genotyping microarrays. PLoS genetics, 4(8):e1000167, 2008.\n10. S. L. Hyland and S. Tople. An Empirical Study on the Intrinsic Privacy of SGD. arXiv preprint arXiv:1912.02919, 2019.\n11. M. Jagielski, J. Ullman, and A. Oprea. Auditing differentially private machine learning: How private is private SGD? Advances in Neural Information Processing Systems, 33:22205\u201322216, 2020.\n12. B. Jayaraman and D. Evans. Evaluating Differentially Private Machine Learning in Practice. In USENIX Security Symposium, pages 1895\u20131912, 2019.\n13. M. Johnson. fix prng key reuse in differential privacy example. https://github.com/google/jax/pull/3646, 2020.\n14. P. Kairouz, S. Oh, and P. Viswanath. The composition theorem for differential privacy. In International conference on machine learning, pages 1376\u20131385. PMLR, 2015.\n15. D. Kifer and A. Machanavajjhala. Pufferfish: A framework for mathematical privacy definitions. ACM Transactions on Database Systems (TODS), 39(1):1\u201336, 2014.\n16. T. Kutta, \u00a8O. Askin, and M. Dunsche. Lower Bounds for R\u00b4enyi Differential Privacy in a Black-Box Setting. arXiv preprint arXiv:2212.04739, 2022.\n17. X. Liu and S. Oh. Minimax Optimal Estimation of Approximate Differential Privacy on Neighboring Databases. In Advances in Neural Information Processing Systems, volume 32, 2019.\n18. F. Lu, J. Munoz, M. Fuchs, T. LeBlond, E. Zaresky-Williams, E. Raff, F. Ferraro, and B. Testa. A General Framework for Auditing Differentially Private Machine Learning. In NeurIPS, 2022.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 2, "value": "References", "md": "## References"}, {"type": "text", "value": "1. C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating Noise to Sensitivity in Private Data Analysis. In Proc. of the Third Conf. on Theory of Cryptography (TCC), pages 265\u2013284, 2006. URL http://dx.doi.org/10.1007/11681878_14.\n2. C. Dwork, A. Smith, T. Steinke, J. Ullman, and S. Vadhan. Robust Traceability from Trace Amounts. In 2015 IEEE 56th Annual Symposium on Foundations of Computer Science, pages 650\u2013669. IEEE, 2015.\n3. M. Gaboardi, A. Haeberlen, J. Hsu, A. Narayan, and B. C. Pierce. Linear Dependent Types for Differential Privacy. In Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages 357\u2013370, 2013.\n4. A. C. Gilbert and A. McMillan. Property Testing for Differential Privacy. In 2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pages 249\u2013258. IEEE, 2018.\n5. C. Guo, B. Karrer, K. Chaudhuri, and L. van der Maaten. Bounding Training Data Reconstruction in Private (Deep) Learning. In Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 8056\u20138071, 17\u201323 Jul 2022.\n6. Y. Han, J. Jiao, and T. Weissman. Minimax estimation of divergences between discrete distributions. IEEE Journal on Selected Areas in Information Theory, 1(3):814\u2013823, 2020.\n7. A. Hannun, C. Guo, and L. van der Maaten. Measuring Data Leakage in Machine-Learning Models with Fisher Information. In UAI, pages 760\u2013770, 2021.\n8. J. Hayes, S. Mahloujifar, and B. Balle. Bounding Training Data Reconstruction in DP-SGD, 2023.\n9. N. Homer, S. Szelinger, M. Redman, D. Duggan, W. Tembe, J. Muehling, J. V. Pearson, D. A. Stephan, S. F. Nelson, and D. W. Craig. Resolving individuals contributing trace amounts of DNA to highly complex mixtures using high-density SNP genotyping microarrays. PLoS genetics, 4(8):e1000167, 2008.\n10. S. L. Hyland and S. Tople. An Empirical Study on the Intrinsic Privacy of SGD. arXiv preprint arXiv:1912.02919, 2019.\n11. M. Jagielski, J. Ullman, and A. Oprea. Auditing differentially private machine learning: How private is private SGD? Advances in Neural Information Processing Systems, 33:22205\u201322216, 2020.\n12. B. Jayaraman and D. Evans. Evaluating Differentially Private Machine Learning in Practice. In USENIX Security Symposium, pages 1895\u20131912, 2019.\n13. M. Johnson. fix prng key reuse in differential privacy example. https://github.com/google/jax/pull/3646, 2020.\n14. P. Kairouz, S. Oh, and P. Viswanath. The composition theorem for differential privacy. In International conference on machine learning, pages 1376\u20131385. PMLR, 2015.\n15. D. Kifer and A. Machanavajjhala. Pufferfish: A framework for mathematical privacy definitions. ACM Transactions on Database Systems (TODS), 39(1):1\u201336, 2014.\n16. T. Kutta, \u00a8O. Askin, and M. Dunsche. Lower Bounds for R\u00b4enyi Differential Privacy in a Black-Box Setting. arXiv preprint arXiv:2212.04739, 2022.\n17. X. Liu and S. Oh. Minimax Optimal Estimation of Approximate Differential Privacy on Neighboring Databases. In Advances in Neural Information Processing Systems, volume 32, 2019.\n18. F. Lu, J. Munoz, M. Fuchs, T. LeBlond, E. Zaresky-Williams, E. Raff, F. Ferraro, and B. Testa. A General Framework for Auditing Differentially Private Machine Learning. In NeurIPS, 2022.", "md": "1. C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating Noise to Sensitivity in Private Data Analysis. In Proc. of the Third Conf. on Theory of Cryptography (TCC), pages 265\u2013284, 2006. URL http://dx.doi.org/10.1007/11681878_14.\n2. C. Dwork, A. Smith, T. Steinke, J. Ullman, and S. Vadhan. Robust Traceability from Trace Amounts. In 2015 IEEE 56th Annual Symposium on Foundations of Computer Science, pages 650\u2013669. IEEE, 2015.\n3. M. Gaboardi, A. Haeberlen, J. Hsu, A. Narayan, and B. C. Pierce. Linear Dependent Types for Differential Privacy. In Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages 357\u2013370, 2013.\n4. A. C. Gilbert and A. McMillan. Property Testing for Differential Privacy. In 2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pages 249\u2013258. IEEE, 2018.\n5. C. Guo, B. Karrer, K. Chaudhuri, and L. van der Maaten. Bounding Training Data Reconstruction in Private (Deep) Learning. In Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 8056\u20138071, 17\u201323 Jul 2022.\n6. Y. Han, J. Jiao, and T. Weissman. Minimax estimation of divergences between discrete distributions. IEEE Journal on Selected Areas in Information Theory, 1(3):814\u2013823, 2020.\n7. A. Hannun, C. Guo, and L. van der Maaten. Measuring Data Leakage in Machine-Learning Models with Fisher Information. In UAI, pages 760\u2013770, 2021.\n8. J. Hayes, S. Mahloujifar, and B. Balle. Bounding Training Data Reconstruction in DP-SGD, 2023.\n9. N. Homer, S. Szelinger, M. Redman, D. Duggan, W. Tembe, J. Muehling, J. V. Pearson, D. A. Stephan, S. F. Nelson, and D. W. Craig. Resolving individuals contributing trace amounts of DNA to highly complex mixtures using high-density SNP genotyping microarrays. PLoS genetics, 4(8):e1000167, 2008.\n10. S. L. Hyland and S. Tople. An Empirical Study on the Intrinsic Privacy of SGD. arXiv preprint arXiv:1912.02919, 2019.\n11. M. Jagielski, J. Ullman, and A. Oprea. Auditing differentially private machine learning: How private is private SGD? Advances in Neural Information Processing Systems, 33:22205\u201322216, 2020.\n12. B. Jayaraman and D. Evans. Evaluating Differentially Private Machine Learning in Practice. In USENIX Security Symposium, pages 1895\u20131912, 2019.\n13. M. Johnson. fix prng key reuse in differential privacy example. https://github.com/google/jax/pull/3646, 2020.\n14. P. Kairouz, S. Oh, and P. Viswanath. The composition theorem for differential privacy. In International conference on machine learning, pages 1376\u20131385. PMLR, 2015.\n15. D. Kifer and A. Machanavajjhala. Pufferfish: A framework for mathematical privacy definitions. ACM Transactions on Database Systems (TODS), 39(1):1\u201336, 2014.\n16. T. Kutta, \u00a8O. Askin, and M. Dunsche. Lower Bounds for R\u00b4enyi Differential Privacy in a Black-Box Setting. arXiv preprint arXiv:2212.04739, 2022.\n17. X. Liu and S. Oh. Minimax Optimal Estimation of Approximate Differential Privacy on Neighboring Databases. In Advances in Neural Information Processing Systems, volume 32, 2019.\n18. F. Lu, J. Munoz, M. Fuchs, T. LeBlond, E. Zaresky-Williams, E. Raff, F. Ferraro, and B. Testa. A General Framework for Auditing Differentially Private Machine Learning. In NeurIPS, 2022."}]}, {"page": 14, "text": "[39] M. Lyu, D. Su, and N. Li. Understanding the sparse vector technique for differential privacy. arXiv\n    preprint arXiv:1603.01699, 2016.\n[40] S. Maddock, A. Sablayrolles, and P. Stock. CANIFE: Crafting canaries for empirical privacy measurement\n    in federated learning. In ICLR, 2023.\n[41] M. Malek Esmaeili, I. Mironov, K. Prasad, I. Shilov, and F. Tramer. Antipodes of label differential\n    privacy: Pate and alibi. Advances in Neural Information Processing Systems, 34:6934\u20136945, 2021.\n[42] F. D. McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis.\n    In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, pages\n    19\u201330. ACM, 2009.\n[43] I. Mironov. R\u00b4\n                  enyi Differential Privacy. In 30th IEEE Computer Security Foundations Symposium, CSF\n    2017, Santa Barbara, CA, USA, August 21-25, 2017, pages 263\u2013275. IEEE Computer Society, 2017.\n[44] M. Nasr, S. Songi, A. Thakurta, N. Papernot, and N. Carlini. Adversary Instantiation: Lower Bounds\n    for Differentially Private Machine Learning. In 2021 IEEE Symposium on Security and Privacy (SP),\n    pages 866\u2013882. IEEE, 2021.\n[45] M. Nasr, J. Hayes, T. Steinke, B. Balle, F. Tram`er, M. Jagielski, N. Carlini, and A. Terzis. Tight\n    Auditing of Differentially Private Machine Learning. arXiv preprint arXiv:2302.07956, 2023.\n[46] M.      Park.               Bug-fix.               https://github.com/mijungi/vips_code/commit/\n    4e32042b66c960af618722a43c32f3f2dda2730c, 2018.\n[47] N. Ponomareva, H. Hazimeh, A. Kurakin, Z. Xu, C. Denison, H. B. McMahan, S. Vassilvitskii, S. Chien,\n    and A. Thakurta. How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy.\n    arXiv Preprint, 2023.\n[48] M. A. Rahman, T. Rahman, R. Lagani`    ere, N. Mohammed, and Y. Wang. Membership Inference Attack\n    against Differentially Private Deep Learning Model. Trans. Data Priv., 11(1):61\u201379, 2018.\n[49] J. Reed and B. C. Pierce. Distance makes the types grow stronger: a calculus for differential privacy. In\n    ACM Sigplan Notices, volume 45, pages 157\u2013168. ACM, 2010.\n[50] I. Roy, S. T. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat: Security and privacy for MapReduce.\n    In NSDI, volume 10, pages 297\u2013312, 2010.\n[51] S. Sankararaman, G. Obozinski, M. I. Jordan, and E. Halperin. Genomic privacy and limits of individual\n    detection in a pool. Nature genetics, 41(9):965\u2013967, 2009.\n[52] R. Shokri, M. Stronati, C. Song, and V. Shmatikov. Membership inference attacks against machine\n    learning models. In 2017 IEEE symposium on security and privacy (SP), pages 3\u201318. IEEE, 2017.\n[53] S. Song, K. Chaudhuri, and A. D. Sarwate. Stochastic gradient descent with differentially private updates.\n    In 2013 IEEE Global Conference on Signal and Information Processing, pages 245\u2013248. IEEE, 2013.\n[54] S. Song, Y. Wang, and K. Chaudhuri. Pufferfish privacy mechanisms for correlated data. In Proceedings\n    of the 2017 ACM International Conference on Management of Data, pages 1291\u20131306, 2017.\n[55] T. Steinke, M. Nasr, and M. Jagielski. Privacy auditing with one (1) training run. arXiv preprint\n    arXiv:2305.08846, 2023.\n[56] T. Stevens, I. C. Ngong, D. Darais, C. Hirsch, D. Slater, and J. P. Near. Backpropagation Clipping for\n    Deep Learning with Differential Privacy. arXiv preprint arXiv:2202.05089, 2022.\n                                                      14", "md": "1. M. Lyu, D. Su, and N. Li. Understanding the sparse vector technique for differential privacy. arXiv preprint arXiv:1603.01699, 2016.\n2. S. Maddock, A. Sablayrolles, and P. Stock. CANIFE: Crafting canaries for empirical privacy measurement in federated learning. In ICLR, 2023.\n3. M. Malek Esmaeili, I. Mironov, K. Prasad, I. Shilov, and F. Tramer. Antipodes of label differential privacy: Pate and alibi. Advances in Neural Information Processing Systems, 34:6934\u20136945, 2021.\n4. F. D. McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, pages 19\u201330. ACM, 2009.\n5. I. Mironov. $R\\acute{e}nyi$ Differential Privacy. In 30th IEEE Computer Security Foundations Symposium, CSF 2017, Santa Barbara, CA, USA, August 21-25, 2017, pages 263\u2013275. IEEE Computer Society, 2017.\n6. M. Nasr, S. Songi, A. Thakurta, N. Papernot, and N. Carlini. Adversary Instantiation: Lower Bounds for Differentially Private Machine Learning. In 2021 IEEE Symposium on Security and Privacy (SP), pages 866\u2013882. IEEE, 2021.\n7. M. Nasr, J. Hayes, T. Steinke, B. Balle, F. Tram\\`{e}r, M. Jagielski, N. Carlini, and A. Terzis. Tight Auditing of Differentially Private Machine Learning. arXiv preprint arXiv:2302.07956, 2023.\n8. M. Park. Bug-fix. https://github.com/mijungi/vips_code/commit/4e32042b66c960af618722a43c32f3f2dda2730c, 2018.\n9. N. Ponomareva, H. Hazimeh, A. Kurakin, Z. Xu, C. Denison, H. B. McMahan, S. Vassilvitskii, S. Chien, and A. Thakurta. How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy. arXiv Preprint, 2023.\n10. M. A. Rahman, T. Rahman, R. Lagani\\`{e}re, N. Mohammed, and Y. Wang. Membership Inference Attack against Differentially Private Deep Learning Model. Trans. Data Priv., 11(1):61\u201379, 2018.\n11. J. Reed and B. C. Pierce. Distance makes the types grow stronger: a calculus for differential privacy. In ACM Sigplan Notices, volume 45, pages 157\u2013168. ACM, 2010.\n12. I. Roy, S. T. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat: Security and privacy for MapReduce. In NSDI, volume 10, pages 297\u2013312, 2010.\n13. S. Sankararaman, G. Obozinski, M. I. Jordan, and E. Halperin. Genomic privacy and limits of individual detection in a pool. Nature genetics, 41(9):965\u2013967, 2009.\n14. R. Shokri, M. Stronati, C. Song, and V. Shmatikov. Membership inference attacks against machine learning models. In 2017 IEEE symposium on security and privacy (SP), pages 3\u201318. IEEE, 2017.\n15. S. Song, K. Chaudhuri, and A. D. Sarwate. Stochastic gradient descent with differentially private updates. In 2013 IEEE Global Conference on Signal and Information Processing, pages 245\u2013248. IEEE, 2013.\n16. S. Song, Y. Wang, and K. Chaudhuri. Pufferfish privacy mechanisms for correlated data. In Proceedings of the 2017 ACM International Conference on Management of Data, pages 1291\u20131306, 2017.\n17. T. Steinke, M. Nasr, and M. Jagielski. Privacy auditing with one (1) training run. arXiv preprint arXiv:2305.08846, 2023.\n18. T. Stevens, I. C. Ngong, D. Darais, C. Hirsch, D. Slater, and J. P. Near. Backpropagation Clipping for Deep Learning with Differential Privacy. arXiv preprint arXiv:2202.05089, 2022.", "images": [], "items": [{"type": "text", "value": "1. M. Lyu, D. Su, and N. Li. Understanding the sparse vector technique for differential privacy. arXiv preprint arXiv:1603.01699, 2016.\n2. S. Maddock, A. Sablayrolles, and P. Stock. CANIFE: Crafting canaries for empirical privacy measurement in federated learning. In ICLR, 2023.\n3. M. Malek Esmaeili, I. Mironov, K. Prasad, I. Shilov, and F. Tramer. Antipodes of label differential privacy: Pate and alibi. Advances in Neural Information Processing Systems, 34:6934\u20136945, 2021.\n4. F. D. McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, pages 19\u201330. ACM, 2009.\n5. I. Mironov. $R\\acute{e}nyi$ Differential Privacy. In 30th IEEE Computer Security Foundations Symposium, CSF 2017, Santa Barbara, CA, USA, August 21-25, 2017, pages 263\u2013275. IEEE Computer Society, 2017.\n6. M. Nasr, S. Songi, A. Thakurta, N. Papernot, and N. Carlini. Adversary Instantiation: Lower Bounds for Differentially Private Machine Learning. In 2021 IEEE Symposium on Security and Privacy (SP), pages 866\u2013882. IEEE, 2021.\n7. M. Nasr, J. Hayes, T. Steinke, B. Balle, F. Tram\\`{e}r, M. Jagielski, N. Carlini, and A. Terzis. Tight Auditing of Differentially Private Machine Learning. arXiv preprint arXiv:2302.07956, 2023.\n8. M. Park. Bug-fix. https://github.com/mijungi/vips_code/commit/4e32042b66c960af618722a43c32f3f2dda2730c, 2018.\n9. N. Ponomareva, H. Hazimeh, A. Kurakin, Z. Xu, C. Denison, H. B. McMahan, S. Vassilvitskii, S. Chien, and A. Thakurta. How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy. arXiv Preprint, 2023.\n10. M. A. Rahman, T. Rahman, R. Lagani\\`{e}re, N. Mohammed, and Y. Wang. Membership Inference Attack against Differentially Private Deep Learning Model. Trans. Data Priv., 11(1):61\u201379, 2018.\n11. J. Reed and B. C. Pierce. Distance makes the types grow stronger: a calculus for differential privacy. In ACM Sigplan Notices, volume 45, pages 157\u2013168. ACM, 2010.\n12. I. Roy, S. T. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat: Security and privacy for MapReduce. In NSDI, volume 10, pages 297\u2013312, 2010.\n13. S. Sankararaman, G. Obozinski, M. I. Jordan, and E. Halperin. Genomic privacy and limits of individual detection in a pool. Nature genetics, 41(9):965\u2013967, 2009.\n14. R. Shokri, M. Stronati, C. Song, and V. Shmatikov. Membership inference attacks against machine learning models. In 2017 IEEE symposium on security and privacy (SP), pages 3\u201318. IEEE, 2017.\n15. S. Song, K. Chaudhuri, and A. D. Sarwate. Stochastic gradient descent with differentially private updates. In 2013 IEEE Global Conference on Signal and Information Processing, pages 245\u2013248. IEEE, 2013.\n16. S. Song, Y. Wang, and K. Chaudhuri. Pufferfish privacy mechanisms for correlated data. In Proceedings of the 2017 ACM International Conference on Management of Data, pages 1291\u20131306, 2017.\n17. T. Steinke, M. Nasr, and M. Jagielski. Privacy auditing with one (1) training run. arXiv preprint arXiv:2305.08846, 2023.\n18. T. Stevens, I. C. Ngong, D. Darais, C. Hirsch, D. Slater, and J. P. Near. Backpropagation Clipping for Deep Learning with Differential Privacy. arXiv preprint arXiv:2202.05089, 2022.", "md": "1. M. Lyu, D. Su, and N. Li. Understanding the sparse vector technique for differential privacy. arXiv preprint arXiv:1603.01699, 2016.\n2. S. Maddock, A. Sablayrolles, and P. Stock. CANIFE: Crafting canaries for empirical privacy measurement in federated learning. In ICLR, 2023.\n3. M. Malek Esmaeili, I. Mironov, K. Prasad, I. Shilov, and F. Tramer. Antipodes of label differential privacy: Pate and alibi. Advances in Neural Information Processing Systems, 34:6934\u20136945, 2021.\n4. F. D. McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, pages 19\u201330. ACM, 2009.\n5. I. Mironov. $R\\acute{e}nyi$ Differential Privacy. In 30th IEEE Computer Security Foundations Symposium, CSF 2017, Santa Barbara, CA, USA, August 21-25, 2017, pages 263\u2013275. IEEE Computer Society, 2017.\n6. M. Nasr, S. Songi, A. Thakurta, N. Papernot, and N. Carlini. Adversary Instantiation: Lower Bounds for Differentially Private Machine Learning. In 2021 IEEE Symposium on Security and Privacy (SP), pages 866\u2013882. IEEE, 2021.\n7. M. Nasr, J. Hayes, T. Steinke, B. Balle, F. Tram\\`{e}r, M. Jagielski, N. Carlini, and A. Terzis. Tight Auditing of Differentially Private Machine Learning. arXiv preprint arXiv:2302.07956, 2023.\n8. M. Park. Bug-fix. https://github.com/mijungi/vips_code/commit/4e32042b66c960af618722a43c32f3f2dda2730c, 2018.\n9. N. Ponomareva, H. Hazimeh, A. Kurakin, Z. Xu, C. Denison, H. B. McMahan, S. Vassilvitskii, S. Chien, and A. Thakurta. How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy. arXiv Preprint, 2023.\n10. M. A. Rahman, T. Rahman, R. Lagani\\`{e}re, N. Mohammed, and Y. Wang. Membership Inference Attack against Differentially Private Deep Learning Model. Trans. Data Priv., 11(1):61\u201379, 2018.\n11. J. Reed and B. C. Pierce. Distance makes the types grow stronger: a calculus for differential privacy. In ACM Sigplan Notices, volume 45, pages 157\u2013168. ACM, 2010.\n12. I. Roy, S. T. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat: Security and privacy for MapReduce. In NSDI, volume 10, pages 297\u2013312, 2010.\n13. S. Sankararaman, G. Obozinski, M. I. Jordan, and E. Halperin. Genomic privacy and limits of individual detection in a pool. Nature genetics, 41(9):965\u2013967, 2009.\n14. R. Shokri, M. Stronati, C. Song, and V. Shmatikov. Membership inference attacks against machine learning models. In 2017 IEEE symposium on security and privacy (SP), pages 3\u201318. IEEE, 2017.\n15. S. Song, K. Chaudhuri, and A. D. Sarwate. Stochastic gradient descent with differentially private updates. In 2013 IEEE Global Conference on Signal and Information Processing, pages 245\u2013248. IEEE, 2013.\n16. S. Song, Y. Wang, and K. Chaudhuri. Pufferfish privacy mechanisms for correlated data. In Proceedings of the 2017 ACM International Conference on Management of Data, pages 1291\u20131306, 2017.\n17. T. Steinke, M. Nasr, and M. Jagielski. Privacy auditing with one (1) training run. arXiv preprint arXiv:2305.08846, 2023.\n18. T. Stevens, I. C. Ngong, D. Darais, C. Hirsch, D. Slater, and J. P. Near. Backpropagation Clipping for Deep Learning with Differential Privacy. arXiv preprint arXiv:2202.05089, 2022."}]}, {"page": 15, "text": "[57] F. Tramer. Tensorflow privacy issue #153: Incorrect comparison between privacy amplification by\n     iteration and DP-SGD. https://github.com/tensorflow/privacy/issues/153, 2020.\n[58] F. Tram`er, R. Shokri, A. San Joaquin, H. Le, M. Jagielski, S. Hong, and N. Carlini. Truth Serum:\n     Poisoning Machine Learning Models to Reveal Their Secrets. In Proceedings of the 2022 ACM SIGSAC\n    Conference on Computer and Communications Security, CCS \u201922, page 2779\u20132792, New York, NY, USA,\n     2022. Association for Computing Machinery. ISBN 9781450394505. doi: 10.1145/3548606.3560554. URL\n     https://doi.org/10.1145/3548606.3560554.\n[59] F. Tramer, A. Terzis, T. Steinke, S. Song, M. Jagielski, and N. Carlini. Debugging differential privacy:\n     A case study for privacy auditing. arXiv preprint arXiv:2202.12219, 2022.\n[60] A. Triastcyn and B. Faltings. Bayesian Differential Privacy for Machine Learning. In International\n    Conference on Machine Learning, pages 9583\u20139592. PMLR, 2020.\n[61] M. C. Tschantz, D. Kaynar, and A. Datta. Formal verification of differential privacy for interactive\n     systems. Electronic Notes in Theoretical Computer Science, 276:61\u201379, 2011.\n[62] S. Vadhan. The complexity of differential privacy. In Tutorials on the Foundations of Cryptography,\n     pages 347\u2013450. Springer, 2017.\n[63] G. Valiant and P. Valiant. Estimating the unseen: improved estimators for entropy and other properties.\n     Journal of the ACM (JACM), 64(6):1\u201341, 2017.\n[64] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine\n     Learning Algorithms. arXiv Preprint, 2017.\n[65] B. Yang, I. Sato, and H. Nakagawa. Bayesian Differential Privacy on Correlated Data. In Proceedings of\n     the 2015 ACM SIGMOD international conference on Management of Data, pages 747\u2013762, 2015.\n[66] J. Ye, A. Maddi, S. K. Murakonda, V. Bindschaedler, and R. Shokri. Enhanced Membership Inference\n     Attacks against Machine Learning Models. arXiv preprint arXiv:2111.09679, 2021.\n[67] S. Yeom, I. Giacomelli, M. Fredrikson, and S. Jha. Privacy Risk in Machine Learning: Analyzing the\n     Connection to Overfitting. In 2018 IEEE 31st computer security foundations symposium (CSF), pages\n     268\u2013282. IEEE, 2018.\n[68] S. Zanella-B\u00b4eguelin, L. Wutschitz, S. Tople, A. Salem, V. R\u00a8   uhle, A. Paverd, M. Naseri, and B. K\u00a8   opf.\n     Bayesian Estimation of Differential Privacy. arXiv preprint arXiv:2206.05199, 2022.\n                                                       15", "md": "# References\n\n## References\n\n[57] F. Tramer. Tensorflow privacy issue #153: Incorrect comparison between privacy amplification by\niteration and DP-SGD. Link, 2020.\n\n[58] F. Tram`er, R. Shokri, A. San Joaquin, H. Le, M. Jagielski, S. Hong, and N. Carlini. Truth Serum:\nPoisoning Machine Learning Models to Reveal Their Secrets. In Proceedings of the 2022 ACM SIGSAC\nConference on Computer and Communications Security, CCS \u201922, page 2779\u20132792, New York, NY, USA,\n2022. Association for Computing Machinery. ISBN 9781450394505. doi: 10.1145/3548606.3560554. URL\nLink.\n\n[59] F. Tramer, A. Terzis, T. Steinke, S. Song, M. Jagielski, and N. Carlini. Debugging differential privacy:\nA case study for privacy auditing. arXiv preprint arXiv:2202.12219, 2022.\n\n[60] A. Triastcyn and B. Faltings. Bayesian Differential Privacy for Machine Learning. In International\nConference on Machine Learning, pages 9583\u20139592. PMLR, 2020.\n\n[61] M. C. Tschantz, D. Kaynar, and A. Datta. Formal verification of differential privacy for interactive\nsystems. Electronic Notes in Theoretical Computer Science, 276:61\u201379, 2011.\n\n[62] S. Vadhan. The complexity of differential privacy. In Tutorials on the Foundations of Cryptography,\npages 347\u2013450. Springer, 2017.\n\n[63] G. Valiant and P. Valiant. Estimating the unseen: improved estimators for entropy and other properties.\nJournal of the ACM (JACM), 64(6):1\u201341, 2017.\n\n[64] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine\nLearning Algorithms. arXiv Preprint, 2017.\n\n[65] B. Yang, I. Sato, and H. Nakagawa. Bayesian Differential Privacy on Correlated Data. In Proceedings of\nthe 2015 ACM SIGMOD international conference on Management of Data, pages 747\u2013762, 2015.\n\n[66] J. Ye, A. Maddi, S. K. Murakonda, V. Bindschaedler, and R. Shokri. Enhanced Membership Inference\nAttacks against Machine Learning Models. arXiv preprint arXiv:2111.09679, 2021.\n\n[67] S. Yeom, I. Giacomelli, M. Fredrikson, and S. Jha. Privacy Risk in Machine Learning: Analyzing the\nConnection to Overfitting. In 2018 IEEE 31st computer security foundations symposium (CSF), pages\n268\u2013282. IEEE, 2018.\n\n[68] S. Zanella-B\u00b4eguelin, L. Wutschitz, S. Tople, A. Salem, V. R\u00a8 uhle, A. Paverd, M. Naseri, and B. K\u00a8 opf.\nBayesian Estimation of Differential Privacy. arXiv preprint arXiv:2206.05199, 2022.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "References", "md": "# References"}, {"type": "heading", "lvl": 2, "value": "References", "md": "## References"}, {"type": "text", "value": "[57] F. Tramer. Tensorflow privacy issue #153: Incorrect comparison between privacy amplification by\niteration and DP-SGD. Link, 2020.\n\n[58] F. Tram`er, R. Shokri, A. San Joaquin, H. Le, M. Jagielski, S. Hong, and N. Carlini. Truth Serum:\nPoisoning Machine Learning Models to Reveal Their Secrets. In Proceedings of the 2022 ACM SIGSAC\nConference on Computer and Communications Security, CCS \u201922, page 2779\u20132792, New York, NY, USA,\n2022. Association for Computing Machinery. ISBN 9781450394505. doi: 10.1145/3548606.3560554. URL\nLink.\n\n[59] F. Tramer, A. Terzis, T. Steinke, S. Song, M. Jagielski, and N. Carlini. Debugging differential privacy:\nA case study for privacy auditing. arXiv preprint arXiv:2202.12219, 2022.\n\n[60] A. Triastcyn and B. Faltings. Bayesian Differential Privacy for Machine Learning. In International\nConference on Machine Learning, pages 9583\u20139592. PMLR, 2020.\n\n[61] M. C. Tschantz, D. Kaynar, and A. Datta. Formal verification of differential privacy for interactive\nsystems. Electronic Notes in Theoretical Computer Science, 276:61\u201379, 2011.\n\n[62] S. Vadhan. The complexity of differential privacy. In Tutorials on the Foundations of Cryptography,\npages 347\u2013450. Springer, 2017.\n\n[63] G. Valiant and P. Valiant. Estimating the unseen: improved estimators for entropy and other properties.\nJournal of the ACM (JACM), 64(6):1\u201341, 2017.\n\n[64] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine\nLearning Algorithms. arXiv Preprint, 2017.\n\n[65] B. Yang, I. Sato, and H. Nakagawa. Bayesian Differential Privacy on Correlated Data. In Proceedings of\nthe 2015 ACM SIGMOD international conference on Management of Data, pages 747\u2013762, 2015.\n\n[66] J. Ye, A. Maddi, S. K. Murakonda, V. Bindschaedler, and R. Shokri. Enhanced Membership Inference\nAttacks against Machine Learning Models. arXiv preprint arXiv:2111.09679, 2021.\n\n[67] S. Yeom, I. Giacomelli, M. Fredrikson, and S. Jha. Privacy Risk in Machine Learning: Analyzing the\nConnection to Overfitting. In 2018 IEEE 31st computer security foundations symposium (CSF), pages\n268\u2013282. IEEE, 2018.\n\n[68] S. Zanella-B\u00b4eguelin, L. Wutschitz, S. Tople, A. Salem, V. R\u00a8 uhle, A. Paverd, M. Naseri, and B. K\u00a8 opf.\nBayesian Estimation of Differential Privacy. arXiv preprint arXiv:2206.05199, 2022.", "md": "[57] F. Tramer. Tensorflow privacy issue #153: Incorrect comparison between privacy amplification by\niteration and DP-SGD. Link, 2020.\n\n[58] F. Tram`er, R. Shokri, A. San Joaquin, H. Le, M. Jagielski, S. Hong, and N. Carlini. Truth Serum:\nPoisoning Machine Learning Models to Reveal Their Secrets. In Proceedings of the 2022 ACM SIGSAC\nConference on Computer and Communications Security, CCS \u201922, page 2779\u20132792, New York, NY, USA,\n2022. Association for Computing Machinery. ISBN 9781450394505. doi: 10.1145/3548606.3560554. URL\nLink.\n\n[59] F. Tramer, A. Terzis, T. Steinke, S. Song, M. Jagielski, and N. Carlini. Debugging differential privacy:\nA case study for privacy auditing. arXiv preprint arXiv:2202.12219, 2022.\n\n[60] A. Triastcyn and B. Faltings. Bayesian Differential Privacy for Machine Learning. In International\nConference on Machine Learning, pages 9583\u20139592. PMLR, 2020.\n\n[61] M. C. Tschantz, D. Kaynar, and A. Datta. Formal verification of differential privacy for interactive\nsystems. Electronic Notes in Theoretical Computer Science, 276:61\u201379, 2011.\n\n[62] S. Vadhan. The complexity of differential privacy. In Tutorials on the Foundations of Cryptography,\npages 347\u2013450. Springer, 2017.\n\n[63] G. Valiant and P. Valiant. Estimating the unseen: improved estimators for entropy and other properties.\nJournal of the ACM (JACM), 64(6):1\u201341, 2017.\n\n[64] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine\nLearning Algorithms. arXiv Preprint, 2017.\n\n[65] B. Yang, I. Sato, and H. Nakagawa. Bayesian Differential Privacy on Correlated Data. In Proceedings of\nthe 2015 ACM SIGMOD international conference on Management of Data, pages 747\u2013762, 2015.\n\n[66] J. Ye, A. Maddi, S. K. Murakonda, V. Bindschaedler, and R. Shokri. Enhanced Membership Inference\nAttacks against Machine Learning Models. arXiv preprint arXiv:2111.09679, 2021.\n\n[67] S. Yeom, I. Giacomelli, M. Fredrikson, and S. Jha. Privacy Risk in Machine Learning: Analyzing the\nConnection to Overfitting. In 2018 IEEE 31st computer security foundations symposium (CSF), pages\n268\u2013282. IEEE, 2018.\n\n[68] S. Zanella-B\u00b4eguelin, L. Wutschitz, S. Tople, A. Salem, V. R\u00a8 uhle, A. Paverd, M. Naseri, and B. K\u00a8 opf.\nBayesian Estimation of Differential Privacy. arXiv preprint arXiv:2206.05199, 2022."}]}, {"page": 16, "text": "Appendix\n Table of Contents\n       A    Related Work                                                                                                  17\n           A.1 Auditing Private Machine Learning with Strong Canaries                . . . . . . . . . . . . . . . . . .  17\n           A.2 Improving Statistical Trade-offs in Auditing . . . . . . . . . . . . . . . . . . . . . . . . . .           18\n           A.3 Connections to Other Notions of Differential Privacy . . . . . . . . . . . . . . . . . . . . .             18\n       B    Properties of Lifted DP and Further Details                                                                   18\n           B.1   Equivalence Between DP and LiDP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .            18\n           B.2 Auditing LiDP with Different Notions of Neighborhood                . . . . . . . . . . . . . . . . . . .  19\n       C    Confidence Intervals for Exchangeable Bernoulli Means                                                         20\n           C.1   Non-Asymptotic Confidence Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .          21\n           C.2 Asymptotic Confidence Intervals          . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   23\n           C.3   Scaling of Higher-Order Bernstein Bounds (Proposition 4) . . . . . . . . . . . . . . . . . .             26\n       D    Canary Design for Lifted DP: Details                                                                          27\n           D.1 Data Poisoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .         28\n           D.2 Random Gradients . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .           28\n       E    Simulations with the Gaussian Mechanism: Details and More Results                                             29\n           E.1   Experiment Setup       . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   29\n           E.2   Additional Experimental Results        . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   31\n       F    Experiments: Details and More Results                                                                         31\n           F.1   Training Details: Datasets, Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .         31\n           F.2   DP and Auditing Setup        . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   32\n           F.3   Miscellaneous Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .      32\n           F.4   Additional Experimental Results        . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   32\n                                                                 16", "md": "# Appendix\n\n# Table of Contents\n\n- ## A Related Work\n\nA.1 Auditing Private Machine Learning with Strong Canaries\n\nA.2 Improving Statistical Trade-offs in Auditing\n\nA.3 Connections to Other Notions of Differential Privacy\n- ## B Properties of Lifted DP and Further Details\n\nB.1 Equivalence Between DP and LiDP\n\nB.2 Auditing LiDP with Different Notions of Neighborhood\n- ## C Confidence Intervals for Exchangeable Bernoulli Means\n\nC.1 Non-Asymptotic Confidence Intervals\n\nC.2 Asymptotic Confidence Intervals\n\nC.3 Scaling of Higher-Order Bernstein Bounds (Proposition 4)\n- ## D Canary Design for Lifted DP: Details\n\nD.1 Data Poisoning\n\nD.2 Random Gradients\n- ## E Simulations with the Gaussian Mechanism: Details and More Results\n\nE.1 Experiment Setup\n\nE.2 Additional Experimental Results\n- ## F Experiments: Details and More Results\n\nF.1 Training Details: Datasets, Models\n\nF.2 DP and Auditing Setup\n\nF.3 Miscellaneous Details\n\nF.4 Additional Experimental Results\n\n16", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Appendix", "md": "# Appendix"}, {"type": "heading", "lvl": 1, "value": "Table of Contents", "md": "# Table of Contents"}, {"type": "text", "value": "- ## A Related Work\n\nA.1 Auditing Private Machine Learning with Strong Canaries\n\nA.2 Improving Statistical Trade-offs in Auditing\n\nA.3 Connections to Other Notions of Differential Privacy\n- ## B Properties of Lifted DP and Further Details\n\nB.1 Equivalence Between DP and LiDP\n\nB.2 Auditing LiDP with Different Notions of Neighborhood\n- ## C Confidence Intervals for Exchangeable Bernoulli Means\n\nC.1 Non-Asymptotic Confidence Intervals\n\nC.2 Asymptotic Confidence Intervals\n\nC.3 Scaling of Higher-Order Bernstein Bounds (Proposition 4)\n- ## D Canary Design for Lifted DP: Details\n\nD.1 Data Poisoning\n\nD.2 Random Gradients\n- ## E Simulations with the Gaussian Mechanism: Details and More Results\n\nE.1 Experiment Setup\n\nE.2 Additional Experimental Results\n- ## F Experiments: Details and More Results\n\nF.1 Training Details: Datasets, Models\n\nF.2 DP and Auditing Setup\n\nF.3 Miscellaneous Details\n\nF.4 Additional Experimental Results\n\n16", "md": "- ## A Related Work\n\nA.1 Auditing Private Machine Learning with Strong Canaries\n\nA.2 Improving Statistical Trade-offs in Auditing\n\nA.3 Connections to Other Notions of Differential Privacy\n- ## B Properties of Lifted DP and Further Details\n\nB.1 Equivalence Between DP and LiDP\n\nB.2 Auditing LiDP with Different Notions of Neighborhood\n- ## C Confidence Intervals for Exchangeable Bernoulli Means\n\nC.1 Non-Asymptotic Confidence Intervals\n\nC.2 Asymptotic Confidence Intervals\n\nC.3 Scaling of Higher-Order Bernstein Bounds (Proposition 4)\n- ## D Canary Design for Lifted DP: Details\n\nD.1 Data Poisoning\n\nD.2 Random Gradients\n- ## E Simulations with the Gaussian Mechanism: Details and More Results\n\nE.1 Experiment Setup\n\nE.2 Additional Experimental Results\n- ## F Experiments: Details and More Results\n\nF.1 Training Details: Datasets, Models\n\nF.2 DP and Auditing Setup\n\nF.3 Miscellaneous Details\n\nF.4 Additional Experimental Results\n\n16"}]}, {"page": 17, "text": "A      Related Work\nPrior to [17], privacy auditing required some access to the description of the mechanism. [5\u20137, 23, 42, 49, 50, 61]\nprovide platforms with a specific set of functions to be used to implement the mechanism, where the end-to-end\nprivacy of the source code can be automatically verified. Closest to our setting is the work of [18], where\nstatistical testing was first proposed for privacy auditing, given access to an oracle that returns the exact\nprobability measure of the mechanism. However, the guarantee is only for a relaxed notion of DP from [8]\nand the run-time depends super-linearly on the size of the output domain.\n    The pioneering work of [17] was the first to propose practical methods to audit privacy claims given a\nblack-box access to a mechanism. The focus was on simple queries that do not involve any training of models.\nThis is motivated by [16, 39], where even simple mechanisms falsely reported privacy guarantees. For such\nmechanisms, sampling a large number, say 500, 000 in [17], of outputs is computationally easy, and no effort\nwas made in [17] to improve the statistical trade-off. However, for private learning algorithms, training such\na large number of models is computationally prohibitive. The main focus of our framework is to improve this\nstatistical trade-off for auditing privacy. We first survey recent breakthroughs in designing stronger canaries,\nwhich is orthogonal to our main focus.\nA.1      Auditing Private Machine Learning with Strong Canaries\nRecent breakthroughs in auditing are accelerated by advances in privacy attacks, in particular membership\ninference. An attacker performing membership inference would like to determine if a particular data sample\nwas part of the training set. Early work on membership inference [11, 22, 29, 51] considered algorithms for\nstatistical methods, and more recent work demonstrates black-box attacks on ML algorithms [14, 32, 52, 66, 67].\n[32] compares different notions of privacy by measuring privacy empirically for the composition of differential\nprivacy [34], concentrated differential privacy [10, 20], and R\u00b4enyi differential privacy [43]. This is motivated\nby [48], which compares different DP mechanisms by measuring the success rates of membership inference\nattacks. [30] attempts to measure the intrinsic privacy of stochastic gradient descent (without additional\nnoise as in DP-SGD) using canary designs from membership inference attacks. Membership inference attacks\nhave been shown to have higher success when the adversary can poison the training dataset [58].\n    A more devastating privacy attack is the extraction or reconstruction of the training data, which is\nparticularly relevant for generative models such as large language models (LLMs). Several papers showed\nthat LLMs tend to memorize their training data [13, 15], allowing an adversary to prompt the generative\nmodels and extract samples of the training set. The connection between the ability of an attacker to perform\ntraining data reconstruction and DP guarantees has been shown in recent work [25, 28].\n    When performing privacy auditing, a stronger canary design increases the success of the adversary in the\ndistinguishing test and improves the empirical privacy bounds. The resulting hypothesis test can tolerate\nlarger confidence intervals and requires less number of samples. Recent advances in privacy auditing have\nfocused on designing such stronger canaries. [31] designs data poisoning canaries, in the direction of the\nlowest variance of the training data. This makes the canary out of distribution, making it easier to detect.\n[44] proposes attack surfaces of varying capabilities. For example, a gradient attack canary returns a gradient\nof choice when accessed by DP-SGD. It is shown that, with more powerful attacks, the canaries become\nstronger and the lower bounds become higher. [59] proposes using an example from the baseline training\ndataset, after changing the label, and introduces a search procedure to find a strong canary. More recently,\n[45] proposes a significantly improved auditing scheme for DP-SGD under a white-box access model where (i)\nthe auditor knows that the underlying mechanism is DP-SGD with a spherical Gaussian noise with unknown\nvariance, and (ii) all intermediate models are revealed. Since each coordinate of the model update provides\nan independent sample from the same Gaussian distribution, sample complexity is dramatically improved.\n[40] proposes CANIFE, a novel canary design method that finds a strong data poisoning canary adaptively\nunder the federated learning scenario.\n    Prior work in this space shows that privacy auditing can be performed via privacy attacks, such as\nmembership inference or reconstruction, and strong canary design results in better empirical privacy bounds.\nWe emphasize that our aim is not to innovate on optimizing canary design for performing privacy auditing.\n                                                        17", "md": "# Related Work\n\n## Related Work\n\nPrior to [17], privacy auditing required some access to the description of the mechanism. [5\u20137, 23, 42, 49, 50, 61] provide platforms with a specific set of functions to be used to implement the mechanism, where the end-to-end privacy of the source code can be automatically verified. Closest to our setting is the work of [18], where statistical testing was first proposed for privacy auditing, given access to an oracle that returns the exact probability measure of the mechanism. However, the guarantee is only for a relaxed notion of DP from [8] and the run-time depends super-linearly on the size of the output domain.\n\nThe pioneering work of [17] was the first to propose practical methods to audit privacy claims given a black-box access to a mechanism. The focus was on simple queries that do not involve any training of models. This is motivated by [16, 39], where even simple mechanisms falsely reported privacy guarantees. For such mechanisms, sampling a large number, say 500,000 in [17], of outputs is computationally easy, and no effort was made in [17] to improve the statistical trade-off. However, for private learning algorithms, training such a large number of models is computationally prohibitive. The main focus of our framework is to improve this statistical trade-off for auditing privacy. We first survey recent breakthroughs in designing stronger canaries, which is orthogonal to our main focus.\n\n### Auditing Private Machine Learning with Strong Canaries\n\nRecent breakthroughs in auditing are accelerated by advances in privacy attacks, in particular membership inference. An attacker performing membership inference would like to determine if a particular data sample was part of the training set. Early work on membership inference [11, 22, 29, 51] considered algorithms for statistical methods, and more recent work demonstrates black-box attacks on ML algorithms [14, 32, 52, 66, 67]. [32] compares different notions of privacy by measuring privacy empirically for the composition of differential privacy [34], concentrated differential privacy [10, 20], and R\u00e9nyi differential privacy [43]. This is motivated by [48], which compares different DP mechanisms by measuring the success rates of membership inference attacks. [30] attempts to measure the intrinsic privacy of stochastic gradient descent (without additional noise as in DP-SGD) using canary designs from membership inference attacks. Membership inference attacks have been shown to have higher success when the adversary can poison the training dataset [58].\n\nA more devastating privacy attack is the extraction or reconstruction of the training data, which is particularly relevant for generative models such as large language models (LLMs). Several papers showed that LLMs tend to memorize their training data [13, 15], allowing an adversary to prompt the generative models and extract samples of the training set. The connection between the ability of an attacker to perform training data reconstruction and DP guarantees has been shown in recent work [25, 28].\n\nWhen performing privacy auditing, a stronger canary design increases the success of the adversary in the distinguishing test and improves the empirical privacy bounds. The resulting hypothesis test can tolerate larger confidence intervals and requires less number of samples. Recent advances in privacy auditing have focused on designing such stronger canaries. [31] designs data poisoning canaries, in the direction of the lowest variance of the training data. This makes the canary out of distribution, making it easier to detect. [44] proposes attack surfaces of varying capabilities. For example, a gradient attack canary returns a gradient of choice when accessed by DP-SGD. It is shown that, with more powerful attacks, the canaries become stronger and the lower bounds become higher. [59] proposes using an example from the baseline training dataset, after changing the label, and introduces a search procedure to find a strong canary. More recently, [45] proposes a significantly improved auditing scheme for DP-SGD under a white-box access model where (i) the auditor knows that the underlying mechanism is DP-SGD with a spherical Gaussian noise with unknown variance, and (ii) all intermediate models are revealed. Since each coordinate of the model update provides an independent sample from the same Gaussian distribution, sample complexity is dramatically improved. [40] proposes CANIFE, a novel canary design method that finds a strong data poisoning canary adaptively under the federated learning scenario.\n\nPrior work in this space shows that privacy auditing can be performed via privacy attacks, such as membership inference or reconstruction, and strong canary design results in better empirical privacy bounds. We emphasize that our aim is not to innovate on optimizing canary design for performing privacy auditing.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Related Work", "md": "# Related Work"}, {"type": "heading", "lvl": 2, "value": "Related Work", "md": "## Related Work"}, {"type": "text", "value": "Prior to [17], privacy auditing required some access to the description of the mechanism. [5\u20137, 23, 42, 49, 50, 61] provide platforms with a specific set of functions to be used to implement the mechanism, where the end-to-end privacy of the source code can be automatically verified. Closest to our setting is the work of [18], where statistical testing was first proposed for privacy auditing, given access to an oracle that returns the exact probability measure of the mechanism. However, the guarantee is only for a relaxed notion of DP from [8] and the run-time depends super-linearly on the size of the output domain.\n\nThe pioneering work of [17] was the first to propose practical methods to audit privacy claims given a black-box access to a mechanism. The focus was on simple queries that do not involve any training of models. This is motivated by [16, 39], where even simple mechanisms falsely reported privacy guarantees. For such mechanisms, sampling a large number, say 500,000 in [17], of outputs is computationally easy, and no effort was made in [17] to improve the statistical trade-off. However, for private learning algorithms, training such a large number of models is computationally prohibitive. The main focus of our framework is to improve this statistical trade-off for auditing privacy. We first survey recent breakthroughs in designing stronger canaries, which is orthogonal to our main focus.", "md": "Prior to [17], privacy auditing required some access to the description of the mechanism. [5\u20137, 23, 42, 49, 50, 61] provide platforms with a specific set of functions to be used to implement the mechanism, where the end-to-end privacy of the source code can be automatically verified. Closest to our setting is the work of [18], where statistical testing was first proposed for privacy auditing, given access to an oracle that returns the exact probability measure of the mechanism. However, the guarantee is only for a relaxed notion of DP from [8] and the run-time depends super-linearly on the size of the output domain.\n\nThe pioneering work of [17] was the first to propose practical methods to audit privacy claims given a black-box access to a mechanism. The focus was on simple queries that do not involve any training of models. This is motivated by [16, 39], where even simple mechanisms falsely reported privacy guarantees. For such mechanisms, sampling a large number, say 500,000 in [17], of outputs is computationally easy, and no effort was made in [17] to improve the statistical trade-off. However, for private learning algorithms, training such a large number of models is computationally prohibitive. The main focus of our framework is to improve this statistical trade-off for auditing privacy. We first survey recent breakthroughs in designing stronger canaries, which is orthogonal to our main focus."}, {"type": "heading", "lvl": 3, "value": "Auditing Private Machine Learning with Strong Canaries", "md": "### Auditing Private Machine Learning with Strong Canaries"}, {"type": "text", "value": "Recent breakthroughs in auditing are accelerated by advances in privacy attacks, in particular membership inference. An attacker performing membership inference would like to determine if a particular data sample was part of the training set. Early work on membership inference [11, 22, 29, 51] considered algorithms for statistical methods, and more recent work demonstrates black-box attacks on ML algorithms [14, 32, 52, 66, 67]. [32] compares different notions of privacy by measuring privacy empirically for the composition of differential privacy [34], concentrated differential privacy [10, 20], and R\u00e9nyi differential privacy [43]. This is motivated by [48], which compares different DP mechanisms by measuring the success rates of membership inference attacks. [30] attempts to measure the intrinsic privacy of stochastic gradient descent (without additional noise as in DP-SGD) using canary designs from membership inference attacks. Membership inference attacks have been shown to have higher success when the adversary can poison the training dataset [58].\n\nA more devastating privacy attack is the extraction or reconstruction of the training data, which is particularly relevant for generative models such as large language models (LLMs). Several papers showed that LLMs tend to memorize their training data [13, 15], allowing an adversary to prompt the generative models and extract samples of the training set. The connection between the ability of an attacker to perform training data reconstruction and DP guarantees has been shown in recent work [25, 28].\n\nWhen performing privacy auditing, a stronger canary design increases the success of the adversary in the distinguishing test and improves the empirical privacy bounds. The resulting hypothesis test can tolerate larger confidence intervals and requires less number of samples. Recent advances in privacy auditing have focused on designing such stronger canaries. [31] designs data poisoning canaries, in the direction of the lowest variance of the training data. This makes the canary out of distribution, making it easier to detect. [44] proposes attack surfaces of varying capabilities. For example, a gradient attack canary returns a gradient of choice when accessed by DP-SGD. It is shown that, with more powerful attacks, the canaries become stronger and the lower bounds become higher. [59] proposes using an example from the baseline training dataset, after changing the label, and introduces a search procedure to find a strong canary. More recently, [45] proposes a significantly improved auditing scheme for DP-SGD under a white-box access model where (i) the auditor knows that the underlying mechanism is DP-SGD with a spherical Gaussian noise with unknown variance, and (ii) all intermediate models are revealed. Since each coordinate of the model update provides an independent sample from the same Gaussian distribution, sample complexity is dramatically improved. [40] proposes CANIFE, a novel canary design method that finds a strong data poisoning canary adaptively under the federated learning scenario.\n\nPrior work in this space shows that privacy auditing can be performed via privacy attacks, such as membership inference or reconstruction, and strong canary design results in better empirical privacy bounds. We emphasize that our aim is not to innovate on optimizing canary design for performing privacy auditing.", "md": "Recent breakthroughs in auditing are accelerated by advances in privacy attacks, in particular membership inference. An attacker performing membership inference would like to determine if a particular data sample was part of the training set. Early work on membership inference [11, 22, 29, 51] considered algorithms for statistical methods, and more recent work demonstrates black-box attacks on ML algorithms [14, 32, 52, 66, 67]. [32] compares different notions of privacy by measuring privacy empirically for the composition of differential privacy [34], concentrated differential privacy [10, 20], and R\u00e9nyi differential privacy [43]. This is motivated by [48], which compares different DP mechanisms by measuring the success rates of membership inference attacks. [30] attempts to measure the intrinsic privacy of stochastic gradient descent (without additional noise as in DP-SGD) using canary designs from membership inference attacks. Membership inference attacks have been shown to have higher success when the adversary can poison the training dataset [58].\n\nA more devastating privacy attack is the extraction or reconstruction of the training data, which is particularly relevant for generative models such as large language models (LLMs). Several papers showed that LLMs tend to memorize their training data [13, 15], allowing an adversary to prompt the generative models and extract samples of the training set. The connection between the ability of an attacker to perform training data reconstruction and DP guarantees has been shown in recent work [25, 28].\n\nWhen performing privacy auditing, a stronger canary design increases the success of the adversary in the distinguishing test and improves the empirical privacy bounds. The resulting hypothesis test can tolerate larger confidence intervals and requires less number of samples. Recent advances in privacy auditing have focused on designing such stronger canaries. [31] designs data poisoning canaries, in the direction of the lowest variance of the training data. This makes the canary out of distribution, making it easier to detect. [44] proposes attack surfaces of varying capabilities. For example, a gradient attack canary returns a gradient of choice when accessed by DP-SGD. It is shown that, with more powerful attacks, the canaries become stronger and the lower bounds become higher. [59] proposes using an example from the baseline training dataset, after changing the label, and introduces a search procedure to find a strong canary. More recently, [45] proposes a significantly improved auditing scheme for DP-SGD under a white-box access model where (i) the auditor knows that the underlying mechanism is DP-SGD with a spherical Gaussian noise with unknown variance, and (ii) all intermediate models are revealed. Since each coordinate of the model update provides an independent sample from the same Gaussian distribution, sample complexity is dramatically improved. [40] proposes CANIFE, a novel canary design method that finds a strong data poisoning canary adaptively under the federated learning scenario.\n\nPrior work in this space shows that privacy auditing can be performed via privacy attacks, such as membership inference or reconstruction, and strong canary design results in better empirical privacy bounds. We emphasize that our aim is not to innovate on optimizing canary design for performing privacy auditing."}]}, {"page": 18, "text": " Instead, our framework can seamlessly adopt recently designed canaries and inherit their strengths as\n demonstrated in \u00a75 and \u00a76.\n A.2     Improving Statistical Trade-offs in Auditing\n Eq. (2) points to two orthogonal directions that can potentially improve the sample dependence: designing\n stronger canaries and improving the sample dependence of the confidence intervals. The former was addressed\n in the previous section. There is relatively less work in improving the statistical dependence, which our\n framework focuses on.\n     Given a pair of neighboring datasets, (D0, D1), and for a query with discrete output in a finite space,\n the statistical trade-off of estimating privacy parameters was studied in [24] where a plug-in estimator is\n shown to achieve an error of O(       de2\u03b5/n), where d is the size of the discrete output space. [37] proposes a\n sub-linear sample complexity algorithm that achieves an error scaling as          de\u03b5/n log n, based on polynomial\n approximation of a carefully chosen degree to optimally trade-off bias and variance motivated by [26, 63].\n Similarly, [36] provides a lower bound for auditing R\u00b4enyi differential privacy. [9] trains a classifier for the\n binary hypothesis test and uses the classifier to design rejection sets. [3] proposes local search to find the\n rejection set efficiently. More recently, [68] proposes numerical integration over a larger space of false positive\n rate and true positive rate to achieve better sample complexity of the confidence region in the two-dimensional\n space. Our framework can be potentially applied to this confidence region scenario, which is an important\n future research direction.\n A.3     Connections to Other Notions of Differential Privacy\n Similar to Lifted DP, a line of prior works [35, 54, 60, 65] generalizes DP to include a distributional assumption\n over the dataset. However, unlike Lifted DP, they are motivated by the observation that DP is not sufficient\n for preserving privacy when the samples are highly correlated. For example, upon releasing the number of\n people infected with a highly contagious flu within a tight-knit community, the usual Laplace mechanism\n(with sensitivity one) is not sufficient to conceal the likelihood of one member getting infected when the\n private count is significantly high. One could apply group differential privacy to hide the contagion of the\n entire population, but this will suffer from excessive noise. Ideally, we want to add a noise proportional to\n the expected size of the infection. Pufferfish privacy, introduced in [35], achieves this with a generalization of\n DP that takes into account prior knowledge of a class of potential distributions over the dataset. A special\n case of \u03b5-Pufferfish with a specific choice of parameters recovers a special case of our Lifted DP in Eq. (3)\n with \u03b4 = 0 [35, Section 3.2], where a special case of Theorem 3 has been proven for pure DP [35, Theorem\n 3.1]. However, we want to emphasize that our Lifted DP is motivated by a completely different problem of\n auditing differential privacy and is critical to breaking the barriers in the sample complexity.\n B      Properties of Lifted DP and Further Details\n B.1     Equivalence Between DP and LiDP\n In contrast to the usual (\u03b5, \u03b4)-DP in Eq. (1), the probability in LiDP is over both the internal randomness of\n the algorithm A and the distribution P over the triplet (D0, D1, R). Since we require that the definition\n holds only for lifted distributions P that are independent of the algorithm A, it is easy to show its equivalence\n to the usual notion of (\u03b5, \u03b4)-DP.\n Theorem 3. A randomized algorithm A is (\u03b5, \u03b4)-LiDP iff A is (\u03b5, \u03b4)-DP.\n Proof. Suppose A is (\u03b5, \u03b4)-LiDP. Fix a pair of neighboring datasets D0, D1 and an outcome R \u2282              R. Define\n PD0,D1,R as the point mass on (D0, D1, R), i.e.,\n                            dPD0,D1,R(D\u2032   0, D\u2032\n                                               1, R\u2032) = 1(D\u2032 0 = D0, D\u2032 1 = D1, R\u2032 = R) ,\n                                                           18", "md": "# Document\n\nInstead, our framework can seamlessly adopt recently designed canaries and inherit their strengths as demonstrated in \u00a75 and \u00a76.\n\n## A.2 Improving Statistical Trade-offs in Auditing\n\nEq. (2) points to two orthogonal directions that can potentially improve the sample dependence: designing stronger canaries and improving the sample dependence of the confidence intervals. The former was addressed in the previous section. There is relatively less work in improving the statistical dependence, which our framework focuses on.\n\nGiven a pair of neighboring datasets, (D0, D1), and for a query with discrete output in a finite space, the statistical trade-off of estimating privacy parameters was studied in [24] where a plug-in estimator is shown to achieve an error of $$O\\left(\\frac{de^2\\epsilon}{n}\\right)$$, where d is the size of the discrete output space. [37] proposes a sub-linear sample complexity algorithm that achieves an error scaling as $$de\\epsilon/n \\log n$$, based on polynomial approximation of a carefully chosen degree to optimally trade-off bias and variance motivated by [26, 63]. Similarly, [36] provides a lower bound for auditing R\u00e9nyi differential privacy. [9] trains a classifier for the binary hypothesis test and uses the classifier to design rejection sets. [3] proposes local search to find the rejection set efficiently. More recently, [68] proposes numerical integration over a larger space of false positive rate and true positive rate to achieve better sample complexity of the confidence region in the two-dimensional space. Our framework can be potentially applied to this confidence region scenario, which is an important future research direction.\n\n## A.3 Connections to Other Notions of Differential Privacy\n\nSimilar to Lifted DP, a line of prior works [35, 54, 60, 65] generalizes DP to include a distributional assumption over the dataset. However, unlike Lifted DP, they are motivated by the observation that DP is not sufficient for preserving privacy when the samples are highly correlated. For example, upon releasing the number of people infected with a highly contagious flu within a tight-knit community, the usual Laplace mechanism (with sensitivity one) is not sufficient to conceal the likelihood of one member getting infected when the private count is significantly high. One could apply group differential privacy to hide the contagion of the entire population, but this will suffer from excessive noise. Ideally, we want to add a noise proportional to the expected size of the infection. Pufferfish privacy, introduced in [35], achieves this with a generalization of DP that takes into account prior knowledge of a class of potential distributions over the dataset. A special case of \u03b5-Pufferfish with a specific choice of parameters recovers a special case of our Lifted DP in Eq. (3) with \u03b4 = 0 [35, Section 3.2], where a special case of Theorem 3 has been proven for pure DP [35, Theorem 3.1]. However, we want to emphasize that our Lifted DP is motivated by a completely different problem of auditing differential privacy and is critical to breaking the barriers in the sample complexity.\n\n## B Properties of Lifted DP and Further Details\n\n### B.1 Equivalence Between DP and LiDP\n\nIn contrast to the usual (\u03b5, \u03b4)-DP in Eq. (1), the probability in LiDP is over both the internal randomness of the algorithm A and the distribution P over the triplet (D0, D1, R). Since we require that the definition holds only for lifted distributions P that are independent of the algorithm A, it is easy to show its equivalence to the usual notion of (\u03b5, \u03b4)-DP.\n\nTheorem 3. A randomized algorithm A is (\u03b5, \u03b4)-LiDP iff A is (\u03b5, \u03b4)-DP.\n\nProof. Suppose A is (\u03b5, \u03b4)-LiDP. Fix a pair of neighboring datasets D0, D1 and an outcome R \u2282 R. Define PD0,D1,R as the point mass on (D0, D1, R), i.e.,\n\n$$\ndPD0,D1,R(D'_0, D'_1, R') = 1(D'_0 = D0, D'_1 = D1, R' = R) ,\n$$", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "Instead, our framework can seamlessly adopt recently designed canaries and inherit their strengths as demonstrated in \u00a75 and \u00a76.", "md": "Instead, our framework can seamlessly adopt recently designed canaries and inherit their strengths as demonstrated in \u00a75 and \u00a76."}, {"type": "heading", "lvl": 2, "value": "A.2 Improving Statistical Trade-offs in Auditing", "md": "## A.2 Improving Statistical Trade-offs in Auditing"}, {"type": "text", "value": "Eq. (2) points to two orthogonal directions that can potentially improve the sample dependence: designing stronger canaries and improving the sample dependence of the confidence intervals. The former was addressed in the previous section. There is relatively less work in improving the statistical dependence, which our framework focuses on.\n\nGiven a pair of neighboring datasets, (D0, D1), and for a query with discrete output in a finite space, the statistical trade-off of estimating privacy parameters was studied in [24] where a plug-in estimator is shown to achieve an error of $$O\\left(\\frac{de^2\\epsilon}{n}\\right)$$, where d is the size of the discrete output space. [37] proposes a sub-linear sample complexity algorithm that achieves an error scaling as $$de\\epsilon/n \\log n$$, based on polynomial approximation of a carefully chosen degree to optimally trade-off bias and variance motivated by [26, 63]. Similarly, [36] provides a lower bound for auditing R\u00e9nyi differential privacy. [9] trains a classifier for the binary hypothesis test and uses the classifier to design rejection sets. [3] proposes local search to find the rejection set efficiently. More recently, [68] proposes numerical integration over a larger space of false positive rate and true positive rate to achieve better sample complexity of the confidence region in the two-dimensional space. Our framework can be potentially applied to this confidence region scenario, which is an important future research direction.", "md": "Eq. (2) points to two orthogonal directions that can potentially improve the sample dependence: designing stronger canaries and improving the sample dependence of the confidence intervals. The former was addressed in the previous section. There is relatively less work in improving the statistical dependence, which our framework focuses on.\n\nGiven a pair of neighboring datasets, (D0, D1), and for a query with discrete output in a finite space, the statistical trade-off of estimating privacy parameters was studied in [24] where a plug-in estimator is shown to achieve an error of $$O\\left(\\frac{de^2\\epsilon}{n}\\right)$$, where d is the size of the discrete output space. [37] proposes a sub-linear sample complexity algorithm that achieves an error scaling as $$de\\epsilon/n \\log n$$, based on polynomial approximation of a carefully chosen degree to optimally trade-off bias and variance motivated by [26, 63]. Similarly, [36] provides a lower bound for auditing R\u00e9nyi differential privacy. [9] trains a classifier for the binary hypothesis test and uses the classifier to design rejection sets. [3] proposes local search to find the rejection set efficiently. More recently, [68] proposes numerical integration over a larger space of false positive rate and true positive rate to achieve better sample complexity of the confidence region in the two-dimensional space. Our framework can be potentially applied to this confidence region scenario, which is an important future research direction."}, {"type": "heading", "lvl": 2, "value": "A.3 Connections to Other Notions of Differential Privacy", "md": "## A.3 Connections to Other Notions of Differential Privacy"}, {"type": "text", "value": "Similar to Lifted DP, a line of prior works [35, 54, 60, 65] generalizes DP to include a distributional assumption over the dataset. However, unlike Lifted DP, they are motivated by the observation that DP is not sufficient for preserving privacy when the samples are highly correlated. For example, upon releasing the number of people infected with a highly contagious flu within a tight-knit community, the usual Laplace mechanism (with sensitivity one) is not sufficient to conceal the likelihood of one member getting infected when the private count is significantly high. One could apply group differential privacy to hide the contagion of the entire population, but this will suffer from excessive noise. Ideally, we want to add a noise proportional to the expected size of the infection. Pufferfish privacy, introduced in [35], achieves this with a generalization of DP that takes into account prior knowledge of a class of potential distributions over the dataset. A special case of \u03b5-Pufferfish with a specific choice of parameters recovers a special case of our Lifted DP in Eq. (3) with \u03b4 = 0 [35, Section 3.2], where a special case of Theorem 3 has been proven for pure DP [35, Theorem 3.1]. However, we want to emphasize that our Lifted DP is motivated by a completely different problem of auditing differential privacy and is critical to breaking the barriers in the sample complexity.", "md": "Similar to Lifted DP, a line of prior works [35, 54, 60, 65] generalizes DP to include a distributional assumption over the dataset. However, unlike Lifted DP, they are motivated by the observation that DP is not sufficient for preserving privacy when the samples are highly correlated. For example, upon releasing the number of people infected with a highly contagious flu within a tight-knit community, the usual Laplace mechanism (with sensitivity one) is not sufficient to conceal the likelihood of one member getting infected when the private count is significantly high. One could apply group differential privacy to hide the contagion of the entire population, but this will suffer from excessive noise. Ideally, we want to add a noise proportional to the expected size of the infection. Pufferfish privacy, introduced in [35], achieves this with a generalization of DP that takes into account prior knowledge of a class of potential distributions over the dataset. A special case of \u03b5-Pufferfish with a specific choice of parameters recovers a special case of our Lifted DP in Eq. (3) with \u03b4 = 0 [35, Section 3.2], where a special case of Theorem 3 has been proven for pure DP [35, Theorem 3.1]. However, we want to emphasize that our Lifted DP is motivated by a completely different problem of auditing differential privacy and is critical to breaking the barriers in the sample complexity."}, {"type": "heading", "lvl": 2, "value": "B Properties of Lifted DP and Further Details", "md": "## B Properties of Lifted DP and Further Details"}, {"type": "heading", "lvl": 3, "value": "B.1 Equivalence Between DP and LiDP", "md": "### B.1 Equivalence Between DP and LiDP"}, {"type": "text", "value": "In contrast to the usual (\u03b5, \u03b4)-DP in Eq. (1), the probability in LiDP is over both the internal randomness of the algorithm A and the distribution P over the triplet (D0, D1, R). Since we require that the definition holds only for lifted distributions P that are independent of the algorithm A, it is easy to show its equivalence to the usual notion of (\u03b5, \u03b4)-DP.\n\nTheorem 3. A randomized algorithm A is (\u03b5, \u03b4)-LiDP iff A is (\u03b5, \u03b4)-DP.\n\nProof. Suppose A is (\u03b5, \u03b4)-LiDP. Fix a pair of neighboring datasets D0, D1 and an outcome R \u2282 R. Define PD0,D1,R as the point mass on (D0, D1, R), i.e.,\n\n$$\ndPD0,D1,R(D'_0, D'_1, R') = 1(D'_0 = D0, D'_1 = D1, R' = R) ,\n$$", "md": "In contrast to the usual (\u03b5, \u03b4)-DP in Eq. (1), the probability in LiDP is over both the internal randomness of the algorithm A and the distribution P over the triplet (D0, D1, R). Since we require that the definition holds only for lifted distributions P that are independent of the algorithm A, it is easy to show its equivalence to the usual notion of (\u03b5, \u03b4)-DP.\n\nTheorem 3. A randomized algorithm A is (\u03b5, \u03b4)-LiDP iff A is (\u03b5, \u03b4)-DP.\n\nProof. Suppose A is (\u03b5, \u03b4)-LiDP. Fix a pair of neighboring datasets D0, D1 and an outcome R \u2282 R. Define PD0,D1,R as the point mass on (D0, D1, R), i.e.,\n\n$$\ndPD0,D1,R(D'_0, D'_1, R') = 1(D'_0 = D0, D'_1 = D1, R' = R) ,\n$$"}]}, {"page": 19, "text": "so that PA,PD0,D1,R(A(D0) \u2208            R) = P(A(D0) \u2208         R) and similarly for D1. Then, applying the definition of\n(\u03b5, \u03b4)-LiDP w.r.t. the distribution PD0,D1,R gives\n                                          PA(A(D1) \u2208       R) \u2264   e\u03b5 PA(A(D0) \u2208       R) + \u03b4 .\nSince this holds for any neighboring datasets D0, D1 and outcome set R, we get that A is (\u03b5, \u03b4)-DP.\n     Conversely, suppose that A is (\u03b5, \u03b4)-DP. For any distribution P over pairs of neighboring datasets D0, D1\nand outcome set R, we have by integrating the DP definition\n                         P(A(D1) \u2208      R) dP(D0, D1, R) \u2264        e\u03b5    P(A(D0) \u2208      R) dP(D0, D1, R) + \u03b4 .                       (11)\nNext, we use the law of iterated expectation to get\n                   PA,P   A(D0) \u2208      R)   = EA,P      I A(D0) \u2208     R                     D0, R\n                                            = E(D0,D1,R)\u223cP        EA    I  A(D0) \u2208     R\n                                            =      EA   I  A(D0) \u2208     R    D0 = D0, R = R          dP(D0, D1, R)\n                                            (\u2217)\n                                             =      EA   I  A(D0) \u2208    R     dP(D0, D1, R)\n                                            =      PA   A(D0) \u2208     R   dP(D0, D1, R) ,\nwhere (\u2217) followed from the independence of A and P. Plugging this and the analogous expression for\nP(A(D1) \u2208      R) into (11) gives us that A is (\u03b5, \u03b4)-LiDP.\nB.2       Auditing LiDP with Different Notions of Neighborhood\nWe describe how to modify the recipe of \u00a73 for other notions of neighborhoods of datasets. The notion of\nneighborhood in Definition 1 is also known as the \u201cadd-or-remove\u201d neighborhood.\nReplace-one Neighborhood.                   Two datasets D, D\u2032 \u2208          Z\u2217   are considered neighboring if |D| = |D\u2032| and\n|D \\ D\u2032| = |D\u2032 \\ D| = 1. Roughly speaking, this leads to privacy guarantees that are roughly twice as strong\nas the add-or-remove notion of neighborhood in Definition 1, as the worst-case sensitivity of the operation is\ndoubled. We refer to [47, 62] for more details. Just like Definition 1, Definition 2 can also be adapted to this\nnotion of neighborhood.\nAuditing LiDP with Replace-one Neighborhood. The recipe of \u00a73.2 can be slightly modified for this\nnotion of neighborhood. The main difference is that the null hypothesis must now use K canaries as well,\nwith one fresh canary.\n     The alternative hypothesis is the same \u2014 we train a model on a randomized training dataset D1 =\nD \u222a{c1, . . . , cK} augmented with K random canaries drawn i.i.d. from Pcanary. Under the jth null hypothesis\nfor each j \u2208     [K], we construct a coupled dataset D0,j = D \u222a                {c1, . . . , cj\u22121, c\u2032\n                                                                                                  j, cj+1, . . . , cK}, where c\u2032  j is a\nfresh canary drawn i.i.d. from Pcanary. This coupling ensures that (D0,j, D1) are neighboring with probability\none. We restrict the rejection region Rj to now depend only on cj and not in the index j, e.g., we test for\nthe present of cj.2\n     Note the symmetry of the setup. Testing for the presence on cj in D0,j is exactly identical to testing for\nthe presence of c\u2032    j in D1. Thus, we can again rewrite the LiDP condition as\n                                  1   K   P(A(D1) \u2208      Rk)    \u2264     e\u03b5  m   P(A(D1) \u2208      R\u2032j) + \u03b4 .                             (12)\n                                  K  k=1                              m  j=1\n    2Note that the test could have depended on c\u2032    j as well, but we do not need it here.\n                                                                   19", "md": "# LiDP Auditing\n\nso that \\(PA, PD0, D1, R(A(D0) \\in R) = P(A(D0) \\in R)\\) and similarly for D1. Then, applying the definition of \\((\\epsilon, \\delta)\\)-LiDP w.r.t. the distribution \\(PD0, D1, R\\) gives\n\n$$PA(A(D1) \\in R) \\leq e^{\\epsilon} PA(A(D0) \\in R) + \\delta.$$\n\nSince this holds for any neighboring datasets \\(D0, D1\\) and outcome set \\(R\\), we get that A is \\((\\epsilon, \\delta)\\)-DP.\n\nConversely, suppose that A is \\((\\epsilon, \\delta)\\)-DP. For any distribution \\(P\\) over pairs of neighboring datasets \\(D0, D1\\) and outcome set \\(R\\), we have by integrating the DP definition\n\n$$P(A(D1) \\in R) dP(D0, D1, R) \\leq e^{\\epsilon} P(A(D0) \\in R) dP(D0, D1, R) + \\delta.$$ (11)\n\nNext, we use the law of iterated expectation to get\n\n$$PA, P(A(D0) \\in R) = E_{A, P} [I_{A(D0) \\in R}] = E(D0, D1, R) \\sim P [EA [I_{A(D0) \\in R} | D0, R]]$$\n\n$$= EA [I_{A(D0) \\in R} | D0 = D0, R = R] dP(D0, D1, R)$$\n\n\\((*)\\)\n\n$$= EA [I_{A(D0) \\in R}] dP(D0, D1, R) = PA [A(D0) \\in R] dP(D0, D1, R),$$\n\nwhere \\((*)\\) followed from the independence of A and P. Plugging this and the analogous expression for \\(P(A(D1) \\in R)\\) into (11) gives us that A is \\((\\epsilon, \\delta)\\)-LiDP.\n\n## Auditing LiDP with Different Notions of Neighborhood\n\nWe describe how to modify the recipe of \u00a73 for other notions of neighborhoods of datasets. The notion of neighborhood in Definition 1 is also known as the \u201cadd-or-remove\u201d neighborhood.\n\nReplace-one Neighborhood. Two datasets \\(D, D' \\in Z^*\\) are considered neighboring if \\(|D| = |D'|\\) and \\(|D \\ D'| = |D' \\ D| = 1\\). Roughly speaking, this leads to privacy guarantees that are roughly twice as strong as the add-or-remove notion of neighborhood in Definition 1, as the worst-case sensitivity of the operation is doubled. We refer to [47, 62] for more details. Just like Definition 1, Definition 2 can also be adapted to this notion of neighborhood.\n\nAuditing LiDP with Replace-one Neighborhood. The recipe of \u00a73.2 can be slightly modified for this notion of neighborhood. The main difference is that the null hypothesis must now use \\(K\\) canaries as well, with one fresh canary.\n\nThe alternative hypothesis is the same \u2014 we train a model on a randomized training dataset \\(D1 = D \\cup \\{c1, ..., cK\\}\\) augmented with \\(K\\) random canaries drawn i.i.d. from \\(P_{canary}\\). Under the \\(j\\)th null hypothesis for each \\(j \\in [K]\\), we construct a coupled dataset \\(D0, j = D \\cup \\{c1, ..., cj-1, c'_j, cj+1, ..., cK\\}\\), where \\(c'_j\\) is a fresh canary drawn i.i.d. from \\(P_{canary}\\). This coupling ensures that \\((D0, j, D1)\\) are neighboring with probability one. We restrict the rejection region \\(Rj\\) to now depend only on \\(cj\\) and not in the index \\(j\\), e.g., we test for the present of \\(cj\\).\n\nNote the symmetry of the setup. Testing for the presence on \\(cj\\) in \\(D0, j\\) is exactly identical to testing for the presence of \\(c'_j\\) in \\(D1\\). Thus, we can again rewrite the LiDP condition as\n\n$$\\frac{1}{K} \\sum_{k=1}^{K} P(A(D1) \\in R_k) \\leq e^{\\epsilon} \\frac{m}{K} \\sum_{j=1}^{m} P(A(D1) \\in R'_j) + \\delta.$$ (12)\n\n2Note that the test could have depended on \\(c'_j\\) as well, but we do not need it here.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "LiDP Auditing", "md": "# LiDP Auditing"}, {"type": "text", "value": "so that \\(PA, PD0, D1, R(A(D0) \\in R) = P(A(D0) \\in R)\\) and similarly for D1. Then, applying the definition of \\((\\epsilon, \\delta)\\)-LiDP w.r.t. the distribution \\(PD0, D1, R\\) gives\n\n$$PA(A(D1) \\in R) \\leq e^{\\epsilon} PA(A(D0) \\in R) + \\delta.$$\n\nSince this holds for any neighboring datasets \\(D0, D1\\) and outcome set \\(R\\), we get that A is \\((\\epsilon, \\delta)\\)-DP.\n\nConversely, suppose that A is \\((\\epsilon, \\delta)\\)-DP. For any distribution \\(P\\) over pairs of neighboring datasets \\(D0, D1\\) and outcome set \\(R\\), we have by integrating the DP definition\n\n$$P(A(D1) \\in R) dP(D0, D1, R) \\leq e^{\\epsilon} P(A(D0) \\in R) dP(D0, D1, R) + \\delta.$$ (11)\n\nNext, we use the law of iterated expectation to get\n\n$$PA, P(A(D0) \\in R) = E_{A, P} [I_{A(D0) \\in R}] = E(D0, D1, R) \\sim P [EA [I_{A(D0) \\in R} | D0, R]]$$\n\n$$= EA [I_{A(D0) \\in R} | D0 = D0, R = R] dP(D0, D1, R)$$\n\n\\((*)\\)\n\n$$= EA [I_{A(D0) \\in R}] dP(D0, D1, R) = PA [A(D0) \\in R] dP(D0, D1, R),$$\n\nwhere \\((*)\\) followed from the independence of A and P. Plugging this and the analogous expression for \\(P(A(D1) \\in R)\\) into (11) gives us that A is \\((\\epsilon, \\delta)\\)-LiDP.", "md": "so that \\(PA, PD0, D1, R(A(D0) \\in R) = P(A(D0) \\in R)\\) and similarly for D1. Then, applying the definition of \\((\\epsilon, \\delta)\\)-LiDP w.r.t. the distribution \\(PD0, D1, R\\) gives\n\n$$PA(A(D1) \\in R) \\leq e^{\\epsilon} PA(A(D0) \\in R) + \\delta.$$\n\nSince this holds for any neighboring datasets \\(D0, D1\\) and outcome set \\(R\\), we get that A is \\((\\epsilon, \\delta)\\)-DP.\n\nConversely, suppose that A is \\((\\epsilon, \\delta)\\)-DP. For any distribution \\(P\\) over pairs of neighboring datasets \\(D0, D1\\) and outcome set \\(R\\), we have by integrating the DP definition\n\n$$P(A(D1) \\in R) dP(D0, D1, R) \\leq e^{\\epsilon} P(A(D0) \\in R) dP(D0, D1, R) + \\delta.$$ (11)\n\nNext, we use the law of iterated expectation to get\n\n$$PA, P(A(D0) \\in R) = E_{A, P} [I_{A(D0) \\in R}] = E(D0, D1, R) \\sim P [EA [I_{A(D0) \\in R} | D0, R]]$$\n\n$$= EA [I_{A(D0) \\in R} | D0 = D0, R = R] dP(D0, D1, R)$$\n\n\\((*)\\)\n\n$$= EA [I_{A(D0) \\in R}] dP(D0, D1, R) = PA [A(D0) \\in R] dP(D0, D1, R),$$\n\nwhere \\((*)\\) followed from the independence of A and P. Plugging this and the analogous expression for \\(P(A(D1) \\in R)\\) into (11) gives us that A is \\((\\epsilon, \\delta)\\)-LiDP."}, {"type": "heading", "lvl": 2, "value": "Auditing LiDP with Different Notions of Neighborhood", "md": "## Auditing LiDP with Different Notions of Neighborhood"}, {"type": "text", "value": "We describe how to modify the recipe of \u00a73 for other notions of neighborhoods of datasets. The notion of neighborhood in Definition 1 is also known as the \u201cadd-or-remove\u201d neighborhood.\n\nReplace-one Neighborhood. Two datasets \\(D, D' \\in Z^*\\) are considered neighboring if \\(|D| = |D'|\\) and \\(|D \\ D'| = |D' \\ D| = 1\\). Roughly speaking, this leads to privacy guarantees that are roughly twice as strong as the add-or-remove notion of neighborhood in Definition 1, as the worst-case sensitivity of the operation is doubled. We refer to [47, 62] for more details. Just like Definition 1, Definition 2 can also be adapted to this notion of neighborhood.\n\nAuditing LiDP with Replace-one Neighborhood. The recipe of \u00a73.2 can be slightly modified for this notion of neighborhood. The main difference is that the null hypothesis must now use \\(K\\) canaries as well, with one fresh canary.\n\nThe alternative hypothesis is the same \u2014 we train a model on a randomized training dataset \\(D1 = D \\cup \\{c1, ..., cK\\}\\) augmented with \\(K\\) random canaries drawn i.i.d. from \\(P_{canary}\\). Under the \\(j\\)th null hypothesis for each \\(j \\in [K]\\), we construct a coupled dataset \\(D0, j = D \\cup \\{c1, ..., cj-1, c'_j, cj+1, ..., cK\\}\\), where \\(c'_j\\) is a fresh canary drawn i.i.d. from \\(P_{canary}\\). This coupling ensures that \\((D0, j, D1)\\) are neighboring with probability one. We restrict the rejection region \\(Rj\\) to now depend only on \\(cj\\) and not in the index \\(j\\), e.g., we test for the present of \\(cj\\).\n\nNote the symmetry of the setup. Testing for the presence on \\(cj\\) in \\(D0, j\\) is exactly identical to testing for the presence of \\(c'_j\\) in \\(D1\\). Thus, we can again rewrite the LiDP condition as\n\n$$\\frac{1}{K} \\sum_{k=1}^{K} P(A(D1) \\in R_k) \\leq e^{\\epsilon} \\frac{m}{K} \\sum_{j=1}^{m} P(A(D1) \\in R'_j) + \\delta.$$ (12)\n\n2Note that the test could have depended on \\(c'_j\\) as well, but we do not need it here.", "md": "We describe how to modify the recipe of \u00a73 for other notions of neighborhoods of datasets. The notion of neighborhood in Definition 1 is also known as the \u201cadd-or-remove\u201d neighborhood.\n\nReplace-one Neighborhood. Two datasets \\(D, D' \\in Z^*\\) are considered neighboring if \\(|D| = |D'|\\) and \\(|D \\ D'| = |D' \\ D| = 1\\). Roughly speaking, this leads to privacy guarantees that are roughly twice as strong as the add-or-remove notion of neighborhood in Definition 1, as the worst-case sensitivity of the operation is doubled. We refer to [47, 62] for more details. Just like Definition 1, Definition 2 can also be adapted to this notion of neighborhood.\n\nAuditing LiDP with Replace-one Neighborhood. The recipe of \u00a73.2 can be slightly modified for this notion of neighborhood. The main difference is that the null hypothesis must now use \\(K\\) canaries as well, with one fresh canary.\n\nThe alternative hypothesis is the same \u2014 we train a model on a randomized training dataset \\(D1 = D \\cup \\{c1, ..., cK\\}\\) augmented with \\(K\\) random canaries drawn i.i.d. from \\(P_{canary}\\). Under the \\(j\\)th null hypothesis for each \\(j \\in [K]\\), we construct a coupled dataset \\(D0, j = D \\cup \\{c1, ..., cj-1, c'_j, cj+1, ..., cK\\}\\), where \\(c'_j\\) is a fresh canary drawn i.i.d. from \\(P_{canary}\\). This coupling ensures that \\((D0, j, D1)\\) are neighboring with probability one. We restrict the rejection region \\(Rj\\) to now depend only on \\(cj\\) and not in the index \\(j\\), e.g., we test for the present of \\(cj\\).\n\nNote the symmetry of the setup. Testing for the presence on \\(cj\\) in \\(D0, j\\) is exactly identical to testing for the presence of \\(c'_j\\) in \\(D1\\). Thus, we can again rewrite the LiDP condition as\n\n$$\\frac{1}{K} \\sum_{k=1}^{K} P(A(D1) \\in R_k) \\leq e^{\\epsilon} \\frac{m}{K} \\sum_{j=1}^{m} P(A(D1) \\in R'_j) + \\delta.$$ (12)\n\n2Note that the test could have depended on \\(c'_j\\) as well, but we do not need it here."}]}, {"page": 20, "text": " Note the subtle difference between (4) and (12): both sides depend only on A(D1) and we have completely\n eliminated the need to train models on K \u2212                            1 canaries.\n      From here on, the rest of the recipe is identical to \u00a73 and Algorithm 1; we construct XBern confidence\n intervals for both sides of (12) and get a lower bound \u02c6                             \u03b5.\n C         Confidence Intervals for Exchangeable Bernoulli Means\nWe give a rigorous definition of the multivariate Exchangeable Bernoulli (XBern) distributions and derive\n their confidence intervals. We also give proofs of correctness of the confidence intervals.\n Definition 5 (XBern Distributions). A random vector (x1, . . . , xK) \u2208                                            {0, 1}K is said to be distributed as\nXBernK(\u00b51, . . . , \u00b5K) if:\n      \u2022 x1, . . . , xK is exchangeable, i.e., the vector (x1, . . . , xK) is identical in distribution to (x\u03c0(1), . . . , x\u03c0(K))\n          for any permutation \u03c0 : [K] \u2192                    [K], and,\n      \u2022 for each \u2113        = 1, . . . , K, we have E[m\u2113] = \u00b5\u2113, where\n                                                               m\u2113    :=     1                       xj 1 \u00b7 \u00b7 \u00b7 xj\u2113  .                                            (13)\n                                                                           K\u2113    j1<\u00b7\u00b7\u00b7<j\u2113\u2208[K]\n      We note that the XBernK distribution is fully determined by its K moments \u00b51, . . . , \u00b5K. For K = 1,\nXBern1(\u00b51) = Bernoulli(\u00b51) is just the Bernoulli distribution.\n      The moments m\u2113               satisfy a computationally efficient recurrence.\n Proposition 6. Let x \u223c                  XBernK(\u00b51, . . . , \u00b5K). We have the recurrence for \u2113                               = 1, . . . , K \u2212     1:\n                                                                m\u2113+1 = m\u2113            Km1 \u2212          \u2113     .                                                      (14)\n                                                                                         K \u2212     \u2113\n(13). Computing the \u2113th moment thus takes time O(K\u2113) rather than O(K\u2113) by naively computing the sum in\n Proof of Proposition 6. We show that this holds for any fixed vector (x1, . . . , xK) \u2208                                                      {0, 1}K and their\n corresponding moments m1, . . . , mK as defined in (13). For any 1 \u2264                                            \u2113  < K, consider the sum over \u2113                  + 1\n indices j1, . . . , j\u2113+1 \u2208        [K] such that j1 < \u00b7 \u00b7 \u00b7 < j\u2113              and j\u2113+1 can take all possible values in [K]. We have,\n                                                                  \uf8ee                             \uf8f9   \uf8ee                \uf8f9           K\n                       j1<\u00b7\u00b7\u00b7<j\u2113    ; j\u2113+1 xj  1 \u00b7 \u00b7 \u00b7 xj\u2113+1 =    \uf8f0  j1<\u00b7\u00b7\u00b7<j\u2113   xj1 \u00b7 \u00b7 \u00b7 xj\u2113  \uf8fb   \uf8f0  j\u2113+1  xj\u2113+1   \uf8fb   = K        \u2113    m\u2113m1 .                  (15)\n On the other hand, out of the K possible values of j\u2113+1, \u2113                                     of them coincide with one of j1, . . . , j\u2113. In this\n case, xj    1 \u00b7 \u00b7 \u00b7 xj\u2113+1 = xj1 \u00b7 \u00b7 \u00b7 xj\u2113      since each xj is an indicator. Of the other possibilities, j\u2113+1 is distinct from\n j1, . . . , j\u2113 and this leads to \u2113           + 1 orderings: (1) j\u2113+1 < j1 < \u00b7 \u00b7 \u00b7 < j\u2113, (2) j1 < j\u2113+1 < j2 < \u00b7 \u00b7 \u00b7 < j\u2113, \u00b7 \u00b7 \u00b7 , and\n(\u2113  + 1) j1 < \u00b7 \u00b7 \u00b7 < j\u2113         < j\u2113+1. By symmetry, the sum over each of these is equal. This gives\n                     j1<\u00b7\u00b7\u00b7<j\u2113    ; j\u2113+1 xj  1 \u00b7 \u00b7 \u00b7 xj\u2113+1 = \u2113     j1<\u00b7\u00b7\u00b7<j\u2113    xj1 \u00b7 \u00b7 \u00b7 xj\u2113  + (\u2113    + 1)    j1<\u00b7\u00b7\u00b7<j\u2113<j\u2113+1      xj1 \u00b7 \u00b7 \u00b7 xj\u2113+1\n                                                            = \u2113    K      m\u2113    + (\u2113   + 1)        K       m\u2113+1 .                                                (16)\n                                                                     \u2113                           \u2113 + 1\n Combining (15) and (16) and simplifying the coefficients using                                        K     /  K     = (K \u2212       \u2113)/(\u2113   + 1) gives\n                                                                                                      \u2113+1        \u2113\n Rearranging completes the proof.                           (K \u2212      \u2113)m\u2113+1 + \u2113m\u2113          = Km\u2113m1 .\n                                                                                    20", "md": "Note the subtle difference between (4) and (12): both sides depend only on \\(A(D1)\\) and we have completely eliminated the need to train models on \\(K - 1\\) canaries.\n\nFrom here on, the rest of the recipe is identical to \u00a73 and Algorithm 1; we construct \\(XBern\\) confidence intervals for both sides of (12) and get a lower bound \\(\\hat{\\epsilon}\\).\n\n## Confidence Intervals for Exchangeable Bernoulli Means\n\nWe give a rigorous definition of the multivariate Exchangeable Bernoulli (\\(XBern\\)) distributions and derive their confidence intervals. We also give proofs of correctness of the confidence intervals.\n\n### Definition 5 (XBern Distributions)\n\nA random vector \\((x_1, ..., x_K) \\in \\{0, 1\\}^K\\) is said to be distributed as \\(XBern_K(\\mu_1, ..., \\mu_K)\\) if:\n\n- \\(x_1, ..., x_K\\) is exchangeable, i.e., the vector \\((x_1, ..., x_K)\\) is identical in distribution to \\((x_{\\pi(1)}, ..., x_{\\pi(K)})\\) for any permutation \\(\\pi : [K] \\rightarrow [K]\\), and,\n- for each \\(\\ell = 1, ..., K\\), we have \\(E[m_{\\ell}] = \\mu_{\\ell}\\), where\n\\[\nm_{\\ell} := \\frac{1}{K \\choose \\ell} \\sum_{j_1 < ... < j_{\\ell} \\in [K]} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}}. \\tag{13}\n\\]\n\nWe note that the \\(XBern_K\\) distribution is fully determined by its \\(K\\) moments \\(\\mu_1, ..., \\mu_K\\). For \\(K = 1\\), \\(XBern_1(\\mu_1) = Bernoulli(\\mu_1)\\) is just the Bernoulli distribution.\n\nThe moments \\(m_{\\ell}\\) satisfy a computationally efficient recurrence.\n\n### Proposition 6\n\nLet \\(x \\sim XBern_K(\\mu_1, ..., \\mu_K)\\). We have the recurrence for \\(\\ell = 1, ..., K - 1\\):\n\\[\nm_{\\ell+1} = m_{\\ell} \\cdot \\frac{K \\mu_1 - \\ell}{K - \\ell}. \\tag{14}\n\\]\n\nComputing the \\(\\ell\\)th moment thus takes time \\(O(K^{\\ell})\\) rather than \\(O(K^{\\ell})\\) by naively computing the sum in\n\nProof of Proposition 6. We show that this holds for any fixed vector \\((x_1, ..., x_K) \\in \\{0, 1\\}^K\\) and their corresponding moments \\(m_1, ..., m_K\\) as defined in (13). For any \\(1 \\leq \\ell < K\\), consider the sum over \\(\\ell + 1\\) indices \\(j_1, ..., j_{\\ell+1} \\in [K]\\) such that \\(j_1 < ... < j_{\\ell}\\) and \\(j_{\\ell+1}\\) can take all possible values in \\([K]\\). We have,\n\\[\n\\sum_{j_1 < ... < j_{\\ell}; j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\left( \\sum_{j_1 < ... < j_{\\ell}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}} \\right) \\cdot x_{j_{\\ell+1}} = K \\ell \\cdot m_{\\ell} \\cdot m_1. \\tag{15}\n\\]\n\nOn the other hand, out of the \\(K\\) possible values of \\(j_{\\ell+1}\\), \\(\\ell\\) of them coincide with one of \\(j_1, ..., j_{\\ell}\\). In this case, \\(x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}}\\) since each \\(x_j\\) is an indicator. Of the other possibilities, \\(j_{\\ell+1}\\) is distinct from \\(j_1, ..., j_{\\ell}\\) and this leads to \\(\\ell + 1\\) orderings: (1) \\(j_{\\ell+1} < j_1 < ... < j_{\\ell}\\), (2) \\(j_1 < j_{\\ell+1} < j_2 < ... < j_{\\ell}\\), ..., and \\((\\ell + 1)\\) \\(j_1 < ... < j_{\\ell} < j_{\\ell+1}\\). By symmetry, the sum over each of these is equal. This gives\n\\[\n\\sum_{j_1 < ... < j_{\\ell}; j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\ell \\sum_{j_1 < ... < j_{\\ell}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}} + (\\ell + 1) \\sum_{j_1 < ... < j_{\\ell} < j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\ell K m_{\\ell} + (\\ell + 1) K m_{\\ell+1}. \\tag{16}\n\\]\n\nCombining (15) and (16) and simplifying the coefficients using \\(\\frac{K}{K} = \\frac{K - \\ell}{\\ell + 1}\\) gives\n\nRearranging completes the proof. (K - \\ell) \\(m_{\\ell+1} + \\ell m_{\\ell} = K m_{\\ell} m_1\\).", "images": [], "items": [{"type": "text", "value": "Note the subtle difference between (4) and (12): both sides depend only on \\(A(D1)\\) and we have completely eliminated the need to train models on \\(K - 1\\) canaries.\n\nFrom here on, the rest of the recipe is identical to \u00a73 and Algorithm 1; we construct \\(XBern\\) confidence intervals for both sides of (12) and get a lower bound \\(\\hat{\\epsilon}\\).", "md": "Note the subtle difference between (4) and (12): both sides depend only on \\(A(D1)\\) and we have completely eliminated the need to train models on \\(K - 1\\) canaries.\n\nFrom here on, the rest of the recipe is identical to \u00a73 and Algorithm 1; we construct \\(XBern\\) confidence intervals for both sides of (12) and get a lower bound \\(\\hat{\\epsilon}\\)."}, {"type": "heading", "lvl": 2, "value": "Confidence Intervals for Exchangeable Bernoulli Means", "md": "## Confidence Intervals for Exchangeable Bernoulli Means"}, {"type": "text", "value": "We give a rigorous definition of the multivariate Exchangeable Bernoulli (\\(XBern\\)) distributions and derive their confidence intervals. We also give proofs of correctness of the confidence intervals.", "md": "We give a rigorous definition of the multivariate Exchangeable Bernoulli (\\(XBern\\)) distributions and derive their confidence intervals. We also give proofs of correctness of the confidence intervals."}, {"type": "heading", "lvl": 3, "value": "Definition 5 (XBern Distributions)", "md": "### Definition 5 (XBern Distributions)"}, {"type": "text", "value": "A random vector \\((x_1, ..., x_K) \\in \\{0, 1\\}^K\\) is said to be distributed as \\(XBern_K(\\mu_1, ..., \\mu_K)\\) if:\n\n- \\(x_1, ..., x_K\\) is exchangeable, i.e., the vector \\((x_1, ..., x_K)\\) is identical in distribution to \\((x_{\\pi(1)}, ..., x_{\\pi(K)})\\) for any permutation \\(\\pi : [K] \\rightarrow [K]\\), and,\n- for each \\(\\ell = 1, ..., K\\), we have \\(E[m_{\\ell}] = \\mu_{\\ell}\\), where\n\\[\nm_{\\ell} := \\frac{1}{K \\choose \\ell} \\sum_{j_1 < ... < j_{\\ell} \\in [K]} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}}. \\tag{13}\n\\]\n\nWe note that the \\(XBern_K\\) distribution is fully determined by its \\(K\\) moments \\(\\mu_1, ..., \\mu_K\\). For \\(K = 1\\), \\(XBern_1(\\mu_1) = Bernoulli(\\mu_1)\\) is just the Bernoulli distribution.\n\nThe moments \\(m_{\\ell}\\) satisfy a computationally efficient recurrence.", "md": "A random vector \\((x_1, ..., x_K) \\in \\{0, 1\\}^K\\) is said to be distributed as \\(XBern_K(\\mu_1, ..., \\mu_K)\\) if:\n\n- \\(x_1, ..., x_K\\) is exchangeable, i.e., the vector \\((x_1, ..., x_K)\\) is identical in distribution to \\((x_{\\pi(1)}, ..., x_{\\pi(K)})\\) for any permutation \\(\\pi : [K] \\rightarrow [K]\\), and,\n- for each \\(\\ell = 1, ..., K\\), we have \\(E[m_{\\ell}] = \\mu_{\\ell}\\), where\n\\[\nm_{\\ell} := \\frac{1}{K \\choose \\ell} \\sum_{j_1 < ... < j_{\\ell} \\in [K]} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}}. \\tag{13}\n\\]\n\nWe note that the \\(XBern_K\\) distribution is fully determined by its \\(K\\) moments \\(\\mu_1, ..., \\mu_K\\). For \\(K = 1\\), \\(XBern_1(\\mu_1) = Bernoulli(\\mu_1)\\) is just the Bernoulli distribution.\n\nThe moments \\(m_{\\ell}\\) satisfy a computationally efficient recurrence."}, {"type": "heading", "lvl": 3, "value": "Proposition 6", "md": "### Proposition 6"}, {"type": "text", "value": "Let \\(x \\sim XBern_K(\\mu_1, ..., \\mu_K)\\). We have the recurrence for \\(\\ell = 1, ..., K - 1\\):\n\\[\nm_{\\ell+1} = m_{\\ell} \\cdot \\frac{K \\mu_1 - \\ell}{K - \\ell}. \\tag{14}\n\\]\n\nComputing the \\(\\ell\\)th moment thus takes time \\(O(K^{\\ell})\\) rather than \\(O(K^{\\ell})\\) by naively computing the sum in\n\nProof of Proposition 6. We show that this holds for any fixed vector \\((x_1, ..., x_K) \\in \\{0, 1\\}^K\\) and their corresponding moments \\(m_1, ..., m_K\\) as defined in (13). For any \\(1 \\leq \\ell < K\\), consider the sum over \\(\\ell + 1\\) indices \\(j_1, ..., j_{\\ell+1} \\in [K]\\) such that \\(j_1 < ... < j_{\\ell}\\) and \\(j_{\\ell+1}\\) can take all possible values in \\([K]\\). We have,\n\\[\n\\sum_{j_1 < ... < j_{\\ell}; j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\left( \\sum_{j_1 < ... < j_{\\ell}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}} \\right) \\cdot x_{j_{\\ell+1}} = K \\ell \\cdot m_{\\ell} \\cdot m_1. \\tag{15}\n\\]\n\nOn the other hand, out of the \\(K\\) possible values of \\(j_{\\ell+1}\\), \\(\\ell\\) of them coincide with one of \\(j_1, ..., j_{\\ell}\\). In this case, \\(x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}}\\) since each \\(x_j\\) is an indicator. Of the other possibilities, \\(j_{\\ell+1}\\) is distinct from \\(j_1, ..., j_{\\ell}\\) and this leads to \\(\\ell + 1\\) orderings: (1) \\(j_{\\ell+1} < j_1 < ... < j_{\\ell}\\), (2) \\(j_1 < j_{\\ell+1} < j_2 < ... < j_{\\ell}\\), ..., and \\((\\ell + 1)\\) \\(j_1 < ... < j_{\\ell} < j_{\\ell+1}\\). By symmetry, the sum over each of these is equal. This gives\n\\[\n\\sum_{j_1 < ... < j_{\\ell}; j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\ell \\sum_{j_1 < ... < j_{\\ell}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}} + (\\ell + 1) \\sum_{j_1 < ... < j_{\\ell} < j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\ell K m_{\\ell} + (\\ell + 1) K m_{\\ell+1}. \\tag{16}\n\\]\n\nCombining (15) and (16) and simplifying the coefficients using \\(\\frac{K}{K} = \\frac{K - \\ell}{\\ell + 1}\\) gives\n\nRearranging completes the proof. (K - \\ell) \\(m_{\\ell+1} + \\ell m_{\\ell} = K m_{\\ell} m_1\\).", "md": "Let \\(x \\sim XBern_K(\\mu_1, ..., \\mu_K)\\). We have the recurrence for \\(\\ell = 1, ..., K - 1\\):\n\\[\nm_{\\ell+1} = m_{\\ell} \\cdot \\frac{K \\mu_1 - \\ell}{K - \\ell}. \\tag{14}\n\\]\n\nComputing the \\(\\ell\\)th moment thus takes time \\(O(K^{\\ell})\\) rather than \\(O(K^{\\ell})\\) by naively computing the sum in\n\nProof of Proposition 6. We show that this holds for any fixed vector \\((x_1, ..., x_K) \\in \\{0, 1\\}^K\\) and their corresponding moments \\(m_1, ..., m_K\\) as defined in (13). For any \\(1 \\leq \\ell < K\\), consider the sum over \\(\\ell + 1\\) indices \\(j_1, ..., j_{\\ell+1} \\in [K]\\) such that \\(j_1 < ... < j_{\\ell}\\) and \\(j_{\\ell+1}\\) can take all possible values in \\([K]\\). We have,\n\\[\n\\sum_{j_1 < ... < j_{\\ell}; j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\left( \\sum_{j_1 < ... < j_{\\ell}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}} \\right) \\cdot x_{j_{\\ell+1}} = K \\ell \\cdot m_{\\ell} \\cdot m_1. \\tag{15}\n\\]\n\nOn the other hand, out of the \\(K\\) possible values of \\(j_{\\ell+1}\\), \\(\\ell\\) of them coincide with one of \\(j_1, ..., j_{\\ell}\\). In this case, \\(x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}}\\) since each \\(x_j\\) is an indicator. Of the other possibilities, \\(j_{\\ell+1}\\) is distinct from \\(j_1, ..., j_{\\ell}\\) and this leads to \\(\\ell + 1\\) orderings: (1) \\(j_{\\ell+1} < j_1 < ... < j_{\\ell}\\), (2) \\(j_1 < j_{\\ell+1} < j_2 < ... < j_{\\ell}\\), ..., and \\((\\ell + 1)\\) \\(j_1 < ... < j_{\\ell} < j_{\\ell+1}\\). By symmetry, the sum over each of these is equal. This gives\n\\[\n\\sum_{j_1 < ... < j_{\\ell}; j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\ell \\sum_{j_1 < ... < j_{\\ell}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell}} + (\\ell + 1) \\sum_{j_1 < ... < j_{\\ell} < j_{\\ell+1}} x_{j_1} \\cdot ... \\cdot x_{j_{\\ell+1}} = \\ell K m_{\\ell} + (\\ell + 1) K m_{\\ell+1}. \\tag{16}\n\\]\n\nCombining (15) and (16) and simplifying the coefficients using \\(\\frac{K}{K} = \\frac{K - \\ell}{\\ell + 1}\\) gives\n\nRearranging completes the proof. (K - \\ell) \\(m_{\\ell+1} + \\ell m_{\\ell} = K m_{\\ell} m_1\\)."}]}, {"page": 21, "text": "Algorithm 2 First-Order Bernstein Intervals\nInput: Random vectors x(1), . . . , x(n) \u223c                 XBernK(\u00b51, . . . , \u00b5K) with unknown parameters, failure probability\n      \u03b2 \u2208   (0, 1).\nOutput: Confidence intervals [\u00b5                 1, \u00b51] such that P(\u00b51 < \u00b5            1) \u2264   \u03b2 and P(\u00b51 > \u00b51) \u2264            \u03b2.\n  1: Set \u00b5    1 as the unique solution of x \u2208              [0, \u02c6\n                                                               \u00b51] such that\n                                                    \u02c6                  2\n            if it exists, else set \u00b5     1 = 0.     \u00b51 \u2212   x \u2212         n log 1 \u03b2     x(1 \u2212    x) = 2  3n log 1  \u03b2\n  2: Set \u00b5                                                 \u00b51, 1] such that\n              1 as the unique solution of x \u2208       x \u2212   \u02c6[\u02c6          2             x(1 \u2212    x) = 2\n            if it exists, else set \u00b5     1 = 1.          \u00b51 \u2212          n log 1 \u03b2                      3n log 1  \u03b2\n  3: return \u00b5       1, \u00b51.\nNotation. In this section, we are interested in giving confidence intervals on the mean \u00b51 of a XBernK(\u00b51, . . . , \u00b5K)\nrandom variable from n i.i.d. observations:\n                                                 x(1) , . . . , x(n) i.i.d.\nWe will define the confidence intervals using the empirical mean      \u223c    XBernK(\u00b51, . . . , \u00b5K) .\n                                             \u02c6           n                                         K\n                                            \u00b51 = 1           m(i)      where       m(i)   = 1          x(i)\n                                                     n  i=1     1                     1       K   j=1    j ,\nas well as the higher-order moments for \u2113    n              \u2208  [K],\n                                 \u02c6                                                 1                     x(i)\n                                \u00b5\u2113   = 1         m(i)      where      m(i)    =    K                       j1 \u00b7 \u00b7 \u00b7 x(i)\n                                         n  i=1     \u2113                     \u2113         \u2113   j1<\u00b7\u00b7\u00b7<j\u2113\u2208[K]                j\u2113  .\nC.1        Non-Asymptotic Confidence Intervals\nWe start by giving non-asymptotic confidence intervals for the XBern distributions based on the Bernstein\nbound.\nC.1.1        First-Order Bernstein Intervals\nThe first-order Bernstein interval only depends on the empirical mean \u00b51 and is given in Algorithm 2.\nProposition 7. Consider Algorithm 2 with inputs n i.i.d. samples x(1), . . . , x(n) i.i.d.                              \u223c    XBernK(\u00b51, . . . , \u00b5K)\nfor some K \u2265         1. Then, its outputs \u00b51, \u00b51 satisfy P(\u00b51 \u2264                   \u00b51) \u2265     1 \u2212   \u03b2 and P(\u00b51 \u2265        \u00b51) \u2265     1 \u2212  \u03b2.\nProof. Applying Bernstein\u2019s inequality to m1 := (1/k)  k                           j=1 xj, we have with probability 1 \u2212                 \u03b2 that\n                      \u00b51 \u2212    \u02c6           2Var(m1)                                       2\u00b51(1 \u2212     \u00b51)\n                              \u00b51 \u2264              n        log 1\u03b2 + 2  3n log 1 \u03b2 \u2264               n         log 1 \u03b2 + 2 3n log 1  \u03b2 ,\nwhere we used that Var(m1) \u2264                 \u00b51(1 \u2212    \u00b51) since m1 \u2208         [0, 1] a.s. We see from Figure 2 that \u00b51 is that largest\nvalue of \u00b51 that satisfies the above inequality, showing that it is an upper confidence bound. Similarly, we get\nthat \u00b5    1 is a valid lower confidence bound.\n                                                                           21", "md": "Algorithm 2 First-Order Bernstein Intervals\n\nInput: Random vectors $$x^{(1)}, \\ldots, x^{(n)} \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ with unknown parameters, failure probability $$\\beta \\in (0, 1)$$.\n\nOutput: Confidence intervals $$[\\mu_1, \\hat{\\mu}_1]$$ such that $$P(\\mu_1 < \\mu_1) \\leq \\beta$$ and $$P(\\mu_1 > \\mu_1) \\leq \\beta$$.\n\n1. Set $\\mu_1$ as the unique solution of $x \\in [0, \\hat{\\mu}_1]$ such that\n$\\hat{\\mu}_1 = \\begin{cases} \\mu_1 - x - \\frac{n \\log(1/\\beta)}{x(1 - x)} & \\text{if it exists,} \\\\ 0 & \\text{else} \\end{cases}$\n2. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that\n$\\hat{\\mu}_1 = \\begin{cases} x - \\hat{\\mu}_1^2 \\frac{x(1 - x)}{2} & \\text{if it exists,} \\\\ \\mu_1 - \\frac{n \\log(1/\\beta)}{3n \\log(1/\\beta)} & \\text{else} \\end{cases}$\n3. Return $\\mu_1, \\hat{\\mu}_1$.\n\nNotation. In this section, we are interested in giving confidence intervals on the mean $$\\mu_1$$ of a $$XBernK(\\mu_1, \\ldots, \\mu_K)$$ random variable from $$n$$ i.i.d. observations: $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d.\n\nWe will define the confidence intervals using the empirical mean $$\\hat{\\mu}_1 \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$.\n\n$$\\hat{\\mu}_1 = \\frac{1}{n} \\sum_{i=1}^{n} m(i)$$ where $$m(i) = \\frac{1}{n} \\sum_{j=1}^{K} j$$,\n\nas well as the higher-order moments for $$\\ell \\in [K]$$,\n\n$$\\hat{\\mu}_{\\ell} = \\frac{1}{n} \\sum_{i=1}^{n} m(i)$$ where $$m(i) = \\frac{1}{n} \\sum_{j_1 < \\ldots < j_{\\ell} \\in [K]} j_1 \\cdot \\ldots \\cdot x^{(i)}_{j_{\\ell}}$$.\n\nC.1 Non-Asymptotic Confidence Intervals\n\nWe start by giving non-asymptotic confidence intervals for the $$XBern$$ distributions based on the Bernstein bound.\n\nC.1.1 First-Order Bernstein Intervals\n\nThe first-order Bernstein interval only depends on the empirical mean $$\\mu_1$$ and is given in Algorithm 2.\n\nProposition 7. Consider Algorithm 2 with inputs $$n$$ i.i.d. samples $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d. $$\\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ for some $$K \\geq 1$$. Then, its outputs $$\\mu_1, \\hat{\\mu}_1$$ satisfy $$P(\\mu_1 \\leq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\geq \\hat{\\mu}_1) \\geq 1 - \\beta$$.\n\nProof. Applying Bernstein\u2019s inequality to $$m_1 := \\left(\\frac{1}{k} \\sum_{j=1}^{k} x_j\\right)$$, we have with probability $$1 - \\beta$$ that\n$$\\mu_1 - \\hat{\\mu}_1 \\leq 2\\text{Var}(m_1) \\leq \\frac{2\\mu_1(1 - \\mu_1)}{n} \\log\\frac{1}{\\beta} + \\frac{2}{3n} \\log\\frac{1}{\\beta} \\leq \\frac{n}{\\log\\frac{1}{\\beta}} + \\frac{2}{3n} \\log\\frac{1}{\\beta}$$,\nwhere we used that $$\\text{Var}(m_1) \\leq \\mu_1(1 - \\mu_1)$$ since $$m_1 \\in [0, 1]$$ a.s. We see from Figure 2 that $$\\mu_1$$ is that largest value of $$\\mu_1$$ that satisfies the above inequality, showing that it is an upper confidence bound. Similarly, we get that $$\\hat{\\mu}_1$$ is a valid lower confidence bound.\n\n21", "images": [], "items": [{"type": "text", "value": "Algorithm 2 First-Order Bernstein Intervals\n\nInput: Random vectors $$x^{(1)}, \\ldots, x^{(n)} \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ with unknown parameters, failure probability $$\\beta \\in (0, 1)$$.\n\nOutput: Confidence intervals $$[\\mu_1, \\hat{\\mu}_1]$$ such that $$P(\\mu_1 < \\mu_1) \\leq \\beta$$ and $$P(\\mu_1 > \\mu_1) \\leq \\beta$$.\n\n1. Set $\\mu_1$ as the unique solution of $x \\in [0, \\hat{\\mu}_1]$ such that\n$\\hat{\\mu}_1 = \\begin{cases} \\mu_1 - x - \\frac{n \\log(1/\\beta)}{x(1 - x)} & \\text{if it exists,} \\\\ 0 & \\text{else} \\end{cases}$\n2. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that\n$\\hat{\\mu}_1 = \\begin{cases} x - \\hat{\\mu}_1^2 \\frac{x(1 - x)}{2} & \\text{if it exists,} \\\\ \\mu_1 - \\frac{n \\log(1/\\beta)}{3n \\log(1/\\beta)} & \\text{else} \\end{cases}$\n3. Return $\\mu_1, \\hat{\\mu}_1$.\n\nNotation. In this section, we are interested in giving confidence intervals on the mean $$\\mu_1$$ of a $$XBernK(\\mu_1, \\ldots, \\mu_K)$$ random variable from $$n$$ i.i.d. observations: $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d.\n\nWe will define the confidence intervals using the empirical mean $$\\hat{\\mu}_1 \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$.\n\n$$\\hat{\\mu}_1 = \\frac{1}{n} \\sum_{i=1}^{n} m(i)$$ where $$m(i) = \\frac{1}{n} \\sum_{j=1}^{K} j$$,\n\nas well as the higher-order moments for $$\\ell \\in [K]$$,\n\n$$\\hat{\\mu}_{\\ell} = \\frac{1}{n} \\sum_{i=1}^{n} m(i)$$ where $$m(i) = \\frac{1}{n} \\sum_{j_1 < \\ldots < j_{\\ell} \\in [K]} j_1 \\cdot \\ldots \\cdot x^{(i)}_{j_{\\ell}}$$.\n\nC.1 Non-Asymptotic Confidence Intervals\n\nWe start by giving non-asymptotic confidence intervals for the $$XBern$$ distributions based on the Bernstein bound.\n\nC.1.1 First-Order Bernstein Intervals\n\nThe first-order Bernstein interval only depends on the empirical mean $$\\mu_1$$ and is given in Algorithm 2.\n\nProposition 7. Consider Algorithm 2 with inputs $$n$$ i.i.d. samples $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d. $$\\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ for some $$K \\geq 1$$. Then, its outputs $$\\mu_1, \\hat{\\mu}_1$$ satisfy $$P(\\mu_1 \\leq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\geq \\hat{\\mu}_1) \\geq 1 - \\beta$$.\n\nProof. Applying Bernstein\u2019s inequality to $$m_1 := \\left(\\frac{1}{k} \\sum_{j=1}^{k} x_j\\right)$$, we have with probability $$1 - \\beta$$ that\n$$\\mu_1 - \\hat{\\mu}_1 \\leq 2\\text{Var}(m_1) \\leq \\frac{2\\mu_1(1 - \\mu_1)}{n} \\log\\frac{1}{\\beta} + \\frac{2}{3n} \\log\\frac{1}{\\beta} \\leq \\frac{n}{\\log\\frac{1}{\\beta}} + \\frac{2}{3n} \\log\\frac{1}{\\beta}$$,\nwhere we used that $$\\text{Var}(m_1) \\leq \\mu_1(1 - \\mu_1)$$ since $$m_1 \\in [0, 1]$$ a.s. We see from Figure 2 that $$\\mu_1$$ is that largest value of $$\\mu_1$$ that satisfies the above inequality, showing that it is an upper confidence bound. Similarly, we get that $$\\hat{\\mu}_1$$ is a valid lower confidence bound.\n\n21", "md": "Algorithm 2 First-Order Bernstein Intervals\n\nInput: Random vectors $$x^{(1)}, \\ldots, x^{(n)} \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ with unknown parameters, failure probability $$\\beta \\in (0, 1)$$.\n\nOutput: Confidence intervals $$[\\mu_1, \\hat{\\mu}_1]$$ such that $$P(\\mu_1 < \\mu_1) \\leq \\beta$$ and $$P(\\mu_1 > \\mu_1) \\leq \\beta$$.\n\n1. Set $\\mu_1$ as the unique solution of $x \\in [0, \\hat{\\mu}_1]$ such that\n$\\hat{\\mu}_1 = \\begin{cases} \\mu_1 - x - \\frac{n \\log(1/\\beta)}{x(1 - x)} & \\text{if it exists,} \\\\ 0 & \\text{else} \\end{cases}$\n2. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that\n$\\hat{\\mu}_1 = \\begin{cases} x - \\hat{\\mu}_1^2 \\frac{x(1 - x)}{2} & \\text{if it exists,} \\\\ \\mu_1 - \\frac{n \\log(1/\\beta)}{3n \\log(1/\\beta)} & \\text{else} \\end{cases}$\n3. Return $\\mu_1, \\hat{\\mu}_1$.\n\nNotation. In this section, we are interested in giving confidence intervals on the mean $$\\mu_1$$ of a $$XBernK(\\mu_1, \\ldots, \\mu_K)$$ random variable from $$n$$ i.i.d. observations: $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d.\n\nWe will define the confidence intervals using the empirical mean $$\\hat{\\mu}_1 \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$.\n\n$$\\hat{\\mu}_1 = \\frac{1}{n} \\sum_{i=1}^{n} m(i)$$ where $$m(i) = \\frac{1}{n} \\sum_{j=1}^{K} j$$,\n\nas well as the higher-order moments for $$\\ell \\in [K]$$,\n\n$$\\hat{\\mu}_{\\ell} = \\frac{1}{n} \\sum_{i=1}^{n} m(i)$$ where $$m(i) = \\frac{1}{n} \\sum_{j_1 < \\ldots < j_{\\ell} \\in [K]} j_1 \\cdot \\ldots \\cdot x^{(i)}_{j_{\\ell}}$$.\n\nC.1 Non-Asymptotic Confidence Intervals\n\nWe start by giving non-asymptotic confidence intervals for the $$XBern$$ distributions based on the Bernstein bound.\n\nC.1.1 First-Order Bernstein Intervals\n\nThe first-order Bernstein interval only depends on the empirical mean $$\\mu_1$$ and is given in Algorithm 2.\n\nProposition 7. Consider Algorithm 2 with inputs $$n$$ i.i.d. samples $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d. $$\\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ for some $$K \\geq 1$$. Then, its outputs $$\\mu_1, \\hat{\\mu}_1$$ satisfy $$P(\\mu_1 \\leq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\geq \\hat{\\mu}_1) \\geq 1 - \\beta$$.\n\nProof. Applying Bernstein\u2019s inequality to $$m_1 := \\left(\\frac{1}{k} \\sum_{j=1}^{k} x_j\\right)$$, we have with probability $$1 - \\beta$$ that\n$$\\mu_1 - \\hat{\\mu}_1 \\leq 2\\text{Var}(m_1) \\leq \\frac{2\\mu_1(1 - \\mu_1)}{n} \\log\\frac{1}{\\beta} + \\frac{2}{3n} \\log\\frac{1}{\\beta} \\leq \\frac{n}{\\log\\frac{1}{\\beta}} + \\frac{2}{3n} \\log\\frac{1}{\\beta}$$,\nwhere we used that $$\\text{Var}(m_1) \\leq \\mu_1(1 - \\mu_1)$$ since $$m_1 \\in [0, 1]$$ a.s. We see from Figure 2 that $$\\mu_1$$ is that largest value of $$\\mu_1$$ that satisfies the above inequality, showing that it is an upper confidence bound. Similarly, we get that $$\\hat{\\mu}_1$$ is a valid lower confidence bound.\n\n21"}]}, {"page": 22, "text": "Algorithm 3 Second-Order Bernstein Intervals\n Input: Random vectors x(1), . . . , x(n) \u223c                       XBernK(\u00b51, . . . , \u00b5K) with unknown parameters, failure probability\n       \u03b2 \u2208   (0, 1).\n Output: Confidence intervals [\u00b5                     1, \u00b51] such that P(\u00b51 < \u00b5                1) \u2264   \u03b2 and P(\u00b51 > \u00b51) \u2264                \u03b2.\n   1: For each i \u2208         [n], set m(i)   1   = (1/K)  K        j=1 x(i)j    and m(i)   2   = m(i)  1      Km(i)1 \u22121        .\n   2: Set \u02c6  \u00b5\u2113   = (1/n)  n       i=1 m(i) \u2113    for \u2113   = 1, 2.  \u00b52, 1] such that                             K\u22121\n   3: Set \u00b5     2 as the unique solution of x \u2208         x \u2212    \u02c6 [\u02c6           2\n             if it exists, else set \u00b5         2 = 1.           \u00b52 \u2212           n log 2  \u03b2      x(1 \u2212    x) = 2   3n log 2   \u03b2 .\n   4: Set \u00b5     1 as the unique solution of x \u2208                  [0, \u02c6\n                                                                     \u00b51] such that\n                                                    \u02c6                    2                  x                      = 2\n                                                   \u00b51 \u2212     x \u2212          n log 2  \u03b2        K \u2212     x2 + \u00b52             3n log 2   \u03b2\n             if it exists, else set \u00b5         1 = 0.\n   5: Set \u00b5     1 as the unique solution of x \u2208                  [\u02c6\n                                                                  \u00b51, 1] such that\n                                                   x \u2212    \u02c6              2                  x\n             if it exists, else set \u00b5         1 = 1.      \u00b51 \u2212           n log 2  \u03b2        K \u2212     x2 + \u00b52         = 2 3n log 2   \u03b2\n   6: return \u00b5        1, \u00b51.\n C.1.2        Second-Order Bernstein Intervals\nThe second-order Bernstein interval only depends on first two empirical moments \u00b51 and \u00b52. It is given in\nAlgorithm 3. The algorithm is based on the calculation\n                                          Var(m1) = E[m2        \uf8ee   1] \u2212  K\u00b521                                        \uf8f9\n                                                         = E    \uf8f0   1         x2 j + 2                      xj1xj2    \uf8fb  \u2212   \u00b521                                    (17)\n                                                                   K2    j=1           K2    j 1<j2\u2208[K]\n                                                         = \u00b51 K \u2212     \u00b521 + K \u2212   K   1  \u00b52 ,\nwhere we used x2           j = xj since it is an indicator.\n Proposition 8. Consider Algorithm 3 with inputs n i.i.d. samples x(1), . . . , x(n) i.i.d.                                          \u223c     XBernk(\u00b51, . . . , \u00b5K)\n for some K \u2265             2. Then, its outputs \u00b51, \u00b51 satisfy P(\u00b51 \u2265                               \u00b51) \u2265      1 \u2212    \u03b2 and P(\u00b51 \u2264             \u00b51) \u2265       1 \u2212   \u03b2 and\n P(\u00b5   1 \u2264   \u00b51 \u2264     \u00b51) \u2264     1 \u2212    3\u03b2\n                                        2 .\n Proof. Algorithm 3 computes the correct 2nd moment m(i)                                      2    due to Proposition 6. Applying Bernstein\u2019s\n inequality to m2, we get P(\u00b52 \u2264                    \u00b52) \u2265      1 \u2212   \u03b2/2 (see also the proof of Proposition 7). Next, from Bernstein\u2019s\n                                                                                    22", "md": "Algorithm 3 Second-Order Bernstein Intervals\n\nInput: Random vectors $$x^{(1)}, \\ldots, x^{(n)} \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ with unknown parameters, failure probability $$\\beta \\in (0, 1)$$.\n\nOutput: Confidence intervals $$[\\mu_1, \\hat{\\mu}_1]$$ such that $$P(\\mu_1 < \\hat{\\mu}_1) \\leq \\beta$$ and $$P(\\mu_1 > \\hat{\\mu}_1) \\leq \\beta$$.\n\n1. For each $i \\in [n]$, set $m^{(1)}_i = \\left(\\frac{1}{K}\\right) \\sum_{j=1}^{K} x^{(i)}_j$ and $m^{(2)}_i = m^{(1)}_i \\left(\\frac{K}{m^{(1)}_i} - 1\\right)$.\n2. Set $\\hat{\\mu}_{\\ell} = \\left(\\frac{1}{n}\\right) \\sum_{i=1}^{n} m^{(\\ell)}_i$ for $\\ell = 1, 2$.\n3. Set $\\mu_2$ as the unique solution of $x \\in [0, \\hat{\\mu}_2]$ such that $\\hat{\\mu}_2 - x - \\frac{n \\log 2 \\beta}{x(1 - x)} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_2 = 1$.\n4. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that $\\mu_1 - x - \\frac{n \\log 2 \\beta}{K - x^2 + \\mu_2} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_1 = 0$.\n5. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that $x - \\hat{\\mu}_2 - \\frac{n \\log 2 \\beta}{K - x^2 + \\mu_2} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_1 = 1$.\n6. Return $\\mu_1, \\hat{\\mu}_1$.\n\nC.1.2 Second-Order Bernstein Intervals\n\nThe second-order Bernstein interval only depends on the first two empirical moments $$\\mu_1$$ and $$\\mu_2$$. It is given in Algorithm 3. The algorithm is based on the calculation\n\n$$\n\\begin{align*}\n\\text{Var}(m^{(1)}) & = E[m^{(2)}_1] - K\\mu_1^2 \\\\\n& = E\\left[\\sum_{j=1}^{K} x^2_j + 2\\sum_{j_1 < j_2} x_{j_1}x_{j_2}\\right] - \\mu_1^2 \\\\\n& = \\mu_1 K - \\mu_1^2 + K(K-1)\\mu_2,\n\\end{align*}\n$$\nwhere we used $$x^2_j = x_j$$ since it is an indicator.\n\nProposition 8. Consider Algorithm 3 with inputs $$n$$ i.i.d. samples $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d. $$\\sim XBernk(\\mu_1, \\ldots, \\mu_K)$$ for some $$K \\geq 2$$. Then, its outputs $$\\mu_1, \\hat{\\mu}_1$$ satisfy $$P(\\mu_1 \\geq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\leq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\leq \\mu_1 \\leq \\hat{\\mu}_1) \\leq 1 - \\frac{3\\beta}{2}$$.\n\nProof. Algorithm 3 computes the correct 2nd moment $$m^{(1)}_2$$ due to Proposition 6. Applying Bernstein\u2019s inequality to $$m^2$$, we get $$P(\\mu_2 \\leq \\hat{\\mu}_2) \\geq 1 - \\frac{\\beta}{2}$$ (see also the proof of Proposition 7). Next, from Bernstein\u2019s", "images": [], "items": [{"type": "text", "value": "Algorithm 3 Second-Order Bernstein Intervals\n\nInput: Random vectors $$x^{(1)}, \\ldots, x^{(n)} \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ with unknown parameters, failure probability $$\\beta \\in (0, 1)$$.\n\nOutput: Confidence intervals $$[\\mu_1, \\hat{\\mu}_1]$$ such that $$P(\\mu_1 < \\hat{\\mu}_1) \\leq \\beta$$ and $$P(\\mu_1 > \\hat{\\mu}_1) \\leq \\beta$$.\n\n1. For each $i \\in [n]$, set $m^{(1)}_i = \\left(\\frac{1}{K}\\right) \\sum_{j=1}^{K} x^{(i)}_j$ and $m^{(2)}_i = m^{(1)}_i \\left(\\frac{K}{m^{(1)}_i} - 1\\right)$.\n2. Set $\\hat{\\mu}_{\\ell} = \\left(\\frac{1}{n}\\right) \\sum_{i=1}^{n} m^{(\\ell)}_i$ for $\\ell = 1, 2$.\n3. Set $\\mu_2$ as the unique solution of $x \\in [0, \\hat{\\mu}_2]$ such that $\\hat{\\mu}_2 - x - \\frac{n \\log 2 \\beta}{x(1 - x)} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_2 = 1$.\n4. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that $\\mu_1 - x - \\frac{n \\log 2 \\beta}{K - x^2 + \\mu_2} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_1 = 0$.\n5. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that $x - \\hat{\\mu}_2 - \\frac{n \\log 2 \\beta}{K - x^2 + \\mu_2} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_1 = 1$.\n6. Return $\\mu_1, \\hat{\\mu}_1$.\n\nC.1.2 Second-Order Bernstein Intervals\n\nThe second-order Bernstein interval only depends on the first two empirical moments $$\\mu_1$$ and $$\\mu_2$$. It is given in Algorithm 3. The algorithm is based on the calculation\n\n$$\n\\begin{align*}\n\\text{Var}(m^{(1)}) & = E[m^{(2)}_1] - K\\mu_1^2 \\\\\n& = E\\left[\\sum_{j=1}^{K} x^2_j + 2\\sum_{j_1 < j_2} x_{j_1}x_{j_2}\\right] - \\mu_1^2 \\\\\n& = \\mu_1 K - \\mu_1^2 + K(K-1)\\mu_2,\n\\end{align*}\n$$\nwhere we used $$x^2_j = x_j$$ since it is an indicator.\n\nProposition 8. Consider Algorithm 3 with inputs $$n$$ i.i.d. samples $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d. $$\\sim XBernk(\\mu_1, \\ldots, \\mu_K)$$ for some $$K \\geq 2$$. Then, its outputs $$\\mu_1, \\hat{\\mu}_1$$ satisfy $$P(\\mu_1 \\geq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\leq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\leq \\mu_1 \\leq \\hat{\\mu}_1) \\leq 1 - \\frac{3\\beta}{2}$$.\n\nProof. Algorithm 3 computes the correct 2nd moment $$m^{(1)}_2$$ due to Proposition 6. Applying Bernstein\u2019s inequality to $$m^2$$, we get $$P(\\mu_2 \\leq \\hat{\\mu}_2) \\geq 1 - \\frac{\\beta}{2}$$ (see also the proof of Proposition 7). Next, from Bernstein\u2019s", "md": "Algorithm 3 Second-Order Bernstein Intervals\n\nInput: Random vectors $$x^{(1)}, \\ldots, x^{(n)} \\sim XBernK(\\mu_1, \\ldots, \\mu_K)$$ with unknown parameters, failure probability $$\\beta \\in (0, 1)$$.\n\nOutput: Confidence intervals $$[\\mu_1, \\hat{\\mu}_1]$$ such that $$P(\\mu_1 < \\hat{\\mu}_1) \\leq \\beta$$ and $$P(\\mu_1 > \\hat{\\mu}_1) \\leq \\beta$$.\n\n1. For each $i \\in [n]$, set $m^{(1)}_i = \\left(\\frac{1}{K}\\right) \\sum_{j=1}^{K} x^{(i)}_j$ and $m^{(2)}_i = m^{(1)}_i \\left(\\frac{K}{m^{(1)}_i} - 1\\right)$.\n2. Set $\\hat{\\mu}_{\\ell} = \\left(\\frac{1}{n}\\right) \\sum_{i=1}^{n} m^{(\\ell)}_i$ for $\\ell = 1, 2$.\n3. Set $\\mu_2$ as the unique solution of $x \\in [0, \\hat{\\mu}_2]$ such that $\\hat{\\mu}_2 - x - \\frac{n \\log 2 \\beta}{x(1 - x)} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_2 = 1$.\n4. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that $\\mu_1 - x - \\frac{n \\log 2 \\beta}{K - x^2 + \\mu_2} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_1 = 0$.\n5. Set $\\mu_1$ as the unique solution of $x \\in [\\hat{\\mu}_1, 1]$ such that $x - \\hat{\\mu}_2 - \\frac{n \\log 2 \\beta}{K - x^2 + \\mu_2} = 2 \\frac{3n \\log 2 \\beta}{x}$ if it exists, else set $\\mu_1 = 1$.\n6. Return $\\mu_1, \\hat{\\mu}_1$.\n\nC.1.2 Second-Order Bernstein Intervals\n\nThe second-order Bernstein interval only depends on the first two empirical moments $$\\mu_1$$ and $$\\mu_2$$. It is given in Algorithm 3. The algorithm is based on the calculation\n\n$$\n\\begin{align*}\n\\text{Var}(m^{(1)}) & = E[m^{(2)}_1] - K\\mu_1^2 \\\\\n& = E\\left[\\sum_{j=1}^{K} x^2_j + 2\\sum_{j_1 < j_2} x_{j_1}x_{j_2}\\right] - \\mu_1^2 \\\\\n& = \\mu_1 K - \\mu_1^2 + K(K-1)\\mu_2,\n\\end{align*}\n$$\nwhere we used $$x^2_j = x_j$$ since it is an indicator.\n\nProposition 8. Consider Algorithm 3 with inputs $$n$$ i.i.d. samples $$x^{(1)}, \\ldots, x^{(n)}$$ i.i.d. $$\\sim XBernk(\\mu_1, \\ldots, \\mu_K)$$ for some $$K \\geq 2$$. Then, its outputs $$\\mu_1, \\hat{\\mu}_1$$ satisfy $$P(\\mu_1 \\geq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\leq \\hat{\\mu}_1) \\geq 1 - \\beta$$ and $$P(\\mu_1 \\leq \\mu_1 \\leq \\hat{\\mu}_1) \\leq 1 - \\frac{3\\beta}{2}$$.\n\nProof. Algorithm 3 computes the correct 2nd moment $$m^{(1)}_2$$ due to Proposition 6. Applying Bernstein\u2019s inequality to $$m^2$$, we get $$P(\\mu_2 \\leq \\hat{\\mu}_2) \\geq 1 - \\frac{\\beta}{2}$$ (see also the proof of Proposition 7). Next, from Bernstein\u2019s"}]}, {"page": 23, "text": " inequality applied to m1, we leverage (17) to say that with probability at least 1 \u2212                                                \u03b2/2, we have\n                                        \u00b51 \u2212     \u02c6                              2            \u00b51\n                                                 \u00b51 \u2264      2                                              1 + K \u2212       1 \u00b52     .\n                                                          3n log 2   \u03b2 +        n log 2  \u03b2     K \u2212      \u00b52         K\nTogether with the result on \u00b5                   2, we have with probability at least 1 \u2212                       \u03b2 that\n                                        \u00b51 \u2212     \u02c6                              2            \u00b51\n                                                \u00b51 \u2264       2                                              1 + K \u2212       1 \u00b52      .\n                                                          3n log 2   \u03b2 +        n log 2  \u03b2     K \u2212      \u00b52         K\nWe can verify that the output \u00b5                     1 is the largest value of \u00b51 \u2264                1 that satisfies the above inequality. Similarly,\n \u00b5 1 is obtained as a lower Bernstein bound on m1 with probability at least 1 \u2212                                                    \u03b2. By the union bound,\n \u00b5 1 \u2264     \u00b51 \u2264     \u00b51 holds with probability at least 1 \u2212                          3\u03b2/2, since we have three invocations of Bernstein\u2019s\n inequality, each with a failure probability of \u03b2/2.\n C.1.3        Fourth-Order Bernstein Intervals\nThe fourth-order Bernstein interval depends on the first four empirical moments \u00b51, . . . , \u00b54. It is given in\nAlgorithm 4. The derivation of the interval is based on the calculation\n                          Var(m2) = E[m2            2] \u2212   \u00b522\n                                         =        2\u00b52               2 + 4(K \u2212         2)                                    \u00b54\n                                             K(K \u2212        1) \u2212    \u00b52      K(K \u2212        1)\u00b53 + (K \u2212          2)(K \u2212       3)\n                                                                                                        K(K \u2212       1)                                              (18)\n                                         = 2\u00b52(1 \u2212        \u00b52)                                    2) + (K \u2212        2)(K \u2212      3)  (\u00b54 \u2212    \u00b52 2)\n                                               K(K \u2212       1) + 4(K \u2212            2)\n                                         =: \u03c32  2(\u00b52, \u00b53, \u00b54) .      K(K \u2212       1)(\u00b53 \u2212       \u00b52            K(K \u2212        1)\n Proposition 9. Consider Algorithm 4 with inputs n i.i.d. samples x(1), . . . , x(n) i.i.d.                                         \u223c     XBernK(\u00b51, . . . , \u00b5K)\n for some K \u2265             4. Then, its outputs \u00b51, \u00b51 satisfy P(\u00b51 \u2265                               \u00b51) \u2265      1 \u2212    \u03b2 and P(\u00b51 \u2264             \u00b51) \u2265       1 \u2212   \u03b2 and\n P(\u00b5   1 \u2264   \u00b51 \u2264     \u00b51) \u2264     1 \u2212    5\u03b2\n                                        4 .\n Proof. Algorithm 4 computes the correct moments m(i)                               \u2113    for \u2113   \u2264   4 due to Proposition 6. Applying Bernstein\u2019s\n inequality to m3 and m4, we get P(\u00b5\u2113                         \u2264   \u00b5\u2113) \u2265     1 \u2212    \u03b2/4 for \u2113      = 3, 4 (see also the proof of Proposition 7).\n      Next, from Bernstein\u2019s inequality applied to m2, we have with probability at least 1 \u2212                                                    \u03b2/4 that\n                                                \u00b52 \u2212     \u02c6                           2\u03c32    2 (\u00b52, \u00b53, \u00b54)      log 4\n                                                         \u00b52 \u2264      2\n                                                                  3n log 4   \u03b2 +                   n                  \u03b2 .\n Combining this with the results on \u00b5                       3, \u00b5  4 with the union bound, we get with probability at least 1 \u2212                                     3\u03b2/4\n that                                           \u00b52 \u2212     \u02c6                          2\u03c32    2 (\u00b52, \u00b53, \u00b54)\n                                                        \u00b52 \u2264       2                                             log 4\n                                                                  3n log 4  \u03b2 +                    n                   \u03b2 .\n Finally, plugging this into a Bernstein bound on m1 using the variance calculation from (17) (also see the\n proof of Proposition 8) completes the proof.\n C.2         Asymptotic Confidence Intervals\nWe derive asymptotic versions of the Algorithms 2 to 4 using the Wilson confidence interval.\n                                                                                    23", "md": "When the inequality is applied to \\( m_1 \\), we leverage (17) to say that with probability at least \\( 1 - \\frac{\\beta}{2} \\), we have\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\leq \\frac{\\mu_1}{2(1 + K - \\frac{1}{\\mu_2})} \\cdot \\frac{3n \\log 2}{\\beta} + \\frac{n \\log 2}{\\beta} \\cdot (K - \\mu_2) \\cdot K\n$$\n\nTogether with the result on \\( \\mu_2 \\), we have with probability at least \\( 1 - \\beta \\) that\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\leq \\frac{\\mu_1}{2(1 + K - \\frac{1}{\\mu_2})} \\cdot \\frac{3n \\log 2}{\\beta} + \\frac{n \\log 2}{\\beta} \\cdot (K - \\mu_2) \\cdot K\n$$\n\nWe can verify that the output \\( \\mu_1 \\) is the largest value of \\( \\mu_1 \\leq 1 \\) that satisfies the above inequality. Similarly, \\( \\mu_1 \\) is obtained as a lower Bernstein bound on \\( m_1 \\) with probability at least \\( 1 - \\beta \\). By the union bound, \\( \\mu_1 \\leq \\mu_1 \\leq \\mu_1 \\) holds with probability at least \\( 1 - \\frac{3\\beta}{2} \\), since we have three invocations of Bernstein\u2019s inequality, each with a failure probability of \\( \\frac{\\beta}{2} \\).\n\n### Fourth-Order Bernstein Intervals\n\nThe fourth-order Bernstein interval depends on the first four empirical moments \\( \\mu_1, ..., \\mu_4 \\). It is given in Algorithm 4. The derivation of the interval is based on the calculation\n\n$$\n\\text{Var}(m_2) = E[m_2^2] - \\mu_2^2 = 2\\mu_2^2 + 4(K - 2)\\mu_4 - \\mu_2(K - 1)\\mu_3 + (K - 2)(K - 3)(\\mu_4 - \\mu_2^2) = 2\\mu_2(1 - \\mu_2)^2 + (K - 2)(K - 3)(\\mu_4 - \\mu_2^2)\n$$\n\n$$\n= \\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) = \\frac{K(K - 1)(\\mu_3 - \\mu_2)}{K(K - 1)}\n$$\n\nProposition 9. Consider Algorithm 4 with inputs \\( n \\) i.i.d. samples \\( x(1), ..., x(n) \\) i.i.d. ~ XBernK(\\mu_1, ..., \\mu_K) for some \\( K \\geq 4 \\). Then, its outputs \\( \\mu_1, \\mu_1 \\) satisfy \\( P(\\mu_1 \\geq \\mu_1) \\geq 1 - \\beta \\) and \\( P(\\mu_1 \\leq \\mu_1) \\geq 1 - \\beta \\) and \\( P(\\mu_1 \\leq \\mu_1 \\leq \\mu_1) \\leq 1 - \\frac{5\\beta}{4} \\).\n\nProof. Algorithm 4 computes the correct moments \\( m(i)_{\\ell} \\) for \\( \\ell \\leq 4 \\) due to Proposition 6. Applying Bernstein\u2019s inequality to \\( m_3 \\) and \\( m_4 \\), we get \\( P(\\mu_{\\ell} \\leq \\mu_{\\ell}) \\geq 1 - \\frac{\\beta}{4} \\) for \\( \\ell = 3, 4 \\) (see also the proof of Proposition 7). Next, from Bernstein\u2019s inequality applied to \\( m_2 \\), we have with probability at least \\( 1 - \\frac{\\beta}{4} \\) that\n\n$$\n\\mu_2 - \\hat{\\mu}_2^2 \\leq \\frac{2\\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) \\log 4}{3n \\log 4 \\beta + n \\beta}\n$$\n\nCombining this with the results on \\( \\mu_3, \\mu_4 \\) with the union bound, we get with probability at least \\( 1 - \\frac{3\\beta}{4} \\) that\n\n$$\n\\mu_2 - \\hat{\\mu}_2^2 \\leq \\frac{2\\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) \\log 4}{3n \\log 4 \\beta + n \\beta}\n$$\n\nFinally, plugging this into a Bernstein bound on \\( m_1 \\) using the variance calculation from (17) (also see the proof of Proposition 8) completes the proof.\n\n### Asymptotic Confidence Intervals\n\nWe derive asymptotic versions of the Algorithms 2 to 4 using the Wilson confidence interval.", "images": [], "items": [{"type": "text", "value": "When the inequality is applied to \\( m_1 \\), we leverage (17) to say that with probability at least \\( 1 - \\frac{\\beta}{2} \\), we have\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\leq \\frac{\\mu_1}{2(1 + K - \\frac{1}{\\mu_2})} \\cdot \\frac{3n \\log 2}{\\beta} + \\frac{n \\log 2}{\\beta} \\cdot (K - \\mu_2) \\cdot K\n$$\n\nTogether with the result on \\( \\mu_2 \\), we have with probability at least \\( 1 - \\beta \\) that\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\leq \\frac{\\mu_1}{2(1 + K - \\frac{1}{\\mu_2})} \\cdot \\frac{3n \\log 2}{\\beta} + \\frac{n \\log 2}{\\beta} \\cdot (K - \\mu_2) \\cdot K\n$$\n\nWe can verify that the output \\( \\mu_1 \\) is the largest value of \\( \\mu_1 \\leq 1 \\) that satisfies the above inequality. Similarly, \\( \\mu_1 \\) is obtained as a lower Bernstein bound on \\( m_1 \\) with probability at least \\( 1 - \\beta \\). By the union bound, \\( \\mu_1 \\leq \\mu_1 \\leq \\mu_1 \\) holds with probability at least \\( 1 - \\frac{3\\beta}{2} \\), since we have three invocations of Bernstein\u2019s inequality, each with a failure probability of \\( \\frac{\\beta}{2} \\).", "md": "When the inequality is applied to \\( m_1 \\), we leverage (17) to say that with probability at least \\( 1 - \\frac{\\beta}{2} \\), we have\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\leq \\frac{\\mu_1}{2(1 + K - \\frac{1}{\\mu_2})} \\cdot \\frac{3n \\log 2}{\\beta} + \\frac{n \\log 2}{\\beta} \\cdot (K - \\mu_2) \\cdot K\n$$\n\nTogether with the result on \\( \\mu_2 \\), we have with probability at least \\( 1 - \\beta \\) that\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\leq \\frac{\\mu_1}{2(1 + K - \\frac{1}{\\mu_2})} \\cdot \\frac{3n \\log 2}{\\beta} + \\frac{n \\log 2}{\\beta} \\cdot (K - \\mu_2) \\cdot K\n$$\n\nWe can verify that the output \\( \\mu_1 \\) is the largest value of \\( \\mu_1 \\leq 1 \\) that satisfies the above inequality. Similarly, \\( \\mu_1 \\) is obtained as a lower Bernstein bound on \\( m_1 \\) with probability at least \\( 1 - \\beta \\). By the union bound, \\( \\mu_1 \\leq \\mu_1 \\leq \\mu_1 \\) holds with probability at least \\( 1 - \\frac{3\\beta}{2} \\), since we have three invocations of Bernstein\u2019s inequality, each with a failure probability of \\( \\frac{\\beta}{2} \\)."}, {"type": "heading", "lvl": 3, "value": "Fourth-Order Bernstein Intervals", "md": "### Fourth-Order Bernstein Intervals"}, {"type": "text", "value": "The fourth-order Bernstein interval depends on the first four empirical moments \\( \\mu_1, ..., \\mu_4 \\). It is given in Algorithm 4. The derivation of the interval is based on the calculation\n\n$$\n\\text{Var}(m_2) = E[m_2^2] - \\mu_2^2 = 2\\mu_2^2 + 4(K - 2)\\mu_4 - \\mu_2(K - 1)\\mu_3 + (K - 2)(K - 3)(\\mu_4 - \\mu_2^2) = 2\\mu_2(1 - \\mu_2)^2 + (K - 2)(K - 3)(\\mu_4 - \\mu_2^2)\n$$\n\n$$\n= \\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) = \\frac{K(K - 1)(\\mu_3 - \\mu_2)}{K(K - 1)}\n$$\n\nProposition 9. Consider Algorithm 4 with inputs \\( n \\) i.i.d. samples \\( x(1), ..., x(n) \\) i.i.d. ~ XBernK(\\mu_1, ..., \\mu_K) for some \\( K \\geq 4 \\). Then, its outputs \\( \\mu_1, \\mu_1 \\) satisfy \\( P(\\mu_1 \\geq \\mu_1) \\geq 1 - \\beta \\) and \\( P(\\mu_1 \\leq \\mu_1) \\geq 1 - \\beta \\) and \\( P(\\mu_1 \\leq \\mu_1 \\leq \\mu_1) \\leq 1 - \\frac{5\\beta}{4} \\).\n\nProof. Algorithm 4 computes the correct moments \\( m(i)_{\\ell} \\) for \\( \\ell \\leq 4 \\) due to Proposition 6. Applying Bernstein\u2019s inequality to \\( m_3 \\) and \\( m_4 \\), we get \\( P(\\mu_{\\ell} \\leq \\mu_{\\ell}) \\geq 1 - \\frac{\\beta}{4} \\) for \\( \\ell = 3, 4 \\) (see also the proof of Proposition 7). Next, from Bernstein\u2019s inequality applied to \\( m_2 \\), we have with probability at least \\( 1 - \\frac{\\beta}{4} \\) that\n\n$$\n\\mu_2 - \\hat{\\mu}_2^2 \\leq \\frac{2\\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) \\log 4}{3n \\log 4 \\beta + n \\beta}\n$$\n\nCombining this with the results on \\( \\mu_3, \\mu_4 \\) with the union bound, we get with probability at least \\( 1 - \\frac{3\\beta}{4} \\) that\n\n$$\n\\mu_2 - \\hat{\\mu}_2^2 \\leq \\frac{2\\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) \\log 4}{3n \\log 4 \\beta + n \\beta}\n$$\n\nFinally, plugging this into a Bernstein bound on \\( m_1 \\) using the variance calculation from (17) (also see the proof of Proposition 8) completes the proof.", "md": "The fourth-order Bernstein interval depends on the first four empirical moments \\( \\mu_1, ..., \\mu_4 \\). It is given in Algorithm 4. The derivation of the interval is based on the calculation\n\n$$\n\\text{Var}(m_2) = E[m_2^2] - \\mu_2^2 = 2\\mu_2^2 + 4(K - 2)\\mu_4 - \\mu_2(K - 1)\\mu_3 + (K - 2)(K - 3)(\\mu_4 - \\mu_2^2) = 2\\mu_2(1 - \\mu_2)^2 + (K - 2)(K - 3)(\\mu_4 - \\mu_2^2)\n$$\n\n$$\n= \\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) = \\frac{K(K - 1)(\\mu_3 - \\mu_2)}{K(K - 1)}\n$$\n\nProposition 9. Consider Algorithm 4 with inputs \\( n \\) i.i.d. samples \\( x(1), ..., x(n) \\) i.i.d. ~ XBernK(\\mu_1, ..., \\mu_K) for some \\( K \\geq 4 \\). Then, its outputs \\( \\mu_1, \\mu_1 \\) satisfy \\( P(\\mu_1 \\geq \\mu_1) \\geq 1 - \\beta \\) and \\( P(\\mu_1 \\leq \\mu_1) \\geq 1 - \\beta \\) and \\( P(\\mu_1 \\leq \\mu_1 \\leq \\mu_1) \\leq 1 - \\frac{5\\beta}{4} \\).\n\nProof. Algorithm 4 computes the correct moments \\( m(i)_{\\ell} \\) for \\( \\ell \\leq 4 \\) due to Proposition 6. Applying Bernstein\u2019s inequality to \\( m_3 \\) and \\( m_4 \\), we get \\( P(\\mu_{\\ell} \\leq \\mu_{\\ell}) \\geq 1 - \\frac{\\beta}{4} \\) for \\( \\ell = 3, 4 \\) (see also the proof of Proposition 7). Next, from Bernstein\u2019s inequality applied to \\( m_2 \\), we have with probability at least \\( 1 - \\frac{\\beta}{4} \\) that\n\n$$\n\\mu_2 - \\hat{\\mu}_2^2 \\leq \\frac{2\\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) \\log 4}{3n \\log 4 \\beta + n \\beta}\n$$\n\nCombining this with the results on \\( \\mu_3, \\mu_4 \\) with the union bound, we get with probability at least \\( 1 - \\frac{3\\beta}{4} \\) that\n\n$$\n\\mu_2 - \\hat{\\mu}_2^2 \\leq \\frac{2\\sigma^2 2(\\mu_2, \\mu_3, \\mu_4) \\log 4}{3n \\log 4 \\beta + n \\beta}\n$$\n\nFinally, plugging this into a Bernstein bound on \\( m_1 \\) using the variance calculation from (17) (also see the proof of Proposition 8) completes the proof."}, {"type": "heading", "lvl": 3, "value": "Asymptotic Confidence Intervals", "md": "### Asymptotic Confidence Intervals"}, {"type": "text", "value": "We derive asymptotic versions of the Algorithms 2 to 4 using the Wilson confidence interval.", "md": "We derive asymptotic versions of the Algorithms 2 to 4 using the Wilson confidence interval."}]}, {"page": 24, "text": "Algorithm 4 Fourth-Order Bernstein Intervals\n Input: Random vectors x(1), . . . , x(n) \u223c                       XBernK(\u00b51, . . . , \u00b5K) with unknown parameters, failure probability\n       \u03b2 \u2208   (0, 1).\n Output: Confidence intervals [\u00b5                     1, \u00b51] such that P(\u00b51 < \u00b5                1) \u2264   \u03b2 and P(\u00b51 > \u00b51) \u2264           Km(i)\u03b2. 1 \u2212\u2113\n   1: For each i \u2208         [n], set m(i)   1   = (1/K)  K        j=1 x(i)j    and for \u2113      = 1, 2, 3: m(i)    \u2113+1 = m(i)   \u2113          K\u2212\u2113          .\n   2: Set \u02c6  \u00b5\u2113   = (1/n)  n       i=1 m(i) \u2113    for \u2113   = 1, 2, 3, 4.               \u00b5\u2113, 1] such that\n   3: For \u2113     = 3, 4, set \u00b5      \u2113  as the unique solution of x \u2208                 [\u02c6\n                                                         x \u2212    \u02c6             2\n             if it exists, else set \u00b5         \u2113  = 1.          \u00b5\u2113   \u2212         n log 4  \u03b2     x(1 \u2212     x) = 2   3n log 4   \u03b2 .\n   4: Set \u00b5     2 as the unique solution, if it exists, of x \u2208                      [\u02c6\n                                                                                     \u00b52, 1] such that\n                                                     x \u2212    \u02c6              2               \u03c32\n                                                            \u00b52 \u2212           n log 4  \u03b2        2 (x, \u00b53, \u00b54) = 2       3n log 4  \u03b2\n             where \u03c32     2(\u00b7, \u00b7, \u00b7) is as defined in (18). Else set \u00b52 = 1.\n   5: Set \u00b5     1 as the unique solution of x \u2208                  [0, \u02c6\n                                                                     \u00b51] such that\n                                                    \u02c6                     2               x\n             if it exists, else set \u00b5         1 = 0.\u00b51 \u2212    x \u2212           n log 4 \u03b2         k \u2212    x2 + \u00b52        = 2 3n log 4   \u03b2\n   6: Set \u00b5     1 as the unique solution of x \u2208                  [\u02c6\n                                                                  \u00b51, 1] such that\n                                                    x \u2212    \u02c6              2               x\n             if it exists, else set \u00b5         1 = 1.      \u00b51 \u2212            n log 4 \u03b2         k \u2212    x2 + \u00b52        = 2 3n log 4   \u03b2\n   7: return \u00b5        1, \u00b51.\n      The Wilson confidence interval is a tightening of the constants for the Bernstein confidence interval\n                        \u00b51 \u2212     \u02c6           2 log(1/\u03b2)                                                                       Z2\u03b2\n                                \u00b51 \u2264                          Var(m1) + 2                         to     \u00b51 \u2212    \u02c6\n                                                    n                            3n log 1  \u03b2                     \u00b51 \u2264          n Var(m1) ,\nwhere Z\u03b2 is the (1 \u2212              \u03b2)-quantile of the standard Gaussian. Essentially, this completely eliminates the 1/n\n term, while the coefficient of the 1/\u221an term improves from                                        2 log(1/\u03b2) to Z\u03b2 \u2014 see Figure 2. The Wilson\n approximation holds under the assumption that (\u00b51 \u2212                                     \u02c6                             d\n confidence interval. This can be formalized by the the central limit theorem.           \u00b51)/       Var(m1)/n          \u2248   N  (0, 1) and using a Gaussian\n Lemma 10 (Lindeberg\u2013L\u00b4                  evy Central Limit Theorem). Consider a sequence of independent random variables\n y(1)  , y(2) , . . . with finite moments E[y(i)] = \u00b5 < \u221e                      and E(y(i) \u2212\u00b5)2 = \u03c32 < \u221e                    for each i. Then, the empirical\nmean \u02c6    \u00b5n = (1/n)  n         i=1 y(i) based on n samples satisfies\n                                                                   \u02c6\n                                                      lim          \u00b5n \u2212     \u00b5           = P\u03be\u223cN (0,1) (\u03be > t)\n                                                     n\u2192\u221e     P      \u03c3/\u221an > t\n                                                                                    24", "md": "Algorithm 4 Fourth-Order Bernstein Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(P(\\mu_1 > \\mu_1) \\leq Km(i)\\beta\\).\n\n1. For each \\(i \\in [n]\\), set \\(m(i)_1 = (1/K) \\sum_{j=1}^{K} x(i)_j\\) and for \\(\\ell = 1, 2, 3\\): \\(m(i)_{\\ell+1} = m(i)_{\\ell} \\sum_{K-\\ell}\\).\n2. Set \\(\\hat{\\mu}_{\\ell} = (1/n) \\sum_{i=1}^{n} m(i)_{\\ell}\\) for \\(\\ell = 1, 2, 3, 4\\).\n3. For \\(\\ell = 3, 4\\), set \\(\\mu_{\\ell}\\) as the unique solution of \\(x \\in [\\hat{x} - \\hat{x}^2, 1]\\) such that if it exists, else set \\(\\mu_{\\ell} = 1\\).\n4. Set \\(\\mu_2\\) as the unique solution, if it exists, of \\(x \\in [\\hat{\\mu}_2 - \\hat{\\mu}_2^2, 1]\\) such that where \\(\\sigma^2_2(\\cdot, \\cdot, \\cdot)\\) is as defined in (18). Else set \\(\\mu_2 = 1\\).\n5. Set \\(\\mu_1\\) as the unique solution of \\(x \\in [0, \\hat{\\mu}_1]\\) such that if it exists, else set \\(\\mu_1 = 0\\).\n6. Set \\(\\mu_1\\) as the unique solution of \\(x \\in [\\hat{\\mu}_1, 1]\\) such that if it exists, else set \\(\\mu_1 = 1\\).\n7. Return \\(\\mu_1, \\mu_1\\).\n\nThe Wilson confidence interval is a tightening of the constants for the Bernstein confidence interval\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\log(1/\\beta) \\leq Z_{2\\beta} \\sqrt{\\frac{{\\text{Var}(m_1)} + 2}}{{n}} \\leq \\mu_1 - \\hat{\\mu}_1^2 \\frac{{n}}{{3n}} \\log(1/\\beta) \\leq n \\text{Var}(m_1),\n$$\nwhere \\(Z_{\\beta}\\) is the \\((1 - \\beta)\\)-quantile of the standard Gaussian. Essentially, this completely eliminates the \\(1/n\\) term, while the coefficient of the \\(1/\\sqrt{n}\\) term improves from \\(2 \\log(1/\\beta)\\) to \\(Z_{\\beta}\\) \u2014 see Figure 2. The Wilson approximation holds under the assumption that \\((\\mu_1 - \\hat{\\mu}_1)/\\sqrt{{\\text{Var}(m_1)/n}} \\approx N(0, 1)\\) and using a Gaussian confidence interval. This can be formalized by the central limit theorem.\n\nLemma 10 (Lindeberg\u2013L\u00e9vy Central Limit Theorem). Consider a sequence of independent random variables \\(y(1), y(2), . . .\\) with finite moments \\(E[y(i)] = \\mu < \\infty\\) and \\(E(y(i) - \\mu)^2 = \\sigma^2 < \\infty\\) for each \\(i\\). Then, the empirical mean \\(\\hat{\\mu}_n = (1/n) \\sum_{i=1}^{n} y(i)\\) based on \\(n\\) samples satisfies\n\n$$\n\\lim_{n \\to \\infty} P\\left(\\frac{\\hat{\\mu}_n - \\mu}{\\sigma/\\sqrt{n}} > t\\right) = P\\left(\\xi \\sim N(0,1) (\\xi > t)\\right)\n$$", "images": [], "items": [{"type": "text", "value": "Algorithm 4 Fourth-Order Bernstein Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(P(\\mu_1 > \\mu_1) \\leq Km(i)\\beta\\).\n\n1. For each \\(i \\in [n]\\), set \\(m(i)_1 = (1/K) \\sum_{j=1}^{K} x(i)_j\\) and for \\(\\ell = 1, 2, 3\\): \\(m(i)_{\\ell+1} = m(i)_{\\ell} \\sum_{K-\\ell}\\).\n2. Set \\(\\hat{\\mu}_{\\ell} = (1/n) \\sum_{i=1}^{n} m(i)_{\\ell}\\) for \\(\\ell = 1, 2, 3, 4\\).\n3. For \\(\\ell = 3, 4\\), set \\(\\mu_{\\ell}\\) as the unique solution of \\(x \\in [\\hat{x} - \\hat{x}^2, 1]\\) such that if it exists, else set \\(\\mu_{\\ell} = 1\\).\n4. Set \\(\\mu_2\\) as the unique solution, if it exists, of \\(x \\in [\\hat{\\mu}_2 - \\hat{\\mu}_2^2, 1]\\) such that where \\(\\sigma^2_2(\\cdot, \\cdot, \\cdot)\\) is as defined in (18). Else set \\(\\mu_2 = 1\\).\n5. Set \\(\\mu_1\\) as the unique solution of \\(x \\in [0, \\hat{\\mu}_1]\\) such that if it exists, else set \\(\\mu_1 = 0\\).\n6. Set \\(\\mu_1\\) as the unique solution of \\(x \\in [\\hat{\\mu}_1, 1]\\) such that if it exists, else set \\(\\mu_1 = 1\\).\n7. Return \\(\\mu_1, \\mu_1\\).\n\nThe Wilson confidence interval is a tightening of the constants for the Bernstein confidence interval\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\log(1/\\beta) \\leq Z_{2\\beta} \\sqrt{\\frac{{\\text{Var}(m_1)} + 2}}{{n}} \\leq \\mu_1 - \\hat{\\mu}_1^2 \\frac{{n}}{{3n}} \\log(1/\\beta) \\leq n \\text{Var}(m_1),\n$$\nwhere \\(Z_{\\beta}\\) is the \\((1 - \\beta)\\)-quantile of the standard Gaussian. Essentially, this completely eliminates the \\(1/n\\) term, while the coefficient of the \\(1/\\sqrt{n}\\) term improves from \\(2 \\log(1/\\beta)\\) to \\(Z_{\\beta}\\) \u2014 see Figure 2. The Wilson approximation holds under the assumption that \\((\\mu_1 - \\hat{\\mu}_1)/\\sqrt{{\\text{Var}(m_1)/n}} \\approx N(0, 1)\\) and using a Gaussian confidence interval. This can be formalized by the central limit theorem.\n\nLemma 10 (Lindeberg\u2013L\u00e9vy Central Limit Theorem). Consider a sequence of independent random variables \\(y(1), y(2), . . .\\) with finite moments \\(E[y(i)] = \\mu < \\infty\\) and \\(E(y(i) - \\mu)^2 = \\sigma^2 < \\infty\\) for each \\(i\\). Then, the empirical mean \\(\\hat{\\mu}_n = (1/n) \\sum_{i=1}^{n} y(i)\\) based on \\(n\\) samples satisfies\n\n$$\n\\lim_{n \\to \\infty} P\\left(\\frac{\\hat{\\mu}_n - \\mu}{\\sigma/\\sqrt{n}} > t\\right) = P\\left(\\xi \\sim N(0,1) (\\xi > t)\\right)\n$$", "md": "Algorithm 4 Fourth-Order Bernstein Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(P(\\mu_1 > \\mu_1) \\leq Km(i)\\beta\\).\n\n1. For each \\(i \\in [n]\\), set \\(m(i)_1 = (1/K) \\sum_{j=1}^{K} x(i)_j\\) and for \\(\\ell = 1, 2, 3\\): \\(m(i)_{\\ell+1} = m(i)_{\\ell} \\sum_{K-\\ell}\\).\n2. Set \\(\\hat{\\mu}_{\\ell} = (1/n) \\sum_{i=1}^{n} m(i)_{\\ell}\\) for \\(\\ell = 1, 2, 3, 4\\).\n3. For \\(\\ell = 3, 4\\), set \\(\\mu_{\\ell}\\) as the unique solution of \\(x \\in [\\hat{x} - \\hat{x}^2, 1]\\) such that if it exists, else set \\(\\mu_{\\ell} = 1\\).\n4. Set \\(\\mu_2\\) as the unique solution, if it exists, of \\(x \\in [\\hat{\\mu}_2 - \\hat{\\mu}_2^2, 1]\\) such that where \\(\\sigma^2_2(\\cdot, \\cdot, \\cdot)\\) is as defined in (18). Else set \\(\\mu_2 = 1\\).\n5. Set \\(\\mu_1\\) as the unique solution of \\(x \\in [0, \\hat{\\mu}_1]\\) such that if it exists, else set \\(\\mu_1 = 0\\).\n6. Set \\(\\mu_1\\) as the unique solution of \\(x \\in [\\hat{\\mu}_1, 1]\\) such that if it exists, else set \\(\\mu_1 = 1\\).\n7. Return \\(\\mu_1, \\mu_1\\).\n\nThe Wilson confidence interval is a tightening of the constants for the Bernstein confidence interval\n\n$$\n\\mu_1 - \\hat{\\mu}_1^2 \\log(1/\\beta) \\leq Z_{2\\beta} \\sqrt{\\frac{{\\text{Var}(m_1)} + 2}}{{n}} \\leq \\mu_1 - \\hat{\\mu}_1^2 \\frac{{n}}{{3n}} \\log(1/\\beta) \\leq n \\text{Var}(m_1),\n$$\nwhere \\(Z_{\\beta}\\) is the \\((1 - \\beta)\\)-quantile of the standard Gaussian. Essentially, this completely eliminates the \\(1/n\\) term, while the coefficient of the \\(1/\\sqrt{n}\\) term improves from \\(2 \\log(1/\\beta)\\) to \\(Z_{\\beta}\\) \u2014 see Figure 2. The Wilson approximation holds under the assumption that \\((\\mu_1 - \\hat{\\mu}_1)/\\sqrt{{\\text{Var}(m_1)/n}} \\approx N(0, 1)\\) and using a Gaussian confidence interval. This can be formalized by the central limit theorem.\n\nLemma 10 (Lindeberg\u2013L\u00e9vy Central Limit Theorem). Consider a sequence of independent random variables \\(y(1), y(2), . . .\\) with finite moments \\(E[y(i)] = \\mu < \\infty\\) and \\(E(y(i) - \\mu)^2 = \\sigma^2 < \\infty\\) for each \\(i\\). Then, the empirical mean \\(\\hat{\\mu}_n = (1/n) \\sum_{i=1}^{n} y(i)\\) based on \\(n\\) samples satisfies\n\n$$\n\\lim_{n \\to \\infty} P\\left(\\frac{\\hat{\\mu}_n - \\mu}{\\sigma/\\sqrt{n}} > t\\right) = P\\left(\\xi \\sim N(0,1) (\\xi > t)\\right)\n$$"}]}, {"page": 25, "text": "Algorithm 5 First-Order Wilson Intervals\n Input: Random vectors x(1), . . . , x(n) \u223c                       XBernK(\u00b51, . . . , \u00b5K) with unknown parameters, failure probability\n       \u03b2 \u2208   (0, 1).\n Output: Asymptotic confidence intervals [\u00b5                              1, \u00b51] such that limn\u2192\u221e                P(\u00b51 < \u00b51) \u2264           \u03b2 and limn\u2192\u221e         P(\u00b51 >\n       \u00b5 1) \u2264    \u03b2.\n   1: Set \u00b5     1 < \u00b51 as the roots of the quadratic in x:\n                                                            (n + Z2                     \u00b5 1 + Z2               \u00b52\n   2: return \u00b5        1, \u00b51.                                          \u03b2) x2 \u2212     (2n\u02c6             \u03b2) x + n\u02c61 = 0 .\nAlgorithm 6 Second-Order Wilson Intervals\n Input: Random vectors x(1), . . . , x(n) \u223c                       XBernK(\u00b51, . . . , \u00b5K) with unknown parameters, failure probability\n       \u03b2 \u2208   (0, 1).\n Output: Asymptotic confidence intervals [\u00b5                              1, \u00b51] such that limn\u2192\u221e                P(\u00b51 < \u00b51) \u2264           \u03b2 and limn\u2192\u221e         P(\u00b51 >\n       \u00b5 1) \u2264    \u03b2.                                                           and m(i)       = m(i)         Km(i)1 \u22121\n   1: For each i \u2208         [n], set m(i)   1   = (1/K)  K        j=1 x(i)j               2           1         K\u22121           .\n   2: Set \u02c6  \u00b5\u2113   = (1/n)  n       i=1 m(i) \u2113    for \u2113   = 1, 2.\n   3: Let \u00b5     2 be the larger root of the quadratic in x:\n                                                         (n + Z2   \u03b2/2) x2 \u2212      (2n\u02c6  \u00b5 2 + Z2   \u03b2/2) x + n\u02c6    \u00b52 2 = 0 .\n   4: Set \u00b5     1 < \u00b51 as the roots of the quadratic in x:\n   5: return \u00b5        1, \u00b51.          (n + Z2    \u03b2/2) x2 \u2212        2n\u02c6 \u00b51 +     Z2K\u03b2/2      x + n\u02c6   \u00b52 1 \u2212    K \u2212  K   1     Z2\u03b2/2 \u00b52 = 0 .\n for all t \u2208     R. Consequently, we have,\n                      lim        \u00b5 \u2212    \u02c6                                                              \u02c6\n                                        \u00b5n > \u03c3Z\u03b2/\u221an              \u2265   1 \u2212   \u03b2     and         lim        \u00b5n \u2212     \u00b5 > \u03c3Z\u03b2/\u221an             \u2265   1 \u2212   \u03b2 .\n                     n\u2192\u221e     P                                                             n\u2192\u221e      P\n      The finite moment requirement above is satisfied in our case because all our random variables are bounded\n between 0 and 1.\n      We give the Wilson-variants of Algorithms 2 to 4 respectively in Algorithms 5 to 7. Apart from the fact\n that the Wilson intervals are tighter, we can also solve the equations associated with the Wilson intervals in\n closed form as they are simply quadratic equations (i.e., without the need for numerical root-finding). The\n following proposition shows their correctness.\n Proposition 11. Consider n i.i.d. samples x(1), . . . , x(n) i.i.d.                        \u223c     XBernK(\u00b51, . . . , \u00b5K) as inputs to Algorithms 5\nto 7. Then, their outputs \u00b5                  1, \u00b51 satisfy limn\u2192\u221e             P(\u00b51 \u2264       \u00b51) \u2265     1 \u2212   \u03b2 and limn\u2192\u221e            P(\u00b51 \u2265       \u00b51) \u2265  1 \u2212    \u03b2 and\n limn\u2192\u221e       P(\u00b51 \u2264       \u00b51 \u2264    \u00b51) \u2264      1 \u2212   C\u03b2 if\n   (a) K \u2265        1 and C = 2 for Algorithm 5,\n   (b) K \u2265        2 and C = 3/2 for Algorithm 6, and\n   (c) K \u2265        4 and C = 5/4 for Algorithm 7.\n                                                                                    25", "md": "Algorithm 5 First-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n\\begin{enumerate}\n\\item Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\mu_1 + Z^2 \\mu_2}{\\beta}) x^2 - (2n\\hat{\\beta}) x + n\\hat{1} = 0 .\n\\]\n\\item return \\(\\mu_1, \\mu_1\\).\n\\end{enumerate}\n\nAlgorithm 6 Second-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n\\begin{enumerate}\n\\item For each \\(i \\in [n]\\), set \\(m(i)_1 = \\frac{1}{K} \\sum_{j=1}^{K} x(i)_j^2 \\).\n\\item Set \\(\\hat{\\mu}_\\ell = \\frac{1}{n} \\sum_{i=1}^{n} m(i)_\\ell\\) for \\(\\ell = 1, 2\\).\n\\item Let \\(\\mu_2\\) be the larger root of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\beta}{2}) x^2 - (2n\\hat{\\mu}_2 + Z^2 \\frac{\\beta}{2}) x + n\\hat{\\mu}_2^2 = 0 .\n\\]\n\\item Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\beta}{2}) x^2 - 2n\\hat{\\mu}_1 + Z^2K\\frac{\\beta}{2} x + n\\hat{\\mu}_1^2 - K - K^2 1 Z^2 \\frac{\\beta}{2} \\mu_2 = 0 .\n\\]\n\\item return \\(\\mu_1, \\mu_1\\).\n\\end{enumerate}\n\nFor all \\(t \\in \\mathbb{R}\\), we have,\n\\[\n\\lim_{n \\to \\infty} P\\left(\\mu - \\hat{\\mu}_n > \\sigma Z_{\\beta}/\\sqrt{n}\\right) \\geq 1 - \\beta \\quad \\text{and} \\quad \\lim_{n \\to \\infty} P\\left(\\hat{\\mu}_n - \\mu > \\sigma Z_{\\beta}/\\sqrt{n}\\right) \\geq 1 - \\beta .\n\\]\n\nThe finite moment requirement above is satisfied in our case because all our random variables are bounded between 0 and 1.\n\nWe give the Wilson-variants of Algorithms 2 to 4 respectively in Algorithms 5 to 7. Apart from the fact that the Wilson intervals are tighter, we can also solve the equations associated with the Wilson intervals in closed form as they are simply quadratic equations (i.e., without the need for numerical root-finding). The following proposition shows their correctness.\n\n\\textbf{Proposition 11.} Consider \\(n\\) i.i.d. samples \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) as inputs to Algorithms 5 to 7. Then, their outputs \\(\\mu_1, \\mu_1\\) satisfy \\(\\lim_{n \\to \\infty} P(\\mu_1 \\leq \\mu_1) \\geq 1 - \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 \\geq \\mu_1) \\geq 1 - \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 \\leq \\mu_1 \\leq \\mu_1) \\leq 1 - C\\beta\\) if\n\\begin{enumerate}\n\\item \\(K \\geq 1\\) and \\(C = 2\\) for Algorithm 5,\n\\item \\(K \\geq 2\\) and \\(C = 3/2\\) for Algorithm 6, and\n\\item \\(K \\geq 4\\) and \\(C = 5/4\\) for Algorithm 7.\n\\end{enumerate}", "images": [], "items": [{"type": "text", "value": "Algorithm 5 First-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n\\begin{enumerate}\n\\item Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\mu_1 + Z^2 \\mu_2}{\\beta}) x^2 - (2n\\hat{\\beta}) x + n\\hat{1} = 0 .\n\\]\n\\item return \\(\\mu_1, \\mu_1\\).\n\\end{enumerate}\n\nAlgorithm 6 Second-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n\\begin{enumerate}\n\\item For each \\(i \\in [n]\\), set \\(m(i)_1 = \\frac{1}{K} \\sum_{j=1}^{K} x(i)_j^2 \\).\n\\item Set \\(\\hat{\\mu}_\\ell = \\frac{1}{n} \\sum_{i=1}^{n} m(i)_\\ell\\) for \\(\\ell = 1, 2\\).\n\\item Let \\(\\mu_2\\) be the larger root of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\beta}{2}) x^2 - (2n\\hat{\\mu}_2 + Z^2 \\frac{\\beta}{2}) x + n\\hat{\\mu}_2^2 = 0 .\n\\]\n\\item Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\beta}{2}) x^2 - 2n\\hat{\\mu}_1 + Z^2K\\frac{\\beta}{2} x + n\\hat{\\mu}_1^2 - K - K^2 1 Z^2 \\frac{\\beta}{2} \\mu_2 = 0 .\n\\]\n\\item return \\(\\mu_1, \\mu_1\\).\n\\end{enumerate}\n\nFor all \\(t \\in \\mathbb{R}\\), we have,\n\\[\n\\lim_{n \\to \\infty} P\\left(\\mu - \\hat{\\mu}_n > \\sigma Z_{\\beta}/\\sqrt{n}\\right) \\geq 1 - \\beta \\quad \\text{and} \\quad \\lim_{n \\to \\infty} P\\left(\\hat{\\mu}_n - \\mu > \\sigma Z_{\\beta}/\\sqrt{n}\\right) \\geq 1 - \\beta .\n\\]\n\nThe finite moment requirement above is satisfied in our case because all our random variables are bounded between 0 and 1.\n\nWe give the Wilson-variants of Algorithms 2 to 4 respectively in Algorithms 5 to 7. Apart from the fact that the Wilson intervals are tighter, we can also solve the equations associated with the Wilson intervals in closed form as they are simply quadratic equations (i.e., without the need for numerical root-finding). The following proposition shows their correctness.\n\n\\textbf{Proposition 11.} Consider \\(n\\) i.i.d. samples \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) as inputs to Algorithms 5 to 7. Then, their outputs \\(\\mu_1, \\mu_1\\) satisfy \\(\\lim_{n \\to \\infty} P(\\mu_1 \\leq \\mu_1) \\geq 1 - \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 \\geq \\mu_1) \\geq 1 - \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 \\leq \\mu_1 \\leq \\mu_1) \\leq 1 - C\\beta\\) if\n\\begin{enumerate}\n\\item \\(K \\geq 1\\) and \\(C = 2\\) for Algorithm 5,\n\\item \\(K \\geq 2\\) and \\(C = 3/2\\) for Algorithm 6, and\n\\item \\(K \\geq 4\\) and \\(C = 5/4\\) for Algorithm 7.\n\\end{enumerate}", "md": "Algorithm 5 First-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n\\begin{enumerate}\n\\item Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\mu_1 + Z^2 \\mu_2}{\\beta}) x^2 - (2n\\hat{\\beta}) x + n\\hat{1} = 0 .\n\\]\n\\item return \\(\\mu_1, \\mu_1\\).\n\\end{enumerate}\n\nAlgorithm 6 Second-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n\\begin{enumerate}\n\\item For each \\(i \\in [n]\\), set \\(m(i)_1 = \\frac{1}{K} \\sum_{j=1}^{K} x(i)_j^2 \\).\n\\item Set \\(\\hat{\\mu}_\\ell = \\frac{1}{n} \\sum_{i=1}^{n} m(i)_\\ell\\) for \\(\\ell = 1, 2\\).\n\\item Let \\(\\mu_2\\) be the larger root of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\beta}{2}) x^2 - (2n\\hat{\\mu}_2 + Z^2 \\frac{\\beta}{2}) x + n\\hat{\\mu}_2^2 = 0 .\n\\]\n\\item Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\\[\n(n + Z^2 \\frac{\\beta}{2}) x^2 - 2n\\hat{\\mu}_1 + Z^2K\\frac{\\beta}{2} x + n\\hat{\\mu}_1^2 - K - K^2 1 Z^2 \\frac{\\beta}{2} \\mu_2 = 0 .\n\\]\n\\item return \\(\\mu_1, \\mu_1\\).\n\\end{enumerate}\n\nFor all \\(t \\in \\mathbb{R}\\), we have,\n\\[\n\\lim_{n \\to \\infty} P\\left(\\mu - \\hat{\\mu}_n > \\sigma Z_{\\beta}/\\sqrt{n}\\right) \\geq 1 - \\beta \\quad \\text{and} \\quad \\lim_{n \\to \\infty} P\\left(\\hat{\\mu}_n - \\mu > \\sigma Z_{\\beta}/\\sqrt{n}\\right) \\geq 1 - \\beta .\n\\]\n\nThe finite moment requirement above is satisfied in our case because all our random variables are bounded between 0 and 1.\n\nWe give the Wilson-variants of Algorithms 2 to 4 respectively in Algorithms 5 to 7. Apart from the fact that the Wilson intervals are tighter, we can also solve the equations associated with the Wilson intervals in closed form as they are simply quadratic equations (i.e., without the need for numerical root-finding). The following proposition shows their correctness.\n\n\\textbf{Proposition 11.} Consider \\(n\\) i.i.d. samples \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) as inputs to Algorithms 5 to 7. Then, their outputs \\(\\mu_1, \\mu_1\\) satisfy \\(\\lim_{n \\to \\infty} P(\\mu_1 \\leq \\mu_1) \\geq 1 - \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 \\geq \\mu_1) \\geq 1 - \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 \\leq \\mu_1 \\leq \\mu_1) \\leq 1 - C\\beta\\) if\n\\begin{enumerate}\n\\item \\(K \\geq 1\\) and \\(C = 2\\) for Algorithm 5,\n\\item \\(K \\geq 2\\) and \\(C = 3/2\\) for Algorithm 6, and\n\\item \\(K \\geq 4\\) and \\(C = 5/4\\) for Algorithm 7.\n\\end{enumerate}"}]}, {"page": 26, "text": "Algorithm 7 Fourth-Order Wilson Intervals\n Input: Random vectors x(1), . . . , x(n) \u223c                       XBernK(\u00b51, . . . , \u00b5K) with unknown parameters, failure probability\n       \u03b2 \u2208   (0, 1).\n Output: Asymptotic confidence intervals [\u00b5                              1, \u00b51] such that limn\u2192\u221e                P(\u00b51 < \u00b51) \u2264           \u03b2 and limn\u2192\u221e            P(\u00b51 >\n       \u00b5 1) \u2264    \u03b2.                                                                                                                  Km(i)1 \u2212\u2113\n   1: For each i \u2208         [n], set m(i)   1   = (1/K)  K        j=1 x(i)j    and for \u2113      = 1, 2, 3: m(i)    \u2113+1 = m(i)   \u2113          K\u2212\u2113          .\n   2: Set \u02c6  \u00b5\u2113   = (1/n)  n       i=1 m(i) \u2113    for \u2113   = 1, 2, 3, 4.\n   3: For \u2113     = 3, 4, let \u00b5      \u2113 be the larger root of the quadratic in x:\n                                                         (n + Z2   \u03b2/4) x2 \u2212      (2n\u02c6  \u00b5 \u2113 + Z2   \u03b2/4) x + n\u02c6    \u00b52 \u2113 = 0 .\n   4: Let \u00b5     2 be the larger root of the quadratic in x:\n                                     n +    2Z2 \u03b2/4(2K \u2212        3)     x2 \u2212       2n\u02c6 \u00b52 +         2Z2 \u03b2/4         x + n\u02c6   \u00b52 2 \u2212   cZ2 \u03b2/4 = 0 ,\n                                               K(K \u2212        1)                                 K(K \u2212        1)\n                                                 where        c = (K \u2212        2)(K \u2212      3)  (\u00b5  4 \u2212   \u00b523) + 4(K \u2212          2)\n   5: Set \u00b5     1 < \u00b51 as the roots of the quadratic in x:               K(K \u2212        1)                          K(K \u2212        1)\u00b53\n   6: return \u00b5        1, \u00b51.          (n + Z2    \u03b2/4) x2 \u2212        2n\u02c6 \u00b51 +     Z2K\u03b2/4      x + n\u02c6   \u00b52 1 \u2212    K \u2212  K   1     Z2\u03b2/4 \u00b52 = 0 .\n      We omit the proof as it is identical to those of Propositions 7 to 9 except that it uses the Wilson interval\n from Lemma 10 rather than the Bernstein interval.\n C.3         Scaling of Higher-Order Bernstein Bounds (Proposition 4)\nWe now re-state and prove Proposition 4.\n Proposition 4. For any positive integer \u2113                            that is a power of two and K = \u2308n(\u2113\u22121)/\u2113\u2309, suppose we have n\nsamples from a K-dimensional XBern distribution with parameters (\u00b51, . . . , \u00b5K). If all \u2113\u2032th-order correlations\nscale as 1/K, i.e., |\u00b52\u2113\u2032 \u2212              \u00b52\u2113\u2032| = O(1/K), for all \u2113\u2032 \u2264               \u2113  and \u2113\u2032 is a power of two, then the \u2113th-order Bernstein\nbound is |\u00b51 \u2212          \u02c6\n                        \u00b51| = O(1/n(2\u2113\u22121)/(2\u2113)).\n Proof. We are given n samples from an XBern distribution x \u2208                                       {0, 1}K with parameters (\u00b51, . . . , \u00b5K), where\n \u00b5\u2113  := E[m\u2113] with\n                                    m\u2113       :=                         1                                            xj  1 \u00b7 \u00b7 \u00b7 xj\u2113  .\n                                                     K(K \u2212       1) \u00b7 \u00b7 \u00b7 (K \u2212     \u2113 + 1)    j1<j2<...<j\u2113\u2208[K]\n By exchangeability, it also holds that \u00b5\u2113                            = E[x1 \u00b7 \u00b7 \u00b7 x\u2113].          Assuming a confidence level 1 \u2212                        \u03b2 < 1 and\n K = \u2308n(\u2113\u22121)/\u2113\u2309, the 1st-order Bernstein bound gives           |\u00b51 \u2212     \u02c6                        \u03c321\n                                                                        \u00b51|      =      O          n       ,                                                        (19)\n                                                                                    26", "md": "Algorithm 7 Fourth-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n1. For each \\(i \\in [n]\\), set \\(m(i)_1 = (1/K) \\sum_{j=1}^{K} x(i)_j\\) and for \\(\\ell = 1, 2, 3\\): \\(m(i)_{\\ell+1} = m(i)_{\\ell} \\cdot \\frac{K-\\ell}{K}\\).\n2. Set \\(\\hat{\\mu}_{\\ell} = (1/n) \\sum_{i=1}^{n} m(i)_{\\ell}\\) for \\(\\ell = 1, 2, 3, 4\\).\n3. For \\(\\ell = 3, 4\\), let \\(\\mu_{\\ell}\\) be the larger root of the quadratic in \\(x\\):\n\n\\[\n(n + Z^2 \\beta/4) x^2 - (2n\\hat{\\mu}_{\\ell} + Z^2 \\beta/4) x + n\\hat{\\mu}_{\\ell}^2 = 0\n\\]\n4. Let \\(\\mu_2\\) be the larger root of the quadratic in \\(x\\):\n\n\\[\nn + 2Z^2 \\beta/4(2K - 3) x^2 - 2n\\hat{\\mu}_2 + 2Z^2 \\beta/4 x + n\\hat{\\mu}_2^2 - cZ^2 \\beta/4 = 0\n\\]\n\nwhere \\(c = (K - 2)(K - 3)(\\mu_4 - \\mu_2^3) + 4(K - 2)\\)\n5. Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\n\\[\nK(K - 1) \\mu^3 - K(K - 1)\\mu_3\n\\]\n6. Return \\(\\mu_1, \\mu_1\\).\n\nWe omit the proof as it is identical to those of Propositions 7 to 9 except that it uses the Wilson interval from Lemma 10 rather than the Bernstein interval.\n\nC.3 Scaling of Higher-Order Bernstein Bounds (Proposition 4)\n\nWe now re-state and prove Proposition 4.\n\nProposition 4. For any positive integer \\(\\ell\\) that is a power of two and \\(K = \\lceil n(\\ell-1)/\\ell \\rceil\\), suppose we have \\(n\\) samples from a \\(K\\)-dimensional XBern distribution with parameters \\((\\mu_1, . . . , \\mu_K)\\). If all \\(\\ell'\\)th-order correlations scale as \\(1/K\\), i.e., \\(|\\mu_{2\\ell'} - \\mu_{2\\ell'}| = O(1/K)\\), for all \\(\\ell' \\leq \\ell\\) and \\(\\ell'\\) is a power of two, then the \\(\\ell\\)th-order Bernstein bound is \\(|\\mu_1 - \\hat{\\mu}_1| = O(1/n^{(2\\ell-1)/(2\\ell)})\\).\n\nProof. We are given \\(n\\) samples from an XBern distribution \\(x \\in \\{0, 1\\}^K\\) with parameters \\((\\mu_1, . . . , \\mu_K)\\), where \\(\\mu_{\\ell} := E[m_{\\ell}]\\) with\n\n\\(m_{\\ell} := \\frac{1}{K(K - 1) \\cdots (K - \\ell + 1)} \\prod_{j_1 < j_2 < \\ldots < j_{\\ell} \\in [K]} x_{j_1} x_{j_2} \\ldots x_{j_{\\ell}}\\).\n\nBy exchangeability, it also holds that \\(\\mu_{\\ell} = E[x_1 x_2 \\ldots x_{\\ell}]\\). Assuming a confidence level \\(1 - \\beta < 1\\) and \\(K = \\lceil n(\\ell-1)/\\ell \\rceil\\), the 1st-order Bernstein bound gives \\(|\\mu_1 - \\hat{\\mu}_1| = O(\\sqrt{n})\\).", "images": [], "items": [{"type": "text", "value": "Algorithm 7 Fourth-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n1. For each \\(i \\in [n]\\), set \\(m(i)_1 = (1/K) \\sum_{j=1}^{K} x(i)_j\\) and for \\(\\ell = 1, 2, 3\\): \\(m(i)_{\\ell+1} = m(i)_{\\ell} \\cdot \\frac{K-\\ell}{K}\\).\n2. Set \\(\\hat{\\mu}_{\\ell} = (1/n) \\sum_{i=1}^{n} m(i)_{\\ell}\\) for \\(\\ell = 1, 2, 3, 4\\).\n3. For \\(\\ell = 3, 4\\), let \\(\\mu_{\\ell}\\) be the larger root of the quadratic in \\(x\\):\n\n\\[\n(n + Z^2 \\beta/4) x^2 - (2n\\hat{\\mu}_{\\ell} + Z^2 \\beta/4) x + n\\hat{\\mu}_{\\ell}^2 = 0\n\\]\n4. Let \\(\\mu_2\\) be the larger root of the quadratic in \\(x\\):\n\n\\[\nn + 2Z^2 \\beta/4(2K - 3) x^2 - 2n\\hat{\\mu}_2 + 2Z^2 \\beta/4 x + n\\hat{\\mu}_2^2 - cZ^2 \\beta/4 = 0\n\\]\n\nwhere \\(c = (K - 2)(K - 3)(\\mu_4 - \\mu_2^3) + 4(K - 2)\\)\n5. Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\n\\[\nK(K - 1) \\mu^3 - K(K - 1)\\mu_3\n\\]\n6. Return \\(\\mu_1, \\mu_1\\).\n\nWe omit the proof as it is identical to those of Propositions 7 to 9 except that it uses the Wilson interval from Lemma 10 rather than the Bernstein interval.\n\nC.3 Scaling of Higher-Order Bernstein Bounds (Proposition 4)\n\nWe now re-state and prove Proposition 4.\n\nProposition 4. For any positive integer \\(\\ell\\) that is a power of two and \\(K = \\lceil n(\\ell-1)/\\ell \\rceil\\), suppose we have \\(n\\) samples from a \\(K\\)-dimensional XBern distribution with parameters \\((\\mu_1, . . . , \\mu_K)\\). If all \\(\\ell'\\)th-order correlations scale as \\(1/K\\), i.e., \\(|\\mu_{2\\ell'} - \\mu_{2\\ell'}| = O(1/K)\\), for all \\(\\ell' \\leq \\ell\\) and \\(\\ell'\\) is a power of two, then the \\(\\ell\\)th-order Bernstein bound is \\(|\\mu_1 - \\hat{\\mu}_1| = O(1/n^{(2\\ell-1)/(2\\ell)})\\).\n\nProof. We are given \\(n\\) samples from an XBern distribution \\(x \\in \\{0, 1\\}^K\\) with parameters \\((\\mu_1, . . . , \\mu_K)\\), where \\(\\mu_{\\ell} := E[m_{\\ell}]\\) with\n\n\\(m_{\\ell} := \\frac{1}{K(K - 1) \\cdots (K - \\ell + 1)} \\prod_{j_1 < j_2 < \\ldots < j_{\\ell} \\in [K]} x_{j_1} x_{j_2} \\ldots x_{j_{\\ell}}\\).\n\nBy exchangeability, it also holds that \\(\\mu_{\\ell} = E[x_1 x_2 \\ldots x_{\\ell}]\\). Assuming a confidence level \\(1 - \\beta < 1\\) and \\(K = \\lceil n(\\ell-1)/\\ell \\rceil\\), the 1st-order Bernstein bound gives \\(|\\mu_1 - \\hat{\\mu}_1| = O(\\sqrt{n})\\).", "md": "Algorithm 7 Fourth-Order Wilson Intervals\n\nInput: Random vectors \\(x(1), . . . , x(n) \\sim XBernK(\\mu_1, . . . , \\mu_K)\\) with unknown parameters, failure probability \\(\\beta \\in (0, 1)\\).\n\nOutput: Asymptotic confidence intervals \\([\\mu_1, \\mu_1]\\) such that \\(\\lim_{n \\to \\infty} P(\\mu_1 < \\mu_1) \\leq \\beta\\) and \\(\\lim_{n \\to \\infty} P(\\mu_1 > \\mu_1) \\leq \\beta\\).\n\n1. For each \\(i \\in [n]\\), set \\(m(i)_1 = (1/K) \\sum_{j=1}^{K} x(i)_j\\) and for \\(\\ell = 1, 2, 3\\): \\(m(i)_{\\ell+1} = m(i)_{\\ell} \\cdot \\frac{K-\\ell}{K}\\).\n2. Set \\(\\hat{\\mu}_{\\ell} = (1/n) \\sum_{i=1}^{n} m(i)_{\\ell}\\) for \\(\\ell = 1, 2, 3, 4\\).\n3. For \\(\\ell = 3, 4\\), let \\(\\mu_{\\ell}\\) be the larger root of the quadratic in \\(x\\):\n\n\\[\n(n + Z^2 \\beta/4) x^2 - (2n\\hat{\\mu}_{\\ell} + Z^2 \\beta/4) x + n\\hat{\\mu}_{\\ell}^2 = 0\n\\]\n4. Let \\(\\mu_2\\) be the larger root of the quadratic in \\(x\\):\n\n\\[\nn + 2Z^2 \\beta/4(2K - 3) x^2 - 2n\\hat{\\mu}_2 + 2Z^2 \\beta/4 x + n\\hat{\\mu}_2^2 - cZ^2 \\beta/4 = 0\n\\]\n\nwhere \\(c = (K - 2)(K - 3)(\\mu_4 - \\mu_2^3) + 4(K - 2)\\)\n5. Set \\(\\mu_1 < \\mu_1\\) as the roots of the quadratic in \\(x\\):\n\n\\[\nK(K - 1) \\mu^3 - K(K - 1)\\mu_3\n\\]\n6. Return \\(\\mu_1, \\mu_1\\).\n\nWe omit the proof as it is identical to those of Propositions 7 to 9 except that it uses the Wilson interval from Lemma 10 rather than the Bernstein interval.\n\nC.3 Scaling of Higher-Order Bernstein Bounds (Proposition 4)\n\nWe now re-state and prove Proposition 4.\n\nProposition 4. For any positive integer \\(\\ell\\) that is a power of two and \\(K = \\lceil n(\\ell-1)/\\ell \\rceil\\), suppose we have \\(n\\) samples from a \\(K\\)-dimensional XBern distribution with parameters \\((\\mu_1, . . . , \\mu_K)\\). If all \\(\\ell'\\)th-order correlations scale as \\(1/K\\), i.e., \\(|\\mu_{2\\ell'} - \\mu_{2\\ell'}| = O(1/K)\\), for all \\(\\ell' \\leq \\ell\\) and \\(\\ell'\\) is a power of two, then the \\(\\ell\\)th-order Bernstein bound is \\(|\\mu_1 - \\hat{\\mu}_1| = O(1/n^{(2\\ell-1)/(2\\ell)})\\).\n\nProof. We are given \\(n\\) samples from an XBern distribution \\(x \\in \\{0, 1\\}^K\\) with parameters \\((\\mu_1, . . . , \\mu_K)\\), where \\(\\mu_{\\ell} := E[m_{\\ell}]\\) with\n\n\\(m_{\\ell} := \\frac{1}{K(K - 1) \\cdots (K - \\ell + 1)} \\prod_{j_1 < j_2 < \\ldots < j_{\\ell} \\in [K]} x_{j_1} x_{j_2} \\ldots x_{j_{\\ell}}\\).\n\nBy exchangeability, it also holds that \\(\\mu_{\\ell} = E[x_1 x_2 \\ldots x_{\\ell}]\\). Assuming a confidence level \\(1 - \\beta < 1\\) and \\(K = \\lceil n(\\ell-1)/\\ell \\rceil\\), the 1st-order Bernstein bound gives \\(|\\mu_1 - \\hat{\\mu}_1| = O(\\sqrt{n})\\)."}]}, {"page": 27, "text": "where \u03c32     \u2113  := Var(m\u2113). Expanding \u03c32                    \u2113 , it is easy to show that it is dominated by the 2\u2113th-order correlation\n|\u00b52\u2113   \u2212   \u00b52\u2113|:                                        1                             =     O       1        \u00b52\u2113   \u2212    \u02c6             \u03c322\u2113\n                                  \u03c32\u2113     =     O      K + |\u00b52\u2113        \u2212   \u00b52\u2113|                    K + |     \u02c6         \u00b52 \u2113| +         n         .\nNote that our Bernstein confidence interval does not use the fact that the higher-order correlations are small.\nWe only use that assumption to bound the resulting size of the confidence interval in the analysis. Applying\nthe assumption that all the higher order correlations are bounded by 1/K, i.e., |\u00b52\u2113\u2032 \u2212                                                        \u00b52\u2113\u2032| = O(1/K), we get\nthat |    \u02c6\n         \u00b52\u2113\u2032 \u2212      \u02c6\n                     \u00b52\u2113\u2032| = O(1/K +                \u03c32 2\u2113\u2032/n). Applying this recursively into (19), we get that\n                                                                                            1              \u03c31/\u2113\n                                                     |\u00b51 \u2212      \u02c6                                            \u2113\n                                                               \u00b51|      =      O          nK +        n(2\u2113\u22121)/(2\u2113)           ,\nfor any \u2113       that is a power of two. For an \u2113th-order Bernstein bound, we only use moment estimates up to \u2113\nand bound \u03c32         \u2113  \u2264   1. The choice of K = n(\u2113\u22121)/\u2113                      gives the desired bound: |\u00b51 \u2212                      \u00b5\u02c6 1| = O(1/n(2\u2113\u22121)/(2\u2113)).\nD          Canary Design for Lifted DP: Details\nThe canary design employed in the auditing of the usual (\u03b5, \u03b4)-DP can be easily extended to create distributions\nover canaries to audit LiDP. We give some examples for common classes of canaries.\nSetup. We assume a supervised learning setting with a training dataset Dtrain = {(xi, yi)}N                                                           i=1 and a held-out\ndataset Dval = {(xi, yi)}N+N \u2032           i=N+1 of pairs of input xi \u2208                     X and output yi \u2208                Y. We then aim to minimize the\naverage loss\n                                                                                      N\n                                                                   F  (\u03b8) = 1   N    i=1   L((x   i, yi), \u03b8) ,                                                               (20)\nwhere L(z, \u03b8) is the loss incurred by model \u03b8 on input-output pair z = (x, y).\n      In the presence of canaries c1, . . . , ck, we instead aim to minimize the objective\n                                                                              \uf8eb   N                               k                         \uf8f6\n                                  Fcanary(\u03b8; c1, . . . , ck) = 1         N    \uf8ed  i=1   L((xi, yi), \u03b8) +         j=1   Lcanary(cj, \u03b8)        \uf8f8   ,                            (21)\nwhere Lcanary(c, \u03b8) is the loss function for a canary c \u2014 this may or may not coincide with the usual loss L.\nGoals of Auditing DP. The usual practice is to set D0 = Dtrain and D1 = D0 \u222a                                                                   {c} and R \u2261            Rc for a\ncanary c. Recall from the definition of (\u03b5, \u03b4)-DP in (1), we have\n                                                            \u03b5 \u2265    sup   log    P(A(D1) \u2208            Rc) \u2212      \u03b4     ,\n                                                                   c\u2208C               P(A(D0) \u2208           Rc)\nfor some class C of canaries. The goal then is to find canaries c that approximate the sup over C. Since this\ngoal is hard, one usually resorts to finding canaries whose effect can be \u201ceasy to detect\u201d in some sense.\nGoals of Auditing LiDP. Let Pcanary denote a probability distribution over a set C of allowed canaries.\n                                                         i.i.d.\nWe sample K canaries c1, . . . , cK                       \u223c     Pcanary and set\n                            D0 = Dtrain \u222a            {c1, . . . , cK\u22121},           D1 = Dtrain \u222a           {c1, . . . , cK},          R = RcK .\n                                                                                        27", "md": "where $$\\sigma^2_{\\ell} := \\text{Var}(m_{\\ell})$$. Expanding $$\\sigma^2_{\\ell}$$, it is easy to show that it is dominated by the 2\u2113th-order correlation\n$$|\\mu_{2\\ell} - \\mu_{2\\ell}|: \\frac{1}{\\sigma^2_{\\ell}} = O\\left(\\frac{1}{\\mu_{2\\ell} - \\hat{\\mu}_{2\\ell} \\sigma^2_{2\\ell}}\\right)$$\n$$\\sigma^2_{\\ell} = O\\left(K + |\\mu_{2\\ell} - \\mu_{2\\ell}| K + |\\hat{\\mu}_{2\\ell} - \\mu_{2\\ell}| + n\\right)$$.\nNote that our Bernstein confidence interval does not use the fact that the higher-order correlations are small.\nWe only use that assumption to bound the resulting size of the confidence interval in the analysis. Applying\nthe assumption that all the higher order correlations are bounded by $$\\frac{1}{K}$$, i.e., $$|\\mu_{2\\ell'} - \\mu_{2\\ell'}| = O\\left(\\frac{1}{K}\\right)$$, we get\nthat $$|\\hat{\\mu}_{2\\ell'} - \\hat{\\mu}_{2\\ell'}| = O\\left(\\frac{1}{K + \\sigma^2_{2\\ell'}/n}\\right)$$. Applying this recursively into (19), we get that\n$$|\\mu_1 - \\hat{\\mu}_1| = O\\left(nK + n(2\\ell-1)/(2\\ell)\\right)$$,\nfor any $$\\ell$$ that is a power of two. For an $$\\ell$$th-order Bernstein bound, we only use moment estimates up to $$\\ell$$\nand bound $$\\sigma^2_{\\ell} \\leq 1$$. The choice of $$K = n(\\ell-1)/\\ell$$ gives the desired bound: $$|\\mu_1 - \\hat{\\mu}_1| = O\\left(\\frac{1}{n(2\\ell-1)/(2\\ell)}\\right)$$.\n\nD Canary Design for Lifted DP: Details\n\nThe canary design employed in the auditing of the usual (\u03b5, \u03b4)-DP can be easily extended to create distributions\nover canaries to audit LiDP. We give some examples for common classes of canaries.\n\nSetup. We assume a supervised learning setting with a training dataset $$D_{\\text{train}} = \\{(x_i, y_i)\\}_{N i=1}$$ and a held-out\ndataset $$D_{\\text{val}} = \\{(x_i, y_i)\\}_{N+N' i=N+1}$$ of pairs of input $$x_i \\in X$$ and output $$y_i \\in Y$$. We then aim to minimize the\naverage loss\n$$F(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L((x_i, y_i), \\theta)$$ (20),\nwhere $$L(z, \\theta)$$ is the loss incurred by model $$\\theta$$ on input-output pair $$z = (x, y)$$.\nIn the presence of canaries $$c_1, ..., c_k$$, we instead aim to minimize the objective\n$$F_{\\text{canary}}(\\theta; c_1, ..., c_k) = \\frac{1}{N} \\left(\\sum_{i=1}^{N} L((x_i, y_i), \\theta) + \\sum_{j=1}^{k} L_{\\text{canary}}(c_j, \\theta)\\right)$$ (21),\nwhere $$L_{\\text{canary}}(c, \\theta)$$ is the loss function for a canary $$c$$ \u2014 this may or may not coincide with the usual loss $$L$$.\n\nGoals of Auditing DP. The usual practice is to set $$D_0 = D_{\\text{train}}$$ and $$D_1 = D_0 \\cup \\{c\\}$$ and $$R \\equiv R_c$$ for a\ncanary $$c$$. Recall from the definition of (\u03b5, \u03b4)-DP in (1), we have\n$$\\epsilon \\geq \\sup_{c \\in C} \\log P(A(D_1) \\in R_c) - \\delta P(A(D_0) \\in R_c)$$\nfor some class $$C$$ of canaries. The goal then is to find canaries $$c$$ that approximate the sup over $$C$$. Since this\ngoal is hard, one usually resorts to finding canaries whose effect can be \u201ceasy to detect\u201d in some sense.\n\nGoals of Auditing LiDP. Let $$P_{\\text{canary}}$$ denote a probability distribution over a set $$C$$ of allowed canaries.\nWe sample $$K$$ canaries $$c_1, ..., c_K \\sim P_{\\text{canary}}$$ and set\n$$D_0 = D_{\\text{train}} \\cup \\{c_1, ..., c_{K-1}\\}, D_1 = D_{\\text{train}} \\cup \\{c_1, ..., c_K\\}, R = R_{c_K}$$.", "images": [], "items": [{"type": "text", "value": "where $$\\sigma^2_{\\ell} := \\text{Var}(m_{\\ell})$$. Expanding $$\\sigma^2_{\\ell}$$, it is easy to show that it is dominated by the 2\u2113th-order correlation\n$$|\\mu_{2\\ell} - \\mu_{2\\ell}|: \\frac{1}{\\sigma^2_{\\ell}} = O\\left(\\frac{1}{\\mu_{2\\ell} - \\hat{\\mu}_{2\\ell} \\sigma^2_{2\\ell}}\\right)$$\n$$\\sigma^2_{\\ell} = O\\left(K + |\\mu_{2\\ell} - \\mu_{2\\ell}| K + |\\hat{\\mu}_{2\\ell} - \\mu_{2\\ell}| + n\\right)$$.\nNote that our Bernstein confidence interval does not use the fact that the higher-order correlations are small.\nWe only use that assumption to bound the resulting size of the confidence interval in the analysis. Applying\nthe assumption that all the higher order correlations are bounded by $$\\frac{1}{K}$$, i.e., $$|\\mu_{2\\ell'} - \\mu_{2\\ell'}| = O\\left(\\frac{1}{K}\\right)$$, we get\nthat $$|\\hat{\\mu}_{2\\ell'} - \\hat{\\mu}_{2\\ell'}| = O\\left(\\frac{1}{K + \\sigma^2_{2\\ell'}/n}\\right)$$. Applying this recursively into (19), we get that\n$$|\\mu_1 - \\hat{\\mu}_1| = O\\left(nK + n(2\\ell-1)/(2\\ell)\\right)$$,\nfor any $$\\ell$$ that is a power of two. For an $$\\ell$$th-order Bernstein bound, we only use moment estimates up to $$\\ell$$\nand bound $$\\sigma^2_{\\ell} \\leq 1$$. The choice of $$K = n(\\ell-1)/\\ell$$ gives the desired bound: $$|\\mu_1 - \\hat{\\mu}_1| = O\\left(\\frac{1}{n(2\\ell-1)/(2\\ell)}\\right)$$.\n\nD Canary Design for Lifted DP: Details\n\nThe canary design employed in the auditing of the usual (\u03b5, \u03b4)-DP can be easily extended to create distributions\nover canaries to audit LiDP. We give some examples for common classes of canaries.\n\nSetup. We assume a supervised learning setting with a training dataset $$D_{\\text{train}} = \\{(x_i, y_i)\\}_{N i=1}$$ and a held-out\ndataset $$D_{\\text{val}} = \\{(x_i, y_i)\\}_{N+N' i=N+1}$$ of pairs of input $$x_i \\in X$$ and output $$y_i \\in Y$$. We then aim to minimize the\naverage loss\n$$F(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L((x_i, y_i), \\theta)$$ (20),\nwhere $$L(z, \\theta)$$ is the loss incurred by model $$\\theta$$ on input-output pair $$z = (x, y)$$.\nIn the presence of canaries $$c_1, ..., c_k$$, we instead aim to minimize the objective\n$$F_{\\text{canary}}(\\theta; c_1, ..., c_k) = \\frac{1}{N} \\left(\\sum_{i=1}^{N} L((x_i, y_i), \\theta) + \\sum_{j=1}^{k} L_{\\text{canary}}(c_j, \\theta)\\right)$$ (21),\nwhere $$L_{\\text{canary}}(c, \\theta)$$ is the loss function for a canary $$c$$ \u2014 this may or may not coincide with the usual loss $$L$$.\n\nGoals of Auditing DP. The usual practice is to set $$D_0 = D_{\\text{train}}$$ and $$D_1 = D_0 \\cup \\{c\\}$$ and $$R \\equiv R_c$$ for a\ncanary $$c$$. Recall from the definition of (\u03b5, \u03b4)-DP in (1), we have\n$$\\epsilon \\geq \\sup_{c \\in C} \\log P(A(D_1) \\in R_c) - \\delta P(A(D_0) \\in R_c)$$\nfor some class $$C$$ of canaries. The goal then is to find canaries $$c$$ that approximate the sup over $$C$$. Since this\ngoal is hard, one usually resorts to finding canaries whose effect can be \u201ceasy to detect\u201d in some sense.\n\nGoals of Auditing LiDP. Let $$P_{\\text{canary}}$$ denote a probability distribution over a set $$C$$ of allowed canaries.\nWe sample $$K$$ canaries $$c_1, ..., c_K \\sim P_{\\text{canary}}$$ and set\n$$D_0 = D_{\\text{train}} \\cup \\{c_1, ..., c_{K-1}\\}, D_1 = D_{\\text{train}} \\cup \\{c_1, ..., c_K\\}, R = R_{c_K}$$.", "md": "where $$\\sigma^2_{\\ell} := \\text{Var}(m_{\\ell})$$. Expanding $$\\sigma^2_{\\ell}$$, it is easy to show that it is dominated by the 2\u2113th-order correlation\n$$|\\mu_{2\\ell} - \\mu_{2\\ell}|: \\frac{1}{\\sigma^2_{\\ell}} = O\\left(\\frac{1}{\\mu_{2\\ell} - \\hat{\\mu}_{2\\ell} \\sigma^2_{2\\ell}}\\right)$$\n$$\\sigma^2_{\\ell} = O\\left(K + |\\mu_{2\\ell} - \\mu_{2\\ell}| K + |\\hat{\\mu}_{2\\ell} - \\mu_{2\\ell}| + n\\right)$$.\nNote that our Bernstein confidence interval does not use the fact that the higher-order correlations are small.\nWe only use that assumption to bound the resulting size of the confidence interval in the analysis. Applying\nthe assumption that all the higher order correlations are bounded by $$\\frac{1}{K}$$, i.e., $$|\\mu_{2\\ell'} - \\mu_{2\\ell'}| = O\\left(\\frac{1}{K}\\right)$$, we get\nthat $$|\\hat{\\mu}_{2\\ell'} - \\hat{\\mu}_{2\\ell'}| = O\\left(\\frac{1}{K + \\sigma^2_{2\\ell'}/n}\\right)$$. Applying this recursively into (19), we get that\n$$|\\mu_1 - \\hat{\\mu}_1| = O\\left(nK + n(2\\ell-1)/(2\\ell)\\right)$$,\nfor any $$\\ell$$ that is a power of two. For an $$\\ell$$th-order Bernstein bound, we only use moment estimates up to $$\\ell$$\nand bound $$\\sigma^2_{\\ell} \\leq 1$$. The choice of $$K = n(\\ell-1)/\\ell$$ gives the desired bound: $$|\\mu_1 - \\hat{\\mu}_1| = O\\left(\\frac{1}{n(2\\ell-1)/(2\\ell)}\\right)$$.\n\nD Canary Design for Lifted DP: Details\n\nThe canary design employed in the auditing of the usual (\u03b5, \u03b4)-DP can be easily extended to create distributions\nover canaries to audit LiDP. We give some examples for common classes of canaries.\n\nSetup. We assume a supervised learning setting with a training dataset $$D_{\\text{train}} = \\{(x_i, y_i)\\}_{N i=1}$$ and a held-out\ndataset $$D_{\\text{val}} = \\{(x_i, y_i)\\}_{N+N' i=N+1}$$ of pairs of input $$x_i \\in X$$ and output $$y_i \\in Y$$. We then aim to minimize the\naverage loss\n$$F(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} L((x_i, y_i), \\theta)$$ (20),\nwhere $$L(z, \\theta)$$ is the loss incurred by model $$\\theta$$ on input-output pair $$z = (x, y)$$.\nIn the presence of canaries $$c_1, ..., c_k$$, we instead aim to minimize the objective\n$$F_{\\text{canary}}(\\theta; c_1, ..., c_k) = \\frac{1}{N} \\left(\\sum_{i=1}^{N} L((x_i, y_i), \\theta) + \\sum_{j=1}^{k} L_{\\text{canary}}(c_j, \\theta)\\right)$$ (21),\nwhere $$L_{\\text{canary}}(c, \\theta)$$ is the loss function for a canary $$c$$ \u2014 this may or may not coincide with the usual loss $$L$$.\n\nGoals of Auditing DP. The usual practice is to set $$D_0 = D_{\\text{train}}$$ and $$D_1 = D_0 \\cup \\{c\\}$$ and $$R \\equiv R_c$$ for a\ncanary $$c$$. Recall from the definition of (\u03b5, \u03b4)-DP in (1), we have\n$$\\epsilon \\geq \\sup_{c \\in C} \\log P(A(D_1) \\in R_c) - \\delta P(A(D_0) \\in R_c)$$\nfor some class $$C$$ of canaries. The goal then is to find canaries $$c$$ that approximate the sup over $$C$$. Since this\ngoal is hard, one usually resorts to finding canaries whose effect can be \u201ceasy to detect\u201d in some sense.\n\nGoals of Auditing LiDP. Let $$P_{\\text{canary}}$$ denote a probability distribution over a set $$C$$ of allowed canaries.\nWe sample $$K$$ canaries $$c_1, ..., c_K \\sim P_{\\text{canary}}$$ and set\n$$D_0 = D_{\\text{train}} \\cup \\{c_1, ..., c_{K-1}\\}, D_1 = D_{\\text{train}} \\cup \\{c_1, ..., c_K\\}, R = R_{c_K}$$."}]}, {"page": 28, "text": " From the definition of (\u03b5, \u03b4)-LiDP in (3), we have\n                                                        \u03b5 \u2265     sup     log   P(A(D1) \u2208            R) \u2212     \u03b4     ,\n                                                              Pcanary              P(A(D0) \u2208          R)\n for some class C of canaries. The goal then is to approximate the distribution Pcanary for each choice of the\n canary set C. Since this is hard, we will attempt to define a distribution over canaries that are easy to detect\n(similar to the case of auditing DP). Following the discussion in \u00a73.3, auditing LiDP benefits the most when\n the canaries are uncorrelated. To this end, we will also impose the restriction that a canary c \u223c                                                             Pcanary,\n if included in training of a model \u03b8, is unlikely to change the membership of \u03b8 \u2208                                                   Rc\u2032 for an i.i.d. canary\n c\u2032 \u223c   Pcanary that is independent of c.\n      We consider two choices of the canary set C (as well as the outcome set Rc and the loss Lcanary): data\n poisoning, and random gradients.\n D.1         Data Poisoning\nWe describe the data poisoning approach known as ClipBKD [31] that is based on using the tail singular\nvectors of the input data matrix and its extension to auditing LiDP.\n      Let X = (x\u22a4         1 ; \u00b7 \u00b7 \u00b7 ; x\u22a4\n                                       N) \u2208      RN\u00d7d denote the matrix with the datapoints xi \u2208                                      Rd as rows. Let X =\n  min{N,d}        \u03c3iuiv\u22a4  i   be the singular value decomposition of X with \u03c31 \u2264                                      \u03c32 \u2264      \u00b7 \u00b7 \u00b7 be the singular values\n    i=1\n arranged in ascending order. Let Y denote set of allowed labels.\n      For this section, we take the set of allowed canaries C = {\u03b1v1, \u03b1v2, . . . , \u03b1vmin{N,d}} \u00d7 Y as the set of right\n singular vector of X scaled by a given factor \u03b1 > 0 together with any possible target from Y. We take\n Lcanary(c, \u03b8) = L(c, \u03b8) to be the usual loss function, and the output set Rc to be the loss-thresholded set\n for some threshold \u03c4.                                         Rc := {\u03b8 \u2208        R : L(c, \u03b8) \u2264         \u03c4} ,                                                         (22)\n Auditing DP. The ClipBKD approach [31] uses a canary with input \u03b1v1, the singular vector corresponding\n to the smallest singular value, scaled by a parameter \u03b1 > 0. The label is taken as y\u22c6(\u03b1v1), where\n                                                               y\u22c6 (x) = arg max          L((x, y), \u03b8\u22c6    0)\n                                                                                y\u2208Y\n is the target that has the highest loss on input x under the empirical risk minimizer \u03b8\u22c6                                                0 = arg min        \u03b8\u2208R F    (\u03b8).\n Since a unique \u03b8\u22c6        0 is not guaranteed for deep nets nor can we find it exactly, we train 100 models with different\n random seeds and pick the class y that yields the highest average loss over these runs.\n Auditing LiDP. We extend ClipBKD to define a probability distribution over a given number p of canaries.\nWe take\n                                     Pcanary = Uniform             {c1, . . . , cp}        with       cj =     \u03b1vj, y\u22c6(\u03b1vj)          ,                              (23)\n i.e., Pcanary is the uniform distribution over the p singular vectors corresponding to the smallest singular\nvalues.\n D.2         Random Gradients\nThe update poisoning approach of [2] relies of supplying gradients c \u223c                                           Uniform(BR(0, r)) that are uniform\n on the Euclidean ball of a given radius r. This is achieved by setting the loss of the canary as\n                                            Lcanary(c, \u03b8) = \u27e8c, \u03b8\u27e9,              so that       \u2207\u03b8Lcanary(c, \u03b8) = c ,\n                                                                                    28", "md": "From the definition of ($\\epsilon, \\delta$)-LiDP in (3), we have\n\n$$\n\\epsilon \\geq \\sup \\log \\frac{P(A(D1) \\in R)}{P_{\\text{canary}}(A(D0) \\in R)} - \\delta,\n$$\nfor some class C of canaries. The goal then is to approximate the distribution $P_{\\text{canary}}$ for each choice of the canary set C. Since this is hard, we will attempt to define a distribution over canaries that are easy to detect (similar to the case of auditing DP). Following the discussion in \u00a73.3, auditing LiDP benefits the most when the canaries are uncorrelated. To this end, we will also impose the restriction that a canary $c \\sim P_{\\text{canary}}$, if included in training of a model $\\theta$, is unlikely to change the membership of $\\theta \\in R_{c'}$ for an i.i.d. canary $c' \\sim P_{\\text{canary}}$ that is independent of c.\n\nWe consider two choices of the canary set C (as well as the outcome set $R_c$ and the loss $L_{\\text{canary}}$): data poisoning, and random gradients.\n\n## D.1 Data Poisoning\n\nWe describe the data poisoning approach known as ClipBKD [31] that is based on using the tail singular vectors of the input data matrix and its extension to auditing LiDP.\n\nLet $X = (x_1^{\\top}, \\ldots, x_N^{\\top}) \\in \\mathbb{R}^{N \\times d}$ denote the matrix with the datapoints $x_i \\in \\mathbb{R}^d$ as rows. Let $X = \\sum_{i=1}^{\\min\\{N,d\\}} \\sigma_i u_i v_i^{\\top}$ be the singular value decomposition of X with $\\sigma_1 \\leq \\sigma_2 \\leq \\ldots$ be the singular values arranged in ascending order. Let Y denote set of allowed labels.\n\nFor this section, we take the set of allowed canaries $C = \\{\\alpha v_1, \\alpha v_2, \\ldots, \\alpha v_{\\min\\{N,d\\}}\\} \\times Y$ as the set of right singular vector of X scaled by a given factor $\\alpha > 0$ together with any possible target from Y. We take $L_{\\text{canary}}(c, \\theta) = L(c, \\theta)$ to be the usual loss function, and the output set $R_c$ to be the loss-thresholded set for some threshold $\\tau$.\n\n$$\nR_c := \\{\\theta \\in \\mathbb{R} : L(c, \\theta) \\leq \\tau\\}\n$$\nAuditing DP. The ClipBKD approach [31] uses a canary with input $\\alpha v_1$, the singular vector corresponding to the smallest singular value, scaled by a parameter $\\alpha > 0$. The label is taken as $y^*(\\alpha v_1)$, where\n\n$$\ny^*(x) = \\arg \\max_{y \\in Y} L((x, y), \\theta^*_0)\n$$\nis the target that has the highest loss on input x under the empirical risk minimizer $\\theta^*_0 = \\arg \\min_{\\theta \\in \\mathbb{R}} F(\\theta)$. Since a unique $\\theta^*_0$ is not guaranteed for deep nets nor can we find it exactly, we train 100 models with different random seeds and pick the class y that yields the highest average loss over these runs.\n\nAuditing LiDP. We extend ClipBKD to define a probability distribution over a given number p of canaries. We take\n\n$$\nP_{\\text{canary}} = \\text{Uniform} \\{c_1, \\ldots, c_p\\} \\text{ with } c_j = \\alpha v_j, y^*(\\alpha v_j),\n$$\ni.e., $P_{\\text{canary}}$ is the uniform distribution over the p singular vectors corresponding to the smallest singular values.\n\n## D.2 Random Gradients\n\nThe update poisoning approach of [2] relies of supplying gradients $c \\sim \\text{Uniform}(B_R(0, r))$ that are uniform on the Euclidean ball of a given radius r. This is achieved by setting the loss of the canary as\n\n$$\nL_{\\text{canary}}(c, \\theta) = \\langle c, \\theta \\rangle,\n$$\nso that $\\nabla_{\\theta} L_{\\text{canary}}(c, \\theta) = c$.", "images": [], "items": [{"type": "text", "value": "From the definition of ($\\epsilon, \\delta$)-LiDP in (3), we have\n\n$$\n\\epsilon \\geq \\sup \\log \\frac{P(A(D1) \\in R)}{P_{\\text{canary}}(A(D0) \\in R)} - \\delta,\n$$\nfor some class C of canaries. The goal then is to approximate the distribution $P_{\\text{canary}}$ for each choice of the canary set C. Since this is hard, we will attempt to define a distribution over canaries that are easy to detect (similar to the case of auditing DP). Following the discussion in \u00a73.3, auditing LiDP benefits the most when the canaries are uncorrelated. To this end, we will also impose the restriction that a canary $c \\sim P_{\\text{canary}}$, if included in training of a model $\\theta$, is unlikely to change the membership of $\\theta \\in R_{c'}$ for an i.i.d. canary $c' \\sim P_{\\text{canary}}$ that is independent of c.\n\nWe consider two choices of the canary set C (as well as the outcome set $R_c$ and the loss $L_{\\text{canary}}$): data poisoning, and random gradients.", "md": "From the definition of ($\\epsilon, \\delta$)-LiDP in (3), we have\n\n$$\n\\epsilon \\geq \\sup \\log \\frac{P(A(D1) \\in R)}{P_{\\text{canary}}(A(D0) \\in R)} - \\delta,\n$$\nfor some class C of canaries. The goal then is to approximate the distribution $P_{\\text{canary}}$ for each choice of the canary set C. Since this is hard, we will attempt to define a distribution over canaries that are easy to detect (similar to the case of auditing DP). Following the discussion in \u00a73.3, auditing LiDP benefits the most when the canaries are uncorrelated. To this end, we will also impose the restriction that a canary $c \\sim P_{\\text{canary}}$, if included in training of a model $\\theta$, is unlikely to change the membership of $\\theta \\in R_{c'}$ for an i.i.d. canary $c' \\sim P_{\\text{canary}}$ that is independent of c.\n\nWe consider two choices of the canary set C (as well as the outcome set $R_c$ and the loss $L_{\\text{canary}}$): data poisoning, and random gradients."}, {"type": "heading", "lvl": 2, "value": "D.1 Data Poisoning", "md": "## D.1 Data Poisoning"}, {"type": "text", "value": "We describe the data poisoning approach known as ClipBKD [31] that is based on using the tail singular vectors of the input data matrix and its extension to auditing LiDP.\n\nLet $X = (x_1^{\\top}, \\ldots, x_N^{\\top}) \\in \\mathbb{R}^{N \\times d}$ denote the matrix with the datapoints $x_i \\in \\mathbb{R}^d$ as rows. Let $X = \\sum_{i=1}^{\\min\\{N,d\\}} \\sigma_i u_i v_i^{\\top}$ be the singular value decomposition of X with $\\sigma_1 \\leq \\sigma_2 \\leq \\ldots$ be the singular values arranged in ascending order. Let Y denote set of allowed labels.\n\nFor this section, we take the set of allowed canaries $C = \\{\\alpha v_1, \\alpha v_2, \\ldots, \\alpha v_{\\min\\{N,d\\}}\\} \\times Y$ as the set of right singular vector of X scaled by a given factor $\\alpha > 0$ together with any possible target from Y. We take $L_{\\text{canary}}(c, \\theta) = L(c, \\theta)$ to be the usual loss function, and the output set $R_c$ to be the loss-thresholded set for some threshold $\\tau$.\n\n$$\nR_c := \\{\\theta \\in \\mathbb{R} : L(c, \\theta) \\leq \\tau\\}\n$$\nAuditing DP. The ClipBKD approach [31] uses a canary with input $\\alpha v_1$, the singular vector corresponding to the smallest singular value, scaled by a parameter $\\alpha > 0$. The label is taken as $y^*(\\alpha v_1)$, where\n\n$$\ny^*(x) = \\arg \\max_{y \\in Y} L((x, y), \\theta^*_0)\n$$\nis the target that has the highest loss on input x under the empirical risk minimizer $\\theta^*_0 = \\arg \\min_{\\theta \\in \\mathbb{R}} F(\\theta)$. Since a unique $\\theta^*_0$ is not guaranteed for deep nets nor can we find it exactly, we train 100 models with different random seeds and pick the class y that yields the highest average loss over these runs.\n\nAuditing LiDP. We extend ClipBKD to define a probability distribution over a given number p of canaries. We take\n\n$$\nP_{\\text{canary}} = \\text{Uniform} \\{c_1, \\ldots, c_p\\} \\text{ with } c_j = \\alpha v_j, y^*(\\alpha v_j),\n$$\ni.e., $P_{\\text{canary}}$ is the uniform distribution over the p singular vectors corresponding to the smallest singular values.", "md": "We describe the data poisoning approach known as ClipBKD [31] that is based on using the tail singular vectors of the input data matrix and its extension to auditing LiDP.\n\nLet $X = (x_1^{\\top}, \\ldots, x_N^{\\top}) \\in \\mathbb{R}^{N \\times d}$ denote the matrix with the datapoints $x_i \\in \\mathbb{R}^d$ as rows. Let $X = \\sum_{i=1}^{\\min\\{N,d\\}} \\sigma_i u_i v_i^{\\top}$ be the singular value decomposition of X with $\\sigma_1 \\leq \\sigma_2 \\leq \\ldots$ be the singular values arranged in ascending order. Let Y denote set of allowed labels.\n\nFor this section, we take the set of allowed canaries $C = \\{\\alpha v_1, \\alpha v_2, \\ldots, \\alpha v_{\\min\\{N,d\\}}\\} \\times Y$ as the set of right singular vector of X scaled by a given factor $\\alpha > 0$ together with any possible target from Y. We take $L_{\\text{canary}}(c, \\theta) = L(c, \\theta)$ to be the usual loss function, and the output set $R_c$ to be the loss-thresholded set for some threshold $\\tau$.\n\n$$\nR_c := \\{\\theta \\in \\mathbb{R} : L(c, \\theta) \\leq \\tau\\}\n$$\nAuditing DP. The ClipBKD approach [31] uses a canary with input $\\alpha v_1$, the singular vector corresponding to the smallest singular value, scaled by a parameter $\\alpha > 0$. The label is taken as $y^*(\\alpha v_1)$, where\n\n$$\ny^*(x) = \\arg \\max_{y \\in Y} L((x, y), \\theta^*_0)\n$$\nis the target that has the highest loss on input x under the empirical risk minimizer $\\theta^*_0 = \\arg \\min_{\\theta \\in \\mathbb{R}} F(\\theta)$. Since a unique $\\theta^*_0$ is not guaranteed for deep nets nor can we find it exactly, we train 100 models with different random seeds and pick the class y that yields the highest average loss over these runs.\n\nAuditing LiDP. We extend ClipBKD to define a probability distribution over a given number p of canaries. We take\n\n$$\nP_{\\text{canary}} = \\text{Uniform} \\{c_1, \\ldots, c_p\\} \\text{ with } c_j = \\alpha v_j, y^*(\\alpha v_j),\n$$\ni.e., $P_{\\text{canary}}$ is the uniform distribution over the p singular vectors corresponding to the smallest singular values."}, {"type": "heading", "lvl": 2, "value": "D.2 Random Gradients", "md": "## D.2 Random Gradients"}, {"type": "text", "value": "The update poisoning approach of [2] relies of supplying gradients $c \\sim \\text{Uniform}(B_R(0, r))$ that are uniform on the Euclidean ball of a given radius r. This is achieved by setting the loss of the canary as\n\n$$\nL_{\\text{canary}}(c, \\theta) = \\langle c, \\theta \\rangle,\n$$\nso that $\\nabla_{\\theta} L_{\\text{canary}}(c, \\theta) = c$.", "md": "The update poisoning approach of [2] relies of supplying gradients $c \\sim \\text{Uniform}(B_R(0, r))$ that are uniform on the Euclidean ball of a given radius r. This is achieved by setting the loss of the canary as\n\n$$\nL_{\\text{canary}}(c, \\theta) = \\langle c, \\theta \\rangle,\n$$\nso that $\\nabla_{\\theta} L_{\\text{canary}}(c, \\theta) = c$."}]}, {"page": 29, "text": "                             Lower Confi     dence Interval                                     Upper Confidence Interval\n            Width of Confi     dence Interval                                 Width of Confi      dence Interval\n                                                                                10\u22121\n             10\u22122                                                               10\u22122\n                               Clopper-Pearson\n             10\u22123              Jeffreys                                         10\u22123\n                               Wilson\n                  101      102      103       104      105      106                 101       102      103      104       105      106\n                                     Sample size n                                                      Sample size n\nFigure 6: Comparing the Binomial proportion confidence intervals. We sample m \u223c                              Binomial(n, p) for p = 0.1 and n\nvarying and find the 95% confidence interval [p              n, pn]. We plot the widths p \u2212          pn and pn \u2212       p versus n. We find that\nall confidence intervals are nearly equivalent once n is larger than \u2248                   1/ min{p, 1 \u2212     p}2.\nis the desired vector c.\n    The set Rc is a threshold of the dot product\n                                                         Rc = {\u03b8 \u2208      R : \u27e8c, \u03b8\u27e9    \u2264   \u03c4}                                                     (24)\nfor a given threshold \u03c4. This set is analogous to the loss-based thresholding of (22) in that both can be\nwritten as Lcanary(c, \u03b8) \u2264          \u03c4.\nAuditing DP and LiDP. The random gradient approach of [2] relies on defining a distribution Pcanary \u2261\nUniform(BR(0, r)) over canaries. It can be used directly to audit LiDP.\nE       Simulations with the Gaussian Mechanism: Details and More\n        Results\nHere, we give the full details and additional results of auditing the Gaussian mechanism with synthetic data\nin \u00a74.\nE.1       Experiment Setup\nFix a dimension d and a failure probability \u03b2 \u2208                       (0, 1). Suppose we have a randomized algorithm A that\nreturns a noisy sum of its inputs with a goal of simulating the Gaussian mechanism. Concretely, the input\nspace Z = {z \u2208          Rd : \u2225z\u22252 \u2264         1} is the unit ball in Rd. Given a finite set D \u2208                       Z\u2217, we sample a vector\n\u03be \u223c   N(0, \u03c32Id) of a given variance \u03c32 and return            A(D) = \u03be +       z\u2208D   z .\n    To isolate the effect of the canaries, we set our original dataset D = {0d} as a singleton with the vector of\nzeros in Rd. Since we are in the blackbox setting, we do not assume that this is known to the auditor.\n                                                                         29", "md": "# Document\n\nLower Confidence Interval Upper Confidence Interval\n\n|Width of Confidence Interval|Width of Confidence Interval|\n|---|---|\n|$10^{-2}$|$10^{-2}$|\n|Clopper-Pearson|Jeffreys|Wilson|\n|$10^{-3}$|$10^{-3}$|\n\nSample size n\n\n| |101|102|103|104|105|106|\n|---|---|---|---|---|---|---|\n|Figure 6: Comparing the Binomial proportion confidence intervals. We sample m ~ Binomial(n, p) for p = 0.1 and n varying and find the 95% confidence interval [p, pn]. We plot the widths p - pn and pn - p versus n. We find that all confidence intervals are nearly equivalent once n is larger than \u2248 1/min{p, 1 - p}^2.| | | | | | |\n\nThe desired vector c is the set Rc is a threshold of the dot product\n\n$$Rc = \\{ \\theta \\in R : \\langle c, \\theta \\rangle \\leq \\tau \\}$$ (24)\n\nfor a given threshold \u03c4. This set is analogous to the loss-based thresholding of (22) in that both can be written as Lcanary(c, \u03b8) \u2264 \u03c4.\n\nAuditing DP and LiDP. The random gradient approach of [2] relies on defining a distribution Pcanary \u2261 Uniform(BR(0, r)) over canaries. It can be used directly to audit LiDP.\n\nE Simulations with the Gaussian Mechanism: Details and More Results\n\nHere, we give the full details and additional results of auditing the Gaussian mechanism with synthetic data in \u00a74.\n\nE.1 Experiment Setup\n\nFix a dimension d and a failure probability \u03b2 \u2208 (0, 1). Suppose we have a randomized algorithm A that returns a noisy sum of its inputs with a goal of simulating the Gaussian mechanism. Concretely, the input space Z = {z \\in R^d : ||z||_2 \\leq 1} is the unit ball in R^d. Given a finite set D \\in Z^*, we sample a vector \u03be ~ N(0, \u03c3^2Id) of a given variance \u03c3^2 and return A(D) = \u03be + \\sum_{z \\in D} z.\n\nTo isolate the effect of the canaries, we set our original dataset D = {0^d} as a singleton with the vector of zeros in R^d. Since we are in the blackbox setting, we do not assume that this is known to the auditor.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "text", "value": "Lower Confidence Interval Upper Confidence Interval", "md": "Lower Confidence Interval Upper Confidence Interval"}, {"type": "table", "rows": [["Width of Confidence Interval", "Width of Confidence Interval"], ["$10^{-2}$", "$10^{-2}$"], ["Clopper-Pearson", "Jeffreys", "Wilson"], ["$10^{-3}$", "$10^{-3}$"]], "md": "|Width of Confidence Interval|Width of Confidence Interval|\n|---|---|\n|$10^{-2}$|$10^{-2}$|\n|Clopper-Pearson|Jeffreys|Wilson|\n|$10^{-3}$|$10^{-3}$|", "isPerfectTable": false, "csv": "\"Width of Confidence Interval\",\"Width of Confidence Interval\"\n\"$10^{-2}$\",\"$10^{-2}$\"\n\"Clopper-Pearson\",\"Jeffreys\",\"Wilson\"\n\"$10^{-3}$\",\"$10^{-3}$\""}, {"type": "text", "value": "Sample size n", "md": "Sample size n"}, {"type": "table", "rows": [["", "101", "102", "103", "104", "105", "106"], ["Figure 6: Comparing the Binomial proportion confidence intervals. We sample m ~ Binomial(n, p) for p = 0.1 and n varying and find the 95% confidence interval [p, pn]. We plot the widths p - pn and pn - p versus n. We find that all confidence intervals are nearly equivalent once n is larger than \u2248 1/min{p, 1 - p}^2.", "", "", "", "", "", ""]], "md": "| |101|102|103|104|105|106|\n|---|---|---|---|---|---|---|\n|Figure 6: Comparing the Binomial proportion confidence intervals. We sample m ~ Binomial(n, p) for p = 0.1 and n varying and find the 95% confidence interval [p, pn]. We plot the widths p - pn and pn - p versus n. We find that all confidence intervals are nearly equivalent once n is larger than \u2248 1/min{p, 1 - p}^2.| | | | | | |", "isPerfectTable": true, "csv": "\"\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\"\n\"Figure 6: Comparing the Binomial proportion confidence intervals. We sample m ~ Binomial(n, p) for p = 0.1 and n varying and find the 95% confidence interval [p, pn]. We plot the widths p - pn and pn - p versus n. We find that all confidence intervals are nearly equivalent once n is larger than \u2248 1/min{p, 1 - p}^2.\",\"\",\"\",\"\",\"\",\"\",\"\""}, {"type": "text", "value": "The desired vector c is the set Rc is a threshold of the dot product\n\n$$Rc = \\{ \\theta \\in R : \\langle c, \\theta \\rangle \\leq \\tau \\}$$ (24)\n\nfor a given threshold \u03c4. This set is analogous to the loss-based thresholding of (22) in that both can be written as Lcanary(c, \u03b8) \u2264 \u03c4.\n\nAuditing DP and LiDP. The random gradient approach of [2] relies on defining a distribution Pcanary \u2261 Uniform(BR(0, r)) over canaries. It can be used directly to audit LiDP.\n\nE Simulations with the Gaussian Mechanism: Details and More Results\n\nHere, we give the full details and additional results of auditing the Gaussian mechanism with synthetic data in \u00a74.\n\nE.1 Experiment Setup\n\nFix a dimension d and a failure probability \u03b2 \u2208 (0, 1). Suppose we have a randomized algorithm A that returns a noisy sum of its inputs with a goal of simulating the Gaussian mechanism. Concretely, the input space Z = {z \\in R^d : ||z||_2 \\leq 1} is the unit ball in R^d. Given a finite set D \\in Z^*, we sample a vector \u03be ~ N(0, \u03c3^2Id) of a given variance \u03c3^2 and return A(D) = \u03be + \\sum_{z \\in D} z.\n\nTo isolate the effect of the canaries, we set our original dataset D = {0^d} as a singleton with the vector of zeros in R^d. Since we are in the blackbox setting, we do not assume that this is known to the auditor.", "md": "The desired vector c is the set Rc is a threshold of the dot product\n\n$$Rc = \\{ \\theta \\in R : \\langle c, \\theta \\rangle \\leq \\tau \\}$$ (24)\n\nfor a given threshold \u03c4. This set is analogous to the loss-based thresholding of (22) in that both can be written as Lcanary(c, \u03b8) \u2264 \u03c4.\n\nAuditing DP and LiDP. The random gradient approach of [2] relies on defining a distribution Pcanary \u2261 Uniform(BR(0, r)) over canaries. It can be used directly to audit LiDP.\n\nE Simulations with the Gaussian Mechanism: Details and More Results\n\nHere, we give the full details and additional results of auditing the Gaussian mechanism with synthetic data in \u00a74.\n\nE.1 Experiment Setup\n\nFix a dimension d and a failure probability \u03b2 \u2208 (0, 1). Suppose we have a randomized algorithm A that returns a noisy sum of its inputs with a goal of simulating the Gaussian mechanism. Concretely, the input space Z = {z \\in R^d : ||z||_2 \\leq 1} is the unit ball in R^d. Given a finite set D \\in Z^*, we sample a vector \u03be ~ N(0, \u03c3^2Id) of a given variance \u03c3^2 and return A(D) = \u03be + \\sum_{z \\in D} z.\n\nTo isolate the effect of the canaries, we set our original dataset D = {0^d} as a singleton with the vector of zeros in R^d. Since we are in the blackbox setting, we do not assume that this is known to the auditor."}]}, {"page": 30, "text": " DP Upper Bound. The non-private version of our function computes the sum D  \u2192                                                             z\u2208D z. where each\n z \u2208   D is a canary. Hence, the \u21132 sensitivity of the operation is \u22062 = maxx\u2208D \u2225x\u22252 = 1, as stated in \u00a74.\n      Since we add \u03be \u223c              N  (0, \u03c32Id), it follows that the operation A(\u00b7) is                             \u03b1, \u03b1/(2\u03c32)        -RDP for every \u03b1 > 1.\nThus, A(\u00b7) is (\u03b5\u03b4, \u03b4)-DP where                 \u03b5\u03b4\u2264     inf       \u03b1            1                           1 \u2212    1        ,\n                                                      \u03b1>1      2\u03c32 +      \u03b1 \u2212    1 log 1  \u03b1\u03b4 + log               \u03b1\n based on [4, Thm. 21]. This can be shown to be bounded above by 1                                                      2 log 1          1\n                                                                                                                  \u03c3             \u03b4 +    2\u03c32 [43, Prop. 3]. By\nTheorem 3, it follows that the operation A(\u00b7) is also (\u03b5\u03b4, \u03b4)-LiDP.\n Auditing LiDP. We follow the recipe of Algorithm 1. We set the rejection region R = R\u03c4(cK) as a function\n of the canary cK that differs between D0 and D1, where\n and \u03c4 \u2208      R is a tuned threshold.                     R\u03c4(cj) :=          u \u2208   Rd : \u27e8u, cj\u27e9        \u2265  \u03c4     ,                                             (25)\n      We evaluate empirical privacy auditing methods by how large lower bound \u02c6                                                \u03b5 is \u2014 the higher the lower\n bound, the better is the confidence interval.\n Methods Compared. An empirical privacy auditing method is defined by the type of privacy auditing\n(DP or LiDP) and the type of confidence intervals. We compare the following auditing methods:\n      \u2022 DP + Wilson: We audit the usual (\u03b5, \u03b4)-DP with K = 1 canary. This corresponds exactly to auditing\n          LiDP with K = 1. We use the 1st-Order Wilson confidence intervals for a fair comparison with the\n          other LiDP auditing methods. This performs quite similarly to the other intervals used in the literature,\n          cf. Figure 6.\n      \u2022 LiDP + 1st-Order Wilson: We audit LiDP with K canaries with the 1st-Order Wilson confidence\n          interval. This method cannot leverage the shrinking of the confidence intervals from higher order\n          estimates.\n      \u2022 LiDP + 2nd/4th-Order Wilson: We audit LiDP with k > 1 canaries using the higher-order Wilson\n          confidence intervals.\n Parameters of the Experiment. We vary the following parameters in the experiment:\n      \u2022 Number of trials n \u2208                {28, 210, \u00b7 \u00b7 \u00b7 , 216}.\n      \u2022 Number of canaries k \u2208                  {1, 2, 22, . . . , 210}.\n      \u2022 Dimension d \u2208             {102, 103, . . . , 106}.\n      \u2022 DP upper bound \u03b5 \u2208                  {1, 2, 4, 8}.\nWe fix the DP parameter \u03b4 = 10\u22125 and the failure probability \u03b2 = 0.05.\n Tuning the threshold \u03c4. For each confidence interval scheme, we repeat the estimation of the lower bound\n \u02c6\n \u03b5(\u03c4) for a grid of thresholds \u03c4 \u2208                 \u0393 on a holdout set of n trials. We fix the best threshold \u03c4 \u2217                              = arg max\u03c4\u2208\u0393 \u02c6  \u03b5(\u03c4)\n that gives the largest lower bound \u02c6                   \u03b5(\u03c4) from the grid \u0393. We then fix the threshold \u03c4 \u2217                               and report numbers\n over a fresh set of n trials.\n Randomness and Repetitions. We repeat each experiment 25 times (after fixing the threshold) with\n different random seeds and report the mean and standard error.\n                                                                                    30", "md": "# DP Upper Bound and Auditing LiDP\n\n## DP Upper Bound\n\nThe non-private version of our function computes the sum $$\\sum_{z\\in D} z$$ where each $$z \\in D$$ is a canary. Hence, the \u21132 sensitivity of the operation is $$\\Delta_2 = \\max_{x\\in D} \\|x\\|_2 = 1$$, as stated in \u00a74. Since we add $$\\xi \\sim \\mathcal{N}(0, \\sigma^2 I_d)$$, it follows that the operation A(\u00b7) is $$\\alpha, \\frac{\\alpha}{2\\sigma^2}$$-RDP for every $$\\alpha > 1$$. Thus, A(\u00b7) is $$(\\epsilon\\delta, \\delta)$$-DP where $$\\epsilon\\delta \\leq \\inf_{\\alpha > 1} \\left(1 - \\frac{1}{2\\sigma^2 + \\alpha - 1}\\log\\frac{1}{\\alpha\\delta} + \\log\\alpha\\right)$$ based on [4, Thm. 21]. This can be shown to be bounded above by $$\\frac{1}{2}\\log\\frac{1}{\\sigma\\delta} + \\frac{2\\sigma^2}{\\delta}$$ [43, Prop. 3]. By Theorem 3, it follows that the operation A(\u00b7) is also $$(\\epsilon\\delta, \\delta)$$-LiDP.\n\n## Auditing LiDP\n\nWe follow the recipe of Algorithm 1. We set the rejection region $$R = R_\\tau(c_K)$$ as a function of the canary $$c_K$$ that differs between $$D_0$$ and $$D_1$$, where $$\\tau \\in R$$ is a tuned threshold. $$R_\\tau(c_j) := \\{u \\in \\mathbb{R}^d : \\langle u, c_j \\rangle \\geq \\tau\\}$$ (25). We evaluate empirical privacy auditing methods by how large lower bound $$\\hat{\\epsilon}$$ is \u2014 the higher the lower bound, the better is the confidence interval.\n\n## Methods Compared\n\nAn empirical privacy auditing method is defined by the type of privacy auditing (DP or LiDP) and the type of confidence intervals. We compare the following auditing methods:\n- DP + Wilson: We audit the usual $(\\epsilon, \\delta)$-DP with $K = 1$ canary. This corresponds exactly to auditing LiDP with $K = 1$. We use the 1st-Order Wilson confidence intervals for a fair comparison with the other LiDP auditing methods. This performs quite similarly to the other intervals used in the literature, cf. Figure 6.\n- LiDP + 1st-Order Wilson: We audit LiDP with $K$ canaries with the 1st-Order Wilson confidence interval. This method cannot leverage the shrinking of the confidence intervals from higher order estimates.\n- LiDP + 2nd/4th-Order Wilson: We audit LiDP with $k > 1$ canaries using the higher-order Wilson confidence intervals.\n\n## Parameters of the Experiment\n\nWe vary the following parameters in the experiment:\n- Number of trials $n \\in \\{28, 210, \\ldots, 2^{16}\\}$.\n- Number of canaries $k \\in \\{1, 2, 22, \\ldots, 210\\}$.\n- Dimension $d \\in \\{102, 103, \\ldots, 10^6\\}$.\n- DP upper bound $\\epsilon \\in \\{1, 2, 4, 8\\}$.\n\nWe fix the DP parameter $$\\delta = 10^{-5}$$ and the failure probability $$\\beta = 0.05$$.\n\n## Tuning the Threshold $$\\tau$$\n\nFor each confidence interval scheme, we repeat the estimation of the lower bound $$\\hat{\\epsilon}(\\tau)$$ for a grid of thresholds $$\\tau \\in \\Gamma$$ on a holdout set of $$n$$ trials. We fix the best threshold $$\\tau^* = \\arg\\max_{\\tau\\in\\Gamma} \\hat{\\epsilon}(\\tau)$$ that gives the largest lower bound $$\\hat{\\epsilon}(\\tau)$$ from the grid $$\\Gamma$$. We then fix the threshold $$\\tau^*$$ and report numbers over a fresh set of $$n$$ trials.\n\n## Randomness and Repetitions\n\nWe repeat each experiment 25 times (after fixing the threshold) with different random seeds and report the mean and standard error.\n\n30", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "DP Upper Bound and Auditing LiDP", "md": "# DP Upper Bound and Auditing LiDP"}, {"type": "heading", "lvl": 2, "value": "DP Upper Bound", "md": "## DP Upper Bound"}, {"type": "text", "value": "The non-private version of our function computes the sum $$\\sum_{z\\in D} z$$ where each $$z \\in D$$ is a canary. Hence, the \u21132 sensitivity of the operation is $$\\Delta_2 = \\max_{x\\in D} \\|x\\|_2 = 1$$, as stated in \u00a74. Since we add $$\\xi \\sim \\mathcal{N}(0, \\sigma^2 I_d)$$, it follows that the operation A(\u00b7) is $$\\alpha, \\frac{\\alpha}{2\\sigma^2}$$-RDP for every $$\\alpha > 1$$. Thus, A(\u00b7) is $$(\\epsilon\\delta, \\delta)$$-DP where $$\\epsilon\\delta \\leq \\inf_{\\alpha > 1} \\left(1 - \\frac{1}{2\\sigma^2 + \\alpha - 1}\\log\\frac{1}{\\alpha\\delta} + \\log\\alpha\\right)$$ based on [4, Thm. 21]. This can be shown to be bounded above by $$\\frac{1}{2}\\log\\frac{1}{\\sigma\\delta} + \\frac{2\\sigma^2}{\\delta}$$ [43, Prop. 3]. By Theorem 3, it follows that the operation A(\u00b7) is also $$(\\epsilon\\delta, \\delta)$$-LiDP.", "md": "The non-private version of our function computes the sum $$\\sum_{z\\in D} z$$ where each $$z \\in D$$ is a canary. Hence, the \u21132 sensitivity of the operation is $$\\Delta_2 = \\max_{x\\in D} \\|x\\|_2 = 1$$, as stated in \u00a74. Since we add $$\\xi \\sim \\mathcal{N}(0, \\sigma^2 I_d)$$, it follows that the operation A(\u00b7) is $$\\alpha, \\frac{\\alpha}{2\\sigma^2}$$-RDP for every $$\\alpha > 1$$. Thus, A(\u00b7) is $$(\\epsilon\\delta, \\delta)$$-DP where $$\\epsilon\\delta \\leq \\inf_{\\alpha > 1} \\left(1 - \\frac{1}{2\\sigma^2 + \\alpha - 1}\\log\\frac{1}{\\alpha\\delta} + \\log\\alpha\\right)$$ based on [4, Thm. 21]. This can be shown to be bounded above by $$\\frac{1}{2}\\log\\frac{1}{\\sigma\\delta} + \\frac{2\\sigma^2}{\\delta}$$ [43, Prop. 3]. By Theorem 3, it follows that the operation A(\u00b7) is also $$(\\epsilon\\delta, \\delta)$$-LiDP."}, {"type": "heading", "lvl": 2, "value": "Auditing LiDP", "md": "## Auditing LiDP"}, {"type": "text", "value": "We follow the recipe of Algorithm 1. We set the rejection region $$R = R_\\tau(c_K)$$ as a function of the canary $$c_K$$ that differs between $$D_0$$ and $$D_1$$, where $$\\tau \\in R$$ is a tuned threshold. $$R_\\tau(c_j) := \\{u \\in \\mathbb{R}^d : \\langle u, c_j \\rangle \\geq \\tau\\}$$ (25). We evaluate empirical privacy auditing methods by how large lower bound $$\\hat{\\epsilon}$$ is \u2014 the higher the lower bound, the better is the confidence interval.", "md": "We follow the recipe of Algorithm 1. We set the rejection region $$R = R_\\tau(c_K)$$ as a function of the canary $$c_K$$ that differs between $$D_0$$ and $$D_1$$, where $$\\tau \\in R$$ is a tuned threshold. $$R_\\tau(c_j) := \\{u \\in \\mathbb{R}^d : \\langle u, c_j \\rangle \\geq \\tau\\}$$ (25). We evaluate empirical privacy auditing methods by how large lower bound $$\\hat{\\epsilon}$$ is \u2014 the higher the lower bound, the better is the confidence interval."}, {"type": "heading", "lvl": 2, "value": "Methods Compared", "md": "## Methods Compared"}, {"type": "text", "value": "An empirical privacy auditing method is defined by the type of privacy auditing (DP or LiDP) and the type of confidence intervals. We compare the following auditing methods:\n- DP + Wilson: We audit the usual $(\\epsilon, \\delta)$-DP with $K = 1$ canary. This corresponds exactly to auditing LiDP with $K = 1$. We use the 1st-Order Wilson confidence intervals for a fair comparison with the other LiDP auditing methods. This performs quite similarly to the other intervals used in the literature, cf. Figure 6.\n- LiDP + 1st-Order Wilson: We audit LiDP with $K$ canaries with the 1st-Order Wilson confidence interval. This method cannot leverage the shrinking of the confidence intervals from higher order estimates.\n- LiDP + 2nd/4th-Order Wilson: We audit LiDP with $k > 1$ canaries using the higher-order Wilson confidence intervals.", "md": "An empirical privacy auditing method is defined by the type of privacy auditing (DP or LiDP) and the type of confidence intervals. We compare the following auditing methods:\n- DP + Wilson: We audit the usual $(\\epsilon, \\delta)$-DP with $K = 1$ canary. This corresponds exactly to auditing LiDP with $K = 1$. We use the 1st-Order Wilson confidence intervals for a fair comparison with the other LiDP auditing methods. This performs quite similarly to the other intervals used in the literature, cf. Figure 6.\n- LiDP + 1st-Order Wilson: We audit LiDP with $K$ canaries with the 1st-Order Wilson confidence interval. This method cannot leverage the shrinking of the confidence intervals from higher order estimates.\n- LiDP + 2nd/4th-Order Wilson: We audit LiDP with $k > 1$ canaries using the higher-order Wilson confidence intervals."}, {"type": "heading", "lvl": 2, "value": "Parameters of the Experiment", "md": "## Parameters of the Experiment"}, {"type": "text", "value": "We vary the following parameters in the experiment:\n- Number of trials $n \\in \\{28, 210, \\ldots, 2^{16}\\}$.\n- Number of canaries $k \\in \\{1, 2, 22, \\ldots, 210\\}$.\n- Dimension $d \\in \\{102, 103, \\ldots, 10^6\\}$.\n- DP upper bound $\\epsilon \\in \\{1, 2, 4, 8\\}$.\n\nWe fix the DP parameter $$\\delta = 10^{-5}$$ and the failure probability $$\\beta = 0.05$$.", "md": "We vary the following parameters in the experiment:\n- Number of trials $n \\in \\{28, 210, \\ldots, 2^{16}\\}$.\n- Number of canaries $k \\in \\{1, 2, 22, \\ldots, 210\\}$.\n- Dimension $d \\in \\{102, 103, \\ldots, 10^6\\}$.\n- DP upper bound $\\epsilon \\in \\{1, 2, 4, 8\\}$.\n\nWe fix the DP parameter $$\\delta = 10^{-5}$$ and the failure probability $$\\beta = 0.05$$."}, {"type": "heading", "lvl": 2, "value": "Tuning the Threshold $$\\tau$$", "md": "## Tuning the Threshold $$\\tau$$"}, {"type": "text", "value": "For each confidence interval scheme, we repeat the estimation of the lower bound $$\\hat{\\epsilon}(\\tau)$$ for a grid of thresholds $$\\tau \\in \\Gamma$$ on a holdout set of $$n$$ trials. We fix the best threshold $$\\tau^* = \\arg\\max_{\\tau\\in\\Gamma} \\hat{\\epsilon}(\\tau)$$ that gives the largest lower bound $$\\hat{\\epsilon}(\\tau)$$ from the grid $$\\Gamma$$. We then fix the threshold $$\\tau^*$$ and report numbers over a fresh set of $$n$$ trials.", "md": "For each confidence interval scheme, we repeat the estimation of the lower bound $$\\hat{\\epsilon}(\\tau)$$ for a grid of thresholds $$\\tau \\in \\Gamma$$ on a holdout set of $$n$$ trials. We fix the best threshold $$\\tau^* = \\arg\\max_{\\tau\\in\\Gamma} \\hat{\\epsilon}(\\tau)$$ that gives the largest lower bound $$\\hat{\\epsilon}(\\tau)$$ from the grid $$\\Gamma$$. We then fix the threshold $$\\tau^*$$ and report numbers over a fresh set of $$n$$ trials."}, {"type": "heading", "lvl": 2, "value": "Randomness and Repetitions", "md": "## Randomness and Repetitions"}, {"type": "text", "value": "We repeat each experiment 25 times (after fixing the threshold) with different random seeds and report the mean and standard error.\n\n30", "md": "We repeat each experiment 25 times (after fixing the threshold) with different random seeds and report the mean and standard error.\n\n30"}]}, {"page": 31, "text": "E.2     Additional Experimental Results\nWe give additional experimental results, expanding on the plots shown in Figures 3 and 4:\n    \u2022 Figure 7 shows the effect of varying the number of trials n, similar to Figure 3 (left).\n    \u2022 Figure 8 shows the effect of varying the number of canaries k, similar to Figure 3 (middle).\n    \u2022 Figure 9 shows the effect of varying the data dimension d, similar to Figure 3 (right).\n    \u2022 Figure 10 shows the effect of varying the number of canaries k on the moment estimates, similar to\n      Figure 4 (right).\n    \u2022 Figure 11 shows the effect of varying the data dimension d on the moment estimates, similar to Figure 4\n      (right).\n    We observe that the insights discussed in \u00a74 hold across a wide range of the parameter values. In addition\nwe make the following observations.\nThe benefit of higher-order confidence estimators. We see from Figures 7 to 9 that the higher-order\nWilson estimators lead to larger relative improvements at smaller \u03b5. On the other hand, they perform similarly\nat large \u03b5 (e.g., \u03b5 = 8) to the lower-order estimators.\n4th-Order Wilson vs. 2nd-Order Wilson. We note that the 4th-order Wilson intervals outperforms the\n2nd-order Wilson interval at \u03b5 = 1, while the opposite is true at large \u03b5 = 8. At intermediate values of \u03b5,\nboth behave very similarly. We suggest the 2nd-order Wilson interval as a default because it is nearly as\ngood as or better than the 4th-order variant across the board, but is easier to implement.\nF      Experiments: Details and More Results\nWe describe the detailed experimental setup here.\nF.1     Training Details: Datasets, Models\nWe consider two datasets, FMNIST and Purchase-100. Both are multiclass classification datasets trained\nwith the cross entropy loss using stochastic gradient descent (without momentum) for fixed epoch budget.\n    \u2022 FMNIST: FMNIST or FashionMNIST [64] is a classifi              cation of 28 \u00d7 28 grayscale images of various\n      articles of clothing into 10 classes. It contains 60K train images and 10K test images. The dataset is\n      available under the MIT license. We experiment with two models: a linear model and a multi-layer\n      perceptron (MLP) with 2 hidden layers of dimension 256 each. We train each model for 30 epochs with\n      a batch size of 100 and a fixed learning rate of 0.02 for the linear model and 0.01 for the MLP.\n    \u2022 Purchase-100: The Purchase dataset is based on Kaggle\u2019s \u201cacquire valued shoppers\u201d challenge [19]\n      that records the shopping history of 200K customers. The dataset is available publicly on Kaggle but\n      the owners have not created a license as far as we could tell. We use the preprocessed version of [52]3\n      where the input is a 600 dimensional binary vector encoding the shopping history. The classes are\n      obtained by grouping the records into 100 clusters using k-means. We use a fixed subsample of 20K\n      training points and 5K test points. The model is a MLP with 2 hidden layers of 256 units each. It is\n      trained for 100 epochs with a batch size of 100 and a fixed learning rate of 0.05.\n   3https://github.com/privacytrustlab/datasets\n                                                          31", "md": "## Additional Experimental Results\n\nWe give additional experimental results, expanding on the plots shown in Figures 3 and 4:\n\n- Figure 7 shows the effect of varying the number of trials n, similar to Figure 3 (left).\n- Figure 8 shows the effect of varying the number of canaries k, similar to Figure 3 (middle).\n- Figure 9 shows the effect of varying the data dimension d, similar to Figure 3 (right).\n- Figure 10 shows the effect of varying the number of canaries k on the moment estimates, similar to Figure 4 (right).\n- Figure 11 shows the effect of varying the data dimension d on the moment estimates, similar to Figure 4 (right).\n\nWe observe that the insights discussed in \u00a74 hold across a wide range of the parameter values. In addition, we make the following observations:\n\n- The benefit of higher-order confidence estimators: We see from Figures 7 to 9 that the higher-order Wilson estimators lead to larger relative improvements at smaller \u03b5. On the other hand, they perform similarly at large \u03b5 (e.g., \u03b5 = 8) to the lower-order estimators.\n- 4th-Order Wilson vs. 2nd-Order Wilson: We note that the 4th-order Wilson intervals outperform the 2nd-order Wilson interval at \u03b5 = 1, while the opposite is true at large \u03b5 = 8. At intermediate values of \u03b5, both behave very similarly. We suggest the 2nd-order Wilson interval as a default because it is nearly as good as or better than the 4th-order variant across the board, but is easier to implement.\n\n## Experiments: Details and More Results\n\n### Training Details: Datasets, Models\n\nWe consider two datasets, FMNIST and Purchase-100. Both are multiclass classification datasets trained with the cross entropy loss using stochastic gradient descent (without momentum) for a fixed epoch budget.\n\n- FMNIST: FMNIST or FashionMNIST [64] is a classification of 28 \u00d7 28 grayscale images of various articles of clothing into 10 classes. It contains 60K train images and 10K test images. The dataset is available under the MIT license. We experiment with two models: a linear model and a multi-layer perceptron (MLP) with 2 hidden layers of dimension 256 each. We train each model for 30 epochs with a batch size of 100 and a fixed learning rate of 0.02 for the linear model and 0.01 for the MLP.\n- Purchase-100: The Purchase dataset is based on Kaggle\u2019s \u201cacquire valued shoppers\u201d challenge [19] that records the shopping history of 200K customers. The dataset is available publicly on Kaggle but the owners have not created a license as far as we could tell. We use the preprocessed version of [52] where the input is a 600-dimensional binary vector encoding the shopping history. The classes are obtained by grouping the records into 100 clusters using k-means. We use a fixed subsample of 20K training points and 5K test points. The model is an MLP with 2 hidden layers of 256 units each. It is trained for 100 epochs with a batch size of 100 and a fixed learning rate of 0.05.\n\nSource: https://github.com/privacytrustlab/datasets", "images": [], "items": [{"type": "heading", "lvl": 2, "value": "Additional Experimental Results", "md": "## Additional Experimental Results"}, {"type": "text", "value": "We give additional experimental results, expanding on the plots shown in Figures 3 and 4:\n\n- Figure 7 shows the effect of varying the number of trials n, similar to Figure 3 (left).\n- Figure 8 shows the effect of varying the number of canaries k, similar to Figure 3 (middle).\n- Figure 9 shows the effect of varying the data dimension d, similar to Figure 3 (right).\n- Figure 10 shows the effect of varying the number of canaries k on the moment estimates, similar to Figure 4 (right).\n- Figure 11 shows the effect of varying the data dimension d on the moment estimates, similar to Figure 4 (right).\n\nWe observe that the insights discussed in \u00a74 hold across a wide range of the parameter values. In addition, we make the following observations:\n\n- The benefit of higher-order confidence estimators: We see from Figures 7 to 9 that the higher-order Wilson estimators lead to larger relative improvements at smaller \u03b5. On the other hand, they perform similarly at large \u03b5 (e.g., \u03b5 = 8) to the lower-order estimators.\n- 4th-Order Wilson vs. 2nd-Order Wilson: We note that the 4th-order Wilson intervals outperform the 2nd-order Wilson interval at \u03b5 = 1, while the opposite is true at large \u03b5 = 8. At intermediate values of \u03b5, both behave very similarly. We suggest the 2nd-order Wilson interval as a default because it is nearly as good as or better than the 4th-order variant across the board, but is easier to implement.", "md": "We give additional experimental results, expanding on the plots shown in Figures 3 and 4:\n\n- Figure 7 shows the effect of varying the number of trials n, similar to Figure 3 (left).\n- Figure 8 shows the effect of varying the number of canaries k, similar to Figure 3 (middle).\n- Figure 9 shows the effect of varying the data dimension d, similar to Figure 3 (right).\n- Figure 10 shows the effect of varying the number of canaries k on the moment estimates, similar to Figure 4 (right).\n- Figure 11 shows the effect of varying the data dimension d on the moment estimates, similar to Figure 4 (right).\n\nWe observe that the insights discussed in \u00a74 hold across a wide range of the parameter values. In addition, we make the following observations:\n\n- The benefit of higher-order confidence estimators: We see from Figures 7 to 9 that the higher-order Wilson estimators lead to larger relative improvements at smaller \u03b5. On the other hand, they perform similarly at large \u03b5 (e.g., \u03b5 = 8) to the lower-order estimators.\n- 4th-Order Wilson vs. 2nd-Order Wilson: We note that the 4th-order Wilson intervals outperform the 2nd-order Wilson interval at \u03b5 = 1, while the opposite is true at large \u03b5 = 8. At intermediate values of \u03b5, both behave very similarly. We suggest the 2nd-order Wilson interval as a default because it is nearly as good as or better than the 4th-order variant across the board, but is easier to implement."}, {"type": "heading", "lvl": 2, "value": "Experiments: Details and More Results", "md": "## Experiments: Details and More Results"}, {"type": "heading", "lvl": 3, "value": "Training Details: Datasets, Models", "md": "### Training Details: Datasets, Models"}, {"type": "text", "value": "We consider two datasets, FMNIST and Purchase-100. Both are multiclass classification datasets trained with the cross entropy loss using stochastic gradient descent (without momentum) for a fixed epoch budget.\n\n- FMNIST: FMNIST or FashionMNIST [64] is a classification of 28 \u00d7 28 grayscale images of various articles of clothing into 10 classes. It contains 60K train images and 10K test images. The dataset is available under the MIT license. We experiment with two models: a linear model and a multi-layer perceptron (MLP) with 2 hidden layers of dimension 256 each. We train each model for 30 epochs with a batch size of 100 and a fixed learning rate of 0.02 for the linear model and 0.01 for the MLP.\n- Purchase-100: The Purchase dataset is based on Kaggle\u2019s \u201cacquire valued shoppers\u201d challenge [19] that records the shopping history of 200K customers. The dataset is available publicly on Kaggle but the owners have not created a license as far as we could tell. We use the preprocessed version of [52] where the input is a 600-dimensional binary vector encoding the shopping history. The classes are obtained by grouping the records into 100 clusters using k-means. We use a fixed subsample of 20K training points and 5K test points. The model is an MLP with 2 hidden layers of 256 units each. It is trained for 100 epochs with a batch size of 100 and a fixed learning rate of 0.05.\n\nSource: https://github.com/privacytrustlab/datasets", "md": "We consider two datasets, FMNIST and Purchase-100. Both are multiclass classification datasets trained with the cross entropy loss using stochastic gradient descent (without momentum) for a fixed epoch budget.\n\n- FMNIST: FMNIST or FashionMNIST [64] is a classification of 28 \u00d7 28 grayscale images of various articles of clothing into 10 classes. It contains 60K train images and 10K test images. The dataset is available under the MIT license. We experiment with two models: a linear model and a multi-layer perceptron (MLP) with 2 hidden layers of dimension 256 each. We train each model for 30 epochs with a batch size of 100 and a fixed learning rate of 0.02 for the linear model and 0.01 for the MLP.\n- Purchase-100: The Purchase dataset is based on Kaggle\u2019s \u201cacquire valued shoppers\u201d challenge [19] that records the shopping history of 200K customers. The dataset is available publicly on Kaggle but the owners have not created a license as far as we could tell. We use the preprocessed version of [52] where the input is a 600-dimensional binary vector encoding the shopping history. The classes are obtained by grouping the records into 100 clusters using k-means. We use a fixed subsample of 20K training points and 5K test points. The model is an MLP with 2 hidden layers of 256 units each. It is trained for 100 epochs with a batch size of 100 and a fixed learning rate of 0.05.\n\nSource: https://github.com/privacytrustlab/datasets"}]}, {"page": 32, "text": "F.2     DP and Auditing Setup\nWe train each dataset-model pair with DP-SGD [1]. The noise level is calibrated so that the entire training\nalgorithm satisfies (\u03b5, \u03b4)-differential privacy with \u03b5 varying and \u03b4 = 10\u22125 fixed across all experiments. We\ntune the per-example gradient clip norm for each dataset, model, and DP parameter \u03b5 so as to maximize the\nvalidation accuracy.\nAuditing Setup. We follow the LiDP auditing setup described in Appendix B.2. Recall that auditing LiDP\nwith K = 1 canaries and corresponds exactly with auditing DP. We train n \u2208        {125, 250, 500, 1000} trials,\nwhere each trial corresponds to a model trained with K canaries in each run. We try two methods for canary\ndesign (as well as their corresponding rejection regions), as discussed in Appendix D: data poisoning and\nrandom gradients.\n    With data poisoning for FMNIST, we define the canary distribution Pcanary as the uniform distribution\nover the last p = 284 principal components (i.e., principal components 500 to 784). For Purchase-100, we use\nthe uniform distribution over the last p = 300 principal components (i.e., principal components 300 to 600).\n    For both settings, we audit only the final model, assuming that we do not have access to the intermediate\nmodels. This corresponds to the blackbox auditing setting for data poisoning and a graybox setting for\nrandom gradient canaries.\nF.3     Miscellaneous Details\nHardware. We run each job on an internal compute cluster using only CPUs (i.e., no hardware accelerators\nsuch as GPUs were used). Each job was run with 8 CPU cores and 16G memory.\nF.4     Additional Experimental Results\nWe give the following plots to augment Table 1 and Figure 5:\n    \u2022 Figure 12: plot of the test accuracy upon adding K canaries to the training process.\n    \u2022 Figure 13: experimental results for FMNIST linear model.\n    \u2022 Figure 14: experimental results for FMNIST MLP model.\n    \u2022 Figure 15: experimental results for Purchase MLP model.\n                                                     32", "md": "# Document\n\n## F.2 DP and Auditing Setup\n\nWe train each dataset-model pair with DP-SGD [1]. The noise level is calibrated so that the entire training\nalgorithm satisfies (\u03b5, \u03b4)-differential privacy with \u03b5 varying and \u03b4 = 10-5 fixed across all experiments. We\ntune the per-example gradient clip norm for each dataset, model, and DP parameter \u03b5 so as to maximize the\nvalidation accuracy.\n\n### Auditing Setup\n\nWe follow the LiDP auditing setup described in Appendix B.2. Recall that auditing LiDP\nwith K = 1 canaries and corresponds exactly with auditing DP. We train n \u2208 {125, 250, 500, 1000} trials,\nwhere each trial corresponds to a model trained with K canaries in each run. We try two methods for canary\ndesign (as well as their corresponding rejection regions), as discussed in Appendix D: data poisoning and\nrandom gradients.\n\n- With data poisoning for FMNIST, we define the canary distribution Pcanary as the uniform distribution\nover the last p = 284 principal components (i.e., principal components 500 to 784). For Purchase-100, we use\nthe uniform distribution over the last p = 300 principal components (i.e., principal components 300 to 600).\n- For both settings, we audit only the final model, assuming that we do not have access to the intermediate\nmodels. This corresponds to the blackbox auditing setting for data poisoning and a graybox setting for\nrandom gradient canaries.\n\n## F.3 Miscellaneous Details\n\nHardware: We run each job on an internal compute cluster using only CPUs (i.e., no hardware accelerators\nsuch as GPUs were used). Each job was run with 8 CPU cores and 16G memory.\n\n## F.4 Additional Experimental Results\n\nWe give the following plots to augment Table 1 and Figure 5:\n\n- Figure 12: plot of the test accuracy upon adding K canaries to the training process.\n- Figure 13: experimental results for FMNIST linear model.\n- Figure 14: experimental results for FMNIST MLP model.\n- Figure 15: experimental results for Purchase MLP model.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "heading", "lvl": 2, "value": "F.2 DP and Auditing Setup", "md": "## F.2 DP and Auditing Setup"}, {"type": "text", "value": "We train each dataset-model pair with DP-SGD [1]. The noise level is calibrated so that the entire training\nalgorithm satisfies (\u03b5, \u03b4)-differential privacy with \u03b5 varying and \u03b4 = 10-5 fixed across all experiments. We\ntune the per-example gradient clip norm for each dataset, model, and DP parameter \u03b5 so as to maximize the\nvalidation accuracy.", "md": "We train each dataset-model pair with DP-SGD [1]. The noise level is calibrated so that the entire training\nalgorithm satisfies (\u03b5, \u03b4)-differential privacy with \u03b5 varying and \u03b4 = 10-5 fixed across all experiments. We\ntune the per-example gradient clip norm for each dataset, model, and DP parameter \u03b5 so as to maximize the\nvalidation accuracy."}, {"type": "heading", "lvl": 3, "value": "Auditing Setup", "md": "### Auditing Setup"}, {"type": "text", "value": "We follow the LiDP auditing setup described in Appendix B.2. Recall that auditing LiDP\nwith K = 1 canaries and corresponds exactly with auditing DP. We train n \u2208 {125, 250, 500, 1000} trials,\nwhere each trial corresponds to a model trained with K canaries in each run. We try two methods for canary\ndesign (as well as their corresponding rejection regions), as discussed in Appendix D: data poisoning and\nrandom gradients.\n\n- With data poisoning for FMNIST, we define the canary distribution Pcanary as the uniform distribution\nover the last p = 284 principal components (i.e., principal components 500 to 784). For Purchase-100, we use\nthe uniform distribution over the last p = 300 principal components (i.e., principal components 300 to 600).\n- For both settings, we audit only the final model, assuming that we do not have access to the intermediate\nmodels. This corresponds to the blackbox auditing setting for data poisoning and a graybox setting for\nrandom gradient canaries.", "md": "We follow the LiDP auditing setup described in Appendix B.2. Recall that auditing LiDP\nwith K = 1 canaries and corresponds exactly with auditing DP. We train n \u2208 {125, 250, 500, 1000} trials,\nwhere each trial corresponds to a model trained with K canaries in each run. We try two methods for canary\ndesign (as well as their corresponding rejection regions), as discussed in Appendix D: data poisoning and\nrandom gradients.\n\n- With data poisoning for FMNIST, we define the canary distribution Pcanary as the uniform distribution\nover the last p = 284 principal components (i.e., principal components 500 to 784). For Purchase-100, we use\nthe uniform distribution over the last p = 300 principal components (i.e., principal components 300 to 600).\n- For both settings, we audit only the final model, assuming that we do not have access to the intermediate\nmodels. This corresponds to the blackbox auditing setting for data poisoning and a graybox setting for\nrandom gradient canaries."}, {"type": "heading", "lvl": 2, "value": "F.3 Miscellaneous Details", "md": "## F.3 Miscellaneous Details"}, {"type": "text", "value": "Hardware: We run each job on an internal compute cluster using only CPUs (i.e., no hardware accelerators\nsuch as GPUs were used). Each job was run with 8 CPU cores and 16G memory.", "md": "Hardware: We run each job on an internal compute cluster using only CPUs (i.e., no hardware accelerators\nsuch as GPUs were used). Each job was run with 8 CPU cores and 16G memory."}, {"type": "heading", "lvl": 2, "value": "F.4 Additional Experimental Results", "md": "## F.4 Additional Experimental Results"}, {"type": "text", "value": "We give the following plots to augment Table 1 and Figure 5:\n\n- Figure 12: plot of the test accuracy upon adding K canaries to the training process.\n- Figure 13: experimental results for FMNIST linear model.\n- Figure 14: experimental results for FMNIST MLP model.\n- Figure 15: experimental results for Purchase MLP model.", "md": "We give the following plots to augment Table 1 and Figure 5:\n\n- Figure 12: plot of the test accuracy upon adding K canaries to the training process.\n- Figure 13: experimental results for FMNIST linear model.\n- Figure 14: experimental results for FMNIST MLP model.\n- Figure 15: experimental results for Purchase MLP model."}]}, {"page": 33, "text": "                          \u03b5 = 1.0, K = \u221an, d = 105                                                         \u03b5 = 1.0, K = 64, d = 105                                    \u03b5 = 1.0, K = 256, d = 105                                                  \u03b5 = 1.0, K = 1024, d = 105\n         Empirical lower bound \u02c6                                                        Empirical lower bound \u02c6                                      Empirical lower bound \u02c6                                                     Empirical lower bound \u02c6\n         \u03b50.4                                                                           \u03b5 0.4                                                        \u03b5 0.4                                                                       \u03b50.4\n          0.3                                                                             0.3                                                          0.3                                                                        0.3\n          0.2                                                                             0.2                                                          0.2                                                                        0.2\n          0.1                                                                             0.1                                                          0.1                                                                        0.1\n          0.0            29            211            213             215                 0.0           29             211            213  215         0.0           29             211           213         215                 0.0            29            211            213  215\n                                  Number of trials n                                                              Number of trials n                                          Number of trials n                                                          Number of trials n\n          0.8             \u03b5 = 2.0, K = \u221an, d = 105                                        0.8              \u03b5 = 2.0, K = 64, d = 105                    0.8             \u03b5 = 2.0, K = 256, d = 105                                  0.8             \u03b5 = 2.0, K = 1024, d = 105\n         Empirical lower bound \u02c6                                                        Empirical lower bound \u02c6                                      Empirical lower bound \u02c6                                                     Empirical lower bound \u02c6\n         \u03b5                                                                              \u03b5                                                            \u03b5                                                                           \u03b5\n          0.6                                                                             0.6                                                          0.6                                                                        0.6\n          0.4                                                                             0.4                                                          0.4                                                                        0.4\n          0.2                                                                             0.2                                                          0.2                                                                        0.2\n                         29            211            213             215                               29             211            213  215                       29             211           213         215                                29            211            213  215\n                                  Number of trials n                                                              Number of trials n                                          Number of trials n                                                          Number of trials n\n          1.8             \u03b5 = 4.0, K = \u221an, d = 105                                        1.8              \u03b5 = 4.0, K = 64, d = 105                    1.8             \u03b5 = 4.0, K = 256, d = 105                                  1.8             \u03b5 = 4.0, K = 1024, d = 105\n         Empirical lower bound \u02c6                                                        Empirical lower bound \u02c6                                      Empirical lower bound \u02c6                                                     Empirical lower bound \u02c6\n         \u03b51.6                                                                           \u03b5 1.6                                                        \u03b5 1.6                                                                       \u03b51.6\n          1.4                                                                             1.4                                                          1.4                                                                        1.4\n          1.2                                                                             1.2                                                          1.2                                                                        1.2\n          1.0                                                                             1.0                                                          1.0                                                                        1.0\n          0.8                                                                             0.8                                                          0.8                                                                        0.8\n          0.6\n                         29            211            213             215                               29             211            213  215                       29             211           213         215                                29            211            213  215\n                                  Number of trials n                                                              Number of trials n                                          Number of trials n                                                          Number of trials n\n         3.75             \u03b5 = 8.0, K = \u221an, d = 105                                       3.75              \u03b5 = 8.0, K = 64, d = 105                  3.75              \u03b5 = 8.0, K = 256, d = 105                                 3.75             \u03b5 = 8.0, K = 1024, d = 105\n         3.50                                                                            3.50                                                        3.50                                                                        3.50\n       Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6                                      Empirical lower bound \u02c6                                                    Empirical lower bound \u02c6\n       \u03b5                                                                               \u03b5                                                            \u03b5                                                                          \u03b5\n         3.25                                                                            3.25                                                        3.25                                                                        3.25\n         3.00                                                                            3.00                                                        3.00                                                                        3.00\n         2.75                                                                            2.75                                                        2.75                                                                        2.75\n         2.50                                                                            2.50                                                        2.50                                                                        2.50\n         2.25                                                                            2.25                                                        2.25                                                                        2.25\n         2.00                                                                            2.00                                                        2.00                                                                        2.00\n         1.75                                                                            1.75                                                        1.75                                                                        1.75\n                         29            211            213             215                               29             211            213  215                       29             211           213         215                                29            211            213  215\n                                  Number of trials n                                                              Number of trials n                                          Number of trials n                                                          Number of trials n\n                                                                            DP + Wilson                          LiDP + 1st-Order Wilson            LiDP + 2nd-Order Wilson                            LiDP + 4th-Order Wilson\nFigure 7: Effect of the number n of trials on the empirical lower bound \u02c6                                                                                                                                         \u03b5 from auditing the Gaussian\nmechanism for DP and LiDP. The shaded are denotes the standard error over 25 random seeds.\n                                                                                                                                                33", "md": "# Math Equations and Table\n\n$$\\epsilon = 1.0, K = \\sqrt{n}, d = 105 \\quad \\epsilon = 1.0, K = 64, d = 105 \\quad \\epsilon = 1.0, K = 256, d = 105 \\quad \\epsilon = 1.0, K = 1024, d = 105$$\n\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|---|---|---|---|\n|$\\epsilon 0.4$|$\\epsilon 0.4$|$\\epsilon 0.4$|$\\epsilon 0.4$|\n|0.3|0.3|0.3|0.3|\n|0.2|0.2|0.2|0.2|\n|0.1|0.1|0.1|0.1|\n|0.0 29 211 213 215|0.0 29 211 213 215|0.0 29 211 213 215|0.0 29 211 213 215|\n|Number of trials n|Number of trials n|Number of trials n|Number of trials n|\n\n$$0.8 \\quad \\epsilon = 2.0, K = \\sqrt{n}, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 64, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 256, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 1024, d = 105$$\n\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|---|---|---|---|\n|$\\epsilon$|$\\epsilon$|$\\epsilon$|$\\epsilon$|\n|0.6|0.6|0.6|0.6|\n|0.4|0.4|0.4|0.4|\n|0.2|0.2|0.2|0.2|\n|29 211 213 215|29 211 213 215|29 211 213 215|29 211 213 215|\n|Number of trials n|Number of trials n|Number of trials n|Number of trials n|\n\n$$1.8 \\quad \\epsilon = 4.0, K = \\sqrt{n}, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 64, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 256, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 1024, d = 105$$\n\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|---|---|---|---|\n|$\\epsilon 1.6$|$\\epsilon 1.6$|$\\epsilon 1.6$|$\\epsilon 1.6$|\n|1.4|1.4|1.4|1.4|\n|1.2|1.2|1.2|1.2|\n|1.0|1.0|1.0|1.0|\n|0.8|0.8|0.8|0.8|\n|0.6 29 211 213 215|0.6 29 211 213 215|0.6 29 211 213 215|0.6 29 211 213 215|\n|Number of trials n|Number of trials n|Number of trials n|Number of trials n|\n\n$$3.75 \\quad \\epsilon = 8.0, K = \\sqrt{n}, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 64, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 256, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 1024, d = 105$$\n\nEmpirical lower bound \u02c6\n\n$$\\epsilon \\quad \\epsilon \\quad \\epsilon \\quad \\epsilon$$\n\n3.25 3.25 3.25 3.25\n\n3.00 3.00 3.00 3.00\n\n2.75 2.75 2.75 2.75\n\n2.50 2.50 2.50 2.50\n\n2.25 2.25 2.25 2.25\n\n2.00 2.00 2.00 2.00\n\n1.75 1.75 1.75 1.75\n\n29 211 213 215 29 211 213 215 29 211 213 215 29 211 213 215\n\nNumber of trials n Number of trials n Number of trials n Number of trials n\n\nDP + Wilson\n\nLiDP + 1st-Order Wilson\n\nLiDP + 2nd-Order Wilson\n\nLiDP + 4th-Order Wilson\n\nFigure 7: Effect of the number n of trials on the empirical lower bound \u02c6 \u03b5 from auditing the Gaussian mechanism for DP and LiDP. The shaded area denotes the standard error over 25 random seeds.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Table", "md": "# Math Equations and Table"}, {"type": "text", "value": "$$\\epsilon = 1.0, K = \\sqrt{n}, d = 105 \\quad \\epsilon = 1.0, K = 64, d = 105 \\quad \\epsilon = 1.0, K = 256, d = 105 \\quad \\epsilon = 1.0, K = 1024, d = 105$$", "md": "$$\\epsilon = 1.0, K = \\sqrt{n}, d = 105 \\quad \\epsilon = 1.0, K = 64, d = 105 \\quad \\epsilon = 1.0, K = 256, d = 105 \\quad \\epsilon = 1.0, K = 1024, d = 105$$"}, {"type": "table", "rows": [["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6"], ["$\\epsilon 0.4$", "$\\epsilon 0.4$", "$\\epsilon 0.4$", "$\\epsilon 0.4$"], ["0.3", "0.3", "0.3", "0.3"], ["0.2", "0.2", "0.2", "0.2"], ["0.1", "0.1", "0.1", "0.1"], ["0.0 29 211 213 215", "0.0 29 211 213 215", "0.0 29 211 213 215", "0.0 29 211 213 215"], ["Number of trials n", "Number of trials n", "Number of trials n", "Number of trials n"]], "md": "|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|---|---|---|---|\n|$\\epsilon 0.4$|$\\epsilon 0.4$|$\\epsilon 0.4$|$\\epsilon 0.4$|\n|0.3|0.3|0.3|0.3|\n|0.2|0.2|0.2|0.2|\n|0.1|0.1|0.1|0.1|\n|0.0 29 211 213 215|0.0 29 211 213 215|0.0 29 211 213 215|0.0 29 211 213 215|\n|Number of trials n|Number of trials n|Number of trials n|Number of trials n|", "isPerfectTable": true, "csv": "\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\"\n\"$\\epsilon 0.4$\",\"$\\epsilon 0.4$\",\"$\\epsilon 0.4$\",\"$\\epsilon 0.4$\"\n\"0.3\",\"0.3\",\"0.3\",\"0.3\"\n\"0.2\",\"0.2\",\"0.2\",\"0.2\"\n\"0.1\",\"0.1\",\"0.1\",\"0.1\"\n\"0.0 29 211 213 215\",\"0.0 29 211 213 215\",\"0.0 29 211 213 215\",\"0.0 29 211 213 215\"\n\"Number of trials n\",\"Number of trials n\",\"Number of trials n\",\"Number of trials n\""}, {"type": "text", "value": "$$0.8 \\quad \\epsilon = 2.0, K = \\sqrt{n}, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 64, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 256, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 1024, d = 105$$", "md": "$$0.8 \\quad \\epsilon = 2.0, K = \\sqrt{n}, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 64, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 256, d = 105 \\quad 0.8 \\quad \\epsilon = 2.0, K = 1024, d = 105$$"}, {"type": "table", "rows": [["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6"], ["$\\epsilon$", "$\\epsilon$", "$\\epsilon$", "$\\epsilon$"], ["0.6", "0.6", "0.6", "0.6"], ["0.4", "0.4", "0.4", "0.4"], ["0.2", "0.2", "0.2", "0.2"], ["29 211 213 215", "29 211 213 215", "29 211 213 215", "29 211 213 215"], ["Number of trials n", "Number of trials n", "Number of trials n", "Number of trials n"]], "md": "|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|---|---|---|---|\n|$\\epsilon$|$\\epsilon$|$\\epsilon$|$\\epsilon$|\n|0.6|0.6|0.6|0.6|\n|0.4|0.4|0.4|0.4|\n|0.2|0.2|0.2|0.2|\n|29 211 213 215|29 211 213 215|29 211 213 215|29 211 213 215|\n|Number of trials n|Number of trials n|Number of trials n|Number of trials n|", "isPerfectTable": true, "csv": "\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\"\n\"$\\epsilon$\",\"$\\epsilon$\",\"$\\epsilon$\",\"$\\epsilon$\"\n\"0.6\",\"0.6\",\"0.6\",\"0.6\"\n\"0.4\",\"0.4\",\"0.4\",\"0.4\"\n\"0.2\",\"0.2\",\"0.2\",\"0.2\"\n\"29 211 213 215\",\"29 211 213 215\",\"29 211 213 215\",\"29 211 213 215\"\n\"Number of trials n\",\"Number of trials n\",\"Number of trials n\",\"Number of trials n\""}, {"type": "text", "value": "$$1.8 \\quad \\epsilon = 4.0, K = \\sqrt{n}, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 64, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 256, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 1024, d = 105$$", "md": "$$1.8 \\quad \\epsilon = 4.0, K = \\sqrt{n}, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 64, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 256, d = 105 \\quad 1.8 \\quad \\epsilon = 4.0, K = 1024, d = 105$$"}, {"type": "table", "rows": [["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6"], ["$\\epsilon 1.6$", "$\\epsilon 1.6$", "$\\epsilon 1.6$", "$\\epsilon 1.6$"], ["1.4", "1.4", "1.4", "1.4"], ["1.2", "1.2", "1.2", "1.2"], ["1.0", "1.0", "1.0", "1.0"], ["0.8", "0.8", "0.8", "0.8"], ["0.6 29 211 213 215", "0.6 29 211 213 215", "0.6 29 211 213 215", "0.6 29 211 213 215"], ["Number of trials n", "Number of trials n", "Number of trials n", "Number of trials n"]], "md": "|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|---|---|---|---|\n|$\\epsilon 1.6$|$\\epsilon 1.6$|$\\epsilon 1.6$|$\\epsilon 1.6$|\n|1.4|1.4|1.4|1.4|\n|1.2|1.2|1.2|1.2|\n|1.0|1.0|1.0|1.0|\n|0.8|0.8|0.8|0.8|\n|0.6 29 211 213 215|0.6 29 211 213 215|0.6 29 211 213 215|0.6 29 211 213 215|\n|Number of trials n|Number of trials n|Number of trials n|Number of trials n|", "isPerfectTable": true, "csv": "\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\"\n\"$\\epsilon 1.6$\",\"$\\epsilon 1.6$\",\"$\\epsilon 1.6$\",\"$\\epsilon 1.6$\"\n\"1.4\",\"1.4\",\"1.4\",\"1.4\"\n\"1.2\",\"1.2\",\"1.2\",\"1.2\"\n\"1.0\",\"1.0\",\"1.0\",\"1.0\"\n\"0.8\",\"0.8\",\"0.8\",\"0.8\"\n\"0.6 29 211 213 215\",\"0.6 29 211 213 215\",\"0.6 29 211 213 215\",\"0.6 29 211 213 215\"\n\"Number of trials n\",\"Number of trials n\",\"Number of trials n\",\"Number of trials n\""}, {"type": "text", "value": "$$3.75 \\quad \\epsilon = 8.0, K = \\sqrt{n}, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 64, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 256, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 1024, d = 105$$\n\nEmpirical lower bound \u02c6\n\n$$\\epsilon \\quad \\epsilon \\quad \\epsilon \\quad \\epsilon$$\n\n3.25 3.25 3.25 3.25\n\n3.00 3.00 3.00 3.00\n\n2.75 2.75 2.75 2.75\n\n2.50 2.50 2.50 2.50\n\n2.25 2.25 2.25 2.25\n\n2.00 2.00 2.00 2.00\n\n1.75 1.75 1.75 1.75\n\n29 211 213 215 29 211 213 215 29 211 213 215 29 211 213 215\n\nNumber of trials n Number of trials n Number of trials n Number of trials n\n\nDP + Wilson\n\nLiDP + 1st-Order Wilson\n\nLiDP + 2nd-Order Wilson\n\nLiDP + 4th-Order Wilson\n\nFigure 7: Effect of the number n of trials on the empirical lower bound \u02c6 \u03b5 from auditing the Gaussian mechanism for DP and LiDP. The shaded area denotes the standard error over 25 random seeds.", "md": "$$3.75 \\quad \\epsilon = 8.0, K = \\sqrt{n}, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 64, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 256, d = 105 \\quad 3.75 \\quad \\epsilon = 8.0, K = 1024, d = 105$$\n\nEmpirical lower bound \u02c6\n\n$$\\epsilon \\quad \\epsilon \\quad \\epsilon \\quad \\epsilon$$\n\n3.25 3.25 3.25 3.25\n\n3.00 3.00 3.00 3.00\n\n2.75 2.75 2.75 2.75\n\n2.50 2.50 2.50 2.50\n\n2.25 2.25 2.25 2.25\n\n2.00 2.00 2.00 2.00\n\n1.75 1.75 1.75 1.75\n\n29 211 213 215 29 211 213 215 29 211 213 215 29 211 213 215\n\nNumber of trials n Number of trials n Number of trials n Number of trials n\n\nDP + Wilson\n\nLiDP + 1st-Order Wilson\n\nLiDP + 2nd-Order Wilson\n\nLiDP + 4th-Order Wilson\n\nFigure 7: Effect of the number n of trials on the empirical lower bound \u02c6 \u03b5 from auditing the Gaussian mechanism for DP and LiDP. The shaded area denotes the standard error over 25 random seeds."}]}, {"page": 34, "text": "                          \u03b5 = 1.0, n = 1024, d = 105                                                      \u03b5 = 1.0, n = 4096, d = 105                                             \u03b5 = 1.0, n = 16384, d = 105                                        \u03b5 = 1.0, n = 65536, d = 105\n                                                                                        0.425\n         0.30\n                                                                                        0.400                                                                    0.44                                                               0.45\n       Empirical lower bound \u02c6                                                        Empirical lower bound \u02c6                                                  Empirical lower bound \u02c6                                            Empirical lower bound \u02c6\n       \u03b5                                                                              \u03b5                                                                        \u03b5                                                                  \u03b5\n         0.25                                                                           0.375                                                                    0.42                                                               0.44\n                                                                                        0.350\n         0.20                                                                                                                                                    0.40                                                               0.43\n                                                                                        0.325\n         0.15                                                                           0.300                                                                    0.38                                                               0.42\n                                                                                        0.275                                                                    0.36                                                               0.41\n         0.10\n                                                                                        0.250                                                                                                                                       0.40\n                                                                                                                                                                 0.34\n                       21          23          25          27          29                              21          23          25          27          29                      21          23          25     27  29                              21          23          25     27  29\n                              Number of canaries K                                                             Number of canaries K                                                    Number of canaries K                                               Number of canaries K\n                          \u03b5 = 2.0, n = 1024, d = 105                                                      \u03b5 = 2.0, n = 4096, d = 105                                             \u03b5 = 2.0, n = 16384, d = 105                                        \u03b5 = 2.0, n = 65536, d = 105\n         0.70                                                                            0.85                                                                                                                                       0.90\n                                                                                                                                                                 0.88\n       Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6                                                 Empirical lower bound \u02c6                                            Empirical lower bound \u02c6\n       \u03b5 0.65                                                                          \u03b5                                                                       \u03b5                                                                  \u03b5 0.89\n                                                                                         0.80                                                                    0.86\n         0.60                                                                                                                                                                                                                       0.88\n                                                                                                                                                                 0.84\n         0.55                                                                            0.75                                                                                                                                       0.87\n                                                                                                                                                                 0.82\n         0.50                                                                                                                                                                                                                       0.86\n                                                                                         0.70                                                                    0.80\n         0.45                                                                                                                                                                                                                       0.85\n         0.40                                                                            0.65                                                                    0.78                                                               0.84\n                       21          23          25          27          29                              21          23          25          27          29                      21          23          25     27  29                              21          23          25     27  29\n                              Number of canaries K                                                             Number of canaries K                                                    Number of canaries K                                               Number of canaries K\n         1.50             \u03b5 = 4.0, n = 1024, d = 105                                                      \u03b5 = 4.0, n = 4096, d = 105                                             \u03b5 = 4.0, n = 16384, d = 105                                        \u03b5 = 4.0, n = 65536, d = 105\n                                                                                                                                                                 1.80                                                               1.82\n         1.45                                                                            1.70\n       Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6                                                 Empirical lower bound \u02c6                                            Empirical lower bound \u02c6\n       \u03b5                                                                               \u03b5                                                                       \u03b5 1.78                                                             \u03b5\n         1.40                                                                                                                                                    1.76                                                               1.80\n                                                                                         1.65\n         1.35                                                                                                                                                    1.74\n                                                                                                                                                                                                                                    1.78\n         1.30                                                                            1.60                                                                    1.72\n         1.25                                                                            1.55                                                                    1.70                                                               1.76\n         1.20                                                                                                                                                    1.68\n                                                                                         1.50                                                                    1.66                                                               1.74\n         1.15\n                       21          23          25          27          29                              21          23          25          27          29                      21          23          25     27  29                              21          23          25     27  29\n                              Number of canaries K                                                             Number of canaries K                                                    Number of canaries K                                               Number of canaries K\n                          \u03b5 = 8.0, n = 1024, d = 105                                                      \u03b5 = 8.0, n = 4096, d = 105                                             \u03b5 = 8.0, n = 16384, d = 105                                        \u03b5 = 8.0, n = 65536, d = 105\n         2.70                                                                                                                                                                                                                      3.775\n                                                                                          3.3                                                                    3.65                                                              3.750\n       Empirical lower bound \u02c6                                                           Empirical lower bound \u02c6                                               Empirical lower bound \u02c6                                           Empirical lower bound \u02c6\n       \u03b5 2.65                                                                            \u03b5                                                                     \u03b5                                                                 \u03b5\n                                                                                                                                                                 3.60                                                              3.725\n         2.60                                                                             3.2                                                                                                                                      3.700\n         2.55                                                                                                                                                    3.55                                                              3.675\n         2.50                                                                             3.1                                                                    3.50                                                              3.650\n                                                                                                                                                                                                                                   3.625\n         2.45                                                                             3.0                                                                    3.45\n                                                                                                                                                                                                                                   3.600\n         2.40                                                                                                                                                    3.40                                                              3.575\n                       21          23          25          27          29                              21          23          25          27          29                      21          23          25     27  29                              21          23          25     27  29\n                              Number of canaries K                                                             Number of canaries K                                                    Number of canaries K                                               Number of canaries K\n                                                             K = \u221an                        DP + Wilson                          LiDP + 1st-Order Wilson                       LiDP + 2nd-Order Wilson                   LiDP + 4th-Order Wilson\nFigure 8: Effect of the number k of canaries on the empirical lower bound \u02c6                                                                                                                                           \u03b5 from auditing the Gaussian\nmechanism for DP and LiDP. The shaded are denotes the standard error over 25 random seeds.\n                                                                                                                                                           34", "md": "# Math Equations and Table\n\n$$\\epsilon = 1.0, n = 1024, d = 105 \\quad \\epsilon = 1.0, n = 4096, d = 105 \\quad \\epsilon = 1.0, n = 16384, d = 105 \\quad \\epsilon = 1.0, n = 65536, d = 105$$\n\n| |0.425|0.30|\n|---|---|---|\n|Empirical lower bound \u02c6|0.400|0.44|\n|\u03b5|0.25|0.375|\n| |0.350| |\n|0.20| |0.40|\n| |0.325| |\n|0.15|0.300|0.38|\n| |0.275|0.36|\n|0.10| |0.40|\n| |0.34| |\n| |21 23 25 27 29| |\n|Number of canaries K| | |\n\n$$\\epsilon = 2.0, n = 1024, d = 105 \\quad \\epsilon = 2.0, n = 4096, d = 105 \\quad \\epsilon = 2.0, n = 16384, d = 105 \\quad \\epsilon = 2.0, n = 65536, d = 105$$\n\n| |0.70|0.85|\n|---|---|---|\n|Empirical lower bound \u02c6|0.65|0.80|\n|\u03b5|0.60| |\n| |0.75| |\n|0.50| |0.70|\n| |0.65| |\n|0.45|0.60|0.68|\n| |0.55|0.66|\n|0.40| |0.64|\n| |0.62| |\n| |21 23 25 27 29| |\n|Number of canaries K| | |\n\n$$\\epsilon = 4.0, n = 1024, d = 105 \\quad \\epsilon = 4.0, n = 4096, d = 105 \\quad \\epsilon = 4.0, n = 16384, d = 105 \\quad \\epsilon = 4.0, n = 65536, d = 105$$\n\n| |1.50| |\n|---|---|---|\n|Empirical lower bound \u02c6|1.45|1.70|\n|\u03b5|1.40| |\n| |1.65| |\n|1.30|1.60|1.72|\n|1.25|1.55|1.70|\n|1.20| |1.68|\n| |1.50|1.66|\n|1.15| |1.74|\n| |21 23 25 27 29| |\n|Number of canaries K| | |\n\n$$\\epsilon = 8.0, n = 1024, d = 105 \\quad \\epsilon = 8.0, n = 4096, d = 105 \\quad \\epsilon = 8.0, n = 16384, d = 105 \\quad \\epsilon = 8.0, n = 65536, d = 105$$\n\n| |2.70|3.775|\n|---|---|---|\n|Empirical lower bound \u02c6|2.65|3.3|\n|\u03b5|2.60| |\n| |3.2| |\n|2.55| |3.65|\n| |3.60| |\n|2.50|3.55|3.675|\n| |3.50|3.650|\n|2.45| |3.625|\n| |3.45| |\n| |21 23 25 27 29| |\n|Number of canaries K| | |\n\nK = \u221an DP + Wilson LiDP + 1st-Order Wilson LiDP + 2nd-Order Wilson LiDP + 4th-Order Wilson\n\nFigure 8: Effect of the number k of canaries on the empirical lower bound \u02c6 \u03b5 from auditing the Gaussian mechanism for DP and LiDP. The shaded area denotes the standard error over 25 random seeds.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Table", "md": "# Math Equations and Table"}, {"type": "text", "value": "$$\\epsilon = 1.0, n = 1024, d = 105 \\quad \\epsilon = 1.0, n = 4096, d = 105 \\quad \\epsilon = 1.0, n = 16384, d = 105 \\quad \\epsilon = 1.0, n = 65536, d = 105$$", "md": "$$\\epsilon = 1.0, n = 1024, d = 105 \\quad \\epsilon = 1.0, n = 4096, d = 105 \\quad \\epsilon = 1.0, n = 16384, d = 105 \\quad \\epsilon = 1.0, n = 65536, d = 105$$"}, {"type": "table", "rows": [["", "0.425", "0.30"], ["Empirical lower bound \u02c6", "0.400", "0.44"], ["\u03b5", "0.25", "0.375"], ["", "0.350", ""], ["0.20", "", "0.40"], ["", "0.325", ""], ["0.15", "0.300", "0.38"], ["", "0.275", "0.36"], ["0.10", "", "0.40"], ["", "0.34", ""], ["", "21 23 25 27 29", ""], ["Number of canaries K", "", ""]], "md": "| |0.425|0.30|\n|---|---|---|\n|Empirical lower bound \u02c6|0.400|0.44|\n|\u03b5|0.25|0.375|\n| |0.350| |\n|0.20| |0.40|\n| |0.325| |\n|0.15|0.300|0.38|\n| |0.275|0.36|\n|0.10| |0.40|\n| |0.34| |\n| |21 23 25 27 29| |\n|Number of canaries K| | |", "isPerfectTable": true, "csv": "\"\",\"0.425\",\"0.30\"\n\"Empirical lower bound \u02c6\",\"0.400\",\"0.44\"\n\"\u03b5\",\"0.25\",\"0.375\"\n\"\",\"0.350\",\"\"\n\"0.20\",\"\",\"0.40\"\n\"\",\"0.325\",\"\"\n\"0.15\",\"0.300\",\"0.38\"\n\"\",\"0.275\",\"0.36\"\n\"0.10\",\"\",\"0.40\"\n\"\",\"0.34\",\"\"\n\"\",\"21 23 25 27 29\",\"\"\n\"Number of canaries K\",\"\",\"\""}, {"type": "text", "value": "$$\\epsilon = 2.0, n = 1024, d = 105 \\quad \\epsilon = 2.0, n = 4096, d = 105 \\quad \\epsilon = 2.0, n = 16384, d = 105 \\quad \\epsilon = 2.0, n = 65536, d = 105$$", "md": "$$\\epsilon = 2.0, n = 1024, d = 105 \\quad \\epsilon = 2.0, n = 4096, d = 105 \\quad \\epsilon = 2.0, n = 16384, d = 105 \\quad \\epsilon = 2.0, n = 65536, d = 105$$"}, {"type": "table", "rows": [["", "0.70", "0.85"], ["Empirical lower bound \u02c6", "0.65", "0.80"], ["\u03b5", "0.60", ""], ["", "0.75", ""], ["0.50", "", "0.70"], ["", "0.65", ""], ["0.45", "0.60", "0.68"], ["", "0.55", "0.66"], ["0.40", "", "0.64"], ["", "0.62", ""], ["", "21 23 25 27 29", ""], ["Number of canaries K", "", ""]], "md": "| |0.70|0.85|\n|---|---|---|\n|Empirical lower bound \u02c6|0.65|0.80|\n|\u03b5|0.60| |\n| |0.75| |\n|0.50| |0.70|\n| |0.65| |\n|0.45|0.60|0.68|\n| |0.55|0.66|\n|0.40| |0.64|\n| |0.62| |\n| |21 23 25 27 29| |\n|Number of canaries K| | |", "isPerfectTable": true, "csv": "\"\",\"0.70\",\"0.85\"\n\"Empirical lower bound \u02c6\",\"0.65\",\"0.80\"\n\"\u03b5\",\"0.60\",\"\"\n\"\",\"0.75\",\"\"\n\"0.50\",\"\",\"0.70\"\n\"\",\"0.65\",\"\"\n\"0.45\",\"0.60\",\"0.68\"\n\"\",\"0.55\",\"0.66\"\n\"0.40\",\"\",\"0.64\"\n\"\",\"0.62\",\"\"\n\"\",\"21 23 25 27 29\",\"\"\n\"Number of canaries K\",\"\",\"\""}, {"type": "text", "value": "$$\\epsilon = 4.0, n = 1024, d = 105 \\quad \\epsilon = 4.0, n = 4096, d = 105 \\quad \\epsilon = 4.0, n = 16384, d = 105 \\quad \\epsilon = 4.0, n = 65536, d = 105$$", "md": "$$\\epsilon = 4.0, n = 1024, d = 105 \\quad \\epsilon = 4.0, n = 4096, d = 105 \\quad \\epsilon = 4.0, n = 16384, d = 105 \\quad \\epsilon = 4.0, n = 65536, d = 105$$"}, {"type": "table", "rows": [["", "1.50", ""], ["Empirical lower bound \u02c6", "1.45", "1.70"], ["\u03b5", "1.40", ""], ["", "1.65", ""], ["1.30", "1.60", "1.72"], ["1.25", "1.55", "1.70"], ["1.20", "", "1.68"], ["", "1.50", "1.66"], ["1.15", "", "1.74"], ["", "21 23 25 27 29", ""], ["Number of canaries K", "", ""]], "md": "| |1.50| |\n|---|---|---|\n|Empirical lower bound \u02c6|1.45|1.70|\n|\u03b5|1.40| |\n| |1.65| |\n|1.30|1.60|1.72|\n|1.25|1.55|1.70|\n|1.20| |1.68|\n| |1.50|1.66|\n|1.15| |1.74|\n| |21 23 25 27 29| |\n|Number of canaries K| | |", "isPerfectTable": true, "csv": "\"\",\"1.50\",\"\"\n\"Empirical lower bound \u02c6\",\"1.45\",\"1.70\"\n\"\u03b5\",\"1.40\",\"\"\n\"\",\"1.65\",\"\"\n\"1.30\",\"1.60\",\"1.72\"\n\"1.25\",\"1.55\",\"1.70\"\n\"1.20\",\"\",\"1.68\"\n\"\",\"1.50\",\"1.66\"\n\"1.15\",\"\",\"1.74\"\n\"\",\"21 23 25 27 29\",\"\"\n\"Number of canaries K\",\"\",\"\""}, {"type": "text", "value": "$$\\epsilon = 8.0, n = 1024, d = 105 \\quad \\epsilon = 8.0, n = 4096, d = 105 \\quad \\epsilon = 8.0, n = 16384, d = 105 \\quad \\epsilon = 8.0, n = 65536, d = 105$$", "md": "$$\\epsilon = 8.0, n = 1024, d = 105 \\quad \\epsilon = 8.0, n = 4096, d = 105 \\quad \\epsilon = 8.0, n = 16384, d = 105 \\quad \\epsilon = 8.0, n = 65536, d = 105$$"}, {"type": "table", "rows": [["", "2.70", "3.775"], ["Empirical lower bound \u02c6", "2.65", "3.3"], ["\u03b5", "2.60", ""], ["", "3.2", ""], ["2.55", "", "3.65"], ["", "3.60", ""], ["2.50", "3.55", "3.675"], ["", "3.50", "3.650"], ["2.45", "", "3.625"], ["", "3.45", ""], ["", "21 23 25 27 29", ""], ["Number of canaries K", "", ""]], "md": "| |2.70|3.775|\n|---|---|---|\n|Empirical lower bound \u02c6|2.65|3.3|\n|\u03b5|2.60| |\n| |3.2| |\n|2.55| |3.65|\n| |3.60| |\n|2.50|3.55|3.675|\n| |3.50|3.650|\n|2.45| |3.625|\n| |3.45| |\n| |21 23 25 27 29| |\n|Number of canaries K| | |", "isPerfectTable": true, "csv": "\"\",\"2.70\",\"3.775\"\n\"Empirical lower bound \u02c6\",\"2.65\",\"3.3\"\n\"\u03b5\",\"2.60\",\"\"\n\"\",\"3.2\",\"\"\n\"2.55\",\"\",\"3.65\"\n\"\",\"3.60\",\"\"\n\"2.50\",\"3.55\",\"3.675\"\n\"\",\"3.50\",\"3.650\"\n\"2.45\",\"\",\"3.625\"\n\"\",\"3.45\",\"\"\n\"\",\"21 23 25 27 29\",\"\"\n\"Number of canaries K\",\"\",\"\""}, {"type": "text", "value": "K = \u221an DP + Wilson LiDP + 1st-Order Wilson LiDP + 2nd-Order Wilson LiDP + 4th-Order Wilson\n\nFigure 8: Effect of the number k of canaries on the empirical lower bound \u02c6 \u03b5 from auditing the Gaussian mechanism for DP and LiDP. The shaded area denotes the standard error over 25 random seeds.", "md": "K = \u221an DP + Wilson LiDP + 1st-Order Wilson LiDP + 2nd-Order Wilson LiDP + 4th-Order Wilson\n\nFigure 8: Effect of the number k of canaries on the empirical lower bound \u02c6 \u03b5 from auditing the Gaussian mechanism for DP and LiDP. The shaded area denotes the standard error over 25 random seeds."}]}, {"page": 35, "text": "         0.30            \u03b5 = 1.0, n = 1024, K = \u221an                                      0.400            \u03b5 = 1.0, n = 4096, K = \u221an                      0.44           \u03b5 = 1.0, n = 16384, K = \u221an                                       0.45           \u03b5 = 1.0, n = 65536, K = \u221an\n       Empirical lower bound \u02c6                                                        Empirical lower bound \u02c6                                         Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6\n       \u03b5 0.25                                                                         \u03b5 0.375                                                         \u03b5                                                                               \u03b5 0.44\n                                                                                                                                                        0.42\n                                                                                        0.350                                                                                                                                           0.43\n         0.20\n                                                                                        0.325                                                           0.40                                                                            0.42\n         0.15                                                                           0.300                                                           0.38                                                                            0.41\n                                                                                        0.275                                                                                                                                           0.40\n         0.10\n                                                                                        0.250                                                           0.36                                                                            0.39\n         0.05                                                                           0.225                                                           0.34                                                                            0.38\n                102            103            104            105            106                 102            103            104         105  106             102            103            104            105            106          0.37   102            103            104   105  106\n                                      Dimension d                                                                     Dimension d                                                    Dimension d                                                                     Dimension d\n         0.70            \u03b5 = 2.0, n = 1024, K = \u221an                                       0.85            \u03b5 = 2.0, n = 4096, K = \u221an                                     \u03b5 = 2.0, n = 16384, K = \u221an                                       0.90           \u03b5 = 2.0, n = 65536, K = \u221an\n       Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6                                        Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6\n       \u03b5 0.65                                                                          \u03b5 0.80                                                         \u03b5 0.85                                                                          \u03b5 0.85\n         0.60\n                                                                                         0.75                                                           0.80                                                                            0.80\n         0.55\n         0.50                                                                            0.70                                                           0.75                                                                            0.75\n         0.45                                                                            0.65                                                                                                                                           0.70\n                                                                                                                                                        0.70\n         0.40\n                                                                                         0.60                                                                                                                                           0.65\n                102            103            104            105            106                 102            103            104         105  106             102            103            104            105            106                 102            103            104   105  106\n                                      Dimension d                                                                     Dimension d                                                    Dimension d                                                                     Dimension d\n                         \u03b5 = 4.0, n = 1024, K = \u221an                                        1.7            \u03b5 = 4.0, n = 4096, K = \u221an                       1.8           \u03b5 = 4.0, n = 16384, K = \u221an                                        1.8           \u03b5 = 4.0, n = 65536, K = \u221an\n         Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6                                        Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6\n         \u03b51.4                                                                            \u03b5                                                              \u03b51.7                                                                            \u03b5\n                                                                                          1.6                                                                                                                                            1.6\n                                                                                                                                                         1.6\n          1.3\n                                                                                          1.5                                                            1.5\n                                                                                                                                                                                                                                         1.4\n          1.2                                                                             1.4                                                            1.4\n                                                                                                                                                         1.3                                                                             1.2\n          1.1                                                                             1.3\n                                                                                                                                                         1.2\n                                                                                          1.2                                                                                                                                            1.0\n          1.0                                                                                                                                            1.1\n                102            103            104            105            106                 102            103            104         105  106             102            103            104            105            106                 102            103            104   105  106\n                                      Dimension d                                                                     Dimension d                                                    Dimension d                                                                     Dimension d\n                         \u03b5 = 8.0, n = 1024, K = \u221an                                        3.4            \u03b5 = 8.0, n = 4096, K = \u221an                                     \u03b5 = 8.0, n = 16384, K = \u221an                                                      \u03b5 = 8.0, n = 65536, K = \u221an\n          2.6                                                                             3.2                                                            3.5                                                                             3.5\n         Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6                                        Empirical lower bound \u02c6                                                         Empirical lower bound \u02c6\n         \u03b5                                                                               \u03b5                                                              \u03b5                                                                               \u03b5\n                                                                                          3.0\n          2.4                                                                             2.8                                                            3.0                                                                             3.0\n                                                                                          2.6                                                                                                                                            2.5\n          2.2                                                                                                                                            2.5\n                                                                                          2.4\n                                                                                                                                                                                                                                         2.0\n          2.0                                                                             2.2                                                            2.0\n                                                                                          2.0                                                                                                                                            1.5\n          1.8                                                                             1.8                                                            1.5\n                                                                                                                                                                                                                                         1.0\n                102            103            104            105            106                 102            103            104         105  106             102            103            104            105            106                 102            103            104   105  106\n                                      Dimension d                                                                     Dimension d                                                    Dimension d                                                                     Dimension d\n                                                                            DP + Wilson                          LiDP + 1st-Order Wilson              LiDP + 2nd-Order Wilson                                LiDP + 4th-Order Wilson\nFigure 9: Effect of the data dimension d on the empirical lower bound \u02c6                                                                                                                      \u03b5 from auditing the Gaussian mechanism\nfor DP and LiDP. The shaded are denotes the standard error over 25 random seeds.\n                                                                                                                                                  35", "md": "# Effect of Data Dimension on Empirical Lower Bound\n\n## Effect of Data Dimension on Empirical Lower Bound\n\n| |\u03b5 = 1.0, n = 1024, K = \u221an|\u03b5 = 1.0, n = 4096, K = \u221an|\u03b5 = 1.0, n = 16384, K = \u221an|\u03b5 = 1.0, n = 65536, K = \u221an|\n|---|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6| |\n|\u03b5|0.25|0.375| |0.44|\n| | | | |0.42|\n| |0.350|0.40| |0.43|\n| |0.325|0.38| |0.42|\n| |0.300|0.36| |0.41|\n| |0.275|0.34| |0.40|\n| |0.250|0.32| |0.39|\n| |0.225|0.30| |0.38|\n| |102|103|104|105|106|102|103|104|105|106|102|103|104|105|106|0.37|102|103|104|105|106|\n|Dimension d| | | | | | | | | | | | | | | | | | | | | |\n\n$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 2.0, n = 1024, K = \\sqrt{n} & \\epsilon = 2.0, n = 4096, K = \\sqrt{n} & \\epsilon = 2.0, n = 16384, K = \\sqrt{n} & \\epsilon = 2.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & 0.65 & 0.80 & 0.85 & 0.85 \\\\\n& & & & 0.80 \\\\\n& 0.60 & 0.75 & 0.80 & 0.80 \\\\\n& 0.55 & 0.70 & 0.75 & 0.75 \\\\\n& 0.50 & 0.65 & & 0.70 \\\\\n& & 0.60 & & 0.70 \\\\\n& 0.45 & & & 0.65 \\\\\n& 0.40 & & & 0.65 \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\n$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 4.0, n = 1024, K = \\sqrt{n} & \\epsilon = 4.0, n = 4096, K = \\sqrt{n} & \\epsilon = 4.0, n = 16384, K = \\sqrt{n} & \\epsilon = 4.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & 1.4 & & 1.7 & \\\\\n& 1.6 & & 1.6 & \\\\\n& 1.3 & & 1.5 & \\\\\n& 1.2 & 1.4 & 1.4 & \\\\\n& 1.1 & 1.3 & & 1.2 \\\\\n& & 1.2 & & 1.0 \\\\\n& 1.0 & 1.1 & & \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\n$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 8.0, n = 1024, K = \\sqrt{n} & \\epsilon = 8.0, n = 4096, K = \\sqrt{n} & \\epsilon = 8.0, n = 16384, K = \\sqrt{n} & \\epsilon = 8.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & & & & \\\\\n& 3.0 & & 3.5 & 3.5 \\\\\n& 2.8 & & 3.0 & 3.0 \\\\\n& 2.6 & & 2.5 & \\\\\n& 2.4 & 2.8 & 2.0 & \\\\\n& 2.2 & 2.5 & & 1.5 \\\\\n& 2.0 & 2.2 & & \\\\\n& 1.8 & 1.8 & 1.5 & \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\nFigure 9: Effect of the data dimension d on the empirical lower bound \u02c6 for DP and LiDP. The shaded area denotes the standard error over 25 random seeds.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Effect of Data Dimension on Empirical Lower Bound", "md": "# Effect of Data Dimension on Empirical Lower Bound"}, {"type": "heading", "lvl": 2, "value": "Effect of Data Dimension on Empirical Lower Bound", "md": "## Effect of Data Dimension on Empirical Lower Bound"}, {"type": "table", "rows": [["", "\u03b5 = 1.0, n = 1024, K = \u221an", "\u03b5 = 1.0, n = 4096, K = \u221an", "\u03b5 = 1.0, n = 16384, K = \u221an", "\u03b5 = 1.0, n = 65536, K = \u221an"], ["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", ""], ["\u03b5", "0.25", "0.375", "", "0.44"], ["", "", "", "", "0.42"], ["", "0.350", "0.40", "", "0.43"], ["", "0.325", "0.38", "", "0.42"], ["", "0.300", "0.36", "", "0.41"], ["", "0.275", "0.34", "", "0.40"], ["", "0.250", "0.32", "", "0.39"], ["", "0.225", "0.30", "", "0.38"], ["", "102", "103", "104", "105", "106", "102", "103", "104", "105", "106", "102", "103", "104", "105", "106", "0.37", "102", "103", "104", "105", "106"], ["Dimension d", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""]], "md": "| |\u03b5 = 1.0, n = 1024, K = \u221an|\u03b5 = 1.0, n = 4096, K = \u221an|\u03b5 = 1.0, n = 16384, K = \u221an|\u03b5 = 1.0, n = 65536, K = \u221an|\n|---|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6| |\n|\u03b5|0.25|0.375| |0.44|\n| | | | |0.42|\n| |0.350|0.40| |0.43|\n| |0.325|0.38| |0.42|\n| |0.300|0.36| |0.41|\n| |0.275|0.34| |0.40|\n| |0.250|0.32| |0.39|\n| |0.225|0.30| |0.38|\n| |102|103|104|105|106|102|103|104|105|106|102|103|104|105|106|0.37|102|103|104|105|106|\n|Dimension d| | | | | | | | | | | | | | | | | | | | | |", "isPerfectTable": false, "csv": "\"\",\"\u03b5 = 1.0, n = 1024, K = \u221an\",\"\u03b5 = 1.0, n = 4096, K = \u221an\",\"\u03b5 = 1.0, n = 16384, K = \u221an\",\"\u03b5 = 1.0, n = 65536, K = \u221an\"\n\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"\"\n\"\u03b5\",\"0.25\",\"0.375\",\"\",\"0.44\"\n\"\",\"\",\"\",\"\",\"0.42\"\n\"\",\"0.350\",\"0.40\",\"\",\"0.43\"\n\"\",\"0.325\",\"0.38\",\"\",\"0.42\"\n\"\",\"0.300\",\"0.36\",\"\",\"0.41\"\n\"\",\"0.275\",\"0.34\",\"\",\"0.40\"\n\"\",\"0.250\",\"0.32\",\"\",\"0.39\"\n\"\",\"0.225\",\"0.30\",\"\",\"0.38\"\n\"\",\"102\",\"103\",\"104\",\"105\",\"106\",\"102\",\"103\",\"104\",\"105\",\"106\",\"102\",\"103\",\"104\",\"105\",\"106\",\"0.37\",\"102\",\"103\",\"104\",\"105\",\"106\"\n\"Dimension d\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\""}, {"type": "text", "value": "$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 2.0, n = 1024, K = \\sqrt{n} & \\epsilon = 2.0, n = 4096, K = \\sqrt{n} & \\epsilon = 2.0, n = 16384, K = \\sqrt{n} & \\epsilon = 2.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & 0.65 & 0.80 & 0.85 & 0.85 \\\\\n& & & & 0.80 \\\\\n& 0.60 & 0.75 & 0.80 & 0.80 \\\\\n& 0.55 & 0.70 & 0.75 & 0.75 \\\\\n& 0.50 & 0.65 & & 0.70 \\\\\n& & 0.60 & & 0.70 \\\\\n& 0.45 & & & 0.65 \\\\\n& 0.40 & & & 0.65 \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\n$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 4.0, n = 1024, K = \\sqrt{n} & \\epsilon = 4.0, n = 4096, K = \\sqrt{n} & \\epsilon = 4.0, n = 16384, K = \\sqrt{n} & \\epsilon = 4.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & 1.4 & & 1.7 & \\\\\n& 1.6 & & 1.6 & \\\\\n& 1.3 & & 1.5 & \\\\\n& 1.2 & 1.4 & 1.4 & \\\\\n& 1.1 & 1.3 & & 1.2 \\\\\n& & 1.2 & & 1.0 \\\\\n& 1.0 & 1.1 & & \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\n$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 8.0, n = 1024, K = \\sqrt{n} & \\epsilon = 8.0, n = 4096, K = \\sqrt{n} & \\epsilon = 8.0, n = 16384, K = \\sqrt{n} & \\epsilon = 8.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & & & & \\\\\n& 3.0 & & 3.5 & 3.5 \\\\\n& 2.8 & & 3.0 & 3.0 \\\\\n& 2.6 & & 2.5 & \\\\\n& 2.4 & 2.8 & 2.0 & \\\\\n& 2.2 & 2.5 & & 1.5 \\\\\n& 2.0 & 2.2 & & \\\\\n& 1.8 & 1.8 & 1.5 & \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\nFigure 9: Effect of the data dimension d on the empirical lower bound \u02c6 for DP and LiDP. The shaded area denotes the standard error over 25 random seeds.", "md": "$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 2.0, n = 1024, K = \\sqrt{n} & \\epsilon = 2.0, n = 4096, K = \\sqrt{n} & \\epsilon = 2.0, n = 16384, K = \\sqrt{n} & \\epsilon = 2.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & 0.65 & 0.80 & 0.85 & 0.85 \\\\\n& & & & 0.80 \\\\\n& 0.60 & 0.75 & 0.80 & 0.80 \\\\\n& 0.55 & 0.70 & 0.75 & 0.75 \\\\\n& 0.50 & 0.65 & & 0.70 \\\\\n& & 0.60 & & 0.70 \\\\\n& 0.45 & & & 0.65 \\\\\n& 0.40 & & & 0.65 \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\n$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 4.0, n = 1024, K = \\sqrt{n} & \\epsilon = 4.0, n = 4096, K = \\sqrt{n} & \\epsilon = 4.0, n = 16384, K = \\sqrt{n} & \\epsilon = 4.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & 1.4 & & 1.7 & \\\\\n& 1.6 & & 1.6 & \\\\\n& 1.3 & & 1.5 & \\\\\n& 1.2 & 1.4 & 1.4 & \\\\\n& 1.1 & 1.3 & & 1.2 \\\\\n& & 1.2 & & 1.0 \\\\\n& 1.0 & 1.1 & & \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\n$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\epsilon = 8.0, n = 1024, K = \\sqrt{n} & \\epsilon = 8.0, n = 4096, K = \\sqrt{n} & \\epsilon = 8.0, n = 16384, K = \\sqrt{n} & \\epsilon = 8.0, n = 65536, K = \\sqrt{n} \\\\\n\\hline\n\\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} & \\text{Empirical lower bound} \\hat{} \\\\\n\\epsilon & & & & \\\\\n& 3.0 & & 3.5 & 3.5 \\\\\n& 2.8 & & 3.0 & 3.0 \\\\\n& 2.6 & & 2.5 & \\\\\n& 2.4 & 2.8 & 2.0 & \\\\\n& 2.2 & 2.5 & & 1.5 \\\\\n& 2.0 & 2.2 & & \\\\\n& 1.8 & 1.8 & 1.5 & \\\\\n& 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 & 102 & 103 & 104 & 105 & 106 \\\\\n\\text{Dimension d} & & & & & & & & & & & & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\n\nFigure 9: Effect of the data dimension d on the empirical lower bound \u02c6 for DP and LiDP. The shaded area denotes the standard error over 25 random seeds."}]}, {"page": 36, "text": "         10\u22122            \u03b5 = 1.0, n = 1024, d = 105                                 10\u22122            \u03b5 = 1.0, n = 4096, d = 105                    10\u22122           \u03b5 = 1.0, n = 16384, d = 105              10\u22122           \u03b5 = 1.0, n = 65536, d = 105\n         10\u22123                                                                       10\u22123                                                          10\u22123                                                    10\u22123\n        Correlation Measure                                                        Correlation Measure                                          Correlation Measure                                     Correlation Measure\n         10\u22124                                                                       10\u22124                                                          10\u22124                                                    10\u22124\n         10\u22125                                                                       10\u22125                                                          10\u22125                                                    10\u22125\n         10\u22126                                                                       10\u22126                                                          10\u22126                                                    10\u22126\n         10\u22127                                                                       10\u22127                                                          10\u22127                                                    10\u22127\n                                                                                    10\u22128                                                          10\u22128\n         10\u22128                                                                       10\u22129                                                          10\u22129                                                    10\u22128\n                       22           24          26           28          210                      22           24          26     28  210                       22           24          26   28  210                   22          24           26   28  210\n                              Number of canaries K                                                       Number of canaries K                                         Number of canaries K                                    Number of canaries K\n         10\u22122            \u03b5 = 2.0, n = 1024, d = 105                                 10\u22122            \u03b5 = 2.0, n = 4096, d = 105                    10\u22122           \u03b5 = 2.0, n = 16384, d = 105              10\u22122           \u03b5 = 2.0, n = 65536, d = 105\n         10\u22123                                                                       10\u22123                                                          10\u22123                                                    10\u22123\n        Correlation Measure                                                        Correlation Measure                                          Correlation Measure                                     Correlation Measure\n         10\u22124                                                                       10\u22124                                                          10\u22124                                                    10\u22124\n         10\u22125                                                                       10\u22125                                                          10\u22125                                                    10\u22125\n         10\u22126                                                                       10\u22126                                                          10\u22126                                                    10\u22126\n         10\u22127                                                                       10\u22127                                                          10\u22127                                                    10\u22127\n         10\u22128                                                                       10\u22128                                                          10\u22128                                                    10\u22128\n         10\u22129                                                                       10\u22129                                                          10\u22129                                                    10\u22129\n                       22           24          26           28          210                      22           24          26     28  210                       22           24          26   28  210                   22          24           26   28  210\n                              Number of canaries K                                                       Number of canaries K                                         Number of canaries K                                    Number of canaries K\n                         \u03b5 = 4.0, n = 1024, d = 105                                                 \u03b5 = 4.0, n = 4096, d = 105                                   \u03b5 = 4.0, n = 16384, d = 105              10\u22122           \u03b5 = 4.0, n = 65536, d = 105\n         10\u22123                                                                       10\u22123                                                          10\u22123\n                                                                                                                                                                                                          10\u22124\n        Correlation Measure                                                        Correlation Measure                                          Correlation Measure                                    Correlation Measure\n         10\u22125                                                                       10\u22125                                                          10\u22125                                                    10\u22126\n         10\u22127                                                                       10\u22127                                                          10\u22127                                                    10\u22128\n         10\u22129                                                                       10\u22129                                                          10\u22129                                                   10\u221210\n                       22           24          26           28          210                      22           24          26     28  210                       22           24          26   28  210                   22          24           26   28  210\n                              Number of canaries K                                                       Number of canaries K                                         Number of canaries K                                    Number of canaries K\n         10\u22122            \u03b5 = 8.0, n = 1024, d = 105                                 10\u22123            \u03b5 = 8.0, n = 4096, d = 105                    10\u22122           \u03b5 = 8.0, n = 16384, d = 105              10\u22123           \u03b5 = 8.0, n = 65536, d = 105\n         10\u22124                                                                                                                                     10\u22124\n       Correlation Measure                                                        Correlation Measure                                           Correlation Measure                                    Correlation Measure\n         10\u22126                                                                       10\u22125                                                          10\u22126                                                    10\u22125\n                                                                                                                                                                                                          10\u22127\n         10\u22128                                                                       10\u22127                                                          10\u22128                                                    10\u22129\n        10\u221210                                                                       10\u22129                                                         10\u221210                                                   10\u221211\n        10\u221212                                                                      10\u221211                                                         10\u221212                                                   10\u221213\n                       22           24          26           28          210                      22           24          26     28  210                       22           24          26   28  210                   22          24           26   28  210\n                              Number of canaries K                                                       Number of canaries K                                         Number of canaries K                                    Number of canaries K\n                                                                                                                             1/K      |\u02c6\n                                                                                                                                       \u00b52      \u00b52|                  |\u02c6\n                                                                                                                                                                     \u00b52     \u00b54|\n                                                                                                                                          1 \u2212  \u02c6                       2 \u2212   \u02c6\nFigure 10: Effect of the number k of canaries on the moment estimates employed by the higher-order Wilson\nintervals in auditing LiDP.\n                                                                                                                                         36", "md": "# Math Equations and Table\n\n## Effect of the number k of canaries on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP.\n\n$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\text{Number of canaries } K & \\text{Number of canaries } K & \\text{Number of canaries } K & \\text{Number of canaries } K \\\\\n\\hline\n10^{-2} & \\epsilon = 1.0, n = 1024, d = 105 & \\epsilon = 1.0, n = 4096, d = 105 & \\epsilon = 1.0, n = 16384, d = 105 & \\epsilon = 1.0, n = 65536, d = 105 \\\\\n10^{-3} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} \\\\\n10^{-4} & & & & \\\\\n10^{-5} & & & & \\\\\n10^{-6} & & & & \\\\\n10^{-7} & & & & \\\\\n10^{-8} & & & & \\\\\n10^{-9} & & & & \\\\\n\\hline\n10^{-2} & \\epsilon = 2.0, n = 1024, d = 105 & \\epsilon = 2.0, n = 4096, d = 105 & \\epsilon = 2.0, n = 16384, d = 105 & \\epsilon = 2.0, n = 65536, d = 105 \\\\\n10^{-3} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} \\\\\n10^{-4} & & & & \\\\\n10^{-5} & & & & \\\\\n10^{-6} & & & & \\\\\n10^{-7} & & & & \\\\\n10^{-8} & & & & \\\\\n10^{-9} & & & & \\\\\n\\hline\n\\end{array}\n$$\nFigure 10: Effect of the number k of canaries on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Math Equations and Table", "md": "# Math Equations and Table"}, {"type": "heading", "lvl": 2, "value": "Effect of the number k of canaries on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP.", "md": "## Effect of the number k of canaries on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP."}, {"type": "text", "value": "$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\text{Number of canaries } K & \\text{Number of canaries } K & \\text{Number of canaries } K & \\text{Number of canaries } K \\\\\n\\hline\n10^{-2} & \\epsilon = 1.0, n = 1024, d = 105 & \\epsilon = 1.0, n = 4096, d = 105 & \\epsilon = 1.0, n = 16384, d = 105 & \\epsilon = 1.0, n = 65536, d = 105 \\\\\n10^{-3} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} \\\\\n10^{-4} & & & & \\\\\n10^{-5} & & & & \\\\\n10^{-6} & & & & \\\\\n10^{-7} & & & & \\\\\n10^{-8} & & & & \\\\\n10^{-9} & & & & \\\\\n\\hline\n10^{-2} & \\epsilon = 2.0, n = 1024, d = 105 & \\epsilon = 2.0, n = 4096, d = 105 & \\epsilon = 2.0, n = 16384, d = 105 & \\epsilon = 2.0, n = 65536, d = 105 \\\\\n10^{-3} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} \\\\\n10^{-4} & & & & \\\\\n10^{-5} & & & & \\\\\n10^{-6} & & & & \\\\\n10^{-7} & & & & \\\\\n10^{-8} & & & & \\\\\n10^{-9} & & & & \\\\\n\\hline\n\\end{array}\n$$\nFigure 10: Effect of the number k of canaries on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP.", "md": "$$\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n& \\text{Number of canaries } K & \\text{Number of canaries } K & \\text{Number of canaries } K & \\text{Number of canaries } K \\\\\n\\hline\n10^{-2} & \\epsilon = 1.0, n = 1024, d = 105 & \\epsilon = 1.0, n = 4096, d = 105 & \\epsilon = 1.0, n = 16384, d = 105 & \\epsilon = 1.0, n = 65536, d = 105 \\\\\n10^{-3} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} \\\\\n10^{-4} & & & & \\\\\n10^{-5} & & & & \\\\\n10^{-6} & & & & \\\\\n10^{-7} & & & & \\\\\n10^{-8} & & & & \\\\\n10^{-9} & & & & \\\\\n\\hline\n10^{-2} & \\epsilon = 2.0, n = 1024, d = 105 & \\epsilon = 2.0, n = 4096, d = 105 & \\epsilon = 2.0, n = 16384, d = 105 & \\epsilon = 2.0, n = 65536, d = 105 \\\\\n10^{-3} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} & \\text{Correlation Measure} \\\\\n10^{-4} & & & & \\\\\n10^{-5} & & & & \\\\\n10^{-6} & & & & \\\\\n10^{-7} & & & & \\\\\n10^{-8} & & & & \\\\\n10^{-9} & & & & \\\\\n\\hline\n\\end{array}\n$$\nFigure 10: Effect of the number k of canaries on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP."}]}, {"page": 37, "text": "        10\u22123         \u03b5 = 1.0, n = 1024, K = \u221an                                           \u03b5 = 1.0, n = 4096, K = \u221an                                \u03b5 = 1.0, n = 16384, K = \u221an                          \u03b5 = 1.0, n = 65536, K = \u221an\n        10\u22124                                                               10\u22124                                                      10\u22124                                                10\u22124\n      Moment statistics                                                   Moment statistics                                         Moment statistics                                   Moment statistics\n        10\u22125                                                               10\u22125                                                      10\u22125                                                10\u22125\n        10\u22126                                                               10\u22126                                                      10\u22126                                                10\u22126\n        10\u22127                                                               10\u22127                                                      10\u22127                                                10\u22127\n        10\u22128  102          103          104         105          106       10\u22128   102         103          104        105  106       10\u22128   102          103         104      105  106   10\u22128   102          103         104      105  106\n                                 Dimension d                                                        Dimension d                                               Dimension d                                          Dimension d\n        10\u22123         \u03b5 = 2.0, n = 1024, K = \u221an                             10\u22123          \u03b5 = 2.0, n = 4096, K = \u221an                   10\u22123         \u03b5 = 2.0, n = 16384, K = \u221an             10\u22123         \u03b5 = 2.0, n = 65536, K = \u221an\n        10\u22124                                                               10\u22124                                                      10\u22124                                                10\u22124\n      Moment statistics                                                   Moment statistics                                         Moment statistics                                   Moment statistics\n        10\u22125                                                               10\u22125                                                      10\u22125                                                10\u22125\n        10\u22126                                                               10\u22126                                                      10\u22126                                                10\u22126\n        10\u22127                                                               10\u22127                                                      10\u22127                                                10\u22127\n        10\u22128  102          103          104         105          106       10\u22128   102         103          104        105  106       10\u22128   102          103         104      105  106   10\u22128   102          103         104      105  106\n                                 Dimension d                                                        Dimension d                                               Dimension d                                          Dimension d\n        10\u22123         \u03b5 = 4.0, n = 1024, K = \u221an                             10\u22123          \u03b5 = 4.0, n = 4096, K = \u221an                   10\u22123         \u03b5 = 4.0, n = 16384, K = \u221an             10\u22123         \u03b5 = 4.0, n = 65536, K = \u221an\n        10\u22124                                                               10\u22124                                                      10\u22124                                                10\u22124\n      Moment statistics                                                   Moment statistics                                         Moment statistics                                   Moment statistics\n        10\u22125                                                               10\u22125                                                      10\u22125                                                10\u22125\n        10\u22126                                                               10\u22126                                                      10\u22126                                                10\u22126\n        10\u22127                                                               10\u22127                                                      10\u22127                                                10\u22127\n        10\u22128  102          103          104         105          106       10\u22128   102         103          104        105  106       10\u22128   102          103         104      105  106   10\u22128   102          103         104      105  106\n                                 Dimension d                                                        Dimension d                                               Dimension d                                          Dimension d\n        10\u22123         \u03b5 = 8.0, n = 1024, K = \u221an                             10\u22123          \u03b5 = 8.0, n = 4096, K = \u221an                   10\u22123         \u03b5 = 8.0, n = 16384, K = \u221an             10\u22123         \u03b5 = 8.0, n = 65536, K = \u221an\n                                                                           10\u22124                                                      10\u22124                                                10\u22124\n      Moment statistics                                                   Moment statistics                                         Moment statistics                                   Moment statistics\n        10\u22124\n        10\u22125                                                               10\u22125                                                      10\u22125                                                10\u22125\n        10\u22126                                                               10\u22126                                                      10\u22126                                                10\u22126\n        10\u22127                                                               10\u22127                                                      10\u22127                                                10\u22127\n        10\u22128  102          103          104         105          106       10\u22128   102         103          104        105  106       10\u22128   102          103         104      105  106   10\u22128   102          103         104      105  106\n                                 Dimension d                                                        Dimension d                                               Dimension d                                          Dimension d\n                                                                                                                 1/d       |\u02c6\n                                                                                                                            \u00b52     \u00b52|               |\u02c6\n                                                                                                                                                      \u00b52     \u00b54|\n                                                                                                                              1 \u2212  \u02c6                    2 \u2212   \u02c6\nFigure 11: Effect of the data dimension on the moment estimates employed by the higher-order Wilson\nintervals in auditing LiDP.\n                                                                                                                              37", "md": "| |$\\epsilon = 1.0, n = 1024, K = \\sqrt{n}$|$\\epsilon = 1.0, n = 4096, K = \\sqrt{n}$|$\\epsilon = 1.0, n = 16384, K = \\sqrt{n}$|$\\epsilon = 1.0, n = 65536, K = \\sqrt{n}$|\n|---|---|---|---|---|\n|$10^{-4}$|Moment statistics|Moment statistics|Moment statistics|Moment statistics|\n|$10^{-5}$| | | | |\n|$10^{-6}$| | | | |\n|$10^{-7}$| | | | |\n|$10^{-8}$|102|103|104|105|106|\n|Dimension d| | | | |\n| |$\\epsilon = 2.0, n = 1024, K = \\sqrt{n}$|$\\epsilon = 2.0, n = 4096, K = \\sqrt{n}$|$\\epsilon = 2.0, n = 16384, K = \\sqrt{n}$|$\\epsilon = 2.0, n = 65536, K = \\sqrt{n}$|\n|$10^{-4}$|Moment statistics|Moment statistics|Moment statistics|Moment statistics|\n|$10^{-5}$| | | | |\n|$10^{-6}$| | | | |\n|$10^{-7}$| | | | |\n|$10^{-8}$|102|103|104|105|106|\n|Dimension d| | | | |\n| |$\\epsilon = 4.0, n = 1024, K = \\sqrt{n}$|$\\epsilon = 4.0, n = 4096, K = \\sqrt{n}$|$\\epsilon = 4.0, n = 16384, K = \\sqrt{n}$|$\\epsilon = 4.0, n = 65536, K = \\sqrt{n}$|\n|$10^{-4}$|Moment statistics|Moment statistics|Moment statistics|Moment statistics|\n|$10^{-5}$| | | | |\n|$10^{-6}$| | | | |\n|$10^{-7}$| | | | |\n|$10^{-8}$|102|103|104|105|106|\n|Dimension d| | | | |\n| |$\\epsilon = 8.0, n = 1024, K = \\sqrt{n}$|$\\epsilon = 8.0, n = 4096, K = \\sqrt{n}$|$\\epsilon = 8.0, n = 16384, K = \\sqrt{n}$|$\\epsilon = 8.0, n = 65536, K = \\sqrt{n}$|\n|$10^{-4}$|Moment statistics|Moment statistics|Moment statistics|Moment statistics|\n|$10^{-5}$| | | | |\n|$10^{-6}$| | | | |\n|$10^{-7}$| | | | |\n|$10^{-8}$|102|103|104|105|106|\n|Dimension d| | | | |\n\n$$\\text{Figure 11: Effect of the data dimension on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP.}$$", "images": [], "items": [{"type": "table", "rows": [["", "$\\epsilon = 1.0, n = 1024, K = \\sqrt{n}$", "$\\epsilon = 1.0, n = 4096, K = \\sqrt{n}$", "$\\epsilon = 1.0, n = 16384, K = \\sqrt{n}$", "$\\epsilon = 1.0, n = 65536, K = \\sqrt{n}$"], ["$10^{-4}$", "Moment statistics", "Moment statistics", "Moment statistics", "Moment statistics"], ["$10^{-5}$", "", "", "", ""], ["$10^{-6}$", "", "", "", ""], ["$10^{-7}$", "", "", "", ""], ["$10^{-8}$", "102", "103", "104", "105", "106"], ["Dimension d", "", "", "", ""], ["", "$\\epsilon = 2.0, n = 1024, K = \\sqrt{n}$", "$\\epsilon = 2.0, n = 4096, K = \\sqrt{n}$", "$\\epsilon = 2.0, n = 16384, K = \\sqrt{n}$", "$\\epsilon = 2.0, n = 65536, K = \\sqrt{n}$"], ["$10^{-4}$", "Moment statistics", "Moment statistics", "Moment statistics", "Moment statistics"], ["$10^{-5}$", "", "", "", ""], ["$10^{-6}$", "", "", "", ""], ["$10^{-7}$", "", "", "", ""], ["$10^{-8}$", "102", "103", "104", "105", "106"], ["Dimension d", "", "", "", ""], ["", "$\\epsilon = 4.0, n = 1024, K = \\sqrt{n}$", "$\\epsilon = 4.0, n = 4096, K = \\sqrt{n}$", "$\\epsilon = 4.0, n = 16384, K = \\sqrt{n}$", "$\\epsilon = 4.0, n = 65536, K = \\sqrt{n}$"], ["$10^{-4}$", "Moment statistics", "Moment statistics", "Moment statistics", "Moment statistics"], ["$10^{-5}$", "", "", "", ""], ["$10^{-6}$", "", "", "", ""], ["$10^{-7}$", "", "", "", ""], ["$10^{-8}$", "102", "103", "104", "105", "106"], ["Dimension d", "", "", "", ""], ["", "$\\epsilon = 8.0, n = 1024, K = \\sqrt{n}$", "$\\epsilon = 8.0, n = 4096, K = \\sqrt{n}$", "$\\epsilon = 8.0, n = 16384, K = \\sqrt{n}$", "$\\epsilon = 8.0, n = 65536, K = \\sqrt{n}$"], ["$10^{-4}$", "Moment statistics", "Moment statistics", "Moment statistics", "Moment statistics"], ["$10^{-5}$", "", "", "", ""], ["$10^{-6}$", "", "", "", ""], ["$10^{-7}$", "", "", "", ""], ["$10^{-8}$", "102", "103", "104", "105", "106"], ["Dimension d", "", "", "", ""]], "md": "| |$\\epsilon = 1.0, n = 1024, K = \\sqrt{n}$|$\\epsilon = 1.0, n = 4096, K = \\sqrt{n}$|$\\epsilon = 1.0, n = 16384, K = \\sqrt{n}$|$\\epsilon = 1.0, n = 65536, K = \\sqrt{n}$|\n|---|---|---|---|---|\n|$10^{-4}$|Moment statistics|Moment statistics|Moment statistics|Moment statistics|\n|$10^{-5}$| | | | |\n|$10^{-6}$| | | | |\n|$10^{-7}$| | | | |\n|$10^{-8}$|102|103|104|105|106|\n|Dimension d| | | | |\n| |$\\epsilon = 2.0, n = 1024, K = \\sqrt{n}$|$\\epsilon = 2.0, n = 4096, K = \\sqrt{n}$|$\\epsilon = 2.0, n = 16384, K = \\sqrt{n}$|$\\epsilon = 2.0, n = 65536, K = \\sqrt{n}$|\n|$10^{-4}$|Moment statistics|Moment statistics|Moment statistics|Moment statistics|\n|$10^{-5}$| | | | |\n|$10^{-6}$| | | | |\n|$10^{-7}$| | | | |\n|$10^{-8}$|102|103|104|105|106|\n|Dimension d| | | | |\n| |$\\epsilon = 4.0, n = 1024, K = \\sqrt{n}$|$\\epsilon = 4.0, n = 4096, K = \\sqrt{n}$|$\\epsilon = 4.0, n = 16384, K = \\sqrt{n}$|$\\epsilon = 4.0, n = 65536, K = \\sqrt{n}$|\n|$10^{-4}$|Moment statistics|Moment statistics|Moment statistics|Moment statistics|\n|$10^{-5}$| | | | |\n|$10^{-6}$| | | | |\n|$10^{-7}$| | | | |\n|$10^{-8}$|102|103|104|105|106|\n|Dimension d| | | | |\n| |$\\epsilon = 8.0, n = 1024, K = \\sqrt{n}$|$\\epsilon = 8.0, n = 4096, K = \\sqrt{n}$|$\\epsilon = 8.0, n = 16384, K = \\sqrt{n}$|$\\epsilon = 8.0, n = 65536, K = \\sqrt{n}$|\n|$10^{-4}$|Moment statistics|Moment statistics|Moment statistics|Moment statistics|\n|$10^{-5}$| | | | |\n|$10^{-6}$| | | | |\n|$10^{-7}$| | | | |\n|$10^{-8}$|102|103|104|105|106|\n|Dimension d| | | | |", "isPerfectTable": false, "csv": "\"\",\"$\\epsilon = 1.0, n = 1024, K = \\sqrt{n}$\",\"$\\epsilon = 1.0, n = 4096, K = \\sqrt{n}$\",\"$\\epsilon = 1.0, n = 16384, K = \\sqrt{n}$\",\"$\\epsilon = 1.0, n = 65536, K = \\sqrt{n}$\"\n\"$10^{-4}$\",\"Moment statistics\",\"Moment statistics\",\"Moment statistics\",\"Moment statistics\"\n\"$10^{-5}$\",\"\",\"\",\"\",\"\"\n\"$10^{-6}$\",\"\",\"\",\"\",\"\"\n\"$10^{-7}$\",\"\",\"\",\"\",\"\"\n\"$10^{-8}$\",\"102\",\"103\",\"104\",\"105\",\"106\"\n\"Dimension d\",\"\",\"\",\"\",\"\"\n\"\",\"$\\epsilon = 2.0, n = 1024, K = \\sqrt{n}$\",\"$\\epsilon = 2.0, n = 4096, K = \\sqrt{n}$\",\"$\\epsilon = 2.0, n = 16384, K = \\sqrt{n}$\",\"$\\epsilon = 2.0, n = 65536, K = \\sqrt{n}$\"\n\"$10^{-4}$\",\"Moment statistics\",\"Moment statistics\",\"Moment statistics\",\"Moment statistics\"\n\"$10^{-5}$\",\"\",\"\",\"\",\"\"\n\"$10^{-6}$\",\"\",\"\",\"\",\"\"\n\"$10^{-7}$\",\"\",\"\",\"\",\"\"\n\"$10^{-8}$\",\"102\",\"103\",\"104\",\"105\",\"106\"\n\"Dimension d\",\"\",\"\",\"\",\"\"\n\"\",\"$\\epsilon = 4.0, n = 1024, K = \\sqrt{n}$\",\"$\\epsilon = 4.0, n = 4096, K = \\sqrt{n}$\",\"$\\epsilon = 4.0, n = 16384, K = \\sqrt{n}$\",\"$\\epsilon = 4.0, n = 65536, K = \\sqrt{n}$\"\n\"$10^{-4}$\",\"Moment statistics\",\"Moment statistics\",\"Moment statistics\",\"Moment statistics\"\n\"$10^{-5}$\",\"\",\"\",\"\",\"\"\n\"$10^{-6}$\",\"\",\"\",\"\",\"\"\n\"$10^{-7}$\",\"\",\"\",\"\",\"\"\n\"$10^{-8}$\",\"102\",\"103\",\"104\",\"105\",\"106\"\n\"Dimension d\",\"\",\"\",\"\",\"\"\n\"\",\"$\\epsilon = 8.0, n = 1024, K = \\sqrt{n}$\",\"$\\epsilon = 8.0, n = 4096, K = \\sqrt{n}$\",\"$\\epsilon = 8.0, n = 16384, K = \\sqrt{n}$\",\"$\\epsilon = 8.0, n = 65536, K = \\sqrt{n}$\"\n\"$10^{-4}$\",\"Moment statistics\",\"Moment statistics\",\"Moment statistics\",\"Moment statistics\"\n\"$10^{-5}$\",\"\",\"\",\"\",\"\"\n\"$10^{-6}$\",\"\",\"\",\"\",\"\"\n\"$10^{-7}$\",\"\",\"\",\"\",\"\"\n\"$10^{-8}$\",\"102\",\"103\",\"104\",\"105\",\"106\"\n\"Dimension d\",\"\",\"\",\"\",\"\""}, {"type": "text", "value": "$$\\text{Figure 11: Effect of the data dimension on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP.}$$", "md": "$$\\text{Figure 11: Effect of the data dimension on the moment estimates employed by the higher-order Wilson intervals in auditing LiDP.}$$"}]}, {"page": 38, "text": "                    FMNIST-Linear + Data Poisoning                          FMNIST-MLP + Data Poisoning                      Purchase-100-MLP + Data Poisoning\n              0.838                                                  0.850                                                 0.55\n              0.836                                                                                                        0.50\n             est Accuracy                                          est Accuracy                                           est Accuracy\n              0.834                                                  0.845                                                 0.45\n                                                                     0.840                                                 0.40\n              0.832                                                                                                        0.35\n             T0.830                                                T 0.835                                                T0.30\n              0.828                                                  0.830                                                 0.25\n                            21           23           25                          21           23            25            0.20         21           23         25\n                           Number of canaries K                                   Number of canaries K                                 Number of canaries K\n                  FMNIST-Linear + Random Gradient                         FMNIST-MLP + Random Gradient                     Purchase-100-MLP + Random Gradient\n              0.838                                                                                                        0.55\n              0.836                                                  0.850                                                 0.50\n             est Accuracy                                          est Accuracy                                           est Accuracy\n              0.834                                                  0.845                                                 0.45\n                                                                     0.840                                                 0.40\n              0.832                                                                                                        0.35\n             T0.830                                                T 0.835                                                T0.30\n              0.828                                                  0.830                                                 0.25\n                         21      23      25      27      29                     21      23     25      27      29          0.20       21        23        25      27\n                           Number of canaries K                                   Number of canaries K                                 Number of canaries K\n                                               = 1.0                  = 2.0                 = 4.0                  = 8.0                = 16.0\nFigure 12: Test accuracy versus the number of canaries K. We plot the mean over 1000 training runs (the standard\nerror in under 10\u22125). Adding multiple canaries to audit LiDP does not have any impact on the final test accuracy of\nthe model trained with DP.\n                                                                                            38", "md": "# Document\n\n|FMNIST-Linear + Data Poisoning|FMNIST-MLP + Data Poisoning|Purchase-100-MLP + Data Poisoning|\n|---|---|---|\n|0.838|0.850|0.55|\n|0.836| |0.50|\n|est Accuracy|est Accuracy|est Accuracy|\n|0.834|0.845|0.45|\n| |0.840|0.40|\n|0.832| |0.35|\n|T0.830|T 0.835|T0.30|\n|0.828|0.830|0.25|\n|21 23 25|21 23 25|21 23 25|\n|Number of canaries K|Number of canaries K|Number of canaries K|\n\n|FMNIST-Linear + Random Gradient|FMNIST-MLP + Random Gradient|Purchase-100-MLP + Random Gradient|\n|---|---|---|\n|0.838| |0.55|\n|0.836|0.850|0.50|\n|est Accuracy|est Accuracy|est Accuracy|\n|0.834|0.845|0.45|\n| |0.840|0.40|\n|0.832| |0.35|\n|T0.830|T 0.835|T0.30|\n|0.828|0.830|0.25|\n|21 23 25 27 29|21 23 25 27 29|21 23 25 27|\n|Number of canaries K|Number of canaries K|Number of canaries K|\n\n= 1.0 = 2.0 = 4.0 = 8.0 = 16.0\n\nFigure 12: Test accuracy versus the number of canaries K. We plot the mean over 1000 training runs (the standard error in under $$10^{-5}$$). Adding multiple canaries to audit LiDP does not have any impact on the final test accuracy of the model trained with DP.", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Document", "md": "# Document"}, {"type": "table", "rows": [["FMNIST-Linear + Data Poisoning", "FMNIST-MLP + Data Poisoning", "Purchase-100-MLP + Data Poisoning"], ["0.838", "0.850", "0.55"], ["0.836", "", "0.50"], ["est Accuracy", "est Accuracy", "est Accuracy"], ["0.834", "0.845", "0.45"], ["", "0.840", "0.40"], ["0.832", "", "0.35"], ["T0.830", "T 0.835", "T0.30"], ["0.828", "0.830", "0.25"], ["21 23 25", "21 23 25", "21 23 25"], ["Number of canaries K", "Number of canaries K", "Number of canaries K"]], "md": "|FMNIST-Linear + Data Poisoning|FMNIST-MLP + Data Poisoning|Purchase-100-MLP + Data Poisoning|\n|---|---|---|\n|0.838|0.850|0.55|\n|0.836| |0.50|\n|est Accuracy|est Accuracy|est Accuracy|\n|0.834|0.845|0.45|\n| |0.840|0.40|\n|0.832| |0.35|\n|T0.830|T 0.835|T0.30|\n|0.828|0.830|0.25|\n|21 23 25|21 23 25|21 23 25|\n|Number of canaries K|Number of canaries K|Number of canaries K|", "isPerfectTable": true, "csv": "\"FMNIST-Linear + Data Poisoning\",\"FMNIST-MLP + Data Poisoning\",\"Purchase-100-MLP + Data Poisoning\"\n\"0.838\",\"0.850\",\"0.55\"\n\"0.836\",\"\",\"0.50\"\n\"est Accuracy\",\"est Accuracy\",\"est Accuracy\"\n\"0.834\",\"0.845\",\"0.45\"\n\"\",\"0.840\",\"0.40\"\n\"0.832\",\"\",\"0.35\"\n\"T0.830\",\"T 0.835\",\"T0.30\"\n\"0.828\",\"0.830\",\"0.25\"\n\"21 23 25\",\"21 23 25\",\"21 23 25\"\n\"Number of canaries K\",\"Number of canaries K\",\"Number of canaries K\""}, {"type": "table", "rows": [["FMNIST-Linear + Random Gradient", "FMNIST-MLP + Random Gradient", "Purchase-100-MLP + Random Gradient"], ["0.838", "", "0.55"], ["0.836", "0.850", "0.50"], ["est Accuracy", "est Accuracy", "est Accuracy"], ["0.834", "0.845", "0.45"], ["", "0.840", "0.40"], ["0.832", "", "0.35"], ["T0.830", "T 0.835", "T0.30"], ["0.828", "0.830", "0.25"], ["21 23 25 27 29", "21 23 25 27 29", "21 23 25 27"], ["Number of canaries K", "Number of canaries K", "Number of canaries K"]], "md": "|FMNIST-Linear + Random Gradient|FMNIST-MLP + Random Gradient|Purchase-100-MLP + Random Gradient|\n|---|---|---|\n|0.838| |0.55|\n|0.836|0.850|0.50|\n|est Accuracy|est Accuracy|est Accuracy|\n|0.834|0.845|0.45|\n| |0.840|0.40|\n|0.832| |0.35|\n|T0.830|T 0.835|T0.30|\n|0.828|0.830|0.25|\n|21 23 25 27 29|21 23 25 27 29|21 23 25 27|\n|Number of canaries K|Number of canaries K|Number of canaries K|", "isPerfectTable": true, "csv": "\"FMNIST-Linear + Random Gradient\",\"FMNIST-MLP + Random Gradient\",\"Purchase-100-MLP + Random Gradient\"\n\"0.838\",\"\",\"0.55\"\n\"0.836\",\"0.850\",\"0.50\"\n\"est Accuracy\",\"est Accuracy\",\"est Accuracy\"\n\"0.834\",\"0.845\",\"0.45\"\n\"\",\"0.840\",\"0.40\"\n\"0.832\",\"\",\"0.35\"\n\"T0.830\",\"T 0.835\",\"T0.30\"\n\"0.828\",\"0.830\",\"0.25\"\n\"21 23 25 27 29\",\"21 23 25 27 29\",\"21 23 25 27\"\n\"Number of canaries K\",\"Number of canaries K\",\"Number of canaries K\""}, {"type": "text", "value": "= 1.0 = 2.0 = 4.0 = 8.0 = 16.0\n\nFigure 12: Test accuracy versus the number of canaries K. We plot the mean over 1000 training runs (the standard error in under $$10^{-5}$$). Adding multiple canaries to audit LiDP does not have any impact on the final test accuracy of the model trained with DP.", "md": "= 1.0 = 2.0 = 4.0 = 8.0 = 16.0\n\nFigure 12: Test accuracy versus the number of canaries K. We plot the mean over 1000 training runs (the standard error in under $$10^{-5}$$). Adding multiple canaries to audit LiDP does not have any impact on the final test accuracy of the model trained with DP."}]}, {"page": 39, "text": "                                                                                                                                      Linear Model on FMNIST with Data Poisoning Canary\n                                                                                         DP \u03b5 = 1.0                                                                                   DP \u03b5 = 2.0                                                                                DP \u03b5 = 4.0\n                                                  0.14\n                                                 Empirical lower bound \u02c6                                                                      Empirical lower bound \u02c6                                                                      Empirical lower bound \u02c6\n                                                 \u03b50.12                                                                                        \u03b5 0.25                                                                                       \u03b50.30\n                                                  0.10                                                                                          0.20                                                                                        0.25\n                                                  0.08                                                                                          0.15                                                                                        0.20\n                                                  0.06                                                                                                                                                                                      0.15\n                                                                                                                                                0.10\n                                                  0.04                                                                                                                                                                                      0.10\n                                                  0.02                                                                                          0.05                                                                                        0.05\n                                                  0.00                                                                                          0.00                                                                                        0.00\n                                                            27                       28                     29                       210                  27                       28                    29                      210                  27                    28                     29          210\n                                                                                   Number of trials n                                                                            Number of trials n                                                                       Number of trials n\n                                                                                         DP \u03b5 = 8.0                                              0.6                                 DP \u03b5 = 16.0                                                                               DP \u03b5 = 32.0\n                                                  Empirical lower bound \u02c6                                                                       Empirical lower bound \u02c6                                                                     Empirical lower bound \u02c6\n                                                  \u03b5 0.5                                                                                         \u03b50.5                                                                                        \u03b5\n                                                    0.4                                                                                          0.4                                                                                          0.6\n                                                    0.3                                                                                          0.3                                                                                          0.4\n                                                    0.2                                                                                          0.2\n                                                                                                                                                                                                                                              0.2\n                                                    0.1                                                                                          0.1\n                                                    0.0                                                                                          0.0                                                                                          0.0\n                                                            27                       28                     29                       210                  27                       28                    29                      210                  27                    28                     29          210\n                                                                                   Number of trials n                                                                            Number of trials n                                                                       Number of trials n\n                                                                                                                                   Linear Model on FMNIST with Random Gradient Canary\n                                                                                                                         DP + Wilson                             LiDP + 2nd-Order Wilson                                   LiDP + 4th-Order Wilson\n                                                  0.175                                   DP \u03b5 = 1.0                                             0.25                                  DP \u03b5 = 2.0                                            0.35                               DP \u03b5 = 4.0\n                                                 Empirical lower bound \u02c6                                                                       Empirical lower bound \u02c6                                                                     Empirical lower bound \u02c6\n                                                 \u03b50.150                                                                                        \u03b5 0.20                                                                                      \u03b5 0.30\n                                                  0.125                                                                                                                                                                                      0.25\n                                                  0.100                                                                                          0.15                                                                                        0.20\n                                                  0.075                                                                                          0.10                                                                                        0.15\n                                                  0.050                                                                                                                                                                                      0.10\n                                                                                                                                                 0.05\n                                                  0.025                                                                                                                                                                                      0.05\n                                                  0.000                                                                                          0.00                                                                                        0.00\n                                                             27                       28                     29                      210                  27                       28                    29                       210                  27                   28                     29          210\n                                                                                    Number of trials n                                                                           Number of trials n                                                                       Number of trials n\n                                                                                          DP \u03b5 = 8.0                                                                                  DP \u03b5 = 16.0                                                                              DP \u03b5 = 32.0\n                                                                                                                                                  0.6\n                                                   Empirical lower bound \u02c6                                                                      Empirical lower bound \u02c6                                                                      Empirical lower bound \u02c6\n                                                   \u03b5 0.4                                                                                        \u03b5                                                                                            \u03b50.5\n                                                                                                                                                  0.5\n                                                     0.3                                                                                          0.4                                                                                         0.4\n                                                                                                                                                  0.3                                                                                         0.3\n                                                     0.2\n                                                                                                                                                  0.2                                                                                         0.2\n                                                     0.1                                                                                          0.1                                                                                         0.1\n                                                     0.0                                                                                          0.0                                                                                         0.0\n                                                             27                       28                     29                      210                  27                       28                    29                       210                  27                   28                     29          210\n                                                                                    Number of trials n                                                                           Number of trials n                                                                       Number of trials n\n                                                                                                                                      Linear Model on FMNIST with Data Poisoning Canary\n                                                                                                                         DP + Wilson                             LiDP + 2nd-Order Wilson                                   LiDP + 4th-Order Wilson\n                                                                                          DP \u03b5 = 1                                                                                      DP \u03b5 = 2                                                                                 DP \u03b5 = 4\n                                                 Empirical lower bound \u02c6                                                                      Empirical lower bound \u02c6                                                                      Empirical lower bound \u02c6\n                                                 \u03b5                                                                                            \u03b5                                                                                            \u03b50.30\n                                                  0.15                                                                                          0.25                                                                                        0.25\n                                                                                                                                                0.20                                                                                        0.20\n                                                  0.10\n                                                                                                                                                                                                                                            0.15\n                                                  0.05                                                                                          0.15                                                                                        0.10\n                                                                                                                                                                                                                                            0.05\n                                                                                                                                                0.10\n                                                  0.00                                                                                                                                                                                      0.00\n                                                           20           21          22           23        24           25          26                   20          21           22          23        24          25           26                  20           21       22           23        24   25     26\n                                                                                Number of canaries K                                                                          Number of canaries K                                                                     Number of canaries K\n                                                  0.55                                    DP \u03b5 = 8                                                                                     DP \u03b5 = 16                                                                                DP \u03b5 = 32\n                                                                                                                                                                                                                                            0.75\n                                                 Empirical lower bound \u02c6                                                                        Empirical lower bound \u02c6                                                                    Empirical lower bound \u02c6\n                                                 \u03b50.50                                                                                          \u03b50.6                                                                                       \u03b5\n                                                                                                                                                                                                                                            0.70\n                                                  0.45\n                                                                                                                                                 0.5                                                                                        0.65\n                                                  0.40\n                                                                                                                                                 0.4                                                                                        0.60\n                                                  0.35                                                                                                                                                                                      0.55\n                                                  0.30                                                                                           0.3                                                                                        0.50\n                                                  0.25                                                                                           0.2                                                                                        0.45\n                                                           20           21          22           23        24           25          26                   20          21           22          23        24          25           26                  20           21       22           23        24   25     26\n                                                                                Number of canaries K                                                                          Number of canaries K                                                                     Number of canaries K\n                                                                                                                                   Linear Model on FMNIST with Random Gradient Canary\n                                                                            K = \u221an                          DP + Wilson                             LiDP + 1st-Order Wilson                                  LiDP + 2nd-Order Wilson                                  LiDP + 4th-Order Wilson\n                                                                                          DP \u03b5 = 1                                                                                      DP \u03b5 = 2                                                                                 DP \u03b5 = 4\n                                                                                                                                                0.25                                                                                        0.35\n                                                 Empirical lower bound \u02c6                                                                      Empirical lower bound \u02c6                                                                      Empirical lower bound \u02c6\n                                                 \u03b5                                                                                            \u03b5                                                                                            \u03b50.30\n                                                  0.15                                                                                          0.20                                                                                        0.25\n                                                                                                                                                                                                                                            0.20\n                                                  0.10                                                                                          0.15\n                                                                                                                                                                                                                                            0.15\n                                                  0.05                                                                                          0.10                                                                                        0.10\n                                                                                                                                                                                                                                            0.05\n                                                  0.00                                                                                          0.05                                                                                        0.00\n                                                                     21                23               25                 27                                     21                 23              25                27                                      21             23               25         27\n                                                                                Number of canaries K                                                                          Number of canaries K                                                                     Number of canaries K\n                                                                                          DP \u03b5 = 8                                                                                     DP \u03b5 = 16                                                                                DP \u03b5 = 32\n                                                    0.5                                                                                          0.6                                                                                          0.6\n                                                  Empirical lower bound \u02c6                                                                       Empirical lower bound \u02c6                                                                     Empirical lower bound \u02c6\n                                                  \u03b5                                                                                             \u03b5                                                                                           \u03b5\n                                                    0.4                                                                                          0.5                                                                                          0.5\n                                                    0.3                                                                                          0.4                                                                                          0.4\n                                                                                                                                                 0.3                                                                                          0.3\n                                                    0.2\n                                                                                                                                                 0.2                                                                                          0.2\n                                                    0.1                                                                                          0.1                                                                                          0.1\n                                                    0.0                                                                                          0.0                                                                                          0.0\n                                                                     21                23               25                 27                                     21                 23              25                27                                      21             23               25         27\n                                                                                Number of canaries K                                                                          Number of canaries K                                                                     Number of canaries K\n                                                                            K = \u221an                          DP + Wilson                             LiDP + 1st-Order Wilson                                  LiDP + 2nd-Order Wilson                                  LiDP + 4th-Order Wilson\nFigure 13: Experimental results for FMNIST linear model (top two: varying n, bottom two: varying K                                                                                                                                                                                                                  ).\n                                                                                                                                                                                      39", "md": "# Experimental Results\n\n## Linear Model on FMNIST with Data Poisoning Canary\n\n| |DP \u03b5 = 1.0|DP \u03b5 = 2.0|DP \u03b5 = 4.0|\n|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|\u03b5|0.12|0.25|0.30|\n|0.10| |0.20|0.25|\n|0.08| |0.15|0.20|\n|0.06| | |0.15|\n|0.04| |0.10|0.10|\n|0.02| |0.05|0.05|\n|0.00|0.00|0.00|0.00|\n|Number of trials n|27|28|29|210|27|28|29|210|27|28|29|210|\n\n## Linear Model on FMNIST with Random Gradient Canary\n\n| |DP \u03b5 = 1.0|DP \u03b5 = 2.0|DP \u03b5 = 4.0|\n|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|\u03b5|0.15|0.25|0.30|\n|0.125| | |0.25|\n|0.10|0.15| |0.20|\n|0.075|0.10| |0.15|\n|0.050| | |0.10|\n|0.025| | |0.05|\n|0.00|0.00|0.00| |\n|Number of trials n|27|28|29|210|27|28|29|210|27|28|29|210|\n\n## Linear Model on FMNIST with Data Poisoning Canary\n\n| |DP \u03b5 = 1|DP \u03b5 = 2|DP \u03b5 = 4|\n|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|\u03b5|0.15|0.25|0.30|\n|0.10|0.15|0.10| |\n|0.05|0.15|0.05| |\n|0.00|0.00|0.00| |\n|Number of canaries K|20|21|22|23|24|25|26|20|21|22|23|24|25|26|20|21|22|23|24|25|26|\n\n## Linear Model on FMNIST with Random Gradient Canary\n\n| |DP \u03b5 = 1|DP \u03b5 = 2|DP \u03b5 = 4|\n|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|\u03b5|0.15|0.20|0.25|\n|0.10|0.15|0.10| |\n|0.05| | |0.10|0.05|\n|0.00|0.05|0.00| |\n|Number of canaries K|21|23|25|27|21|23|25|27|21|23|25|27|\n\n## Experimental results for FMNIST linear model (top two: varying n, bottom two: varying K).\n\nFigure 13: Experimental results for FMNIST linear model (top two: varying n, bottom two: varying K).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Experimental Results", "md": "# Experimental Results"}, {"type": "heading", "lvl": 2, "value": "Linear Model on FMNIST with Data Poisoning Canary", "md": "## Linear Model on FMNIST with Data Poisoning Canary"}, {"type": "table", "rows": [["", "DP \u03b5 = 1.0", "DP \u03b5 = 2.0", "DP \u03b5 = 4.0"], ["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6"], ["\u03b5", "0.12", "0.25", "0.30"], ["0.10", "", "0.20", "0.25"], ["0.08", "", "0.15", "0.20"], ["0.06", "", "", "0.15"], ["0.04", "", "0.10", "0.10"], ["0.02", "", "0.05", "0.05"], ["0.00", "0.00", "0.00", "0.00"], ["Number of trials n", "27", "28", "29", "210", "27", "28", "29", "210", "27", "28", "29", "210"]], "md": "| |DP \u03b5 = 1.0|DP \u03b5 = 2.0|DP \u03b5 = 4.0|\n|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|\u03b5|0.12|0.25|0.30|\n|0.10| |0.20|0.25|\n|0.08| |0.15|0.20|\n|0.06| | |0.15|\n|0.04| |0.10|0.10|\n|0.02| |0.05|0.05|\n|0.00|0.00|0.00|0.00|\n|Number of trials n|27|28|29|210|27|28|29|210|27|28|29|210|", "isPerfectTable": false, "csv": "\"\",\"DP \u03b5 = 1.0\",\"DP \u03b5 = 2.0\",\"DP \u03b5 = 4.0\"\n\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\"\n\"\u03b5\",\"0.12\",\"0.25\",\"0.30\"\n\"0.10\",\"\",\"0.20\",\"0.25\"\n\"0.08\",\"\",\"0.15\",\"0.20\"\n\"0.06\",\"\",\"\",\"0.15\"\n\"0.04\",\"\",\"0.10\",\"0.10\"\n\"0.02\",\"\",\"0.05\",\"0.05\"\n\"0.00\",\"0.00\",\"0.00\",\"0.00\"\n\"Number of trials n\",\"27\",\"28\",\"29\",\"210\",\"27\",\"28\",\"29\",\"210\",\"27\",\"28\",\"29\",\"210\""}, {"type": "heading", "lvl": 2, "value": "Linear Model on FMNIST with Random Gradient Canary", "md": "## Linear Model on FMNIST with Random Gradient Canary"}, {"type": "table", "rows": [["", "DP \u03b5 = 1.0", "DP \u03b5 = 2.0", "DP \u03b5 = 4.0"], ["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6"], ["\u03b5", "0.15", "0.25", "0.30"], ["0.125", "", "", "0.25"], ["0.10", "0.15", "", "0.20"], ["0.075", "0.10", "", "0.15"], ["0.050", "", "", "0.10"], ["0.025", "", "", "0.05"], ["0.00", "0.00", "0.00", ""], ["Number of trials n", "27", "28", "29", "210", "27", "28", "29", "210", "27", "28", "29", "210"]], "md": "| |DP \u03b5 = 1.0|DP \u03b5 = 2.0|DP \u03b5 = 4.0|\n|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|\u03b5|0.15|0.25|0.30|\n|0.125| | |0.25|\n|0.10|0.15| |0.20|\n|0.075|0.10| |0.15|\n|0.050| | |0.10|\n|0.025| | |0.05|\n|0.00|0.00|0.00| |\n|Number of trials n|27|28|29|210|27|28|29|210|27|28|29|210|", "isPerfectTable": false, "csv": "\"\",\"DP \u03b5 = 1.0\",\"DP \u03b5 = 2.0\",\"DP \u03b5 = 4.0\"\n\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\"\n\"\u03b5\",\"0.15\",\"0.25\",\"0.30\"\n\"0.125\",\"\",\"\",\"0.25\"\n\"0.10\",\"0.15\",\"\",\"0.20\"\n\"0.075\",\"0.10\",\"\",\"0.15\"\n\"0.050\",\"\",\"\",\"0.10\"\n\"0.025\",\"\",\"\",\"0.05\"\n\"0.00\",\"0.00\",\"0.00\",\"\"\n\"Number of trials n\",\"27\",\"28\",\"29\",\"210\",\"27\",\"28\",\"29\",\"210\",\"27\",\"28\",\"29\",\"210\""}, {"type": "heading", "lvl": 2, "value": "Linear Model on FMNIST with Data Poisoning Canary", "md": "## Linear Model on FMNIST with Data Poisoning Canary"}, {"type": "table", "rows": [["", "DP \u03b5 = 1", "DP \u03b5 = 2", "DP \u03b5 = 4"], ["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6"], ["\u03b5", "0.15", "0.25", "0.30"], ["0.10", "0.15", "0.10", ""], ["0.05", "0.15", "0.05", ""], ["0.00", "0.00", "0.00", ""], ["Number of canaries K", "20", "21", "22", "23", "24", "25", "26", "20", "21", "22", "23", "24", "25", "26", "20", "21", "22", "23", "24", "25", "26"]], "md": "| |DP \u03b5 = 1|DP \u03b5 = 2|DP \u03b5 = 4|\n|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|\u03b5|0.15|0.25|0.30|\n|0.10|0.15|0.10| |\n|0.05|0.15|0.05| |\n|0.00|0.00|0.00| |\n|Number of canaries K|20|21|22|23|24|25|26|20|21|22|23|24|25|26|20|21|22|23|24|25|26|", "isPerfectTable": false, "csv": "\"\",\"DP \u03b5 = 1\",\"DP \u03b5 = 2\",\"DP \u03b5 = 4\"\n\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\"\n\"\u03b5\",\"0.15\",\"0.25\",\"0.30\"\n\"0.10\",\"0.15\",\"0.10\",\"\"\n\"0.05\",\"0.15\",\"0.05\",\"\"\n\"0.00\",\"0.00\",\"0.00\",\"\"\n\"Number of canaries K\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\""}, {"type": "heading", "lvl": 2, "value": "Linear Model on FMNIST with Random Gradient Canary", "md": "## Linear Model on FMNIST with Random Gradient Canary"}, {"type": "table", "rows": [["", "DP \u03b5 = 1", "DP \u03b5 = 2", "DP \u03b5 = 4"], ["Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6", "Empirical lower bound \u02c6"], ["\u03b5", "0.15", "0.20", "0.25"], ["0.10", "0.15", "0.10", ""], ["0.05", "", "", "0.10", "0.05"], ["0.00", "0.05", "0.00", ""], ["Number of canaries K", "21", "23", "25", "27", "21", "23", "25", "27", "21", "23", "25", "27"]], "md": "| |DP \u03b5 = 1|DP \u03b5 = 2|DP \u03b5 = 4|\n|---|---|---|---|\n|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|Empirical lower bound \u02c6|\n|\u03b5|0.15|0.20|0.25|\n|0.10|0.15|0.10| |\n|0.05| | |0.10|0.05|\n|0.00|0.05|0.00| |\n|Number of canaries K|21|23|25|27|21|23|25|27|21|23|25|27|", "isPerfectTable": false, "csv": "\"\",\"DP \u03b5 = 1\",\"DP \u03b5 = 2\",\"DP \u03b5 = 4\"\n\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\",\"Empirical lower bound \u02c6\"\n\"\u03b5\",\"0.15\",\"0.20\",\"0.25\"\n\"0.10\",\"0.15\",\"0.10\",\"\"\n\"0.05\",\"\",\"\",\"0.10\",\"0.05\"\n\"0.00\",\"0.05\",\"0.00\",\"\"\n\"Number of canaries K\",\"21\",\"23\",\"25\",\"27\",\"21\",\"23\",\"25\",\"27\",\"21\",\"23\",\"25\",\"27\""}, {"type": "heading", "lvl": 2, "value": "Experimental results for FMNIST linear model (top two: varying n, bottom two: varying K).", "md": "## Experimental results for FMNIST linear model (top two: varying n, bottom two: varying K)."}, {"type": "text", "value": "Figure 13: Experimental results for FMNIST linear model (top two: varying n, bottom two: varying K).", "md": "Figure 13: Experimental results for FMNIST linear model (top two: varying n, bottom two: varying K)."}]}, {"page": 40, "text": "                                                                                                                                  MLP Model on FMNIST with Data Poisoning Canary\n                                                                                        DP \u03b5 = 1.0                                                                               DP \u03b5 = 2.0                                                                             DP \u03b5 = 4.0\n                                                                                                                                           0.08\n                                                Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6\n                                                \u03b50.08                                                                                    \u03b5                                                                                         \u03b50.20\n                                                                                                                                           0.06\n                                                 0.06                                                                                                                                                                               0.15\n                                                                                                                                           0.04\n                                                 0.04                                                                                                                                                                               0.10\n                                                 0.02                                                                                      0.02                                                                                     0.05\n                                                 0.00                                                                                      0.00                                                                                     0.00\n                                                           27                       28                 29                       210                  27                       28                 29                      210                  27                    28                 29             210\n                                                                                  Number of trials n                                                                        Number of trials n                                                                    Number of trials n\n                                                 0.30                                   DP \u03b5 = 8.0                                                                              DP \u03b5 = 16.0                                           0.5                              DP \u03b5 = 32.0\n                                                Empirical lower bound \u02c6                                                                    Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6\n                                                \u03b5                                                                                          \u03b50.4                                                                                     \u03b5\n                                                 0.25                                                                                                                                                                                 0.4\n                                                 0.20                                                                                       0.3                                                                                       0.3\n                                                 0.15                                                                                       0.2                                                                                       0.2\n                                                 0.10\n                                                 0.05                                                                                       0.1                                                                                       0.1\n                                                 0.00                                                                                       0.0                                                                                       0.0\n                                                           27                       28                 29                       210                  27                       28                 29                      210                  27                    28                 29             210\n                                                                                  Number of trials n                                                                        Number of trials n                                                                    Number of trials n\n                                                                                                                               MLP Model on FMNIST with Random Gradient Canary\n                                                                                                                    DP + Wilson                             LiDP + 2nd-Order Wilson                                LiDP + 4th-Order Wilson\n                                                                                       DP \u03b5 = 1.0                                                                                DP \u03b5 = 2.0                                                                             DP \u03b5 = 4.0\n                                                                                                                                           0.20\n                                                                                                                                                                                                                                    0.175\n                                                Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6                                                                 Empirical lower bound \u02c6\n                                                \u03b50.06                                                                                     \u03b5                                                                                       \u03b5\n                                                 0.05                                                                                      0.15                                                                                     0.150\n                                                                                                                                                                                                                                    0.125\n                                                 0.04\n                                                 0.03                                                                                      0.10                                                                                     0.100\n                                                                                                                                                                                                                                    0.075\n                                                 0.02                                                                                      0.05                                                                                     0.050\n                                                 0.01                                                                                                                                                                               0.025\n                                                 0.00                                                                                      0.00                                                                                     0.000\n                                                           27                       28                29                       210                   27                       28                29                       210                   27                    28                29             210\n                                                                                  Number of trials n                                                                        Number of trials n                                                                     Number of trials n\n                                                   0.5                                 DP \u03b5 = 8.0                                            0.5                                DP \u03b5 = 16.0                                            0.6                             DP \u03b5 = 32.0\n                                                 Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6\n                                                 \u03b5                                                                                         \u03b5                                                                                         \u03b5\n                                                   0.4                                                                                       0.4                                                                                       0.5\n                                                   0.3                                                                                       0.3                                                                                       0.4\n                                                                                                                                                                                                                                       0.3\n                                                   0.2                                                                                       0.2\n                                                                                                                                                                                                                                       0.2\n                                                   0.1                                                                                       0.1                                                                                       0.1\n                                                   0.0                                                                                       0.0                                                                                       0.0\n                                                           27                       28                29                       210                   27                       28                29                       210                   27                    28                29             210\n                                                                                  Number of trials n                                                                        Number of trials n                                                                     Number of trials n\n                                                                                                                                  MLP Model on FMNIST with Data Poisoning Canary\n                                                                                                                    DP + Wilson                             LiDP + 2nd-Order Wilson                                LiDP + 4th-Order Wilson\n                                                                                         DP \u03b5 = 1                                                                                  DP \u03b5 = 2                                                                               DP \u03b5 = 4\n                                                                                                                                                                                                                                     0.25\n                                                Empirical lower bound \u02c6                                                                 Empirical lower bound \u02c6                                                                     Empirical lower bound \u02c6\n                                                \u03b50.08                                                                                   \u03b5 0.150                                                                                     \u03b5\n                                                                                                                                          0.125                                                                                      0.20\n                                                 0.06\n                                                                                                                                          0.100\n                                                 0.04                                                                                     0.075                                                                                      0.15\n                                                 0.02                                                                                     0.050                                                                                      0.10\n                                                                                                                                          0.025\n                                                 0.00                                                                                     0.000                                                                                      0.05\n                                                          20           21          22          23     24          25          26                    20           21          22          23     24          25          26                    20          21        22          23     24    25      26\n                                                                               Number of canaries K                                                                      Number of canaries K                                                                   Number of canaries K\n                                                                                         DP \u03b5 = 8                                                                                 DP \u03b5 = 16                                                                              DP \u03b5 = 32\n                                                                                                                                           0.45                                                                                      0.60\n                                                 Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6\n                                                 \u03b5                                                                                        \u03b5                                                                                         \u03b5\n                                                   0.3                                                                                     0.40                                                                                      0.55\n                                                                                                                                                                                                                                     0.50\n                                                   0.2                                                                                     0.35                                                                                      0.45\n                                                                                                                                           0.30                                                                                      0.40\n                                                   0.1\n                                                                                                                                           0.25                                                                                      0.35\n                                                   0.0                                                                                     0.20                                                                                      0.30\n                                                          20           21          22          23     24          25          26                    20           21          22          23     24          25          26                    20          21        22          23     24    25      26\n                                                                               Number of canaries K                                                                      Number of canaries K                                                                   Number of canaries K\n                                                                                                                               MLP Model on FMNIST with Random Gradient Canary\n                                                                           K = \u221an                      DP + Wilson                             LiDP + 1st-Order Wilson                               LiDP + 2nd-Order Wilson                                  LiDP + 4th-Order Wilson\n                                                                                         DP \u03b5 = 1                                                                                  DP \u03b5 = 2                                                                              DP \u03b5 = 4\n                                                Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6\n                                                \u03b50.08                                                                                    \u03b5 0.20                                                                                    \u03b50.20\n                                                 0.06                                                                                      0.15\n                                                                                                                                                                                                                                    0.15\n                                                 0.04                                                                                      0.10\n                                                                                                                                                                                                                                    0.10\n                                                 0.02                                                                                      0.05\n                                                                                                                                                                                                                                    0.05\n                                                 0.00                                                                                      0.00\n                                                                  21             23             25       27             29                                 21             23             25       27             29                                  21          23             25       27      29\n                                                                               Number of canaries K                                                                      Number of canaries K                                                                  Number of canaries K\n                                                                                         DP \u03b5 = 8                                                                                 DP \u03b5 = 16                                                                             DP \u03b5 = 32\n                                                                                                                                            0.5                                                                                     0.60\n                                                Empirical lower bound \u02c6                                                                    Empirical lower bound \u02c6                                                                 Empirical lower bound \u02c6\n                                                \u03b50.45                                                                                      \u03b5                                                                                       \u03b5\n                                                                                                                                            0.4                                                                                     0.55\n                                                 0.40                                                                                       0.3                                                                                     0.50\n                                                 0.35                                                                                                                                                                               0.45\n                                                                                                                                            0.2\n                                                 0.30                                                                                                                                                                               0.40\n                                                                                                                                            0.1\n                                                                                                                                                                                                                                    0.35\n                                                 0.25\n                                                                                                                                            0.0                                                                                     0.30\n                                                                  21             23             25       27             29                                 21             23             25       27             29                                  21          23             25       27      29\n                                                                               Number of canaries K                                                                      Number of canaries K                                                                  Number of canaries K\n                                                                           K = \u221an                      DP + Wilson                             LiDP + 1st-Order Wilson                               LiDP + 2nd-Order Wilson                                  LiDP + 4th-Order Wilson\nFigure 14: Experimental results for FMNIST MLP model (top two: varying n, bottom two: varying K                                                                                                                                                                                                            ).\n                                                                                                                                                                                 40", "md": "# Experimental Results for FMNIST MLP Model\n\n## MLP Model on FMNIST with Data Poisoning Canary\n\n|DP \u03b5 = 1.0|DP \u03b5 = 2.0|DP \u03b5 = 4.0|\n|---|---|---|\n|$ \\begin{array}{|c|c|c|c|c|} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.30 & 0.25 & 0.20 & 0.15 & 0.10 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $|$ \\begin{array}{|c|c|c|c|c|c|} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $|$ \\begin{array}{|c|c|c|c|c|c|} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.60 & 0.55 & 0.50 & 0.45 & 0.40 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $|\n\n## MLP Model on FMNIST with Random Gradient Canary\n\n|DP \u03b5 = 1.0|DP \u03b5 = 2.0|DP \u03b5 = 4.0|\n|---|---|---|\n|$ \\begin{array}{|c|c|c|c|c|} \\hline & 0.20 & 0.175 & 0.150 & 0.125 & 0.100 & 0.075 & 0.050 & 0.025 & 0.000 \\\\ \\hline 27 & 0.45 & 0.40 & 0.35 & 0.30 & 0.25 & 0.20 & 0.15 & 0.10 & 0.05 \\\\ 28 & & & & & & & & & \\\\ 29 & & & & & & & & & \\\\ 210 & & & & & & & & & \\\\ \\hline \\end{array} $|$ \\begin{array}{|c|c|c|c|c|} \\hline & 0.25 & 0.20 & 0.15 & 0.10 & 0.05 & 0.00 \\\\ \\hline 27 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1 & 0.0 \\\\ 28 & & & & & & \\\\ 29 & & & & & & \\\\ 210 & & & & & & \\\\ \\hline \\end{array} $|$ \\begin{array}{|c|c|c|c|c|} \\hline & 0.45 & 0.40 & 0.35 & 0.30 & 0.25 \\\\ \\hline 27 & 0.60 & 0.55 & 0.50 & 0.45 & 0.40 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $|\n\nFigure 14: Experimental results for FMNIST MLP model (top two: varying n, bottom two: varying K).", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "Experimental Results for FMNIST MLP Model", "md": "# Experimental Results for FMNIST MLP Model"}, {"type": "heading", "lvl": 2, "value": "MLP Model on FMNIST with Data Poisoning Canary", "md": "## MLP Model on FMNIST with Data Poisoning Canary"}, {"type": "table", "rows": [["DP \u03b5 = 1.0", "DP \u03b5 = 2.0", "DP \u03b5 = 4.0"], ["$ \\begin{array}{", "c", "c", "c", "c", "c", "} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.30 & 0.25 & 0.20 & 0.15 & 0.10 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $", "$ \\begin{array}{", "c", "c", "c", "c", "c", "c", "} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $", "$ \\begin{array}{", "c", "c", "c", "c", "c", "c", "} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.60 & 0.55 & 0.50 & 0.45 & 0.40 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $"]], "md": "|DP \u03b5 = 1.0|DP \u03b5 = 2.0|DP \u03b5 = 4.0|\n|---|---|---|\n|$ \\begin{array}{|c|c|c|c|c|} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.30 & 0.25 & 0.20 & 0.15 & 0.10 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $|$ \\begin{array}{|c|c|c|c|c|c|} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $|$ \\begin{array}{|c|c|c|c|c|c|} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.60 & 0.55 & 0.50 & 0.45 & 0.40 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $|", "isPerfectTable": false, "csv": "\"DP \u03b5 = 1.0\",\"DP \u03b5 = 2.0\",\"DP \u03b5 = 4.0\"\n\"$ \\begin{array}{\",\"c\",\"c\",\"c\",\"c\",\"c\",\"} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.30 & 0.25 & 0.20 & 0.15 & 0.10 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $\",\"$ \\begin{array}{\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $\",\"$ \\begin{array}{\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"} \\hline & 0.08 & 0.06 & 0.04 & 0.02 & 0.00 \\\\ \\hline 27 & 0.60 & 0.55 & 0.50 & 0.45 & 0.40 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $\""}, {"type": "heading", "lvl": 2, "value": "MLP Model on FMNIST with Random Gradient Canary", "md": "## MLP Model on FMNIST with Random Gradient Canary"}, {"type": "table", "rows": [["DP \u03b5 = 1.0", "DP \u03b5 = 2.0", "DP \u03b5 = 4.0"], ["$ \\begin{array}{", "c", "c", "c", "c", "c", "} \\hline & 0.20 & 0.175 & 0.150 & 0.125 & 0.100 & 0.075 & 0.050 & 0.025 & 0.000 \\\\ \\hline 27 & 0.45 & 0.40 & 0.35 & 0.30 & 0.25 & 0.20 & 0.15 & 0.10 & 0.05 \\\\ 28 & & & & & & & & & \\\\ 29 & & & & & & & & & \\\\ 210 & & & & & & & & & \\\\ \\hline \\end{array} $", "$ \\begin{array}{", "c", "c", "c", "c", "c", "} \\hline & 0.25 & 0.20 & 0.15 & 0.10 & 0.05 & 0.00 \\\\ \\hline 27 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1 & 0.0 \\\\ 28 & & & & & & \\\\ 29 & & & & & & \\\\ 210 & & & & & & \\\\ \\hline \\end{array} $", "$ \\begin{array}{", "c", "c", "c", "c", "c", "} \\hline & 0.45 & 0.40 & 0.35 & 0.30 & 0.25 \\\\ \\hline 27 & 0.60 & 0.55 & 0.50 & 0.45 & 0.40 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $"]], "md": "|DP \u03b5 = 1.0|DP \u03b5 = 2.0|DP \u03b5 = 4.0|\n|---|---|---|\n|$ \\begin{array}{|c|c|c|c|c|} \\hline & 0.20 & 0.175 & 0.150 & 0.125 & 0.100 & 0.075 & 0.050 & 0.025 & 0.000 \\\\ \\hline 27 & 0.45 & 0.40 & 0.35 & 0.30 & 0.25 & 0.20 & 0.15 & 0.10 & 0.05 \\\\ 28 & & & & & & & & & \\\\ 29 & & & & & & & & & \\\\ 210 & & & & & & & & & \\\\ \\hline \\end{array} $|$ \\begin{array}{|c|c|c|c|c|} \\hline & 0.25 & 0.20 & 0.15 & 0.10 & 0.05 & 0.00 \\\\ \\hline 27 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1 & 0.0 \\\\ 28 & & & & & & \\\\ 29 & & & & & & \\\\ 210 & & & & & & \\\\ \\hline \\end{array} $|$ \\begin{array}{|c|c|c|c|c|} \\hline & 0.45 & 0.40 & 0.35 & 0.30 & 0.25 \\\\ \\hline 27 & 0.60 & 0.55 & 0.50 & 0.45 & 0.40 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $|", "isPerfectTable": false, "csv": "\"DP \u03b5 = 1.0\",\"DP \u03b5 = 2.0\",\"DP \u03b5 = 4.0\"\n\"$ \\begin{array}{\",\"c\",\"c\",\"c\",\"c\",\"c\",\"} \\hline & 0.20 & 0.175 & 0.150 & 0.125 & 0.100 & 0.075 & 0.050 & 0.025 & 0.000 \\\\ \\hline 27 & 0.45 & 0.40 & 0.35 & 0.30 & 0.25 & 0.20 & 0.15 & 0.10 & 0.05 \\\\ 28 & & & & & & & & & \\\\ 29 & & & & & & & & & \\\\ 210 & & & & & & & & & \\\\ \\hline \\end{array} $\",\"$ \\begin{array}{\",\"c\",\"c\",\"c\",\"c\",\"c\",\"} \\hline & 0.25 & 0.20 & 0.15 & 0.10 & 0.05 & 0.00 \\\\ \\hline 27 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1 & 0.0 \\\\ 28 & & & & & & \\\\ 29 & & & & & & \\\\ 210 & & & & & & \\\\ \\hline \\end{array} $\",\"$ \\begin{array}{\",\"c\",\"c\",\"c\",\"c\",\"c\",\"} \\hline & 0.45 & 0.40 & 0.35 & 0.30 & 0.25 \\\\ \\hline 27 & 0.60 & 0.55 & 0.50 & 0.45 & 0.40 \\\\ 28 & & & & & \\\\ 29 & & & & & \\\\ 210 & & & & & \\\\ \\hline \\end{array} $\""}, {"type": "text", "value": "Figure 14: Experimental results for FMNIST MLP model (top two: varying n, bottom two: varying K).", "md": "Figure 14: Experimental results for FMNIST MLP model (top two: varying n, bottom two: varying K)."}]}, {"page": 41, "text": "                                                                                                                                    MLP Model on Purchase-100 with Data Poisoning Canary\n                                                                                               DP \u03b5 = 1.0                                                                               DP \u03b5 = 2.0                                                                             DP \u03b5 = 4.0\n                                                                                                                                                  0.25\n                                                                                                                                                                                                                                             0.4\n                                                       Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6                                                                    Empirical lower bound \u02c6\n                                                       \u03b5                                                                                        \u03b5                                                                                          \u03b5\n                                                        0.06                                                                                      0.20\n                                                                                                                                                                                                                                             0.3\n                                                                                                                                                  0.15\n                                                        0.04\n                                                                                                                                                                                                                                             0.2\n                                                                                                                                                  0.10\n                                                        0.02                                                                                      0.05                                                                                       0.1\n                                                        0.00                                                                                      0.00                                                                                       0.0\n                                                                  27                       28                 29                       210                  27                       28                 29                      210                  27                    28                  29       210\n                                                                                         Number of trials n                                                                        Number of trials n                                                                    Number of trials n\n                                                                                               DP \u03b5 = 8.0                                                                              DP \u03b5 = 16.0                                                                            DP \u03b5 = 32.0\n                                                                                                                                                                                                                                             1.2\n                                                        Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6\n                                                        \u03b5 0.6                                                                                     \u03b50.8                                                                                     \u03b5 1.0\n                                                          0.5\n                                                                                                                                                   0.6                                                                                       0.8\n                                                          0.4\n                                                                                                                                                                                                                                             0.6\n                                                          0.3                                                                                      0.4\n                                                          0.2                                                                                                                                                                                0.4\n                                                                                                                                                   0.2\n                                                          0.1                                                                                                                                                                                0.2\n                                                          0.0                                                                                      0.0                                                                                       0.0\n                                                                  27                       28                 29                       210                  27                       28                 29                      210                  27                    28                  29       210\n                                                                                         Number of trials n                                                                        Number of trials n                                                                    Number of trials n\n                                                                                                                                  MLP Model on Purchase-100 with Random Gradient Canary\n                                                                                                                           DP + Wilson                             LiDP + 2nd-Order Wilson                                LiDP + 4th-Order Wilson\n                                                                                               DP \u03b5 = 1.0                                                                               DP \u03b5 = 2.0                                                                             DP \u03b5 = 4.0\n                                                       Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6                                                                    Empirical lower bound \u02c6\n                                                       \u03b50.12                                                                                    \u03b5 0.25                                                                                     \u03b5 1.0\n                                                        0.10                                                                                      0.20                                                                                       0.8\n                                                        0.08\n                                                                                                                                                  0.15                                                                                       0.6\n                                                        0.06\n                                                        0.04                                                                                      0.10                                                                                       0.4\n                                                        0.02                                                                                      0.05                                                                                       0.2\n                                                        0.00                                                                                      0.00                                                                                       0.0\n                                                                  27                       28                 29                       210                  27                       28                 29                      210                  27                    28                  29       210\n                                                                                         Number of trials n                                                                        Number of trials n                                                                    Number of trials n\n                                                          1.0                                  DP \u03b5 = 8.0                                          1.2                                 DP \u03b5 = 16.0                                                                            DP \u03b5 = 32.0\n                                                                                                                                                                                                                                           1.75\n                                                        Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6                                                                 Empirical lower bound \u02c6\n                                                        \u03b5 0.8                                                                                     \u03b51.0                                                                                    \u03b51.50\n                                                                                                                                                   0.8                                                                                     1.25\n                                                          0.6\n                                                                                                                                                   0.6                                                                                     1.00\n                                                          0.4                                                                                                                                                                              0.75\n                                                                                                                                                   0.4\n                                                                                                                                                                                                                                           0.50\n                                                          0.2                                                                                      0.2                                                                                     0.25\n                                                          0.0                                                                                      0.0                                                                                     0.00\n                                                                  27                       28                 29                       210                  27                       28                 29                      210                  27                    28                  29       210\n                                                                                         Number of trials n                                                                        Number of trials n                                                                    Number of trials n\n                                                                                                                                    MLP Model on Purchase-100 with Data Poisoning Canary\n                                                                                                                           DP + Wilson                             LiDP + 2nd-Order Wilson                                LiDP + 4th-Order Wilson\n                                                                                                DP \u03b5 = 1                                                                                  DP \u03b5 = 2                                                                              DP \u03b5 = 4\n                                                                                                                                                  0.25                                                                                     0.55\n                                                       Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6\n                                                       \u03b5                                                                                        \u03b5                                                                                         \u03b5\n                                                        0.06                                                                                      0.20                                                                                     0.50\n                                                                                                                                                  0.15                                                                                     0.45\n                                                        0.04\n                                                                                                                                                                                                                                           0.40\n                                                                                                                                                  0.10\n                                                        0.02                                                                                                                                                                               0.35\n                                                                                                                                                  0.05\n                                                                                                                                                                                                                                           0.30\n                                                        0.00                                                                                      0.00\n                                                                 20           21          22           23    24           25          26                   20          21           22          23     24          25           26                  20           21       22           23     24   25  26\n                                                                                      Number of canaries K                                                                      Number of canaries K                                                                  Number of canaries K\n                                                                                                DP \u03b5 = 8                                                                                 DP \u03b5 = 16                                                                             DP \u03b5 = 32\n                                                       Empirical lower bound \u02c6                                                                    Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6\n                                                       \u03b50.65                                                                                      \u03b50.8                                                                                     \u03b5 1.2\n                                                        0.60                                                                                       0.6                                                                                       1.1\n                                                        0.55                                                                                                                                                                                 1.0\n                                                                                                                                                   0.4\n                                                                                                                                                                                                                                             0.9\n                                                        0.50\n                                                                                                                                                   0.2                                                                                       0.8\n                                                        0.45\n                                                                                                                                                   0.0                                                                                       0.7\n                                                                 20           21          22           23    24           25          26                   20          21           22          23     24          25           26                  20           21       22           23     24   25  26\n                                                                                      Number of canaries K                                                                      Number of canaries K                                                                  Number of canaries K\n                                                                                                                                  MLP Model on Purchase-100 with Random Gradient Canary\n                                                                                  K = \u221an                      DP + Wilson                             LiDP + 1st-Order Wilson                               LiDP + 2nd-Order Wilson                                  LiDP + 4th-Order Wilson\n                                                                                                DP \u03b5 = 1                                                                                  DP \u03b5 = 2                                                                              DP \u03b5 = 4\n                                                                                                                                                  0.45\n                                                       Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6\n                                                       \u03b5                                                                                        \u03b5                                                                                         \u03b50.85\n                                                        0.15                                                                                      0.40\n                                                                                                                                                                                                                                           0.80\n                                                                                                                                                  0.35\n                                                                                                                                                                                                                                           0.75\n                                                        0.10\n                                                                                                                                                  0.30                                                                                     0.70\n                                                        0.05                                                                                      0.25                                                                                     0.65\n                                                                                                                                                  0.20                                                                                     0.60\n                                                        0.00                                                                                                                                                                               0.55\n                                                                 20           21          22           23    24           25          26                   20          21           22          23     24          25           26                  20           21       22           23     24   25  26\n                                                                                      Number of canaries K                                                                      Number of canaries K                                                                  Number of canaries K\n                                                                                                DP \u03b5 = 8                                                                                 DP \u03b5 = 16                                                                             DP \u03b5 = 32\n                                                                                                                                                   1.2\n                                                        Empirical lower bound \u02c6                                                                   Empirical lower bound \u02c6                                                                  Empirical lower bound \u02c6\n                                                        \u03b5 1.0                                                                                     \u03b5                                                                                        \u03b5 1.9\n                                                                                                                                                   1.0                                                                                       1.8\n                                                          0.8\n                                                                                                                                                   0.8                                                                                       1.7\n                                                          0.6\n                                                                                                                                                                                                                                             1.6\n                                                                                                                                                   0.6\n                                                          0.4                                                                                                                                                                                1.5\n                                                                                                                                                   0.4\n                                                          0.2                                                                                                                                                                                1.4\n                                                                 20           21          22           23    24           25          26                   20          21           22          23     24          25           26                  20           21       22           23     24   25  26\n                                                                                      Number of canaries K                                                                      Number of canaries K                                                                  Number of canaries K\n                                                                                  K = \u221an                      DP + Wilson                             LiDP + 1st-Order Wilson                               LiDP + 2nd-Order Wilson                                  LiDP + 4th-Order Wilson\nFigure 15: Experimental results for Purchase-100 MLP model (top two: varying n, bottom two: varying K                                                                                                                                                                                                        ).\n                                                                                                                                                                                        41", "md": "# MLP Model on Purchase-100 with Data Poisoning Canary\n\n## DP \u03b5 = 1.0\n\n|Empirical lower bound \u02c6|\u03b5|\n|---|---|\n|0.06|0.20|\n|0.04|0.15|\n|0.02|0.10|\n|0.00|0.00|\n\n## DP \u03b5 = 2.0\n\n|Empirical lower bound \u02c6|\u03b5|\n|---|---|\n|0.25|0.40|\n|0.20|0.30|\n|0.05|0.20|\n|0.00|0.00|\n\n## DP \u03b5 = 4.0\n\n|Empirical lower bound \u02c6|\u03b5|\n|---|---|\n|0.15|0.20|\n|0.10|0.10|\n|0.05|0.00|", "images": [], "items": [{"type": "heading", "lvl": 1, "value": "MLP Model on Purchase-100 with Data Poisoning Canary", "md": "# MLP Model on Purchase-100 with Data Poisoning Canary"}, {"type": "heading", "lvl": 2, "value": "DP \u03b5 = 1.0", "md": "## DP \u03b5 = 1.0"}, {"type": "table", "rows": [["Empirical lower bound \u02c6", "\u03b5"], ["0.06", "0.20"], ["0.04", "0.15"], ["0.02", "0.10"], ["0.00", "0.00"]], "md": "|Empirical lower bound \u02c6|\u03b5|\n|---|---|\n|0.06|0.20|\n|0.04|0.15|\n|0.02|0.10|\n|0.00|0.00|", "isPerfectTable": true, "csv": "\"Empirical lower bound \u02c6\",\"\u03b5\"\n\"0.06\",\"0.20\"\n\"0.04\",\"0.15\"\n\"0.02\",\"0.10\"\n\"0.00\",\"0.00\""}, {"type": "heading", "lvl": 2, "value": "DP \u03b5 = 2.0", "md": "## DP \u03b5 = 2.0"}, {"type": "table", "rows": [["Empirical lower bound \u02c6", "\u03b5"], ["0.25", "0.40"], ["0.20", "0.30"], ["0.05", "0.20"], ["0.00", "0.00"]], "md": "|Empirical lower bound \u02c6|\u03b5|\n|---|---|\n|0.25|0.40|\n|0.20|0.30|\n|0.05|0.20|\n|0.00|0.00|", "isPerfectTable": true, "csv": "\"Empirical lower bound \u02c6\",\"\u03b5\"\n\"0.25\",\"0.40\"\n\"0.20\",\"0.30\"\n\"0.05\",\"0.20\"\n\"0.00\",\"0.00\""}, {"type": "heading", "lvl": 2, "value": "DP \u03b5 = 4.0", "md": "## DP \u03b5 = 4.0"}, {"type": "table", "rows": [["Empirical lower bound \u02c6", "\u03b5"], ["0.15", "0.20"], ["0.10", "0.10"], ["0.05", "0.00"]], "md": "|Empirical lower bound \u02c6|\u03b5|\n|---|---|\n|0.15|0.20|\n|0.10|0.10|\n|0.05|0.00|", "isPerfectTable": true, "csv": "\"Empirical lower bound \u02c6\",\"\u03b5\"\n\"0.15\",\"0.20\"\n\"0.10\",\"0.10\"\n\"0.05\",\"0.00\""}]}], "job_id": "34a1c46a-1f9c-4855-8ce9-06c3c6d94c84", "file_path": "./corpus/2305.18447.pdf"}