question,contexts,ground_truth,evolution_type,metadata,episode_done
What does the assumption of single-policy concentrability for \(\pi^*_\alpha\) entail in the context of reinforcement learning or decision-making models?,"["" in (2). The following single-policy concentrability assumption assumes that \\(\\pi^*_\\alpha\\) is well covered by the offline dataset.\n\nAssumption 1 (Single-policy concentrability for \\(\\pi^*_\\alpha\\)). Let \\(d^*_\\alpha\\) be the optimal solution of (5), and let \\(\\pi^*_\\alpha = \\pi d^*_\\alpha\\) as defined in (2). We assume \\(C_{\\pi^*_\\alpha} \\leq C^*_\\alpha\\) where \\(C_{\\pi^*_\\alpha}\\) is defined in Definition 1 and \\(C^*_\\alpha > 0\\) is a constant.\n\nUnder Assumption 1, it can be observed that the performance difference between the regularized optimal policy \\(\\pi^*_\\alpha\\) and the optimal policy \\(\\pi^*\\) is bounded by \\(O(\\alpha)\\). The following proposition formally presents this observation.\n\nProposition 3.1. Let \\(d^*_\\alpha\\) be the optimal solution of (5), and let \\(\\pi^*_\\alpha = \\pi d^*_\\alpha\\) as defined in (2). Then under Assumption 1, it holds that \\(J(\\pi^*) - J(\\pi^*_\\alpha) \\leq O(\\alpha(C^*_\\alpha)^2)\\).\n\nThe proof of Proposition 3.1 is deferred to Appendix A.1. Proposition 3.1 shows that by solving the regularized program (5), we can obtain a near-optimal policy as long as \\(\\alpha\\) is small. The algorithm of Ma et al. [2022c] also aims to solve (5) and they simply choose \\(\\alpha = 1\\). We show empirically in Section 5 that \\(\\alpha < 1\\) achieves better performance than \\(\\alpha = 1\\). In theory, we must carefully choose the value of \\(\\alpha\\) s.t. the suboptimality of our learned policy vanishes to 0 with a reasonable rate. Finally, as in Ma et al. [2022c], we convert (5) to the dual form, which is an unconstrained problem and amenable to solve:\n\nProposition 3.2 (Dual form of (5)). The duality form of (5) is\n\n$$\n\\begin{aligned}\n& \\min_{V(s;g) \\geq 0} \\left[(1 - \\gamma) \\mathbb{E}(s,g) \\sim (\\rho, p(g))[V(s; g)] + \\mathbb{E}(s,a,g) \\sim \\mu[1\\{g'\\} \\geq 0}\\right].\n\\end{aligned} \\tag{6}\n$$\n\n# Document\n\nwhere $$g^*$$ is the convex conjugate of $$g = \\alpha \\cdot f$$. Moreover, let $$V^*_{\\alpha}$$ denote the optimal solution of (6), then it holds\n\n$$\\alpha(s, a; g) = \\mu(s, a; g)g'^* (r(s; g) + \\gamma T V^*_{\\alpha}(s, a; g) - V^*_{\\alpha}$$ for all $$(s, a, g) \\in S \\times A \\times G$$.\n\nThe proof of Proposition 3.2 is shown in Appendix A.2. According to the above proposition, one can first learn the $$V$$ function according to (6), and then use the learned $$V$$ function to learn the desired policy by (7). We call the first step $$V$$-learning and the second step policy learning, which will be discussed in detail in Sections 3.1 and 3.2 respectively. Finally, the main algorithm, which we call VP-learning, is presented in Algorithm 1.\n\nAlgorithm 1 VP-learning\n\n1. Input: Dataset $D = \\{(s_i, a_i, r_i, s'_i, g_i)\\}_{N i=1}$, $D_0 = \\{(s_{0,i}, g_{0,i})\\}_{N_0 i=1}$, value function class $V$, policy class $\\Pi$, model class $P$ for stochastic settings.\n2. Obtain $\\hat{U}$ by $V$-Learning (Algorithm 2 or 3).\n3. Obtain $\\hat{\\pi}$ by policy learning (Algorithm 4) using learned function $\\hat{U}$.\n4. Output: $\\hat{\\pi}$.\n\n### 3.1 $$""]",The assumption of single-policy concentrability for (pi*_alpha) entails that the performance difference between the regularized optimal policy (pi*_alpha) and the optimal policy (pi*) is bounded by O(alpha). This assumption allows for obtaining a near-optimal policy as long as alpha is small.,simple,[{'filename': '2302.03770.pdf'}],True
How does the performance of GSL algorithms change when random feature noise is injected into the graph structures of Cora and Citeseer?,"['.\n\nRobustness analysis with respect to random noise. We randomly remove edges from or add edges to the original graph structures of Cora and Citeseer, then evaluated the performance of GSL algorithms on the corrupted graphs. We change the ratios of modified edges from 0 to 0.9 to simulate different attack intensities. As shown in Figure 3, as the noise intensity increases, the modelsâ€™ performance generally exhibits a downward trend. And we can observe that GSL algorithms commonly demonstrate a certain degree of robustness, as they tend to exhibit more stable performance than GCN when random noise is injected. Besides, we also found that, due to variations in the graph modeling process, different algorithms display varying levels of robustness when facing edge deletion and edge addition scenarios. For example, GRCN demonstrates strong robustness in edge deletion scenarios. However, in the edge addition scenarios, it only exhibits slight performance improvements compared to GCN. On the contrary, STABLE exhibits strong robustness in the edge deletion scenario, while showing the opposite trend in edge addition.\n\nRobust analysis with respect to graph topology attack. Following [21, 55], we conduct robust analysis on three graph datasets, i.e., Cora, Citeseer, and Polblogs. First, we select the largest connected component in the graph, and utilize Mettack [58], a non-targeted adversarial topology attack method, to generate perturbed graphs. We select the perturbation rate from 0% to 20%. Table 6 shows the performance of GSL algorithms on three datasets with respect to various perturbation rates. Surprisingly, we can observe that most GSL algorithms exhibit strong robustness against graph topology attacks, even better than state-of-the-art defense GNNs (e.g., Jaccard [41] and SimPGCN [19]). GSL can effectively remove the newly added adversarial edges, and recover important edges to promote message passing. As mentioned in Li et al. [21], optimizing graph structures based on either features or supervised signals might not be reliable. We found that self-supervised graph structure modeling methods (e.g., STABLE and SUBLIME) show excellent\n\n# Graph Structure Learning\n\n## Performance Analysis\n\n| |GCN|GRCN|IDGL|ProGNN|SUBLIME|MLP|SLAPS|HES-GSL|\n|---|---|---|---|---|---|---|---|---|\n|TR on Cora|85| | | | | | | |\n|TR on Citeseer| |75| | | | | | |\n|TI on Cora|75| | | | | | | |\n|TI on Citeseer| | | | | | | |70|\n\nAccuracy (%)\n\n$$\n\\begin{array}{|c|c|c|c|c|c|c|c|c|}\n\\hline\n80 & & & & & & & & \\\\\n\\hline\n75 & & & & & & & & \\\\\n\\hline\n70 & & & & & & & & \\\\\n\\hline\n65 & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\nFigure 4: Analysis of robustness when injecting random feature noise on Cora and Citeseer.\n\n## Robust Analysis\n\n| |GCN|LDS|GRCN|IDGL|ProGNN|CoGSL|SUBLIME|NodeFormer|\n|---|---|---|---|---|---|---|---|---|\n|Cora|84| |74| |81| | | |\n|Citeseer| |72| | |80| | | |\n|Pubmed| | | | | | | | |\n\nAccuracy (%)\n\n$$\n\\begin{array}{|c|c|c|c|c|c|c|c|c|c|}\n\\hline\n83 & & & & & & & & & \\\\\n\\hline\n82 & & & & & & & & & \\\\\n\\hline\n81 & & & & & & & & & \\\\\n\\hline\n80 & & & & & & & & & \\\\\n\\hline\n\\end{array}\n$$\nFigure 5: Training time and space analysis on Cora, Citeseer and Pubmed.\n\nPerformance on corrupted graph structure datasets, which means unsupervised representation learning might produce more reliable and high-quality representations to conduct structure modeling.\n\nRobust analysis with respect to feature noise. On the basis of exploring structural robustness, we also study the feature robustness of GSL. We randomly mask a certain proportion of node features by filling them with zeros, to investigate the performance of GSL']","As shown in Figure 4, the performance of GSL algorithms generally exhibits a downward trend as the noise intensity increases when random feature noise is injected into the graph structures of Cora and Citeseer. GSL algorithms commonly demonstrate a certain degree of robustness, showing more stable performance than GCN.",simple,[{'filename': '505_gslb_the_graph_structure_learn.pdf'}],True
"How do local balanced samplers in generative models compare in terms of sample quality and diversity, specifically in the context of RBM training results and a text filling task on BERT?","[' balanced samplers generate samples with higher qualities and can typically visit multiple modalities in the distribution.\n\n## Domain Specific Scores\n\nDomain Specific Scores: In many deep generative tasks, the goal is to efficiently sample high-quality samples, instead of mixing in the learned energy-based models. In this scenario, domain-specific scores that directly evaluate the sample qualities are a better choice. For example, DISCS provides text filling tasks based on pre-trained language models like BERT (Wang & Cho, 2019; Devlin et al., 2018). Following the settings in prior work (Zhang et al., 2022), DISCS randomly samples 20 sentences from TBC (Zhu et al., 2015) and WiKiText-103 (Merity et al., 2016), masks four words in each sentence (Donahue et al., 2020), and samples 25 sentences from the probability distribution given loading the checkpoint from https://huggingface.co/bert-base-uncased.\n\n# Binary RBM with hidden dimension 25\n\n## Binary RBM with hidden dimension 25\n\n$$\\begin{array}{|c|c|}\n\\hline\n102 & \\text{hb-10-1} \\\\\n\\hline\n\\text{bg-2} & \\text{rmw} \\\\\n\\hline\n\\text{gwg t t} & \\text{gwg t + 1} \\\\\n\\hline\n\\text{dmala t t} & \\text{dmala t + 1} \\\\\n\\hline\n\\text{pas t t} & \\text{pas t + 1} \\\\\n\\hline\n\\text{dlmcf t t} & \\text{dlmcf t + 1} \\\\\n\\hline\n\\text{dlmc t t} & \\text{dlmc t + 1} \\\\\n\\hline\n\\end{array}$$\n\n## Binary RBM with hidden dimension 200\n\n$$\\begin{array}{|c|c|}\n\\hline\n\\text{hb-10-1} & \\text{Binary RBM with hidden dimension 200} \\\\\n\\hline\n\\text{bg-2} & \\text{rmw} \\\\\n\\hline\n\\text{gwg t t} & \\text{gwg t + 1} \\\\\n\\hline\n\\text{dmala t t} & \\text{dmala t + 1} \\\\\n\\hline\n\\text{pas t t} & \\text{pas t + 1} \\\\\n\\hline\n\\text{dlmcf t t} & \\text{dlmcf t + 1} \\\\\n\\hline\n\\text{dlmc t t} & \\text{dlmc t + 1} \\\\\n\\hline\n\\end{array}$$\n\n### Results on RBMs trained on MNIST dataset\n\n- RBMs with 25 binary hidden variables\n- RBMs with 200 binary hidden variables\n\n### Samplers\n\n- pas\n- gwg\n- dmala\n- dlmc\n- dlmcf\n- rmw\n- bg-2\n- hb-10-1\n\n### x1k Steps\n\n- MNIST\n- BERT\n\n### Snapshots of energy-based generative models\n\n- Snapshots for every 1k steps on MNIST ResNet\n- Snapshots for text filling task on BERT in Table 2\n\n262 by BERT. As a common practice in non-auto-regressive text generation, we select the top-5 sentences\nwith the highest likelihood out of 25 sentences to avoid low-quality generation (Gu et al., 2017; Zhou\net al., 2019). We evaluate the generated samples in terms of diversity and quality. For diversity,\nwe use self-BLEU (Zhu et al., 2018) and the number of unique n-grams (Wang & Cho, 2019) to\nmeasure the difference between the generated sentences. For quality, we measure the BLEU score\n(Papineni et al., 2002) between the generated texts and the original dataset, which is the combination\nof TBC and WikiText-103. We report the quantitative results in Table 2. We do not have the results\nfor HB and BG as they are computationally infeasible for this task with 30k+ tokens. In this task,\nthe locally balanced sampler still outperforms RMW. Also, one can notice that the weight function\n$$t+1$$ significantly outperforms $$t$$. The reason is that the overparameterized neural network is a low\ntemperature system with a sharp landscape. This phenomenon is consistent with the results in Figure 2.\n\n### Conclusion']","In the task of RBM training results and a text filling task on BERT, locally balanced samplers outperform RMW. The weight function t+1 significantly outperforms t due to the overparameterized neural network being a low-temperature system with a sharp landscape.",multi_context,[{'filename': '35_discs_a_benchmark_for_discrete.pdf'}],True
