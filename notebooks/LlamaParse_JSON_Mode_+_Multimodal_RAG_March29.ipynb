{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bHjfeuXqkBS"
      },
      "source": [
        "# Testing:\n",
        "This notebook demo's LlamaParse's ability to work in JSON mode for parsing text from images via indexing.\n",
        "\n",
        "> Using JSON mode gives you back a list of json dictionaries, which contains both text and images. You can then download these images and use a multimodal model to extract information and index them.\n",
        "\n",
        "> https://github.com/run-llama/llama_parse/blob/main/examples/demo_json.ipynb\n",
        "\n",
        "## Document Corpus:\n",
        "This notebook runs JSON mode from `llama-parse` on a single, local PDF. \"Solving Linear Inverse Problems Provably via\n",
        "Posterior Sampling with Latent Diffusion Models\" -- which can be found here for `wget` https://arxiv.org/pdf/2307.00619.pdf. For this demo notebook, I've elected to just load it w/in the notebook's runtime for testing.\n",
        "\n",
        "# API Key Management:\n",
        "Using this notebook's secret feature to call API keys where applicable. (found in left panel of the Colab). Previous iterations of this I used `getPass` module.\n",
        "\n",
        "```\n",
        "from google.colab import userdata\n",
        "userdata.get('secretName')\n",
        "```\n",
        "alt:\n",
        "\n",
        "```\n",
        "import os\n",
        "import getpass\n",
        "#API Access to llama-cloud\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = getpass.getpass(\"Enter LlamaParse API Key:\")\n",
        "\n",
        "# Using OpenAI API for embeddings/LLMs\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter OpenAI API Key:\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nVV14ETq1xi"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Going to use OpenAI for the LLM and HuggingFace Hub for the BAII embedding model - _no Qdrant on this demo for persistent vector database._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfmyz3N6qdqt",
        "outputId": "007d2f58-1af9-4080-bdc2-eb1d3ff672f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: llama-index in /Users/rashad/Library/Python/3.9/lib/python/site-packages (0.10.26)\n",
            "Requirement already satisfied: llama-index-core in /Users/rashad/Library/Python/3.9/lib/python/site-packages (0.10.26)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.2.1)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.11)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.7)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.5)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.14)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.4)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.5)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.13)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.1.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (0.5.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (2024.3.1)\n",
            "Requirement already satisfied: httpx in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (0.1.15)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (3.8.1)\n",
            "Requirement already satisfied: numpy in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (1.24.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (1.16.1)\n",
            "Requirement already satisfied: pandas in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (2.2.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (8.2.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (0.8.0)\n",
            "Requirement already satisfied: wrapt in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.10 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core) (1.10.7)\n",
            "Requirement already satisfied: anyio in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core) (3.6.2)\n",
            "Requirement already satisfied: certifi in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core) (1.0.5)\n",
            "Requirement already satisfied: idna in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core) (3.4)\n",
            "Requirement already satisfied: sniffio in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
            "Requirement already satisfied: click in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (8.1.3)\n",
            "Requirement already satisfied: joblib in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from openai>=1.1.0->llama-index-core) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core) (3.0.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core) (1.26.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core) (0.4.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core) (2024.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.3.2.post1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index-core) (23.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /Users/rashad/Library/Python/3.9/lib/python/site-packages (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.22.2)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-embeddings-huggingface) (0.10.26)\n",
            "Requirement already satisfied: sentence-transformers<3.0.0,>=2.6.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: filelock in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
            "Requirement already satisfied: requests in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.9.0)\n",
            "Requirement already satisfied: aiohttp in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.3)\n",
            "Requirement already satisfied: minijinja>=1.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.0.16)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.27)\n",
            "Requirement already satisfied: dataclasses-json in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.5.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
            "Requirement already satisfied: httpx in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.1.15)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
            "Requirement already satisfied: numpy in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.24.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.1)\n",
            "Requirement already satisfied: pandas in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.2.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (9.4.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.2.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.8.0)\n",
            "Requirement already satisfied: wrapt in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.14.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (4.39.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.4.1.post1)\n",
            "Requirement already satisfied: scipy in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.12.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.2)\n",
            "Requirement already satisfied: pydantic>=1.10 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.10.7)\n",
            "Requirement already satisfied: anyio in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.6.2)\n",
            "Requirement already satisfied: certifi in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.5)\n",
            "Requirement already satisfied: idna in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.4)\n",
            "Requirement already satisfied: sniffio in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
            "Requirement already satisfied: click in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.1.3)\n",
            "Requirement already satisfied: joblib in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.0.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\n",
            "Requirement already satisfied: sympy in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.12)\n",
            "Requirement already satisfied: jinja2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.1.2)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (0.4.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.4.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from sympy->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: llama-parse in /Users/rashad/Library/Python/3.9/lib/python/site-packages (0.4.0)\n",
            "Requirement already satisfied: llama-index-core>=0.10.7 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-parse) (0.10.26)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.10.7->llama-parse) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (0.5.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (2024.3.1)\n",
            "Requirement already satisfied: httpx in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (0.1.15)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (3.8.1)\n",
            "Requirement already satisfied: numpy in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (1.24.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (1.16.1)\n",
            "Requirement already satisfied: pandas in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (2.2.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (8.2.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (0.8.0)\n",
            "Requirement already satisfied: wrapt in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llama-index-core>=0.10.7->llama-parse) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.7->llama-parse) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.7->llama-parse) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.7->llama-parse) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.7->llama-parse) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.7->llama-parse) (1.9.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.7->llama-parse) (4.0.2)\n",
            "Requirement already satisfied: pydantic>=1.10 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core>=0.10.7->llama-parse) (1.10.7)\n",
            "Requirement already satisfied: anyio in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core>=0.10.7->llama-parse) (3.6.2)\n",
            "Requirement already satisfied: certifi in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core>=0.10.7->llama-parse) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core>=0.10.7->llama-parse) (1.0.5)\n",
            "Requirement already satisfied: idna in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core>=0.10.7->llama-parse) (3.4)\n",
            "Requirement already satisfied: sniffio in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core>=0.10.7->llama-parse) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core>=0.10.7->llama-parse) (0.14.0)\n",
            "Requirement already satisfied: click in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.7->llama-parse) (8.1.3)\n",
            "Requirement already satisfied: joblib in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.7->llama-parse) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.7->llama-parse) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from openai>=1.1.0->llama-index-core>=0.10.7->llama-parse) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core>=0.10.7->llama-parse) (3.0.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core>=0.10.7->llama-parse) (1.26.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.10.7->llama-parse) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.10.7->llama-parse) (0.4.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core>=0.10.7->llama-parse) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core>=0.10.7->llama-parse) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core>=0.10.7->llama-parse) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core>=0.10.7->llama-parse) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-core>=0.10.7->llama-parse) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index-core>=0.10.7->llama-parse) (23.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rashad/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core>=0.10.7->llama-parse) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama-index-core\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-parse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uIzVL_lxrdGg"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "St9uwsNAQiao",
        "outputId": "45b3e1b9-3783-4983-ff35-60b5d61ea50a"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496,
          "referenced_widgets": [
            "ade5e69f577944e9aaeef094255eeada",
            "8fc433ac0dcb475582f0ad0e6605f24e",
            "cb8ffa4a4e4846b2a243b817d8b85fd4",
            "1aa87194147243fa84d0e24a42e7adb1",
            "b2b2176b997c420983265595fc6909fe",
            "fc3ac953214640819126d0d38ac9f881",
            "c7cb7b1c70ed45dfb8b6e59a9605887a",
            "03c4950aa5394851af4d8050b8262a9e",
            "091b69d527c54d06a6e030c7719e191a",
            "2dc9a8db6a2c451ea3aa2e2a015b1fa7",
            "355ff71b02d543e7b39e4d270dc5029b",
            "0014c037bf764d04823a551ef4c83fe5",
            "e9f6167df0c84883a9bff50c0e197c33",
            "3d36543fc7284ad2bbe990513b4acde8",
            "b8df078303d248e08c6d8df0e99ecd71",
            "e1475b8608ae4a6a9fdc59157aa41718",
            "a4ad58e4baf245e7a81cfd83e9ffb1bf",
            "665326709ee149d28dfa6f11fc0cc9fb",
            "cf63633fc63d4b99a59be501e051a46f",
            "b426c9fb44be46bd8a77e44a3a1f5fec",
            "c56171bcf23147d0ba722241aef388cc",
            "c7c199b6b57041a0a47cce98b2280fd6",
            "5735745b5f50420fb8e56384e18eeef0",
            "5f4e78a93d1c47c2bc4165fcbf5049e5",
            "7596d0a8a0f44f6b829cbaf5bcb93aa9",
            "d6daa09826ae476ba92e1694c1234662",
            "9be24691c1724d2ab9afffb9af53990a",
            "cde3bbfe14d04193b23f8983f1ad18ec",
            "7cabccb2074e4765b9b3cabeb7e72636",
            "94e554606a324fd49d0f7f577affa92b",
            "c9cb19d2b7454634accfb320d5d6d73f",
            "e2b96fc09be844ed9ffe7ad43e87ac12",
            "a6becdc96c934e11ba67d12120a99229",
            "c67dd0e41fcc480fb1be128f8e8f0339",
            "e5e49c5c1fdf4e4db27b3989c04c4d39",
            "8523ac99495f42e0bdbfd36fa719f82c",
            "792ffc9a5cc741e987d3e4d27e008e93",
            "e654a0c8aacf4d7e87d1e85b1726ae15",
            "8ecde80adba84c3ca527f33007ee9a1e",
            "906fad7af45e42bb9439250b72be0797",
            "a4398641f79448429b6818bc489702a4",
            "11d9e5a62b694211a0c7e0b06ebbd4db",
            "ad0f7175f9964d5187a6c33eecf36ebf",
            "4bae38c885ff4ed98b08e0a451d10cd9",
            "60375d3fba2d42a1bb856dfd0704a582",
            "ee3b2e7a4afc42a38d41113d78ee1549",
            "1ebad4cd40464273bbe726ed5d14eada",
            "ca0aca54104a454f84b8dcb67e548d8e",
            "e98ed21025424044b28a590fa1a6c325",
            "4c11dbb4dbbc418595585a49771f5a6b",
            "80a8585e97dd4136ab849733a3e9f9e4",
            "81f7203d9ba547aa925eefdd38d1469c",
            "03e7ca36488d48cd9f16463c09af646d",
            "eb60692e822043d7b725b03d53429981",
            "8e1fd686e98e4958889919e15875fa88",
            "17641a2b875e4755a09b59e9d4256dbe",
            "e58bbde5bf904548bf649967ec2137a8",
            "5c91948dc37048e0a93f89061923b5f9",
            "b6a7e005312c47c2887eef5a27d44c50",
            "c01c91480a984148a6ddd42c05e34613",
            "a4d7274695284dcba317e55a77e7f18c",
            "bb4e5681c4b844f9a44a76df8c51ab59",
            "b5cc17a7279d46f9bbce07c0e18bfa1a",
            "d5616b6f22384033bc5a3259f282bb0a",
            "c713156f2b4745938aee66b3d8e90716",
            "08358e92183e454086204c2e38d41024",
            "072f814728ba4b55a9764de4db5feb76",
            "d90153df16dd4b25ba552bf4befcba95",
            "9df5094a55524bcfa0fbbd1ba35df467",
            "453abd3e2ac3450ead01e9ae09434133",
            "e2d9693266be4d4ea01b822c12a93b38",
            "cd760c9f68384b2fb03521659e7d7dba",
            "0c95485d631c4815a634d24686017e2d",
            "4b59047e44d74e5e9a5f7e92990f1349",
            "80b03ef71d0e46c099e06e47be4565cf",
            "a25293b5d6ae4d3dadc5a2ab97f2103a",
            "8d3a14fcaf8c4ba19f5a406545feacf1",
            "e29576ad44d84e5890a5c717fe3ae3d1",
            "6db0c5b620044215b52ccb2d2b57ccdf",
            "85083aeec32e4a718e3d80fea0ae9f5e",
            "65e3219dfb134b59bd1bef6047573081",
            "a883e7a835bd459198fb7faaf2c79bd2",
            "86ead2dacb444dd1a6efb096f9914eb2",
            "02f0ada298284f1892d63849aadb3ea6",
            "c7b486cbb24645a4a5c8241fb72060a3",
            "4c5c82c8538242a5bb05df7069883b57",
            "7f6f764dc652464e81b242c8cd28d7b1",
            "e6216808409e4204979d75733ba16e20",
            "33fbc212c8884f5f9d0b265c10d11062",
            "02348ddbe6af466285f6424472785b8e",
            "3101d5dc061c44fe91d5cd62aaef1df7",
            "28c42521a78149e3917cab9e984fc744",
            "f7dc43724a5f41f3825d8ba8cceed9a6",
            "2efae6ea209f49e6920fbad9b443fbe4",
            "e6ff92c06e18435fb63a840a43b9ff40",
            "5787d2246c6c4076b7a55d916858c31f",
            "2ad7e7bb730c4d1f91d6b6dda763a3a2",
            "c0e28bfc0af043ed84c8c0e94e7d34c4",
            "cf536abd6250454fbf1d179381d879f8",
            "cb0c3060600042508cf7ea863d1f49bd",
            "09d808a0f9984bd3aaac93624b1b014c",
            "3801bcb88d27417e9d655bf7276800de",
            "77ba62d27afa40f787907b1d23863822",
            "2e38907d7ebc4a4f8de1a8f4a9ccd6aa",
            "d9b0d781fbb94fa5ab898aa5e8eae2e8",
            "5ff9d0879da94483a817501bc694b0c9",
            "09ff39f1691c4b31affca458dbdb9ec3",
            "fb7000e79c1446f78b6014df7ed3a2c4",
            "106a4e8bec864f89939e06dfcc5e89e1",
            "9c544995a1a34044802839016fb4c1b7",
            "f66babf1da964042806dc2faa6f957a7",
            "2318c02473bd423e9a9ee0781861ea5a",
            "f76cb6ada7fc475fafc3f15da9ceed40",
            "56514d14647a4c2fb849673fe684438e",
            "510e73f9c1914184b43a623f3df1d41e",
            "7e118b7c61384bf893c64bf41faa8c80",
            "b7a24ecd92ee4d49b71b79b708325030",
            "ef6769ed7b2a429d9f3f5d5fc7e134aa",
            "5d1be1ec56744d1e83837ec25676fe68",
            "212b4f74d9204dc7a7ad26e1d774efe3",
            "b394363b46c94cba95a90479abbd79c9"
          ]
        },
        "id": "zc7GWJQFr3aC",
        "outputId": "0305040c-d54c-4a83-d337-4de890457c5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/rashad/Library/Caches/pypoetry/virtualenvs/rag-project-RXD1v8WZ-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# LLM:\n",
        "from llama_index.llms.openai import OpenAI\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Core:\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = \"local:BAAI/bge-small-en-v1.5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqRV0BpTtUQw"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "As mentioned above going to use \"Solving Linear Inverse Problems Provably via\n",
        "Posterior Sampling with Latent Diffusion Models\"\n",
        "> - https://drive.google.com/drive/folders/1viTmkHmHupA2qX6ePJBtdc5BUOqjdz7S\n",
        "> - https://arxiv.org/pdf/2307.00619.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-10PDS_XuXlG"
      },
      "source": [
        "## Using LlamaParse in JSON Mode for PDF Reading\n",
        "\n",
        "> Following along as shown in this Llama-parse demo [notebook](https://colab.research.google.com/github/run-llama/llama_parse/blob/main/examples/demo_json.ipynb)  - but also adding instructions for the parser for our specific use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUP3eDcytPgT",
        "outputId": "19691450-2cbc-438f-b7de-112f6a9426ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started parsing the file under job_id 3bd197ee-0a14-4bd4-ad71-ffafcc19e9d3\n",
            "....................."
          ]
        }
      ],
      "source": [
        "from llama_parse import LlamaParse\n",
        "\n",
        "MyparsingInstruction = \"\"\"The provided document includes both text and math equations.\n",
        "Output any math equation in LATEX markdown, using $$ at the start and end of the LATEX.\n",
        "Any table in the document needs to preserve markdown structure.\"\"\"\n",
        "\n",
        "parser = LlamaParse(verbose=True,\n",
        "                    parsing_instruction=MyparsingInstruction)\n",
        "json_objs = parser.get_json_result(\"../corpus/solving-linear-inverse-probs.pdf\")\n",
        "json_list = json_objs[0][\"pages\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson_objs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "json_objs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_U7m_pxRnH3"
      },
      "source": [
        "### Create the \"get_text_nodes\" function\n",
        "Using for loop, build `json_list`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbFPZMBuuoYa"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.schema import TextNode\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def get_text_nodes(json_list: List[dict]):\n",
        "    text_nodes = []\n",
        "    for idx, page in enumerate(json_list):\n",
        "        text_node = TextNode(\n",
        "            text=page[\"text\"],\n",
        "            metadata={\n",
        "                \"page\": page[\"page\"]\n",
        "            }\n",
        "        )\n",
        "        text_nodes.append(text_node)\n",
        "    return text_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKhk7mJtveOP"
      },
      "outputs": [],
      "source": [
        "text_nodes = get_text_nodes(json_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph3VhSH-j2zP",
        "outputId": "41f7e7ee-91d4-42f8-ada6-f4c18d09ac44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TextNode(id_='ffd79866-215f-429e-8026-72fc9fe0c4a4', embedding=None, metadata={'page': 1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='        Solving Linear Inverse Problems Provably via\\n     Posterior Sampling with Latent Diffusion Models\\n                               Litu Rout     Negin Raoof       Giannis Daras\\n                 Constantine Caramanis        Alexandros G. Dimakis         Sanjay Shakkottai\\n                                    The University of Texas at Austin\\n                                                 Abstract\\n          We present the first framework to solve linear inverse problems leveraging pre-\\n          trained latent diffusion models. Previously proposed algorithms (such as DPS and\\n          DDRM) only apply to pixel-space diffusion models. We theoretically analyze our\\n          algorithm showing provable sample recovery in a linear model setting. The algo-\\n          rithmic insight obtained from our analysis extends to more general settings often\\n          considered in practice. Experimentally, we outperform previously proposed poste-\\n          rior sampling algorithms in a wide variety of problems including random inpainting,\\n          block inpainting, denoising, deblurring, destriping, and super-resolution.\\n1    Introduction\\nWe study the use of pre-trained latent diffusion models to solve linear inverse problems such as\\ndenoising, inpainting, compressed sensing and super-resolution. There are two classes of approaches\\nfor inverse problems: supervised methods where a restoration model is trained to solve the task at\\nhand [37, 39, 56, 31], and unsupervised methods that use the prior learned by a generative model\\nto guide the restoration process [52, 40, 5, 33, 11, 26]; see also the survey of Ongie et al. [36] and\\nreferences therein.\\nThe second family of unsupervised methods has gained popularity because: (i) general-domain\\nfoundation generative models have become widely available, (ii) unsupervised methods do not require\\nany training to solve inverse problems and leverage the massive data and compute investment of\\npre-trained models and (iii) generative models sample from the posterior-distribution, mitigating\\ncertain pitfalls of likelihood-maximization methods such as bias in the reconstructions [35, 24] and\\nregression to the mean [23, 22].\\nDiffusion models have emerged as a powerful new approach to generative modeling [47, 48, 49, 20,\\n29, 18, 54]. This family of generative models works by first corrupting the data distribution p0(x0)\\nusing an It Stochastic Differential Equation (SDE), dx = f(x, t)dt + g(t)dw, and then by learning\\nthe score-function, xt log pt(xt), at all levels t, using Denoising Score Matching (DSM) [21, 53].\\nThe seminal result of Anderson [1] shows that we can reverse the corruption process, i.e., start with\\nnoise and then sample from the data distribution, by running another It SDE. The SDE that corrupts\\nthe data is often termed as Forward SDE and its reverse as Reverse SDE [49]. The latter depends\\non the score-function xt log pt(xt) that we learn through DSM. In [8, 9], the authors provided a\\nnon-asymptotic analysis for the sampling of diffusion models when the score-function is only learned\\napproximately.\\nThe success of diffusion models sparked the interest to investigate how we can use them to solve\\ninverse problems. Song et al. [49] showed that given measurements y = Ax0 + yn, we can\\n    Email:{litu.rout,neginmr,giannisdaras,constantine,sanjay.shakkottai}utexas.edu, dimakis@austin.utexas.edu\\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='c1f2d466-e4c0-4f8b-96ed-49b07d553b45', embedding=None, metadata={'page': 2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='                      SOp\\nFigure 1: Overall pipeline of our proposed framework from left to right. Given an image (left) and a\\nuser defined mask (center), our algorithm inpaints the masked region (right). The known part of the\\nimages are unaltered (see Appendix C for web demo and image sources).\\nprovably sample from the distribution p0(x0|y) by running a modified Reverse SDE that depends\\non the unconditional score xt log pt(xt) and the term xt log p(y|xt). The latter term captures\\nhow much the current iterate explains the measurements and it is intractable even for linear inverse\\nproblems without assumptions on the distribution p0(x0) [11, 14]. To deal with the intractability\\nof the problem, a series of approximation algorithms have been developed [22, 11, 2, 13, 26, 10,\\n6, 46, 12, 27] for solving (linear and non-linear) inverse problems with diffusion models. These\\nalgorithms use pre-trained diffusion models as flexible priors for the data distribution to effectively\\nsolve problems such as inpainting, deblurring, super-resolution among others.\\nRecently, diffusion models have been generalized to learn to invert non-Markovian and non-linear\\ncorruption processes [16, 15, 3]. One instance of this generalization is the family of Latent Diffusion\\nModels (LDMs) [41]. LDMs project the data into some latent space, z0 = E(x0), perform the\\n                                                  2', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='d5affef6-37bb-466b-bac1-1a65c7a73033', embedding=None, metadata={'page': 3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='diffusion in the latent space and use a decoder, D(z0), to move back to the pixel space. LDMs\\npower state-of-the-art foundation models such as Stable Diffusion [41] and have enabled a wide-\\nrange of applications across many data modalities including images [41], video [4], audio [30]\\nand medical domain distributions (e.g., for MRI and proteins) [38, 51]. Unfortunately, none of the\\nexisting algorithms for solving inverse problems works with Latent Diffusion Models. Hence, to\\nuse a foundation model, such as Stable Diffusion, for some inverse problem, one needs to perform\\nfinetuning for each task of interest.\\nIn this paper, we present the first framework to solve general inverse problems with pre-trained latent\\ndiffusion models. Our main idea is to extend DPS by adding an extra gradient update step to guide the\\ndiffusion process to sample latents for which the decoding-encoding map is not lossy. By harnessing\\nthe power of available foundation models, we are able to outperform previous approaches without\\nfinetuning across a wide range of problems (see Figure 1 and 2).\\nOur contributions are as follows:\\n      (i) We show how to use Latent Diffusion Models models (such as Stable Diffusion) to solve\\n          linear inverse problem when the degradation operator is known.\\n     (ii) We theoretically analyze our algorithm and show provable sample recovery in a linear model\\n          setting with two-step diffusion processes.\\n     (iii) We achieve a new state-of-the-art for solving inverse problems with latent diffusion models,\\n          outperforming previous approaches for inpainting, block inpainting, denoising, deblurring,\\n          destriping, and super-resolution.2\\n2    Background and Method\\nNotation: Bold lower-case x, bold upper-case X, and normal lower case x denote a vector, a matrix,\\nand a scalar variable, respectively. We denote by      element-wise multiplication. D(x) represents\\na diagonal matrix with entries x. We use E(.) for the encoder and D(.) for the decoder. Ep is a\\npushforward measure of p, i.e., for every x       p, the sample E(x) is a sample from Ep. We use\\narrows in Section 3 to distinguish random variables of the forward () and the reverse process ().\\nThe standard diffusion modeling framework involves training a network, s(xt, t), to learn the\\nscore-function, xt log pt(xt), at all levels t, of a stochastic process described by an It SDE:\\n                                      dx = f(x, t)dt + g(t)dw,                                         (1)\\nwhere w is the standard Wiener process. To generate samples from the trained model, one can run\\nthe (unconditional) Reverse SDE, where the score-function is approximated by the trained neural\\nnetwork. Given measurements y = Ax0 + yn, one can sample from the distribution p0(x0|y) by\\nrunning the conditional Reverse SDE given by:\\n             dx =    f(x, t)   g2(t) (xt log pt(xt) + xt log p(y|xt))      dt + g(t)dw.             (2)\\nAs mentioned, xt log p(y|xt) is intractable for general inverse problems. One of the most effective\\napproximation methods is the DPS algorithm proposed by Chung et al. [11]. DPS assumes that:\\n                p(y|xt)    p (y|\\n                                 x0 := E[x0|xt]) = N(y;  = AE[x0|xt],  = 2         yI).             (3)\\nEssentially, DPS substitutes the unknown clean image x0 with its conditional expectation given the\\nnoisy input, E[x0|xt]. Under this approximation, the term p(y|xt) becomes tractable.\\nThe theoretical properties of the DPS algorithm are not well understood. In this paper, we analyze\\nDPS in a linear model setting where the data distribution lives in a low-dimensional subspace,\\nand show that DPS actually samples from p(x0|y) (Section A.1). Then, we provide an algorithm\\n(Section 2.1) and its analysis to sample from p(x0|y) using latent diffusion models (Section 3.2).\\nImportantly, our analysis suggests that our algorithm enjoys the same theoretical guarantees while\\navoiding the curse of ambient dimension observed in pixel-space diffusion models including DPS.\\nUsing experiments (Section 4), we show that our algorithm allows us to use powerful foundation\\nmodels and solve linear inverse problems, outperforming previous unsupervised approaches without\\nthe need for finetuning.\\n    2\\n    The source code is available at: https://github.com/LituRout/PSLD and a web application for image\\ninpainting is available at: https://huggingface.co/spaces/PSLD/PSLD.\\n                                                    3', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='cf49a276-7177-4215-b90a-f7bf0ce3c0c0', embedding=None, metadata={'page': 4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=' 2.1     Method\\n In Latent Diffusion Models, the diffusion occurs in the latent space. Specifically, we train a model\\n s(zt, t) to predict the score zt log pt(zt), of a diffusion process:\\n                                                     dz = f(z, t)dt + g(t)dw,                                                               (4)\\n where z0 = E(x0) for some encoder function E() : Rd                                 Rk. During sampling, we start with zT ,\\n we run the Reverse Diffusion Process and then we obtain a clean image by passing z0                                            p0(z0|zT )\\n through a decoder D : Rk                 Rd.\\n Although Latent Diffusion Models underlie some of the most powerful foundation models for image\\n generation, existing algorithms for solving inverse problems with diffusion models do not apply for\\n LDMs. The most natural extension of the DPS idea would be to approximate p(y|zt) with:\\n                                              p(y|zt)        p(y|x0 = D (E[z0|zt])),                                                       (5)\\n i.e., to approximate the unknown clean image x0 with the decoded version of the conditional\\n expectation of the clean latent z0 given the noisy latent zt. However, as we show experimentally in\\n Section 4, this idea does not work. The failure of the vanilla extension of the DPS algorithm for\\n latent diffusion models should not come as a surprise. The fundamental reason is that the encoder is a\\n many-to-one mapping. Simply put, there are many latents z0 that correspond to encoded versions\\n of images that explain the measurements. Taking the gradient of the density given by (5) could be\\n pulling zt towards any of these latents z0, potentially in different directions. On the other hand, the\\n score-function is pulling zt towards a specific z0 that corresponds to the best denoised version of zt.\\n To address this problem, we propose an extra term that penalizes latents that are not fixed-points of\\n the composition of the decoder-function with the encoder-function. Specifically, we approximate the\\n intractable       log p(y|zt) with:\\n   zt log p(y|zt) = zt log p(y|               x0 = D (E[z0|zt]))           +t zt ||E[z0|zt]             E(D(E[z0|zt]))||2          . (6)\\n                                        DPS vanilla extension                                       goodness of z0\\nWe refer to this approximation as Goodness Modified Latent DPS (GML-DPS). Intuitively, we guide\\n the diffusion process towards latents such that: i) they explain the measurements when passed through\\n the decoder, and ii) they are fixed points of the decoder-encoder composition. The latter is useful\\n to make sure that the generated sample remains on the manifold of real data. However, it does not\\n penalize the reverse SDE for generating other latents z0 as long as D(z0) lies on the manifold of\\n natural images. Even in the linear case (see Section 3), this can lead to inconsistency at the boundary\\n of the mask in the pixel space. The linear theory in Section 3 suggests that we can circumvent this\\n problem by introducing the following gluing objective. In words, the gluing objective penalizes\\n decoded images having a discontinuity at the boundary of the mask.\\n               zt log p(y|zt) = zt log p(y|x0 = D (E[z0|zt]))\\n                                                     DPS vanilla extension\\n                                       + t zt        E[z0|zt]        E(AT y + (I           AT A)D(E[z0|zt]))              2  .          (7)\\n                                                                              gluing of z0\\n The gluing objective is critical for our algorithm as it ensures that the denoising update, measurement-\\n matching update, and the gluing update point to the same optima in the latent space. We refer to this\\n approximation (7) as Posterior Sampling with Latent Diffusion (PSLD). In the next Section 3, we\\n provide an analysis of these gradient updates, along with the associated algorithms.\\n Remark 2.1. Consider the optimization problem of projecting onto the measurements:\\n                                                              min     \\n                                                               x0      x0      x02  2\\n                                                         subject to Ax0 = y,\\n In the linear setting, the optimal solution is given by x                                   0    =      AT (AAT )1y + (             x0 \\n AT (AAT )1(A          x0)). Now further suppose that the measurement rows are orthogonal, i.e. AAT =\\n Il. This condition holds for some natural linear inverse problems like inpainting. Suppose that\\n we want to update the latent vector zt such that E[z0|zt] = E(x                              0); this ensures that the gradients\\n                                                                       4', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='5b04f8a7-8254-4fc3-bfc2-1788188b3113', embedding=None, metadata={'page': 5}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='   Algorithm 1: DPS                                             Algorithm 2: PSLD\\n   Input: T , y, T     i}T                                     Input: T , y, {i}T                i}T\\n1 xT     N (0, I)i=1, {   i=1, s                           1 zT     N (0, I)   i=1, {i}Ti=1, {    i=1, E, D, A, s\\n2 for i = T     1 to 0 do                                    2 for i = T    1 to 0 do\\n                                                                     \\n 3      s    s(xi, i)                                       3       s   s(zi, i)\\n                1               i)s)                                     1               i)s)\\n 4      x0       i (xi + (1                              4       z0       \\n                                                                                i (zi + (1    \\n 5      z    N (0, I)                                        5          N (0, I)                    \\n 6      xi1                                                                  i(1  i1)          i1i   \\n                                                              6       z                       zi +             z0 + i\\n          i(1  i1)         i1i                             i1          1i              1i\\n               1 i     xi +     1    x0 + iz          7       z                                    z0))2\\n                                       i                               i1     z\\n 7      xi1     xi1    ixiy     A( x0)22           8       zi1      i1    iziy     A(D(        2\\n8 end                                                                   z              z0   E(AT y + (I      AT A)D(  z0))2\\n9 return x0                                                  9 end      i1   izi                                           2\\n                                                             10 return D( z0)\\n   resulting from the two terms in (7) both point to the same optima in the latent space. Equivalently,\\n   we want to solve the following minimization problem: minz                            t E[z0|zt]       E(x 0)2 2. Substituting\\n   E(x  0) = E(AT y+(       x0AT A       x0)) = E(AT y+(IAT A)                x0), and   x0 = D(E[z0|zt]), we can thus\\n   interpret the gluing objective in (7) as a one step of gradient descent of this loss E[z0|zt]                            E(x  0)22\\n   with respect to zt. Note that, if there was no latent space, our gluing would be equivalent to a\\n   projection on the measurements, but now because of the encoder and decoder, it is not.\\n   3     Theoretical Results\\n   As discussed in Section 2, diffusion models consist of two stochastic processes: the forward and\\n   reverse processes, each governed by It SDEs. For implementation purposes, these SDEs are\\n   discretized over a finite number of (time) steps, and the diffusion takes place using a transition\\n   kernel. The forward process starts from                                                                                \\n                                                             x0       p(x0) and gradually adds noise, i.e., x t+1 =\\n      1    tx t + t where t             [0, 1] and t        t1 for t = 0, . . . , T        1 . The reverse process\\n                                                                                            \\n   is initialized with x T            N (0, Id) and generates x t1 = (x t, t) + t. In the last step,\\n         \\n   (x 1, 1) is displayed without the noise.\\n   In this section, we consider the diffusion discretized to two steps ({                      \\n                                                                                           x0, x1}), and a Gaussian transition\\n   kernel that arises from the Ornstein-Uhlenbeck (OU) process. We choose this setup because it captures\\n   essential components of complex diffusion processes without raising unnecessary complications in the\\n   analysis. We provide a principled analysis of Algorithm 1 and Algorithm 2 in a linear model setting\\n   with this two-step diffusion process under assumptions that guarantee exact reconstruction is possible\\n   in principle. A main result of our work is to prove that in this setting we can solve inverse problems\\n   perfectly. As we show, this requires some novel algorithmic ideas that are suggested by our theory.\\n   In Section 4, we then show that these algorithmic ideas are much more general, and apply to large-\\n   scale real-world applications of diffusion models that use multiple steps ({                                         \\n                                                                                                         x0, x1,    , \\n   T = 1000), and moreover do not satisfy the recoverability assumptions. We provide post-processing                      xT }, where\\n   details of Algorithm 2 in Appendix C.1. All proofs are given in Appendix B.\\n   3.1     Problem Setup\\n   The goal is to show that posterior sampling algorithms (such as DPS) can provably solve inverse\\n   problems in a perfectly recoverable setting. To show exact recovery, we analyze two-step diffusion\\n   processes in a linear model setting similar to [42, 7], where the images (                        \\n   subspace of the form                                                                          x0     Rd) reside in a linear\\n                                 x0 = S     w0, S      Rdl,   w0     Rl, and y = 0. Here, S is a tall thin matrix\\n   with rank(S) = l            d that lifts any latent vector       w0      N (0, Il) to the image space with ambient\\n   dimension d. Given the measurements y = A                     x0 + yn, A           Rld, n       Rl, the goal is to sample\\n   from p0(    \\n               x0|y) using a pre-trained latent diffusion model. In the inpainting task, the measurement\\n   operator A is such that AT A is a diagonal matrix D(m), where m is the masking vector with\\n   elements set to 1 where data is observed and 0 where data is masked (see Appendix B for further\\n   details). Recall that in latent diffusion models, the diffusion takes place in the latent space of a\\n   pre-trained Variational Autoencoder (VAE). Following the common practice [41], we consider a\\n   setting where the latent vector of the VAE is k-dimensional and the latent distribution is a standard\\n   Gaussian N (0, Ik). Our analysis shows that the proposed Algorithm 2 provably solves inverse\\n   problems under the following assumptions.\\n                                                                      5', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='16f95618-994f-4971-ac90-35f63267b773', embedding=None, metadata={'page': 6}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=' Assumption 3.1. The columns of the data generating model S are orthonormal, i.e., ST S = Il.\\n Assumption 3.2. The measurement operator A satisfies (AS)T (AS)                                                     0.\\n These assumptions have previously appeared, e.g., [42]. While Assumption 3.1 is mild and can\\n be relaxed at the expense of (standard) mathematical complications, Assumption 3.2 indicates that\\n(AS)T (AS) is a positive definite matrix. The latter ensures that there is enough energy left in\\n the measurements for perfect reconstruction. More precisely, any subset of l coordinates exactly\\n                                                                              \\n determines the remaining (d                      l) coordinates of         x0. The underlying assumption is that there exists a\\n solution and it is unique [42]. Thus, the theoretical question becomes how close the recovered sample\\n is to this groundtruth sample from the true posterior. Alternatively, one may consider other types of\\n posteriors and prove that the generated samples are close to this posterior in distribution. However,\\n this does not guarantee that the exact groundtruth sample is recovered. Therefore, motivated by prior\\n works [42, 7], we analyze posterior sampling in a two-step diffusion model and answer a fundamental\\n question: Can a pre-trained latent diffusion model provably solve inverse problems in a perfectly\\n recoverable setting?\\n 3.2      Posterior Sampling using Latent Diffusion Model\\n In this section, we analyze two approximations: GML-DPS based on (6), and PSLD based on (7),\\n displayed in Algorithm 2. We consider the case where the latent distribution of the VAE is in the\\n same space as the latent distribution of the data generating model, i.e., k = l, and normalize i = 1\\n (as this is immaterial in the linear setting). In Proposition 3.3, we provide analytical solutions for the\\n encoder and the decoder of the VAE.\\n Proposition 3.3 (Variational Autoencoder). Suppose Assumption 3.1 holds. For an encoder E :\\n Rd        Rk and a decoder D : Rk                       Rd, denote by L (, ) the training objective of VAE:\\n                                                             D(E(                           2        + KL (Ep, N             (0, Ik)) ,\\n               arg min                                                  x0; ); )          \\n                      , L (, ) := E           x0p                                      x0     2\\n then the combination of E(                                                                      \\n Using the encoder E(                     x0; ) = ST       x0 and D(        z0; ) = S       z0 is a minimizer of L (, ).\\n                                    x0; ) = ST         x0, we can use the analytical solution                          of the LDM obtained\\n in Theorem A.1. To verify that                            recovers the true subspace p                     x0     , we compose the decoder\\n D(                                                                                                                                        \\n      z0; ) = S       z0 with the generator of the LDM, i.e.,                         x0 = D           z1     = D       Ik z1     = S   z1. Since\\n                                                                                                                                                \\n                                                                                                                                             x0). Thus\\n z1      N (0, Ik) and S is the data generating model, this shows that                                    x0 is a sample from p(\\n we have the following.\\n Theorem 3.4 (Generative Modeling using Diffusion in Latent Space). Suppose Assumption 3.1\\n holds. Let the optimal solution of the latent diffusion model be\\n                                                                                                                    2    .\\n                            = arg min     E    z0,        1    z1(  z0,  ),    z0            z1     z0, \\n                                                                          :=              \\n For a fixed variance  > 0, if                         z1    z0,         1       z1     z0,       , then the closed-form solution is     \\n   = 1          Ik, which after normalization by                      1 and composition with the decoder D                             z0;      =\\n S z0 recovers the true subspace of p                       x0    .\\n With this optimal , we can now prove exact sample recovery using GML-DPS (6).\\n Theorem 3.5 (Posterior Sampling using Goodness Modified Latent DPS). Let Assumptions 3.1 and\\n 3.2 hold. Let j, j = 1, . . . , r, denote the singular values of (AS)T (AS), and let\\n                                                                                                                    2\\n                            = arg min     E    z0,        1    z1(  z0,  ),    z0            z1     z0,               .\\n                                                                  \\n Given a partially known image                      x0       p(x0), any fixed variance                      (0, 1), then with the (unique)\\n step size j    i = 1/2j, j = 1, 2, . . . , r, the GML-DPS Algorithm (6) samples from the true posterior\\n p(                                                                                                   \\n    x0|y) and exactly recovers the groundtruth sample, i.e.,                                  x0 =    x0.\\n Theorem 3.5 shows that GML-DPS (6) recovers the true sample using an LDM. This approach,\\n however, requires the step size  to be chosen coordinate-wise in a specific manner. Also, multiple\\n natural images could have the same measurements in the pixel space. This is a reasonable concern for\\n                                                                               6', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='ffbfa01c-d993-4836-a207-821396be9c53', embedding=None, metadata={'page': 7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=' LDMs due to one-to-many mappings of the decoder. Note that the goodness objective (Section 2.1)                                        \\n cannot help in this scenario because it assigns uniform probability to many of these latents                                         z1 for\\n                                                     2 = 0. These challenges motivate the gluing objective in\\n which      z1    z0( z1)]      E(D(   z0( z1)))\\n Theorem 3.6. This is crucial for two reasons. First, we show that it helps recover the true sample\\n even when the step size  is chosen arbitrarily. Second, it assigns all the probability mass to the\\n desired (unique) solution in the pixel space.\\n Theorem 3.6 (Posterior Sampling using Diffusion in Latent Space). Let Assumptions 3.1 and 3.2\\n hold. Let j, j = 1, . . . , r denote the singular values of (AS)T (AS) and let\\n                                                                                                    \\n                                                                                                          2\\n                         = arg min    E   z0,      1    z1(  z0,  ),  z0           z1    z0,             .\\n                                                           \\n Given a partially known image                 x0      p(x0), any fixed variance                  (0, 1), and any positive step\\n                                                                                                                       \\n sizes j i , j = 1, 2, . . . , r, the PSLD Algorithm 2 samples from the true posterior p(                            x 0|y) and exactly\\n recovers the groundtruth sample, i.e.,               x0=     \\n                                                                x0.\\n The important distinction between Theorem 3.5 and Theorem 3.6 is that the former requires the\\n exact step size while the latter works for any finite step size. Combining denoising, measurement-\\n consistency (with a scalar ), and gluing updates, we have\\n                           AD(                      2                                                                              2\\n z0 =     z1       z1           z0( z1))      y    2     z1    z0( z1)     E(AT A     x0 + (Id         AT A)D(      z0( z1)))   2 .\\nWhen  is chosen arbitrarily, then the third term guides the reverse SDE towards the optimal solution\\n                                                                                                                                 \\n z0. When the reverse SDE generates the exact same groundtruth sample, i.e., D(                                    z1( z0)) =    x0, then\\n the third term becomes zero. For all other samples, it penalizes the reverse SDE. Thus, it forces the\\n reverse SDE to recover the true underlying sample irrespective of the value of .\\nWe draw the following key insights from our Theorem 3.6: Curse of ambient dimension: In order\\n to run posterior sampling using diffusion in the pixel space, the gradient of the measurement error\\n needs to be computed in the d-dimensional ambient space. Therefore, DPS algorithm suffers from\\n the curse of ambient dimension. On the other hand, our algorithm uses diffusion in the latent space,\\n and therefore avoids the curse of ambient dimension. Large-scale foundation model: We propose a\\n posterior sampling algorithm which offers the provision to use large-scale foundation models, and\\n it provably solves general linear inverse problems. Robustness to measurement step: The gluing\\n objective makes our algorithm robust to the choice of step size . Furthermore, it allows the same\\n (scalar) step size across all the coordinates of                 \\n                                                                   x0.\\n 4     Experimental Evaluation\\n We experiment with in-distribution and out-of-\\n distribution datasets. For in-distribution, we con-                    Table 1: Quantitative super-resolution (using mea-\\n duct our experiments on a subset of the FFHQ                           surement operator from [32]) results on FFHQ 256\\n dataset [25] (downscaled to 2562563, denoted                          validation samples [25, 11]. We use PSLD with\\n by FFHQ 256). For out-of-distribution, we use                          Stable Diffusion. Table shows LPIPS ().\\n images from the web and ImageNet dataset [17]\\n (resized to 256256, denoted by ImageNet 256).                                   Method         PSLD (Ours)             DPS [11]\\n To make a fair comparison, we use the same vali-\\n dation subset and follow the same masking strat-                                 2             0.185                   0.220\\n egy as the baseline DPS [11]. It is important to                                 3             0.220                   0.247\\n note that our main contribution is an algorithm                                  4             0.233                   0.291\\n that can leverage any latent diffusion model. We\\n test our algorithm with two pre-trained latent diffusion models: (i) the Stable Diffusion model that\\n is trained on multiple subsets of the LAION dataset [44, 45]; and (ii) the Latent Diffusion model\\n (LDM-VQ-4) trained on the FFHQ 256 dataset [41]. The DPS model is similarly trained from scratch\\n for 1M steps using 49k FFHQ 256 images, which excludes the first 1K images used as validation set.\\n Inverse Problems. We experiment with the following task-specific measurement operators from\\n the baseline DPS [11]: (i) Box inpainting uses a mask of size 128128 at the center. (ii) Random\\n inpainting chooses a drop probability uniformly at random between (0.2, 0.8) and applies this drop\\n     3https://www.kaggle.com/datasets/denislukovnikov/ffhq256-images-only\\n                                                                       7', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='b8f8080a-58d9-4366-8fe9-4bd386fc631b', embedding=None, metadata={'page': 8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=' Table 2: Quantitative inpainting results on FFHQ 256 validation set [25, 11]. We use Stable Diffusion\\n v-1.5 and the measurement operators as in DPS [11]. As shown, our PSLD model outperforms DPS\\n since it is able to leverage the power of the Stable Diffusion foundation model.\\n                        Inpaint (random)         Inpaint (box)             SR (4)            Gaussian Deblur\\n   Method             FID ()   LPIPS ()    FID ()    LPIPS ()    FID ()   LPIPS ()    FID ()    LPIPS ()\\n   PSLD (Ours)        21.34     0.096        43.11      0.167        34.28     0.201        41.53      0.221\\n   DPS [11]           33.48     0.212        35.14      0.216        39.35     0.214        44.05      0.257\\n   DDRM [26]          69.71     0.587        42.93      0.204        62.15     0.294        74.92      0.332\\n   MCG [13]           29.26     0.286        40.11      0.309        87.64     0.520        101.2      0.340\\n   PnP-ADMM [6]       123.6     0.692        151.9      0.406        66.52     0.353        90.42      0.441\\n   Score-SDE [50]     76.54     0.612        60.06      0.331        96.72     0.563        109.0      0.403\\n   ADMM-TV            181.5     0.463        68.94      0.322        110.6     0.428        186.7      0.507\\n probability to all the pixels. (iii) Super-resolution downsamples images at 4 scale. (iv) Gaussian blur\\n convolves images with a Gaussian blur kernel. (v) Motion blur convolves images with a motion blur\\n kernel. We also experiment with these additional operators from RePaint [32]: (vi) Super-resolution\\n downsamples images at 2, 3, and 4 scale. (vii) Denoising has Gaussian noise with  = 0.05.\\n (viii) Destriping has vertical and horizontal stripes in the input images.\\n Evaluation. We compare the performance of our PSLD algorithm with the state-of-the-art DPS\\n algorithm [11] on random inpainting, box inpainting, denoising, Gaussian deblur, motion deblur,\\n arbitrary masking, and super-resolution tasks. We show that PSLD outperforms DPS, both in-\\n distribution and out-of-distribution datasets, using the Stable Diffusion v-1.5 model pre-trained on the\\n LAION dataset. We also test PSLD with LDM-VQ-4 trained on FFHQ 256, to compare with DPS\\n trained on the same data distribution. Note that the LDM-v4 is a latent-based model released prior to\\n Stable Diffusion. Therefore, it does not match the performance of Stable Diffusion in solving inverse\\n problems. However, it shows the general applicability of our framework to leverage an LDM in\\n posterior sampling. Since Stable Diffusion v-1.5 is trained with an image resolution of 512  512, we\\n apply the forward operator after upsampling inputs to 512512, run posterior sampling at 512512,\\n and then downsample images to the original 256  256 resolution for a fair comparison with DPS.\\nWe observed a similar performance while applying the masking operator at 256  256 and upscaling\\n to 512  512 before running PSLD. More implementation details are provided in Appendix C.1.\\n Metrics. We use the commonly used Learned Perceptual Image Patch Similarity (LPIPS), Peak\\n Signal-to-Noise Ratio (PSNR), Structural Similarity Index Metric (SSIM), and Frchet Inception\\n Distance4 (FID) metrics for quantitative evaluation.\\n Results. Figure 2 shows the inpainting results on out-of-distribution samples. This experiment was\\n performed on commercial platforms that use (to the best of our knowledge) Stable diffusion and\\n additional proprietary models. This evaluation was performed on models deployed in May 2023 and\\n may change as commercial providers improve their platforms.\\n The qualitative advantage of PSLD is clearly demonstrated in Figures 2, 3, 4, 15 and 16. In Figure 5,\\nwe compare PSLD and DPS in random inpainting task for varying percentage of dropped pixels.\\n Quantitatively, PSLD outperforms DPS in commonly used metrics: LPIPS, PSNR, and SSIM.\\n In our PSLD algorithm, we use Stable Diffusion v1.5 model and (zero-shot) test it on inverse problems.\\n Table 6 compares the quantitative results of PSLD with related works on random inpainting, box\\n inpainting, super-resolution, and Gaussian deblur tasks. PSLD significantly outperforms previous\\n approaches on the relatively easier random inpainting task, and it is better or comparable on harder\\n tasks. Table 4 draws a comparison between PSLD and the strongest baseline (among the compared\\n methods) on out-of-distribution images. Table 1 shows the super-resolution results using nearest-\\n neighbor kernels from [32] on FFHQ 256 validation dataset. Observe that PSLD outperforms\\n state-of-the-art methods across diverse tasks and standard evaluation metrics.\\n In Table 3, we compare PSLD (using LDM-VQ-4) and DPS on random and box inpainting tasks\\nwith the same operating resolution (256  256) and training distributions (FFHQ 256). Although\\n the LDM model exceeds DPS performance in box inpainting, it is comparable in random inpainting.\\nAs expected, using a more powerful pre-trained model such as Stable Diffusion is beneficial in\\n    4https://github.com/mseitzer/pytorch-fid\\n                                                           8', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='4ae8dc9e-95af-489a-855e-a84c0d747bcf', embedding=None, metadata={'page': 9}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='       (a) Input          (b) Groundtruth      (c) Comm. Serv. 1      (d) Comm. Serv. 2      (e) PSLD (Ours)\\nFigure 2: Inpainting results in general domain images from the web (see Appendix C for image\\nsources). Our model compared to state-of-art commercial inpainting services that leverage the same\\nfoundation model (Stable Diffusion v-1.5).\\nTable 3: Quantitative inpainting results on FFHQ 256 validation set [25, 11]. We use the latent\\ndiffusion (LDM-VQ-4) trained on FFHQ 256. Note that in this experiment PSLD and DPS use\\ndiffusion models trained on the same dataset. As shown, PSLD with LDM-VQ-4 as diffusion model\\noutperforms DPS in box inpainting and has comparable performance in random inpainting.\\n                                    Inpaint (random)                           Inpaint (box)\\n         Method           PSNR ()      SSIM ()     LPIPS ()     PSNR ()      SSIM ()     LPIPS ()\\n         PSLD (Ours)      30.31         0.851        0.221         24.22         0.819        0.158\\n         DPS [11]         29.49         0.844        0.212         23.39         0.798        0.214\\nTable 4: Quantitative results of random inpainting and denoising on FFHQ 256 [25, 11] using Stable\\nDiffusion v-1.5. Note that DPS is trained on FFHQ 256. The results show that our method PSLD\\ngeneralizes well to out-of-distribution samples even without finetuning.\\n                          Random inpaint + denoise  = 0.00        Random inpaint + denoise  = 0.05\\n        Method            PSNR ()     SSIM ()      LPIPS ()     PSNR ()      SSIM ()     LPIPS ()\\n        PSLD (Ours)       34.02         0.951        0.083         33.71         0.943        0.096\\n        DPS [11]          31.41        0.884         0.171         29.49         0.844        0.212\\nreconstructionsee Table 6. This highlights the significance of our PSLD algorithm that has the\\nprovision to incorporate a powerful foundation model with no extra training costs for solving inverse\\nproblems. Importantly, PSLD uses latent-based diffusion, and thus it avoids the curse of ambient\\ndimension (Theorem 3.6), while still achieving comparable results to the state-of-the-art method\\nDPS [11] that has been trained on the same dataset. Additional experimental evaluation is provided\\nin Appendix C.\\n5    Conclusion\\nIn this paper, we leverage latent diffusion models to solve general linear inverse problems. While\\npreviously proposed approaches only apply to pixel-space diffusion models, our algorithm allows\\nus to use the image prior learned by latent-based foundation generative models. We provide a\\nprincipled analysis of our algorithm in a linear two-step diffusion setting, and use insights from this\\nanalysis to design a modified objective (goodness and gluing). This leads to our algorithm  Posterior\\n                                                        9', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='84b1ace6-eae4-43cf-929f-51e165ceca2c', embedding=None, metadata={'page': 10}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"Figure 3: Left panel: Random Inpainting on images from FFHQ 256 [25] using PSLD with Stable Diffusion\\nv-1.5. Notice the text in the top row and the facial expression in the bottom row. Right panel: Block (128128)\\ninpainting, using the LDM-VQ-4 model trained on FFHQ 256 [25]. Notice the glasses in the top row and eyes\\nin the bottom row.\\n          (a) Input                (b) Groundtruth              (c) DPS [11]               (d) PSLD (Ours)\\nFigure 4: Inpainting (random and box) results on out-of-distribution samples, 256  256 (see\\nAppendix C for image sources). We use PSLD with Stable Diffusion v-1.5 as generative foundation\\nmodel.\\n    0.20       PSLD                    '                                     '\\n    0.15                                           FSL                        0.75        FSLD\\n         Percentage of dropped pxels         Percentage    diopre                        Miane   'dropped\\nFigure 5: Comparing DPS and PSLD performance in random inpainting on FFHQ 256 [25, 11], as\\nthe percentage of masked pixels increases. PSLD with Stable Diffusion outperforms DPS.\\nSampling with Latent Diffusion (PSLD)  that experimentally outperforms state-of-art baselines on\\na wide variety of tasks including random inpainting, block inpainting, denoising, destriping, and\\nsuper-resolution.\\nLimitations. Our evaluation is based on Stable Diffusion which was trained on the LAION dataset.\\nBiases in this dataset and foundation model will be implicitly affecting our algorithm. Our method\\ncan work with any LDM and we expect new foundation models trained on better datasets like [19] to\\nmitigate these issues. Second, we have not explored how to use latent-based foundation models to\\nsolve non-linear inverse problems. Our method builds on the DPS approximation (which performs\\nwell on non-linear inverse problems), and hence we believe our method can also be similarly extended.\\n                                                        10\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='9ccd6011-ca92-4cb0-b96f-a87e58d03684', embedding=None, metadata={'page': 11}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Acknowledgements\\nThis research has been supported by NSF Grants 2019844, 2112471, AF 1901292, CNS 2148141,\\nTripods CCF 1934932, the Texas Advanced Computing Center (TACC) and research gifts by Western\\nDigital, Wireless Networking and Communications Group (WNCG) Industrial Affiliates Program,\\nUT Austin Machine Learning Lab (MLL), Cisco and the Stanly P. Finch Centennial Professorship in\\nEngineering. Litu Rout has been supported by the Ju-Nam and Pearl Chew Endowed Presidential\\nFellowship in Engineering. Giannis Daras has been supported by the Onassis Fellowship (Scholarship\\nID: F ZS 012-1/2022-2023), the Bodossaki Fellowship and the Leventis Fellowship. We thank the\\nHuggingFace team for providing us GPU support for the demo of our work.\\nReferences\\n  [1]  Brian D.O. Anderson. Reverse-time diffusion equation models. In: Stochastic Processes and\\n       their Applications 12.3 (1982), pp. 313326 (page 1).\\n  [2]  Marius Arvinte, Ajil Jalal, Giannis Daras, Eric Price, Alex Dimakis, and Jonathan I Tamir.\\n       Single-Shot Adaptation using Score-Based Models for MRI Reconstruction. In: International\\n       Society for Magnetic Resonance in Medicine, Annual Meeting. 2022 (page 2).\\n  [3]  Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie S Li, Hamid Kazemi, Furong Huang, Micah\\n       Goldblum, Jonas Geiping, and Tom Goldstein. Cold Diffusion: Inverting arbitrary image\\n       transforms without noise. In: arXiv preprint arXiv:2208.09392 (2022) (page 2).\\n  [4]  Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim, Sanja\\n       Fidler, and Karsten Kreis. Align your latents: High-resolution video synthesis with latent\\n       diffusion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and\\n       Pattern Recognition. 2023, pp. 2256322575 (page 3).\\n  [5]  Ashish Bora, Ajil Jalal, Eric Price, and Alexandros G Dimakis. Compressed sensing using\\n       generative models. In: International Conference on Machine Learning. PMLR. 2017, pp. 537\\n       546 (page 1).\\n  [6]  Stanley H Chan, Xiran Wang, and Omar A Elgendy. Plug-and-play ADMM for image restora-\\n       tion: Fixed-point convergence and applications. In: IEEE Transactions on Computational\\n       Imaging 3.1 (2016), pp. 8498 (pages 2, 8, 24, 27).\\n  [7]  Minshuo Chen, Kaixuan Huang, Tuo Zhao, and Mengdi Wang. Score Approximation, Esti-\\n       mation and Distribution Recovery of Diffusion Models on Low-Dimensional Data. In: arXiv\\n       preprint arXiv:2302.07194 (2023) (pages 5, 6).\\n  [8]  Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru R Zhang. Sampling is\\n       as easy as learning the score: theory for diffusion models with minimal data assumptions. In:\\n       arXiv preprint arXiv:2209.11215 (2022) (page 1).\\n  [9]  Sitan Chen, Giannis Daras, and Alexandros G Dimakis. Restoration-Degradation Beyond\\n       Linear Diffusions: A Non-Asymptotic Analysis For DDIM-Type Samplers. In: arXiv preprint\\n       arXiv:2303.03384 (2023) (page 1).\\n[10]   Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.\\n       Ilvr: Conditioning method for denoising diffusion probabilistic models. In: arXiv preprint\\n       arXiv:2108.02938 (2021) (page 2).\\n[11]   Hyungjin Chung, Jeongsol Kim, Michael Thompson Mccann, Marc Louis Klasky, and Jong\\n       Chul Ye. Diffusion Posterior Sampling for General Noisy Inverse Problems. In: The Eleventh\\n       International Conference on Learning Representations. 2023. URL: https://openreview.\\n       net/forum?id=OnD9zGAGT0k (pages 13, 710, 15, 18, 20, 22, 2431).\\n[12]   Hyungjin Chung, Jeongsol Kim, and Jong Chul Ye. Direct Diffusion Bridge using Data\\n       Consistency for Inverse Problems. In: arXiv preprint arXiv:2305.19809 (2023) (page 2).\\n[13]   Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, and Jong Chul Ye. Improving Diffusion\\n       Models for Inverse Problems using Manifold Constraints. In: Advances in Neural Information\\n       Processing Systems. Ed. by Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun\\n       Cho. 2022. URL: https://openreview.net/forum?id=nJJjv0JDJju (pages 2, 8, 24, 27,\\n       31).\\n[14]   Giannis Daras, Yuval Dagan, Alexandros G Dimakis, and Constantinos Daskalakis. Score-\\n       guided intermediate layer optimization: Fast langevin mixing for inverse problem. In: arXiv\\n       preprint arXiv:2206.09104 (2022) (page 2).\\n                                                  11', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='0ece1996-ca11-49c3-a69e-50bffb21cec6', embedding=None, metadata={'page': 12}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[15]   Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alexandros G Dimakis, and Peyman\\n       Milanfar. Soft diffusion: Score matching for general corruptions. In: arXiv preprint\\n       arXiv:2209.05442 (2022) (page 2).\\n[16]   Mauricio Delbracio and Peyman Milanfar. Inversion by direct iteration: An alternative\\n       to denoising diffusion for image restoration. In: arXiv preprint arXiv:2303.11435 (2023)\\n       (page 2).\\n[17]   Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-\\n       scale hierarchical image database. In: 2009 IEEE conference on computer vision and pattern\\n       recognition. Ieee. 2009, pp. 248255 (pages 7, 21, 22, 2729).\\n[18]   Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. In:\\n       Advances in Neural Information Processing Systems 34 (2021), pp. 87808794 (page 1).\\n[19]   Samir Yitzhak Gadre, Gabriel Ilharco, Alex Fang, Jonathan Hayase, Georgios Smyrnis, Thao\\n       Nguyen, Ryan Marten, Mitchell Wortsman, Dhruba Ghosh, Jieyu Zhang, et al. DataComp: In\\n       search of the next generation of multimodal datasets. In: arXiv preprint arXiv:2304.14108\\n       (2023) (page 10).\\n[20]   Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In:\\n       Advances in Neural Information Processing Systems 33 (2020), pp. 68406851 (page 1).\\n[21]   Aapo Hyvrinen and Peter Dayan. Estimation of non-normalized statistical models by score\\n       matching. In: Journal of Machine Learning Research 6.4 (2005) (page 1).\\n[22]   Ajil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G Dimakis, and Jon Tamir.\\n      Robust compressed sensing mri with deep generative priors. In: Advances in Neural Informa-\\n       tion Processing Systems 34 (2021), pp. 1493814954 (pages 1, 2).\\n[23]   Ajil Jalal, Sushrut Karmalkar, Alexandros G Dimakis, and Eric Price. Instance-optimal\\n       compressed sensing via posterior sampling. In: arXiv preprint arXiv:2106.11438 (2021)\\n       (page 1).\\n[24]   Ajil Jalal, Sushrut Karmalkar, Jessica Hoffmann, Alex Dimakis, and Eric Price. Fairness\\n       for Image Generation with Uncertain Sensitive Attributes. In: Proceedings of the 38th Inter-\\n       national Conference on Machine Learning. Ed. by Marina Meila and Tong Zhang. Vol. 139.\\n       Proceedings of Machine Learning Research. PMLR, 1824 Jul 2021, pp. 47214732. URL:\\n       https://proceedings.mlr.press/v139/jalal21b.html (page 1).\\n[25]   Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative\\n       adversarial networks. In: Proceedings of the IEEE/CVF conference on computer vision and\\n       pattern recognition. 2019, pp. 44014410 (pages 710, 2428, 31).\\n[26]   Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. Denoising Diffusion Restora-\\n       tion Models. In: Advances in Neural Information Processing Systems (pages 1, 2, 8, 24, 27,\\n       31).\\n[27]   Bahjat Kawar, Noam Elata, Tomer Michaeli, and Michael Elad. GSURE-Based Diffusion\\n       Model Training with Corrupted Data. In: arXiv preprint arXiv:2305.13128 (2023) (page 2).\\n[28]   Bahjat Kawar, Gregory Vaksman, and Michael Elad. SNIPS: Solving noisy inverse problems\\n       stochastically. In: Advances in Neural Information Processing Systems 34 (2021), pp. 21757\\n       21769 (page 31).\\n[29]   Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, and Il-Chul Moon. Soft\\n       truncation: A universal training technique of score-based diffusion model for high precision\\n       score estimation. In: International Conference on Machine Learning. PMLR. 2022, pp. 11201\\n       11228 (page 1).\\n[30]   Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, and\\n       Mark D Plumbley. Audioldm: Text-to-audio generation with latent diffusion models. In:\\n       arXiv preprint arXiv:2301.12503 (2023) (page 3).\\n[31]   Hongyu Liu, Bin Jiang, Yi Xiao, and Chao Yang. Coherent Semantic Attention for Image\\n       Inpainting. In: 2019 IEEE/CVF International Conference on Computer Vision (ICCV) (Oct.\\n       2019). DOI: 10.1109/iccv.2019.00427. URL: http://dx.doi.org/10.1109/ICCV.\\n       2019.00427 (page 1).\\n[32]   Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and Luc Van\\n       Gool. Repaint: Inpainting using denoising diffusion probabilistic models. In: Proceedings of\\n       the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 11461\\n       11471 (pages 7, 8, 30).\\n                                                 12', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='fedb9ac1-f877-4a21-b0ae-f0a66f5f9ab7', embedding=None, metadata={'page': 13}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[33]  Gary Mataev, Peyman Milanfar, and Michael Elad. DeepRED: Deep image prior powered\\n      by RED. In: Proceedings of the IEEE/CVF International Conference on Computer Vision\\n      Workshops. 2019, pp. 00 (page 1).\\n[34]  Xiangming Meng and Yoshiyuki Kabashima. Diffusion model based posterior sampling for\\n      noisy linear inverse problems. In: arXiv preprint arXiv:2211.12343 (2022) (pages 27, 31).\\n[35]  Sachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. Pulse: Self-\\n      supervised photo upsampling via latent space exploration of generative models. In: Proceed-\\n      ings of the ieee/cvf conference on computer vision and pattern recognition. 2020, pp. 2437\\n      2445 (page 1).\\n[36]  Gregory Ongie, Ajil Jalal, Christopher A Metzler, Richard G Baraniuk, Alexandros G Dimakis,\\n      and Rebecca Willett. Deep learning techniques for inverse problems in imaging. In: IEEE\\n      Journal on Selected Areas in Information Theory 1.1 (2020), pp. 3956 (page 1).\\n[37]  Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. Con-\\n      text encoders: Feature learning by inpainting. In: Proceedings of the IEEE conference on\\n      computer vision and pattern recognition. 2016, pp. 25362544 (page 1).\\n[38]  Walter HL Pinaya, Petru-Daniel Tudosiu, Jessica Dafflon, Pedro F Da Costa, Virginia Fernan-\\n      dez, Parashkev Nachev, Sebastien Ourselin, and M Jorge Cardoso. Brain imaging generation\\n      with latent diffusion models. In: Deep Generative Models: Second MICCAI Workshop,\\n      DGM4MICCAI 2022, Held in Conjunction with MICCAI 2022, Singapore, September 22,\\n      2022, Proceedings. Springer. 2022, pp. 117126 (page 3).\\n[39]  Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, and\\n      Daniel Cohen-Or. Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation.\\n      In: arXiv preprint arXiv:2008.00951 (2020) (page 1).\\n[40]  Yaniv Romano, Michael Elad, and Peyman Milanfar. The little engine that could: Regulariza-\\n      tion by denoising (RED). In: SIAM Journal on Imaging Sciences 10.4 (2017), pp. 18041844\\n      (pages 1, 31).\\n[41]  Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjrn Ommer.\\n      High-resolution image synthesis with latent diffusion models. In: Proceedings of the\\n      IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 1068410695\\n      (pages 2, 3, 5, 7).\\n[42]  Litu Rout, Advait Parulekar, Constantine Caramanis, and Sanjay Shakkottai. A Theoretical\\n      Justification for Image Inpainting using Denoising Diffusion Probabilistic Models. In: arXiv\\n      preprint arXiv:2302.01217 (2023) (pages 5, 6, 15).\\n[43]  Chitwan Saharia, William Chan, Huiwen Chang, Chris A. Lee, Jonathan Ho, Tim Salimans,\\n      David J. Fleet, and Mohammad Norouzi. Palette: Image-to-Image Diffusion Models. 2022.\\n      arXiv: 2111.05826 [cs.CV] (page 31).\\n[44]  Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton\\n      Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki. LAION-400M:\\n      Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs. 2021. arXiv: 2111.02114\\n      [cs.CV] (page 7).\\n[45]  Christoph Schuhmann et al. LAION-5B: An open large-scale dataset for training next genera-\\n      tion image-text models. 2022. arXiv: 2210.08402 [cs.CV] (page 7).\\n[46]  Jiaming Song, Arash Vahdat, Morteza Mardani, and Jan Kautz. Pseudoinverse-guided diffu-\\n      sion models for inverse problems. In: International Conference on Learning Representations.\\n      2023 (pages 2, 31).\\n[47]  Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data\\n      distribution. In: Advances in Neural Information Processing Systems 32 (2019) (page 1).\\n[48]  Yang Song and Stefano Ermon. Improved techniques for training score-based generative\\n      models. In: Advances in neural information processing systems 33 (2020), pp. 1243812448\\n      (page 1).\\n[49]  Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and\\n      Ben Poole. Score-Based Generative Modeling through Stochastic Differential Equations. In:\\n      International Conference on Learning Representations. 2021 (page 1).\\n[50]  Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and\\n      Ben Poole. Score-Based Generative Modeling through Stochastic Differential Equations. In:\\n      International Conference on Learning Representations (pages 8, 24, 27).\\n                                                    13', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='5dda07fc-8802-4cae-b40d-08b3bc749fb6', embedding=None, metadata={'page': 14}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[51]  Yu Takagi and Shinji Nishimoto. High-resolution image reconstruction with latent diffusion\\n      models from human brain activity. In: Proceedings of the IEEE/CVF Conference on Computer\\n      Vision and Pattern Recognition. 2023, pp. 1445314463 (page 3).\\n[52]  Singanallur V Venkatakrishnan, Charles A Bouman, and Brendt Wohlberg. Plug-and-play\\n      priors for model based reconstruction. In: 2013 IEEE Global Conference on Signal and\\n      Information Processing. IEEE. 2013, pp. 945948 (page 1).\\n[53]  Pascal Vincent. A connection between score matching and denoising autoencoders. In:\\n      Neural computation 23.7 (2011), pp. 16611674 (page 1).\\n[54]  Su Wang, Chitwan Saharia, Ceslee Montgomery, Jordi Pont-Tuset, Shai Noy, Stefano Pelle-\\n      grini, Yasumasa Onoe, Sarah Laszlo, David J Fleet, Radu Soricut, et al. Imagen editor and\\n      editbench: Advancing and evaluating text-guided image inpainting. In: Proceedings of the\\n      IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023, pp. 1835918369\\n      (pages 1, 21).\\n[55]  Yinhuai Wang, Jiwen Yu, and Jian Zhang. Zero-Shot Image Restoration Using Denoising\\n      Diffusion Null-Space Model. In: The Eleventh International Conference on Learning Repre-\\n      sentations. 2023. URL: https://openreview.net/forum?id=mRieQgMtNTQ (page 31).\\n[56]  Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas Huang. Free-Form\\n      Image Inpainting With Gated Convolution. In: 2019 IEEE/CVF International Conference\\n      on Computer Vision (ICCV) (Oct. 2019). DOI: 10.1109/iccv.2019.00457. URL: http:\\n      //dx.doi.org/10.1109/ICCV.2019.00457 (page 1).\\n                                                 14', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='cbb113ad-4130-409c-a89d-5efa343e6ee7', embedding=None, metadata={'page': 15}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=' A       Additional Theoretical Results\\n Notation and Measurement Matrix. We elaborate on the structure of the measurement matrix\\n A      Rld. In our setting, we are considering linear inverse problems. Thus, this matrix is a pixel\\n selector and consists of a subset of the rows from the d  d identity matrix (the rows that are present \\n correspond to the indices of the selected pixels from the image                                        x0       Rd). Given this structure, it\\n immediately follows that AT A is a d  d matrix that has the interpretation of a pixel selection mask.\\n Specifically, AT A is a d                d diagonal matrix D(m), where the elements of m are set to 1 where data\\n (pixel) is observed and 0 where data (pixel) is masked. Without the loss of generality, we suppose\\n that the first k coordinates are known.\\n A.1       Posterior Sampling using Pixel-space Diffusion Model\\n We first consider the reverse process, starting with                           x1      N (0, Id), and borrow a result from [42] to\\n show that the sample             x0generated by the reverse process is a valid image from p(                                     \\n                                                                                                                                    x0).\\n Theorem A.1 (Generative Modeling using Diffusion in Pixel Space, [42]). Suppose Assumption 3.1\\n holds. Let\\n                                                                                                                     2    .\\n                            = arg min     E   x0,        1     x1(  x0,  ),    x0             x1     x0, \\n                                                                         :=              \\n For a fixed variance  > 0, if                       x1     x0,                  x1     x0,       , then the closed-form solution      \\n is 1        SST , which after normalizationby 1/1                                  recovers the true subspace of p                      x0    .\\n Though this establishes that               x0 generated by the reverse process is a valid image from p(                                  x0), it is not\\n necessarily a sample from the posterior p(                        \\n                                                                    x0|y) that satisfies the measurements. To accomplish this\\n we perform one additional step of gradient descent for every step of the reverse process. This gives\\n us Algorithm 1, the DPS algorithm. The next theorem shows that the reverse SDE guided by these\\n measurements (3) recovers the true underlying sample5.\\n Theorem A.2 (Posterior Sampling using Diffusion in Pixel Space). Suppose Assumption 3.1 and\\n Assumption 3.2 hold. Let us denote by j, j = 1, . . . , r, the singular values of (AS)T (AS) and\\n                                                                                                                     2    .\\n                            = arg min     E   x0,        1     x1(  x0,  ),    x0             x1     x0, \\n Given a partially known image                                      \\n j                                                    x0       p( x0), a fixed variance  > 0, there exists a step size\\n   i = 1/2j for all the coordinates of                        x0 such that Algorithm 1 samples from the true posterior\\n p(                                                                                                   \\n    x0|y) and exactly recovers the groundtruth sample, i.e.,                                  x0 =    x0.\\n B       Technical Proofs\\n This section contains proofs of all the theorems and propositions presented in the main body of the\\n paper. For clarity, we restate the theorems more formally with precise mathematical details.\\n B.1       Proof of Theorem A.2\\n Theorem B.1 (Posterior Sampling using Diffusion in Pixel Space). Suppose Assumption 3.1 and\\n Assumption 3.2 hold. Let us denote by  = {j}k                                       j=1 the singular values of (AS)T (AS), i.e.\\n(AS)T (AS) = UV T := UD()V T , U                                        Rkk, V            Rkk and\\n                                                                                                                       2\\n                            = arg min                      1     x1(  x0,  ),    x0             x1    x0,                .\\n                                            E   x0,\\n      5While the DPS Algorithm [11] uses a scalar step size i at each step, this does not suffice for exact recovery.\\n However, by generalizing to allow a different step size per coordinate, we can show sample recovery. Thus, in\\n this section, we denote j         i to be the step size at step i and coordinate j, 1                     j     r. Also note that the step index\\n i is vacuous in this section, as we consider a two-step diffusion process (i.e., i is always 1).\\n                                                                              15', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='7f20f647-b13e-45b4-808f-ffdcee40233b', embedding=None, metadata={'page': 16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='                                                                   \\n Suppose    x0     p(x0). Given measurements y = A               x0 and a fixed variance              (0, 1), there exists a \\n matrix step size6  = (1/2)(SU)D(i)(SU)T , i = {j                        i = 1/j}k    j=1 for all the coordinates of         x0\\n such that Algorithm 1 samples from the true posterior p(                   \\n sample, i.e.,                                                            x0|y) and exactly recovers the groundtruth\\n                  x0 =   x0.\\n Proof. Our goal is to show that                                   \\n reverse process starts with               x0 =    x0, where     x0 is returned by Algorithm 1. Recall that the\\n                                     x1     N (0, Id) and generates the following:\\n                                                     A                 2\\n                            x0 =     x1      x1       x0( x1)     y   2\\n                                 =                  ASST               2\\n                                        x1      x1             x1     y   2  \\n                                                                                x1     y\\n                                 = SST    x1     2   ASST  T  ASST        \\n                                                                            x1     y\\n                                 = SST    x1     2SST AT  ASST          \\n                                                                          x1 + 2SST AT y\\n                                 = SST    x1     2SST AT ASST                                   \\n                                                                          x1 + 2SST AT A          x0\\n                                 = SST    x1     2SST AT ASST \\n                                 = SST                                                              \\n                                           x1     2SST AT ASST          x1 + 2SST AT AS           z0.\\n Now, we use the singular value decomposition of (AS)T (AS) with left singular vectors in U                                  Rkk,\\n right singular vectors in V            Rkk, and singular values  = [1, . . . , k] in  = D(). Thus, the\\n above expression becomes\\n                                                                       \\n       x0 = SST      x1     2SUV T ST         x1 + 2SUV T          z0\\n            = SST                                                       \\n                      x1     2SUV T ST         x1 + 2SUV T          z0\\n            = SST                                                                                                         \\n            (i)       x1     2(SU)D(i)(SU)T SUV T ST                    x1 + 2(SU)D(i)(SU)T SUV T                     z0\\n            = SST                                                                                                         \\n            (ii)      x1     2(SU)D(i)U T ST SUV T ST                   x1 + 2(SU)D(i)U T ST SUV T                    z0\\n            = SST                                                                                            \\n                       x1     2(SU)D(i)U T UU T ST                x1 + 2(SU)D(i)U T UU T                 z0\\n            = SST                                                                          \\n                      x1     2(SU)D(i)U T ST            x1 + 2(SU)D(i)U T              z0\\n            = SST                                                                                 \\n                      x1     2SUD(i)D()U T ST              x1 + 2SUD(i)D()U T                z0\\n            = SST                                                                             \\n                      x1     2SUD(i          )U T ST     x1 + 2SUD(i             )U T   z0,\\n where (i) is due to Assumption 3.1 and (ii) uses Assumption 3.2. By choosing j                            i as half the inverse\\n of the non-zero singular values of (AS)T (AS), i.e., j                 i = 1/2i i = 1, . . . , k, we obtain\\n                                                                                          \\n                                      x0 = SST      x1     SUU T ST      x1 + SUU T       z0\\n                                           = SST                                  \\n which completes the statement of the theorem.       x1     SST  x1 + S    z0 =  x0,                                            \\n B.2     Proof of Proposition 3.3\\n Proposition B.2 (Variational Autoencoder). Suppose Assumption 3.1 holds. For an encoder E :\\n Rd      Rk and a decoder D : Rk                Rd, denote by L (, ) the training objective of VAE:\\n                                                    D(E(                       2\\n             arg min                                         x0; ); )       \\n                   , L (, ) := E      x0p                                x0   2   + KL (Ep, N(0, Ik)) ,\\n then the combination of E(                                                      \\n     6                               x0; ) = ST     x0 and D(     z0; ) = S    z0 is a minimizer of L (, ).\\n      We use the term step size in a more general way than is normally used. In this case, the step size is a\\npre-conditioning positive definite matrix, whose eigenvalue magnitudes correspond to the scalar step sizes per\\n coordinate along an appropriately rotated basis. This general form is needed and with carefully selected (unique)\\n eigenvalues; otherwise the DPS algorithm fails to converge to the groundtruth sample. We will later see that for\\n our PSLD Algorithm in Theorem 3.6, we can revert to the commonly used notion of step size (a single scalar),\\n as any finite step size (including a single scalar common across all coordinates) suffices for proving recovery.\\n                                                                  16', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='b3956e9e-7895-42eb-b7b8-51e0443a121a', embedding=None, metadata={'page': 17}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='                                                                                                                                        \\nProof. To show that the encoder E(                        x0; ) = ST          x0 and the decoder D(                z0; ) = S        z0 minimize\\nthe VAE training objective L (, ), we begin with the first part of the loss, which is also called                                      \\nreconstruction error Lrecon (, ). Substituting E(                                                 x0 and D(       z0; ) = S        z0, we have\\n                                                                                  x0; ) = ST \\n                                                                               D(E(                             2\\n                                      Lrecon (, ) := E                                 x0; ); )          \\n                                                                    x0p                                       x0    2\\n                                                                              D(ST                         2\\n                                                            = E                          x0; )        \\n                                                                   x0p                                  x0     2\\n                                                                              SST                  2\\n                                                            = E                        x0      \\n                                                                   x0p                          x0     2\\nUsing the fact that           \\n                              x0 lives in a linear subspace, we arrive at\\n                                                                             SST S                     2\\n                                     Lrecon (, ) = E           x0p                    z0      Sz0     2\\n                                                           (i)                         S                 2\\n                                                           = E    z0N (0,Ik)              z0      S z0    2    = 0,\\nwhere (i) is due to Assumption 3.1. Now, we analyze the distribution loss. Note that the KL-\\ndivergence between two Gaussian distributions with moments (1, 1) and (2, 2) is given by\\n                        KL (N        (1, 1), N        (2, 2)) = log           2        + 2   1 + (1         2)2         1\\n                                                                                       1                    22  2                 2.\\nSince E (x0) = ST x0 = ST Sz0 = z0, the distribution loss becomes:\\n                        Ldist () := KL (Ep, N                   (0, Ik)) = KL (N              (0, Ik), N       (0, Ik)) = 0.\\nB.3       Proof of Theorem 3.4\\nTheorem B.3 (Generative Modeling using Diffusion in Latent Space). Suppose Assumption 3.1\\nholds. Let the optimal solution of the latent diffusion model be\\n                                                                                                                   2    .\\n                           = arg min     E    z0,        1    z1(  z0,  ),    z0            z1     z0, \\n                                                                         :=              \\nFor a fixed variance  > 0, if                         z1    z0,         1       z1     z0,       , then the closed-form solution is          :=\\n  = 1          Ik, which after normalization by                      1 and composition with the decoder D                            z0; \\nS z0 recovers the true subspace of p                       x0    .\\nProof. In latent diffusion models, the training is performed in the latent space of a pre-trained VAE. If\\nthe VAE is chosen from Proposition 3.3, then the training objective becomes:\\n                min                1(                                                                       2\\n                   E   x0,              z1     E( x0),  ), E(     x0)              z1     E( x0), \\n                        = E            1(                                                    2\\n                               z0,             z1     z0,  ),   z0             z1     z0, \\n                                                                        2                                                2\\n                        = E   z0,       z0           z1     z0,                = E   z0,        z0      z1     z0, \\n                                                                                          2\\n                        = E   z0,       z0    k     z0      1      +         \\n                                                                                                          2\\n                        =        E                     z0,i      T i    z0      1      +                      ,\\n                                 z0p            i=1\\n                             N (0,Ik)\\n                                                                             17', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='1f165523-5520-4c59-9c24-f2965470ed2c', embedding=None, metadata={'page': 18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='where T    i denotes the ith row of matrix . The solution of this regression problem is given by7\\ni = E  x0,      z0      1     +               z0     1      +          T  1     Ex0,      z0,i    z0      1     +         \\n     = E x0,      z0      1     +               z0     1      +          T  1     Ex0,      z0,i    z0      1     +         \\n     = E x0,      E(x0)        1      +              E(x0)        1      +          T  1     Ex0,      E(x0)i       E(x0)         1     +        \\n     = E z0,      E(Sz0)         1     +               E(Sz0)         1      +          T  1     Ez0,      E(Sz0)i        E(Sz0)          1     +     \\n     = E z0,      ST Sz0         1     +               ST Sz0         1     +           T  1     Ez0,     (ST Sz0)i         ST Sz0         1      +     \\nUsing Assumption 3.1, the above expression simplifies to\\ni = E  z0,      z0     1      +              z0      1     +           T  1     Ez0,     (z0)i      z0      1     +        \\n     = E z0,   (1     )z0zT    0 + z0T          (1       ) + zT    0     (1      ) + T  1          Ez0,     (z0)i      z0      1     +        \\n     =       (1     ) E z0,   z0zT  0    + Ez0,    z0T          (1      ) + E  z0,    zT 0       (1      ) +  E   z0,    T    1\\n                                                                     Ez0,       (z0)i      z0     1      +        \\n     =       (1     )Ik + E    z0 [z0] E   []T       (1      ) + E    [] Ez0 [z0]T        (1      ) + Ik         1\\n                                                                     Ez0,       (z0)i      z0     1      +              ,\\nwhere the last step uses the fact that z0 and  are independent Gaussian random vectors with zero\\nmean and unit covariance. Simplifying further, we arrive at\\n                          i = [(1        )Ik + Ik]1 Ez0,               (z0)i      z0     1     +         \\n                               = Ez0,       (z0)i      z0      1     +        \\n                               = Ez0       (z0)iz0        1         + Ez0,       (z0)i       \\n                               = Ez0       (z0)iz0        1         + Ez0 [(z0)i] E []             .\\nThe final step follows from independence of z0 and . Since z0 and  are also N (0, Ik), we get\\n                          i = Ez0        (z0)iz0        1         =     0, . . . , 0,    1    , 0, . . . , 0  T   ,\\nwhere the ith coordinate is 1                      and zero everywhere else. Therefore, stacking all the rows\\ntogether, we get           = 1         Ik, which after normalization by 1/1                           gives the desired result.\\nNext, we show that                 recovers the true subspace of                              \\n                                                                                    x0       p   x0    . When composed with the\\ndecoder of VAE, the generator of the LDM gives                              x0= D                                             \\n                                                                                               z1     = D       Ik z1     = S   z1. Since\\nz1      N (0, Ik), this completes the statement of the theorem.                                                                                 \\nB.4      Proof of Theorem 3.5\\nRecall that the the latent-space GML-DPS (6) algorithm (based on the pixel-space DPS algorithm\\n[11]) has three key steps. In the first step, it uses the normalized closed-form solution obtained in\\n    7 For ease of notation, we drop the forward arrow in the rest of this proof.\\n                                                                        18', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='9529bc17-3e2b-4cae-a11d-066b6e0e5470', embedding=None, metadata={'page': 19}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=' Theorem 3.4 to perform one step of denoising by the reverse SDE. In the second step, it runs one\\n step of gradient descent to satisfy the measurements in the pixel space. Finally, it takes one step of\\n gradient descent on the goodness objective, which acts as a regularizer to ensure that the reconstructed\\n image lies on the data manifold.\\n This can be formalized as:\\n                                                                    AD(                     2\\n                                         z0 =     z1       z1           z0( z1))      y   2 ;                                     (8)\\n                                                                                     2\\n                                                              z               z\\n                                         z0 = arg min           0     E(D(      0))    2 ,                                               (9)\\n                                                         z\\n                                                          0\\n In practice, solving (9) can be difficult, and can be approximated via gradient descent. In our analysis\\n however, we analyze the exact system of equations above, as (9) has a closed-form solution in the\\n linear setting.\\n Theorem B.4 (Posterior Sampling using Goodness Modified Latent DPS). Suppose Assumptions 3.1\\n and Assumption 3.2 hold. Denote by  = {j}k                                j=1 the singular values of (AS)T (AS), i.e.,\\n(AS)T (AS) = UU T := UD()U T , U                                Rkk, and let                    \\n                                                                                                          2\\n Suppose              = arg min    E   z0,      1    z1(  z0, ),  z0           z1    z0,         2   .\\n              x0      p(x0). Given measurements y = A                   x0 and any fixed variance                   (0, 1), then with\\n the (unique) step size  = (1/2)UD(i)U T , i = {j                          i = 1/2j}k       j=1, the GML-DPS algorithm (6)\\n samples from the true posterior p(                                                                                                      \\n                                                  x0|y) and exactly recovers the groundtruth sample, i.e.,                        x0 =    x0.\\n Proof. We start with the measurement consistency update (8) and then show that the solution obtained\\n from (8) is already a minimizer of (9). Therefore, we have\\n                                                                 AD(                      2\\n                                      z0 =     z1       z1           z0( z1))      y    2\\n                                           = Ik                   AD(Ik                 2\\n                                                  z1        z1               z1)     y   2\\n                                           =                  AS               2\\n                                               z1       z1         z1)      y   2\\n                                           =                  AS               2\\n                                               z1       z1         z1)      y   2\\n                                           (i)                  AS             2\\n                                           =  z1        z1         z1     y   2\\n                                           =                                \\n                                               z1     2ST AT  AS          z1     y\\n                                           =                             \\n                                               z1     2ST AT AS        z1 + 2ST AT y\\n                                           =                                                     \\n                                               z1     2ST AT AS        z1 + 2ST AT A          x0\\n                                           =                                                       \\n                                               z1     2ST AT AS        z1 + 2ST AT AS            z0,\\n where (i) is due to Assumption 3.1. By Assumption 3.2, (AS)T (AS) is a positive definite matrix\\n and can be written as UU T :\\n                                                                               \\n                          z0 =   z1     2UU T        z1 + 2UU T          z0\\n                               =                                                                                \\n                                   z1     2UD(i)U T UU T               z1 + 2UD(i)U T UU T                  z0\\n                               =                                                              \\n                                   z1     2UD(i)U T           z1 + 2UD(i)U T              z0\\n                               =                                                                           \\n                                   z1     2UD(i)D()U T              z1 + 2UD(i)D()U T                  z0\\n                               =                                                                       \\n                                   z1     2UD(i           )U T   z1 + 2UD(i              )U T    z0.\\n Since i  j = 1/2j, the above expression further simplifies to\\n                                                                                           \\n Next, we show that                       z0 =   z1     UU T    z1 + UU T       z0 =    z0.\\n                              z0 is already a minimizer of (9). This is a direct consequence of the encoder-\\n                                                                                                                          2\\n decoder architecture of the VAE: E(D(                  z                 z      z                  z0    E(D(0))z         = 0, and\\n                                                           0)) = ST S0 = 0. Hence,\\n                                                                       19', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='ac9c9bcc-4e20-4925-ac2d-bdd507f63bf1', embedding=None, metadata={'page': 20}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=' consequently                                                     2      \\n                     z0 =   z0      z0    z0    E(D(0))z         =  z0. Thus, the reconstructed sample becomes\\n                               \\n x0 = D(     z0) = S    z0 =    x0.\\n                                                 2                   \\n Furthermore, as           z0    E(D(   z0))       = 0 for all    z0, it is evident that the goodness objective cannot\\n rectify the error incurred in the measurement update (8). For this reason, GML-DPS algorithm (6)\\n requires the exact step size to sample from the posterior.                                                                                  \\n Beyond the linear setting, we also refer to Table 5 for experiments supporting this result.\\n B.5     Proof of Theorem 3.6\\n Different from GML-DPS, PSLD Algorithm 2 replaces the goodness objective (6) with the gluing\\n objective (7), which can be formalized as:\\n                                                       AD(                      2\\n                             z0 =     z1       z1           z0( z1))      y   2 ;                                               (10)\\n                                                                                                         2\\n                             z0 = arg min         z0     E(AT A    z0 + (Id         AT A)D(z       0))    2 .                      (11)\\n                                             z\\n                                              0\\nWe again remind that solving the minimization problem (11) is hard in general, and can be approxi-\\n mated by gradient descent as typically followed in practice [11]. However, in a linear model setting,\\n (11) has a closed-form solution which we derive to prove exact recovery.\\n Theorem B.5 (Posterior Sampling using Diffusion in Latent Space). Let Assumptions 3.1 and 3.2\\n hold. Let j, j = 1, . . . , r denote the singular values of (AS)T (AS) and let\\n                                                                                                    \\n                                                                                                          2\\n                         = arg min    E   z0,      1    z1(  z0,  ),  z0           z1    z0,             .\\n                                                                       \\n Suppose    x0      p(x0). Given measurements y = A                  x0, any fixed variance              (0, 1), and any positive\\n                                                                                                                                  \\n step sizes j   i , j = 1, 2, . . . , r, the PSLD Algorithm 2 samples from the true posterior p(                               x0|y) and\\n exactly recovers the groundtruth sample, i.e.,                  x0=     \\n                                                                           x0.\\n Proof. Following the proof in Appendix B.4, we have\\n                                                                 AD(                      2\\n                                       z0 =    z1       z1           z0( z1))      y    2\\n                                           = Ik                   AD(                2\\n                                                   z1       z1           z1)     y    2\\n                                           =                  AS              2\\n                                               z1       z1         z1      y   2\\n                                           =                               \\n                                               z1     2ST AT (AS         z1     y)\\n                                           =                                                       \\n                                               z1     2ST AT AS        z1 + 2ST AT AS            z0\\n                                           =                                                       \\n                                               z1     2ST AT AS        z1 + 2ST AT AS            z0.\\nWe use the above expression to derive a closed-form solution to the minimization problem (11):\\n                                                                                   2\\n            0 =     z0   z0    ST (AT AS       z0 + (Id         AT A)Sz      0)   2 2\\n                                                                                  \\n                =   z0   z0    ST AT AS       z0     ST (Id       AT A)Sz      0)   2   2\\n                                                                                    \\n                =   z0   z0    ST AT AS       z0     ST Sz   0    ST AT AS        z0)  22\\n                                                                                    \\n                =   z0   z0    ST AT AS       z0     ST Sz   0 + ST AT AS          z0)   2\\n                                                                                                                        \\n                = 2    Ik     ST S + ST AT AS                 z0    ST AT AS      z0     ST Sz    0 + ST AT AS         z0)\\n                                                                            \\n                = 2ST AT AS            ST AT ASz       0     ST AT AS      z0)     ,\\n where the last step is due to Assumption 3.1. Thus, we have\\n                                                                                                         2     \\n                                                                                                                z0,\\n                         z0 = arg min         z0     E(AT A    z0 + (Id         AT A)D(z       0))    2 = \\n                                         z\\n                                          0\\n                                                                       20', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='d76a95b3-bfac-464d-85b7-220a89bc03f0', embedding=None, metadata={'page': 21}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='which produces                                 \\n                 x0 = D( z0) = D(  z0) = S z0 = x0.                                               \\nIt is worth highlighting that PSLD exactly recovers the groundtruth sample irrespective of the choice\\nof the step size , whereas GML-DPS requires the step size to be exactly  = (1/2)UD(i)U T .\\nC    Additional Experiments\\nC.1   Implementation Details\\nFor inpainting tasks, we note that the PSLD sampler generates missing parts (by design of our gluing\\nobjective) that are consistent with the known portions of the image, i.e.,                \\nAT A)D(                                                                      x0 = AT A  x0 + (Id \\n          z0). This is different from the DPS sampler, which generates the whole image which\\nmay not match the observations exactly. In other words, in the last of step of our algorithm, the\\nobservations are glued onto the corresponding parts of the generated image, leaving the unmasked\\nportions untouched [54]. This sometimes creates edge effects which are then removed by post-\\nprocessing the glued image through the encoder and decoder of the SD model, i.e. running one last\\nstep of our algorithm. Figure 2 illustrates that gluing the observations in commercial services still\\nleads to visually inconsistent results (e.g. head in top row) unlike our method.\\nFor all other tasks, such as motion deblur, Gaussian deblur, and super-resolution, this last step is not\\nneeded, as there is no box inpainting, i.e.,        \\n                                            x0 = D( z0). Furthermore, we use the same measurement\\noperator A and its transpose AT as provided by the DPS code repository8. However, since Stable\\nDiffusion v1.5 generates images of size 512  512 resolution and DPS operates at 256  256, we\\nadjust the size of the kernels used in PSLD to ensure that both the methods use the same amount of\\ninformation while sampling from the posterior. During evaluation, we downsample PSLD generated\\nimages from 512  512 to 256  256 to compare with DPS at the same resolution.\\nPSLD (Stable Diffusion-V1.5 ): We run Algorithm 2 with Stable Diffusion version 1.5 as the\\nfoundation model9. We use a fixed  = 1 and  = 0.1. Since we study posterior sampling of images\\nwithout conditioning on text inputs, we pass an empty string to the Stable Diffusion foundation model,\\nwhich accepts texts as an input argument. For better performance, we recommend using the latest\\npretrained weights.\\nPSLD (LDM-VQ-4 ): This is the same sampling algorithm as before but with a different latent\\ndiffusion model, LDM-VQ-410 , which contains pretrained weights for FFHQ 25611 and large-scale\\ntext-to-image generative model12. We keep the hyperparameters same ( = 1 and  = 0.1). For each\\ntask, we provide hyper-parameter details in our codebase13. Although we have tested our framework\\nwith these two latent-diffusion-models, one may experiment with other latent-diffusion-models\\navailable in the same repository.\\nDPS: We use the original source code provided by the authors14.\\nOOD images are sourced online:\\n      1. Figure 1: the original images are generated by Stable Diffusion v-2.115.\\n      2. Figure 2 first row: Walking example from the web.\\n      3. Figure 2 second row, Obama-Biden image from the web.\\n      4. Figure 2 third row, Fisherman from ImageNet 256 [17].\\n      5. Figure 4 first row: Racoon image from the web.\\n      6. Figure 4 second row: Fisherman from ImageNet 256 [17].\\n      7. Figure 15: Celebrity face from the web.\\n   8https://github.com/DPS2022/diffusion-posterior-sampling/blob/main/guided_\\ndiffusion/measurements.py\\n   9https://huggingface.co/runwayml/stable-diffusion-v1-5\\n  10https://github.com/CompVis/latent-diffusion\\n  11https://ommer-lab.com/files/latent-diffusion/ffhq.zip\\n  12https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt\\n  13https://github.com/LituRout/PSLD\\n  14https://github.com/DPS2022/diffusion-posterior-sampling\\n  15https://huggingface.co/spaces/stabilityai/stable-diffusion\\n                                                   21', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='ec182459-bc26-4689-aa49-b1dc8e2aba8d', embedding=None, metadata={'page': 22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='                                            PSLD Marc Inpilintin?\\nFigure 6: Results from the web application of our PSLD algorithm, 512  512. The original image\\n(1) is generated by Stable Diffusion v-2.1 with the prompt,A dinner date between a robot couple\\nduring sunset.\\nC.2   Additional Experimental Evaluation\\nHere, we provide additional results to support our theoretical claims on various inverse problems.\\nFigures 6, 7, 8, and 9 show the inpainting results of user defined masks obtained from our PSLD\\ninpainting web demo. Note that the foundation model used in this demo is a generic model. For\\nbetter performance on specific images, we recommend finetuning the foundation model on this class\\nand then running posterior sampling using our web demo: https://huggingface.co/spaces/\\nPSLD/PSLD.\\nFigure 10 and 11 illustrate super-resolution (4) of in-distribution samples from the validation set of\\nFFHQ 256. Observe that the samples generated by DPS are far from the groundtruth sample. On the\\nother hand, the samples generated by PSLD closely capture the perceptual quality of the groundtruth\\nsample. In other words, one may identify (b) and (c) as images of two different individuals, whereas\\n(b) and (d) of the same individual. We attribute this photorealism of our method to the power of\\nStable Diffusion foundation model and the ability to use the knowledge of the VAE encoder-decoder\\nin the gluing objective.\\nIn addition, we test on out-of-distribution samples from ImageNet [17] validation set. Figure 12\\nand Figure 13 show the results in motion deblur and Gaussian deblur, respectively. By leveraging\\nthe foundation model Stable Diffusion v1.5, our PSLD method clearly outperforms DPS [11] in the\\ngeneral domain. Further, Figures 14, 15, and 16 show reconstruction of general domain samples\\nfor random inpainting, super-resolution, and destriping tasks, respectively. In all these tasks, the\\nsamples generated by PSLD are closer to the groundtruth sample than the ones generated by DPS.\\nFigure 17 shows the results on image colorization. Table 5 and Table 6 show the quantitative results.\\nTable 7 draws a comparison between the latent-DPS and PSLD algorithms, and shows that the PSLD\\nobjective enhances the reconstruction performance.\\nIn Table 8, we compare the runtime and NFEs of PSLD with prior works. PSLD-SD (trained on\\nLAION-5B) takes 776 s to generate 512x512 images. To compare with other methods that generate\\n256x256 images, we divide our runtime by 4. All the other methods use diffusion models trained on\\nFFHQ and produce 256x256 images.\\n                                                  22', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='658330ef-59d8-4b4a-8c80-d8e984c43295', embedding=None, metadata={'page': 23}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='                                                  PSLD Imaze Inpainting\\nFigure 7: Results from the web application of our PSLD algorithm, 512  512. The original image\\n(1) is generated by Stable Diffusion v-2.1 with the prompt,A panda wearing a spiderman costume.\\n                                                 PSLD ImageInpalntng\\nFigure 8: Results from the web application of our PSLD algorithm, 512  512. The original image\\n(1) is generated by Stable Diffusion v-2.1 with the prompt,A teddy bear showing stop sign at the\\ntraffic.\\n                                                          23', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='9b4fcdd5-8d64-4290-aea6-5d7c44428a0a', embedding=None, metadata={'page': 24}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='                                                    Inpalnting\\n                                           PSLD Imaze\\nFigure 9: Results from the web application of our PSLD algorithm, 512  512. The original image\\n(1) is generated by Stable Diffusion v-2.1 with the prompt,A cute dog playing with a toy teddy bear\\non the lawn.\\nTable 5: Quantitative random inpainting results on FFHQ 256 validation set [25, 11]. We use Stable\\nDiffusion (v1.5) trained on LAION.\\n                            Inpaint (random)              SR (4)               Gaussian Deblur\\n   Method                PSNR ()     SSIM ()     PSNR ()     SSIM ()     PSNR ()     SSIM ()\\n   PSLD (Ours)           33.71        0.943        30.73        0.867        30.10        0.843\\n   GML-DPS (Ours)        29.49        0.844        29.77        0.860        29.21        0.820\\n   DPS [11]              25.23        0.851        25.67        0.852        24.25        0.811\\n   DDRM [26]             9.19         0.319        25.36        0.835        23.36        0.767\\n   MCG [13]              21.57        0.751        20.05        0.559        6.72         0.051\\n   PnP-ADMM [6]          8.41         0.325        26.55        0.865        24.93        0.812\\n   Score-SDE [50]        13.52        0.437        17.62        0.617        7.12         0.109\\n   ADMM-TV               22.03        0.784        23.86        0.803        22.37        0.801\\nD     Additional Discussion\\nCurse of ambient dimension: DPS [11] suffers from the curse of ambient dimension because in\\nthis method, gradients are computed in the pixel space with dimension d. However, latent-based\\nmethods such as PSLD compute gradients in the latent dimension k, and hence the computation\\nis more efficient. Furthermore, applying the chain rule on VAE and running diffusion in the latent\\nspace is less expensive than running diffusion in pixel space directly. In practice, the computational\\ncomplexity of Stable Diffusion model (     4GB) is higher (roughly 6 times) than the computational\\ncomplexity of the encoder-decoder model (       700MB). Therefore, applying the chain rule in the\\nencoder-decoder and running diffusion in the latent space is less expensive than applying diffusion\\nmodels in the pixel space directly.\\n                                                  24', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='35f59350-5a1b-45cf-8ec5-ff4366dea8c5', embedding=None, metadata={'page': 25}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='                    (a) Input                                        (b) Groundtruth\\n                  (c) DPS [11]                                      (d) PSLD (Ours)\\nFigure 10: Super-resolution results on images from FFHQ 256 [25, 11] (in distribution).\\n                                                  25', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='dfdac3a2-7a09-4196-b4f8-47016ef86fcc', embedding=None, metadata={'page': 26}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='            (a) Input                                        (b) Groundtruth\\n          (c) DPS [11]                                      (d) PSLD (Ours)\\nFigure 11: Super-resolution results on FFHQ 256 [25, 11] (in distribution).\\n                                          26', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='c13d97b8-4a8f-47d3-853e-ac28f4125160', embedding=None, metadata={'page': 27}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='(a) Input                (b) Groundtruth                (c) DPS [11]                (d) PSLD (Ours)\\n   Figure 12: Motion deblur results on ImageNet 256 [17] (out-of-distribution).\\n   Table 6: Additional quantitative results on FFHQ 256 validation set [25, 11].\\n                                       SR (4)                   Gaussian Deblur\\n     Method                   FID ()        LPIPS ()       FID ()        LPIPS ()\\n     PSLD (Ours)              34.28          0.201           41.53          0.221\\n     DPS [11]                 39.35          0.214           44.05          0.257\\n     DDRM [26]                62.15          0.294           74.92          0.332\\n     MCG [13]                 87.64          0.520           101.2          0.340\\n     PnP-ADMM [6]             66.52          0.353           90.42          0.441\\n     Score-SDE [50]           96.72          0.563           109.0          0.403\\n     ADMM-TV                  110.6          0.428           186.7          0.507\\n                                       SR (4)                   Gaussian Deblur\\n     Method                   PSNR ()       SSIM ()        PSNR ()       SSIM ()\\n     PSLD (Ours)              30.73          0.867           30.10          0.843\\n     GML-DPS (Ours)           29.77          0.860           29.21          0.820\\n     DMPS [34]                27.63          -               25.41          -\\n     DPS [11]                 25.67          0.852           24.25          0.811\\n     DDRM [26]                25.36          0.835           23.36          0.767\\n     MCG [13]                 20.05          0.559           6.72           0.051\\n     PnP-ADMM [6]             26.55          0.865           24.93          0.812\\n     Score-SDE [50]           17.62          0.617           7.12           0.109\\n     ADMM-TV                  23.86          0.803           22.37          0.801\\n                                               27', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='ddeb05e8-d740-42b6-8ca6-da3d6afb34e9', embedding=None, metadata={'page': 28}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='          (a) Input                (b) Groundtruth              (c) DPS [11]               (d) PSLD (Ours)\\n            Figure 13: Gaussian deblur results on ImageNet 256 [17] (out-of-distribution).\\nTable 7: Latent-DPS and PSLD methods evaluated on FFHQ 256 validation set [25, 11]. We use the\\nlatent diffusion (LDM-VQ-4) trained on FFHQ 256. Latent-DPS is a special case of PSLD algorithm\\nwhen  = 0.\\n                                                         Inpaint (box)\\n                               Method        PSNR ()      SSIM ()     LPIPS ()\\n                               PSLD          24.22         0.819        0.158\\n                               latent-DPS    17.58         0.780        0.21\\n                                                        28', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='dbdf795f-d8fb-4685-b14d-4fa87802dc00', embedding=None, metadata={'page': 29}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='(a) Input                (b) Groundtruth              (c) DPS [11]               (d) PSLD (Ours)\\nFigure 14: Random inpainting results on ImageNet 256 [17] (out-of-distribution).\\n                                              29', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='11cfdb56-d161-494c-8afc-9c50014157cf', embedding=None, metadata={'page': 30}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='          (a) Input                (b) Groundtruth              (c) DPS [11]               (d) PSLD (Ours)\\nFigure 15: Super-resolution (using nearest neighbor kernel from [32]) results on out-of-distribution\\nsamples from the web, 256  256 (see Table 1 for LPIPS of these images).\\n          (a) Input                (b) Groundtruth              (c) DPS [11]               (d) PSLD (Ours)\\nFigure 16: Destriping results on out-of-distribution samples from the web, 256  256. (Top row)\\nHorizontal destriping: LPIPS of PSLD=0.244 and DPS [11]=0.613. (Bottom row) Vertical destriping:\\nLPIPS of PSLD=0.255, DPS [11]=0.597.\\n                                                        30', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), TextNode(id_='ab647c5e-209c-4e29-9fdb-3d4525e179e7', embedding=None, metadata={'page': 31}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='          (a) Input                (b) Groundtruth              (c) DPS [11]               (d) PSLD (Ours)\\nFigure 17: Additional colorization results on images from FFHQ 256 [25, 11]. PSLD generates\\nphoto-realistic color, whereas DPS [11] generates overly saturated images.\\nTable 8: Runtime (top) and NFEs (bottom) of different posterior sampling algorithms. Runtimes are\\ncomputed for the super-resolution task.\\n                               Method                               Runtime (s)\\n                               PSLD-LDM                             187.00\\n                               PSLD-LDM (LAION-400M)                190.00\\n                               PSLD-SD (LAION-5B)                   194.25\\n                               DMPS [34]                            67.02\\n                               DPS [11]                             180.00\\n                               DDNM+ [55]                           18.5\\n                               DDRM [26]                            2.15\\n                               MCG [13]                             193.71\\n                               Method                               NFEs\\n                               PSLD (Ours)                          100 to 1000\\n                               DPS [11]                             1000\\n                               DDRM [26]                            20\\n                               RED [40]                             500\\n                               GDM [46]                            20 to 100\\n                               Palette [43]                         1000\\n                               Regression                           1\\n                               SNIPS [28]                           1000\\n                                                        31', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
          ]
        }
      ],
      "source": [
        "print(text_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkqEQTAGv1Gi"
      },
      "source": [
        "## Extract/Index images from Image Dict\n",
        "\n",
        "here we use a multimodal to extract and index images from image dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6XW8d3yvf-d"
      },
      "outputs": [],
      "source": [
        "# call get_images on parser, convert to ImageDocuments\n",
        "!mkdir llama2_images\n",
        "\n",
        "from llama_index.core.schema import ImageDocument\n",
        "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
        "\n",
        "\n",
        "def get_image_text_nodes(json_objs: List[dict]):\n",
        "    \"\"\"Extract out text from images using a multimodal model.\"\"\"\n",
        "    openai_mm_llm = OpenAIMultiModal(max_tokens=500)\n",
        "    image_dicts = parser.get_images(json_objs, download_path=\"llama2_images\")\n",
        "    image_documents = []\n",
        "    img_text_nodes = []\n",
        "    for image_dict in image_dicts:\n",
        "        image_doc = ImageDocument(image_path=image_dict[\"path\"])\n",
        "        response = openai_mm_llm.complete(\n",
        "            prompt=\"Describe the images as an alternative, informative text\",\n",
        "            image_documents=[image_doc],\n",
        "        )\n",
        "        text_node = TextNode(\n",
        "            text=str(response),\n",
        "            metadata={\"path\": image_dict[\"path\"]}\n",
        "        )\n",
        "        img_text_nodes.append(text_node)\n",
        "    return img_text_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfhRmHz7wbVt",
        "outputId": "4081cbdf-d3e0-49fd-b2b2-796c344406ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Image for page 1: []\n",
            "> Image for page 2: [{'name': 'page-2-4.jpg', 'height': 119, 'width': 119, 'x': 246, 'y': 191}, {'name': 'page-2-0.jpg', 'height': 119, 'width': 119, 'x': 125, 'y': 72}, {'name': 'page-2-1.jpg', 'height': 119, 'width': 119, 'x': 246, 'y': 72}, {'name': 'page-2-8.jpg', 'height': 119, 'width': 119, 'x': 367, 'y': 311}, {'name': 'page-2-6.jpg', 'height': 119, 'width': 119, 'x': 125, 'y': 311}, {'name': 'page-2-3.jpg', 'height': 119, 'width': 119, 'x': 125, 'y': 191}, {'name': 'page-2-2.jpg', 'height': 119, 'width': 119, 'x': 367, 'y': 72}, {'name': 'page-2-9.jpg', 'height': 119, 'width': 119, 'x': 125, 'y': 431}, {'name': 'page-2-7.jpg', 'height': 119, 'width': 119, 'x': 246, 'y': 311}, {'name': 'page-2-5.jpg', 'height': 119, 'width': 119, 'x': 367, 'y': 191}, {'name': 'page-2-11.jpg', 'height': 119, 'width': 119, 'x': 367, 'y': 431}, {'name': 'page-2-10.jpg', 'height': 119, 'width': 119, 'x': 246, 'y': 431}]\n",
            "> Image for page 3: []\n",
            "> Image for page 4: []\n",
            "> Image for page 5: []\n",
            "> Image for page 6: []\n",
            "> Image for page 7: []\n",
            "> Image for page 8: []\n",
            "> Image for page 9: [{'name': 'page-9-3.jpg', 'height': 76, 'width': 76, 'x': 346, 'y': 72}, {'name': 'page-9-4.jpg', 'height': 76, 'width': 76, 'x': 423, 'y': 72}, {'name': 'page-9-2.jpg', 'height': 76, 'width': 76, 'x': 268, 'y': 72}, {'name': 'page-9-6.jpg', 'height': 76, 'width': 76, 'x': 190, 'y': 148}, {'name': 'page-9-5.jpg', 'height': 76, 'width': 76, 'x': 112, 'y': 148}, {'name': 'page-9-1.jpg', 'height': 76, 'width': 76, 'x': 190, 'y': 71}, {'name': 'page-9-0.jpg', 'height': 76, 'width': 76, 'x': 112, 'y': 71}, {'name': 'page-9-8.jpg', 'height': 76, 'width': 76, 'x': 346, 'y': 148}, {'name': 'page-9-7.jpg', 'height': 76, 'width': 76, 'x': 268, 'y': 148}, {'name': 'page-9-9.jpg', 'height': 76, 'width': 76, 'x': 423, 'y': 148}, {'name': 'page-9-11.jpg', 'height': 76, 'width': 76, 'x': 190, 'y': 224}, {'name': 'page-9-12.jpg', 'height': 76, 'width': 76, 'x': 268, 'y': 224}, {'name': 'page-9-10.jpg', 'height': 76, 'width': 76, 'x': 112, 'y': 224}, {'name': 'page-9-13.jpg', 'height': 76, 'width': 76, 'x': 346, 'y': 224}, {'name': 'page-9-14.jpg', 'height': 76, 'width': 76, 'x': 423, 'y': 224}]\n",
            "> Image for page 10: [{'name': 'page-10-1.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 239}, {'name': 'page-10-2.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 239}, {'name': 'page-10-0.jpg', 'height': 107, 'width': 400, 'x': 108, 'y': 71}, {'name': 'page-10-8.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 335}, {'name': 'page-10-4.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 239}, {'name': 'page-10-3.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 239}, {'name': 'page-10-6.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 335}, {'name': 'page-10-5.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 335}, {'name': 'page-10-7.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 335}, {'name': 'page-10-11.jpg', 'height': 79, 'width': 127, 'x': 371, 'y': 502}, {'name': 'page-10-10.jpg', 'height': 80, 'width': 127, 'x': 242, 'y': 502}, {'name': 'page-10-9.jpg', 'height': 82, 'width': 127, 'x': 113, 'y': 500}]\n",
            "> Image for page 11: []\n",
            "> Image for page 12: []\n",
            "> Image for page 13: []\n",
            "> Image for page 14: []\n",
            "> Image for page 15: []\n",
            "> Image for page 16: []\n",
            "> Image for page 17: []\n",
            "> Image for page 18: []\n",
            "> Image for page 19: []\n",
            "> Image for page 20: []\n",
            "> Image for page 21: []\n",
            "> Image for page 22: [{'name': 'page-22-0.jpg', 'height': 259, 'width': 396, 'x': 108, 'y': 72}]\n",
            "> Image for page 23: [{'name': 'page-23-0.jpg', 'height': 258, 'width': 396, 'x': 108, 'y': 86}, {'name': 'page-23-1.jpg', 'height': 257, 'width': 396, 'x': 108, 'y': 409}]\n",
            "> Image for page 24: [{'name': 'page-24-0.jpg', 'height': 257, 'width': 396, 'x': 108, 'y': 71}]\n",
            "> Image for page 25: [{'name': 'page-25-1.jpg', 'height': 179, 'width': 179, 'x': 307, 'y': 192}, {'name': 'page-25-0.jpg', 'height': 179, 'width': 179, 'x': 126, 'y': 192}, {'name': 'page-25-2.jpg', 'height': 179, 'width': 179, 'x': 126, 'y': 387}, {'name': 'page-25-3.jpg', 'height': 179, 'width': 179, 'x': 307, 'y': 387}]\n",
            "> Image for page 26: [{'name': 'page-26-0.jpg', 'height': 179, 'width': 179, 'x': 126, 'y': 192}, {'name': 'page-26-3.jpg', 'height': 179, 'width': 179, 'x': 307, 'y': 387}, {'name': 'page-26-1.jpg', 'height': 179, 'width': 179, 'x': 307, 'y': 192}, {'name': 'page-26-2.jpg', 'height': 179, 'width': 179, 'x': 126, 'y': 387}]\n",
            "> Image for page 27: [{'name': 'page-27-0.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 81}, {'name': 'page-27-2.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 81}, {'name': 'page-27-3.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 81}, {'name': 'page-27-4.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 177}, {'name': 'page-27-1.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 81}, {'name': 'page-27-7.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 177}, {'name': 'page-27-8.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 273}, {'name': 'page-27-6.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 177}, {'name': 'page-27-10.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 273}, {'name': 'page-27-5.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 177}, {'name': 'page-27-9.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 273}, {'name': 'page-27-11.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 273}]\n",
            "> Image for page 28: [{'name': 'page-28-3.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 127}, {'name': 'page-28-0.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 127}, {'name': 'page-28-5.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 223}, {'name': 'page-28-4.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 223}, {'name': 'page-28-2.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 127}, {'name': 'page-28-1.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 127}, {'name': 'page-28-7.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 223}, {'name': 'page-28-6.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 223}, {'name': 'page-28-8.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 319}, {'name': 'page-28-10.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 319}, {'name': 'page-28-9.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 319}, {'name': 'page-28-11.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 319}]\n",
            "> Image for page 29: [{'name': 'page-29-4.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 235}, {'name': 'page-29-8.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 331}, {'name': 'page-29-7.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 235}, {'name': 'page-29-6.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 235}, {'name': 'page-29-10.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 331}, {'name': 'page-29-11.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 331}, {'name': 'page-29-3.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 139}, {'name': 'page-29-2.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 139}, {'name': 'page-29-1.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 139}, {'name': 'page-29-0.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 139}, {'name': 'page-29-5.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 235}, {'name': 'page-29-9.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 331}, {'name': 'page-29-12.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 427}, {'name': 'page-29-13.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 427}, {'name': 'page-29-15.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 427}, {'name': 'page-29-18.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 523}, {'name': 'page-29-16.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 523}, {'name': 'page-29-14.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 427}, {'name': 'page-29-19.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 523}, {'name': 'page-29-17.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 523}]\n",
            "> Image for page 30: [{'name': 'page-30-1.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 87}, {'name': 'page-30-3.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 87}, {'name': 'page-30-0.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 87}, {'name': 'page-30-4.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 183}, {'name': 'page-30-2.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 87}, {'name': 'page-30-6.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 183}, {'name': 'page-30-5.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 183}, {'name': 'page-30-7.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 183}, {'name': 'page-30-9.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 279}, {'name': 'page-30-8.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 279}, {'name': 'page-30-12.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 457}, {'name': 'page-30-13.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 457}, {'name': 'page-30-11.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 279}, {'name': 'page-30-10.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 279}, {'name': 'page-30-14.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 457}, {'name': 'page-30-15.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 457}, {'name': 'page-30-17.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 553}, {'name': 'page-30-18.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 553}, {'name': 'page-30-16.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 553}, {'name': 'page-30-19.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 553}]\n",
            "> Image for page 31: [{'name': 'page-31-0.jpg', 'height': 96, 'width': 96, 'x': 112, 'y': 110}, {'name': 'page-31-1.jpg', 'height': 96, 'width': 96, 'x': 209, 'y': 110}, {'name': 'page-31-2.jpg', 'height': 96, 'width': 96, 'x': 307, 'y': 110}, {'name': 'page-31-3.jpg', 'height': 96, 'width': 96, 'x': 404, 'y': 110}]\n"
          ]
        }
      ],
      "source": [
        "image_text_nodes = get_image_text_nodes(json_objs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "OB0Cv_uIwmP4",
        "outputId": "0f202530-807b-4311-8cc1-0ee0be3f3d47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The image appears to be a digitally altered or photoshopped picture where a person is dressed in a panda costume and is also wearing a superhero costume, specifically resembling Spider-Man's iconic red and blue suit. The individual is squatting on the ground, with one arm extended forward as if mimicking Spider-Man's web-slinging action. The image is whimsical and humorous, combining elements of wildlife and popular culture. There is a blue vertical stripe obscuring part of the image on the left side.\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of an image description\n",
        "image_text_nodes[0].get_content()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "Wv_xeEDtnpiQ",
        "outputId": "f5207951-c6ae-4379-ea20-c971c3622b25"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The image is a line graph with a white background and a grid. The x-axis is labeled \"Percentage of dropped pixels\" and ranges from 20 to 80, with increments of 20. The y-axis is labeled \"SSIM\" and ranges from 0.75 to 0.90, with increments of 0.05. There are two lines representing different data sets plotted on the graph:\\n\\n1. A blue dashed line with diamond-shaped markers represents \"DPS.\" This line starts at approximately 0.88 SSIM at 20% dropped pixels and decreases steadily to about 0.78 SSIM at 80% dropped pixels.\\n\\n2. An orange dashed line with square markers represents \"PSLD.\" This line also starts at around 0.88 SSIM at 20% dropped pixels but decreases at a slower rate than the DPS line, ending at about 0.82 SSIM at 80% dropped pixels.\\n\\nThe graph is used to show the relationship between the percentage of dropped pixels and the Structural Similarity Index (SSIM), a measure of the similarity between two images. The two lines suggest that as more pixels are dropped, the SSIM decreases for both DPS and PSLD, with DPS experiencing a more significant decrease in SSIM compared to PSLD.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Example of an embedded graph description\n",
        "image_text_nodes[36].get_content()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "jnkpWWgak7Uc",
        "outputId": "db0b440e-6316-4ca7-a33e-b07fd9998b04"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The image is a close-up portrait of a woman with a neutral expression. She has medium-length brown hair, fair skin, and her eyes are looking directly at the camera. The background is a plain, muted green color, providing a contrast that highlights her features. The woman appears to be wearing minimal makeup with a natural look.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Another example of an image description\n",
        "image_text_nodes[100].get_content()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGBOPHzdkisl"
      },
      "source": [
        "# Bulding the Index across the Image and Text nodes\n",
        "Building this here to demo and test queries over this parsed data.\n",
        "\n",
        "**In production, we'd need to put the content into our vectorDB (Qdrant, VoyageAI).**\n",
        "\n",
        "> *Going to try and present questions to the model that will require answers from the 3 nodes referenced above.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTCiOXE9xrMg"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex(text_nodes + image_text_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZln6iB6oRVr"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFCJvXWbo9q9",
        "outputId": "36de36a5-d81c-4e9e-e8ae-c70ee6e713db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The graphs titled 'Percentage of dropped pixels' show the relationship between the percentage of dropped pixels and specific metrics (IPPS for one graph and SSIM for the other graph). Both graphs illustrate how as the percentage of dropped pixels increases, there is an impact on the corresponding metric being measured (IPPS or SSIM). In both cases, there is a clear trend where as more pixels are dropped, the metric value decreases, indicating a negative correlation between the percentage of dropped pixels and the metric being measured.\n"
          ]
        }
      ],
      "source": [
        "# ask question over image!\n",
        "response = query_engine.query(\"What do the graphs titled 'Percentage of dropped pixels' show?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXRHoBuLpN3_",
        "outputId": "1f306cbe-5aea-4b9e-b050-72a0bbb3d4b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The research findings indicate that as the percentage of dropped pixels increases, the similarity between images, as measured by SSIM, decreases. The data sets DPS and PSLD both show a decline in SSIM as more pixels are dropped, with DPS experiencing a more significant decrease compared to PSLD. This suggests that the method used to drop pixels impacts the similarity between images.\n"
          ]
        }
      ],
      "source": [
        "# ask question over text!\n",
        "response = query_engine.query(\"How would you summarize 3 key findings from this research for a non-technical reader?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT_UTGxuppnL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0014c037bf764d04823a551ef4c83fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9f6167df0c84883a9bff50c0e197c33",
              "IPY_MODEL_3d36543fc7284ad2bbe990513b4acde8",
              "IPY_MODEL_b8df078303d248e08c6d8df0e99ecd71"
            ],
            "layout": "IPY_MODEL_e1475b8608ae4a6a9fdc59157aa41718"
          }
        },
        "02348ddbe6af466285f6424472785b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2efae6ea209f49e6920fbad9b443fbe4",
            "placeholder": "",
            "style": "IPY_MODEL_e6ff92c06e18435fb63a840a43b9ff40",
            "value": "tokenizer.json:100%"
          }
        },
        "02f0ada298284f1892d63849aadb3ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03c4950aa5394851af4d8050b8262a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e7ca36488d48cd9f16463c09af646d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "072f814728ba4b55a9764de4db5feb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d90153df16dd4b25ba552bf4befcba95",
              "IPY_MODEL_9df5094a55524bcfa0fbbd1ba35df467",
              "IPY_MODEL_453abd3e2ac3450ead01e9ae09434133"
            ],
            "layout": "IPY_MODEL_e2d9693266be4d4ea01b822c12a93b38"
          }
        },
        "08358e92183e454086204c2e38d41024": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "091b69d527c54d06a6e030c7719e191a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09d808a0f9984bd3aaac93624b1b014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b0d781fbb94fa5ab898aa5e8eae2e8",
            "placeholder": "",
            "style": "IPY_MODEL_5ff9d0879da94483a817501bc694b0c9",
            "value": "special_tokens_map.json:100%"
          }
        },
        "09ff39f1691c4b31affca458dbdb9ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c95485d631c4815a634d24686017e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "106a4e8bec864f89939e06dfcc5e89e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d9e5a62b694211a0c7e0b06ebbd4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17641a2b875e4755a09b59e9d4256dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e58bbde5bf904548bf649967ec2137a8",
              "IPY_MODEL_5c91948dc37048e0a93f89061923b5f9",
              "IPY_MODEL_b6a7e005312c47c2887eef5a27d44c50"
            ],
            "layout": "IPY_MODEL_c01c91480a984148a6ddd42c05e34613"
          }
        },
        "1aa87194147243fa84d0e24a42e7adb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dc9a8db6a2c451ea3aa2e2a015b1fa7",
            "placeholder": "",
            "style": "IPY_MODEL_355ff71b02d543e7b39e4d270dc5029b",
            "value": "349/349[00:00&lt;00:00,16.6kB/s]"
          }
        },
        "1ebad4cd40464273bbe726ed5d14eada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81f7203d9ba547aa925eefdd38d1469c",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03e7ca36488d48cd9f16463c09af646d",
            "value": 743
          }
        },
        "212b4f74d9204dc7a7ad26e1d774efe3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2318c02473bd423e9a9ee0781861ea5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e118b7c61384bf893c64bf41faa8c80",
            "placeholder": "",
            "style": "IPY_MODEL_b7a24ecd92ee4d49b71b79b708325030",
            "value": "1_Pooling/config.json:100%"
          }
        },
        "28c42521a78149e3917cab9e984fc744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e28bfc0af043ed84c8c0e94e7d34c4",
            "placeholder": "",
            "style": "IPY_MODEL_cf536abd6250454fbf1d179381d879f8",
            "value": "711k/711k[00:00&lt;00:00,15.3MB/s]"
          }
        },
        "2ad7e7bb730c4d1f91d6b6dda763a3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dc9a8db6a2c451ea3aa2e2a015b1fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e38907d7ebc4a4f8de1a8f4a9ccd6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2efae6ea209f49e6920fbad9b443fbe4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3101d5dc061c44fe91d5cd62aaef1df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5787d2246c6c4076b7a55d916858c31f",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ad7e7bb730c4d1f91d6b6dda763a3a2",
            "value": 711396
          }
        },
        "33fbc212c8884f5f9d0b265c10d11062": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02348ddbe6af466285f6424472785b8e",
              "IPY_MODEL_3101d5dc061c44fe91d5cd62aaef1df7",
              "IPY_MODEL_28c42521a78149e3917cab9e984fc744"
            ],
            "layout": "IPY_MODEL_f7dc43724a5f41f3825d8ba8cceed9a6"
          }
        },
        "355ff71b02d543e7b39e4d270dc5029b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3801bcb88d27417e9d655bf7276800de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09ff39f1691c4b31affca458dbdb9ec3",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb7000e79c1446f78b6014df7ed3a2c4",
            "value": 125
          }
        },
        "3d36543fc7284ad2bbe990513b4acde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf63633fc63d4b99a59be501e051a46f",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b426c9fb44be46bd8a77e44a3a1f5fec",
            "value": 124
          }
        },
        "453abd3e2ac3450ead01e9ae09434133": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a25293b5d6ae4d3dadc5a2ab97f2103a",
            "placeholder": "",
            "style": "IPY_MODEL_8d3a14fcaf8c4ba19f5a406545feacf1",
            "value": "366/366[00:00&lt;00:00,9.54kB/s]"
          }
        },
        "4b59047e44d74e5e9a5f7e92990f1349": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bae38c885ff4ed98b08e0a451d10cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c11dbb4dbbc418595585a49771f5a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5c82c8538242a5bb05df7069883b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "510e73f9c1914184b43a623f3df1d41e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56514d14647a4c2fb849673fe684438e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212b4f74d9204dc7a7ad26e1d774efe3",
            "placeholder": "",
            "style": "IPY_MODEL_b394363b46c94cba95a90479abbd79c9",
            "value": "190/190[00:00&lt;00:00,6.64kB/s]"
          }
        },
        "5735745b5f50420fb8e56384e18eeef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f4e78a93d1c47c2bc4165fcbf5049e5",
              "IPY_MODEL_7596d0a8a0f44f6b829cbaf5bcb93aa9",
              "IPY_MODEL_d6daa09826ae476ba92e1694c1234662"
            ],
            "layout": "IPY_MODEL_9be24691c1724d2ab9afffb9af53990a"
          }
        },
        "5787d2246c6c4076b7a55d916858c31f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c91948dc37048e0a93f89061923b5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5cc17a7279d46f9bbce07c0e18bfa1a",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5616b6f22384033bc5a3259f282bb0a",
            "value": 133466304
          }
        },
        "5d1be1ec56744d1e83837ec25676fe68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f4e78a93d1c47c2bc4165fcbf5049e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde3bbfe14d04193b23f8983f1ad18ec",
            "placeholder": "",
            "style": "IPY_MODEL_7cabccb2074e4765b9b3cabeb7e72636",
            "value": "README.md:100%"
          }
        },
        "5ff9d0879da94483a817501bc694b0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60375d3fba2d42a1bb856dfd0704a582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee3b2e7a4afc42a38d41113d78ee1549",
              "IPY_MODEL_1ebad4cd40464273bbe726ed5d14eada",
              "IPY_MODEL_ca0aca54104a454f84b8dcb67e548d8e"
            ],
            "layout": "IPY_MODEL_e98ed21025424044b28a590fa1a6c325"
          }
        },
        "65e3219dfb134b59bd1bef6047573081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f6f764dc652464e81b242c8cd28d7b1",
            "placeholder": "",
            "style": "IPY_MODEL_e6216808409e4204979d75733ba16e20",
            "value": "232k/232k[00:00&lt;00:00,5.41MB/s]"
          }
        },
        "665326709ee149d28dfa6f11fc0cc9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6db0c5b620044215b52ccb2d2b57ccdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86ead2dacb444dd1a6efb096f9914eb2",
            "placeholder": "",
            "style": "IPY_MODEL_02f0ada298284f1892d63849aadb3ea6",
            "value": "vocab.txt:100%"
          }
        },
        "7596d0a8a0f44f6b829cbaf5bcb93aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94e554606a324fd49d0f7f577affa92b",
            "max": 94783,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9cb19d2b7454634accfb320d5d6d73f",
            "value": 94783
          }
        },
        "77ba62d27afa40f787907b1d23863822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_106a4e8bec864f89939e06dfcc5e89e1",
            "placeholder": "",
            "style": "IPY_MODEL_9c544995a1a34044802839016fb4c1b7",
            "value": "125/125[00:00&lt;00:00,2.85kB/s]"
          }
        },
        "792ffc9a5cc741e987d3e4d27e008e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0f7175f9964d5187a6c33eecf36ebf",
            "placeholder": "",
            "style": "IPY_MODEL_4bae38c885ff4ed98b08e0a451d10cd9",
            "value": "52.0/52.0[00:00&lt;00:00,3.00kB/s]"
          }
        },
        "7cabccb2074e4765b9b3cabeb7e72636": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e118b7c61384bf893c64bf41faa8c80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6f764dc652464e81b242c8cd28d7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a8585e97dd4136ab849733a3e9f9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80b03ef71d0e46c099e06e47be4565cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81f7203d9ba547aa925eefdd38d1469c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85083aeec32e4a718e3d80fea0ae9f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b486cbb24645a4a5c8241fb72060a3",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c5c82c8538242a5bb05df7069883b57",
            "value": 231508
          }
        },
        "8523ac99495f42e0bdbfd36fa719f82c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4398641f79448429b6818bc489702a4",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11d9e5a62b694211a0c7e0b06ebbd4db",
            "value": 52
          }
        },
        "86ead2dacb444dd1a6efb096f9914eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3a14fcaf8c4ba19f5a406545feacf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e1fd686e98e4958889919e15875fa88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ecde80adba84c3ca527f33007ee9a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc433ac0dcb475582f0ad0e6605f24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3ac953214640819126d0d38ac9f881",
            "placeholder": "",
            "style": "IPY_MODEL_c7cb7b1c70ed45dfb8b6e59a9605887a",
            "value": "modules.json:100%"
          }
        },
        "906fad7af45e42bb9439250b72be0797": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94e554606a324fd49d0f7f577affa92b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9be24691c1724d2ab9afffb9af53990a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c544995a1a34044802839016fb4c1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df5094a55524bcfa0fbbd1ba35df467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b59047e44d74e5e9a5f7e92990f1349",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80b03ef71d0e46c099e06e47be4565cf",
            "value": 366
          }
        },
        "a25293b5d6ae4d3dadc5a2ab97f2103a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4398641f79448429b6818bc489702a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ad58e4baf245e7a81cfd83e9ffb1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d7274695284dcba317e55a77e7f18c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6becdc96c934e11ba67d12120a99229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a883e7a835bd459198fb7faaf2c79bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad0f7175f9964d5187a6c33eecf36ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade5e69f577944e9aaeef094255eeada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fc433ac0dcb475582f0ad0e6605f24e",
              "IPY_MODEL_cb8ffa4a4e4846b2a243b817d8b85fd4",
              "IPY_MODEL_1aa87194147243fa84d0e24a42e7adb1"
            ],
            "layout": "IPY_MODEL_b2b2176b997c420983265595fc6909fe"
          }
        },
        "b2b2176b997c420983265595fc6909fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b394363b46c94cba95a90479abbd79c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b426c9fb44be46bd8a77e44a3a1f5fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5cc17a7279d46f9bbce07c0e18bfa1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a7e005312c47c2887eef5a27d44c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c713156f2b4745938aee66b3d8e90716",
            "placeholder": "",
            "style": "IPY_MODEL_08358e92183e454086204c2e38d41024",
            "value": "133M/133M[00:01&lt;00:00,120MB/s]"
          }
        },
        "b7a24ecd92ee4d49b71b79b708325030": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8df078303d248e08c6d8df0e99ecd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c56171bcf23147d0ba722241aef388cc",
            "placeholder": "",
            "style": "IPY_MODEL_c7c199b6b57041a0a47cce98b2280fd6",
            "value": "124/124[00:00&lt;00:00,4.29kB/s]"
          }
        },
        "bb4e5681c4b844f9a44a76df8c51ab59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c01c91480a984148a6ddd42c05e34613": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0e28bfc0af043ed84c8c0e94e7d34c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56171bcf23147d0ba722241aef388cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67dd0e41fcc480fb1be128f8e8f0339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5e49c5c1fdf4e4db27b3989c04c4d39",
              "IPY_MODEL_8523ac99495f42e0bdbfd36fa719f82c",
              "IPY_MODEL_792ffc9a5cc741e987d3e4d27e008e93"
            ],
            "layout": "IPY_MODEL_e654a0c8aacf4d7e87d1e85b1726ae15"
          }
        },
        "c713156f2b4745938aee66b3d8e90716": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b486cbb24645a4a5c8241fb72060a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c199b6b57041a0a47cce98b2280fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7cb7b1c70ed45dfb8b6e59a9605887a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9cb19d2b7454634accfb320d5d6d73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca0aca54104a454f84b8dcb67e548d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb60692e822043d7b725b03d53429981",
            "placeholder": "",
            "style": "IPY_MODEL_8e1fd686e98e4958889919e15875fa88",
            "value": "743/743[00:00&lt;00:00,42.3kB/s]"
          }
        },
        "cb0c3060600042508cf7ea863d1f49bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09d808a0f9984bd3aaac93624b1b014c",
              "IPY_MODEL_3801bcb88d27417e9d655bf7276800de",
              "IPY_MODEL_77ba62d27afa40f787907b1d23863822"
            ],
            "layout": "IPY_MODEL_2e38907d7ebc4a4f8de1a8f4a9ccd6aa"
          }
        },
        "cb8ffa4a4e4846b2a243b817d8b85fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c4950aa5394851af4d8050b8262a9e",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_091b69d527c54d06a6e030c7719e191a",
            "value": 349
          }
        },
        "cd760c9f68384b2fb03521659e7d7dba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde3bbfe14d04193b23f8983f1ad18ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf536abd6250454fbf1d179381d879f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf63633fc63d4b99a59be501e051a46f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5616b6f22384033bc5a3259f282bb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6daa09826ae476ba92e1694c1234662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b96fc09be844ed9ffe7ad43e87ac12",
            "placeholder": "",
            "style": "IPY_MODEL_a6becdc96c934e11ba67d12120a99229",
            "value": "94.8k/94.8k[00:00&lt;00:00,2.20MB/s]"
          }
        },
        "d90153df16dd4b25ba552bf4befcba95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd760c9f68384b2fb03521659e7d7dba",
            "placeholder": "",
            "style": "IPY_MODEL_0c95485d631c4815a634d24686017e2d",
            "value": "tokenizer_config.json:100%"
          }
        },
        "d9b0d781fbb94fa5ab898aa5e8eae2e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1475b8608ae4a6a9fdc59157aa41718": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e29576ad44d84e5890a5c717fe3ae3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6db0c5b620044215b52ccb2d2b57ccdf",
              "IPY_MODEL_85083aeec32e4a718e3d80fea0ae9f5e",
              "IPY_MODEL_65e3219dfb134b59bd1bef6047573081"
            ],
            "layout": "IPY_MODEL_a883e7a835bd459198fb7faaf2c79bd2"
          }
        },
        "e2b96fc09be844ed9ffe7ad43e87ac12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d9693266be4d4ea01b822c12a93b38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58bbde5bf904548bf649967ec2137a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d7274695284dcba317e55a77e7f18c",
            "placeholder": "",
            "style": "IPY_MODEL_bb4e5681c4b844f9a44a76df8c51ab59",
            "value": "model.safetensors:100%"
          }
        },
        "e5e49c5c1fdf4e4db27b3989c04c4d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ecde80adba84c3ca527f33007ee9a1e",
            "placeholder": "",
            "style": "IPY_MODEL_906fad7af45e42bb9439250b72be0797",
            "value": "sentence_bert_config.json:100%"
          }
        },
        "e6216808409e4204979d75733ba16e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e654a0c8aacf4d7e87d1e85b1726ae15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ff92c06e18435fb63a840a43b9ff40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e98ed21025424044b28a590fa1a6c325": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f6167df0c84883a9bff50c0e197c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4ad58e4baf245e7a81cfd83e9ffb1bf",
            "placeholder": "",
            "style": "IPY_MODEL_665326709ee149d28dfa6f11fc0cc9fb",
            "value": "config_sentence_transformers.json:100%"
          }
        },
        "eb60692e822043d7b725b03d53429981": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee3b2e7a4afc42a38d41113d78ee1549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c11dbb4dbbc418595585a49771f5a6b",
            "placeholder": "",
            "style": "IPY_MODEL_80a8585e97dd4136ab849733a3e9f9e4",
            "value": "config.json:100%"
          }
        },
        "ef6769ed7b2a429d9f3f5d5fc7e134aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66babf1da964042806dc2faa6f957a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2318c02473bd423e9a9ee0781861ea5a",
              "IPY_MODEL_f76cb6ada7fc475fafc3f15da9ceed40",
              "IPY_MODEL_56514d14647a4c2fb849673fe684438e"
            ],
            "layout": "IPY_MODEL_510e73f9c1914184b43a623f3df1d41e"
          }
        },
        "f76cb6ada7fc475fafc3f15da9ceed40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef6769ed7b2a429d9f3f5d5fc7e134aa",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d1be1ec56744d1e83837ec25676fe68",
            "value": 190
          }
        },
        "f7dc43724a5f41f3825d8ba8cceed9a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7000e79c1446f78b6014df7ed3a2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc3ac953214640819126d0d38ac9f881": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
